{"description": " relative paths in tests can point directly to .d.ts files. however, those references don't reflect what users can actually write. this pr rewrites references like './index' and \"..\" to the name of the package. ansi-styles had an unused reference, so i just deleted that one. ", "commit_messages": " fix relative paths in tests, attempt 1  revert athenajs change ", "linked_issue_titles": "", "title": "fix relative paths in tests, part 1"}
{"description": " changes get_class() to disallow null being a valid parameter, as that behaviour is highly astonishing. the ratio of the number of characters in the rfc to the actual code change, is too darn high. ", "commit_messages": " require parameter to be an object if passed.  add test.  fixed ext/standard test that calls get_class() ", "linked_issue_titles": "", "title": "get_class() disallow null parameter rfc"}
{"description": " closes #14799 closes #15034 fixes #14774 @amueller i think this is enough? (that doesn't fix the nonsense that the attribute has size 2 (i.e. 2 classes) for oneclass and svr but that's a different issue)  it does now ", "commit_messages": " fixed n_support  removed comment  add comment ", "linked_issue_titles": " oneclasssvm n_support_ returns incorrect value ", "title": "fixed n_support_ attr for oneclasssvm and svr"}
{"description": " refactor typecheckfunctionbodyrequest to return the type-checked body, and remove typecheckabstractfunctionbody in favor of a method on abstractfunctiondecl. in addition, start returning an errorexpr body instead of a partially type-checked body if type-checking fails. then, start using gettypecheckedbody in silgen to allow lazy type-checking when emitting function definitions. ", "commit_messages": " [ast] remove newbodykind default  a bunch of callers were accidentally misusing it.  add abstractfunctiondecl::gettypecheckedbody  refactor typecheckfunctionbodyrequest to return  the type-checked body, and remove  typecheckabstractfunctionbody in favor of  a method on abstractfunctiondecl. in addition,  start returning an errorexpr body instead of  a partially type-checked body if type-checking  fails.  add some missing calls to setthrows  we no longer run error checking for already  type-checked synthesized functions, so add a  couple of setthrows calls where they were  previously missing.  [silgen] use gettypecheckedbody  use gettypecheckedbody to allow lazy  type-checking when emitting function definitions. ", "linked_issue_titles": "", "title": "add and use abstractfunctiondecl::gettypecheckedbody"}
{"description": " xref #30539 ", "commit_messages": " pandas\\core\\common.py:273: error: implicit generic \"any\". use \"typing.list\" and specify generic parameters  pandas\\core\\arrays\\categorical.py:514: error: implicit generic \"any\". use \"typing.list\" and specify generic parameters  pandas\\core\\indexing.py:2227: error: implicit generic \"any\". use \"typing.tuple\" and specify generic parameters  pandas\\core\\groupby\\grouper.py:422: error: implicit generic \"any\". use \"typing.dict\" and specify generic parameters  pandas\\tests\\frame\\methods\\test_replace.py:15: error: implicit generic \"any\". use \"typing.list\" and specify generic parameters  pandas\\tests\\frame\\methods\\test_replace.py:20: error: implicit generic \"any\". use \"typing.list\" and specify generic parameters  pandas\\io\\pytables.py:1462: error: implicit generic \"any\". use \"typing.list\" and specify generic parameters ", "linked_issue_titles": "", "title": "implicit generic \"any\" for builtins"}
{"description": " reduces checkstyle errors for patterns: api-gateway lazy-loading leader-election changes involved java docs reordering imports indentations line length issues ", "commit_messages": " reduces checkstyle errors in lazy-loading  reduces checkstyle errors in leader-election  reduces checkstyle errors in api-gateway ", "linked_issue_titles": "", "title": "resolves checkstyle errors for api-gateway, lazy-loading, leader-election"}
{"description": " issue: #13336 primarily this fixes the handling of the -s (--static-dir) flag for windows users. this flag accepts a string in the shape of <dirname>:<endpoint>. currently it fails to handle absolute paths on windows: for a value like c:\\path it would assume c to be the dirname and \\path the endpoint. that bug is addressed here. besides fixing the bug at hand, i've extracted this piece of logic into a util, because it previously existed in two separate places. the util is now under unit test and the surrounding code has been cleaned up with some nicer logging. i've also replaced shelljs with copy from fs-extra. one less dependency is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no ", "commit_messages": " extract static file handling to utils and make sure we handle windows well.  we no longer need shelljs. ", "linked_issue_titles": "", "title": "fix --static-dir with absolute path on windows"}
{"description": " added some questions and answers in the filehandle and oop perl topics. ", "commit_messages": " new questions and spell check (#181)  added new questions related with kvm, libvirt and dnf  new perl questions and answers  added some questions and answers in the filehandle and oop topics. ", "linked_issue_titles": "", "title": "feature/new perl questions and answers"}
{"description": " new features others this pr added basic support for 'return' grammar in dy2stat. it supports the control flow of 'return'. the basics idea is using a return value variable to store the early return statements and boolean state variables with if-else to skip the statements after the return statements. this pr is very basic support. there are some corner cases i didn't develop/test. for example, 'return none', 'return different length of variables', 'return non-tensor and tensor together', 'no return statement'. these corner cases will be done in my next prs. target date is this week. note: for the unit test, i changed test_program_translator.py because the staticcode of dyfunc_with_if_else will change. to guarantee the correctness of dyfunc_with_if_else, i also run it in testrecursivereturn in test_return.py. i commented the early return code in bert_dygraph_model.py because 'return different length of variables' is unsupported now. i also know that there are some other models used early return and we didn't enable it in the unit test. i will add support for it in next prs and then re-enable those tests. ", "commit_messages": " add return_transformer, not tested. test=develop  test=develop  add unittest and fix some bugs before testing. test=develop ", "linked_issue_titles": "", "title": "add basic support for grammar 'return'"}
{"description": " and some cosmetics related to the fix this also fixes issues with wrong rendering size after dpi changes and/or display switch off/on ", "commit_messages": " [xbmc] application: handle resize event even in full screen state on windows.  [windowing] win32: update handling wm_dpichanged event ", "linked_issue_titles": "", "title": "don't react on dpi change event on win10 >= fcu"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. (not applicable) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. (already available) ", "commit_messages": " updated typings to match vimeo's player.js v2.6.3, updated tests to reflect new methods, properties, and events  cleanup of unused boilerplate lines  setplaybackrate may return rangeerror  options argument in constructor is optional  removed typings for unexposed internals  both playermap and readymap are internal weakmaps in vimeo's player.js and are never exposed, so there is no need to export their types.  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "removing typings for unexposed internals"}
{"description": " add debug_* constants in place of the hardcoded values. should help making self-documenting code move endian fixes to clang, previous pr was merged... fast :) i was trying to automatically insert bpf_probe_read in situations like ", "commit_messages": " move endian flags to kbuild_helper  add debug constants ", "linked_issue_titles": "", "title": "minor endian and debug enhancement"}
{"description": " i hereby agree to the terms of the cla available at:  fix document for index.md and distinctive-features.md fix document for introduction toc priority detailed description / documentation draft: by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. ", "commit_messages": " fix document for index.md and distinctive-features.md  fix document for introduction toc priority ", "linked_issue_titles": "", "title": "fixed a problem with the translation of introduction"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add and fix line-styles  fix typo  add text-wrap style  add tests ", "linked_issue_titles": "", "title": "fixed typos and added new style options"}
{"description": " make sure set the target branch to develop #3162 add msgtraceenable config in transaction producer benchmark follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. ", "commit_messages": " fix checkstyle fail  add msgtraceenable config in transaction producer benchmark ", "linked_issue_titles": " add msgtraceenable config in transaction producer benchmark ", "title": "[issue #3162 ]add msgtraceenable config in transaction producer benchmark"}
{"description": " this pr fixes #13767 adding in additional interfaces to correctly define certain easing factories, which allow parameterization (i.e. poly, back and elastic) it is related to #11365 and #11366. thanks for spotting the bug @billdwhite make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"../tslint.json\" }. ", "commit_messages": " fetch-merge commit from dt master  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'definitelytyped/master'  d3-ease:  * [fix]: added interfaces and changed definitions for three classes of easing functions, which can be parameterized. fixes #13767.  * [enhancement]: activated strictnullchecks after validation  * [chore]: added jsdoc comments  * [chore]: added linting config file. ", "linked_issue_titles": " [bug] d3-ease omitted easing function parameterizations ", "title": "add parameterization, strictnullchecks and  jsdoc comments"}
{"description": " this adds support for setting docker_graphdriver and docker_execdriver to select the graph driver and the execution driver for the cli integration tests. this pr also fixes a race at the end of the test-integration-cli which makes the tests always fail on some systems. ", "commit_messages": " cli integration: allow driver selection via vars  this makes it possible to choose the graphdriver and the execdriver  which is going to be used for the cli integration tests.  docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack)  cli integration: fix wait race  the wait at the end of cli integration script could end up failing if  the process had already exited. this was making it look like the tests  have failed.  this change fixes the problem.  docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) ", "linked_issue_titles": "", "title": "add docker options & fix the wait at the end"}
{"description": " description: when using !include_dir_list in yaml to bring in the contents of multiple yaml files as entries in a list, there is currently no way to control the order of that list.    a typical use is when creating lovelace views: if you use one file per tab then they appear in random order. this one-word patch causes files to be incorporated in alphanumeric order, which makes it predictable and controllable. checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io.  the pr is here. if the code does not interact with devices: ", "commit_messages": " make yaml includes such as !include_dir_list incorporate files in alphabetical order  test for !include_dir_list sorting ", "linked_issue_titles": "", "title": "make !include_dir_list use alphanumeric order"}
{"description": " this is an implementation of eap-tls protocol for the ppp stack. yes, now you can authorize via certificates using native windows clients too. i've implemented the eap stack kinda basically for now, but i hope it would be possible to expand it. although i'm not sure what else would be needed to implement. i was thinking implementing eap-ttls with inner eap protocol for secure password-based authentication (plaintext mschapv2 is kinda meh), but we got either ssl of sstp or ipsec of l2tp (noone uses plain l2tp, right?), so i guess this is already \"secure enough\" even with pap... anyway, i've also adjusted the user policy timeouts - now they are propagating correctly in ppp-based protocols too. another important thing. i've added the ability to load ca certificates from the chain_certs folder (and basically making them trusted). before that we had no way of loading our own ca certificates to pass the verification of the client certificate, now we do. but it should be noted, that this is a change which may arise questions about security of such a decision. maybe we should create a configuration setting and making it working only when it is true, and making it false by default. some changes to newsslpipeex were mostly hacks to allow working different clients (once again the android sstp \"vpn client pro\" gave me a headache...), for example for some reason pppd doesn't go well with tlsv1.3. i've tested it on sstp windows 10 native client, sstp \"vpn client pro\" on android, sstp-client on linux (of course all with certificates). as i don't have access to ios and macos devices, tests would be highly appreciated. big thanks for @davidebeatrici who directed me in the direction of newsslpipeex, which was the key to implement this at all. i hope my code is not too horrible. =) ", "commit_messages": " adding timeout propagation from user policy in ppp sessions (including l2tp and sstp).  fixing errors as per static analysis  writing skeleton for eap-tls implementation  preliminary (untested) eap-tls implementation  fixing up some errors  added possibility to load ca certificates from chain_certs folder to allow verifying the client certificates against it.  fixing linux... ", "linked_issue_titles": "", "title": "implementation of eap-tls for ppp"}
{"description": " #18324 checks to see if x features are all 0 variance. if so, raises value error and will avoid divide by 0. not sure if this is desired behavior but seems like best way to handle, let me know if the error message is specific enough. ", "commit_messages": " added value error for divide by zero caused by zero variance in all features.  formatting fix ", "linked_issue_titles": "", "title": "nearest centroid divide by zero fix"}
{"description": " 1.adjust the related tolua files from external/lua/tolua to cocos/scripting/lua-bindings/manual/tolua, and adjust cocos/scripting/lua-bindings/manual/tolua_fix.cpp/.h to cocos/scripting/lua-bindings/manual/tolua 2.remove the reference of files in the external/lua/quick, and adjust the lua template. 3.adjust cocos_headers in the cocos2dx_studio.ini for lua bindings-generator ", "commit_messages": " adjust the related tolua files from external/lua/tolua to cocos/scripting/lua-bindings/manual/tolua and update the project configure  remove the files in the external/lua/quick from project and adjust the related configuration and lua template project ", "linked_issue_titles": "", "title": "adjust the directory structure for libluacocos2d project and update the configuration and the lua template"}
{"description": " part of #21125 fixes #95074 ", "commit_messages": " move links files into own folder, start regex link provider  basic regex link detection  pass in validation callback  add first test for regex local link provider  port old link format tests  rename to validated  create word link provider  fix compile ", "linked_issue_titles": " emojis before terminal links offset underline position when experimentallinkprovider is turned on ", "title": "support validated regex-based link detection and word-based as a fallback that uses quick access"}
{"description": " (click an open the full image if viewing on a non-retina display) this patch adds support for window.devicepixelratio in the canvas renderer. animations using the canvas renderer on screens with a high pixel density > 1 (e.g. apple's retina displays) now look much crisper. to achieve this effect, the canvas size is multiplied by the value in  window.devicepixelratio (e.g. 2), while the size of the wrapper element remains the same. this makes the browser scale down the canvas element, resulting in a much crisper image. the effect is enabled by default if animationitem.wrapper exists and config.dpr is not set to a different value. it is also possible to set config.dpr manually. ", "commit_messages": " add support for window.devicepixelratio in canvas renderer  add check for config object ", "linked_issue_titles": "", "title": "add device pixel ratio support"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add methods  add examples of method use ", "linked_issue_titles": "", "title": "add instance methods to react native material textfield"}
{"description": " fixes #100709 ", "commit_messages": " move some ptyprocessready usage inside proc manager  part of #100709  fix compile  directly expose environmentvariableinfo  it's readonly on the interface  create a new pty ready promise on relaunch ", "linked_issue_titles": " improve how process is managed when the terminal is reused ", "title": "make terminal relaunch logic more internal to the process manager"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). no functional changes, just added new exports for use in module loaders, and removed all but 1 disabled linter rules and fixed the linting issues in the module and the tests.  the remaining listing error for having i in the interface name would be a breaking change so i did not fix that. ", "commit_messages": " improve importability of angular-websocket  move tslint, tsconfig closer to defaults, fix all linting issues ", "linked_issue_titles": "", "title": "improve angular-websocket importability, fix linter issues"}
{"description": " make parenthesis optional for named expressions used with while statement. the following used to be a syntaxerror which should be valid according to pep 572. this pr fixes the same. while match := pattern.search(f.read()): pass feel free to rephrase news entry if needed. i couldn't come up with a good test for an actual program for this case without reading a file or iteration. so i have added a test only to test_parser to make sure this is syntactically valid. cc : @gvanrossum @emilyemorehouse ", "commit_messages": " add parenthesis optional in named expressions for while statement  add news entry ", "linked_issue_titles": "", "title": "make parenthesis optional for named expression in while statement"}
{"description": " current implementation of 429 handling was totally flawed (many mistakes on promise usage, like resolving+rejection of the same promise, creating promise and throwing it away, 429 retry within 429 retry, etc.). this pr fixes this. ", "commit_messages": " bugfixes for aws.request 429 handling  conflicts:  lib/provideraws.js ", "linked_issue_titles": "", "title": "bugfixes for 'too many requests' usage"}
{"description": " fix a bug where you cannot switch between ct/e2e by correctly closing the existing project before opening a new one update global mode to show recent projects instead of hard-coded placeholders open recent project when selecting one from the global mode \"welcome\" component fix a bug where it flashes \"loading\" without styles on the open browser screen - now it shows the browsers immediately demo: demo2.mov ", "commit_messages": " allow to switch between ct and e2e seamlessly  show most recent projects  update test ", "linked_issue_titles": "", "title": "fix bugs and update global mode component"}
{"description": " address problem with #12377 by setting threshold my appropriately. ran test with 10000 random seeds and did not produce error. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change set activation to 1e-5 ", "commit_messages": " remove disable flag  finite difference should use mean  lower numerical eps  set threshold to 1e-5 ", "linked_issue_titles": "", "title": "fix test_activation by lowering threshold + validate eps for check_numeric_gradient"}
{"description": " this finishes the implementation of --window to also accept a string as the \"name\" of the window. so you can say wt -w foo new-tab wt -w foo split-pane and have both those commands execute in the same window, the one named \"foo\". this is just slightly more ergonomic than manually using the ids of windows. in the future, i'll be working on renaming windows, and displaying these names. --window,-w <window-id> run these commands in the given windows terminal session. this enables opening new tabs, splits, etc. in already running windows terminal windows. if window-id is 0, run the given commands in the current window. if window-id is a negative number, or the reserved name new, run the commands in a new terminal window. if window-id is the id or name of an existing window, then run the commandline in that window. if window-id is not the id or name of an existing window, create a new window. that window will be assigned the id or name provided in the commandline. the provided subcommands will be run in that new window. if window-id is omitted, then obey the value of windowingbehavior when determining which window to run the command in. before this pr, i think we didn't actually properly support assigning the id with wt -w 12345. if 12345 didn't exist, it would make a new window, but just assign it the next id, not assign it 12345. #4472, #8135  ran tests messed with naming windows, working as expected. closes ", "commit_messages": " rebase all the changes on main  the history of this had gotten way, way too long. it included everything since i started working on this  fix a bug and fix the tests  fix tests  good ole java  finish that test ", "linked_issue_titles": "", "title": "add support for naming windows with the -w parameter"}
{"description": " i have added an algorithm for swap case in string folder i have fixed unexpected expression part from 2 algorithm. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " removed an extra '=' which was creating an error while running a program.  removed the unexpected expression part.  added program for swap cases in string folder ", "linked_issue_titles": "", "title": "added swap case program and removed unexpected expression part"}
{"description": " this pr addresses two aspects of the c++ launcher compilations, and fixes #1729. handling versions with this pr, upon build time the version string is automatically generated by reading the contents of changelog.md and adjusting a resource file. atm, the copyright/company info is hardcoded directly into the template file because i was unsure whether i should've read them from readme.me. added manifest the manifest file handles dpi-awareness (prevents the messagebox becoming blurry) and controls the uac definitions. (more work needs to be done on the subject of dpi-awareness and switching the dialogs to taskdialog as discussed in #1726.) ", "commit_messages": " fixed line endings  added version resources and manifest.  add cmder manifest file  added version.rc2.sample  this file controls how the version strings appears in the final compiled .exe file  add functions to get version and generate rc  these functions can be used to a) extract the version from changelog.md and b) create a .rc2 file from the sample template by replacing its content  add automatic version creation  with this commit, the build script extracts the latest version string found in changelog.md, and then creates appropriate resource files for the executable compilation ", "linked_issue_titles": " cmder.exe should have a version number ", "title": "generate win32 version string based on build no, git tag or fallback to changelog"}
{"description": " doc only changes, no code changes. ", "commit_messages": " convert comments to rustdocs for box, char, comm and cytpes.rs  add spaces before newlines in rustdocs  forgot to add some spaces before backslashes  remove un-needed &lt; ", "linked_issue_titles": "", "title": "rustdocs for box.rs, comm.rs, ctypes.rs, char.rs"}
{"description": " related issue: #22267 i converted all *utils files in the examples to esmodules to allow for tree-shaking. they now need to be imported like this: import * as nurbsutils from '../curves/nurbsutils.js'; the files i touched are nurbsutils, camerautils, sceneutils, geometrycompressionutils, geometryutils, skeletonutils. i had to move packedphongmaterial out of geometrycompressionutils as well. ", "commit_messages": " nurbsutils: convert to esmodules  camerautils: convert to esmodules  sceneutils: convert to esmodules  geometrycompressionutils: convert to esmodules  geometryutils: convert to esmodules  skeletonutils: convert to esmodules  nurbsutils: update imports  camerautils: update imports  geometrycompressionutils: update imports  geometryutils: update imports  skeletonutils: update imports ", "linked_issue_titles": "", "title": "convert utils files to esmodules"}
{"description": " commit message: to prevent long event loop when too many udp packets are in the queue, limit how many packets to read in each event loop. if haven't finished reading, artifacts a read event to continue in the next event loop. add numpacketsexpectedpereventloop() callback to udplistenercallback, so that quic listener can tell how many packets it wants to read in each loop. the actually number of packets read are still bound by max_num_packets_per_event_loop (6000). quic listener returns numpacketsexpectedpereventloop() based on number of connections it has at the moment and the configured envoy::config::listener::quicprotocoloptions.packets_to_read_to_connection_count_ratio. made injectablesingleton really thread safe. risk level: medium, other than quic listener, other udplistenercallbacks return max size_t for numpacketsexpectedpereventloop(). this will cause those callbacks to read 6000 packets per read event. testing: added udp listener unit tests. fixes #16335 #16278 part of #16198 #16493 ", "commit_messages": " add read limit  test pass  refine comments ", "linked_issue_titles": " flakes in ipversions/http2integrationtest.largeflowcontrolonandgiantbodywithcontentlength/ipv6_http3downstream_httpupstream ", "title": "limit number of reads per event loop"}
{"description": " tagging @kiall for review, thanks! with the current chart, if .values.storageclass.create is false, the parameters and mountoptions were still rendered in the template, thus making the chart undeployable (since the manifest is not complete). this pr simply moves the else clause of the .values.storageclass.create to the end of the file, so that the rendered template is completely empty (no-op), and the deployment succeeds. (i did not create an issue for this, as the fix is trivial) dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " when a storage class is not created, mountoptions and parameters are also not included in the file  bump nfs-server-provisioner version ", "linked_issue_titles": "", "title": "fix deployment when not creating storage class"}
{"description": " this pr includes minor edits to the data frame transform apis and the delete anomaly detection job api in the java rest client documentation. for example, it addresses the feedback in #44839 (comment) ", "commit_messages": " [docs] minor edits to data frame transform apis  [docs] minor edits in hlrc delete job api ", "linked_issue_titles": "", "title": "minor edits to hlrc ml apis"}
{"description": " description: adding support for other ptz move modes of  onvif integration only supports relativemove where it should also supports absolutemove and continuousmove. for exemple chinese goke gk7102 based ip camera only support continuousmove mode. this pr add those new modes with avaibility to select mode and params in service call. breaking change: the onvif camera service camera.onvif_ptz has been moved from the camera domain to the onvif domain.  onvif_ptz service was also renamed to ptz. so service calls need to be updated to onvif.ptz. changes: add continuousmove mode add continuous_duration delay to stop movement after that delay add absolutemove mode use service.data[key] instead of service.data.get(key) for keys with default schema values lovelace integration sample: - type: entity-button entity: camera.foscam icon: mdi:arrow-left-bold-outline show_name: false tap_action: action: call-service service: onvif.ptz service_data: entity_id: camera.foscam pan: left tilt: zoom: move_mode: continuousmove continuous_duration: 0.8 distance: 1 related issue (if applicable): at least #27744 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io home-assistant/home-assistant.io#11557 breaking change: domain moved from camera to onvif so service calls need to be update to onvif.onvif_ptz the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " adding support for ptz move modes  adding support for other ptz move modes.  onvif intergration used to only support relativemove where it should also supports absolutemove, continuousmove and stop.  for exemple goke gk7102 based ip camera only support continuousmove mode.  this commit add those new modes with avaibility to select mode and params in service call.  adding support for ptz move modes  adding support for other ptz move modes.  onvif intergration used to only support relativemove where it should also supports absolutemove, continuousmove and stop.  for exemple goke gk7102 based ip camera only support continuousmove mode.  update service helper for new avaibility to select mode and params in service call. ", "linked_issue_titles": "", "title": "add more onvif ptz move modes"}
{"description": " previously the serve controller took 1 cpu and each http proxy actor took 1 cpu.  this is unnecessarily constraining in most cases.  for example, on a machine with 2 cpus, serve wouldn't have any available cpus remaining to start new replicas. this pr sets num_cpus=0 for the serve controller actor and the serve http proxy actors by default.  it also adds the option dedicated_cpu: bool = false in  serve.start() for the controller, and an option num_cpus = 0 inhttpoptions for the http proxies, to allow the user to reserve cpus as needed. the controller can thus have either 0 or 1 cpu, the proxies can each have any number of cpus (the same number of cpus for each proxy.) i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " set num_cpus to zero for controller and proxy  add dedicated_cpu parameters  lint  add test  lint ", "linked_issue_titles": "", "title": "set controller and http proxy num_cpus=0 by default"}
{"description": " 'd with @jasonrudolph fixes #19311 in #19244, i included a dependency on @atom/notify to support watching the file system. it spawns an external binary, which worked fine in tests and in dev mode, but broke when the module was packaged in an asar archive. if you want to spawn a process from a node module that is inside an asar archive, that binary must be on the physical file system. electron's file system hacks support require and other file system operations, but they don't support spawn. this pr updates the @atom/notify dependency to support transforming the binary path to account for the module being packaged in a separate location (atom.asar/@atom/notify) than the binary it is trying to spawn (atom.asar.unpacked/@atom/notify/bin). ", "commit_messages": " exclude notify binary from asar bundle  fix @atom/notify's binary path when running within atom's asar archive  /  :arrow_up: @atom/notify@1.3.2 to remove unnecessary require.resolve step ", "linked_issue_titles": " unable to spawn notify subprocess on windows ", "title": "exclude @atom/notify binary from the asar bundle"}
{"description": " added set which does exist ( add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added set to available types  added set which does exist (  updated tests  - added tests for str  - added tests for pick  bumped version ", "linked_issue_titles": "", "title": "added set method to available types for dot-object package"}
{"description": " rationale it is better to compute the auctionend once during contract creation than to compute it every time someone bids. it is also better to not store unnecessary information on the blockchain. i found these issues distracting while learning solidity. change simpleauction does less computing for each bid by retaining the more-relevant auctionend instead of auctionstart. simpleauction drops its now-unused biddingtime variable. blindauction drops its already-unused auctionstart variable. ", "commit_messages": " remove auctionstart  also rm biddingtime ", "linked_issue_titles": "", "title": "replace biddingtime with auctionend in auction example"}
{"description": " this pr fixes the logic introduced in #15104 to only check for callback parameters when we aren't in a recursive call to comparesignaturesrelated that resulted from an outer callback check. fixes #18277. ", "commit_messages": " don't check for callbacks in recursive call that resulted from callbacks  add regression test  accept new baselines ", "linked_issue_titles": " stack overflow while type checking generic, mutually-defined function interfaces ", "title": "fix checking of recursive callback types"}
{"description": " update the chinese electron mirror url - this should avoid the \"china mirror does not have a v prepended to the electron version in the url\" problem. the cache directory scheme changed (electron/get#113), so update the example directory structure. remove the remaining references to electron-download. cc: @electron/wg-ecosystem npm lint:docs passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " doc: update chinese electron mirror url  doc: replace remaining references of electron-download with @electron/get  doc: update cache dir example based on recent @electron/get cache changes ", "linked_issue_titles": "", "title": "update installation docs to reflect latest @electron/get changes"}
{"description": " i hereby agree to the terms of the cla available at:  fix possible error totals having transform was already added to pipeline in case of a query from delayed replica. ", "commit_messages": " update test.  fix totals and extremes for delayed replica. ", "linked_issue_titles": "", "title": "fix totals for delayed replica"}
{"description": " added a mnist and an imagenet example to show how to run mxnet with horovod. readme page is also added. readme mxnet_mnist.py mxnet_imagenet.py ", "commit_messages": " add examples for mxnet with horovod  update readme ", "linked_issue_titles": "", "title": "add examples of running mxnet with horovod"}
{"description": " fix win32 js project crash issue: 445442c ", "commit_messages": " fix #24345  squashed commit of the following:  commit aff4e27200a77db60b13ea30c2457558e5f53059  author: ricardo quesada <ricardoquesada@gmail.com>  date:   thu dec 10 17:58:41 2015 -0800  compiles with new gc model  commit 1fa69cd71231d56371cd45a378e50a1888308b42  author: ricardo quesada <ricardoquesada@gmail.com>  date:   thu dec 10 17:41:15 2015 -0800  animation3d works ok  commit d439969caf7e6fe83a74e37d078c4361a08cb816  author: ricardo quesada <ricardoquesada@gmail.com>  date:   thu dec 10 13:39:50 2015 -0800  sprite3d create: converted to new api  commit aabe449e4a968fad882c44df9be787eb7c3bfcec  author: ricardo quesada <ricardoquesada@gmail.com>  date:   thu dec 10 13:27:33 2015 -0800  ouch...  commit 688ab610a8cb7607bc3c51b8ca01d800ef3c9794  author: ricardo quesada <ricardoquesada@gmail.com>  date:   thu dec 10 13:12:25 2015 -0800  spawn/sequence init* were not bound  fixed. now js scheduler test works ok  adds memorymodeltest  update changelog  mooooores fixes  but gc memory model doesn't work yet... somewhere someone is still  retaining a reference that prevents the whole thing from  releasing  restores autobindings  squashed commit of the following:  [ci skip][auto]: updating luabinding & jsbinding automatically  [ci skip][auto]: updating luabinding & jsbinding automatically  fix deprecation warnings in pu  fix typos in documentation and comments  replace non-ascii characters in comments  fix inconsistent header include guards  fix typos in documentation and comments  fix inconsistent header include guards  fix deprecation warnings in pu  [ci skip][auto]: updating luabinding & jsbinding automatically  [ci skip][auto]: updating luabinding & jsbinding automatically  upgrade spider monkey to solve win32 js project crash issue ", "linked_issue_titles": "", "title": "sync v3 and fix win32 js project crash issue"}
{"description": " this is a concerted effort to actually clean up our yaml files and have yamllint not report any errors. changes made in this pr: the line length limit for warnings in yaml files is bumped from 120 to 150. this is enough to cut out a lot of warnings while still being a reasonable upper limit. the line-length check configuration is updated to explicitly ignore lines that are long due to unsplittable words (such as extremely long urls). explicit ignore directives have been added for submodules and temporary paths that are known to potentially contain yaml files. this makes manually running yamllint on a local checkout a much nicer experience. one new rule (empty-values) has been enabled in the yamllint config. this explicitly forbids use of implicit null values in mappings, which helps protect against structural errors in mappings resulting from implicit null value behavior combined with incorrect indentation. actual usage of null values is relatively uncommon to begin with, and the only files affected by this are a handful of gha workflows. this was prompted by me actually running into such an issue the other day in a personal project and it taking far too long for me to figure out what was going wrong. all errors (but not warnings) reported by yamllint in the repo are fixed. component name area/ci n/a we had originally planned to just fix yamllint stuff as it came up, but i finally got tired of seeing yamllint errors in unrelated files when running it locally. ", "commit_messages": " assorted yamllint config updates.  * extended line length limit to 150. this is still a reasonable limit  but cuts down on warnings a bit.  * added explicit ignore directives for external repo paths. this makes  using yamllint locally nicer.  * enabled the rule to require null values to be explicit. this rule  helps prevent accidental bogus mapping problems resulting from  implicit null values combined with incorrect indentation.  this only results in new errors in a couple of gha workflows, which will  be fixed in the next commit.  fix all yamllint warnings in yaml file sin the repo.  most are indentation or spurious empty lines. ", "linked_issue_titles": "", "title": "clean up yaml files in the repository."}
{"description": " a variant of this camera has an annoying bug surrounding suspend/resume. these two commits fix it. ", "commit_messages": " sound/usb: add device quirks for a4tech fhd 1080p webcams  these devices use a type of sonix chipset that produces broken microphone  data if suspended/resumed.  they also don't support readback of the sample rate.  sound/usb: call usb_autopm_get_interface() for devices that should not  be suspended  webcams with microphones are composite devices, and autosuspend is set  at the device level. if uvcvideo is probed after snd-usb-audio, the effect  of the quirk applied by snd-usb-audio is undone by uvcvideo's global  application of autosuspend.  incrementing the interface's pm refcount in such cases prevents runtime pm  from happening, thus the device is left active. ", "linked_issue_titles": "", "title": "prevent a4tech fhd 1080p webcams from being suspended automatically"}
{"description": " some 64-bit (unsigned) integers are not compared correctly (see attached test). ", "commit_messages": " valuetest: add test for uint64 comparisons  genericvalue: fix comparison of (ui|i)nt64 numbers  some 64-bit integers cannot be represented losslessly as a double.  due to a typo in the operator==, the comparison has been performed  after a double conversion in too many cases. ", "linked_issue_titles": "", "title": "failing comparisons between certain (ui|i)nt64 numbers"}
{"description": " adds a working failure test for streaming and non-streaming shuffle, without lineage reconstruction. this does a few things. test improvements: modifies autoscalingcluster to allow passing an idle node timeout (the default is very low) some small improvements to the nodekiller actor to hopefully improve flakiness. shuffle fixes: modifies shuffle tracker to wait on futures instead of having tasks signal. during failures, tasks may never signal the tracker, so we can't rely on these to track progress. core fixes: raylet will exit immediately if it receives the shutdown rpc with graceful=false - there was a bug here where it's supposed to exit after replying to the client, but the grpc server goes down for an unknown reason and the client reply is never sent on reference deletion, the owner now publishes an additional message to subscribers that the object has been deleted. previously, this was causing a hang in streaming shuffle because the raylets pulling an object subscribed after the object was already deleted, so they never received the error signal. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix test, shuffle, nodemanager graceful shutdown  error ", "linked_issue_titles": "", "title": "add chaos test for shuffle"}
{"description": " with the following code, model.where(foo: [1, nil]) ar builds an sql like this: where foo in (1) or foo is null here's a tiny patch that makes it like this: where foo = 1 or foo is null ", "commit_messages": " no need to compact an already compacted array  where(foo: [1, nil]) becomes \"where foo = 1 or foo is null\"  was \"where foo in (1) or foo is null\" before ", "linked_issue_titles": "", "title": "ar#where with an array of 2 elements including a nil"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). bringing the array up to date with the latest library code (v1.5.1): ", "commit_messages": " adding investments to the product array  adding investments to the product array in the test as well ", "linked_issue_titles": "", "title": "updating the product list to match the latest library code"}
{"description": " add rss and cache memory stats for containers. docker plugin now returns rss and cache stats for containers. these were commented out due to them not being present in docker 1.11 (maybe due to a bug in docker?) see #848. since these stats are available in newer versions of docker i thought it'd be nice to bring them back. i've also added an additional column for rss in the web ui for containers. bug fix: no fixed tickets: enhacement #1694 ", "commit_messages": " bring back 'rss' and 'cache' memory stats in docker plugin  looks like the stats were removed because they where gone in docker 1.11. this change put them back since they've been available again for a while now.  add rss column for containers in web ui  since resident set size is available for containers, an additional column has been added to display this value. ", "linked_issue_titles": " enhancement: rss for containers ", "title": "add rss metric for containers"}
{"description": " uimanager.js now expects uimanager.getconstantsforviewmanager, but only in production mode.  in dev fallback code exists to read the old constants. fix: add getconstantsforviewmanager synchronous method, uses same function as how we populate all the constants. removed some dead code in populateviewmanagerconstants accidentally left in a year ago. also: add a quick fix in viewpanel, running into -inf width/height sometimes in our app startup add blank line in package.json that gets added after npm install is run microsoft reviewers: open in codeflow ", "commit_messages": " add missing blank line  add uimanager.getconstantsforviewmanager as expected by rn 58  quick fix for uwp ", "linked_issue_titles": "", "title": "fix running with bundle file in 58 - uimanager.getconstantsforviewmanager"}
{"description": " bug fixes apis cherrypick from #34156 ", "commit_messages": " fix the order of unfold parameters (#34156)  * fix the order of unfold parameters  fix the order of unfold parameters (#34156)  * fix the order of unfold parameters  fix unfold ", "linked_issue_titles": "", "title": "[cherrypick 2.1.2]fix the order of unfold parameters"}
{"description": " moving #4885 over here -- for #4848. as we work on the new ui, let's write our stories in the new format. @ndelangen would you be interested in pairing on improving this importall function? how's your hmr? this works as is but makes use of window and is a bit of a hack. ", "commit_messages": " merge 4848-new-example-format into tech/overhaul-ui  fix up parameters examples  change .examples -> .stories ", "linked_issue_titles": "", "title": "use new story format in official storybook"}
{"description": " previously it was not possible to jit hf's modeloutput . by changing dataclass to flax.struct.dataclass this is however possible. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " fix_torch_device_generate_test  remove @  change dataclasses to flax ones ", "linked_issue_titles": "", "title": "allow dataclasses to be jitted"}
{"description": " model.findoneandupdate supports the overwrite option which is not declared in the queryfindoneandupdateoptions interface.  this option was added to mongoose version 5.9.12 on 2020-05-04.  updated to the latest version of the library, 5.10.9, in the header. also removes trailing spaces in index.d.ts and test/model.ts. add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: here include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " [mongoose] add missing overwrite option to interface queryfindoneandupdateoptions  update version ", "linked_issue_titles": "", "title": "add missing option \"overwrite\" to interface queryfindoneandupdateoptions"}
{"description": " description: support is added for lights which are connected to the relays of lcn hardware devices. related issue (if applicable): pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#7977 example entry for configuration.yaml (if applicable): lcn: connections: - name: myhome host: 192.168.2.41 port: 4114 username: !secret lcn_username password: !secret lcn_password lights: - name: living room address: myhome.0.7 output: relay1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. ", "commit_messages": " added relay ports to lcn lights platform  exchanged validation for ports with uppercase validator. makes interfacing with pypck enums much more simple. ", "linked_issue_titles": "", "title": "support for relay ports for lcn light platform"}
{"description": " this refactoring doesn't change the api and makes good code reuse improving maintenance. i've tried to make small incremental commits to make your review easier. relevant changes: now all androidapplication* classes implement the androidapplicationbase interface each androidapplication* class uses a lifecycle listener (if needed) specialized for audio management. androidgraphics is now used as-is by activity, fragment and daydream applications. androidlivewallpaper has its own extension of androidgraphics. since the original androidlivewallpaper is a bit nasty, i've preferred to grab and override main methods of the superclass androidgraphics so to minimize the impact and avoid breaking existing stuff. ", "commit_messages": " preliminary changes to androidapplicationbase propaedeutic for massive code reuse on graphics classes  made code reuse in methods initialize and initializeforview propaedeutic for upcoming changes  removed isfragment method; let's use a specialized audio lifeclycle listener instead.  unified androidgraphics class for activity, fragment, and daydream;  extended for live wallpaper. ", "linked_issue_titles": "", "title": "androidapplication and androidgraphics classes refactoring"}
{"description": " skywalking provides browser ui, cli and graphql ways to support extensions. but some users may have the idea to query data directly from the storage. such as in elasticsearch case, kibana is a great tool to do this. in default, due to save memory/network and storage space, skywalking saves id(s) only in the entity and metadata saved in the *_inventory entities only. but these tools usually don't support nested query, or don't work conveniently. in this special case, skywalking provide a config to add all necessary name column(s) into the final metrics entities with id as a trade-off. take a look at core/default/activeextramodelcolumns config in the application.yaml, and set it as true to open this feature. this feature wouldn't provide any new feature to the native skywalking scenarios, just for the 3rd party integration. ", "commit_messages": " support dynamic column in the source.  support activeextramodelcolumns as a default off option. ", "linked_issue_titles": "", "title": "support name column(s) in the storage for 3rd party integration, like kibana. default off"}
{"description": " if d20382065 successfully rolls out (has some issues still). then we don't need this fork anymore. we should start by at least removing it from modern builds. to do this i needed to fix the unsubscribing stuff mentioned in #18270 (comment). flare is now used by both the fb fork and without it so we should just compile to one or the other. i do that by always returning an unsubscribe listener and always passing that to a removeeventlistener function. the indirections can then be compiled out. ", "commit_messages": " move unsubscribe fork to eventlistener  that way we can statically compile out more of these indirections.  don't use the eventlistener fork for modern www builds ", "linked_issue_titles": "", "title": "don't use eventlistener fork in modern www builds"}
{"description": " windows explorer will show when you type explorer.exe. see  #6917 for the interaction. pr checklist applies to  #6917 cla signed. if not, go over here and sign the cla tests added/passed info on pull request created that it also matches on explorer.exe for explorer. matching explorer.exe also for explorer added unit test optimized multiple iterations for iprogram validation steps performed try the plugin explorer.exe and see that it has a result. ", "commit_messages": " matching explorer.exe also for explorer  added unit test  optimized multiple iterations for iprogram  fixed linter ", "linked_issue_titles": "", "title": "matching exactname for known win32 programs"}
{"description": " so the problem here was that, when requesting another users profile (not your own), the completedchallenges array was only sent back if showcerts and showtimeline were true - aka public. so i filtered out the cert challenges if showcerts was private and sent it back like that. i came up with a few iterations of this logic before landing on what's in the pr. feel free to suggest something better. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. closes #37855 ", "commit_messages": " fix: conditionally send back cert challenges with challenge list  fix: remove empty line ", "linked_issue_titles": " timeline does not appear for public portfolio ", "title": "timeline not showing when set to public"}
{"description": " the reason for this pull request appears in a conversation for #4844 this is the first of two pull requests. the ultimate goal is to add the mice imputation algorithm to scikit-learn. to do so, we need sklearn's bayesian regression algorithms to be able to return standard deviations as well as predictions. this pull requests adds the option return_std to the predict methods of both bayesianridge and ardregression. once this is accepted, i will make a pull request that implements mice using bayesianridge by default (which seems more robust to small sample sizes than ard in my limited experience). ", "commit_messages": " initial commit for return_std  initial commit for return_std  adding tests, examples, ard predict_std  adding tests, examples, ard predict_std  a smidge more documentation  a smidge more documentation ", "linked_issue_titles": "", "title": "adding return_std options for models in linear_model/bayes.py"}
{"description": " several pattern matching needs to be changed when adding a new param now, e.g. #4805 this pr is to refactor xgboost.scala to make code cleaner ", "commit_messages": " cleaning checkpoint file after a successful file  address comments  refactor xgboost.scala to avoid multiple changes when adding params ", "linked_issue_titles": "", "title": "refactor xgboost.scala to put all params processing in one place"}
{"description": " this pr adapts/utilizes recent enhancements in lucene-7.4: replaces exactnumdocs by the soft-deletes count in segmentcommitinfo. this enhancement allows us to back out changes introduced in #30228. always configure the soft-deletes field in iwc ", "commit_messages": " always enable soft-deletes when opening iw  load commit stats directly from segmentinfos  use getsoftdelcount  this reverts commit b12c2f61c5baeb7ba200748834ff69beec5351f5.  configure soft-deletes field  mute matchphraseprefixquerybuildertests  soft-deletes field when restore from snapshot  configure soft-deletes peerrecoverytargetservicetests  when prune commit files ", "linked_issue_titles": "", "title": "replace exact numdocs by soft-del count in segmentcommitinfo"}
{"description": " added fingerprint for 2019 acura ilx. dongle id: 42606d78d7bc5712 thanks to discord user simplyken. ", "commit_messages": " add fingerprint for eu 2019 civic hatch  remove fw electricbrakebooster  remove extra space  add 2019 acura ilx fingerprint  add 2019 acura ilx to readme.md ", "linked_issue_titles": "", "title": "add fingerprint for 2019 acura ilx"}
{"description": " this is a fix for #836.  to stabilize the formatting, i introduce a function which dedupes adjacent invisible parentheses, so that downstream formatting logic involving breaking up lines depending on line length get the same input regardless of whether ((({atom}))) or ({atom}) is attempting to be formatted. open to feedback on this solution and additional test cases i can throw at it; tried to be conservative w.r.t. how these parens are deduped. as an aside, perhaps in a future pr we can refactor how maybe_make_parens_invisible_in_atom looks.  currently, it's responsible for returning a boolean and causing side-effects, which isn't obvious off the bat.  i added a comment to clarify this for now. ", "commit_messages": " fix for unstable formatting involving unwrapping multiple parentheses  more tests ", "linked_issue_titles": "", "title": "fix unstable formatting involving unwrapping multiple parentheses (#836)"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " fix sfdc response payload to not be undefined.  add optional scope to sfdc oauth login params. ", "linked_issue_titles": "", "title": "merge fixes for sfdc canvas sdk oauth login scope and response payloads."}
{"description": " check for the packagemanagement capability for caller apps. all medium-il processes have all capabilities so this will pass for powershell callers. i originally tried to add these checks in the activation factories but the calling process in that case was a svchost process. i also updated the telemetry to log the caller. microsoft reviewers: open in codeflow ", "commit_messages": " merge microsoft/winget-cli changes.  rest endpoint helper and json object field check - bug fix (#821)  merge latest winget changes.  check caller capabilities  revert line ending change. ", "linked_issue_titles": "", "title": "add capability checks for callers to the packagedapi"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. ", "commit_messages": " updated to reflect the relationship between label and input elements  updated to reflect the relationship between label and input elements ", "linked_issue_titles": "", "title": "consistency update for label and input elements for last lessons"}
{"description": " the motivation here is to split the one big switch into many more reasonable-sized methods, which makes the file a little easier to read and should give us better backtraces. it also turned out to clean up several kinds of ad hoc local state. no functionality change. i suggest reviewing commit by commit, and skipping the big one (just assume i got it right; i was very careful not to improve anything during that commit). ", "commit_messages": " [serialization] pull decl deserialization out to a helper class  in preparation for splitting up one big switch into many small  methods. well, medium-sized methods.  no functionality change.  [serialization] move decl attribute deserialization into new helper  no functionality change.  [serialization] move one case in getdeclcheckedimpl out of line  ...as a proof of concept. the next commit will move them /all/ out of  line.  (the intent here is to produce better backtraces when not recovering  from errors.)  [serialization] make astdeserializer stateful, and use that state  ...for decl attributes. also, rename to decldeserializer.  [serialization] move various raii-based setup into decldeserializer  no functionality change.  [serialization] move helper lambda into decldeserializer  and cache the astcontext pointer for convenience.  [serialization] move all the decl layouts into decldeserializer  now we have a separate function for each serialized declaration kind!  much cleaner, still nfc.  [serialization] collapse one level of helper function i didn't need  no functionality change.  [serialization] collapse prefix/postfix operator deserialization  ...using a template. ", "linked_issue_titles": "", "title": "break up getdeclcheckedimpl into a helper class"}
{"description": " fix check for '.' in names with more efficient implementation better error message when transferring from token account with 0 balance unit tests for registering subdomains and buying short names (tlds) at auction ", "commit_messages": " fix #3187 - effecient detection of names with '.'  - also exempt the eosio account from this restriction  implement name auction #3189  fix bugs and implment tests for name auction, fix #3189 ", "linked_issue_titles": "", "title": "issue3189 - account name auction & tlds"}
{"description": " this pr fixes two issues that have been introduced by #9114. when i switched the metric from rate to tokenbucket in the controllermutationquotamanager, i have mixed up the metrics. that broke the quota update path. when a quota is updated, the clientquotamanager updates the metricconfig of the kafkametric. that update was not reflected into the sensor so the sensor was still using the metricconfig that it has been created with. ", "commit_messages": " update the correct metric in the controllerquotamanager when the quota is updated.  wire up the metricconfig differently in the sensor to ensure that updating the metricconfig of the kafkametric is reflected in the sensor. ", "linked_issue_titles": "", "title": "kafka-10458; updating controller quota does not work since token bucket"}
{"description": " there is an option for nodeos that specifies the max flight bytes. however, it did not work fine since the calculation of the bytes in flight was wrong. the bytes in flight was always 0 or 1 so it never exceeds the max flight bytes. it causes an issue that nodeos continues to accept new transactions when there is no new blocks until the process reaches the maximum file descriptors. it causes the nodeos malfunctioning and cannot be recovered. in some environments it causes the whole os malfunctioning. select one ", "commit_messages": " fix the issue that nodeos continues to accept transactions after the flight queue size exceeds the maximum flight bytes  make con not a constant parameter for function verify_max_bytes_in_flight  added more debugging messages  testing  remove debugging message ", "linked_issue_titles": "", "title": "fix the bug that the flight bytes are calculated incorrectly"}
{"description": " this should address #806 on linux, but not on mac. to fix the problem on mac, we probably need to patch the arrow cmake module that finds the python libraries. ", "commit_messages": " tell cmake which python to use when building arrow.  pass different path into cmake when building arrow so that cmake finds the right python.  add correct python executable to path when running cmake for ray. ", "linked_issue_titles": "", "title": "add correct python executable to path when building arrow."}
{"description": " some functionality in #623 was actually fairly trivial to implement. the following features are included in the flow list view: press 'm' to toggle an easily visible mark on the current flow. when the flow list is cleared with 'c', marked flows are not deleted. if all flows in the list are marked, marked flows are deleted with 'c' this means that pressing c twice will clear all flows, including marked ones. the mark is made large to stand out while scrolling, but that can be changed by changing symbol_mark in libmproxy/console/common.py. ", "commit_messages": " implemented basic marking of flows  - press m to toggle flow mark  - flow mark is set in libmproxy/console/common.py. currently set to \"===\"  marked flows not deleted on clear all  marked flows survive a clear all unless all current flows are marked.  bug: they don't show up until another flow is added  fixed console rendering bug  clearing all flows now works properly  changed symbols and colors  added a better symbol for the mark, and changed the color to red. this helps it  stand out more easily. ", "linked_issue_titles": "", "title": "added flow marking functionality in the console"}
{"description": " this pr adds a handful of server rendering unit tests. with the move to fiber, it's likely that the server rendering path and client rendering path are going to diverge significantly, and i think it'd be useful to have a more robust unit test suite for server rendering as the work on fiber ssr begins. this pr starts to port over tests that i wrote in (since abandoned) pr #6836. this pr only ports over some of the helper functions and 4 of the simplest tests. if this pr is accepted, i plan to submit the rest of the tests in a series of further prs; i only added four tests here because i wanted to keep this pr as digestible as possible. thanks for all your great work! note: i ran tests, linting, and flow, but i could not get ./scripts/fiber/record-tests to work. it first complained about not being able to find jest-cli; when i npm installed jest-cli, it complained about an unresolved promise with the error typeerror: path must be a string. received undefined.  i expect the ci build will fail on this, and i'd appreciate any pointers to getting it to work. ", "commit_messages": " added a handful of ssr unit tests, ported from a previous pull request.  fixing linting errors ", "linked_issue_titles": "", "title": "adding some server rendering unit tests."}
{"description": " this removes \"old\" post-process uniforms and samplers. the new post-process materials don't need them, as they use per_material_instance ones. dithering uses the time uniform, which it now gets from frameuniforms. ", "commit_messages": " deprecate post-process uniform buffer  deprecate post-process sampler block ", "linked_issue_titles": "", "title": "remove post-process uniform / sampler blocks"}
{"description": " ref this comment in ie calling getboundingclientrect  on an element that is not attached to the dom throw an unspecified error:  saucelabs is failing because some unit test for scrollspy doesn't add the element worked on to the dom. this pr make sure the unit test add the element used in the test to the qunit-fixture as the scrollspy plugin is meant to work on element present on the page. ", "commit_messages": " merge commit '6aad73ac6d07082e607986339661a8e9f5dc0c93' into v4-dev  merge commit 'cab6f7d16ca64dfcb0de002940d085c8cfe8b304' into v4-dev  * commit 'cab6f7d16ca64dfcb0de002940d085c8cfe8b304':  more config tweaks.  bump to jquery 3.2.1  always append element to fixture in scrollspy unit tests ", "linked_issue_titles": "", "title": "fix saucelabs error following merge of #21788"}
{"description": " original pull-request #23261 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " disable hedged requests  disable hedged requests ", "linked_issue_titles": "", "title": "cherry pick #23261 to 21.5: disable hedged requests"}
{"description": " the get_many function in the backends/base.py file previously received ready_states argument, but only considered it, when looking into tasks that are already in cache. the get_many function now also considers the ready_states arg when fetching new results. also added a test case for this behavior. ", "commit_messages": " backends base get_many pass ready_states arg  test backends base get_many pass ready_states arg ", "linked_issue_titles": "", "title": "backends base get_many function now passes ready_states"}
{"description": " media keys do not work on milk via keymap my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " update fork branch  allow media keys in milk via ", "linked_issue_titles": "", "title": "fix media keys in via keymap for 2% milk"}
{"description": " overwrites some of the other changes already added for babel 6 to flow better and not treat v6 as the anomaly (it's what people will get by default these days). it also does #5360 more completely. ", "commit_messages": " [docs] update getting started for babel 6  [docs] update tooling integration for more babel 6 ", "linked_issue_titles": "", "title": "update docs for babel 6"}
{"description": " built on #8579 ", "commit_messages": " provide a mechanism to create a secure client channel  initial test fix  expand corpus, add call creds  expand corpus, fix crash  expand corpus, fix crash  expand corpus ", "linked_issue_titles": "", "title": "add credentials creation to api_fuzzer"}
{"description": " fixes rdar://problem/46571799. ", "commit_messages": " silgen: drop generic signature from witness thunk if all parameters are concrete  sil functions for ast declarations do this, and the sil verifier enforces  this, so let's do it for witness thunks too, fixing a devirtualizer  crash.  fixes <rdar://problem/46571799>.  sil: silfunctiontypes don't allow generic signatures where all parameters are concrete ", "linked_issue_titles": "", "title": "fix devirtualization of conditional conformance where all generic parameters are concrete [5.0]"}
{"description": " this is to add a plugin for fakerjs as requested in #1199 the name of the plugin is gatsby-source-faker usage of the plugin is described in the readme of the plugin itself and there is an example site with the usage shown. question - i want to make a netlify deploy of this. can you point me to how you are deploying your current examples? i would follow the same. ", "commit_messages": " added plugin  added example usage  add readme ", "linked_issue_titles": "", "title": "plugin in gatsby to use faker"}
{"description": " what do these changes do? fix ddpg optimizers add twin delayed ddpg (td3) the original implementation compute gradients with actor optimizer and critic optimizer respectively but apply gradients with the fake optimizer defined by base class tf policy graph. actually, tensorflow optimizers compute the gradients in the same way, while the momentum adjustments function in applying the gradients. thus, the original implementation failed to use the two optimizers created by the ddpg agent itself. td3 mainly add 3 tricks to ddpg and this pr tries to add td3 upon ddpg. the comparison is showed as follow: td3 seems more stable w.r.t. ddpg and solves the pendulum-v0 quickly in the sense of sample efficiency. ", "commit_messages": " fix ddpg optimizer and add td3  supplement missed argument  formated by yapf ", "linked_issue_titles": "", "title": "enable twin delayed ddpg for rllib ddpg agent"}
{"description": " this pr adds open method to the deserializationschema and serializationschema. it gives users access to metrics. moreover it adds a well defined step in the lifecycle to perform initialization. it also updates kafka, kinesis, pubsub and gcp connectors to call the method. check tests in corresponding connectors. the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (yes / no / don't know) ", "commit_messages": " [flink-17306] added open to deserializationschema  [flink-17306] add open to kafkadeserializationschema  [flink-17306] add open to kinesisdeserializationschema  [flink-17306] add open to pubsubdeserializationschema  [flink-17306] call open of deserializationschema in rmq  [flink-17306] add open to serializationschema  [flink-17306] add open to kafkaserializationschema  [flink-17306] add open to kinesisserializationschema  [flink-17306] call open of serializationschema in pubsub sink  [flink-17306] call open of serializationschema in rmq sink ", "linked_issue_titles": "", "title": "add open method to (de)serializationschema"}
{"description": " fixes #19074 this change disables image lazy-loading when both of the following are true: a image is being rendered following a client-side page transition the image has been previously loaded during this session. before this change, all images with lazy-loading enabled have a visible flicker during client-side page transitions, even though they're already loaded. with this change, there's are two performance risks: there's a chance that some offscreen images will have lazy-loading disabled unnecessarily because they were previously loaded. i think the performance hit here is pretty negligible and the situation is unlikely to come up very often. there's a chance a different-sized version of the image will be selected by the browser, but lazy-loading will be disabled anyway. this seems even more unlikely to me, and anyway the performance hit from a stray un-lazy-loaded image (on a client-side transition) is very minor. in both cases, i think the performance risk is outweighed by the ux improvement of getting rid of the image flicker on page transition. ", "commit_messages": " don't lazy-load already-loaded image in csr  fixes 19074  scope change to client-side only ", "linked_issue_titles": " [next/image] repeated images rerender on every page switch. ", "title": "don't lazy-load already-loaded image in client-side transition"}
{"description": " closes #38053 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry i think if we are at this place and len(values) is 1, we want to return a scalar instead of a series. this happens only because loc is a slice (0,1) with one multiindex level instead of a scalar. should i create a file to move all multiindex at tests to the multiindex folder? ", "commit_messages": " fix at bug  add test and whatsnew ", "linked_issue_titles": " bug: calling at[] on a series with a single-level multiindex returns a series, not a scalar ", "title": "series.at returning series with one element instead of scalar"}
{"description": " when storing renderer process callbacks in the main process, there are two keys for one remote object: 1) the webcontents id and 2) the object id. this pr extends the idweakmap to accept arbitrary key type so it is possible to use two ids as key, instead of relying on hacks to merge two ids into one id. close #5476. ", "commit_messages": " remove unused methods of idweakmap  add keyweakmap without add method  fix leak when keyweakmap::remove is called directly  usually the keyobject would be destroyed when gc happens, but then  remove is called before gc happens, the keyobject would be leaked  forever. this fixes it by keeping keyobject as a member of map.  make keyweakmap a template class  remove idweakmap  use create function instead of idweakmap constructor  turn api::idweakmap into api::keyweakmap<t>  move createidweakmap to v8util  use doubleidweakmap for |rendererfunctions| ", "linked_issue_titles": "", "title": "extend the idweakmap to accept arbitrary key type"}
{"description": " bug fixes apis make paddle.to_tensor() copy if data is varbase, so the computation graph is splited from which of data. make the  stop_gradient of input(data) not changed ", "commit_messages": " fix stop_gradient in paddle.to_tensor  make to_tensor copy if data is varbase ", "linked_issue_titles": "", "title": "make paddle.to_tensor() copy if data is tensor"}
{"description": " this pr adds a new pipeline to ci for testing builds under cuda 11.0. the new pipeline (\"unix-gpu-cu110\") is triggered by the full-build when the sanity build completes. ", "commit_messages": " add new docker containers for cuda 11.0 and libcudnn8.  add new functions for running gpu builds and tests in new cuda11 containers.  add runtime functions for cuda 11.0 related builds/tests.  add new pipeline for testing cuda 11.0 builds. ", "linked_issue_titles": "", "title": "add new ci pipeline for building and testing with cuda 11.0."}
{"description": " the typedefs for pushcontainer and unshiftcontainer were missing. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add typedef for container modification methods  add typedef for unshiftcontainer() and pushcontainer(). these methods  are used to insert nodes into a list of nodes (container) owned by the  current node.  add tests for typdefs of push/unshift container  add \"dean l\" to definitions author list ", "linked_issue_titles": "", "title": "add typedef for push/unshift container"}
{"description": " refactoring no if relevant, link to documentation update: n/a summary getexports was returning 2 types of shape which could force its caller to deopt. this also was the case for identtoloaderrequest no ", "commit_messages": " prevent identtoloaderrequest to return 2 objects with different shapes  unify dependency#getexports result  ensure the type of the binding don't change ", "linked_issue_titles": "", "title": "use a single object shape for dependency exports"}
{"description": " as discussed in #6, the following pr adds a cli for mermaid which is exposed as a mermaid command when installed globally, via npm install -g mermaid. mermaid will look for the phantomjs command in your path and give helpful errors if it's not found, or is too old. additionally, you can specify the path to phantomjs with the -e switch. otherwise, functionality is identical to my mermaid-cli package, which will be deprecated once this pr is accepted and a new version including the cli is published. then, we can focus on improvements here! ", "commit_messages": " adds cli for rendering mermaid files  adds cli tests  adds cli information to the readme.  better information around cli's phantomjs requirement  make obvious that readme known issues section is for the cli ", "linked_issue_titles": "", "title": "adds command line interface for generating pngs from mermaid description files"}
{"description": " related to #20822 previously, in pr #20822, i edited a small typo in the phrase \"where n_samples in the number\" by updating it to \"where n_samples is the number\". this pr: edits new instances of the same typo caught by grep-searching for a version of the phrase where the parameter, n_samples, is enclosed in backticks: git grep 'where n_samples in' . adds backticks to cases of n_samples (also n_features, n_components) in a docstring that don't have them: n_samples -> n_samples . i believe this catches all last cases of the typo. please let me know if anything can be added or changed. ", "commit_messages": " add backticks to mentions of \"n_sample\" (and other nearby parameters) inside of a docstring.  edit instances captured by git grep with the typo: 'where n_samples in' rather than 'where n_samples is'. ", "linked_issue_titles": "", "title": "doc replace the phrase \"where n_samples in the number\" with \"where n_samples is the number\""}
{"description": " fixes #20699 adds a feature to 'passthrough' to pass the features without a transformation and added test and documentation for it. changes made in featureunion._validate_transformers() to allow 'passthrough' changes made in featureunion._iter() to use functiontransformer(none) in place of passthrough to represent the identity transformer. added featureunion._passthrough_function() which returns a functiontransformer(none) with get_feature_names set. this separate function is needed as the functiontransformer class does not have a get_feature_names function which is needed by featureunion. wrote a test function test_set_feature_union_passthrough() to test the functionality. it may be better to check if more than one transformers are not set to passthrough as having a repetition of  the same features is redundant. ", "commit_messages": " add support for passthrough in featureunion  add tests for passthrough  add documentation for passthrough ", "linked_issue_titles": " support \"passthrough\" in featureunion ", "title": "enh add support for 'passthrough' in featureunion"}
{"description": " reading the pagination page, i came across a couple of typos and grammar changes. changed \"loosing\" to \"losing\" changed \"usecases\" to \"use cases\" ", "commit_messages": " fix minor typo on pagination documentation  also fix usecases to use cases ", "linked_issue_titles": "", "title": "some minor typos and grammar changes."}
{"description": " description: use previously stored brightness when turning on light. this is mostly useful with homekit, since it calls turn_on and brightness changes as two separate calls. removed manually handled states because newer library can return states reliably when update() is called. checklist: local tests pass with tox. your pr cannot be merged unless tests pass new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. ", "commit_messages": " remember last brightness value and use it on turn_on()  pyfnip-0.2 now returns state reliably, no manual changes needed.  split too long line of code  updated pyfnip library version ", "linked_issue_titles": "", "title": "make futurenow light remember last brightness when turning on"}
{"description": " continuation of #4167. had to merge that one because the changes to the data files made github unable to handle the diff. this pr builds on top of @polm's work and adds the basic scaffolding for a lookups class (available via vocab.lookups). see #3971 for more details. for consistency, i've also converted all lemmatizer data to json. the json resources can be provided as relative paths in the language defaults, and the lookups takes care of the rest. this lets us avoid a lot of code duplication in the language classes. it will also make it much easier going forward to implement serialization methods and later move the large data files out of the core library and only include them with the model packages. of course, the ultimate goal is to replace the current dict-based lookups with a more efficient implementation (see #3971). having the basic scaffolding in place should make this easier. also, some package size stats (installation on disk from sdist): without compression: 262 mb with compression: 18.1 mb enhancement todo serialization methods docstrings fix serialization issue that seems to cause vocab bytes mismatch on python <= 3.5 (see failing tests) more tests test building a wheel and make sure compression happens i have submitted the spacy contributor agreement. ", "commit_messages": " improve load_language_data helper  wip: add lookups implementation  start moving lemma data over to json  wip: move data over for more languages  convert more languages  fix lemmatizer fixtures in tests  finish conversion  auto-format json files  fix test for now  make sure tables are stored on instance  update docstrings ", "linked_issue_titles": "", "title": "basic lookup class scaffolding and json for all lemmatizer data"}
{"description": " replace dedicated method with typecheckchildindependently always setting the closest possible declaration context for type-check call. this fixes a problem where sub-expression comes from multiple levels or nested closures but csdiag didn't re-typecheck parent closure. resolves: rdar://problem/50869732 ", "commit_messages": " [csdiag] always find and set correct declaration context for sub-expression type-check  replace dedicated method with typecheckchildindependently always  setting the closest possible declaration context for type-check call.  this fixes a problem where sub-expression comes from multiple levels  or nested closures but csdiag didn't re-typecheck parent closure.  resolves: rdar://problem/50869732  (cherry picked from commit a5df7862636a303828cee724c6b779bc77280f65)  [typechecker] nfc: add a test-case for rdar://problem/50869732  (cherry picked from commit 4fdc9fffe8552a1f7c6d5b76031511d8de988c80) ", "linked_issue_titles": "", "title": "always find and set correct declaration context for sub-expr type-check"}
{"description": " this pr fixes issue #1816 . qstring::number doesn't support displaying -0.0, so i converted all usages on the gui to tofloatstring/todoublestring. this fixes the floating point display in the mmx/xmm/ymm editor, in the registers view in simd float/double mode, and in the watch window for floating point type watchpoints. to support this all void* buffer based stringutil functions are now const correct, and tofloatstring/todoublestring got an optional precision parameter, which is set to the previously used value by default. one noteable change is that todoublestring has 15 digits of precision by default, while qstring::number only had 6 (the same as tofloatstring has). with the new precision parameter we can set it back to 6 if necessary, but i think the more precision the better the only place where the added precision could cause problems is the newly added simd mode of the registersview, @torusrxxx could you also take a look to see if it matches your design for displaying the fpu registers? ", "commit_messages": " gui: make stringutil void* buffer functions const-correct  gui: add precision support to tofloatstring and todoublestring  gui: fix -0.0 float display by converting with stl instead of qstring::number ", "linked_issue_titles": "", "title": "fix negative zero floating point display"}
{"description": " this is a slightly premature first cut of the rama u80-a implementation. doing a pr now so @jackhumbert and @yiancar can see the is31fl3736 driver implementation and discuss ideas about merging with the is32fl3733 driver. ", "commit_messages": " initial commit of rama u80-a  initial commit of rama u80-a  moved is31fl3736 driver, minor cleanups  superficial stuff ", "linked_issue_titles": "", "title": "rama u80-a, wilba.tech wt60-a, wt65-a, wt80-a, is31fl3736 driver"}
{"description": " this simplifies check_is_fitted to error if no fitted attribute is found. this clearly is less strict than what we had before, but i did not need to change any tests, so according to our tests (i.e. the guaranteed functionality), this implementation is as good as the previous one. the main motivation for this change is to allow us to reduce boiler-plate in the future. if we introduce a validation method as in #13603, we could now include the check_is_fitted there. ", "commit_messages": " make check_is_fitted not take attributes  cleanup, remove any_or_all  fix lof, birch, mixtures ", "linked_issue_titles": "", "title": "simplify check_is_fitted to use any fitted attributes"}
{"description": " before this patch, a fling of a scrollable will end up recommending deferred loading, but not a similarly large (or larger) jumpto. this adds an _impliedvelocity field to scrollposition that tracks how many pixels were forced in a single frame, and adds that to the activity's velocity when asking the scrollphysics whether we should defer. related issues fixes #64124 i added the following tests: test that this works as expected when using jumpto with large values. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. ", "commit_messages": " deferred loading for jumpto/forcepixels  doc and test ", "linked_issue_titles": " scrollcontroller.jumpto() at top causes a surge in memory ", "title": "make large jumpto recommend deferred loading"}
{"description": " handwired/arrow_pad: layout macro and keymap refactor layout macros moved from the keymaps to arrow_pad.h. layout_pad21 refactored to only accept keys that are physical present (no kc_no entries required in keymap) keymaps now use #include qmk_keyboard_h keymaps refactored to use process_record_user function (from action_get_macro) handwired/arrow_pad: readme cleanup fixed the make commands and updated the layout macro. handwired/arrow_pad: configurator support ", "commit_messages": " handwired/arrow_pad: layout macro and keymap refactor  - layout macros moved from the keymaps to arrow_pad.h.  - layout_pad21 refactored to only accept keys that are physical present (no kc_no entries required in keymap)  - keymaps now use #include qmk_keyboard_h  - keymaps refactored to use process_record_user function (from action_get_macro)  handwired/arrow_pad: readme cleanup  fixed the make commands and updated the layout macro.  handwired/arrow_pad: configurator support ", "linked_issue_titles": "", "title": "handwired/arrow_pad refactor and configurator support"}
{"description": " they are either tst_<name> with: def test_ip_<name>(): for t in [types]: tst_<name>(t) or test_<name> + test_<name>_<other thing>. ", "commit_messages": " tst: use pytest for some already-parametrized tests.  tst: parametrize print tests. ", "linked_issue_titles": "", "title": "use pytest for some already-parametrized core tests"}
{"description": " this fixes tooltips for scatter and bubble charts. also made the scatter chart a first class chart type so that you can create one (with the correct default) by doing var mychart = new chart(ctx, { type: 'scatter', data: [], options: {} }); ", "commit_messages": " update default tooltip callbacks for bubble charts  update default tooltip configs for scatter charts. made scatter charts a first class chart type.  remove commented code ", "linked_issue_titles": "", "title": "fixes scatter and bubble chart tooltips"}
{"description": " for #6331. as discussed. ", "commit_messages": " pass test metadata in via an environment variable.  [only works on the server right now, fairly uselessly]  for #6331  pass test metadata through to the client via meteorenv  for #6331 ", "linked_issue_titles": "", "title": "fix meteor istest for packages 6331"}
{"description": " changed _url_pattern in language/tokenizer_exceptions.py, using url regex validation pattern from:  this change will screen out a number of patterns that are not urls as well as picking up some patterns that were missed. test cases were added to test_urls to expose the issue and validate the fix. types of changes new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. ", "commit_messages": " issue #840 - url pattenr too broad  fix error in test case parameterization ", "linked_issue_titles": "", "title": "fix for issue #840 - url pattern too broad"}
{"description": " epe-1551 add test cases for cleos new option --abi-file that was added in pr#10821 to specify one or more local abi files for cleos for serialzation/deserialization offline, which doesn't require nodeos rpc endpoint. select one: select any that apply: ", "commit_messages": " trigger build  fix flaky test  fix flaky test  test malicious abi ", "linked_issue_titles": "", "title": "add a test for cleos new option --abi-file"}
{"description": " this pr aims to add more cnn models to benchmark scripts like squeezenet and mobilenet and make it more user-friendly. also add a cnn benchmark script for gluon. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change add 'inception-v4', 'inception-resnet-v2', 'mobilenet', 'densenet121', 'squeezenet1.1' to benchmark_score.py add '--network' to script for specific and run all models by default to keep same with before. add '--batch-size' to script for specific and run [1, 2, 4, 8, 16, 32] by default to keep same with before. add script for gluon to benchmark more cnn models. 'densenet121', 'squeezenet1.1' in benchmark_score are converted from gluon in order to cover more cases. these models are benefit a lot from #12530 @pengzhao-intel @juliusshufan ", "commit_messages": " add models to cnn benchmark  improve benchmark score  add benchmark_gluon  improve lint  improve lint ", "linked_issue_titles": "", "title": "add more models to benchmark_score"}
{"description": " prevents logic bugs where kscopedschedulerlock{kernel}; is written instead of: kscopedschedulerlock lock{kernel}; from slipping through silently. now the compiler is obliged to warn about cases like that. ", "commit_messages": " k_scheduler: mark kscopedschedulerlock as [[nodiscard]]  prevents logic bugs like:  kscopedschedulerlock{kernel};  instead of:  kscopedschedulerlock lk{kernel};  from slipping through.  k_scoped_lock: mark class as [[nodiscard]]  prevents logic bugs of the kind described in the previous commit from  slipping through.  k_scoped_lock: delete copy and move assignment operators  if we delete the copy and move constructor, we should also be deleting  the copy and move assignment operators (and even if this were intended,  it would be pretty odd to not document why it's done this way). ", "linked_issue_titles": "", "title": "mark lock helper classes as [[nodiscard]]"}
{"description": " when queue.get is called on an empty queue, previously we would block until something was put into the queue, and similarly when calling queue.put on a full queue we would block until space was created.  this pr provides async get and put methods so that other computations can be done during this blocking situation. when putting or getting large numbers of small items into the queue, serialization overhead becomes significant.  previously, there would be a remote call for each item.  this pr provides batched put and get methods, so there is only one remote call for each batch. this pr also cleans up and adds more details to the documentation. the batched put and get methods are sync and don't support blocking as described above.  this seems appropriate for the use case of, say, quickly grabbing or dumping 10000 strings from the queue.  a future pr could provide async versions of the batched put and get, and an option for blocking for batched put and get. closes #11162. closes #11443. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " expand docstring  add batch put and get, and async put and get  add tests  lint ", "linked_issue_titles": " [util] queue should support batching  [doc] add documentation for ray.util.queue.queue ", "title": "add queue async and batch methods"}
{"description": " this pr fixes #101834 // ", "commit_messages": " enable sandbox for issue reporter and process explorer (fix #101834)  sandbox - enable vscode-file protocol for sandboxed renderers  issues - stop setting nodecacheddatadir ", "linked_issue_titles": " enable sandbox for issue reporter and process explorer ", "title": "enable sandbox, contextisolation and vscode-file for process explorer and issue reporter"}
{"description": " this is a rebased branch based on development per #971 conditional integration is an adaptive limit on the integral term that prevents accumulation when the proportional or other terms would saturate the heater output.  this helps avoid overshoot by not winding up the integral when starting pid control far from the setpoint. see the discussion under the #971 issue for more information. ", "commit_messages": " getting even with v1  update readme.md  heater.c: limit pid i term with conditional integration.  temperature.cpp:add pid conditional integration on heated bed.  configuration.m: set pid_integral_drive_max from pid_max from bang_max.  current defaults are all 255.  if it makes sense to reduce them, they should come down together, and  be in a  pid_integral_drive_max <= pid_max <- bang_max relationship. ", "linked_issue_titles": "", "title": "add conditional integration to prevent excessive integral windup"}
{"description": " i hereby agree to the terms of the cla available at:  documentation for #7974 changelog category: changelog entry: deleted descriptions for settings allow_experimental_data_skipping_indices, allow_experimental_cross_to_join_conversion and allow_experimental_multiple_joins_emulation. removed duplicated description for join_any_take_last_row. ", "commit_messages": " clickhousedocs-511: removed obsolete settings.  clickhousedocs-511: removed duplication for ## join_use_nulls {#join_use_nulls}. ", "linked_issue_titles": "", "title": "deleted some experimental settings. removed duplicated description for join_any_take_last_row."}
{"description": "", "commit_messages": " sqlite.connection type now implements gc protocol  sqlite.cursor type now implements gc protocol  sqlite.row type now implements gc protocol  sqlite.prepareprotocol type now implements gc protocol  sqlite.statement type now implements gc protocol  sqlite3.cache and sqlite3.node types now implements gc protocol ", "linked_issue_titles": "", "title": "fully implement gc protocol for sqlite3 heap types"}
{"description": " hello friends ran into this bug on our production site, prerendermanifest stores revalidation info for the index as \"/\": { .. }, but the code tries to access this information as \"/index\". this leads to our index page always having s-max-age: 1 ", "commit_messages": " use route for prerender manifest path  delete test artifact ", "linked_issue_titles": "", "title": "wrong index path revalidation timer"}
{"description": " adds a new long running multi-node release test for distributed training and testing. will be useful for identifying issues with raysgd and tune fault tolerance before each release. addresses #2877 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " adding long running distributed tests  adding documentation  formatting  updating documentation  updating documentation  more documentation fixes ", "linked_issue_titles": "", "title": "multi-node training+tune long running test"}
{"description": " @martijnvg @talevy i've made some edits to the ingest node doc (sorry to get these in rather late, but elasticon and the all-hands got in the way). can you take a quick look and confirm that the changes are ok? summary of changes: added some explanatory text around concepts (mostly in the intro) that i thought needed a bit more context. tried to remove passive voice where it made the sentence harder to read added some headings to break up long bits of text added ids to sections (otherwise, the generated html pages get renamed whenever we change the heading text). fixed sentences that were ambiguous ", "commit_messages": " ingest node edits  edits to ingest plugin docs ", "linked_issue_titles": "", "title": "add edits to the ingest doc"}
{"description": " reintroduces #21527 (which was reverted in #21723). extra fixes on top of the old pr: update third_party/boringssl-with-bazel to the freshest master-with-bazel to bring fix for #21733 avoid async_end2end_test failures under msan (the issue has been investigated in #21722 and it turned out the only problem is that the test is too slow for 4mb messages when msan is enabled) fixes #21733 ", "commit_messages": " revert \"revert \"unify boringssl submodules and use non-developer boringssl cmake build\"\"  this reverts commit fe2242e603c341833a67f33e49fe7189ab5f9fd6.  update third_party/boringssl-with-bazel, check_submodules.sh and grpc_deps.bzl  run tools/distrib/generate_grpc_shadow_boringssl_symbol_list.sh  regenerate projects  avoid async_end2end_test timeout on msan ", "linked_issue_titles": " boringssl-with-bazel cannot compile shared lib ", "title": "reintroduce #21527 (boringssl submodule unification)"}
{"description": " checklist for the pandas documentation sprint (ignore this if you are doing an unrelated pr): pr title is \"doc: update the  docstring\" the validation script passes: scripts/validate_docstrings.py <your-function-or-method> the pep8 style check passes: git diff upstream/master -u -- \"*.py\" | flake8 --diff the html version looks good: python doc/make.py --single <your-function-or-method> it has been proofread on language by another sprint participant please include the output of the validation script below between the \"\" ticks: ################################################################################ ####################### docstring (pandas.dataframe.mod) ####################### ################################################################################ modulo of dataframe and other, element-wise (binary operator mod). equivalent to dataframe % other, but with support to substitute a fill_value for missing data in one of the inputs. parameters ---------- other : series, dataframe, or constant axis : {0, 1, 'index', 'columns'} for series input, axis to match series index on level : int or name broadcast across a level, matching index values on the passed multiindex level fill_value : none or float value, default none fill existing missing (nan) values, and any new element needed for successful dataframe alignment, with this value before computation. if data in both corresponding dataframe locations is missing the result will be missing notes ----- mismatched indices will be unioned together returns ------- result : dataframe examples -------- >>> a = pd.dataframe([2, 4, np.nan, 6.2], index=[\"a\",\"b\",\"c\",\"d\"], ...                  columns=['one']) >>> a one a   2.0 b   4.0 c   nan d   6.2 >>> a.mod(3, fill_value=-1) one a   2.0 b   1.0 c   2.0 d   0.2 >>> b = pd.dataframe(dict(one=[np.nan, 2, 3, 14], two=[np.nan, 1, 1, 3]), ...                  index=['a', 'b', 'c', 'd']) >>> b one   two a   nan   nan b   2.0   1.0 c   3.0   1.0 d   14.0  3.0 >>> c = pd.dataframe(dict(one=[np.nan, np.nan, 6, np.nan], ...                       three=[np.nan, 10, np.nan, -7]), ...                  index=['a', 'b', 'd', 'e']) >>> c one three a   nan nan b   nan 10.0 d   6.0 nan e   nan -7.0 >>> b.mod(c, fill_value=3) one   three two a   nan   nan   nan b   2.0   3.0   1.0 c   0.0   nan   1.0 d   2.0   nan   0.0 e   nan  -4.0   nan see also -------- dataframe.rmod ################################################################################ ################################## validation ################################## ################################################################################ errors found: use only one blank line to separate sections or paragraphs errors in parameters section parameter \"other\" has no description parameter \"axis\" description should finish with \".\" parameter \"level\" description should finish with \".\" parameter \"fill_value\" description should finish with \".\" missing description for see also \"dataframe.rmod\" reference if the validation script still gives errors, but you think there is a good reason to deviate in this case (and there are certainly such cases), please state this explicitly. i only added  the examples. these errors were present before i added the examples. ", "commit_messages": " doc: update the index.isin docstring (#20249)  doc: added examples to dataframe.mod docstring  removed trailing whitespace ", "linked_issue_titles": "", "title": "update the examples to dataframe.mod docstring"}
{"description": " this pr extracts common logic from codepushcore and moves it to codepushbasecore that could be used as parent class for all codepush platforms implementations. also contains minor improvements and fixes. ", "commit_messages": " extract several methods to codepushbasecore  extract more methods from codepushcore  add more methods for basecodepushcore  change field visibility  minor fixes  fix visibility  minor improvements  minor improvements ", "linked_issue_titles": "", "title": "transit common logic from codepushcore to codepushbasecore"}
{"description": " run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  closes #32900 ", "commit_messages": " fix engineversion result type  closes #28133  closes #27984  merge remote-tracking branch 'upstream/master'  add missing qstatename ro objectlayout  closes #32900  update nxlibrarydimensiondef  fix missing qlabelexpression ", "linked_issue_titles": " [@types/qlik-engineapi] extend definition of interface igenericobjectlayout ", "title": "fix engine api missing fields"}
{"description": " reduces checkstyle errors for patterns: dao data-bus data-locality data-mapper data-transfer-object decorator changes involved java docs reordering imports indentations line length issues ", "commit_messages": " reduces checkstyle errors in dao  reduces checkstyle errors in data-bus  reduces checkstyle errors in data-locality  reduces checkstyle errors in data-mapper  reduces checkstyle errors in data-transfer-object  reduces checkstyle errors in decorator ", "linked_issue_titles": "", "title": "resolves checkstyle errors for dao data-bus data-locality data-mapper data-transfer-object decorator"}
{"description": " force curly braces for one-line control elements (eg. if (true) return \"a\" => if(true) { return \"a\" } prohibit single if/else in else branch f.ex.: if(true){} else{ if(false){} else{} } unignored lib/app/store.js ", "commit_messages": " lint: add curly and no-lonely-if  lint: add lib/app/store.js to eslint config ", "linked_issue_titles": "", "title": "force if braces, no lonely ifs and add store.js"}
{"description": " add some bitmap images to our zipfldr shell extenson. ms version of this has them, but our one currently hasn't. and i think without bitmaps the wizard dialogs look a bit incompleted. i made them similar to ms bitmaps. they have exactly the same size (height x width), but looks differently, in reactos tango style. jira issue: core-17092 add the resource bitmaps into res directory; add accodring definitions into resource.h; enable the bitmaps in zipfldr.rc using the definitions numbers; enable the first bitmap (zipfldr1.bmp) in the idd_proppagedestination and idd_proppagecomplete wizard dialogs for all localizations; fix controls posision of those dialogs after adding the bitmaps same for all localizarions. enable the 2nd bitmap (zipfldr2.bmp) at the right top of the wizard dialogs, same as it done in ms implemetation. (where i need to properly enable it if it should be outside those dialogs, probably near the caption instead of the begin...end section?) also i haven't used the 3rd bitmap (zipfldr3.bmp) anywhere, since the dialog which uses it is not currently implemented in our zipfldr, compared to ms version. so i only added it as a resource file. result before: after: win2k3 zipfldr (for comparison): ", "commit_messages": " [zipfldr] add some bitmap resources  [zipfldr] enable zipfldr1.bmp in some wizard pages  update all localizations accordingly  [zipfldr] fix controls position for all localizations ", "linked_issue_titles": "", "title": "add some bitmap resources core-17092"}
{"description": " original pull requests: #3497, #3695, #3698, #3699, #3704, #3723, #3735. ", "commit_messages": " fix memory leaks appearing when cvopenfilestorage throws  (cherry picked from commit 16ce114e0cad6c85efead4a0ebb07724d691407a)  cvopenfilestorage: reduce the scope of xml_buf and make sure it's freed...  ... before any exceptions occur.  (cherry picked from commit 08da247a871ed40b868119a999af538da6526c6d)  don't install documentation if it isn't built  the have_doc_generator variable was always true.  (cherry picked from commit 3d46c1f9602bea7e6c6a49db8b6f2421166ef65d)  conflicts:  doc/cmakelists.txt  fix a memory leak in cvcapture_ffmpeg::close  ffmpeg now requires that frames allocated with avcodec_alloc_frame are  freed with avcodec_free_frame.  (cherry picked from commit 77578d415f4d2b22a4ee1989ef0afda73c9d649b)  conflicts:  modules/highgui/src/cap_ffmpeg_impl.hpp  remove useless cpack_*_component_install variables  they don't actually do anything. and even if they did, all components are  enabled by default, anyway.  (cherry picked from commit 49fe496914cca93f19dd61aa7b1c120037d65282)  conflicts:  cmake/opencvpackaging.cmake  install data on windows  because why not?  (cherry picked from commit e8a73940099b9823879e156a896e42a1854ca1bb)  conflicts:  data/cmakelists.txt  add a script to run all tests on windows  it's pretty much a simplified copy of the linux script, lacking fancy colors.  also, i had to drop python testing, because it's not easy to pass the python  module location to the script, and i have no pressing need to run the python  tests at the moment.  (cherry picked from commit c1e3ca170e6acd983fc010bffd6bc10f12a738c5)  conflicts:  cmakelists.txt  update the cpack variables to match the changes in asmorkalov/cmake#1  which also happens to align the non-debian specific variables  with the ones used by upstream cmake.  (cherry picked from commit b8c60234c3fa94c31a3e2a72275fefa811c75d5c)  conflicts:  cmake/opencvpackaging.cmake  add component display names  (cherry picked from commit 6d52ea898442d2458a40f8b06b75320c9ab4a5cc)  mark the libs component required  everything else depends on it, after all.  (cherry picked from commit cf54e3b97ea13c0aeef5e94b5330a4b26a601d81)  conflicts:  cmake/opencvpackaging.cmake ", "linked_issue_titles": "", "title": "forward-port a bunch of my changes from 2.4"}
{"description": " see #32515 (comment). had to limit typescript version to 2.1+, because magic-strinc use partial: add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " improve(buble): prefer use \"sourcemap\" type from official package, instead of manually defining it  fix(buble): \"tourl()\" is a method, not a property ", "linked_issue_titles": "", "title": "use sourcemap type from magic-string package"}
{"description": " what do these changes do? this is a re-implementation of the functionrunner which enforces some synchronicity between the thread running the training function and the thread running the trainable which logs results. the main purpose is to make logging consistent across apis in anticipation of a new function api which will be generator based (through yield statements). without these changes, it will be impossible for the (possibly soon to be) deprecated reporter based api to behave the same as the generator based api. this new implementation provides additional guarantees to prevent results from being dropped. this makes the logging behavior more intuitive and consistent with how results are handled in custom subclasses of trainable. new guarantees for the tune function api: every reported result, i.e., reporter(**kwargs) calls, is forwarded to the appropriate loggers instead of being dropped if not enough time has elapsed since the last results. the wrapped function only runs if the functionrunner expects a result, i.e., when functionrunner._train() has been called. this removes the possibility that a result will be generated by the function but never logged. the wrapped function is not called until the first _train() call. currently, the wrapped function is started during the setup phase which could result in dropped results if the trial is cancelled between _setup() and the first _train() call. exceptions raised by the wrapped function won't be propagated until all results are logged to prevent dropped results. the thread running the wrapped function is explicitly stopped when the functionrunner is stopped with _stop(). if the wrapped function terminates without reporting done=true, a duplicate result with {\"done\": true}, is reported to explicitly terminate the trial, but will not be logged. #3956 #3949 #3834 ", "commit_messages": " rewrote the function runner to make the logging behavior consistent across both the trainable class apu and the function api.  fixed missing keyword  bug fixes  fixed wrong order in timing calculation  merge remote-tracking branch 'upstream/master'  changed wrapped function to always report done=true before terminating  fixed typo in new function wrapper, fixed some formatting and unused imports  fixed race condition when reporting results in _train and simplified how functions are wrapped ", "linked_issue_titles": "", "title": "make the logging of the function api consistent and predictable"}
{"description": " adds links to flax colabs did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " fix_torch_device_generate_test  remove @  add colab links ", "linked_issue_titles": "", "title": "add links to google colabs"}
{"description": " fixes #13811 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " tmp.  fixing bc for question answering with long context. ", "linked_issue_titles": " attributeerror when running question answering models for result ", "title": "fixing question-answering with long contexts"}
{"description": " change due to security concerns, this change disables local manifest files by default. user can still turn on local manifest files through group policy, or through running 'winget settings --enable localmanifestfiles' as administrator. validation added tests. also tested manually. microsoft reviewers: open in codeflow ", "commit_messages": " code  tests ", "linked_issue_titles": "", "title": "disable local manifest by default"}
{"description": " currently, the build_type variable of .travis.yml was ignored up to now by travis.sh and the build process. also, while cmake does not complain on build type debug (as listed in .travis.yml currently), the cmake documentation always spells it debug, so take this. using the variable in travis.sh to call cmake -dcmake_build_type=debug leads to the problem reported in issue #1175, i.e. some python driven tests won't find their test executable. the travis build triggered by the first commits here will probably fail; then a fix can be tested and discussed. this pull request fixes #1175 and #1070. ", "commit_messages": " use build type set in .travis.yml  the build_type variable of .travis.yml was ignored up to now.  use upper-case build type  while cmake does not complain on build type 'debug', the cmake  documentation always spells it 'debug', so take this. ", "linked_issue_titles": " some tests are failing when using the debug configuration (-dcmake_build_type=debug) on debian ", "title": "use cmake build type defined in .travis.yml for travis builds"}
{"description": " description: quick version push of lupupy to 0.0.17. this will now correctly transmit the state alarm_triggered which can be used in automations etc. ", "commit_messages": " added state_alarm_triggered transmission; pushed lupupy version  added state_alarm_triggered transmission; pushed lupupy version  added state_alarm_triggered transmission; pushed lupupy version  added state_alarm_triggered transmission; pushed lupupy version ", "linked_issue_titles": "", "title": "lupupy version push to 0.0.17 - will now transmitted state_alarm_triggered"}
{"description": " the vendored libmpdec has been partially updated in 9b9f158, this completes the update to upstream version 2.5.1. patch provided by stefan krah. ", "commit_messages": " complete the update to libmpdec-2.5.1.  add news item ", "linked_issue_titles": "", "title": "finish updating the vendored libmpdec to version 2.5.1"}
{"description": " this addresses cleanups asked for in the comments of #9560. @drybjed has tested the code with the examples in his readme and everything passes.  jimi-c and bcoca took a quick look as well.  we're good to merge code-wise. @drybjed will work up a separate pr to document the new filters. ", "commit_messages": " add ipaddr() filter plugin  first try at only failing if the filter is actually used.  replace large if-elif-else blocks with a dict-dispatcher  use pass instead of bare none value  better error message ", "linked_issue_titles": "", "title": "modified version of pr 9560"}
{"description": " left/right trim/ltrim/rtrim timestampadd/timestampsub other interval-relarted improvements additional case insensitive functions #3712 #3714 #3704 #3705 ", "commit_messages": " rewrite left and right functions to corresponding substring calls #3712  introduce trim/ltrim/rtrim functions #3714  introduce regexpquotemeta function to properly handle regexp special chars in trim #3714 ", "linked_issue_titles": "", "title": "additional functions for sql compatibility"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. @raisedadead per our discussion, i have removed all but the spanish translations in the /docs/i18n folder.  we can download the other languages as they become approved on crowdin. ", "commit_messages": " fix: update translations.md  chore: remove chinese, hinit, and italian ", "linked_issue_titles": "", "title": "chore(docs) - remove all but spanish translations"}
{"description": " similar to what was done in #17827, this pr caches the source directory based on the deps file and saves it to a file store that is attached to our windows vms. pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " ci: speed up src retrieval  don't save zip on ia32 ", "linked_issue_titles": "", "title": "speed up windows source retrieval"}
{"description": " updated dark mode colors. text editing menu color is still not correct: #41507. the color of the clear button seems to have changed  in ios 13.1 so might be different from what you see on ios 13.0 devices/simulators. dark light related issues #35541 i added the following tests: dark mode background color updated goldens: flutter/goldens#47 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. ", "commit_messages": " remove cupertinosystemcolors  wrong color  update docs  comments  update comments  update tests  s/gray/grey/  tab scaffold  text selection  text field  update tests  update colors  update  update tests ", "linked_issue_titles": "", "title": "cupertino { tabscafold, textselection, textfield } dark mode & minor fidelity update"}
{"description": " _convert_scalar_indexer is called with kind=\"iloc\" from only one place, and in that case the base class method is equivalent to just the 1-liner self._validate_indexer(\"positional\", key, \"iloc\") all subclasses just call the base class method so by inlining that 1-liner, we can take the \"iloc\" case out of _convert_scalar_indexer altogether. kind=none is never passed, so we can rip that right out. ultimately i want to disentable/de-duplicate/disambiguate _convert_scalar_indexer vs _maybe_cast_indexer partial overlap with #31625. ", "commit_messages": " inline indexing 1liners  dont pass iloc to convert_scalar_indexer  cln: _convert_scalar_indexer handle only loc and getitem ", "linked_issue_titles": "", "title": "_convert_scalar_indexer only handle \"loc\" and \"getitem\""}
{"description": " this ensures that we write a short log message to the journal whenever we forcibly kill processes remaining in a scope or service after execstop= or the clean signal sending completed. most importantly, log about all services we kill due to logind's killuserprocess= setting on logout. as suggested on the fedora ml. ", "commit_messages": " logind: minor coding style improvements  util: don't send sigcont following a sigcont or sigkill in kill_and_sigcont()  core: when forcibly killing/aborting left-over unit processes log about it  let's lot at log_notice about any processes that we are going to  sigkill/sigabrt because clean termination of them didn't work.  this turns the various boolean flag parameters to cg_kill(), cg_migrate() and  related calls into a single binary flags parameter, simply because the function  now gained even more parameters and the parameter listed shouldn't get too  long.  logging for killing processes is done either when the kill signal is sigabrt or  sigkill, or on explicit request if kill_terminate_and_log instead of log_terminate  is passed. this isn't used yet in this patch, but is made use of in a later  patch.  cgroup: suppress sending follow-up sigcont after sending sigcont/sigkill anyway  core: make sure requeststop signal is send directed  this was accidentally left commented out for debugging purposes, let's fix that  and make the signal directed again.  core: when a scope was abandoned, always log about processes we kill  after all, if a unit is abandoned, all processes inside of it may be considered  \"left over\" and are something we should better log about.  logind: always abandon session scopes before killing them  this way systemd is informed that we consider everything inside the scope as  \"left-over\", and systemd can log about killing it.  with this change systemd will log about all processes killed due to the session  clean-up on killuserprocesses=yes. ", "linked_issue_titles": "", "title": "log about all processes we forcibly kill"}
{"description": " as i mentioned the issue #1503 ,i translated index.md to japanese. ", "commit_messages": " add ja and translate key feature  translate opinions  translate by document upgrade  translate to end  fix text  translate spoiler alert ", "linked_issue_titles": "", "title": "add japanese translation for index.md"}
{"description": " this provides the ability to specify s3 timeouts via environment variables, as requested in #15868. ", "commit_messages": " syncing personal fork to master 20170812  catching up to master 20170822_1652  sublime text index-ignore file (a copy of .gitignore)  pull from master-master  syncing to master-master  picking up asim's multidimensional string tensors  catch-up to master-master  merging down master-master  picking up master-master including am's merge-in  merging back from master 20171028  catch up 20171210  catchup 20171212  sync up 20180104  additions to the s3 filesystem code to allow testing of whether twiddling timeouts will address connectivity issues discussed in #15868  removing .ignore file from the repository. ", "linked_issue_titles": "", "title": "addresses s3 timeout configurability discussed in #15868"}
{"description": " r? @eddyb @nikomatsakis or whoever else.  the strategy employed here was to essentially change code we generate from %s = alloca %s ; potentially smaller than argument, but never larger %1 = bitcast %s* %s to { i64, i64 }* store { i64, i64 } %0, { i64, i64 }* %1, align 4 to %1 = alloca { i64, i64 } ; the copy of argument itself store { i64, i64 } %0, { i64, i64 }* %1, align 4 %s = bitcast { i64, i64 }* %1 to %s* ; potentially truncate by casting to a pointer of smaller type. ", "commit_messages": " fix handling of c arguments  fixes #33868  add a regression test ", "linked_issue_titles": "", "title": "fix handling of ffi arguments"}
{"description": " includes fixes from #487 and other fixes to try to get the tests to run cleanly.  they still do not. :( fix unclaimed user name for \"insanejournal\". remove \"kiwifarms\".  you now have to be logged in to see any profile. update claimed user name for \"gitee\". do not use api call for \"brew\".  it probably needs to be authenticated now. fix claimed username for \"lor\". update user url for \"zomato\".  site did work before, but it is better to use preferred location. update claimed username for \"toster\". remove \"codementor\".  all usernames come back as unclaimed. fix \"opennet\" claimed username. remove \"easyen\".  as of 2019-12-31, usernames appear to redirect to an internal index. remove \"yandexmarket\".  as of 2019-12-31, all usernames are reported as existing. remove \"ramblerdating\".  as of 2019-12-31, site always times out. fix \"football\" claimed username. ", "commit_messages": " fix unclaimed user name for \"insanejournal\".  remove \"kiwifarms\".  you now have to be logged in to see any profile.  update claimed user name for \"gitee\".  do not use api call for \"brew\".  it probably needs to be authenticated now.  fix claimed username for \"lor\".  update user url for \"zomato\".  site did work before, but it is better to use preferred location.  update claimed username for \"toster\".  remove \"codementor\".  all usernames come back as unclaimed.  fix \"opennet\" claimed username.  remove \"easyen\".  as of 2019-12-31, usernames appear to redirect to an internal index.  remove \"yandexmarket\".  as of 2019-12-31, all usernames are reported as existing.  remove \"ramblerdating\".  as of 2019-12-31, site always times out.  fix \"football\" claimed username.  update version and site list. ", "linked_issue_titles": "", "title": "more fixes to site coverage"}
{"description": " description: the current generation of homekit accessories do not show the dash in the pin code on the label that is in the box. so the pairing ui should accept the pin code with and without dashes. it should only pass pin codes with dashes to the underlying library, where they are used to seed homekit crypto primitives. the underlying library can also raise homekit.exceptions.malformedpinerror which we should handle and map to an error in strings.json as well. related issue (if applicable): fixes #25933 checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " handle malformedpinerror from homekit_python  handle both formats of pin codes ", "linked_issue_titles": " homekit_controller: accept both dashed and non-dashed pin codes ", "title": "accept homekit_controller pairing codes both with and without dashes"}
{"description": " with the ability for json-rpc to set art for items, there's the possibility of art such as \"tvshow.poster\" to be set at the episode level.  we don't want this, as otherwise that particular episode will always have that tvshow poster, even after the user changes the tvshow poster.  this will pollute the database with entries that then need to be manually changed one by one via choose art. to fix this, we store all parent art using the . pattern.  e.g. fanart for tvshows is tvshow.fanart.  this still allows season-specific fanart to be used (they can just specify fanart at the season level) and, indeed, even episode-specific if that's appropriate. to pull this off, we need the normal generic listitem.art(fanart) to drop back to the appropriate art.  thus, we generalise the fallback already available for listitem.art(thumb) to allow other fallbacks.  it happens at fetch time, as otherwise the art map is populated with these items that can't be eliminated. tested with old skins and all fallbacks working.  tested with new skins and all fallbacks working. @montellese, @martijnkaijser the change is subtle, but it will mean that you'll no longer retrieve \"fanart\" and \"thumb\" at the episode or season level, unless they're set at that level.  you'll instead retrieve \"tvshow.fanart\".  same with songs/albums - you'll get artist.fanart and probably also album.thumb rather than thumb at the song level. ", "commit_messages": " [art] adds clearart to cguilistitem  [art] use a fallback map for art to generalise the fallback for the 'thumb' type, and set outside of cguilistitem  [art] adds a param to appendart to specify the prefix, and utilise for setting art for children of tvshows, seasons + albums ", "linked_issue_titles": "", "title": "art fallback fixes, and don't save show/album/season art for seasons/songs/episodes"}
{"description": " added loggers registry require training.logger entry in the config current console logging is defined as default: @loggers = \"spacy.consolelogger.v1\" (additional) logging to weights & biases is supported for those who'd want it (and have wandb installed): @loggers = \"spacy.wandblogger.v1\" project_name = \"my_cool_project\" i added a finalize callback to the logger, which currently isn't doing anything, but i could imagine some (yet to be implemented) other loggers could perhaps require one? so i figured it would be best to already take it into account for the logger api. open questions wandblogger calls into consolelogger so you get both. is there a better way? like providing a list of loggers in the config? i felt like that might overcomplicate the config, while the logger implementations could just take care of this themselves. do we want this wandblogger as part of the core lib, or as part of an example project? (can move it if we prefer) comments about weights & biases w&b is really nice. by uploading the full config (not just the training bit), you can basically filter your runs on whatever training/model parameter you like. this all works pretty much out of the box (graphs are on toy data): w&b also automatically analyses your system, including memory utilization, network traffic, disk io, cpu & gpu, ... i think this will be very useful for looking at the results of our training runs, inspecting gpu usage for the transformer models, etc etc... i have submitted the spacy contributor agreement. ", "commit_messages": " quick test as part of train script  train_logger in config, default consolelogger in loggers catalogue  entitiy typo  add wandb_logger  cleanup ", "linked_issue_titles": "", "title": "weights & biases logger for train cli"}
{"description": " converted the guidelines/logo page to theme-ui. fixed the responsive layout. local url:  production url:  screenshot(s) before after ", "commit_messages": " converted guidelines containers from styled-system to theme-ui  guidelines logo page made responsive  copycolumn sticky styling fixed for responsive  converted list, listitem & dontlistitem to theme-ui  converted css to sx in possible places of guidelines logo page  fixed the linting issue by converting double quotes to backtick  contentcolumn width changed for mobile  updated box and flex to theme-ui  used the box component from theme-ui inside layout  updated the breakpoints  breakpoints updated ", "linked_issue_titles": "", "title": "mobile layout for /guidelines/logo + converted to theme-ui"}
{"description": " transportreplicationaction is a rather complex beast, and some of its concrete implementations do not need all of its features. more specifically, it (a) chases a primary around the cluster until it manages to pin it down and then (b) executes an action on that primary and all its replicas. there are some actions that are coordinated by the primary itself, meaning that there is no need for the chase-the-primary phases, and in the case of peer recovery retention leases and primary/replica resync it is important to bypass these first phases. this commit is a step towards separating the transportreplicationaction into these two parts. it is a mostly mechanical sequence of steps to remove some abstractions that are no longer in use. ", "commit_messages": " use channelactionlistener in operationtransporthandler  generic primaryresult  no need for shardreference superclass  use actionlistener instead of channel for primary response handler  use actionlistener instead of channel for replica response handler  use concreteshardrequest throughout asyncprimaryaction  use concretereplicarequest throughout abstractreplicaaction  replace operationtransporthandler with lambda  replace primaryoperationtransporthandler with lambda  replace replicaoperationtransporthandler with lambda  allow subclasses to control whether primary action is forced  today this requires overriding and reimplementing registerrequesthandlers() but  it's clearer to highlight the difference like this ", "linked_issue_titles": "", "title": "remove some abstractions from transportreplicationaction"}
{"description": " this pr fixes remark lint warnings for the readme files in the contrib directory. related: #5941 component name docs ~/netdata$ was removed to avoid it being copied to clipboard. ", "commit_messages": " fix lint error for debian contrib  remove directory name to avoid direct copy ", "linked_issue_titles": "", "title": "fix remark lint for contrib"}
{"description": " detect and diagnose invalid uses of trailing closures - either passed to a parameter which doesn't support that or extraneous e.g. func foo(x: int) {} foo { _ in } // can't pass trailing closure to int foo(x: 42) { _ in } // extraneous trailing closure. resolves: rdar://problem/55102498 ", "commit_messages": " [constraintsystem] allow to check presence of fix by kind and locator  [constraintsystem] intoduce a fix for incorrect use of trailing closures  [diagnostics] add a diagnostic for incorrect use of trailing closures  [constraintsystem] use new trailing closure fix in matchcallarguments  [csdiag] nfc: remove obsolete trailing closure diagnostics ", "linked_issue_titles": "", "title": "port invalid trailing closure use diagnostics"}
{"description": " adding descriptions for dozens of apis that did not previously have them. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " testerrorchange  mainly the bindings apis  adding missing documentation for many apis  typo and fixing dialogoptions info ", "linked_issue_titles": "", "title": "adding missing descriptions to many apis in office.js"}
{"description": " #2922 cause helix:led_test build break. this pullrequest fix build break. copy new quantum/rgblight.[ch] into keyboards/helix/rev2/keymaps/led_test/ add new rgblight mode 35 (rgb cyclic) into local rgblight.[ch] ", "commit_messages": " copy new rgblight.[ch] from quantum/ into keyboards/helix/rev2/keymaps/led_test/ and add mode 35 rgb cyclic mode  force rgb light mode 25 ", "linked_issue_titles": "", "title": "fix helix:led_test build break"}
{"description": " you can now send websocket status codes and reasons when closing. you can now detect which status code and reason was given by a disconnecting peer, and detect if the connection was shutdown cleanly. websocketserver.disconnect_peer, websocketclient.disconnect_from_host, and websocketpeer.close will no longer immediately close the connection (at least in native platforms). please refer to the updated documentation. closes #21617 . ", "commit_messages": " implement websocket close notify.  implement websocket clean close detection.  update websocket documentation ", "linked_issue_titles": " godot doesn't send close frames upon disconnecting, and doesn't allow reading of close frames ", "title": "implement websocket close frame handling"}
{"description": " related: #19891 fixes the following mypy errors. airflow/providers/amazon/aws/sensors/s3.py:27: error: module \"functools\" has no attribute \"cached_property\" from functools import cached_property airflow/providers/amazon/aws/sensors/s3.py:194: error: need type annotation for \"keys\" (hint: \"keys: list[] = ...\") keys = [] airflow/providers/amazon/aws/sensors/emr.py:22: error: module \"functools\" has no attribute \"cached_property\" from functools import cached_property read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " [16185] added localkubernetesexecutor to breeze supported executors  revert \"[16185] added localkubernetesexecutor to breeze supported executors\"  this reverts commit a1c532eacfeddcbefaa3e565a0522e25315286c4.  fixed mypy errors in aws/sensors ", "linked_issue_titles": "", "title": "fix mypy errors in aws/sensors"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. original module uses babel-add-module-exports plugin which adds module.exports = exports['default'] line at the end of each transpiled file and thus breaks default import in typescript because module is converted into common js module. this addresses that and makes definitions of files inside lib be generated in common js style. ", "commit_messages": " fix exports for react-icons lib to comply with commonjs  regenrate lib definitions files  change lib file template, regenrate files ", "linked_issue_titles": "", "title": "fix exports for files in lib"}
{"description": " according to  the performance status of crf decoding, just implemented the intrinsic function's optimization to accelerate the data processing. platform:  intel(r) xeon(r) gold 6140 cpu @ 2.30ghz /  intel(r) xeon(r) cpu e5-2699 v3 @ 2.30ghz model path: models/fluid/chinese_ner batch size: 6, 1, 12 command: python infer.py --device cpu --profile data source: use original date provided in the model chinese_ner in the github. the following is the comparison with the different scenarios. ", "commit_messages": " optimize crf decoding with avx/avx2 instruction  enable the avx2 flags for compiling  clean the code and decrease the count of multiply calculation  add the support of avx512 instruction to optimize crf decoding  clean the code  enable the avx512f flags for compiling  clean the code for the invaluable switch ", "linked_issue_titles": "", "title": "optimize crf decoding with avx/avx2/avx512f instruction"}
{"description": " description this pr migrates the doc's app bar page to hooks. relates to #15032. i have followed (at least) the pr section of the contributing guide. ", "commit_messages": " [docs] migrate bottomappbar to hooks  [docs] migrate buttonappbar to hooks  [docs] migrate denseappbar to hooks  [docs] migrate searchappbar to hooks  [docs] migrate bottomappbar js to hooks from docs:typescript:formatted  [docs] migrate buttonappbar js to hooks from docs:typescript:formatted  [docs] migrate denseappbar js to hooks from docs:typescript:formatted  [docs] migrate searchappbar js to hooks from docs:typescript:formatted ", "linked_issue_titles": "", "title": "migrate docs' app bar page to hooks"}
{"description": " fixing workflow badge to point to the master branch and not forks with pr. looking into how to do the same for codecov ", "commit_messages": " catching exceptions in the dependancy call - eg for pydantic validation error to return a 422  update fastapi/dependencies/utils.py  changed to only focus on value and type errors which arise from pydantic validation  fixing test workflow badge  reseting master fork changes ", "linked_issue_titles": "", "title": "fix badges in readme and main page"}
{"description": " this transitions liballoc to rust 2018 edition and applies relevant idiom lints. i also did a small bit of drive-by cleanup along the way. r? @oli-obk i started with liballoc since it seemed easiest. in particular, adding edition = \"2018\" to libcore gave me way too many errors due to stdsimd. ideally we should be able to continue this crate-by-crate until all crates use 2018. ", "commit_messages": " liballoc => edition = 2018.  liballoc: cargo check passes on 2018  liballoc: refactor & fix some imports.  liballoc: adjust abolute imports + more import fixes.  liballoc: prefer imports of borrow from libcore.  liballoc: apply uniform_paths.  liballoc: elide some lifetimes.  liballoc: elide &'static.  liballoc: fix some idiom lints.  liballoc: remove redundant extern crate. ", "linked_issue_titles": "", "title": "transition liballoc to rust 2018"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test reach__router. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " add generic type for useparams  update tparam with some extra type saftey  a param might be undefined  use 'in keyof' for useparam generics  add a test for useparams ", "linked_issue_titles": "", "title": "update the types of useparams"}
{"description": " please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance ", "commit_messages": " update submodule skywalking-ui  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'origin/master'  fix k8s api bugs  merge remote-tracking branch 'origin/master'  fix api connection leak ", "linked_issue_titles": "", "title": "fix k8s api connection leak"}
{"description": " this pr adds tests for the dashboard graph backend code and several improvements (like correct edges between bucket notifications) ", "commit_messages": " modulraize pytest fixtures  fix infra graph for s3 notifications and add test  add dynamodbnode graph test ", "linked_issue_titles": "", "title": "improve infra graph code and add tests"}
{"description": " looks like on windows (and possibly linux), a web content's render widget host view can report as focused even when in a hidden window. this pull request adds a check to prevent hidden window's from having focused web contents. this mirrors the key window check already in the mac implementation. closes #6811 ", "commit_messages": " add failing webcontents.isfocused spec  ensure hidden windows don't have focused webcontents ", "linked_issue_titles": "", "title": "prevent web contents in hidden windows from reporting as focused"}
{"description": " closes #14885 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " 'bug14885'  added keyerror exception for multiindexes ", "linked_issue_titles": " wrong \"too many indexers\" error message when indexing a series with multiindex ", "title": "raise keyerror when indexing a series with multiindex"}
{"description": " fixes #33197 ", "commit_messages": " removing duplicate text-decoration style for abbr[title] #33197  removing duplicate text-decoration style for abbr[title] #33197  fix: removing duplicate text-decoration style for abbr[title] #33197 ", "linked_issue_titles": " bootstrap reboot 4.x css contains duplicate text-decoration style for abbr[title] ", "title": "remove duplicate text-decoration style for abbr[title]"}
{"description": " closes #30904 (fixed between nightly-2019-07-14 and nightly-2019-07-31) closes #40231 (example 1 is fixed in 1.32.0, example 2 is fixed in 1.38.0) closes #52432 (fixed in rustc 1.40.0-beta.1 (76b4053 2019-11-05)) closes #63279 (fixed in rustc 1.40.0-nightly (246be7e 2019-10-25)) r? @centril ", "commit_messages": " add test for issue-30904  add test for issue-40231  add test for issue-52432  add test for issue-63279 ", "linked_issue_titles": " struct and variant constructors are not generic over lifetimes like regular functions.  ice: unexpected tail in unsized_info_ty with generics + traits  ice casting a reference to a static closure as usize, inside array length  ice: instantiated twice ", "title": "add some tests for fixed ices"}
{"description": " the initial bottom panel size on small screens was too big changed the initial value of the bottom panel size to be dynamic to the screen. ", "commit_messages": " the initial panel size when the position is at the bottom will now be dynamic to the screen size  updated snapshot ", "linked_issue_titles": "", "title": "fix initial bottom panel size"}
{"description": " change adds the id to the manifest fields telemetry event, and logs a detailed search request event. as a side effect/to enable this, getarg now returns a string_view, which will be empty if the value is not present. testing no new tests are added. ", "commit_messages": " everything but search request callout added  move to using string_view for args and log search request  proper line endings ", "linked_issue_titles": "", "title": "add telemetry for more scenarios"}
{"description": " updates the colors for the docs code snippets when using a dark color scheme. here's a before and after: current docs link, pr docs link ", "commit_messages": " update code snippet colors for dark theme  use media queries ", "linked_issue_titles": "", "title": "use a dark color theme for code snippets in dark mode"}
{"description": " test passed for pb 2.6.0, 3.0.0, 3.6.0, 3.7.0, 3.8.0 ", "commit_messages": " make redisrequest derived from redisrequestbase  make redisrequestbase be member of redisrequest  make rpcdumpmeta be member of sampledrequest  make the descriptor and reflection of esp_message, memcache,  nshead_message, serialized_request, thrift_message be independent  of protobuf.  change controller::rpc_dump_meta to controller::sampled_request  compatible with pb 3.8.0  remove headers of test proto when 'make clean'  adapt callback.h after pb3.7 & remove unnecessary files ", "linked_issue_titles": "", "title": "adapt to protobuf 3.7 & 3.8"}
{"description": " there is a bug in current watermark accounting that headers and trailers are not counted. it is suboptimal in gquic, but an accounting bug in iquic. in iquic, if we don't count headers bytes as total bytes buffered, but subtract from it the bytes written in stream oncanwrite(), we would subtract more than we counted into total bytes buffered. this is because iquic stream writes headers/trailers on data stream. the fix is counting headers/trailers into total bytes buffered. in gquic these bytes are counted against connection level watermark, but not stream watermark. because it's hard to determine which byte belongs to which stream when header stream writes them out. in iquic these bytes are counted against both connection level and stream level watermarks. this also fix a concern of unlimited buffer in headers stream where headers-only responses are buffered in headers stream. risk level: low testing: added new test in quic stream and session part of: #8826, #2557 ", "commit_messages": " count headers bytes  new test fail  test pass  adjust stream tests ", "linked_issue_titles": "", "title": "fix headers/trailers bytes accounting against watermark"}
{"description": " related to  when command error message and ping \"dummy\" result json is published from cmndping(), and there is a rule on ping result, json gets broken as per the example below. this pr makes the result response asynchronous by inserting a done ping_t element in the list and move publishing the result json to the polling loop. tagging @sfromis @s-hadinger exemple of broken results: 2:43:12.446 cmd: ping bad.domain 12:43:12.474 mqt: xxxxxxxx/tele/ping = {\"ping\":{\"bad.domain\":{\"reachable\":false,\"ip\":\"\",\"success\":false}}} 12:43:12.485 rul: ping#bad.domain#reachable performs \"var1 false\" 12:43:12.494 mqt: xxxxxxxx/stat/var = {\"var1\":\"false\"} 12:43:12.499 mqt: xxxxxxxx/stat/ping = {\" 16:12:00.890 cmd: ping bad.domain 16:12:00.931 mqt: tele/nodemcu/ping = {\"ping\":{\"bad.domain\":{\"reachable\":false,\"ip\":\"\",\"success\":false}}} 16:12:00.944 rul: ping#bad.domain#reachable performs \"var1 false\" 16:12:00.956 mqt: stat/nodemcu/var = {\"var1\":\"false\"} 16:12:00.961 mqt: stat/nodemcu/ping = {\"s 0\":\"unable to resolve ip address\"} the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " move response for unresolved ip into poll  cleanup ", "linked_issue_titles": "", "title": "fix ping race condition breaks json"}
{"description": " fixes vercel/next.js#4994 componentdidupdate is called for both props + state changes, oneditorchange only has to be called when the state is changed, so i added a shallow equals check to make sure it's only updated when the state really has been changed. this solves the back button issue by removing the custom history api being used. next.js needs to control the history as it puts some state into the history entry for when you're using the back button. hence why you saw the error. ", "commit_messages": " add shallowequals check for onupdate  using next.js router instead of custom history api  fixes ", "linked_issue_titles": "", "title": "don't use custom history api"}
{"description": " this pull request adds basic documentation for the searchable snapshots rest apis. the main motivations are to not break downstream projects (see #53871) and to provide a simple example of how to mount a snapshot. it adds a new \"searchable snapshots apis\" sub section in the rest apis section. the \"mount snapshot api\" is the more complete documentation and provides an example of how to create a new index backed by a snapshot. those api are experimental and marked as such. i've not seen any mention of the license, except the [testenv=\"basic\"]  tags that i copied from other doc. ", "commit_messages": " add basic docs for searchable snapshots rest apis  update links ", "linked_issue_titles": "", "title": "add basic documentation for searchable snapshots rest apis"}
{"description": " fixes #1236 build the development environment as a docker image with the pr, we can build the development docker image by: git clone --recursive  cd paddle docker build -t paddle:dev -f paddle/scripts/docker/dockerfile . note that by default docker build wouldn't import source tree into the image and build it.  if we want to do that, we need to set a build arg: docker build -t paddle:dev -f paddle/scripts/docker/dockerfile --build-arg build_and_install=on . run the development environment once we got the image paddle:dev, we can use it to develop paddle by mounting the local source code tree into a container that runs the image: docker run -d -p 2202:22 -v $pwd:/paddle paddle:dev this runs a container of the development environment docker image with the local source tree mounted to /paddle of the container. note that the default entry-point of paddle:dev is sshd, and above docker run commands actually starts an sshd server listening on port 2202.  this allows us to log into this container with: ssh root@localhost -p 2202 usually, i run above commands on my mac.  i can also run them on a gpu server xxx.yyy.zzz.www and ssh from my mac to it: my-mac$ ssh root@xxx.yyy.zzz.www -p 2202 build and install using the development environment once i am in the container, i can use paddle/scripts/docker/build.sh to build, install, and test paddle: /paddle/paddle/scripts/docker/build.sh this builds everything about paddle in /paddle/build.  and we can run unit tests there: cd /paddle/build ctest ", "commit_messages": " add dockerfile.dev for building a standard develop environment  update dockerfile.dev ", "linked_issue_titles": "", "title": "paddle standard development environment as a docker image"}
{"description": " gradually improving the windows build experience, so far: clean deletes all specified folders (doesn't stop on first missing one) build removes any path entry containing a msbuild.exe (avoids node-gyp errors) ", "commit_messages": " fix clean command to actually work when paths missing  exclude path entries with msbuild.exe to fix node-gyp on windows ", "linked_issue_titles": "", "title": "improve the windows build process"}
{"description": " develop merge master develop merge master format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:chexck findbugs:findbugs to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " naming model refactor  revert \"naming model refactor\"  revert \"naming model refactor\" ", "linked_issue_titles": "", "title": "develop merge master ready 0.5 version"}
{"description": " adds features and method with docstrings update user guide whats new add tests this pr adds the method format_index so that the typical format routines can also be applied to display the index labels and columns headers of a styler. with all the recent functionality here is a complete example: notes also had to move _refactor_levels function from style.py to style_render.py for use here. ", "commit_messages": " build format_index mechanics  test index formatter display_value, and clearing  prelim doc string  format_index docs ", "linked_issue_titles": "", "title": "styler.format_index() to display index values similarly to data-values with format()"}
{"description": " #161 (comment) ", "commit_messages": " exclude /proc/ and /sys/ from the monitored filesystems  read netfilter count of sockets and max sockets on systems without /proc/net/stat/nf_conntrack  added alarm for monitoring the percentage used of connection tracker table  updated configs.signatures  prevent the delay to charge the netfilter alarm ", "linked_issue_titles": "", "title": "netfilter sockets chart when netfilter stats are not available and netfilter alarm"}
{"description": " there are some random failures of apiv3 tests during ci on github (github actions). this is probably caused by clashes of computed identifier of test documents. these clashes probably arise in very fast (or parallel) test execution, when test documents get the same timestamp. this pr tries to solve this by isolating test documents, which is achieved by using different device name in different test file. ", "commit_messages": " apiv3: isolating documents from tests (not allowing clashes of calculated identifiers)  removing unused async keyword ", "linked_issue_titles": "", "title": "trying to fix random fail of apiv3 tests"}
{"description": " hi mike, i've added batchsize and batchstartsat parameters to handle the buffer size problem and to cope with the senario where your buffer is larger than you want to submit at any one time. i.e. your incoming buffer is 10 elements and your ring only has 8 slots. (a problem a tripped over in one of our test scenarios). ", "commit_messages": " expose the publication batches on the ring buffer  expose the publication batches on the disruptor  fix up compiler warnings in ringbuffertest  configure snapshot versioning for publication to local nexus.  expose batchsize on batch event publication.  tidy up idea warnings  add batchsize and offset to batch publication  trypublish will now return false if the batch size is bigger than the ring buffer ", "linked_issue_titles": "", "title": "batch publication on ring buffer (take2)"}
{"description": " this came about as a requirement for converting dataframe.to_html into styler.to_html, citing @jorisvandenbossche in favour of the functionality. note that the dataframe.to_html render_links argument is rather limited to just detecting only a url in a cell. the function added for styler here is a more general pattern search, and it allows the result to be viewed in jupyter notebook directly, which the precursor does not. ", "commit_messages": " render links  tests ", "linked_issue_titles": "", "title": "add render_links for styler.to_html formatting"}
{"description": " rgb mapping is unique between iso and ansi gmmk pro pcbs, split each version into a separate revision for proper support. @hatbuster @giesd @tipok i don't actually have an iso model to test, on so if you could please confirm this actually works. fixes #13524 my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " gmmk/pro: split ansi and iso pcbs into different revisions, properly support rgb  on iso  fix formatting ", "linked_issue_titles": "", "title": "split gmmk pro pcbs into separate revisions, fix rgb mapping on iso"}
{"description": " open-mmlab/mmcv#1330 supported more interfaces in fileclient. now we can load all ground truth files including json files and images from ceph. at the same time, this pr wraps panopticapi so that the evaluation of panoptic segmentation can also be run on ceph. you need to set file_client_args in the dataset. file_client_args = dict( backend='petrel', path_mapping=dict({ '.data/coco/': 's3://openmmlab/datasets/detection/coco/', 'data/coco/': 's3://openmmlab/datasets/detection/coco/' }) data = dict( samples_per_gpu=2, workers_per_gpu=2, train=dict( type=dataset_type, ann_file=data_root + 'annotations/panoptic_train2017.json', img_prefix=data_root + 'train2017/', seg_prefix=data_root + 'annotations/panoptic_train2017/', pipeline=train_pipeline, file_client_args=file_client_args, ), ...) ", "commit_messages": " first version  replace with our api  add copyright  move the runtime error to multi_core interface ", "linked_issue_titles": "", "title": "support file_client in datasets and evaluating panoptic results on ceph"}
{"description": " see title the caching font data mechanics allows have vertices with negative x coordinate. here is an example of real vertices data for the same character: char is not blurry: #float3(x,y,z),float4(r,g,b,a),float2(tu,tv) \"{+72, +124, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13085938, +0.30000001}\" \"{+77, +124, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13574219, +0.30000001}\" \"{+77, +138, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13574219, +0.76666671}\" \"{+72, +138, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13085938, +0.76666671}\" char is blurry: #float3(x,y,z),float4(r,g,b,a),float2(tu,tv) \"{-159, +124, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13085938, +0.30000001}\" \"{-153, +124, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13574219, +0.30000001}\" \"{-153, +138, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13574219, +0.76666671}\" \"{-159, +138, +0}\",\"{+0.89803928, +0.89803928, +0.89803928, +1}\",\"{+0.13085938, +0.76666671}\" as can you see if vertex data has negative value of x coordinate the dimension of char is greater at 1 pixel - 6x14 instead of 5x14. it would be helpful if some one can test this on linux ", "commit_messages": " [guifontttf] fixed rounding x coordinate of a char if it has negative value.  now caching font data algorithm allows negative coordinates of vertices. rounding x coord does not consider negative values and it causes a font blurry in some cases.  [guifontttfdx] optimized: don't change rendering state if there is nothing to render. ", "linked_issue_titles": "", "title": "fixed a blurry font  which is happening sometimes in some cases."}
{"description": " this fixes and updates support for the nook hd (hummingbird) and hd+ (ovation), and adds support for the nook tablet (acclaim). ", "commit_messages": " set nook_pre_header_sz from 0xfffff to 0x100000  all applicable nook hd/hd+ roms are using this offset  add support for the new nook_magic  the new cmdline value that's been in use since marshmallow  add support for the nook tablet, acclaim  also changed occurences of nook with nookhd ", "linked_issue_titles": "", "title": "fixup support for nook hd, add support for acclaim"}
{"description": " use inherited value, 'false', from its base class object3d. ", "commit_messages": " removed override this.receiveshadow = undefined  inherited value is false (from its based class, object3d)  removed checking undefined against receiveshadow  receiveshadow is always boolean. skip redundant check object.receiveshadow !== undefined &&. ", "linked_issue_titles": "", "title": "removed override of .receiveshadow from light.js"}
{"description": " hi guys, here is a new pr for the plugin approach. it is still rough, but should already be as good as the previous version. it features: a plugin folder where we can put different versions of algorithm new plugins with the align extraction and the masked merge (which are the latest afaik) there is still room for improvments: general syntax may be improved, but please provide me specific feedback if you see something (or even do a pr on my own repo if you prefer) we can add easily the plugin choice through arguments, but its out of my scope for now we should add arguments parsing for plugins, but this part is not clear for me i want to add a specific support for model plugins as well as a cleaner model loading, but i'm not sure of the consequences yet, so i let that for later ", "commit_messages": " adding plugins  adding new plugins (extract_align & convert_masked)  adding pluginloader ", "linked_issue_titles": "", "title": "adding plugins + integration of face alignment & masked script"}
{"description": " issue: - this supercedes #13458 avoid bundling all supported syntax highlighter languages for addon-docs, but rather just the ones we need. this shaves off close to 2 mb from the preview vendor bundle. is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no ", "commit_messages": " fix dist/ts path  avoid loading entire react-syntax-highlighter library by importing it direction instead of through @storybook/components.  import languages from esm build.  use ts-expect-error instead of ts-ignore. ", "linked_issue_titles": "", "title": "bundle only required syntax highlighter languages"}
{"description": " why needed? regression due to #20160 which did not consider the consequential behavior change on non-probe systems. this addition of manual_probe_start_z being defined in conditionals_post.h messes up manual mesh bed levelling. when you perform mesh bed levelling, after the home, the nozzle moves to the first point. the height of that point should be \"zero\" - at the last home position. after levelling, the nozzle should move up, to the safe travel height, then move to the next xy point 2, and then move down to the previous z height, same as point 1. walkthrough of problem in code: for mesh bed levelling: if mesh_bed_leveling enabled, sets probe_selected 1 (line 795 in conditionals_lcd.h) [**] for probe_selected, z_clearance_between_probes falls back to z_homing_height. (line 2613 in conditionals_post.h) if z_clearance_between_probes is defined, then manual_probe_start_z is defined (line 2629 on conditionals_post.h) then if manual_probe_start_z is defined, then lines 224-230 in bedlevel.cpp will not run and thus manual_probe_start_z will be used for all bed leveling points as the start z height. the result is, that after moving to each new xy point during manual mesh bed levelling, the nozzle starts from z = manual_probe_start_z rather than z = zprevious. (lines 224-230 in bedlevel.cpp) simple solution, until someone has time to refactor the absolutely abysmally coded bed levelling code. the marlin policy of code devoid of useful comments really comes back to bite here! change line 216 in bedlevel.cpp: #ifdef manual_probe_start_z becomes #if defined(manual_probe_start_z) && !defined(mesh_bed_leveling) for non-probe systems. fixes manual mesh bed leveling process; each point will start from z-height of previous points. this was the previous behavior prior to this regression. fixes #21239 ", "commit_messages": " bugfix 2.0.x  fix manual mesh bed levelling  crude fix for manual mesh bed leveling operation, for non-probe systems. ", "linked_issue_titles": "", "title": "fix usage and commentary of manual_probe_start_z and z_after_probing"}
{"description": " this pr updates the interactive link styles for the management link options on the /manage page. it brings the styles in line with the new look & feel theme. screenshots hover focus active entry 1: updated the styles for the links on the management page changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @timja @daniel-beck before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue must exist, be a bug or improvement, and be labeled as lts-candidate to be considered (see query). ", "commit_messages": " extracts styles from the /manage page  - finalizes extracting the /manage page styles to the the proper less file  update link styles for /manage page ", "linked_issue_titles": "", "title": "update /manage interactive link styles"}
{"description": " the out-of-source build is officially recommended, and it makes us avoid some kinds of build errors like #2093 by removing the build directory easily. also, i've explained h2o_root in the doc to run h2o on the project directory without installing it. ", "commit_messages": " doc: recommend out-of-source build  doc: explain h2o_root for h2o developers ", "linked_issue_titles": "", "title": "recommend out-of-source build, explain h2o_root"}
{"description": " negatesignatures is called with a signature which has not yet had the hashtype appended to it, yet the function assumed a hashtype was there and was incorrectly saving and then appending the last byte of its input (ie the last byte of the original s instead of a hashtype). only one pair of the test scripts was triggering this bug (\"p2pk with high s\"), which was actually causing the invalid version of the test to fail in the wrong place -- it was failing in the isvalidsignatureencoding function rather than further down in islowdersignature where the s value is checked.  fixing negatesignatures causes this test to change so that islowdersignature is now being tested as i believe was intended. fixing that test resulted in there no longer being code coverage for the check in isvalidsignatureencoding relating to extra bytes after the s, so the second commit here adds a pair of tests to exercise that check. ", "commit_messages": " fix negatesignatures to not duplicate last byte of s  negatesignatures is called with a signature without a hashtype, so  do not save the last byte and append it after s negation.  updates the two tests which were affected by this bug.  add test for der-encoding edge case  the fix to negatesignatures caused a test which had been failing  in isvalidsignatureencoding to then fail in islowdersignature.  add new test so the original check remains exercised. ", "linked_issue_titles": "", "title": "fix usage of negatesignatures in script_tests"}
{"description": " some new release tests newly started to fail with the same commit check assertion failure as seen before in #21096, e.g. impala:  this pr applies the fix from #21119 to all app configs used in all release tests that install specific commits from from env[\"ray_wheels\"].  this pr also adds it as an instruction to e2e.py to help people creating new app configs for new release tests. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " uninstall old ray in all release test app configs  add instruction to e2e.py dosctring ", "linked_issue_titles": "", "title": "uninstall old ray in all release test app configs to fix commit mismatch error"}
{"description": " this introduces a new option setoption22 which is related to setoption20. it can essentially be described as \"apply setoption20 setting to commands from the faceplate\" see #469 for more info. ", "commit_messages": " tuya: fix setoption20 for oittm/moes  tuya: add setoption22 to select if brightness-commands from faceplate should be ignored while powered off ", "linked_issue_titles": "", "title": "fix setoption20 behavior for oittm/moes"}
{"description": " when you do: spacy.load('en', disable=['parser', 'tagger', 'ner', 'textcat']) there is a high risk of throwing an exception if the user did not install the model before. te easiest way to use the spacy tokenizer is the one i propose here. this way there is no need for the user to download any spacy model. more info here: ", "commit_messages": " update tokenization_xlm.py  update tokenization_openai.py  update tokenization_openai.py ", "linked_issue_titles": "", "title": "better use of spacy tokenizer in open ai and xlm tokenizers"}
{"description": " move additional code/methods into baseviewer and have the extending classes override/extend methods as necessary this attempts to provide more \"default\" methods in the base class, in order to reduce unnecessary duplication and to improve self-documentation of the baseviewer class slightly. the following changes are made (in no particular order): have baseviewer implement the _scrollintoview method, and extend it as necessary in pdfviewer/pdfsinglepageviewer. simply inline the baseviewer._resizebuffer method, in baseviewer.update, since there's only one call-site at this point. provide a default implementation of _isscrollmodehorizontal in baseviewer, and have pdfsinglepageviewer override it. provide a default implementation of _getvisiblepages, and have pdfviewer extend it and pdfsinglepageviewer override it. try to simplify the pdfsinglepageviewer._scrollintoview method slightly, by unconditionally ensuring that rendering always occurs ", "commit_messages": " move additional code/methods into baseviewer and have the extending classes override/extend methods as necessary  this attempts to provide more \"default\" methods in the base class, in order to reduce unnecessary duplication and to improve self-documentation of the baseviewer class slightly.  the following changes are made (in no particular order):  - have baseviewer implement the _scrollintoview method, and *extend* it as necessary in pdfviewer/pdfsinglepageviewer.  - simply inline the baseviewer._resizebuffer method, in baseviewer.update, since there's only one call-site at this point.  - provide a default implementation of _isscrollmodehorizontal in baseviewer, and have pdfsinglepageviewer override it.  - provide a default implementation of _getvisiblepages, and have pdfviewer extend it and pdfsinglepageviewer override it.  try to simplify the pdfsinglepageviewer._scrollintoview method slightly, by unconditionally ensuring that rendering always occurs ", "linked_issue_titles": "", "title": "move more code/methods into baseviewer, and simplify the pdfsinglepageviewer._scrollintoview method slightly"}
{"description": " fixes #20675 the memoized state of effect hooks is only invalidated when deps change. deps are compared between the previous effect and the current effect. this can be problematic if one commit consists of an update that has changed deps followed by an update that has equal deps. that commit will lead to memoizedstate containing the changed deps even though we committed with unchanged deps. the n+1 update will therefore run an effect because we compare the updated deps with the deps with which we never actually committed. to prevent this we now invalidate memoizedstate on every updateeffectimpl call so that memoizedstat.deps always points to the latest deps. test plan ci green codesandbox of #20675 has expected behavior all codesandboxes in #20676 (comment) have the expected behavior (no effects are logged after clicking) ", "commit_messages": " current behavior of effect dependencies on render phase updates  fix: don't schedule effects when render phase updates aren't committed ", "linked_issue_titles": " bug: functioncomponent re-render phase cause a bug ", "title": "don't run effects if a render phase update results in unchanged deps"}
{"description": " we only really care about the glibc api, but we probably should only use the official parts, wherever possible. ", "commit_messages": " signal-util: don't introduce symbols with double underscores  ansi c reserves identifiers beginning with an underscore for compiler  internal stuff. we already invade that namespace plenty and probably  should not. but even going for the doubly underscore prefixed namespace  is a bit too much. let's just rename the offending table as  \"static_signal_table[]\", since it lists the static defined signals  rather than the \"dynamic\" rtsigmin/rtsigmax signals.  sort-util: use comparison_fn_t instead of __compar_fn_t  let's avoid using the internal type of glibc, and rather use the one  they officially export.    stub: also move magic string in stub into .sdmagic pe section  we already did that for sd-boot, hence do it for sd-stub the same way.  also, move the __attribute__ stuff to the beginning of the statement,  rather than the middle. mostly just because we usually put it first for  implementations for identifiers (for prototypes we put it last).  macro: also use trailing __ for alignof use in attributes  while the underscore is optional, the docs say we should suffix and we  do that everywher else. do so here too.  network: use official bswap_32() rather than inofficial __bswap_32()  the former is a macro for the latter, but let's use the official api  (the one that has an api).  tree-wide: use c99 __func__ rather than obsolete __function__  we use __func__ almost everywhere, but there are some holdouts. fix  that.  ethtool-util: let's use userspace types in userspace code  using kernel types __u32 is fine for headers shared by the kernel, but  if we define something in userspace and only use it in userspace, in our  own .c files, let's stick to userspace fixed-length types.  localed: use project_file rather than __file__ for logging  all our log.h code uses project_file for this, let's hence use it here  too. ", "linked_issue_titles": "", "title": "use less glibc internal symbols, modernize some other stuff"}
{"description": " description: this pr breaks out one of the concepts from #6161 -- an efficient mechanism for remembering a set of statnames to reject, to use for caching the results of the stats-matcher. risk level: low -- not used yet. testing: //test/... docs changes: n/a release notes: n/a ", "commit_messages": " adds sharedstatnamestorageset.  stop using shared_ptr for the rejected-stats set; the way it's structured, this is not necessary. ", "linked_issue_titles": "", "title": "add/test heterogenous set of statnamestorage objects."}
{"description": " add new feature: can create public namespace in different formats, include json, xml, yml, yaml, txt, just like creating a private namespace. public namespace in these formats can be associated correctly. discussion fixes #2602 remove verify formats of creating public namespace in portal api and front-end add front-end elements to create public namespace in formats add front-end text box to show associated namespace when parent namespace are different with child namespace. read the contributing guide before making this pull request. run mvn clean test to make sure this pull request doesn't break anything. update the changes log. ", "commit_messages": " feature: allow create public namespace in many formats  - change front-end and portal service to allow create new namespace in format json/yaml/xml/txt  - can not associating namespace of these formats now  - todo: change some documents on front-end page  feature: portal front-end can request associate namespace info  feature: public namespace in many formats ", "linked_issue_titles": "", "title": "public namespace support different formats"}
{"description": " changing it from a generic \"bad request\" to 431 (request header fields too large) moving the existing h2 integration test to integration.cc and adding http/1.1 coverage. ", "commit_messages": " changing error code on overly long headers to 431, moving h2 test to cover http as well ", "linked_issue_titles": "", "title": "tweaks to the \"headers too long\" path"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). region opacity:  point sensitivity:  increase the version number in the header if appropriate. ", "commit_messages": " add missing fields and run autoformatter  update version and add my name to author list  fix failing test ", "linked_issue_titles": "", "title": "c3 - add missing fields, run autoformatter, fix failing test"}
{"description": " fixing the led code in my keymap to use both leds on the pro micro. before, it was incorrectly using pin b5 instead of d5. edited the led driving code to accurately use the leds on pins b0 and d5 instead of b0 and b5 as my previous code was doing. fixing use of incorrect pins for leds in my keymap. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " fixing led pins to accurately use the pro micro leds  fixing trailing whitespace ", "linked_issue_titles": "", "title": "mf68 keymap led pins fixed"}
{"description": " this updates statusbaritem.hostbackground and statusbaritem.hostforeground to use their own colors, as previously discussed. this also polishes the extension-remote-badge to make it centered. ", "commit_messages": " update statusbaritem.host colors  center remote icon in badge  center remote icon in extension editor ", "linked_issue_titles": "", "title": "polish host colors and badge"}
{"description": " this is a follow up to #24305 which ended up breaking getsentry tests. i made a small change so that getsentry doesn't break on top of that pr. commit to fix tests: 9dd9e29 ", "commit_messages": " have a ready to go buffer of demo orgs  move to different file  adds migration  adds django app for demo  fix times  makes tests  merge from master  update  small fix  update  move import statement  merge from master ", "linked_issue_titles": "", "title": "feat(demo) premake orgs v2"}
{"description": " pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: \"[component] fix leaky abstraction\". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( a few days ago lorempixel.com was down for a couple days. the cards with images on the card page didn't have images for both the avatar and card during that time. this pr replaces the image links with images hosted in the repo. closes #4731 ", "commit_messages": " changed images used for card page to hosted image; added nature image from lorempixel  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "replaces images on card page with hosted images"}
{"description": " resolves #21676. fixes failing test added in #21677 when adding the new suspense/offscreen effects semantics, we intentionally left out the subtreeflags checks since these values aren't 100% reliable and the check is just an optimization. (refer to the // todo (offscreen) comments in the source code.) it looks like #21386 (re)added one though, which was causing a failure case originally reported here: reactwg/react-18#31 for now, this pr just removes that check and adds a follow up todo comment. this is just a bandaid fix to allow us to resume rolling out the new suspense layout semantics. a proper long-term fix would be to identify why the subtreeflags are incorrect in this case. ", "commit_messages": " add failing test for suspense layout semantics  removed subtreeflags check from commitlayouteffects_begin()  this was preventing layout effects from being recreated within offscreen subtrees in some conditions. ", "linked_issue_titles": " bug: layout effects don't re-fire in 18 on suspense re-showing ", "title": "fix for failed suspense layout semantics"}
{"description": " plus some more stuff, read the commit comments / changes. ", "commit_messages": " alias --verbose to --log-level=info  print_verbose is now simply logger.info() and is always displayed if  log level allows it. this affects only the prune and mount  commands which were the only users of the --verbose option. the  additional display is which archives are kept and pruned and a single  message when the fileystem is mounted.  files iteration in create and extract is now printed through a  separate function which will be later controled through a topical  flag.  silence file listing unless --changed is present  silence borg by default  this also prints file status on stderr directly, bypassing the logger  as we do with other topical flags (like progress and status)  update documentation to follow changes  move changed with other topical flags  we need to have a sane default there otherwise the option may not be defined in some sub-commands and will crash  do not display unchanged files by default  add a --unchanged topical file to display those files  change file status test and cleanup last ref to --verbose  this ports the changes here to #445  add a --filter option replacing --changed/--unchanged  the problem here was that we do not just have changed and unchanged items,  but also a lot of items besides regular files which we just back up \"as is\" without  determining whether they are changed or not. thus, we can't support changed/unchanged  in a way users would expect them to work.  the a/m/u status only applies to the data content of regular files (compared to the index).  for all items, we always save the metadata, there is no changed / not changed detection there.  thus, i replaced this with a --filter option where you can just specify which  status chars you want to see listed in the output.  e.g. --filter am will only show regular files with a(dded) or m(odified) state, but nothing else.  not giving --filter defaults to showing all items no matter what status they have.  output is emitted via logger at info level, so it won't show up except if the logger is at that level.  archive checker: remove report_progress, fix log levels  remove --log-level, add --debug and --info option, update docs  removed --log-level due to overlap with how --verbose works now.  for consistency, added --info as alias to --verbose (as the effect is  setting info log level).  also added --debug which sets debug log level.  note: there are no messages emitted at debug level yet.  warning is the default (because we want mostly silent behaviour,  except if something serious happens), so we don't need --warning  as an option.  add developer docs about output and logging ", "linked_issue_titles": "", "title": "refactor --verbose and silence borg by default (supercedes pr 444)"}
{"description": " as discussed in dotnet/aspnetcore#15351, the behavior of the \"defaults\" methods could be clarified a bit. i had a few minutes so i took a stab at it. internal render: kestrel web server implementation in asp.net core configure certificate authentication in asp.net core ", "commit_messages": " update kestrel.md  update certauth.md  update kestrel.md  update kestrel.md  update certauth.md ", "linked_issue_titles": "", "title": "add a clarifying note about kestrel's configureendpointdefaults and configurehttpdefaults methods"}
{"description": " the current kubectl can't proxy anything that's not under the /api path. this removes that restriction while still allowing old tooling work the same. this is required for kubectl to be a drop-in replacement for the ro port; prometheus example is updated to show this. ", "commit_messages": " fix 'kubectl proxy' to allow the /metrics page to be proxied, without breaking the previous proxy behavior  fix prometheus usage of kubectl proxy  gendocs ", "linked_issue_titles": "", "title": "allow kubectl proxy to proxy everything"}
{"description": " corrects the first iconbutton sample, adds a raisedbutton sample. fixes #27168 fixes #12382 ", "commit_messages": " add sample for raisedbutton  updated iconbutton sample ", "linked_issue_titles": " add example in flatbutton, raisedbutton, etc that shows setting the text of the button  iconbutton sample fails to run. ", "title": "update an iconbutton sample, add raisedbutton sample"}
{"description": " openers and editors were still being stored in project. this moves the specs and the variables themselves over to workspace. moving buffers over is something else we could do, but i'm not sure how that fits with our multi-project plans. ", "commit_messages": " move openers to workspace  update workspace::getopeners  move project::eacheditor to workspace::eacheditor  use existing remove method  fix problem with workspace::eacheditor  move editor tracking to workspace  fix bug in project::geteditors  set atom.workspace in workspace spec  move editor removal specs to workspace  move editor-created event to workspace  move editor-created specs to workspace ", "linked_issue_titles": "", "title": "move functionality from project to workspace"}
{"description": " here are the proposed changes to improve seo. additionally, i changed the rest of the h1 titles in the landing page to h2. ", "commit_messages": " feat: change element hierarcy  feat: update meta ", "linked_issue_titles": "", "title": "update seo on landing page"}
{"description": " dealing with issues: #2728 - separate directories for geometry primitives and scene primitives instead of mixing them in src/core? #2729 - ray3 geometry primitive (first part of splitting current ray into separate classes) #2736 - ray - sphere intersection testing. #2738 - bad bounding box calculation in buffergeometry.js if there is only a single point ray has full unit test coverage and all unit tests pass. ", "commit_messages": " initial implementation of ray3.  add recastself and document that i am unsure of the best way to handle failure cases.  fixed #2728, moved geometry primitives out of src/core into src/math.  src/core is now exclusive scene primitives.  rename ray -> raycaster, ray3 -> ray per @mrdoob (see #2729)  ray unit tests.  finished scope of ray unit tests, now i just need to make them work.  all ray unit tests pass. ", "linked_issue_titles": "", "title": "new ray geometric primitive, ray->raycaster rename, move of geometric primitives to src/math"}
{"description": " hey, i have updated the type definitions for the touchripple classes to match what is implemented in the buttonbase component.  fixes #11803. thanks! ", "commit_messages": " fixed typings on touch ripple classes  added semicolon to end of class key ", "linked_issue_titles": "", "title": "corrected the type definitions for the touchripple classes"}
{"description": " update windows openssl to ver 1.1.1 (library files and include files). move visual studio 2008 static link libs from src/buildfiles/library to src/buildfiles/library/vs2008. also .sln and .vcproj files are updated. add visual studio 2017 static link libs of openssl and zlib to src/buildfiles/library/vs2017. improve .gitignore. your great patch is much appreciated. we are considering to apply your patch into the softether vpn main tree. softether vpn patch acceptance policy:  you have two options which are described on the above policy. could you please choose either option 1 or 2, and specify it clearly on the reply? -1 preliminary declaration for future switch to a non-gpl license i hereby agree in advance that my work will be licensed automatically under the apache license or a similar bsd/mit-like open-source license in case the softether vpn project adopts such a license in future. ", "commit_messages": " win32 openssl header file: ver 1.0.2j -> ver 1.1.1  added openssl 1.1.1 .lib files for visual studio 2008.  add automatically generated files to .gitignore  add visual studio automatically generated files to .gitignore  improve .gitignore  added openssl 1.1.1 and zlib's .lib files for visual studio 2017. ", "linked_issue_titles": "", "title": "upgrade windows openssl to 1.1.1, and also visual studio 2017 static link libraries support."}
{"description": " new features apis paddle new apis: put_along_axis. xu huang is on holiday so we created this pr to work on it. it is based on his pr: #37921 api screenshot: ", "commit_messages": " init commit  init commit  add put_along_axis_op and unitest  fix a lot of bug  for ci  fix cmake depency problem in ci  modified as review suggestion and fix rocm ci problem.  split this pr into two parts, this is the put_along_axis_op part  fix a bug in broadcast in python level  fix a bug in caculate gradient of value  using tensorcopy instead directly assign  add inplace api for put_along_axis and unittest.  used pre-commit for manipulation.py ", "linked_issue_titles": "", "title": "put_along_axis (based on pr #37921 by xu huang)"}
{"description": " this pull request is just a small documentation change that i think will be helpful to others. i spent a while trying to figure out how to get material-ui to play well with other styling libs and noticed i needed to specify the default style injection point in my html head to ensure the right order of styles. ", "commit_messages": " add default injection comment to help for overriding  thought it might be useful for others to clarify what comment is used by material-ui by default, to inject styles after. this can greatly help integration with other styling libs.  note that currently the injection comment is  <!-- jss-theme-reactor --> but as mentioned by @oliviertassinari here  update override help injection comment  as per  note current implementation still uses <!-- jss-theme-reactor --> for now. ", "linked_issue_titles": "", "title": "update help for 'overriding' to specify injection point"}
{"description": " ref #205 ", "commit_messages": " remove native contract actions types from built-in types  add from_variant/to_variant specialization for uint{64,32,16,8} to prevent the catch all  template<typename t> void from_variant( const variant& v, boost::multiprecision::number<t>& n ) function  that forces the variant to be in string format (v.get_string()) ", "linked_issue_titles": "", "title": "fix surrounding quotes for uint64 in json"}
{"description": " resolves #5701 ", "commit_messages": " dev  dev upgrade to 0.10.3 for latest reports pgs distribution  dev create pr for activity document  ice cream dev update  dev update for loop overrides  dev  dev  add carb foodtype, absorptiontime to reports  add carb foodtype, absorptiontime to reports  add carb foodtype, absorptiontime to reports ", "linked_issue_titles": "", "title": "add loop carbs foodtype, absorptiontime to reports for issue #5701"}
{"description": " i hereby agree to the terms of the cla available at:  changelog category: documentation for #7572 detailed description: translated to russian topic that was added in #8161. ", "commit_messages": " [clickhousedocs] translate custom http handlers with prepared queries (#126)  * literacy checking  * ru translation  * update docs/ru/interfaces/http.md  * update docs/ru/interfaces/http.md  * update docs/ru/interfaces/http.md  * update docs/ru/interfaces/http.md  * update http.md  * update http.md ", "linked_issue_titles": "", "title": "the predefined http handlers topic translated to russian"}
{"description": " changed method range to rangeclosed to include end. ", "commit_messages": " string to char array and char array to string.  method change  custom threadpool in java 8 parallel streams  implemented suggested edits from editor.  broke long method signature  changed primitive type int to long and formula.  update wrapper type to long  conflicts:  core-java/src/test/java/org/baeldung/java/streams/threadpoolinparallelstream.java ", "linked_issue_titles": "", "title": "custom thread pools in java 8 parallel streams"}
{"description": " i think it may be good to fix this because cmd-line help is more likely to be forgotten in testing and so a program may be distributed to users with one of these two bugs that break cmd line help and so make it unusable. ", "commit_messages": " fix an error when help for an option is blank  update news ", "linked_issue_titles": "", "title": "fix an error in argparse help when help for an option is blank"}
{"description": " this fixes build issues with the 32-bit risc-v port. ", "commit_messages": " library/panic_unwind: add unwind_data_reg for risc-v 32-bit  library/std: linux: add support for risc-v 32-bit  library/std: raw: add support for risc-v 32-bit  library/std: sys_common: add support for risc-v 32-bit  library/unwind: add support for risc-v 32-bit  tools/build-manifest: add support for risc-v 32-bit ", "linked_issue_titles": "", "title": "build fixes for risc-v 32-bit linux support"}
{"description": " for : #5092 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " add unit test for embeddedpermissionpersistserviceimpl ", "linked_issue_titles": "", "title": "add unit tests for class embeddedpermissionpersistserviceimpl in nacos 2.0"}
{"description": " added maven package setup instructions as an alternative to intellij. also removed a duplicate java setup/install markdown file. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) @lanking520 @andrewfayres ", "commit_messages": " added command line alternative to intellij  removed the duplicate file ", "linked_issue_titles": "", "title": "added command line alternative to intellij in install instructions"}
{"description": " some further fix for #12779 will refine all dist deps in next pr. add op_role_var (the op attributes record corresponding parameter and gradient) when transpile to distributed program, in multi_device_graph_pass try to let one gradient's send op and it's recv op for the parameter locate on the same place. tested for cpu/gpu and sync/async mode ", "commit_messages": " dist transpiler add control dependency var between send and recv  fix async deps ", "linked_issue_titles": "", "title": "resovle multi gpu async deps"}
{"description": " closes #23360 ", "commit_messages": " feat(gatsby-recipes): use theme-ui preset as default index.js  feat(gatsby-recipes): show elapsed timer when apply steps after 10 seconds ", "linked_issue_titles": " update the ui when the apply step has taken longer than 10 seconds ", "title": "while apply a step, show the time elapsed after 10 seconds"}
{"description": " visiting a wildcard variable declaration (e.g. let _ = 4) with sourceentitywalker::walktodeclpre(decl *, charsourcerange) currently yields a range of length zero, whereas e.g. let x = 4 yields a range of length 1. the motivating use case for having a length-1-range here instead is to provide an accurate inlay type hint after the variable identifier, see apple/sourcekit-lsp#408 (comment) for details this pr therefore fixes the issue by defaulting to length 1 if the declaration doesn't have a name and an underscore occurs at the corresponding location in the source file. ", "commit_messages": " add wildcard parameter case to variabletype test  fix name range of wildcard names in walktodeclpre ", "linked_issue_titles": "", "title": "fix name range of wildcard declarations"}
{"description": " fixes bug #71 (new installs fail because /var/lib/docker doesn't exist) and also makes a minor improvement to the download progress bar ", "commit_messages": " minor formatting changes to progressreader. newlines when complete  create docker directories *before* allocating a layerstore  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "create /var/lib/docker so new installs don't fail"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " update-repo  update-repo  added access manager v3 types ", "linked_issue_titles": "", "title": "added pubnub access v3 api types"}
{"description": " contributes to #3283. right now maintainer has to type /gha run build-r-artifacts to prepare r-package for submission to cran. this pr moves cran package building from github actions to azure pipelines where we create all other artifacts. new job takes about 1 minute, so it doesn't significantly impact overall ci time. but with this job it is possible to attach cran artifact to releases automatically (refer to #3872 (comment)). @jameslamb could you please help to summarize what else should be done to close issue #3283? ", "commit_messages": " build cran r-package on azure with every commit and attach to releases  test ci  fix path  revert ci test ", "linked_issue_titles": "", "title": "build cran r-package on azure with every commit and attach it to releases"}
{"description": " in my work on the cdt pipeline, i discovered that the docker plugin for buildkite follows docker's philosophy of requiring you to explicitly import environmental variables into your container. this contradicts with the expected behavior of buildkite environmental variables, which are a set of variables available in all buildkite agents providing context about the current build. we write a lot of scripts which rely upon these buildkite environmental variables. this pull request adds the propagate-environment flag to explicitly tell the docker plugin for buildkite to import all the variables you see on the \"environment\" tab of any buildkite job into the running container so we can rely on them when writing automation scripts. i also did some refactoring of these yaml files for pull request 7148, so this pull request reflects that refactoring on develop. long-running tests tested in build 2560 and build 2562. update in pull request 7148 against the release/1.7.x branch, i also added error handling code to ctest in the test scripts. this addresses the case where ctest runs some tests and then throws a non-zero exit code, preventing artifacts from being uploaded. this code disables exit-on-error for the script, saves the ctest exit status, uploads artifacts (failing only when artifacts are not present and ctest exit status is zero), and then rethrows the ctest exit status at the end. update 2 removed the long-running tests as this pipeline has been centralized. see pull request 7159 for more information. none. none. none. ", "commit_messages": " buildkite docker plugin now adds variables on \"environment\" tab to container  updated buildkite yaml to match release/1.7.x branch ", "linked_issue_titles": "", "title": "buildkite docker plugin propagate-environment and ctest error handling"}
{"description": " firstly, the indicators in cpusidebar aren't shown for loopxx instructions. also, back in the days when you selected loopxx instruction, you could spot the hint like \"jump is taken\" or \"jump is not taken\" in the cpuinfobox. i believe this was deleted by this commit 6348cb5 after changes in cpuinfobox::disasmselectionchanged because it is still present in my april snapshot. however, it was working incorrectly. this is, because the loop instruction firstly decrements the ecx, then checks if it's != 0. i will try to explain it using images. ecx = 0, \"jump is not taken\" in the info box however... the jump is in fact taken, ecx = 0xffffffff now when the ecx = 1, \"jump is taken\" in the info box however... the jump is not taken, ecx = 0 x64dbg needs to check whether the ecx = 1 to check if the branch is going to execute, that is because both decrementation and comparison is done inside the cpu loop instruction handler ", "commit_messages": " gui: make loop conditional instruction, fixes #2366  zydis: fixed isbranchgoingtoexecute for loopxx instructions ", "linked_issue_titles": "", "title": "changes connected to loopxx instructions"}
{"description": " description: allow -l warn to configure log level, and sanity check arg value. risk level: low testing: unit test docs changes: n/a release notes: n/a fixes #9560 ", "commit_messages": " allow -l warn to configure log level on startup, and protect against invalid values for log level.  update allowed log levels in usage ", "linked_issue_titles": " envoy_log(warn, ...) vs -l warning inconsistency ", "title": "allow \"-l warn\" and protect against invalid arg values"}
{"description": " add error info when fc bias shape is not 1d issue 15032 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change @patriczhao @taolv @anirudh2290 ", "commit_messages": " add fail info for mkldnn fc  fix lint ", "linked_issue_titles": "", "title": "add error info when mkldnn fc bias dimension is wrong"}
{"description": " followup #3306 ", "commit_messages": " remove util methods from cli/resources.rs  try resource table on state  remove global resource table  cliresource -> streamresource, remove cli/resources.rs  fix stdio resources  fix stdout  add hack not to drop worker ", "linked_issue_titles": "", "title": "per-worker resource table, take 2"}
{"description": " even after tokuhirom/test-tcp#59 went in, we have been seeing occasional ci errors (for an example, see  this might be (at least partly) due to us calling empty_port with no argument (thus looking for an empty port on 127.0.0.1) and then trying to use that port on 0.0.0.0. this pr fixes the issue in either of the two ways depending on the tests being run: look for an empty port on 0.0.0.0 (by calling empty_port({ host => '0.0.0.0' })) bind using the loopback address (i.e. 127.0.0.1) to the empty port being found ", "commit_messages": " call empty_port for 0.0.0.0 since that is the address we listen to  remove unused import  redis-server binds to 0.0.0.0  bind to 127.0.0.1  bind to 127.0.0.1  bind to 127.0.0.1  remove unused import  remove unused import  bind to 127.0.0.1  bind to 127.0.0.1  plack::server::standalone binds to 0.0.0.0  bind to 127.0.0.1  bind to 127.0.0.1  remove unused import  bind to 127.0.0.1  remove unused import ", "linked_issue_titles": "", "title": "check avialability of correct address"}
{"description": " small typo correction to text in two i18n.json files how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog ", "commit_messages": " [fix]: corrects typo in english i18n.json file  [fix]: corrects typo in belarusian i18n.json file  this will need to be re-translated in belarusian ", "linked_issue_titles": "", "title": "corrects typo in analytics section of the admin page"}
{"description": " this pr enables debugging with vscode's ptvsd on a local docker setup. update readme with instructions on how to start debugging - getredash/website#192 bring back --reload by creating a dedicated debug docker entry point (@arikfr wdyt?) ", "commit_messages": " open port 3000 for remote debugging  add ptvsd  use port 5678 to avoid changes in vscode's default config  attach to ptvsd ", "linked_issue_titles": "", "title": "enable remote debugging with ptvsd"}
{"description": " my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " remove unused is_command() instances from keyboard-level config.h, 0-9  remove unused is_command() instances from keyboard-level config.h, a-b  remove unused is_command() instances from keyboard-level config.h, c-d  remove unused is_command() instances from keyboard-level config.h, e-g  remove unused is_command() instances from keyboard-level config.h, handwired  remove unused is_command() instances from keyboard-level config.h, h-m  remove unused is_command() instances from keyboard-level config.h, n-r  remove unused is_command() instances from keyboard-level config.h, s-z  remove unused magic key definitions from keyboard-level config.h, 0-9  remove unused magic key definitions from keyboard-level config.h, a  remove unused magic key definitions from keyboard-level config.h, b  remove unused magic key definitions from keyboard-level config.h, c  remove unused magic key definitions from keyboard-level config.h, d-e  remove unused magic key definitions from keyboard-level config.h, f-h  remove unused magic key definitions from keyboard-level config.h, handwired  remove unused magic key definitions from keyboard-level config.h, i-k  remove unused magic key definitions from keyboard-level config.h, l-m  remove unused magic key definitions from keyboard-level config.h, n-r  remove unused magic key definitions from keyboard-level config.h, s-v  remove unused magic key definitions from keyboard-level config.h, w-z ", "linked_issue_titles": "", "title": "remove unused is_command() instances and magic key definitions"}
{"description": " while here, respect the host default compiler of cc. if that fails, then try gcc and finally clang. now i can do ./configure make and there are zero warnings when cc is clang on netbsd. ", "commit_messages": " toupper(3) says the argument should be of type int  move the format string into the {l,r}print_col() functions.  this avoids a more invasive change to avoid warnings about  passing an unchecked string as a format argument.  prefer the host default compiler  if that fails, fall back to gcc and then clang. ", "linked_issue_titles": "", "title": "fix build when clang is the compiler"}
{"description": " this consistently improves dev performance in chrome. before this change: create 10k rows: 7861 update 1k rows: 1405 update 1k rows: 1337 update 1k rows: 1373 update 1k rows: 1340 update 1k rows: 1381 clear 10k rows: 1603 create 10k rows: 7799 update 1k rows: 1391 update 1k rows: 1339 update 1k rows: 1324 update 1k rows: 1338 clear 10k rows: 1567 after this change: create 10k rows: 6460 update 1k rows: 1312 update 1k rows: 1237 update 1k rows: 1231 update 1k rows: 1263 update 1k rows: 1248 clear 10k rows: 1083 create 10k rows: 6326 update 1k rows: 1298 update 1k rows: 1233 update 1k rows: 1245 update 1k rows: 536 update 1k rows: 1058 update 1k rows: 1299 clear 10k rows: 1104 this only seems to help dev in chrome. i did not observe any significant difference in prod in chrome, or in either build in firefox or safari. normally it would be too much dogscience but i feel the wins for chrome dev (most common use case) are significant, they are consistently reproducible, and it kinda makes sense to use numbers anyway. ", "commit_messages": " ensure this._domid is always a number  ensure this._rootnodeid is always a number ", "linked_issue_titles": "", "title": "improve dev performance in chrome"}
{"description": " this adds support for a virtual serial usb device. it appears along side the other hid devices when enabled. it is useful for being able to send over usb serial instead of as a hid device, in case you ever need such a thing., in my case, i wanted to use a serial device to emulate a stenograph machine to be used in plover. this is implemented for the ergodox, but can easily be adapted for others. macro functions can be used to send whatever you need over serial. ", "commit_messages": " added usb virtual serial support  txbolt (steno) serial protocol for ergodox ez ", "linked_issue_titles": "", "title": "virtual serial port - and a layout that uses that virtual serial port for plover"}
{"description": " added top level 'tutorial' section added a 2 images to help illustrate tutorial ran through the tutorial and made small edits for clarity ", "commit_messages": " tutorial ported from @spicyj's internal wiki to top-level navigation option  fix the conflict  fixed coloring for tutorial  additional tutorial cleanup ", "linked_issue_titles": "", "title": "new top level menu item tutorial, tutorial ported from @spicyj's internal course"}
{"description": " checked out the new release tag if found and do makes docs on it. rest of the logic stays same. added readable comments in many places so reader can follow the logic in the code. ", "commit_messages": " temporary fix to update the verionsioning of 1.1.0 that is skipped during build process  updated build_doc.sh  testing new updates of build_doc.sh  fixed comments and syntax  removed test data and comments ", "linked_issue_titles": "", "title": "updated build_doc.sh to build on the new release tag found"}
{"description": " this change moves all test files from the ./tests folder to ./tests/testdata and makes the cwd ./tests/testsdata for all these tests. ", "commit_messages": " create new testdata folder.  more fixes.  fix remaining integration tests.  fix module graph tests.  fix remaining tests  format. fix linting errors. ", "linked_issue_titles": "", "title": "move test files to testdata directory"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ", "commit_messages": " updating the office-js with addin api and office-js-preview with the acoffice.actions.associate api. ", "linked_issue_titles": "", "title": "adding definition for sharedruntime api in office-js and adding office.actions.associate in office-js-preview"}
{"description": " i ran clang scan-build on code derived from src/buffer.c and am upstreaming a couple of fixes. fix a resource leak in git_buf_try_grow when realloc returns null. minor fix to bounds on an assert in git_buf_join. assert in git_buf_join to keep static analyzers happy. don't pass null str_a to memmove.  it's undefined. add unit tests for calls to git_buf_join where buf->ptr and str_a overlap. ", "commit_messages": " fix corner cases and an undefined behavior  add unit tests for git_buf_join corner cases ", "linked_issue_titles": "", "title": "fix a couple of corner cases and an undefined behavior"}
{"description": " the readme file for the ergodox ez section suggested creating a pull-request to add our custom firmware, so i thought i'd give it a go. motivation essentially, i wanted to switch to a layout that was less jarring than the default ergodox ez layout, and did not require finger gymnastics to perform common os x shortcuts (most of which involve the cmd (lgui) key). how is it different from the default ergodox ez layout? this layout more closely resembles that of the mac keyboard, and has some other goodness baked in. here is a rundown of what that means: mac-like changes the key to the left of \"1\" is \"~\" instead of \"=\". the key to the right of \"0\" is backspace instead of \"-\" (misleadingly labeled \"delete\" on the mac's keyboard). there was no room to fit in \"-\" and \"=\" between \"0\" and backspace, unfortunately. the key to the left of \"q\" is tab instead of delete. the rightmost big key on the left thumb is cmd (lgui) instead of backspace. other changes the button to the left of \"a\" is ctrl/esc instead of backspace. this is actually how i have the keyboard on my macbook set up to be, since it's loads more convenient than a  caps lock key. this is the ctrl key i find myself using most. the key to the right of \"5\" and the key to left of \"6\" are \"[\" and \"]\", respectively, instead of left and right. there is a more convenient set of left and right already present. truth be told, i don't really use these keys, as they are a stretch to reach. the toggle l1 keys have been replaced by the otherwise displaced \"-\" and \"=\". they are laid out, left-to-right, in the same order as on the mac keyboard. honestly, they are not terribly conveniently placed, and their placement might change in a later version. i found that i did not toggle l1 frequently at all, and found using the momentary keys to access l1 to fit my workflow better. the \"~\"/l1 key in the bottom-left is now just momentary l1. the \"~\" key was moved to the top-left as mentioned before, and i like to keep my multi-use keys to a minimum due to the latency for them to switch from \"press\" to \"hold.\" the home and end buttons have been shifted up on the left thumb, and shift inserted below them. this makes doing shift-5 and other such combinations less painful. the page up and page down buttons have been shifted up on the right thumb, and alt was moved from above them to below them. i use alt more than page up or page down (mostly in terminal applications), and thought that it deserved a more accessible location. i'm always open to feedback and/or suggestions! ", "commit_messages": " version 1.0.0  change lower-left control to momentary l1  there's so many control keys in this keymap, one needed to go. so, i changed  the lower-left control key to be a momentary l1, just like the same key on the  right side. ", "linked_issue_titles": "", "title": "add j3rn's mac-centric ergodox ez keymap"}
{"description": " fixes #7058 allows classes to access private and protected member of parent (enclosed) classes. ", "commit_messages": " allow private and protected class members to be accessible in nested classes  added tests  accept baselines ", "linked_issue_titles": " private/protected class members not accessible in nested classes ", "title": "nested private and protected class members"}
{"description": " let's not release stuff with known java incompatiblities, e.g. we know will break in java 9, and could technically even break going forwards in java 8, e.g. calling  this is a backport of all bugfixes so that 2.1 won't have compatibility issues. ", "commit_messages": " add java 9 support for bootclasspath to jvminfo (it throws uoe otherwise which is not properly handled)  update to forbidden-apis 2.0  disable mockfilesystems in 2.1, as they do broken reflection incompatible with java 9  fix mvn verify under jigsaw  get our stats back by reflecting mxbeans correctly  backport removal of illegal test  remove unnecessary permissions that are not possible in java 9  make logger final so its not detected as a static leak  suppressfilesystems in this straggler ", "linked_issue_titles": "", "title": "fix mvn verify on jigsaw with 2.1"}
{"description": " this pr allows one to build the user documentation with python 3 and sphinx>= 2.4.0. it also removes several warnings. remove autogenerated js doc (backport from master) forward-port-of: #47027 forward-port-of: #46069 ", "commit_messages": " [fix] doc: cherry pick of e4b75149f7c  remove js apidoc  breaks doc-building all the time, more advanced es6 features are not  supported by the js parsing library  x-original-commit: 9ac8ac990ebac41a45dee804e86fbfe56fccd02d  [fix] doc: remove warning block quote ends without a blank line  before this commit, the following warnings were displayed:  odoo/doc/reference/orm.rst:714: warning: block quote ends without a blank line; unexpected unindent.  odoo/doc/reference/orm.rst:721: warning: block quote ends without a blank line; unexpected unindent.  odoo/doc/reference/orm.rst:728: warning: block quote ends without a blank line; unexpected unindent.  odoo/doc/reference/orm.rst:735: warning: block quote ends without a blank line; unexpected unindent.  x-original-commit: 3aa41a5131bbc08d7390f207ca84d7a6994d29cd ", "linked_issue_titles": "", "title": "compatible python 3 and sphinx 2.4"}
{"description": " currently, using st.empty() (or st.cache/st.spinner, which use st.empty internally) will break static sharing because of recent changes to the frontend. specifically, the frontend now requires that delta ids start from 0 and increment by 1 for each new delta in each container. because we remove st.empty deltas from serialized reports, we break the implicit \"sequential delta id\" rule, and the frontend crashes when trying to view a shared report that used st.empty. this example app will demonstrate the breakage: run the app, share it, and try to view the shared report: import streamlit as st st.empty() st.write(\"i'm not shareable!\") this pr does a few things. the most basic and important thing is: st.emptys are no longer stripped from shared reports. (fixes #827, which is the original motivation here.) to facilitate that, it also does a few other things: global.sharingmode=\"file\" is now a supported config option. if you use this sharing mode, your protobufs will be serialized to frontend/public/reports, which allows them to be served by the dev server. this is obviously not intended for users; while it's not harmful if they use it, config.py now emits a warning upon config loading if this option is set and global.developmentmode is not. (this means that testing changes to static sharing no longer requires the \"make build -> run app -> share to s3 -> try to debug minified javascript\" routine; you can do it all from the devserver.) the frontend staticconnection code has been refactored and simplified a bit to account for the new sharing mode. there's now a test for reportsession.handle_save_request that ensures the serialized data is what we expect. i've not added frontend/public/reports to the .gitignore, which means that if you use global.sharingmode=\"file\", you'll end up with a bunch of uncommitted serialized report data in your frontend folder. you should remove these before doing a make build so that they don't end up in a pypi wheel file or anything. (make clean will remove them.) next steps the \"strip st.empty deltas out of shared reports\" functionality was in streamlit to prevent serialization of the st.empty's that get auto-created by st.cache. since we'd still like to prevent cache-induced serialization spam, the next step is to change st.spinner (which st.cache uses, and which is what actually creates the additional empties) to be more clever, and probably not involve delta-creation at all. ", "commit_messages": " remove unused variable  remove unused import  re-enable global.sharingmode = \"file\"  save local report files to frontend/public, so we can fetch them at the expected location  unify s3 report object fetching  simplify s3 object fetching  config: show a warning if the user has \"sharingmode=file\" and they aren't in developmentmode  do *not* strip out empty delta messages when serializing a report  this breaks report sharing, because the frontend expects delta ids to be sequential  don't calculate num_deltas; it's not used anywhere  remove unused imports  fix report_test.py  reprotsession serialization test ", "linked_issue_titles": " snapshot crashes when using @st.cache ", "title": "fix st.empty breakage inside shared reports"}
{"description": " fix #5155 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " wip: add nacosnamingmaintainservicetest  wip  add  nacosnamingservicetest ", "linked_issue_titles": "", "title": "add unit tests for package com.alibaba.nacos.client.naming.remote in nacos 2.0"}
{"description": " unchanged backport of #17188. ", "commit_messages": " [flink-23864][docs] add flink-connector-pulsar module to flink-docs, auto generate the config document.  [flink-23864][connector/pulsar] release pulsar message if user enable poolmessage option.  [flink-23864][connector/pulsar] remove pulsar_auto_update_partitions option.  [flink-23864][docs] add pulsar connector document (chinese & english). ", "linked_issue_titles": "", "title": "add pulsar connector document [1.14]"}
{"description": " follow up of  #455 pull request. ", "commit_messages": " alow to disable a downloader handler just like any other component.  tests for loading download handlers  fix minor typo in downloaderhandlers comment  doc for disabling download handler  minor fixes in loadtestcase in test_downloader_handlers  * same __init__ parameters in both download handlers's mocks  * additional assertion in test_disabled_handler ", "linked_issue_titles": "", "title": "allow to disable a downloader handler just like any other component"}
{"description": " d3.geo.stream incorrectly treated geometrycollection as a higher-level object type, rather than a geometry type as specified in the geojson spec. this caused bounds calculations to be incorrect on feature/featurecollection objects that contained geometrycollection geometries. patch adds a test for this case and corrects the handling of geometrycollection in d3.geo.stream (and therefore d3.geo.bounds). ", "commit_messages": " test for problematic nesting case  geometrycollection is a *geometry*, not objecttype (c.f. ", "linked_issue_titles": "", "title": "in d3v3, geo.bounds stopped working for geometrycollection within feature"}
{"description": " conflicts: luck of read error handling in 5.0 branch. ", "commit_messages": " implement module api for aux data in rdb  other changes:  * fix memory leak in error handling of rdb loading of type obj_module  (cherry picked from commit 3b6aeea44cf8bdc64214a5f145da55453722a9a2)  fix to module aux data rdb format for backwards compatibility with old check-rdb  when implementing the code that saves and loads these aux fields we used rdb  format that was added for that in redis 5.0, but then we added the 'when' field  which meant that the old redis-check-rdb won't be able to skip these.  this fix adds an opcode as if that 'when' is part of the module data.  (cherry picked from commit 3bfcae247a1c51788940bd4d2f32751ead451e42) ", "linked_issue_titles": "", "title": "backport module rdb aux data into 5.0"}
{"description": " addresses #20308 this pr ensures radiusneighborsclassifier is compatible with numpydoc. remove radiusneighborsclassifier from docstring_ignore_list. remove deprecate unused parameter kwargs from radiusneighborsclassifier. verify that all tests are passing. add test to check that the futurewarning is correctly raised. just to reiterate, note that the parameter kwargs was removed deprecated from the __init__ method of radiusneighborsclassifier since it was not used. ", "commit_messages": " remove radiusneighborsclassifier from docstring_ignore_list.  fix numpydocs from radiusneighborsclassifier.  remove unused parameter  from radiusneighborsclassifier. ", "linked_issue_titles": "", "title": "doc ensures that radiusneighborsclassifier passes numpydoc validation"}
{"description": " this fixes golint failures under test/e2e/upgrades/.... ref: #68026 does this pr introduce a user-facing change?: ", "commit_messages": " fix golint failures for test/e2e/upgrades/apps  fix golint failures for test/e2e/upgrades/storage  fix golint failures for test/e2e/upgrades ", "linked_issue_titles": "", "title": "fix golint failures for e2e/upgrades/..."}
{"description": " at the moment, the --use-preload-cache option stores everything under one entry in indexeddb which causes issues for preloads >133169152 bytes(?), this pr adds support for chunking the cache into separate entries. (sidenote: i'm not entirely sure i made these commits correctly, let me know if i messed it up) ", "commit_messages": " add support for chunked persistence  consistent use of .md for markdown files (#7300)  cleanup rst files. nfc. (#7301)  - convert tabs to spaces.  - remove trailing whitespace  cleanup create_runtime_funcs. nfc. (#7272)  webidl binder: define properties with js accessors (#7298)  currently c++ class and struct properties are defined in javascript bindings with get_foo and set_foo accessor methods. this pr adds support for directly accessing the properties using native js accessors. for example:  // current way  myobject.set_foo(1);  console.log(myobject.get_foo());  // after this pr:  myobject.foo = 1;  console.log(myobject.foo);  this is more idiomatic javascript, and means that the bindings match the idl correctly. i have left the existing getters and setters in place, so this is be backward-compatible.  explain what happens if error_on_undefined_symbols is set to 0 (#7287) [ci skip]  comment on memory growth [ci skip] (#7297)  add number of wasm funcs to other.test_metadce (#7307)  * but ignore # of functions in main module, it changes a lot  support input from the global module object in modularize_instance (#7293)  fixes #7101  background: normally, if you define module and properties on it, like prerun, then we notice that and use them. in modularize, however, the user creates the instances of the module, and can pass module or something else as desired (if we passed module there it might be surprising). however, in modularize_instance mode we are more like the normal mode in that there is a single instance, started automatically, and defining things on module is how the user can influence it.  add docs for upgrading bundled libs [ci skip] (#7286)  fix export_all with wasm backend (#7310)  the semantics of export_all are not that we should avoid doing  any gc but rather that any symbols that survive gc should be  exported.  report missing exported_functions by default (#7311)  cleaner handling of clusure compiler errors (#7313)  previously you would see an emscripten internal backtrace  if closure compiler failed.  sadly we have a lot of existing warnings so we don't display  the process stderr unless we the subprcess returns non-zero.  i guess we should try to address the closure warnings, at least  the ones in emscripten proper.  clean up file_packager ", "linked_issue_titles": "", "title": "add support for caching large preloads"}
{"description": " please answer these questions before submitting a pull request why submit this pull request? bug fix new feature provided improve performance related issues bug fix bug description. how to fix? new feature or improvement describe the details and related test reports. hi~ now we use spring @scheduled to execute scheduled tasks, but it seems to be not supported. so i add the client side support.  please see if it makes sense. ", "commit_messages": " pull request  support spring @scheduled annotation ", "linked_issue_titles": "", "title": "add support for spring @scheduled"}
{"description": " cherry pick e37dfda 2d891d9 247899a ", "commit_messages": " [v1.x] update armpl version (#20332)  * update armpl version  * enable apl  * downgrade openblas to 3.13  * update dockerfile  [v1.x] use armpl as blas for mxnet aarch64 wheels (#20342)  * use armpl as blas for mxnet  * link libgfortran  * fix cpath  * rectify if condition  * update armpl macro  * remove lapacke.h as duplicate of cblas.h  specify arm cd armpl include path (#20364)  workaround ", "linked_issue_titles": "", "title": "cherry-pick armpl changes from v1.x"}
{"description": " i added the right row export to display the discussions list 2021-04-14.18-02-36.mp4 fixes #21547 ", "commit_messages": " updating the code  updating the code  updating the fork  update main branch  updating the branch  update fork  upating the fork  correcting the discussions problem ", "linked_issue_titles": " the application crashes when you try to open the discussions list ", "title": "fix the bugs opening discussions"}
{"description": " made some small adjustements that make the nel functionality resemble the code for the other pipes more closely. this will be followed by another pr which has the (updated) documentation for all this functionality. goldparse gold.links is now a dictionary with (ent.start_char, ent.end_char) keys and the values being dicts with kb_id:value entries, representing the kb ids mapped to either 1.0 or 0.0, indicating positive and negative examples respectively. this is similar to the gold.cats field for text classification. for training, all the kb_id: value combinations are used, including the negative cases for testing (accuracy measurement), only the positive cases are checked entitylinker gold.links now corresponds 1-to-1 to doc.ents which allows a more proper chaining of entity_linker.predict() and entity_linker.get_loss() functions etc (just like for the other pipes) entitylinker also now returns tensors as part of its predict() output default context_width set to 128 kb new methods in kb: get_vector and get_prior_prob to easily access information about entities & aliases, + unit tests in kb.pyx, renamed entity prob to freq (entity frequency in a corpus) to avoid confusion with prior_prob (which refers to the probability of an alias being linked to an entity) errors.e144 when entity_width or context_width could not be found when building the nel model created kb directory if it didn't exist to address issue #4000 misc black processing caused a lot of edits in the files small fix in tokenizer.pyx documentation enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " tokenizer doc fix  proper error for missing cfg arguments  set default context width  small fix  code cleanup  get vector functionality + unit test  fixes in kb and gold  filter training data beforehand (+black formatting)  use original gold object in get_loss function  have gold.links correspond exactly to doc.ents  output tensors as part of predict  formatting  rename entity frequency  fix for issue #4000  test corner cases ", "linked_issue_titles": "", "title": "api changes for entity linking functionality"}
{"description": " fixes a typeerror when deleting a task result with s3 backend. this links to #5721, which already solved this problem for .get() and .set(), but not for .delete() ", "commit_messages": " convert key from bytes to str  add unit test for s3 delete of key with type bytes ", "linked_issue_titles": "", "title": "fix type error in s3 backend"}
{"description": " currently, selectabletext always stays alive, which can create two problems observed in #91509: performance can suffer in long lists of selectabletexts. selectabletext can cause a primaryscrollcontroller to stay connected unexpectedly. i've changed selectabletext's wantkeepalive to match editabletext, so it only stays alive if it's focused: flutter/packages/flutter/lib/src/widgets/editable_text.dart line 1567 b5e1ebd bool get wantkeepalive => widget.focusnode.hasfocus; @chunhtai do you know of any reason we shouldn't do that? i've also added some docs to try to warn developers about the second problem a bit.  @piinks is there anywhere else i should document that? fixes #91509 ", "commit_messages": " selectabletext will only keepalive when it has selection, and docs improvement  test that selection is preserved  actually, let's do this based on focus like editabletext ", "linked_issue_titles": " nestedscrollview + tabbar + selectabletext: unexpected behaviour when scrolling ", "title": "selectabletext keep alive only when it has selection"}
{"description": " this pr fixes a number of alerts reported by lgtm.com (@lgtmhq). there is a good number of other alerts well worth looking at here:  you can set up automated pull request reviews on lgtm.com as well! ", "commit_messages": " fix lgtm.com alert: can't compare bool to string (operator precedence)  details:    fix lgtm.com alerts: nullness check using !== operator  details:       ", "linked_issue_titles": "", "title": "fix lgtm.com alerts: equality tests"}
{"description": " button \"enable auto-completion in data filter text\" in preferences/dbeaver/editors/dataeditor/presentation adding org.jkiss.dbeaver.ui.editors.data in german, russian localized ", "commit_messages": " #8461 new button in preferences/dbeaver/editors/dataeditor/presentation adding with auto-complition in data filter text  #8461 resultsetmessages localized in org.jkiss.dbeaver.ui.editors.data ", "linked_issue_titles": "", "title": "#8461 button enable auto-complete in preferences/data editor adding"}
{"description": " revert 8302b5a and a temporary fix for runtime env blocking and that also prevent workers from starting up too fast (before #17154 can be solved). closes #16226 closes #16537 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " re-revert  surgical fix ", "linked_issue_titles": " [runtime_env] installing a second environment seems to make workers in a first environment unschedulable  unit & integration tests for runtime_env scheduler blocking ", "title": "fix runtime env and dispatch queue take 2"}
{"description": " see commits comments for details :) ", "commit_messages": " fix and improvements to the backend documentation  improved preamble of the backend.md template:  - fixed a typo  - added few notes that makes the documentation more self explanatory  - made all code examples running by copy&paste  aligned the format of the  backend() function  fixed docstring of set_image_dim_ordering() function  fixed a typo in %userprofile% env name for window users ", "linked_issue_titles": "", "title": "improvements in the documentation of backend"}
{"description": " please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo: coverage service link (codecov, coveralls, gocover etc.) very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. ", "commit_messages": " fix typo in readme.md  fixes #3204  fix typo in readme.md  test  delete main.yml  modify workflow ", "linked_issue_titles": "", "title": "fix test stale repositories workflow"}
{"description": " no-issue this means that we no longer make requests to the stripe api for every request ", "commit_messages": " installed @tryghost/members-ssr@0.4.0  no-issue  this now supports caching of the data returned by the members-api  renamed cookies set by members-ssr  no-issue  as discussed with @erisds i have prefixed these cookies with ghost ", "linked_issue_titles": "", "title": "cached members-api data in members-ssr cookie"}
{"description": " since envoy uses a time system that allows injecting mock timestamps, there is no need to support timestamp parsing in the production code. in the test code, this is cleanly abstracted out as a test-only utility function. risk level: low testing: ran affected tests docs changes: n/a release notes: n/a ", "commit_messages": " use test utility to parse timestamps  forbid the use of std::get_time  there is an existing test utility for parsing timestamps according to a  format string, and non-test code should be using the injectable time  system support instead of parsing real timestamps. ", "linked_issue_titles": "", "title": "remove timestamp parsing with std::get_time"}
{"description": " this continues the port of the java comparison tool to python. changes to the blockstore and a small change in main.cpp are in separate commits. this includes and runs both the \"inexpensive\" and \"barely expensive\" tests. the \"barely expensive\" test (which consists of a few re-orgs) take a minute or two on my machine. java test is here: ", "commit_messages": " tests: rework blockstore to avoid re-serialization.  continuing port of java comptool  catch exceptions from non-canonical encoding and print only to log ", "linked_issue_titles": "", "title": "continuing port of java comparison tool"}
{"description": " fixes #2340 in the future, we should use chunkhash of each file for better caching. for now, we can't do this with our webpack/babel setup. (specially with ssr) we can do that for all assets in the future. ", "commit_messages": " add buildid to the path of dynamic chunks.  add buildid to the webpack devserver's path.  add static export support.  update with-dynamic-import example.  remove async-reactor since it's buggy.  add static export support. ", "linked_issue_titles": "", "title": "use buildid in chunk urls as well"}
{"description": " linear_assignment can now be imported from scipy #13464 removed the use of sklearn.utils.linear_assignment_ and _hungarian and replaced it with scipy.optimize.linear_sum_assignment tweaked test case for _hungarian so that it works with scipy.optimize.linear_sum_assignment more info can be found here #13464 ", "commit_messages": " merge fork  merge fork  merge fork  importing linear assignment from scipy ", "linked_issue_titles": "", "title": "mnt import linear assignment from scipy"}
{"description": " fixes #29337. mksnapshot.zip for macos arm64 (apple silicon) was missing two needed files: mksnapshot_args and clang_x64_v8_arm64/gen/v8/embedded.s.  this pr adds those files to mksnapshot.zip for macos arm64 pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed using custom v8 snapshots on apple silicon. ", "commit_messages": " build: include mksnapshot args in arm64 mksnapshot.zip  get gen/v8/embedded.s from proper location ", "linked_issue_titles": " [bug]: using custom v8 snapshots on apple silicon does not work ", "title": "ensure that mksnapshot for apple silicon has all of the needed files for snapshot generation"}
{"description": " this should finally finish addressing #381. note i haven't actually tested the example applications yet, so i may have introduced bugs. ", "commit_messages": " test examples for pep8 compliance.  make rl_pong example pep8 compliant.  make policy gradient example pep8 compliant.  make lbfgs example pep8 compliant.  make hyperopt example pep8 compliant.  make a3c example pep8 compliant.  make evolution strategies example pep8 compliant.  make resnet example pep8 compliant. ", "linked_issue_titles": "", "title": "make example applications pep8 compliant."}
{"description": " loaders are applied in the wrong order when using inline match resource, as shown in #9053. the resulting behaviour does not match the expected behaviour as described by the documentation. i'm attempting to write a loader which depends on matchresource working as documented, and the bug has been open for a while with no progress. a bugfix. yes. unsure. all tests were run and passing locally, but not sure if fix as written is appropriate, so opening a pr for review/guidance. hopefully none, as this makes matchresource behave as documented, however see above. ", "commit_messages": " add test case for #9053  fix loader ordering ", "linked_issue_titles": "", "title": "wrong loaders order when using inline match resource"}
{"description": " requested in #5242. for example i use bestvideo[height<=?1080][width<=?1920][ext!=?webm]/best[height<=?1080][width<=?1920],bestaudio, which can be written now as (bestvideo[ext!=?webm]/best)[height<=?1080][width<=?1920],bestaudio. since i thought that using regexes would be hard, i decided to use tokenize.tokenize to split the spec in strings and operators (it also checks if there are missing brackets or parenthesis). i admit that the implementation is a bit ugly, so we may want to rethink it or clean it (maybe moving it to utils.py), but it works. the filters (everything inside []) is still processed with the same regexes, because it's simpler and i haven't thought of an alternative implementation. @haasn your string (bestvideo[tbr<13000][height>720]/bestvideo[tbr<13000][fps>30])+(bestaudio[ext=webm]/bestaudio) seems to be parsed correctly, but i'd like to verify it works as expected. ", "commit_messages": " [youtubedl] rework how the format spec is processed  the spec string is processed using 'tokenize.tokenize' to split it in words and operators, the filters are still processed using regular expressions.  this should make easier to allow grouping operators with parens.  [youtubedl] format spec: treat 'all' like a normal specifier  so you can use filters with it, for example 'all[width>=400][width<=600]'.  [youtubedl] format spec: allow grouping specifiers with parentheses ", "linked_issue_titles": "", "title": "allow grouping specifiers in -f"}
{"description": " please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues #3777 bug fix bug description. how to fix? new feature or improvement describe the details and related test reports. ", "commit_messages": " shardingsphere 4.x rc3 test  shardingsphere 4.x rc3 test  shardingsphere 4.x rc3 test  shardingsphere 4.x rc3 plugin  shardingsphere 4.x rc3 plugin  # conflicts:  #\t.github/workflows/plugins-test.yaml  shardingsphere 4.x rc3 plugin ", "linked_issue_titles": "", "title": "provide plugin for shardingsphere 4.0.0-rc3"}
{"description": " will need to open a pr for getsentry but starting in sentry for discussion the default we're currently using. browsers like baidu, op_mini, kaios are telling babel preset to bring in all kinds of core-js functions we don't need. npx browserslist --env=\"production\" and_chr 89 and_ff 86 and_qq 10.4 and_uc 12.12 android 89 baidu 7.12 chrome 89 chrome 88 chrome 87 edge 89 edge 88 firefox 86 firefox 85 firefox 78 ie 11 ios_saf 14.0-14.5 ios_saf 13.4-13.7 kaios 2.5 op_mini all op_mob 62 opera 73 opera 72 safari 14 safari 13.1 samsung 13.0 samsung 12.0 this pr chrome 91 chrome 90 chrome 89 chrome 88 chrome 87 chrome 86 chrome 85 chrome 84 chrome 83 chrome 81 edge 91 edge 90 firefox 90 firefox 89 firefox 88 firefox 87 firefox 86 firefox 85 firefox 84 firefox 83 firefox 82 firefox 81 firefox 78 ios_saf 14.5-14.7 ios_saf 14.0-14.4 ios_saf 13.4-13.7 ios_saf 13.3 ios_saf 13.2 ios_saf 13.0-13.1 ios_saf 12.2-12.4 ios_saf 12.0-12.1 op_mob 62 safari 14.1 safari 14 safari 13.1 safari 13 from looking at what bundle analyzer says, this change would take us from 215 kb to 91 kb gzipped of core-js ", "commit_messages": " feat(ui): add browserslist  declare supported versions instead ", "linked_issue_titles": "", "title": "setup browserslist, reduce core-js use"}
{"description": " this is in the same spirit as #2352. it inserts the engine as an indirection for creating and starting a container, with minimal disruption on the implementation and code structure. ", "commit_messages": " separate a) initialization of the http api and b) actually serving the api into 2 distinct jobs  engine: 'start' starts the specified container  httpapi: don't create a pidfile if it isn't set in the configuration  engine: fix a bug which caused handlers to be shared between multiple engine instances  engine: don't export private testing utilities  engine: improved logging and identification of jobs  engine: optional environment variable 'logging' in 'serveapi'  hack: simplify the creation of test directories  engine: fix a bug when encoding a job environment to json  better error reporting in engine logs and unit tests  fix main()  engine: 'create' creates a container and prints its id on stdout  remove debug messages  conflicts:  engine/engine.go  engine/job.go  server.go  utils_test.go ", "linked_issue_titles": "", "title": "expand the engine api with 'create' and 'start' jobs edit"}
{"description": " my take on ben's pr. does this look more reasonable? / ", "commit_messages": " propose unified rev-parse api  implement unified git_revparse  deprecate git_revparse_single and _rangelike  add rev-list example to makefiles  reintroduce git_revparse_single.  redeploy git_revparse_single.  change git_revparse to output git_object pointers  this will probably prevent many lookup/free  operations in calling code.  clean up example code.  clean up minor details  is this crazy? ", "linked_issue_titles": "", "title": "unified rev-parse, with a revision object"}
{"description": " fixes #454 fixes #701 ", "commit_messages": " add webdialoghelper  implement enumeratedirectory  override => override in atom_browser_client.h  implement runfilechooser  upgrade brightray to handle localized string  mac: add color chooser dialog  aura: add color chooser dialog  win: add color chooser dialog ", "linked_issue_titles": " clicking on file input elements doesn't show file dialog  support for input type color ", "title": "implement file dialog and color chooser for <input> tag"}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. provide a url to documentation or source code which provides context for the suggested changes: release v.1.1.7 and release v1.1.8 increase the version number in the header if appropriate. i looked through the releases since 1.1.0 and it now seems to cover the new api. ", "commit_messages": " new methods  angular-google-analytics: fix typo in extended interface ", "linked_issue_titles": "", "title": "update api since release 1.1.0"}
{"description": " this work does the following: removes the banner add for typeform-based font awesome survey reinstates all other fonticons/black tie banner ads changes references in code and content from \"fonticons\" to \"fort awesome\" updates color combinations for fort awesome (using fa's off-black) and black tie banner ads note: the survey page ( reviewers ui, fed, and content - @davegandy ", "commit_messages": " removing survey promotion to homepage  updating banner ads visually and name-wise to reference fort awesome  adjusting color settings for black tie banner ad ", "linked_issue_titles": "", "title": "remove font awesome feedback survey"}
{"description": " we've split docs.ansible.com/ansible/ and docs.ansible.com/ansible-core, but they still look identical. change the css for the core documentation to make it obvious which site you are looking at. fixes #73202. note: while the pr is wip, the .css file will remain maxified, in case we need to change it more. so far, this pr replaces the ansible \"lake\" (teal) color with ansible black. we'll minify the css before merging. docs.ansible.com/ansible-core for local builds: make coredocs builds the new /ansible-core/ colors make webdocs builds the familiar /ansible/ colors ", "commit_messages": " updates core conf to use separate ccs file  adds unminified core ccs file  replaces lake color with ansible black ", "linked_issue_titles": " differentiate ansible vs ansible-core docsites via theme/color changes ", "title": "change look and feel of the ansible-core docs"}
{"description": " addresses #16965 by showing eeprom errors on the lcd at startup if auto init is not enabled to automatically handle them. some handling for service messages to still function. i have not validated this and tested it here, ill leave that to the requester. ", "commit_messages": " lcd alert eeprom error  add flag to reset status so it only triggers if there is a service state to show ", "linked_issue_titles": "", "title": "set lcd status for eeprom errors"}
{"description": " fixes: #3656 (comment) component name /collectors/python.d.plugin/python_modules i tested, with the changes httpcheck module works with ", "commit_messages": " python.d urlservice: ignore decode errors during decoding bytes (py3)  python.d logger: ignore encoding errors in unicode ", "linked_issue_titles": " httpcheck do not accept urls that do not end with com ", "title": "urlservice bytes decode, logger unicode encoding fix"}
{"description": " floating point from/to string conversion is a very complex topic. i just added the most basic implementation i could think of which is slightly different from the stuff in <ak/printfimplementation.h>. ", "commit_messages": " ak: remove out() and warn().  ak: rename new_out to out and new_warn to warn.  ak: add formatters for floating point numbers. ", "linked_issue_titles": "", "title": "rename new_out/new_warn to out/warn; add formatter for floating point numbers."}
{"description": " this code is my proposal for closing #469. magic numbers are removed from both mnist and cifar10. cifar10 also features a reasonably intuitive approach to handling multiple layers with various pooling / filter sizes. i've tried following the general convention for variables and comments as set forth by other examples. note: it'd be a good idea to add a subsample / stride example in the near future as there are no tests / examples of that within keras and it's non-trivial but that's likely a separate issue. i've still not gotten subsampling to work in my code for the right whale recognition kaggle competition, where the high image resolution almost demands it. ", "commit_messages": " remove magic numbers from mnist_cnn.py (re: #469)  remove magic numbers from cifar10_cnn.py (fixes #469) ", "linked_issue_titles": "", "title": "removing magic numbers from mnist and cifar10"}
{"description": " bpo-30320: test_eintr now uses pthread_sigmask() (#1523) test_eintr: fix resourcewarning warnings test_eintr: remove unused import bpo-25277: add a watchdog to test_eintr ", "commit_messages": " bpo-30320: test_eintr now uses pthread_sigmask() (#1523)  rewrite sigwaitinfo() and sigtimedwait() unit tests for eintr using  pthread_sigmask() to fix a race condition between the child and the  parent process.  remove the pipe which was used as a weak workaround against the race  condition.  sigtimedwait() is now tested with a child process sending a signal  instead of testing the timeout feature which is more unstable  (especially regarding to clock resolution depending on the platform).  (cherry picked from commit 211a392cc15f9a7b1b8ce65d8f6c9f8237d1b77f)  test_eintr: fix resourcewarning warnings  (cherry picked from commit c50cccfcc3b3a9ef3fe7a78b7e7271930dc24aee)  test_eintr: remove unused import  bpo-25277: add a watchdog to test_eintr  set a timeout of 10 minutes in test_eintr using faulthandler. ", "linked_issue_titles": "", "title": "backport test_eintr enhancements from master to 3.5"}
{"description": " fix some assertions, hack out some others (they need more atl work). core-17505 ", "commit_messages": " [explorer][shell32] add workaround for buggy window creation  [netshell] release a pointer instead of leaking it  [shellmenu] only clear a toolbar when it is created  [shellmenu] properly delegate to ccontainedwindow ", "linked_issue_titles": "", "title": "fix some assertions now that they are enabled"}
{"description": " what this pr does / why we need it: builds equivalents of the various kubernetes release tarballs, solely using bazel. for example, you can now do $ make bazel-release $ hack/e2e.go -v -up -test -down special notes for your reviewer: this is currently dependent on ixdy/bazel@3b29803, which i have yet to turn into a pull request, since i'm still trying to figure out if this is the best approach. basically, the issue comes up with the way we generate the various server docker image tarfiles and load them on nodes: we md5sum the binary being encapsulated (e.g. kube-proxy) and save that to $binary.docker_tag in the server tarball we then build the docker image and tag using that md5sum (e.g. gcr.io/google_containers/kube-proxy:$md5sum) we docker save this image, which embeds the full tag in the $binary.tar file. on cluster startup, we docker load these tarballs, which are loaded with the tag that we'd created at build time. the nodes then use the $binary.docker_tag file to find the right image. with the current bazel docker_build rule, the tag isn't saved in the docker image tar, so the node is unable to find the image after docker loading it. my changes to the rule save the tag in the docker image tar, though i don't know if there are subtle issues with it. (maybe we want to only tag when --stamp is given?) also, the docker images produced by bazel have the timestamp set to the unix epoch, which is not great for debugging. might be another thing to change with a --stamp. long story short, we probably need to follow up with bazel folks on the best way to solve this problem. release note: ", "commit_messages": " use custom io_bazel repo for docker_build changes  reorder package_kube_manifests_tarball a bit to make it more readable  refactor docker bazel rules and tag docker images  add genrule to produce e2e_node.test binary artifact ", "linked_issue_titles": "", "title": "build release tars using bazel"}
{"description": " fix #10735 this pr did the following things: add lod_tensor.py utility module providing functions for ease of creating lodtensor in book examples. add test code for lod_tensor.py as an example, modify test_word2vec.py to show how to use the lod_tensor.py module in book examples. ", "commit_messages": " add lod_tensor utility python module  add lod_tensor test code  add more lod tensor tests  modify word2vec example code using new api ", "linked_issue_titles": " make the creation of lodtensor more user friendly in book examples ", "title": "add lod_tensor.py for ease of creating lod tensor in book examples"}
{"description": " texture copies with \"incompatible\" formats (i.e. color <-> depth) were left unimplemented on opengl after tcr. this pr aims to implement format conversions by repurposing the existing method used for bgr <-> rgb texture format conversion. this is expected to fix a number of issues. for example: luigi's mansion 3 shadow trail lm3_bug.mp4 lm3_fix.mp4 bayonetta 2 cutscene dof bayo_bug.mp4 bayo_fix.mp4 closes #6845 closes #4220 ", "commit_messages": " gl_texture_cache: rename bgrcopypass to formatconversionpass  gl_texture_cache: make formatconversionpass more generic  this allows the usage of the formatconversionpass to be applied to more than the previously used bgr conversion scenarios.  texture_cache: use pixel format conversion when supported by the runtime ", "linked_issue_titles": " broken cutscene rendering in bayonetta 2  luigi's mansion, shadow stretching on open gl glsl, glasm ", "title": "implement pixel format conversions for copies"}
{"description": " ios_command not failing in case of receiving 'command authorization failed' in tacacs environments. adding that regex to terminal plugin makes the task to fail correctly. fixes #31575 terminal/ios ", "commit_messages": " add 'command authorization failed' to stderr regex list  add missing comma  remove superfluous comma ", "linked_issue_titles": " ios_config incorrectly claims success when commands fail ", "title": "command authorization failed ios regex"}
{"description": " instead of specialized locking and sleeping blocking strategies, allow using any waitstrategy as a fallback blocking strategy. make sleepingwaitstrategy configurable to allow for sleeping immediately without any retries, as wanted by phasedbackoffwaitstrategy. small typo fix ", "commit_messages": " remove misplaced millis suffix  arbitrary phasedbackoffwait fallback strategy  * instead of specialized locking and sleeping  blocking strategies, allow using any waitstrategy  as a fallback blocking strategy.  * make sleepingwaitstrategy configurable to allow  for sleeping immediately without any retries, as  wanted by phasedbackoffwaitstrategy. ", "linked_issue_titles": "", "title": "arbitrary phased backoff wait fallback + typo fix"}
{"description": " map height changed from 100vh to 100% in #5772, but now map doesn't appear at all. so i set body and html height to 100% in tutorial_frame.html layout. so map with height 100% should look good now. ", "commit_messages": " fix map height in extending example  add html and body styles to tutorial_frame  move js styles to css  remove unnecessary styles from mobile/example.md ", "linked_issue_titles": "", "title": "fix map styles in \"extending leaflet\" example"}
{"description": " can we add me in the owners file? the chart-pr from me was just approved (see #10922 ) but i missed creating an owners file directly. dco signed ", "commit_messages": " add nextcloud chart  insert suggestions from reviews in #5180  disable ingress per default  fix nextcloud e2e tests  [nextcloud] add owners file for further contribution ", "linked_issue_titles": "", "title": "nextcloud chart add owners for further contribution"}
{"description": " this add support for the emulated dogm through spi: spi_graphical_tft. add xpt2046 hw spi version too. recent mks boards have only spi for the tft. currently, the users can just use their lvgl ui. but the lvgl ui isn't complete. mks robin nano v2 and mks gen l 2.0 this pr add an option any other users that have only spi tft. may work with any spi tft. the default marlin default text menu is by far the most complete ui. a lot of users do prefer it. supports 180 screen rotation. text ui will never die!! ", "commit_messages": " hw spi for touch buttons  spi_graphical_tft emulated dogm using spi  config spi_graphical_tft  either ", "linked_issue_titles": "", "title": "spi emulated dogm (like fsmc_graphical_tft, but spi)"}
{"description": " fixes #53612 do not gate the value setting behind the repeat check. this was causing samsung keyboards to freeze/crash when it was re-shown after dismissal. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. ", "commit_messages": " change repeat filter logic  fix logic for tests  test  comments + cleanup ", "linked_issue_titles": " samsung keyboard crash/freeze when dismissing and reopening keyboard ", "title": "un-gate value setting in formatter repeat check logic"}
{"description": " this backports #29190 and #29156. there are slight changes due to the integration tests because of incompatibilities in the test framework between 1.13 and master (see #29210 (comment)). @vieux @diogomonica @cyli @tiborvass ", "commit_messages": " registry: remove reference.go  this removes some very old vestigial code that really should have been  removed during the content addressability transition. it implements  something called \"reference\" but it behaves differently from the actual  reference package. this was only used by client-side content trust code,  and is relatively easy to extricate.  (cherry picked from commit d91ed88365317cd86555e2f54bffa30ec6590dfe)  cli: split out getnotaryrepository and associated functions  split these into cli/trust so that other commands can make use of them.  (cherry picked from commit 4b8c79f25ee00ca5dfe22271c166938009bda976)  cli: pin image to digest using content trust  implement notary-based digest lookup in the client when  docker_content_trust=1.  (cherry picked from commit d4d6f8c0d0c6cd0ba6dc96ab7a9ed07e1e766074) ", "linked_issue_titles": "", "title": "backport \"content trust for swarm services\""}
{"description": " follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " init  semver bump  fix lint problems  fix history  remove unneded util  remove unused exports  fix missing optionals on background image tag  inlined all definitions  correct mistypings  resolve error on obj copy and narrow obj search types  delete temp file  made linktag props optional  linktag extends htmlanchorelement props  fix link attributes  update to scrivito 1.17  update scrivito to 1.18  update scrivito to 1.19  linting ", "linked_issue_titles": "", "title": "update scrivito.js typings to scrivito 1.19"}
{"description": " backport of #63713 and #53286 yum ", "commit_messages": " yum - only instantiate yumbase once (#63713)  * yum - only instantiate yumbase once  previously, this code was re-instantiating the yumbase object  many times which is unnecessary and slow. however, we must do it  twice in the state: absent case because the yumsack and  rpmsack data of the previously instantiated object becomes  invalid and is no longer useful post transaction when we verify  that the package removal did in fact take place. also, this patch  removes the repetitive re-processing of enable/disable of repos in  various places.  here's a display of the speed increase against a rhel7 host:  yaml  - hosts: rhel7  remote_user: root  tasks:  - name: install generic packages  yum:  state: present  name:  - iptraf-ng  - screen  - erlang  - name: remove generic packages  yum:  state: absent  name:  - iptraf-ng  - screen  - erlang    before this patch:    real    0m52.728s  user    0m5.645s  sys     0m0.482s    after this patch:    real    0m17.139s  user    0m3.238s  sys     0m0.277s    fixes #63588  fixes #63551  * add changelog  yum - handle enable of non-existent repo (#53286) ", "linked_issue_titles": "", "title": "backport/2.8/63713 yum single yum base instantiation 53286 non existent repos"}
{"description": " what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where \"xxx\" is the issue number) if adding a new feature, the pr's description includes: when working directly with render functions in typescript / tsx, currently the following code is unsafe and unchecked by the ts compiler: this.$sopedslots.default() // default can be undefined the change in this pr makes typescript complain about the unsafe access accordingly and the code has to be expressed in a way that prevents calling an undefined function, e.g.: ( this.$scopedslots.default || ( () => 'default value' ) )( props ) ", "commit_messages": " fix(types): declare $scopedslots as potentially undefined to enable stricter ts checks  fix(types): fix tests ", "linked_issue_titles": "", "title": "improve $slots and $scopedslots type to prevent unchecked access to undefined"}
{"description": " for changelog. remove if this is non-significant change. short description (up to few sentences): fixed \"no message received\" error when interacting with postgresql odbc driver through tls connection. this fixes #3360. fixed segfault when using mysql odbc driver. ", "commit_messages": " always build odbc bridge as a separate binary #3360  strip clickhouse-odbc-bridge to avoid symbol clash with odbc drivers #3360 ", "linked_issue_titles": " external dictionary, psql: no message received ", "title": "build odbc-bridge as a separate binary. do not export symbols from it."}
{"description": " i'm a still pretty much a git noob so please be gentle ", "commit_messages": " added setviewoffset to camera for multi-monitor displays.  examples in another commit  compile with camera.setviewoffset  2 examples for using setviewoffet.  i think setviewoffset is mostly useful for multiple monitors  synced across multiple machines but that's a hard demo to setup  so these demos show doing it locally with muliple canvases ", "linked_issue_titles": "", "title": "added setviewoffset to camera so three.js can be used for multiple monitor demos"}
{"description": " previously, we created one cache per minor version. this changes allows us to invalidate the ata cache by releasing a new patch version of typescript. invaliding the ata cache may be necessary to work around performance bugs in a version of typescript, like those in 3.4. also, bump the version to 3.4.3. ", "commit_messages": " create an ata cache per patch version of ts  previously, we created one cache per minor version. this changes allows  us to invalidate the ata cache by releasing a new patch version of  typescript.  bump version to 3.4.3 ", "linked_issue_titles": "", "title": "cache ata per patch version"}
{"description": " following this code sample copied & pasted from the yeoman documentation, we should be able to call the generator.option method without a config argument: module.exports = class extends generator { // note: arguments and options should be defined in the constructor. constructor(args, opts) { super(args, opts); // this method adds support for a --coffee flag this.option(\"coffee\"); // and you can then access it later; e.g. this.scriptsuffix = this.options.coffee ? \".coffee\" : \".js\"; }; add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. (n/a) ", "commit_messages": " made option.config argument optional as per yeoman documentation  removed generated dependencies ", "linked_issue_titles": "", "title": "make the config argument of the generator.option method optional"}
{"description": " refactoring and implementing one code style for imports in react-reconciler package ", "commit_messages": " simplify imports in reactchildfiber  import type first in reactcurrentfiber  simplify imports in reactfiberbeginwork  simplify imports in reactfiberscheduler  simplify import in reactfibertreereflection  simplify import in reactfiberunwindwork ", "linked_issue_titles": "", "title": "simplify imports in react reconciler"}
{"description": " this also includes the changes from #25011 for bpo-43612. these make more sense in the context of these changes. currently gzip.compress and gzip.decompress are implemented with gzipfile. this is a lot of overhead when a simple in memory compression is needed. as shown in the benchmarks below, the overhead is considerable for datasizes below 4096 bytes (which are probably very common targets for in memory compression and decompression). this pr changes the implementations to compress and decompress in memory. i compiled python before and after this change with --enable-optimizations to ensure a fair comparison. i used this script to benchmark: import gzip import pathlib import statistics import sys import timeit data=pathlib.path(sys.argv[1]).read_bytes() sizes = [0, 128, 512, 1024, 4096, 8192, 16384] def benchmark(bench_string, number=1000, repetitions=10): for size in sizes: data = data[:size] compressed_data = gzip.compress(data) timeit_kwargs=dict(globals=dict(**locals(), **globals()), number=number) results = [timeit.timeit(bench_string, **timeit_kwargs) for _ in range(repetitions)] average = statistics.mean(results) print(f\"data size {size}: {round(average * (1_000_000 / number),2)} microseconds average\") if __name__ == \"__main__\": print(\"gzip compression\") benchmark(\"gzip.compress(compressed_data)\") print() print(\"gzip decompression\") benchmark(\"gzip.decompress(compressed_data)\") before: gzip compression data size 0: 7.92 microseconds average data size 128: 12.1 microseconds average data size 512: 18.45 microseconds average data size 1024: 22.41 microseconds average data size 4096: 32.51 microseconds average data size 8192: 41.03 microseconds average data size 16384: 57.99 microseconds average gzip decompression data size 0: 8.99 microseconds average data size 128: 10.26 microseconds average data size 512: 12.62 microseconds average data size 1024: 13.55 microseconds average data size 4096: 21.12 microseconds average data size 8192: 30.59 microseconds average data size 16384: 61.24 microseconds average after: gzip compression data size 0: 3.68 microseconds average data size 128: 7.64 microseconds average data size 512: 14.06 microseconds average data size 1024: 17.42 microseconds average data size 4096: 27.25 microseconds average data size 8192: 37.09 microseconds average data size 16384: 53.48 microseconds average gzip decompression data size 0: 1.98 microseconds average data size 128: 3.74 microseconds average data size 512: 5.36 microseconds average data size 1024: 6.72 microseconds average data size 4096: 14.1 microseconds average data size 8192: 23.57 microseconds average data size 16384: 52.72 microseconds average ", "commit_messages": " add test for zlib.compress wbits  add wbits argument to zlib.compress  use clinic to generate input  update documentation for zlib  add blurb news entry for zlib.compress wbits parameter  fix doc typo  remove unnecessary whitespace, add punctionation and complete sentences.  break line to comply with pep-7  update blurb to include :func: reference  remove erroneous double backticks  faster gzip.compress implementation  more efficiently decompress gzip files in memory  ensure correct endianness  remove redundant line  fix typos and test errors  revert changing default on compress for backwards compatibility  update documentation with gzip speed improvements  add a blurb for gzip speed improvements  use + instead of bytes.join() method ", "linked_issue_titles": "", "title": "faster implementation of gzip.compress and gzip.decompress"}
{"description": " using an incorrect count of unpacked values in the for template tag raises an exception rather than failing silently. so 6461b25 was an easy fix, but the last one was a bit more involved. after some more digging around, i found that cramer forgot to do the changes i made in bc722ab in a93ed9c. this lets us keep the existing 3 arg unpacking in context's interfaces in the templates (see for example a7e7711), and even fixes text rendering of the alert email. ", "commit_messages": " django 1.10 is strict about using an incorrect count of unpacked values in the for template tag  (cherry picked from commit 8f5a118513eced0a40c67efddc07e8f4d09cd724)  fix rendering for /debug/mail/alert in tests/acceptance/test_emails.py  you might be thinking this interfaces is the same one in  src/sentry/templates/sentry/emails/error.txt  30:{% if interfaces %}{% for label, _, text in interfaces %}  but it actually comes from src/sentry/web/frontend/debug/mail.py.  that one comes from src/sentry/plugins/sentry_mail/models.py, so no changes to interfaces in src/sentry/templates/sentry/emails/error.txt are required.  never mind, i was wrong. cramer forgot to mirror changes he made in a93ed9c24dc over to here  revert \"fix rendering for /debug/mail/alert in tests/acceptance/test_emails.py\"  this reverts commit 0d838e36ff10cf223cdfe4b488a93f4a40b0d796.  fill in tests/fixtures/emails/alert.txt with test output  cleanup ", "linked_issue_titles": "", "title": "fix unpacking values to for during templating"}
{"description": " i think we're good moving this chapter into copy-editing. ", "commit_messages": " * add version numbers  * update to latest react & livescript  * freeze traceur at 0.0.58  * upgrade traceur to 0.66  * array comprehension is gone from es6; adjust accordingly.  * reflect the readjusted es6 syntax in chapter writeup  * livescript 1.3.0  * s/continue/return/  * beginning to incorporate review ideas from john  * refactor block scope constants  * explicitly mention angularjs as per john  * add a \"why\" section to main.js as per john morrissey  * add calc() flowchart as per @jwm's review.  that's all, folks! ", "linked_issue_titles": "", "title": "incorporate reviews from the two reviewers"}
{"description": " as of now, bad word ids are not checked when added to the configuration/passed as inputs to the generate method. this is an issue when an invalid bad word id is defined: if the vocab size is 30k, then defining a bad word id for 30001 crashes the generation function with the following error: torch.sparse.longtensor(banned_mask.t(), indices, scores.size()).to(scores.device).to_dense().bool() runtimeerror: size is inconsistent with indices: for dim 1, size is 30000 but found index 30001 please let me know if you think this should raise a better error instead, rather than a warning. ", "commit_messages": " removes overflowing bad word ids  raise warning ", "linked_issue_titles": "", "title": "fix overflowing bad word ids"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. see react redux | custom hooks and the source code (each file contains a createsomething function which is typed in this package. the current typing for the createetc functions reflect basic return and argument types, but does not reflect the relation between the argument and return type. this is especially important (in fact, without the relation, the type is useless) because the return type cannot be used, in general, when the argument is non-trivial (i.e. the argument is not {}). the depreciation of the typeduseselectorhook is because the new types will obsolete that type. include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. add it to notneededpackages.json. ", "commit_messages": " update index.d.ts  update react-redux-tests.tsx  update index.d.ts ", "linked_issue_titles": "", "title": "improved factory function types and deprecated typeduseselectorhook."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: postmanlabs/newman#2392 include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " added request agents introduced in newman 5.1.0.  bump newman version ", "linked_issue_titles": "", "title": "add request agents to newman run options"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. ", "commit_messages": " fix: handle no user request  fix: make the current challenge button do something ", "linked_issue_titles": "", "title": "current challenge link on /welcome"}
{"description": " cherry-pick #23587 to swift-5.1-branch-04-24-2019 reviewed by @rintaro extend the support for single-expression closures to handle single-expression functions of all kinds. this allows, e.g. func foo() -> myenum { . } to complete members of myenum. rdar://problem/48938531 ", "commit_messages": " [code-completion] add type context for single-expression functions  extend the support for single-expression closures to handle  single-expression functions of all kinds. this allows, e.g.  func foo() -> myenum { .<here> }  to complete members of myenum.  [code-completion] fix type context for single-expression implicit getter  this adds an implicit body so that we can dig out the return type  context the same way as a normal function. for now, we are also treating  the first expression in a multi-statement implicit getter body the same  way; we'll need to refactor how we complete in accessors to  differentiate those cases.  add top-level and init/deinit tests ", "linked_issue_titles": "", "title": "add type context for single-expression function bodies"}
{"description": " the test cases contained in this pr were automatically generated by diffblue's deeptest software please feel free to merge them into your repository. the tests for fastjson can be viewed in more detail (with a trace view & step-through execution) at  we would be delighted with any feedback you have on these tests. ", "commit_messages": " add unit tests from diffblue deeptest for fastjson.jsonpath  add unit tests from diffblue deeptest for fastjson.parser.jsonscanner ", "linked_issue_titles": "", "title": "add diffblue deeptest unit tests for com.alibaba.fastjson"}
{"description": " make importmeta.url compatible w/ whatwg spec and @types/node typedef references: withastro/snowpack#1869  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: withastro/snowpack#1869 ", "commit_messages": " [@types/snowpack-env] remove readonly flag  make importmeta.url compatible w/ whatwg spec and @types/node typedef  references:  -  -  [@types/snowpack-env] update test stub ", "linked_issue_titles": "", "title": "remove readonly flag for importmeta.url"}
{"description": " uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespaces from that line: /kind design this pr updates the cpumanager and the topologymanager to error out if an invalid policy is specified for either of them. previously, these components would simply fall back to their respective none() policies if an invalid policy was specified. this pr updates these components to return an error when an invalid policy is passed to them, forcing the kubelet to fail fast when this occurs. these semantics should be preferable because an invalid policy likely indicates operator error in setting the policy flag on the kubelet correctly (e.g. misspelling 'static' as 'statiic' or 'strict' as 'striict'). in this case it is better to fail fast so the operator can detect this and correct the mistake, than to mask the error and essentially disable the cpumanager or the topologymanager unexpectedly. does this pr introduce a user-facing change?: passing an invalid policy name in the --cpu-manager-policy flag will now cause the kubelet to fail instead of simply ignoring the flag and running the cpumanagers default policy instead. ", "commit_messages": " update the cpumanager to error out if an invalid policy is given  previously, the cpumanager would simply fall back to the none() policy  if an invalid policy was specified. this patch updates this to return an  error when an invalid policy is passed, forcing the kubelet to fail  fast when this occurs.  these semantics should be preferable because an invalid policy likely  indicates operator error in setting the policy flag on the kubelet  correctly (e.g. misspelling 'static' as 'statiic'). in this case it is  better to fail fast so the operator can detect this and correct the  mistake, than to mask the error and essentially disable the cpumanager  unexpectedly.  update the topologymanager to error out if an invalid policy is given  previously, the topologymanager would simply fall back to the none() policy  if an invalid policy was specified. this patch updates this to return an  error when an invalid policy is passed, forcing the kubelet to fail  fast when this occurs.  these semantics should be preferable because an invalid policy likely  indicates operator error in setting the policy flag on the kubelet  correctly (e.g. misspelling 'strict' as 'striict'). in this case it is  better to fail fast so the operator can detect this and correct the  mistake, than to mask the error and essentially disable the  topologymanager unexpectedly. ", "linked_issue_titles": "", "title": "update the cpumanager and topologymanager to error out if an invalid policy is given"}
{"description": " @jibec please check if this is doing what is needed. ", "commit_messages": " revert \"gitignore .pot file\"  this reverts commit ee4e9a1090941797d7ed64e23a49ceeba762577c.  it seems we need the .pot file in the repo to allow weblate to import it.  po: import the .pot file into version control  fixes #14531. ", "linked_issue_titles": "", "title": "import the .pot file into version control for weblate"}
{"description": " in handbrake 1.2, every resx locale file had windows line-break type. downloading from transifex to my mac resulted in unix line-break type. so, the first commit will change all current resx files back to windows line-break type. (all resx files are then utf-8 + bom and windows line-break type) the second commit updates the locales to latest strings. ", "commit_messages": " change all resx files to windows line-break type  update locales ", "linked_issue_titles": "", "title": "switch locale files to windows line-break type and update to latest strings"}
{"description": " i'm doing a lot of agging over a codebase with single line packed js files scattered through it. i do want to know if there were matches, and on which line, but some of those files with one massive line can play havoc with the output when i'm trying to navigate a couple of dozen matches. things can get a bit tricky when most of the matches are nice 100 column lines, then one 15,000 column monster comes along! lines that long don't exactly play nice with a terminal or a text editor (it crashes the current master of neovim using the ag.vim plugin). i've solved my problem by adding a -w num / --width num option which truncates matched lines to the length specified. -w was chosen as it didn't seem to clash with anything else, including in grep and ack. i thought i might clean it up, write some tests and see if you might find it a useful or worthy addition to ag. make test runs without errors, but i think my own test case might be missing a few scenarios, like the truncation when print_path is set to path_print_each_line. there are a couple of warts with my implementation - the newline handling on line 205 of print.c is problematic when you redirect the output to a file. it seems to clash with the \"file without newline\" detection. i didn't want to start digging too deeply into the newline handling logic without first starting a discussion. i figured it's also one of those things where someone who knew the codebase more intimately might be able to say \"oh yeah, that's easy: you're doing that bit wrong, just move it over here and pow!\", or even just \"no, this whole thing isn't a good idea, you can already do that using x\" ;) ", "commit_messages": " added line width truncation option -w  added missing --width longopt handling ", "linked_issue_titles": "", "title": "added an option to truncate long lines with -w num"}
{"description": " original pull-request #19218 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update dragonbox  update dragonbox ", "linked_issue_titles": "", "title": "cherry pick #19218 to 21.1: update dragonbox"}
{"description": " optionally run spp over rasm2 assembly input with -p(reprocessor) argument adds a new function to ease the addition of the optional bool to the massemble function. removes spp integration from rasm2 ", "commit_messages": " add spp to asm.c  move spp integration to libr.asm.c  also remove the spp parts from rasm2.c  fix #6356  make spp parsing optional  add -p arg to rasm2 ", "linked_issue_titles": "", "title": "move ssp integration to libr/asm.c [fix #6356]"}
{"description": " this pr begins the work on cuda deivce api. the pr only implements memory allocation and deallocation, and makes use of those methods in llvmprogram and memorypool. this would be very useful for unifying the memcpy logic used in ggui, which would facilitate implementing ggui on other backends. ", "commit_messages": " wip  wip  remove virtual  auto format  remove macro  fix  format  resolve some convo  comment ", "linked_issue_titles": "", "title": "cuda device api 1/n: memory allocation"}
{"description": " way back in #2904, we removed some input styling code from the temp basal change percentage field, because it was forcing a numeric keypad to pop up on mobile browsers, and most of those keypads don't have a - key for entering negative amounts. all browsers tested at that time popped full keyboards after this change. getting reports now though that some browsers (samsung phones, kindle fire) are still popping the numeric keypad, since the field has type=\"number\". removing that input type designation to allow for negative values on all devices. (this means a small regression in ux, as all users will now need to switch to the number display on their standard mobile keyboards before entering a value each time, but i think it's better than excluding devices from entering anything at all.) ", "commit_messages": " dev  dev update  dev sync  dev update  dev sync  sync dev  remove type=number ", "linked_issue_titles": "", "title": "temp basal input fix for browsers that don't follow standards (samsung phones, kindle fire)"}
{"description": " i'm new to typescript and most of this stack so apologies if i've missed anything..... this allows you to access the events properties. e.g the example for selecting events at ", "commit_messages": " update definitions to support react-big-calendar event object properties  update version number ", "linked_issue_titles": "", "title": "update definitions to support react-big-calendar event object properties for onselectevent (version 0.15.0)"}
{"description": " on certain os x filesystems mtime is rounded to 1sec, to make sure the test also passes on these machines i changed the sleep to 1 sec, i've also done this in #881, but that's a rather big change, with this one i hope it gets merged faster as some people might get issues with this (in my case this test always fails) ", "commit_messages": " fix fs test for mac ", "linked_issue_titles": "", "title": "fix cache test for os x"}
{"description": " closes #10202 ", "commit_messages": " show 'enable/disable' system messages on edit room  fix double switch enable/disable  undo autoformat ", "linked_issue_titles": " suppress system generated messages in rooms [\"user\" set moderator by \"user\", room topic changed to] ", "title": "missing option to disable/enable system messages"}
{"description": " closes #42076 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry seems to work. let's try this again. ", "commit_messages": " update posix.yml  update python-dev.yml  update ci.yml  update database.yml  update sdist.yml  update pre-commit.yml  update posix.yml  update pre-commit.yml  update python-dev.yml  update sdist.yml  update database.yml  update ci.yml ", "linked_issue_titles": " ci: disable auto-cancel for master branch ", "title": "try to not auto-cancel on master"}
{"description": " consolidating some bug fixes and improvements to the world api. work in progress. handle the corner case when ue deletes an actor visually and from the actor list but reference still exists in memory, causing fatal errors when another object of the same name is spawned. queue up garbage collection when an actor is destroyed. use a tmap for name<->asset mapping, instead of iterating through all assets in the database in getmeshfromregistry at every spawn. use a tmap for name<->actor mapping, instead of iterating through all actors in scene at every object api call. ", "commit_messages": " use a tmap for asset registry  handle ue's garbage collection delays when spawning. don't force particular names  print message when asset registry is ready ", "linked_issue_titles": "", "title": "fixes and improvements to world api"}
{"description": " this should fix #932 - if binding_mode colours are not defined, use urgent_workspace colours as a fallback. three missing settings were also implemented: focused_(workspace|statusline|separator) they provide different colours for swaybar on the focused output. ", "commit_messages": " use urgent_ws color in swaybar if binding_mode is undefined  add bar colours for focused_(workspace|statusline|separator)  if these aren't defined in config, color settings without 'focused_'  prefix are used as a fallback. ", "linked_issue_titles": " resize indicator looks different from i3 ", "title": "fix some colour settings in swaybar"}
{"description": " prefer to make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. run tsc without errors. include the required files and header. base these on the readme, not on an existing project. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. ", "commit_messages": " add definitions for redux-persist  add missin generic types  add definitions for filter transformer  add definitions for encrypt transformer  fix header  add definitions for compress transformer  delete unnecessary linter configs ", "linked_issue_titles": "", "title": "add redux-persist and basic transformers"}
{"description": " currently the set sorting does default to year, but this is then overriden by the default sort by sorttitle of the main movie title node. this changes things so that the sort mode always defaults to sort by year, and if changed by the user, this is no longer saved into the default sort modes for title nodes.  it is still saved for the actual set that's changed. the alternative to this would be to have a set-specific default sorting/view structure, so that if the user changes the view/sort mode/direction in one set it's automatically changed in all other sets (not previously changed by the user).  not sure if that's better or not - typically sort by year would be correct in almost all cases, but there may be cases where the user wants a default view type for listings inside sets that is different than movie title listings??  personally i don't see the use case. ", "commit_messages": " ensure rating sort modes are available inside sets  change sorting inside sets to sort by year, and don't save to the general movie titles default sort when user changes (i.e. save only for the current set) ", "linked_issue_titles": "", "title": "sorting inside sets should default to year"}
{"description": " hi there, in this pr, the code of roialign is adapted from detectron2 roialign. it supports sampling ratio and aligned roialign. roialign with sampling_ratio=0 and aligned=false is consistent with the eldder version. besides, it pre-calculates the sampling weight to accelerate this operator. benchmark on unittest: before after 1.90s 1.45s ", "commit_messages": " update roialign  update tool for roialign ", "linked_issue_titles": "", "title": "improve roialign (accelerate roialign, support sampling ratio and aligned roialign)"}
{"description": " backports #8598 to v1.0.x and add objective-c tests cc: @makdharma @hsaliak ", "commit_messages": " update messages.proto and add a new test  tests hacks  send reset from the client when server closes stream unexpectedly  ensure something executes the new rst_stream code  missed file  undo test hack ", "linked_issue_titles": "", "title": "send rst_stream from client when it receives trailing metadata without the corresponding rst_stream"}
{"description": " this pr improves batched inference for wav2vec2 models by: adding an attention_mask adding zero-mean unit-variance normalization to the tokenizer correctly setting returning attention_mask and doing normalization depending on which architecture is used background some of fairseq's wav2vec2 models apply group normalization over the time axis in the feature extractor. this means that the convolutional layers in the feature extractor can not 100% correctly treat padded input resulting in those models giving different results depending on whether the input is padded or not. see pytorch/fairseq#3227 . those models should never make use of attention_mask which is made sure by setting return_attention_mask=false in their corresponding tokenizer configs:  for the \"newer\" models however that have the improved layer norm architecture in the feature extraction:  performance evaluation i've evaluated both wav2vec2-large-960h-lv60-self and wav2vec2-large-960h-lv60 on the test set of librispeech and got some nice improvements: wav2vec2-large-960h-lv60-self: 2.2 wer -> 1.8 wer wav2vec2-large-960h-lv60: 3.4 wer -> 2.2 wer so that the results now seem to match the paper's results very nicely. also, i checked that wav2vec2-base-960h should not use an attention_mask as the performance on librispeech test then drop heavily from ~4 wer to ~20 wer. todo once this pr is merged, i can fully focus on adding the fine-tuning functionality and will also update the model cards with the new evaluation code & results. ", "commit_messages": " save intermediate  finish batch the same as fairseq ", "linked_issue_titles": "", "title": "improve tokenizer & model for batched inference"}
{"description": " rebased against 2.4, replaces pr #1334. fix for #1330 ", "commit_messages": " regression test for #1330 (coerce none to '')  possible fix for #1330  coerce none to '' in charfield.to_native()  charfield - add allow_null argument  set allow_none = true for charfields with null=true  test for setting allow_none=true for nullable charfields ", "linked_issue_titles": "", "title": "coerce none to empty string"}
{"description": " replace #include \"tinyxml2/tinyxml2.h\" with #include \"tinyxml2.h\" in new cocostudio code. this change fix build with cmake when system installed libraries are used (-duse_prebuilt_libs=no). some systems may install tinyxml2 includes without special prefix directory, so findtinyxml2.cmake was written to find include directory that directly contains tinyxml2.h header (without prefix dir). moreover, official install script in tinyxml2 project install header to <prefix>/include/tinyxml2.h also fix some warnings in code. and remove unneeded inclusion of tinyxml2.h from user visible header file (cocos/editor-support/cocostudio/flatbuffersserialize.h), as a result usage of tinyxml in cocos may be \"private\" for user project. ", "commit_messages": " replace #include \"tinyxml2/tinyxml2.h\" to #include \"tinyxml2.h\" in new cocostudio code. this should fix build with cmake when use_prebuilt_libs=no. because findtinyxml2.cmake find tinyxml2.h header (without prefix dir). and some systems install tinyxml2 includes without special directory.  also this inclusion style match other existing files such as cocos/platform/ccfileutils.cpp  hide tinyxml2 from user visible header.  fix couple of warnings. make forward declarations to match to real declarations. ", "linked_issue_titles": "", "title": "fix usage of tinyxml2 in cocostudio code"}
{"description": " description: there are several differnent foscam libraries, all pretty similar.  it seems that an old, un-maintained version is currently being used.  just redirecting this to one that is more actively maintained and has some newer bug fixes that i have already tested and confirmed work on my local installation.  should not break any existing installations. related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. if the code does not interact with devices: ", "commit_messages": " change foscam python library to pyfoscam, which is more up to date and has several critical bug fixes.  update requirements_all.txt to match. ", "linked_issue_titles": "", "title": "use more up-to-date version of pyfoscam library"}
{"description": " also see #2581. closes #3036. previous behaviour when using mutable values like dictionaries or lists as the default argument, keep in mind that they behave just like mutable default arguments in python functions. this can easily cause unintended results, like the same value being set on all objects instead of only one particular instance. in most cases, it's better to use getters and setters, and only set the default for boolean or string values. the following now works doc.set_extension('mutable', default=[]) doc1 = nlp(\"hello world\") doc2 = nlp(\"what's up?\") doc1._.mutable.append(\"foo\") print(doc1._.mutable)  # ['foo'] print(doc2._.mutable)  # [] enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " support mutable default values in extensions  update documentation ", "linked_issue_titles": "", "title": "support mutable default values for extension attributes"}
{"description": " we can back the note out after the phantomjs issue is fixed, but i think for the time being we need this note. ", "commit_messages": " added a note to advise users to stick with an earlier version of node.js until the known issue with phantomjs is fixed.  fixes #477  added a note about the known issue between phantomjs and node 0.10.x ", "linked_issue_titles": "", "title": "fix for #411 - change to contributing.md about phantomjs and node 0.10.x"}
{"description": " i recently purchased the gulf coast 3-point bed leveling kit, and realized that marlin didn't have a way to take advtantage of it. the problem was that marlin defaults to front left, front right, rear right, rear left. the adjustment knobs for this kit are in the front left, rear left, and the center right. this update will allow users to define the probing order, and will also allow enabling 3-point leveling if they want it. if they enable 3-point leveling, then the corner_bed_leveling will only perform the first 2 corners, then it determines the opposite edge and moves there. this edge will respect whatever offsets would normally be used for the standard 4-corner probe. (so right edge will use rb.x + y_center) configuration.h edits: enable   #define level_bed_corners enable #define level_corners_3_points if you want to try out the 3-point leveling mess with level_corners_leveling_order if you want to change the order. a description comment explaining it is provided. note that i didn't currently error check, so if they put a number less than 0 or greater than 4 into the array, it will likely ignore that corner altogether. picture! as you can see, some additional text has been added to the 'probing' screen so that there is feedback to the user as to the last probe measurement, as well as the # of points probed within tolerance. ", "commit_messages": " add 3-point leveling to corner bed leveling  this added 3-point leveling to the corner bed leveling lcd menu option. this also adds the ability to customize the probing order if you want to change that up as well.  corrected default leveling order ", "linked_issue_titles": "", "title": "corner bed leveling 3 point leveling"}
{"description": " timedelta comparison already handled this correctly but i didn't see a test for it, so added one. closes #15183 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " timestamp comparisons for object arrays, closes #15183  whitespace fixup, add whatsnew ", "linked_issue_titles": " bug: timestamp array comparison may raise recursionerror ", "title": "prevent recursionerror on timestamp comparison against object array"}
{"description": " fixes issue spotted here  the classes are being blocked for root, but forwarded on other slot. however, on this component the docked slot is used as root, so we need to block them. ", "commit_messages": " use shouldforwardprop for docked root  prettier ", "linked_issue_titles": "", "title": "fix classes forwarded to dom node for docked drawer"}
{"description": " a new batch of fixes to be able to build some c++ tests on windows. ", "commit_messages": " make factop build on windows.  make memmapped_file_system build on windows.  make port_test work on windows  enable c++ control_flow_ops_test on windows.  enable more c++ tests on windows. ", "linked_issue_titles": "", "title": "some more c++ test fixes"}
{"description": " since many users on the forum complained that the example was not running due to the fact that delay(10) wasn't enough for some slow servers, i'm proposing this change. ", "commit_messages": " replace delay with while loop in wificlient.ino  oupps ! i forgot to set the timout value ", "linked_issue_titles": "", "title": "replace delay() with a while loop in wificlient.ino"}
{"description": " update doc for v1.1.6 update spring boot version to 1.5.9 add  spring boot actuator endpoints support ", "commit_messages": " add > spring boot actuator endpoints  update > v1.1.6  add > spring boot actuator endpoints  fix > config ", "linked_issue_titles": "", "title": "druid spring boot starter > update doc for 1.1.6 & add spring boot actuator endpoints support"}
{"description": " description: the coinmarketcap sensor can now only display values in dollars. the coinmarketcap api also supports other currencies like euro, pound and more. this pr adds support to use the sensor with other display currencies. this pr also adds the first test for the coinmarkercap sensor. there is one possible breaking change. the name of the sensor attribute '24h_volume_usd' is changed to '24h_volume'. pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3779 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " add support for different display currencies in coinmarkercap sensor.  add test for coinmarketcap sensor.  add test dependency to gen_requirements_all. ", "linked_issue_titles": "", "title": "add display currency setting to coinmarketcap sensor"}
{"description": " translates content-tracing-ko.md remove outdated comments about remote buffer in browser-window.md fix typos and improve grammer in tutorials at ko translations ", "commit_messages": " remove remain sentences  remove remain sentences  remove comments about remote buffer  remove comments about remote buffer in browser-window.md, because remote  buffer now supports in remote module.  fix typos and improve grammer, translate more files  translate content-tracing-ko.md file.  fix typos, improve grammer in tutorials and update as upstream. ", "linked_issue_titles": "", "title": "add more translations and fixes, remove outdated comments"}
{"description": " handle outdir and declrationdir correctly to generate output file names for the tsbuild exclude json files from project reference redirects from files to be emitted list fixes #30382 ", "commit_messages": " handle outdir and declrationdir correctly to generate output file names for the tsbuild  exclude json files from project reference redirects from files to be emitted list  fixes #30382 ", "linked_issue_titles": "", "title": "handle json files included in the project from project reference redirect"}
{"description": " this pull request contains simple lossless and simple lossy webp file support with the help of libwebp. for now this means aseprite can open and save static (not animated) lossless and lossy webp files as long as they do not use the extended format. we still lack support for animation, color profile, exif and xmp. but probably only animation is going to be of interest for aseprite for now. animation will be implemented in a second step along with support for the  extended format, exposing the missing features so aseprite could use them if any need arises. also a rudimentary save options dialog was implemented so user can save webp in lossless or lossy format. it was made quick and probably still needs some optimization for better ux. ", "commit_messages": " add submodule libwebp for #273  implement simple non animation webp for #273  this includes lossless and lossy webp file format. for this reason a  save option dialog was added giving rudimentary options for saving to  the user.  add libwebp info to credits ", "linked_issue_titles": "", "title": "support for the simple lossless and lossy (non animated) webp format for #273"}
{"description": " (maybe) breaking change: not currently a breaking change, but could be. it is possible to expose both the alexa.percentagecontroller and alexa.powerlevelcontroller for variable fan entities. existing entities will use the alexa.percentagecontroller and newly discovered fan entities will expose both. during testing entities that expose both would receive setpowerlevel directives vs. setpercentage indicating alexa prefers powerlevel and powerleveldelta directives when both are exposed. existing alexa.percentagecontroller handlers for fan entities were left in to maintain backwards compatibility. however, if you want to remove the bloat. just remove any references to fan entities from the alexa.percentagecontrollers. but will likely break existing fan entities already connected to alexa, and they will need to be removed and re-discovered. description: implements powerlevelcontroller for variable fan entities. while attempting to maintain percentagecontoller for existing entities already discovered by alexa. this also provides a \"bandaid\" to speed percentage mapping when integrations override the default attr_speed_list. e.g. lutron_caseta_pro maps speed_medium_high to 75, and would be reported as 0 in change reports. related issue (if applicable): checks off #24579 checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " implement alexapowerlevelcontroller  implement alexapowerlevelcontroller tests ", "linked_issue_titles": "", "title": "add powerlevelcontroller for fan to alexa"}
{"description": " based on the new github issue template, i have separated them on specific areas to make it easier if someone wants to contribute to the project. ", "commit_messages": " basic template for new issues  merge remote-tracking branch 'upstream/master'  updated issue template  updated issue template  update issue_template.md  update issue_template.md  merge remote-tracking branch 'upstream/master'  changed bug report to the new github issue template  add feature request template  question template  fixed title of question and added emojis ", "linked_issue_titles": "", "title": "new issue, feature and question template"}
{"description": " this replaces some of the pyint* macros in npy_3kcompat with their definitions. because of type conflicts, it isn't always a simple substitution. the f2py/cfuncs.py case is complicated and most fixes are left to a separate pr. ", "commit_messages": " maint: replace pyint_fromlong by pylong_fromlong.  replace the npy_3kcompat macro pyint_fromlong by its definition.  maint: replace pyint_aslong in some places.  replace the npy_compat macro pyint_aslong in some functions.  this is not a straight forward substitution because of type conflicts.  the fixes for numpy/f2py/cfuncs.py are postponed to another pr because  they are more complicated.  maint: replace pyint_asssize_t by pylong_asssize_t.  replace the npy_3kcompat macro by its definition. ", "linked_issue_titles": "", "title": "replace some  pyint_*  macros defined in npy_3kcompat."}
{"description": " working on fixing:  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " convert tabs to spaces  use grid alignment for keycodes and macro arguments  rework layout macro  update layout macro to resemble the assembled layout.  use human-friendly formatting in info.json  update readme  update maintainer's account name, and add bootloader and flashing instructions. ", "linked_issue_titles": "", "title": "misonoworks karina layout macro rework"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " weixin-app: use covariant event type  add jimexist  add jimexist ", "linked_issue_titles": "", "title": "update weixin app event type"}
{"description": " this pr adds unit tests for wire and xcontent serialization of remaining intervalssourceprovider implementations. closes #50150 ", "commit_messages": " add test for intervalssourceprovider.intervalfilter  add test for intervalssourceprovider.match  add test for intervalssourceprovider.combine  add test for intervalssourceprovider.disjunction  add license headers ", "linked_issue_titles": " add tests for intervalssourceprovider implementations ", "title": "add tests for remaining intervalssourceprovider implementations"}
{"description": " c++ worker will generate a template project, we need to ignore the generated files by c++ worker. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " linkopts shared  ignore generated files ", "linked_issue_titles": "", "title": "[c++ worker]ignore genrated files"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: < if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " added chatpermissions interface  - the field all_members_are_administrators has been removed from the documentation for the chat object. the field is still returned in the object for backward compatibility, but new bots should use the permissions field instead.  - modified chat interface. added : permissions, can_set_sticker_set, and sticker_set_name  updated message interface & added new interfaces - poll & polloption  - forward_sender_name  - media_group_id  - caption_entities  - poll  - connected_website  modified exisiting interfaces - audio, animation  - removed redundancy by extending filebase on animation  - added new properties to animation : width, height, and duration  - added new property to audio : thumb  modified contact and venue interfaces  - added foursquare_type to venue  - added vcard to contact  added new interface loginurl  rearranged interface ordering so that it matches telegram documentation  updated chatmember interface  - rearranged ordering to match telegram documentation  - added new property : is_member  fixed linting errors and made login_url as optional param in inlinekeyboardbutton ", "linked_issue_titles": "", "title": "added new interfaces and updated existing ones"}
{"description": " index-time analyzers are currently specified on the mappedfieldtype.  this has a number of unfortunate consequences; for example, field mappers that index data into implementation sub-fields, such as prefix or phrase accelerators on text fields, need to expose these sub-fields as mappedfieldtypes, which means that they then appear in field caps, are externally searchable, etc.  it also adds index-time logic to a class that should only be concerned with search-time behaviour. this commit removes references to the index analyzer from mappedfieldtype, and instead adds a 'registerindexanalyzer' method to fieldmapper; all index-time analysis is mediated through the delegating analyzer wrapper on mapperservice.  in a follow-up, this will make it possible to register multiple field analyzers from a single fieldmapper, removing the need for 'hidden' mapper implementations on text field, parent joins, and elsewhere. ", "commit_messages": " centralize index analyzer management ", "linked_issue_titles": "", "title": "move index analyzer management to fieldmapper/mapperservice"}
{"description": " in the spirit of jmac & laravelshift i've extracted 2 session variables to the environment file. not 'just because' but that one is able to set session_driver to redis, but unable to set a connection without touching the core session config file. ", "commit_messages": " extract core 2 session configurations to environment  in the spirit of jmac & laravelshift i've extracted 2 session variables to the environment file. not 'just because' but rather that one is able to set session_driver to redis, but unable to set a connection without touching the core session config file.  corrected bad copy paste ", "linked_issue_titles": "", "title": "extract 2 core configurations for sessions to environment"}
{"description": " description: adds try/except to prevent failure if a zone has an invalid schedule, preventing issue #27768 bumps evohome-async client to v0.3.4b1 - this is a version # change only, to match an upstream repo. see: zxdavb/evohome-async@0.3.3b5...0.3.4b1 related issue (if applicable): prevents #27768 pull request with documentation for home-assistant.io (if applicable): n/a **example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. ", "commit_messages": " refactor entity_ids, and consolidate classes  complete refactor  change back boiler name  de-lint  delinting tweaks  bump client to 0.3.4b1  handle bad schedules that cause issue #27768  correct rebase error ", "linked_issue_titles": "", "title": "bugfix evohome and bump client"}
{"description": " resolves devrel-1350 - private access: create explainer doc in nodeos/concepts select one: select any that apply: ", "commit_messages": " add first draft of privacy feature explainer :doc  add lead dev edits to privacy feature explainer :doc ", "linked_issue_titles": "", "title": "add privacy access feature explainer"}
{"description": " the immutable mode assumes that the output of react is a persistent tree, not mutations on a mutable dom tree. useful for targeting frameworks that accept immutable data structures as input. also adding another experimental rn renderer (cs) to try this out. ", "commit_messages": " cs renderer  because we didn't have enough rn experiments. i want to add one more.  split out hydration from the host config object  this makes it easier to do feature detection on the configuration.  move mutation host config to separate optional object  refs and life-cycles should happen even in immutable mode  unmount components even in non-mutation mode  this is the same as committing deletions but instead of finding host  components to delete, it only invokes componentwillunmount and detaching  of refs.  add persistent updates api  this mode will use a clone based api instead of mutating host instances.  needs implementation still.  it's awkward that there can be more than one child inserted into the root.  so we need a new api to create a \"root\" instance so that we can update it  atomically. alternatively we could keep the mutable api for containers  and assume that most use cases would only have a single root.  package up cs renderer ", "linked_issue_titles": "", "title": "split host config out into a mutable or immutable mode"}
{"description": " fixup abort handling of dvdplayer when it's using internal input streams ", "commit_messages": " dvdplayer: complete the update of ffmpeg interrupt interface  the old interface could not handle being called from another thread  udp: fix sign of error codes.  udp: fix non-blocking and interrupt handling.  in non-blocking mode, lowest-level read protocols are  supposed block only for a short amount of time to let  retry_transfer_wrapper() check for interrupts.  also, checking the interrupt_callback in the receiving thread is  wrong, as interrupt_callback is not guaranteed to be thread-safe  and the job is already done by retry_transfer_wrapper(). the error  code was also incorrect.  bug reported by andrey utkin.  dvdplayer: make sure member variables are inited in constructor  dvdplayer: make sure we can also abort the open of a ffmpeg input stream ", "linked_issue_titles": "", "title": "fix abort of ffmpeg streams"}
{"description": " causes memory usage regressions ", "commit_messages": " revert \"disable a text field test that fails on some macs with libtxt (#14895)\"  this reverts commit aa04a056f39cc9db23878509dc61e0dae7cd7b05.  revert \"roll engine to 33b88173f3820690169348859bbdc29133179e0b (#14832)\"  this reverts commit 44592238bbf28fe2038bb51ed86e0038ab09a8c7. ", "linked_issue_titles": "", "title": "revert engine back to 33b881"}
{"description": " original pull-request #22102 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update entrypoint.sh  fix for #22100  update entrypoint.sh  docker: avoid chown of . ", "linked_issue_titles": "", "title": "cherry pick #22102 to 21.1: docker: avoid chown of ."}
{"description": " note the lnks here are being pulled from the search plugin, not the program plugin ", "commit_messages": " removing description from title  adjusting subtitle  removing accidently paste  removing desc for uwp apps  getting dups removed from list if lnk exists  adjusting subtitle  removing accidently paste  getting dups removed from list if lnk exists ", "linked_issue_titles": "", "title": "deduping results for program plugin"}
{"description": " closes #19950 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry very simple implementation at the moment. the thought here is to introduce this method and perhaps subsequently extend to allow for string concatenation of the elements. longer term there could also be a keyword added to .agg of groupby which will dispatch to this instead of simply returning a multiindex column, which could alleviate some of the pain users are experience when trying to rename columns after an aggregation. @tomaugspurger and @jorisvandenbossche from the dev chat today ", "commit_messages": " added initial test  method implementation ", "linked_issue_titles": " add method to flatten all multi-index levels ", "title": "add to_flat_index method to multiindex"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. adeled/react-paginate#334 adeled/react-paginate@aef9d19 ", "commit_messages": " add page label builder  update tests  update package version ", "linked_issue_titles": "", "title": "update reactpaginateprops to match v7.1.2"}
{"description": " fixed corner case for failures and added debug logging. and increase time allowed to shutdown. ", "commit_messages": " fixed corner case for failures and added debug logging.  increased time to wait for shutdown.  cleaned up log statements. ", "linked_issue_titles": "", "title": "extend shutdown allowed time in under min available resources test - 2.0"}
{"description": " please don't merge this pr until cocos2d/cocos2d-js-tests#201 is merged. ", "commit_messages": " issue #2521: updating comments where searchs full path.  issue #2521: capture event of controlbutton in ccb for jsb.  issue #2521: fixing a logical error in ccbreader::addowneroutletnode. 'null  != node' --> 'null == node'.  issue #2521: removing an unused method controlstepper::setvalue(double value, bool send); since it's not implemented and there is an similar method 'setvaluewithsendingevent' could replace it.  issue #2521: testjavascript needs ccbreader support.  issue #2521: adding 'cc.convertcolor3btohexstring' in jsb_cocos2d.js.  issue #2521: updating tojs/cocos2dx_extension.ini, bind more cccontrols.  issue #2521: reporting an error when the callback function is undefined in 'js_cocos2dx_setcallback'.  closed #2521: updating jsb_cocosbuilder.js, it supports cccontrol now.  issue #2521: updating js-test. ", "linked_issue_titles": "", "title": "adding more extensiontest like cocosbuildertest and controlbuttontest and bug fix in ccbreader."}
{"description": " setting a default initial hidden state of zeros if the hidden state is not provided by the user. doing this in the rnnbase class, so it works for all three - rnn, gru and lstm. ", "commit_messages": " fixed issue #434 : default initial hidden state for recurrent layers  fixed a whitespace  fixed whitespace issue again ", "linked_issue_titles": "", "title": "default initial hidden states for recurrent layers : issue#434"}
{"description": " detailed description / documentation draft: this update adds a new page, /careers/, to the website with an embedded greenhouse iframe. this new page is linked to from the \"apply now\" button on the company page. ", "commit_messages": " migrate changes in compiled css to sass source  add greenhouse careers page ", "linked_issue_titles": "", "title": "add greenhouse careers page to website"}
{"description": " #11121 inadvertently broke the constructor for the testnode() object in p2p-segwit.py, silently breaking at least one of the tests. although the python code was raising exceptions due to a testnode() object not existing (or having the right type), mininode was masking these from anyone running the test through the test_runner (like travis), because it catches all exceptions during message delivery and just prints a log message and continues.  such \"graceful\" handling of errors is almost certainly something we don't want in our test suite, so the first commit here attempts to prevent that type of failure from ever being masked. the second commit fixes the particular bug in p2p-segwit.py. ", "commit_messages": " qa: treat mininode p2p exceptions as fatal  qa: fix bug introduced in p2p-segwit.py  changing __init__() -> set_test_params() in the tests should not have  applied to nodeconncb-derived objects. ", "linked_issue_titles": "", "title": "fix error introduced into p2p-segwit.py, and prevent future similar errors"}
{"description": " what do these changes do? add common preprocessing for each request in node manager three parts are included in preprocessing, logging, checking heartbeat and checking being killed. change submit task request to an asynchronous request. linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " add preprocess  finish preprocess  chang log level  fix ", "linked_issue_titles": "", "title": "add common preprocessing for each request in node manager."}
{"description": " i generate java model for api from swagger.yaml. as the swagger spec uses a lot's of inline schema, i end up with various inlineresponse200xx types generated. as swagger do support title as model name, i added this metadata for better generated model. swagger-codegen-plugin for maven  run code generator define titles for swagger inline schema objects so generated code use understandable names ", "commit_messages": " schema is missing canremove & detachkeys  example demonstrates they are expected  duplicate definitions for api response with just an id ", "linked_issue_titles": "", "title": "improve swagger schema for code generation"}
{"description": " also, ensure that privatenetwork=/joinsnamespaceof=/networknamespacepath= have an effect on socket units. ", "commit_messages": " execute: use structured initialization  execute: make things a tiny bit shorter  execute: (void)ify more  execute: no need to check for null when function right after does anyway  core: add open_netns_path() helper  the new call allows us to open a netns from the file system, and store  it in a \"storage fd pair\". it's supposed to work with setup_netns() and  allows pre-population of the netns used with one opened from the file  system.  core: add new setting networknamespacepath= for configuring a netns by path for a service  fixes: #2741  core: support netns joining also for sockets created by .socket unit  similar to the cgroup magic we nowadays do when listening to sockets, to  assign them the right bpf programs, let's also do the same and join the  specified netns in the child process.  this allows people to listen in sockets in specific namespaces, or join  multiple services and socket units together to live in the same  namespace.  run: make sure networknamespacepath= can be used on the systemd-run cmdline  man: document networknamespacepath= ", "linked_issue_titles": "", "title": "add networknamespacepath= to unit files"}
{"description": " i hereby agree to the terms of the cla available at:  do not allow to apply parametric aggregate function with -merge combinator to aggregate function state if state was produced by aggregate function with different parameters. for example, state of foostate(42)(x) cannot be finalized with foomerge(s) or foomerge(123)(s), parameters must be specified explicitly like foomerge(42)(s) and must be equal. it does not affect some special aggregate functions like quantile and sequence* that use parameters for finalization only. detailed description / documentation draft:   -resample combinator determines number of intervals (and size of nested aggregate function states array) based on parameters. quantileresamplemerge(0.5, 257, 65536, 1)(s) expects array of size 65279 and tries to read it, however, quantileresamplestate(0.50, 1, 2, 42)(x) produces array of size 1. probably there are more complicated cases and the simplest solution is just to forbid mismatching parameters. also mismatching parameters of -state and -merge aggregate functions do not make any sense in general case. ", "commit_messages": " fix another bug  fix_tests ", "linked_issue_titles": "", "title": "check aggregate function parameters in -merge combinator"}
{"description": " this change re-enables travis for branches other than 'v2'. the nacl broken nacl build was actually fixed by a new release of native client but this change is still useful for those of use who want to use travis on our own repos and branchs. ", "commit_messages": " fix generate-jsbindings.sh so it can on forked repos.  cleanup .travis.yml, and enable travis on all branchs ", "linked_issue_titles": "", "title": "cleanup travis.yml and re-enable on all branches."}
{"description": " implement various traits (iterbytes and extra's encodable and decodable) for rc when t alreay implements the trait. ", "commit_messages": " add an implementation of encodable and decodable for rc. this will be needed to use rc in place of @ in libsyntax.  implement iterbytes for rc<t>. ", "linked_issue_titles": "", "title": "implement various traits for rc<t>"}
{"description": " this pr migrates the changes in #4534 and rebases them onto master branch. ", "commit_messages": " adds string-to-int and int-to-string methods to enums  remove check for valuetoname property in enumtrait  remove unused imports ", "linked_issue_titles": "", "title": "add enum methods for converting to/from strings"}
{"description": " original pull-request #29925 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update cctz  update cctz ", "linked_issue_titles": "", "title": "cherry pick #29925 to 21.10: update cctz"}
{"description": " references #21088 update :arxiv: update docstrings to use consistent naming of :arxiv: links. together with @aufarkari we updated the :arxiv: links only (so :doi: still need to be updated in a separate pr). ", "commit_messages": " update decomposition.rst  updating the arxiv formatting  updating arxiv formatting  update plot_partial_dependence.py  updating reference formatting ", "linked_issue_titles": "", "title": "doc use the arxiv directive in the docstrings"}
{"description": " the graph extent mechanism is not good. i have some ideas for a better replacement, but this pr simply removes it. it also stops recursing on statement scopes and processes them using an \"on the heap\" stack, which fixes #29466. r? @dotdash ", "commit_messages": " add some comments to mir struct.  remove the graphextents, the design of which seems bogus. they carried  the right information, but it's hard to maintain in the face of  optimizations, and in the form that the analyses probably actually want. ", "linked_issue_titles": " stack overflow when compiling lots of macros ", "title": "remove graph extents and inline statements"}
{"description": " move a handful of tests from renderer to main runner. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none ", "commit_messages": " test: tsify more webcontents specs  getfocusedwebcontents  setdevtoolswebcontents, isfocused, iscurrentlyaudible  getwebpreferences, opendevtools  before-input-event  zoom-changed  sendinputevent  insertcss  startdrag  focus, getosprocessid  zoom api ", "linked_issue_titles": "", "title": "tsify more web contents specs"}
{"description": " currently, if a new commit on master comes between the different stages, the cd pipeline will break. the reason is, the libxmet binary will be posted against one commit id, but the release pipeline (e.g. for pypi packages), will be kicked off with the latest commit id. this pr proposes to fix this issue by introducing a commit_id parameter to the release job definition. this solves the issue. this means we can use the commit id as the branch specifier in the 'pipeline' section of the job configuration and ensure that the specified commit_id will be used for the build. this comes with some drawbacks, namely that release job will assume the state of the last job it ran. this can change the pipeline definition and lead to hard to track errors. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " removes unnecessary parameter  adds revision parameter to release job ", "linked_issue_titles": "", "title": "add commit_id param to release job"}
{"description": " this pr adds links to my article about using antd-scss-theme-plugin to the chinese and english versions of customize-theme. antd-scss-theme-plugin is a webpack plugin for customizing ant design with an scss theme file, using ant design's compiled variables in scss files throughout your project, and hot-reloading the customized ant design styles. connect #9815 (and this comment by @afc163 in particular). please makes sure that these checkboxes are checked before submitting your pr, thank you! make sure that you propose pr to right branch: bugfix for master, feature for latest active branch feature-x.x. make sure that you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. ", "commit_messages": " update customize-theme.en-us.md with link to antd-scss-theme-plugin article  this article describes how to install the use the antd-scss-theme-plugin for webpack, and how doing so allows you to: 1) customize ant design's variables from an scss theme file, 2) use compiled ant design variables in other scss theme files in your project, and 3) enable hot-reloading of ant design styles.  update customize-theme.zh-cn.md with link to antd-scss-theme-plugin article  this article describes how to install the use the antd-scss-theme-plugin for webpack, and how doing so allows you to: 1) customize ant design's variables from an scss theme file, 2) use compiled ant design variables in other scss theme files in your project, and 3) enable hot-reloading of ant design styles. ", "linked_issue_titles": "", "title": "add links to antd-scss-theme-plugin article to the customize-theme doc file"}
{"description": " and some cleanup. additionally, attempted machine translation of french docs. may attempt chinese later? ", "commit_messages": " update newbs flashing guide  for the newbs that want to start flashing  update flashing docs  misc flashing  attempt at flashing in french  lets hope i didn't butcher this too badly with machine transations ", "linked_issue_titles": "", "title": "update flashing information to include :flash target"}
{"description": " closes #16028 closes #16045 this pr provides a way to make predictions with categoricalnb with data that contains categories that were not observed in the training data. e.g., data for a problem can possibly have 2 categories, but training data only contains samples with one category observed: >>> import numpy as np >>> from sklearn.naive_bayes import categoricalnb >>> x_train = np.array([[0], [0], [0]]) >>> y_train = np.array([0, 1, 0]) >>> clf = categoricalnb(min_categories=2) >>> clf.fit(x_train, y_train) >>> x_test = np.array([[1]]) >>> clf.predict(x_test) array([0]) >>> clf.n_categories_ array([2]) this adds the additional parameters/attributes to __init__ of categoricalnb: parameters ---------- min_categories : int or array-like or none, (default=none) minimum number of categories per feature: - int : sets the minimum number of categories per feature to n_categories for each features. - array-like : n_categories[i] holds the minimum number of categories for the ith column of the input. - none : determines the number of categories automatically from the training data. attributes ---------- n_categories_ : ndarray (n_features,) number of categories for each feature. this value is provided inferred from the data or set by the minimum number of categories. this feature has uses in instances where a given category may be rare, and then by random chance is observed in a test/application set, but not in the training set. in the current version, such an instance will raise an error (as detailed in #16028). this differs slightly from the solution i proposed in #16028 . implementation in this way allows a minimum number of categories to be specified, but be overridden if the data has more categories, which i thought may be user-side. this fix will still result in the same unhelpful error message mentioned #16028 if category i has a greater value in a non-training set than the value of n_categories[i] - 1. is #16045 considered stalled at this point?  would it be worth wrapping a helpful error message for that case into this pr? ", "commit_messages": " tst: expose indexerror for unseen feature category  enh: allow unseen categories with n_categories in categoricalnb  tst: test n_categories works and gives appropriate errors  maint: refactor so n_categories_ is kept as attribute in categoricalnb  maint: fix pep8 violation  tst: add test for min_categories < n_categories_ and refactor  fix: remove addition to feature max  doc: remove unique values from docstring ", "linked_issue_titles": " categoricalnb bug with categories present in test but absent in train ", "title": "enh add min_categories parameter for each feature to categoricalnb"}
{"description": " original pull-request #26707 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix set role.  fix set role ", "linked_issue_titles": "", "title": "cherry pick #26707 to 20.8: fix set role"}
{"description": " adds fuchsiasdk a wrapper/shim which provides access to the set of command line tools necessary to work with a fuchsia device. internal tool will inject a different implementation that knows where to look in google3. adds fuchsiaworkflow which defines that fuchsia development is supported wherever an fx command can be found. this is somewhat hacky... adds fuchsiadevices which adds basic support for device discovery using netaddr and netls commands. this should work as-is internally when the tool commands are swapped out with a different fuchsiasdk location. ", "commit_messages": " fuchsia devices  add tests and refactor sdk to fx wrapper  add missing newlines ", "linked_issue_titles": "", "title": "support for fuchsia device discovery, workflow, and sdk wrapper"}
{"description": " added my personal hhkb-based layout for the dz60. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " created personal keymap for dz60 hhkb layout. ", "linked_issue_titles": "", "title": "add hhkb-based keymap for dz60"}
{"description": " fixes #4260. evaluates the output iterable right after the spider callback, as it's currently being done in the process_spider_output chain. (plus some minor styling adjustments) ", "commit_messages": " [test] spider middleware: catch exceptions right after the spider callback  spider middleware: catch exceptions right after the spider callback ", "linked_issue_titles": " first spider middleware does not process exception for generator callback ", "title": "catch spider callback exceptions early"}
{"description": " when the upstream responds a payload whose length is smaller than content-length header value, the current implementation of fastcgi handler and mruby's http_request don't send rst_stream frame. this pr makes those handlers send rst_stream. note1: this pr depends on #1489 to make some tests pass note2: desirable h2o behaviours upstream payload h2o payload rst_stream (h2) chunked (h1) smaller than c-l send all received body yes - bigger than c-l send body upto c-l no - te:chunked ending in mid-of-chunk send all received body yes append a broken chunk (1\\r\\n) te:chunked ending on chunk boundary but no eos send all received body no append an eos (0\\r\\n) see also: #1031 ", "commit_messages": " fix keepalive problem which happens when mruby's http_request shortcut is used  send rst_stream when received smaller payload than content-length header ", "linked_issue_titles": "", "title": "forward the error to the client when upstream closes the connection abruptly"}
{"description": " this pr updates some return types to include undefined. that helps documenting the api and prevents bugs when using strictnullchecks fixes #15841 ", "commit_messages": " update types.ts  update types in parser.ts and scanner.ts ", "linked_issue_titles": "", "title": "update return types of apis"}
{"description": " 3.2 version of #42178 : this pr has most of the things in #41097 (excluding the virtual keyboard support): refactor event handlers, moving add/remove logic to native/utils.js window event handlers no longer usecapture (fixes #33020) canvas resize option now available on export (fixes #37205). plus, a rework of the initialization process to better handle file system synchronization (last commit, fixes #39643): the engine now expects to emscripten fs to be setup and sync-ed before main is called. this is exposed via module[\"initfs\"] which also allows to setup multiple persistence paths (internal use only for now). additionally, fs syncing is done once for every loop if at least one file in a persistent path was open for writing and closed, and if the fs is not syncing already. this should potentially fix issues reported by users where \"autosave\" would not work on the web (never calling syncfs because of too many writes). ", "commit_messages": " move request_quit to javascript_main.  small refactor to javascript handlers.  crated helper class in native/utils.js.  simplify code in os/displayserver.  window event listener do not use capture.  better hidpi support in html5.  make canvas resize optional in html5.  js synchronous start, better persistent fs sync.  the engine now expects to emscripten fs to be setup and sync-ed before  main is called. this is exposed via module[\"initfs\"] which also allows  to setup multiple persistence paths (internal use only for now).  additionally, fs syncing is done **once** for every loop if at least one  file in a persistent path was open for writing and closed, and if the fs  is not syncing already.  this should potentially fix issues reported by users where \"autosave\"  would not work on the web (never calling syncfs because of too many  writes). ", "linked_issue_titles": "", "title": "synchronous main, better persistence, handlers fixes, optional full screen."}
{"description": " i found various things i wanted to adjust while working with this helm chart, so i made this bigger pr for some initial discussion and local development. i can split it  up into reasonable chunks to get it merged later if it makes sense to you. while reviewing, i recommend doing it one commit at the time. change overview some refactoring for readability, these changes are in alignment with common modern practices. see for example: helm/helm#4562 added ability to add more configuration files switched to using a k8s secret over the k8s configmap to save .values.configfile content as sensitive passwords were suggested to be stored in the file. added checksum annotations to restart pods on configuration changes bumped superset version to 0.28.1 ", "commit_messages": " refactor template to include function  refactor to utilize default function  refactor away blank container.env  refactor systematic left whitechomping  refactor indentation for readability  allow for additional config files  restart pods on changed config  secure secrets in config  refactor away unused code  bump superset version  bump chart version ", "linked_issue_titles": "", "title": "refactoring, additional configs, secure secrets, versionbump"}
{"description": " closes #25104 added type set_option docstring in config.py -added type to boxplot_frame_groupby docstring in plotting/_core.py -indented versionadded in excelwriter docstring io/excel.py -updated code_check.sh to take into account pr10 type errors ", "commit_messages": " added type set_option docstring in config.py  added type to boxplot_frame_groupby docstring in plotting/_corew.py  indented versionadded in excelwriter docstring io/excel.py  updated code_check.sh to take into account pr10 type errors ", "linked_issue_titles": "", "title": "fixes to docstrings and add pr10 (space before colon) to validation"}
{"description": " added via support to doodboard/duckboard_r2 as a copy of the default keymap with via enabled. tested on my own duckboard r2.  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " update r1 keymap and config  add duckboard r2  add via support for duckboard r2 ", "linked_issue_titles": "", "title": "add via support to doodboard/duckboard_r2"}
{"description": " the regex's used to find img tags in html fields were changed to match eslint rules but that change broke the matches for certain situations (but not the ones in our tests ). this pr reverts those changes, matches any special character in url's (instead of just url-safe characters), and adds a unit test for 2 of our html regex's. ", "commit_messages": " revert regex's to earlier state before eslint changes and match any character in urls  test wp html image regexs ", "linked_issue_titles": "", "title": "fix(gatsby-source-wordpress): html image regex's"}
{"description": " flutter stable 2.5.0 framework scheduled cherrypicks cherrypick devtools version issues: #89320 commit: 870f5e8 roll engine cherrypicks from: flutter/engine#28496 ", "commit_messages": " update devtools version to latest release 2.6.0 (#89318)  this will need to be cherry picked into the stable release.  'update engine revision to f0826da7ef2d301eb8f4ead91aaf026aa2b52881 for stable release 2.5.0' ", "linked_issue_titles": "", "title": "flutter stable 2.5.0 framework cherrypicks"}
{"description": " as of v140, there were duplicate onpress events firing for keyboard/controller presses on touchable*s. #2968 removed the native onpress, but unfortunately #3042 and #3049 removed the js ones (not realizing that the native ones had already been removed.) this pr brings back the js onpress calls. verified using the playground app and rntester. microsoft reviewers: open in codeflow ", "commit_messages": " add handlepress back to touchable* onkeyup  change files ", "linked_issue_titles": "", "title": "fix onpress not firing for touchable* keyboard events"}
{"description": " removes tmparch/tmpbits from command syntax because we have @a and @b now. moreover, it improves @a/@b usages, because it also correctly sets/restores anal hints. ", "commit_messages": " core/cmd_print: remove redundant code from \"pd\" command  no need to have tmp arch and tmp bits in the syntax, we can use @a and  @b. also, fix @a and @b to temporarily overwrite anal hints.  core: remove useless code in \"pa\" and \"aex\" commands  no need to have arch and bits in the command syntax, just use @a and @b. ", "linked_issue_titles": "", "title": "fix pd syntax (also aex and pa)"}
{"description": " code example for article \"introduction to quartz\" ", "commit_messages": " merged branch master into master  merged branch master into master  merged branch master into master  merge remote-tracking branch 'eugenp/master'  quartz example for article: introduction to quartz  adding new module for java quartz  removing quartz code from jee7 module  fixing folder structure ", "linked_issue_titles": "", "title": "code example for article bael-818"}
{"description": " tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " fixed tests/series/methods/test_asof.py  fixed tests/series/methods/test_droplevel.py  fixed tests/series/methods/test_tz_localize.py  fixed tests/series/test_apply.py  fixed tests/series/test_arithmetic.py  fixed tests/series/test_datetime_values.py  fixed test/series/test_operators.py  fixed tests/tools/test_to_time.py  final commit before style checks  tst: final commit fixing bare pytest raises  tst: fixed bare pytest raises ", "linked_issue_titles": "", "title": "30999 fix bare pytest raises"}
{"description": " there're a few problems with current version of type definitions that this pull request addresses: type checking is not performed in many places using any rather than a generic type. no property name type-check. for example, we ideally shouldn't allow to do this: state.set('foo', 1) // state type doesn't have the property foo types are sometimes wrong. for example, methods shouldn't return solely the mixin part immutableobject<any>, but rather the type plus the mixin part t & immutableobjectmixin<t>. checklist: follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " enforce strong typing for partial objects and property names  enforce strong typing in update, updatein, without  final polishing  add fallback definition to solve dynamic scenarios and when the number of arguments is more than 5  set/update fallbacks, tests, tslint coverage  fix common mistakes  add function-like constructor; fix lint errors ", "linked_issue_titles": "", "title": "replace any with meaningful types, enforce string property typing, fix bugs"}
{"description": " this prodives a https endpoint with a self-signed ca certificate. the main motivation is to provide infrastructure for integration tests for #71979. ansible-test for more information and an example use case see #71979. ", "commit_messages": " introduce self-signed.ansible.http.tests  forwarding of port 444  forward port 8444 to port 444 on http test container  fix port forwarding for windows under docker ", "linked_issue_titles": "", "title": "add self-signed https endpoint for ansible-test"}
{"description": " i hereby agree to the terms of the cla available at:  now partition id in queries like alter table ... partition id xxx validates for correctness. fixes #25718. ", "commit_messages": " add test  simple validation for partition id before drop partition ", "linked_issue_titles": " validate partition id before drop partition ", "title": "add simple validation for partition id before drop partition"}
{"description": " this enables running the built-in js component tests for list. we need to make source copies of these since they are not published in the npm package, but we can keep them synchronized via override tooling. need to add for react-native-win32 in a later change microsoft reviewers: open in codeflow ", "commit_messages": " run rn list jest tests  this enables running the built-in js component tests for list. we need to make source copies of these since they are not published in the npm package, but we can keep them syncrhonized via override tooling.  still need to register these in overrides.json, add for react-native-win32 as well.  change files ", "linked_issue_titles": "", "title": "run rn list component jest uts"}
{"description": " just breaking up the logic so i can reuse it for defer. ", "commit_messages": " [move-function] convert movekillscopyableaddressesobjectchecker.visitor to be a local variable instead of a field.  nfc.  [move-function] move addressestocheck out of movekillscopyableaddressesobjectchecker and into the users of said checker.  this ensures that movekillscopyableaddressesobjectchecker is only ever  processing a single address rather than maintaining this worklist. this will  enable me to reuse parts of it in a simpler way for defer checking.  [gardening] move a utility function into the utility section of the file before more re-organization.  [move-function] refactor out the main dataflow computation into a helper struct.  [move-function] move the single basic block dataflow also onto that helper struct. ", "linked_issue_titles": "", "title": "some refactorings in preparation for defer"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldnt have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " added typings for datadog-winston  updated comments  fixing comments which will also kick the git checks  apparently i can't have a patch in my version. i thought this was supposed to be the version of the js package my types target  ahh i see now, it is the version of the js package, just with patch omitted  updated library to use commonjs style imports  formatting ", "linked_issue_titles": "", "title": "adding typescript support for \"datadog-winston\""}
{"description": " finish testcases  for opentstb-telnet-protocol with taosadapter renew testcases  for opentstb-telnet-protocol with taosc opentsdbtelnettaosadapterinsert.py no ci temporarily because develop branch doesn't build taosadapter. ", "commit_messages": " [td-10908]<test>: add testcases for influxdb-line-protocol with blmv3  modify util/common.py  modify functions  save  finish insert/opentsdbtelnetblm3insert.py  [td-10952]<test>: finish insert/opentsdbtelnetblm3insert.py  [td-10952]<test>: finish testcases  for opentstb-telnet-protocol with taosadapter  rm insert/influxdbblm3insert.py in this branch  [td-10952]<test>: renew testcases  for opentstb-telnet-protocol with taosc ", "linked_issue_titles": "", "title": "renew testcases  for opentstb-telnet-protocol with taosc and finish testcases  for opentstb-telnet-protocol with taosadapter"}
{"description": " change variable name for nettytransporter actually, these are handler not listener follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. ", "commit_messages": " fix typo ,the method not only for get port  change variable name listener to handler ", "linked_issue_titles": "", "title": "fix variable name  in nettytransporter"}
{"description": " i hereby agree to the terms of the cla available at:  documentation for #3210 files from en docs are copied to ru docs. don't review them, they will be overwritten with russian translation. ", "commit_messages": " docapi-6206: odbc engine and table function.  docapi-6206: fix.  docapi-6206: odbc table engine description. ", "linked_issue_titles": "", "title": "docapi-6206 odbc table engine and odbc table functions descriptions"}
{"description": " closes #23490 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry fix issue described in #23490, and add tests to catch this case. ", "commit_messages": " bug - account for names when concating series on axis 1  tst - add test to make sure names argument is accounted for when concating series and axis=1 ", "linked_issue_titles": " bug: pd.concat with all series on axis=1 ignores the `names` argument. ", "title": "bug - pd.concat with all series on axis=1 ignores the names argument (issue: 23490)"}
{"description": " adds mapper functions allows css.core for style/css add new round shapes add extra params to handler connecting unused interfaces (i.e. they are now being used) for the styles add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " allows css.core for the style/css  adds new round shapes  - allow mapper functions when defining style properties  - adds \"ghost\"  - plugs some interfaces to css.node/edge  - add extra params to handler  - fixes the originalevent type  - adds other events methods  fix linting ", "linked_issue_titles": "", "title": "add mapper functions and more"}
{"description": " this is a large refactor of our string methods. the goal is to have the series.str accessor dispatch the actual compute down to the extensionarray. the motivation is to allow a series backed by arrow memory to use the arrow string kernel (e.g. series.str.lower() on an arrow-backed stringarray should eventually call pyarrow.compute.utf8_lower().) to facilitate this, i made the following changes split core/strings.py into a sub package: core/strings/accessor.py: implements the series.str accessor, which (mostly) just delegates to the ea and wraps core/strings/object_array.py: implements the string methods for object-type ndarray. core/strings/categorical.py, core/strings/string_array.py, implements categorical & stringarray-specific methods defines a new extensionarray._str extension point. this is where eas get to take over and use their compute note that there are a few methods like cat, extract, and extractall that don't yet dispatch. i need to look into them a bit more, there implementation is a bit confusing. closes #36216 ", "commit_messages": " implement basedtypetests for arrowstringdtype  refactor to use parametrized stringdtype  wip  annoyed  wip ", "linked_issue_titles": " refactor stringmethods for extension arrays ", "title": "dispatch string methods to extensionarray"}
{"description": " isolate multi-thread support from 'multiplereader', making it an independent decorated reader(threadedreader). add docstring for some python interfaces. combine 'open_files', 'multi_pass_reader' and 'threaded_reader' together to make a new python open_files() interface. simplify python interface 'create_xxx_reader' names, e.g, rename 'create_double_buffer_reader' to 'double_buffer'. remove readers' hasnext(), for it is unsafe in multi-thread environment. ", "commit_messages": " add 'buffer_size' api for open_files op  add docstring  a draft of threadedreader  complete threaded reader  fix compile errors  modify multiplereader  1. removes multiplereader's multi-thread support, for we have got  threadedreader.  2. rename multiplereader to multifilereader  update readers python api  1. combine 'open_files', 'multi_pass_reader' and 'threaded_reader'  together to make the new 'open_files' interface.  2. add some docstring.  3. simplify interface names of 'create_xxx_reader', e.g, rename  'create_double_buffer_reader' to 'double_buffer'.  fix errors ", "linked_issue_titles": "", "title": "modify readers to fit the parallel executor"}
{"description": " migration for the pivot table visualization render updated pivot table make editor settings work clean up old code add tests review changes and manual test -- ", "commit_messages": " npm install react-pivottable  initiate pivot table migration ", "linked_issue_titles": "", "title": "migrate pivot table visualization to react"}
{"description": " closes #8961 related to rocketchat/rocket.chat.livechat#399 the users and managers want to know the website url from where the livechat offline message comes from. now, the livechat widget will send this information among the other fields passed through the endpoint. ps: i'm going to add the new field(host) of the endpoint on the related rest doc page. ", "commit_messages": " add web site url from where the message has been sent.  turn the host field mandatory. ", "linked_issue_titles": " livechat: include website url in email sent when agents are offline ", "title": "add livechat website url to the offline message e-mail"}
{"description": " hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! add courses from kaggle and a few screencasts in brazilian portuguese it has some good skills to be developed within the channels/platforms that are being submitted. both kaggle and youtube are free platforms. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " check_urls=free-courses-en.md  check_urls=free-podcasts-screencasts-pt_br.md  check_urls=free-courses-en.md  check_urls=free-podcasts-screencasts-pt_br.md  check_urls=free-courses-en.md ", "linked_issue_titles": "", "title": "adding courses from kaggle and screencasts"}
{"description": " since the release version is a calculated based on the previous git tag for beta releases, this calculated version will be wrong if there was not a previous dev release. this adds a validating that the calculated version matches the candidate branch numbers. ", "commit_messages": " wip  validate git parsed version and rc branch match ", "linked_issue_titles": "", "title": "validate git parsed version and release branch match"}
{"description": " hello this pr will fix the shown zoffset value in tune and prepare menu. actual behavior value wrong scaled and only one digit after the point like 0.0 screen: ", "commit_messages": " zoffset  update dwin.cpp ", "linked_issue_titles": "", "title": "fix e3v2 (crealityui) zoffset in tune & prepare menu"}
{"description": " this pr contains the changes from #306 by jwisniewski plus some fixes to make it work with latest libgdx code. ", "commit_messages": " what i did (philosophy):  libgdx is based on singletons (gdx.app etc), moreover user can implement  his own singletons and it just works when libgdx is used to make desktop  applications, android activities etc. live wallpaper backend was  designed in wrong way (from libgdx point of view), this design tried to  force libgdx to work in environment it was not designed to. there should  be only one instance of libgdx singletons in application, but libgdx  wallpapers work on many engines with many surfaceholders..  i just moved things to (in my opinion) right direction: i forced live  wallpapers api to create environment libgdx is designed to. redesigned  androidlivewallpaperservice stops all this madness linked with switching  wallpaper 'engines' by itself. rest of user application, libgdx  internals etc. works normally and exactly the same as in other types of  applications (there is only one instantion of applicationlistener,  androidgraphicslivewallpaper, glsurfaceview etc). it should be possible  to run any of existing libgdx apps as wallpaper now (perhaps after  solving few little issues - i'm new in libgdx:)).  all lifecycle issues was resolved. with this lw backend user can switch  wallpapers as fast as he want, can sleep phone in live wallpaper  preview, it now runs without problems on devices on which it crashed  before. no null gl contexts inside render() method.  much faster wallpaper loading (ex in preview)  much faster resuming after phone was in sleep mode.  most of code duplicated for lw backend is no longer used and can be  deleted.  if end developer want to implement custom application behavior in  wallpaper preview, there is additional interface called  androidwallpaperlistener, he should implement it in his application  listener and respond for event called when preview is opened/closed (see  modified livewallpaper test).  what i did (technically):  + completely new implementation of androidlivewallpaperservice. there  can be many engines in runtime, and any of them is linked with own  surfaceholder on wallpaper should draw. but.. only one engine is active  at specific time. wallpaper service switches smartly between them and  update glsurfaceview to use currently active surfaceholder and render on  it. this is transparent for rest of application, and for glsurfaceview  itself too! i just simulates events called when surface holder is lost  or restored. glsurfaceview 'think' its surface was lost and restored,  but really it was just switched to another surface holder (linked with  active wallpaper engine).  + androidgraphicslivewallpaper now uses glsurfaceview and  glsurfaceviewcapcake as original androidgraphics (with slight  modifications). gl..surfaceviewlw classes are deprecated, not used, and  can be removed completely.  + androidgraphislivewallpaper synchronized with current androidgraphics  and androidgraphicsdaydream (now it is near mirror copy of original  androidgraphics, i think you should merge this three classes in near  feature before they will be resynchronized again, it shouldn't be hard  to do)  + androidwallpaperlistener, interface that can be implemented in  addition to applicationlistener in libgdx application to autimatically  add support for live wallpaper specific events  + updated livewallpaper test  + added synchronization to androidgraphicslivewallpaper.resume (as in  pause, destroy etc)  + synchronization in androidgraphicslivewallpaper.resume  + fixed synchronization of lifecycle methods in  androidgraphicslivewallpaper (waiting threads was notified too early and  on some devices it caused errors while rotating device in lwp  preview:  a/libc(1274): fatal signal 11 (sigsegv) at 0x0000003c (code=1), thread  1291 (thread-153)  + more logging  + wallpaperservice ondispose improved: glthread is killed now and audio  is disposed  - disabled logging  + optimized number of calls to logger (less logging! when pausing /  restoring live wallpaper - which can occur very often in contrast to  regular applications)  + some cleaning of commented code etc  ~ input created without help of androidinputfactory - it causes errors  when obfuscated because of reflection relying on plain class names  + more fixes for lifecycle - pausing of lwp was broken  crashing again..  + bugfix: \"fatal signal 11\" on some devices when rotating lwp in preview  application listener pause will not be called anymore!  + fix for surfacechanged event  disabled logging  + mesh constructor with optimizations for dynamic meshes  vertexbufferobjestsubdata restored to original  android backend classpath restored to original from libgdx repo  fixed support for glsurfaceviewcupcake  note:  i added slight modification to lifecycle of surface view in general.  i have tested it on galaxy s and galaxy s3, but it is not yet as heavy  tested as last implementation (by thousands of my clients on google  play and samsung apps). so this update can repair support for opengl  1.x, but can also destroy it on opengl 2.0.  conflicts:  backends/gdx-backend-android/src/com/badlogic/gdx/backends/android/androidgraphicslivewallpaper.java  backends/gdx-backend-android/src/com/badlogic/gdx/backends/android/androidlivewallpaper.java  merged latest changes of lwpredesign from jwisniewski with latest libgdx, fixed some glu stuff ", "linked_issue_titles": "", "title": "redesigned android live wallpaper backend by jwisniewski"}
{"description": " execute monodevelop from the right appdomain. closes #15454 sometimes stackframe.getmethod() returns null (e.g.: latest frame of a missingmethodexception). still not sure what to do with that frame (maybe skip it), but at least it no longer fails. skip csharplanguage::debug_get_current_stack_info() if an error is printed from gdmonoutils::update_corlib_cache(). fix crash when calling gdmonoutils::print_unhandled_exception(exc) if there is no scriptdebugger attached. ", "commit_messages": " mono: fix starting monodevelop process from the wrong appdomain  mono: some stacktrace to stackinfo[] fixes  - sometimes stackframe.getmethod() returns null (e.g.: latest frame of a missingmethodexception). still not sure what to do with that frame (maybe skip it), but at least it no longer fails.  - skip csharplanguage::debug_get_current_stack_info() if an error is printed from gdmonoutils::update_corlib_cache().  - fix crash when calling gdmonoutils::print_unhandled_exception(exc) if there is no scriptdebugger attached. ", "linked_issue_titles": "", "title": "stackframe and monodevelop crash fixes"}
{"description": " i figured out the problem i was having: it was a problem with the test code and not with the submission. anyway, i cleaned it up a bit (changed floats to real_t). ", "commit_messages": " added rot/pos constructor for matrix32 variant.  implemented interpolation for affine transformations (matrix32::interpolate_with)  changed 'scale' to 'scale_basis' in 'interpolate_with'.  changed floats to 'real_t'. ", "linked_issue_titles": "", "title": "interpolation for affine transformations/bound rot/pos matrix32 constructor"}
{"description": " see #5493 implemented all suggestions, except the extended detection of puya like flash operations. current detection is only to match the vendor id from the flash chip id. ", "commit_messages": " [puya] applied espeasy puya_v3.patch  applied the patch to get the starting point as described in  [puya] only allocate memory when puya detected  core 2.5.0 puya patch, no puya:  description\tfunction\t#calls\tcall/sec\tmin (ms)\tavg (ms)\tmax (ms)  save file\t\t4\t0.25\t34.755\t45.264\t67.620  free mem:\t16168  core 2.5.0 puya patch, faked puya detect:  description\tfunction\t#calls\tcall/sec\tmin (ms)\tavg (ms)\tmax (ms)  save file\t\t2\t0.04\t41.332\t57.544\t73.756  free mem:\t11560  [puya] check for puya chip as soon as possible at boot  check for puya chip in call for getflashchipid()  this will only be done once and the result of the get function is also cached.  [puya] use limited buffer (512 byte) allocated at first write  no need to allocate a buffer when not writing to flash.  the default buffer size is 512 bytes, which is 2 pages in the flash chip.  [puya] lower puya flash buffer to 1 page (256 b)  as discussed here: ", "linked_issue_titles": "", "title": "rewrite puya patch to be more universal and mem friendly."}
{"description": " i made the change you proposed on  i also added a test to ensure the string are being converted into unicode. do you think we need a test to ensure they are correctly translated? force_text should be already tested. ", "commit_messages": " added tests for issue 747 in serializer.py  forcing translations of lazy translatable strings in field to_native method ", "linked_issue_titles": "", "title": "issue 747 lazy strings serialized"}
{"description": " i removed all extension checking code to gl-subsystem.c as it needs to be called on all platforms and does not change given a platform. i added a function and tables to handle opengl debug and error messages via the arb_debug_output extension or via the gl 4.0 api if available. i removed the hardcoded request for a 3.2 context on linux and windows. it will now give the latest context given it fits our requirements (which is just a core profile and debug context if _debug is set currently). snuck in was a change to autoconf that allows autoconf to correctly find wxwidgets 2.9 (or greater) with wx-config (not just wx-config-2.9) without user interaction. ", "commit_messages": " added opengl debug callback support and context changes.  1. we no longer hardcode a 3.2 profile. it chooses the latest profile that fits out description.  2. i added three tables and macros to help with the offsets compared to the variables to help reading. read comments for more info.  3. i added glewexperimental being set. what a dumb \"feature\". it doesn't help anything...  remove enable statements. this should be done in platform-independent code using glew.  added gl_update (does nothing for now).  fix previous commit..  added glx version check and assures context is set to none on failure.  fixed the location glewexperimental was being set to just before glewinit() (where it should be).  minor style fixup  change _debug coverage a bit  i removed gl-specific extension checking to a platform independent file.  i also fixed autoconf to find wxwidgets 2.9 without user intervention  removed unused code and added more organization ", "linked_issue_titles": "", "title": "various changes to opengl intialization"}
{"description": " several plugins were using the stat command to determine modified time in order to determine if cached targets needed to be updated.  this command needed to be different on os/x than on other os's.  using the [ builtin's -nt comparison does this and should be more portable. the phing task also had some regex's that would remove legitimate targets from completion. ", "commit_messages": " use [ -nt ] instead of stat -f%m to check cache files.  allow \":\" and \"-\" characters in phing tasks.  tasks that included hyphens or colons were being excluded from  completion.  this improves the usage for this. ", "linked_issue_titles": "", "title": "improve portability of cache file detection for command targets"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add definitions for dropbox chooser  update typedefs  merge from base repo  remove newline ", "linked_issue_titles": "", "title": "update names and cleanup for dropbox chooser definitions"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see issues referenced in commit messages increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " fix: allow ember.typeof zero-argument case  fixes:  fix: remove outdated ember.string.fmt  fixes:  fix: allow zero-argument usage of ember.isblank, .isempty, .ispresent and .isnone  fixes  fixes  fixes  fixes ", "linked_issue_titles": "", "title": "fix several \"empty check\" function zero-argument cases"}
{"description": " looks like there's an issue setting up the middleman server on windows (\"connection actively refused\") on tests that are run after test_valid_actor_state, mark as flaky for now i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " skip test_wrapped_actor_creation on windows  rerun windows ci  mark test_valid_actor_state_2 as flaky  mark test_valid_actor_state ", "linked_issue_titles": "", "title": "skip test_valid_actor_state tests on windows"}
{"description": " fix a few of the javadoc compiler warnings in jenkins core. ", "commit_messages": " fix javadoc warnings for unknown tags  @sine -> @since  @lnk -> @link  @author: -> @author  make embedded @ sign literal in one case where it is literal  remove trailing extra curly brace from javadoc @see reference  use javadoc @see external url syntax for these external urls  remove empty @see javadoc comment in updatecenter  terminate javadoc @link tags with curly brace instead of right paren ", "linked_issue_titles": "", "title": "javadoc fixes for jenkins core"}
{"description": " function safe_eval ansible version $ ansible --version ansible 2.3.0 config file = configured module search path = default w/o overrides i met this issue when i tried to run test_uri under python 3. in this test, there are some json files downloaded through http (with uri module) and some local json files and at the end of test this two groups of files are compared to each other to check if downloaded files are the same. the problem isn't in the task where the result of uri module is registered as a variable but in the task, where this registered variable with results is used to check. when this registered variable is used in the task for final check, function safe_eval is not capable of evaluating it from yaml template. problem is that under python 2 safe_eval returns dictionary, but under python 3 it returns a string because there is invalid expression exception inside the function. this simple change fixes this problem under python 3. however, this change is in the core part of the code so it should be reviewed. related pr with discussion and more details: #18060 ", "commit_messages": " enable tests on python 3 for uri  added one more node type to safe_nodes into safe_eval module.  ast.usub represents unary operators. this is necessary for  parsing some unusual but still valid json files during testing  with python 3. ", "linked_issue_titles": "", "title": "fix ast nodes for python 3 and enable dependent test_uri"}
{"description": " implemented as in ", "commit_messages": " added test for the html5 progressbar element.  tested in opera [9,10,11], firefox [3.6,4], safari 5, ie[7,8] and chrome [9,10,11]  added test for the html5 meter element.  tested in opera [9,10,11], safari 5, chrome 11, firefox [3.6, 4, 5] and msie 8. ", "linked_issue_titles": "", "title": "added tests for progressbar and meter-element."}
{"description": " supports displaying filament sensor data on either a character 20x4 or graphical lcd.  because nearly all the lcd real-estate is taken the code uses the status area to display the data.  the status will display for 5 seconds, and then be replaced by the data display.  to see the status again, press the knob to select the menu again.  also, if the status message is updated, it will display for 5 sec.  a #define in the config file is used to enable the display. i also added some background explanation to the readme about the filament sensor input. ", "commit_messages": " sync up from my marlin_v1 to filament-sensor  display filament sensor data on 20x4 lcd  changes to support displaying the real-time filament width and the  volume factor on a 20x4 lcd.  the data is displayed on the 4th line.  first the status message is displayed for 5 seconds, and then the  filament data is displayed.  the status message can be seen by  re-selecting the info screen in the menu.  display filament sensor data on graphic lcd  added support to show the filament width on the status line of the  graphic lcd.  the status will show for 5 sec and then switch over to  data.  status can be seen by clicking the button.  added filament sensor to the readme  added some background on the filament sensor to explain it better. ", "linked_issue_titles": "", "title": "display filament sensor data on a 20x4 lcd or graphical lcd"}
{"description": " fixes #74633 this was the indirect cause of  #74633. see that issue for an explaination of why it was problematic.  in summary, updating diagnostics can retrigger code actions even if the user facing diagnostics have not actually changed ", "commit_messages": " don't update js/ts diagnostics if they have not changed  fixes #74633  this was the indirect cause of  #74633. see that issue for an explaination of why it was problematic.  in summary, updating diagnostics can retrigger code actions even if the user facing diagnostics have not actually changed  use every for equals  use array prototype instead of creating instance ", "linked_issue_titles": " blinky lightbulb ", "title": "don't update js ts diagnostics if they have not changed"}
{"description": " this pr changes nothing, it's a bug fix fixed debug draw of scaled circle body in arcade physics ", "commit_messages": " fix debug draw of scaled arcade body  forgot to devide width by 2 ", "linked_issue_titles": "", "title": "fix arcade circle debug draw"}
{"description": " similar to #65353 (which this pr should've been a part of), however in this case we didn't previously nest the tables when processing trait paths in impl block declarations. closes #65411 ", "commit_messages": " save-analysis: nest tables when processing impl items  save-analysis: add a relevant test case ", "linked_issue_titles": " -z save-analysis ice when processing impl under an fn item ", "title": "nest tables when processing impl block definitions"}
{"description": " typo you, your ", "commit_messages": " new page an title  add in outline  build tools  node-install  links and preamble  debian too  update gatsby-on-linux.md  copy edits  copy edits  update gatsby-on-linux.md  typo you, your  update from upstream  update from upstream  typo you, your ", "linked_issue_titles": "", "title": "fix typo on linux docs page"}
{"description": " this pr fixes a pretty interesting bug with the ot internal state i observed twice. the boiler may perform a restart. this might happen because of the power blip, internal watchdog reset, or software bug/feature. ot integration sees this as a timeout, and transitions to the otc_disconnected state and reconnect. on reconnect, ot integration does not send all parameters, such as boiler setpoint or dhw temperature. in my case, this leads to the default dhw temperature and a condition when the boiler is unable to start by the ot_ch 1 or by the heat request signal from the mechanical thermostat. this pr adds a reset logic of the internal state before the handshake. that way all the parameters will be queued for sending after the boiler reset. the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " reset ot protocol internal state on handshake  reset current command pointer ", "linked_issue_titles": "", "title": "reset internal state on handshake"}
{"description": " stubs notifymountaddoncontent, notifyunmountaddoncontent and checkaddoncontentmountstatus used by animal crossing: new horizons v2.0.0 dlc ", "commit_messages": " service: aoc: stub notifymountaddoncontent and notifymountaddoncontent  used by animal crossing: new horizons v2.0.0 dlc  service: aoc: stub notifyunmountaddoncontent  used by animal crossing: new horizons v2.0.0 dlc ", "linked_issue_titles": "", "title": "aoc: stub more 13.x functions used by animal crossing"}
{"description": " nio exposed an issue in the new availability walkers where an implicit check was not being performed. they were able to get this to crash by using a defer statement - the body of which contains implicit declarations that got run through the walker. this exposed a wider hole in availability checking of defer statements. namely, that it wasn't happening. this is a narrow fix (as opposed to the broader fix in #36102) that is safer to take for swift 5.4. rdar://74484150 ", "commit_messages": " revert \"fix a family of crashers in availability checking\"  this reverts commit ae711a7e7628f0309ca1eeb7f4be1655c3f2ad9f.  fix a crash in availability checking of defer bodies  nio exposed an issue in the new availability walkers where an implicit  check was not being performed. they were able to get this to crash by  using a defer statement - the body of which contains implicit  declarations that got run through the walker. this exposed a wider hole  in availability checking of defer statements. namely, that it wasn't  happening.  this is a narrow fix (as opposed to the broader fix in    swift 5.4.  rdar://74484150 ", "linked_issue_titles": "", "title": "narrowly fix a crash in availability checking of defer bodies"}
{"description": " this error is similar to eacces, and is thrown when the tool tries to delete a directory that it does not have permissions for. reuse the existing errror message with minor modifications. ", "commit_messages": " add eperm to list of immediate exit error codes  remvove extra mocks ", "linked_issue_titles": "", "title": "add eperm to set of immediate exit errors"}
{"description": " adds option for prometheus compatible metric exports in all pods under the mongodb-replicaset chart fixes some broken tls chart functionality and allows the metrics exporter to use tls options which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # first pr into kubernetes/charts ", "commit_messages": " replicaset prometheus metrics export  bugfix: fix tls issues  1. moves context of ssl configuration script into /work-dir  where certain files are expected to be created.  2. specifies the --sslmode=requiressl flag on the container command when using tls  as specified by mongo docs.    documentation on metrics options ", "linked_issue_titles": "", "title": "add prometheus exports to mongodb replicaset"}
{"description": " cherrypick the change( #53604) to add no-negcache flag to dnsmasq which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): release note: add --no-negcache flag to kube-dns to prevent caching of nxdomain responses. ", "commit_messages": " add no-negcache flag to kube-dns in kubeadm  add no-negcache flag to kube-dns ", "linked_issue_titles": "", "title": "cherrypick pr#53604 to 1.8"}
{"description": " issued #82 caused me to rethink how atom defines words. the config option editor.nonwordcharacters now determines words. i found it easier to understand and describe what is not a word rather than what is a word. this also changes atom's word movement behavior to match vim's instead of textmates, because i think vim has a better mechanic. ", "commit_messages": " editor.wordregex is now a config option.  cursor.getbeginningofcurrentwordbufferposition behaves like vim  make cursor.movecursortobeginningofword behave like vim  selection.selectword will consider whitespace a word  make editsession specs match vim style word behavior  rename wordseparators to nonwordcharacters  :lipstick:  _ and - both considered non word characters. fixes #82  maybe @defunkt wanted the reverse though (consider _ and - word characters)? either way, it's a config option you can change now. ", "linked_issue_titles": "", "title": "change how atom defines a 'word'"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the first argument of the callback function might be an htmlimageelement. see:  there might be a second argument of the callback function providing the image metadata. see:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " merge remote-tracking branch 'definitelytyped/master'  extended loadimagecallback with metadata argument.  lint.  extended unit test.  cleanup test. ", "linked_issue_titles": "", "title": "enhanced load image callback with metadata argument"}
{"description": " in attempting to use the fakeclient, it seemed that the api group and version was not correct everywhere.  these changes made it so that the generated code for the fake client was usable for flowcontrol. ", "commit_messages": " update api/flowcontrol/v1alpha1 to have correct group and version  update generated code ", "linked_issue_titles": "", "title": "update flowcontrol to have correct group and version everywhere"}
{"description": " this is an aggregate table who's function is to provide a simple place to query all of the known auto-executing programs on a system. it's kept very simple: just name, path and the source table. the goal here is to allow system administrators to get a list of all auto-executing executables on a system with one query, and then use that data to e.g. join with file hashes to check for known malicious files, or to run analysis on to detect outliers or large changes across a fleet. any time a new table is added to osquery for windows that contains auto-executing items, the kautoexectablemappings can be updated to include entries from that table in this one. the goal is for this table to keep growing as we add more windows tables, for example browser extensions. ", "commit_messages": " adding autoexec table  adding impl ", "linked_issue_titles": "", "title": "adding autoexec table for windows"}
{"description": "", "commit_messages": " cube/char_bigrams: fix some memory leaks  coverity report:  cid 1164717 (#1 of 1): resource leak (resource_leak)  10. leaked_storage: variable upper_32 going out of scope leaks  the storage it points to.  cid 1164718 (#1 of 1): resource leak (resource_leak)  10. leaked_storage: variable lower_32 going out of scope leaks  the storage it points to.  cube/char_samp: fix some memory leaks  coverity report:  cid 1164722 (#9 of 9): resource leak (resource_leak)  20. leaked_storage: variable label32 going out of scope leaks the storage  it points to. ", "linked_issue_titles": "", "title": "fix issues reported by coverity scan"}
{"description": " a bunch  of small code optimizations and trying to reduce header dependencies by using forward declarations. some important includes were missing, which was found by other changes not part of this pr (those will be submitted soon as well). why is this change required? -> not required, but nice to have. kodi has been running with these commits for two days (using gbm on intel nuc). bug fix (non-breaking change which fixes an issue) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document (i couldn't yet figure out how to run the tests. all tests fail, even without my commits and i have no idea why.) ", "commit_messages": " guilib/guimessage: make the class \"final\"  nobody derives from this class.  this removes some overhead and  clarifies the role of this class.  guilib/guimessage: don't override copy constructor/operator  the implementations auto-generated by the c++ compiler are better than  that and less fragile.  guilib/guibasecontainer: use std::list for cguilistitemlayout  this reduces the overhead, because resizing the std::vector will  create lots of temporary cguilistitemlayout copies.  a std::list never  needs to move its items.  these lists are very small, so the overhead for iterating it is  negligible, but copying a cguilistitemlayout (which is not movable) is  very expensive because a rather large tree of objects needs to be  copied.  guilib/guibasecontainer: forward-declare class cguilistitemlayout  reduce header dependencies and speed up the build.  guilib/guilistitemlayout: make \"final\"  nobody derives from this class, and most instances are managed in a  stl container, where polymorphism is impossible.  this removes some  overhead and clarifies the role of this class.  guilib/guilistgroup: make class \"final\"  eliminate some overhead because this is a leaf class.  guilib/guicontrol: use forward declarations  reduce header dependencies and speed up the build.  guilib/guicontrol: use emplace_back() instead of push_back()  eliminate temporary instance.  guilib/guivisualisationcontrol: add missing includes ", "linked_issue_titles": "", "title": "various guilib optimizations and include cleanup"}
{"description": " this commit adds some clean up logic to esresttestcase so that searchable snapshots indices are deleted after test case executions, before the snapshot and repositories are wipe out. backport of #73555 ", "commit_messages": " [7.x] delete mounted indices after in searchable snapshots yaml tests  revert \"[7.x] delete mounted indices after in searchable snapshots yaml tests\"  this reverts commit 885b187685ee39da9aae0d22619f51792aee8467.  add wipesearchablesnapshotsindices  adjust version  of course  found the culprit  ifs ", "linked_issue_titles": "", "title": "delete mounted indices after test case in esresttestcase"}
{"description": " empty .gitignore files have been added for no reason, and we lost some empty but useful directories (read: \"that will be used later on\") during the git migration. ", "commit_messages": " remove unwanted .gitignore files.  add .keep guard files in order to restore lost but empty directories we had with svn.  note that when you start populating these directories, you can remove the associated .keep guard file(s)! ", "linked_issue_titles": "", "title": "fix svn to git migration"}
{"description": " closes #23865 closes #27075 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff new tests addeded #23865 #27075 both reported that when df.groupby was called and by was set to more than one pd.categorical column, that any missing categories were not returned, even when observed=false. this issue was fixed in #29690. this pull request adds tests to make sure that this correct behaviour is enforced by tests. new bug found testing did reveal one further issue: dataframegroupby.count() returns nan for missing categories, when it should return a count of 0.  seriesgroupby.count() does return 0, which is the expected behaviour. i have raised an issue for this bug (#35028 ) and marked the test with an xfail. when the bug is fixed, the xfail will cause the tests to fail, and the xfail can be removed. existing test changed as it had the wrong expected result a similar issue was reported for .sum() in #31422: missing categories return a sum of nan when they should return a sum of 0. there was a mistake on the existing test for seriesgroupby.sum(), as it said the expected output was nan (see below) when it should have been 0. pandas/pandas/tests/groupby/test_categorical.py line 1315 0159cba (\"sum\", np.nan), i have changed this so that the expected output is 0 (this is inline with the comment here: #31422 (comment) ) and marked the tests for .sum() with xfail. when the bug is addressed, the xfail will cause the tests to fail, and the xfails can be removed. ", "commit_messages": " tests for dataframe.groupby with 2 categoricals  black ", "linked_issue_titles": " inconsistant behaviour of empty groups when grouping with one vs. many  groupby ignores unobserved combinations when passing more than one categorical column even if observed=true ", "title": "add test to ensure that df.groupby() returns the missing categories when grouping on 2 pd.categoricals"}
{"description": " refactor renaming leftovers: \"data frame transform\" to \"transforms\", touch only internals (variable names, non-public api's, doc strings, ...) and apply code-formatting (spotless). no logical changes. ", "commit_messages": " rename leftovers from data frame transforms to transforms  apply code formatting ", "linked_issue_titles": "", "title": "refactor naming leftovers and apply code formating"}
{"description": " reapply 5b35750, which was reviewed in #12700 artificially pin the linter package at 0.1.35 due to dart-lang/linter#824 (see yjbanov@50a4cf5) ", "commit_messages": " revert \"revert \"fix --force-upgrade script; upgrade to the latest package versions (#12700)\" (#12729)\"  this reverts commit 7f0d4f4caae30d20670a8f3272fa1c70170ace8a.  keep linter pinned at 0.1.35 ", "linked_issue_titles": "", "title": "reapply #12700 but keep linter pinned at 0.1.35"}
{"description": " # app ### event: 'certificate-error' returns: * event event * webcontents [webcontents](web-contents.md) * url url * error string - the error code * certificate object * data buffer - pem encoded data * issuername string * callback function emitted when failed to verify the certificate for url, to trust the certificate you should prevent the default behavior with event.preventdefault() and call callback(true). # session ### session.setcertificateverifyproc(proc) * proc function sets the certificate verify proc for session, the proc will be called with proc(hostname, certificate, callback) whenever a server certificate verification is requested. calling callback(true) accepts the certificate, calling callback(false) rejects it. calling setcertificateverifyproc(null) will revert back to default certificate verify proc. close #3330. ", "commit_messages": " add delegate for atombrowserclient  rename select-certificate to select-client-certificate  add certificate-error event  add session.setcertificateverifyproc  docs: update the certificate apis ", "linked_issue_titles": "", "title": "rework of the certificate api"}
{"description": " this pull request will fix #5785. add a file_identifier that i forgot to include use t.finishtbuffer() for each class instead of flatbuffersbuilder.finish(). and add a test to ensure that the file_identifier exists. ", "commit_messages": " use finish***buffer instead.  add file_identifier test. ", "linked_issue_titles": "", "title": "add file identifier to objectapi serialization utility."}
{"description": " since we're adding another target that i believe will require more customization in the future and i think our strategy of just using sed was getting too messy, i've added a new preprocessor which tries to follow the ff preprocessor( also, i added a new build target generic which builds the generic production version of pdf.js.  this is basically the contents of our old web build target.  i mainly did this because now the file build/pdf.js is not preprocessed since it needs to be preprocessed differently by each main build target. for testing, i built all the targets and compared them to the current build output.  everything still needs verification though. ", "commit_messages": " initial build for b2g.  add the new preprocessor.  update the readme to reflect build changes.  remove trailing whitespace.  fix mozcentral build. ", "linked_issue_titles": "", "title": "add b2g build and new preprocessor."}
{"description": " category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation this is pretty minor, but just something i noticed while looking around. since superset uses fontawesome, we can replace a custom component with custom svg by using a simple fontawesome image. we should probably upgrade to fontawesome 5 at some point... many more toys in that toybox! before: after: reviewers @graceguo-supercat / @mistercrunch note: this doesn't change any functionality, but as far as i can tell, that button doesn't have functionality in the first place, or at least nothing happens when i click it. is it for future use, or am i missing something? ", "commit_messages": " replaced!  added role to the fa image/button ", "linked_issue_titles": "", "title": "filter edit icon component replaced with font awesome"}
{"description": " the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. add it to notneededpackages.json. ", "commit_messages": " fixed \"text\" type in iinstruction  i don't believe that the text property should be a number, and when i changed it to a string in a personal project it worked perfectly.  [@types/leaflet-routing-machine] fixed \"text\" type in iinstruction interface.  merge  added 3.2.12 version compatibility  fixed typing bugs  lint errors are fixed  typescript support version is upgraded ", "linked_issue_titles": "", "title": "brings the type definition up to date with its js library version 3.2.12"}
{"description": " original pull-request #25045 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix  better way  odbc fix ", "linked_issue_titles": "", "title": "cherry pick #25045 to 21.5: odbc fix"}
{"description": " #75570 identified that %#v can be expensive, and more specific formatters can be easier to debug in some cases. adjust some relatively core errors to use %t or %s instead. ", "commit_messages": " avoid using %#v for errors when using only a portion of the object  %#v may have significant performance costs in frequently invoked code.  avoid using %#v for errors when %t is clearer  %#v may have significant performance costs in frequently invoked code.  avoid using %#v for errors when %t or %s would be more accurate  %#v may have significant performance costs in frequently invoked code.  avoid using %#v for errors when %t is more informative  %#v may have significant performance costs in frequently invoked code. ", "linked_issue_titles": "", "title": "remove use of %#v in frequently accessed code"}
{"description": " this pr fixes the long-running tests by making the bootstrapping process in the python test scripts use eosio rather than eosio.token as the issuer in order to avoid an inline transfer during issue which would fail when the restrict_action_to_self protocol feature is activated. also the bios contract has been updated to reflect the latest changes in the eosio/eosio.contracts#220 pr which rename the action to pre-activate a protocol feature from preactivate to activate. the rename required changes to unit test and python test frameworks as well as the protocol_feature_tests/double_preactivation unit test. ", "commit_messages": " fix long-running tests given restrict_action_to_self protocol feature changes  use updated bios contract that renames preactivate action to activate; adjust tests and testing utilities accordingly ", "linked_issue_titles": "", "title": "fix tests in forced-replay branch; use updated bios contract"}
{"description": " this pr sets up a common project for preview pane powertoy. the common project would include interface and com object required to write a preview pane handlers. pr checklist applies to #914 cla signed. if not, go over here and sign the cla additional comments added stylecop.json from /src/codeanalysis/stylecop.jsonto common project ", "commit_messages": " added project template for common library  added reference to stylecop.json  fixed xml documetation file path for common project  added reference to stylecop.json ", "linked_issue_titles": "", "title": "setup common project preview pane"}
{"description": " issue: #542 #549 #739 description: implement use_container_width in charts and deprecate height and width properties with a warning ", "commit_messages": " first implementation for vega_lite charts  implement use_container_width to other charts  implement use_container_width in all charts  fix tests  restore examples ", "linked_issue_titles": "", "title": "improve sizes handling for charts"}
{"description": " pr intends to add support for higher order gradient for logp1, expm1, square. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira-978 issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change higher order gradient for a logp1, expm1, square. unit test for the same. ", "commit_messages": " support logp1, expm1, square for higher order grad  add relevant tests ", "linked_issue_titles": "", "title": "higher order gradient support logp1, expm1, square."}
{"description": " currently, if a postgres table contains a record with a binary field and this record is fetched from the db, an exception is raised if the binary data is nil. this bug is due to the fact that the unescaping of the column value is passed directly to pgconn without checking for nil. pgconn#unescape_bytea does a check on the value type and raise an exception if the value isn't a string. this pr adds tests around the binary type (currently no tests exist), and a fix for the mentioned bug. ", "commit_messages": " added a test suite for the postgres binary type  this shows a problem with nil values  fix for the bytea/binary nil value bug ", "linked_issue_titles": "", "title": "ar postgres binary bug fix"}
{"description": " when i first read the output, i spent a lot of time to understand these numbers to match them. now, words along with the ids clearly show what's going on in the sample data and prediction pairs. sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] 3084 originated -> 12 as 3084 originated -> 5239 anarchism 12 as -> 6 a 12 as -> 3084 originated 6 a -> 12 as 6 a -> 195 term 195 term -> 6 a 195 term -> 2 of sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'] 3084 -> 5239 originated -> anarchism 3084 -> 12 originated -> as 12 -> 3084 as -> originated 12 -> 6 as -> a 6 -> 195 a -> term 6 -> 12 a -> as 195 -> 6 term -> a 195 -> 2 term -> of ", "commit_messages": " added words to clearly show word ids and corresponding words together.  now, they clearly show  what's going on in the sample data and prediction pairs.  [new output]: clearly shows the word ids and corresponding words  sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']  3084 originated -> 12 as  3084 originated -> 5239 anarchism  12 as -> 6 a  12 as -> 3084 originated  6 a -> 12 as  6 a -> 195 term  195 term -> 6 a  195 term -> 2 of  [old output]: no words for sample data. word ids and words are mixed, so it's very hard to read  sample data [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156] ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']  3084 -> 5239  originated -> anarchism  3084 -> 12  originated -> as  12 -> 3084  as -> originated  12 -> 6  as -> a  6 -> 195  a -> term  6 -> 12  a -> as  195 -> 6  term -> a  195 -> 2  term -> of  changed it to two space ", "linked_issue_titles": "", "title": "word2vec basic show id and word together"}
{"description": " fixes #8688. see also #8700 (should be closed). in feature_extraction (.text) module there's no validation of ngram_range property for the following vectorizers : class hashingvectorizer(baseestimator, vectorizermixin, transformermixin) class countvectorizer(baseestimator, vectorizermixin) class tfidfvectorizer(countvectorizer) for example we can init a vectorizer that extracts n-grams in this range: 2 >= n >= 1, which doesn't make sense. following @jnothman guidelines on #8688 i added a private function in vectorizermixin and called it on relevant fit/transform functions of hashingvectorizer and countvectorizer (tfidf implements same fit/transform), tested all of the three. the function vectorizermixin.build_analyzer() is the one relying on ngram_range. call to it can be found in hashingvectorizer.transform() and on countvectorizer.fit_transform()/transform() which also uses vectorizermixin.build_analyzer()  through countvectorizer._count_vocab() ", "commit_messages": " added test for vectorizers invalid ngram_range  added ngram_range validation for countvectorizer and hashingvectorizer fit/transform funcs  moved validation call on countvectorizer.transform to be earlier  fixed pep8 warnings ", "linked_issue_titles": " no error on countvectorizer(ngram_range=(2, 1)) ", "title": "fix validation of ngram_range property in vectorizers"}
{"description": " some key codes were forgotten. most of this happened in firefox browser. they included some alphabet letters in persian and arabic. the key codes are as follow: semicolon_firefox: 59 colon: 58 comma_firefox_windows: 60 comma_firefox: 62 bracket_right_firefox: 174 bracket_left_firefox: 175 ", "commit_messages": " + forgotten keycode (firefox)  + add forgotten keycode (firefox in windows) ", "linked_issue_titles": "", "title": "add forgotten keycode and letters"}
{"description": " games that use the depth test will most likely draw a black screen until depth clearing is implemented. see #609 ", "commit_messages": " gpu: implemented the z24s8 depth format and load the depth framebuffer.  gpu: added registers for depth test and cull mode.  maxwelltogl: added conversion functions for depth test and cull mode.  gpu: set up the depth test state on every draw. ", "linked_issue_titles": "", "title": "implemented the depth buffer and depth test + culling"}
{"description": " we currently put all tooltips in a textblock which is unnecessary and moreover breaks word wrapping logic fixes #5625 microsoft reviewers: open in codeflow ", "commit_messages": " use string object for tooltips instead of textblocks since that breaks wordwrap etc  change files ", "linked_issue_titles": " rnw implementation of tooltips causes text truncation ", "title": "fix word-wrapping behavior of tooltips"}
{"description": " adds support for cv_32fc1 and cv_32fc4 to cuda morphology filter. this mostly extends exiting cv_8u implementation. thanks. ", "commit_messages": " implement 32f support for morphology operation  update docs for 32f support in morphology operation ", "linked_issue_titles": "", "title": "cv_32fc1 and cv_32fc4 support for cuda morphology filter"}
{"description": " i hereby agree to the terms of the cla available at:  changelog category: ", "commit_messages": " print correct error message in log for unknown settings in users.xml  add test for custom settings in users.xml ", "linked_issue_titles": "", "title": "correct error message if setting not found in users.xml"}
{"description": " closes #13865 menulist now supports the use of home and end keys, changing focus to the first and last listitem. i have followed (at least) the pr section of the contributing guide. ", "commit_messages": " add home and end keys to be handled in meathod handlekeydown  added support for home and end keys in menulist  added two tests for menulist home and end key functionality ", "linked_issue_titles": "", "title": "add home and end key support"}
{"description": " stash application should stage new files, even when we're not updating the index. c:\\temp\\stash_apply_sucks>git status on branch master changes to be committed: (use \"git reset head <file>...\" to unstage) new file:   bar modified:   foo c:\\temp\\stash_apply_sucks>git stash saved working directory and index state wip on master: 4a6df6d foo head is now at 4a6df6d foo c:\\temp\\stash_apply_sucks>git status on branch master nothing to commit, working directory clean c:\\temp\\stash_apply_sucks>git stash apply on branch master changes to be committed: (use \"git reset head <file>...\" to unstage) new file:   bar changes not staged for commit: (use \"git add <file>...\" to update what will be committed) (use \"git checkout -- <file>...\" to discard changes in working directory) modified:   foo what a sensible architecture this is.  so we need to do the same thing.  we break the actual iterator walking code out of merge to create a new index that has just the new files, which we will set as the new repo's index (unless the user actually specified that they wanted to restore the index). ", "commit_messages": " stash apply: add a newly staged file to tests  stash: don't allow apply with staged changes  iterator: provide git_iterator_walk  provide git_iterator_walk to walk each iterator in lockstep,  returning each iterator's idea of the contents of the next path.  stash: stage new files when unstashing them  files that were new (staged additions) in the stash tree should  be staged when unstashing, even when not applying the index. ", "linked_issue_titles": "", "title": "stage new files even when not updating the index"}
{"description": " fixes #1640 you can now change the entire data object of the chart and then call update and the chart will work. the line sample has been update to test this behaviour. note to whomever reviews this: please test all chart types before merging. ", "commit_messages": " reference data from the main controller wherever possible. updated tests to account for this.  update line sample to change the entire data object ", "linked_issue_titles": "", "title": "can now replace entire chart data object on the fly"}
{"description": " bug fixes apis added type and value checks for parameter \"shape\" in static graph, when passing \"shape\" to function \"fill_constant()\". bugs are described as below: ", "commit_messages": " fixed bugs  fixed bugs  some modifications have been made in branch junhui_dev, now i have to update from upstream develop before push ", "linked_issue_titles": "", "title": "fixed bugs for 2.0 api"}
{"description": " this moves the rollup cleanup code for http tests from the high level rest client into the test framework and then entirely removes the rollup cleanup code for http tests that lived in x-pack. this is nice because it consolidates the cleanup into one spot, automatically invokes the cleanup without the test having to know that it is \"about rollup\", and should allow us to run the rollup docs tests. part of #34530 ", "commit_messages": " wip  fix position  rework  preserve rollup jobs more places  fixup ", "linked_issue_titles": "", "title": "consolidate rollup cleanup for http tests"}
{"description": " this change refactors the goroutine filter parsing from the terminal package into service/api so it can be shared by the terminal client and the dap server. this supports setting goroutine filters using the launch configuration. ", "commit_messages": " service/dap: filter goroutines  adjust defaults  add tests  remove label change ", "linked_issue_titles": "", "title": "support goroutine filters in dap"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #38772 upon first doing this challenge the test messages did not indicate the specified string was not matching. this small modification is to redirect the user to carefully compare their string with those indicated in the instructions. ", "commit_messages": " changed tests messages to indicate string  minor tweak with wording of message ", "linked_issue_titles": " test error message does not indicate wrong string ", "title": "fix/curriculum en es6 complete a promise - modified test messages to be more clearer"}
{"description": " since the multi-root workspace file contains settings/launch configs we need to factor it in workspace trust: factor in the directory storing the workspace file into calculating workspace trust set workspace trust when saving the workspace file if the folders are trusted ", "commit_messages": " do not check untitled workspace files  trust folder when saving workspace file  trust folder when saving workspace file  fix merge conflict ", "linked_issue_titles": "", "title": "workspace trust - multi-root workspace file"}
{"description": " this applies similar fixes to those in #5133 to the rest of the ui forms after #5133 and this pr are merged, all ui forms in the project should now open in qt creator/designer and resave without any entries being shuffled around or clobbered before this change, the changed qwidgets in the form files are not properly shown in qt creator, only their associated layouts are displayed and their qwidget properties are not accessible or shown. these widgets will also get completely removed upon saving. after these changes, the items are properly listed in the qt creator hierarchy. qt creator/designer is the primary method for building ui forms and all our form files should open and save without creating unnecessary history changes all forms have been compared against v27.0.1 to ensure they still get laid out the same at various sizes code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " ui: clean up settings form markup  this continues work from #5133 to correct ui file markup and save correctly in qt creator  defining alignment as an attribute in the <item> tag seems to be old behaviour that current versions of qt creator do not respect and will clobber these entries on save.  the correct approach is to have alignment as a property element in the widget.  as well, qwidgets that contain property definitions as well as a layout child item do not properly show up in the qt creator hierarchy.  these properties are still invisibly applied but the qwidgets are not shown in qt creator and will get removed from the file after saving.  ui: clean up toolbar form markup  ui: clean up autoconfig form markup  ui: clean up about form markup  ui: clean up filters form markup  fixes some qwidgets that qt creator tries to clobber. as a result, there are a couple spacers added now for the toolbars to align properly and a stretch policy on the main layout.  this re-adds the native attribute for the obsqtdisplay that was removed in #3782. i believe this particular removal was an error, and there is no way around this entry being native since obsqtdisplay extends qwidget  ui: clean up interact form markup  this re-adds the native attribute for the obsqtdisplay that was removed in #3782. i believe this particular removal was an error, and there is no way around this entry being native since obsqtdisplay extends qwidget  ui: clean up transform form markup  fixes some qwidgets that qt creator tries to clobber. as a result, there is a new spacer added now to ensure the controls remain grouped at the top of the window.  ui: clean up custom browser docks form markup  minor alphabetical rearrange by qt creator  ui: clean up importer form markup  minor alphabetical rearrange by qt creator  ui: clean up missing files form markup  minor alphabetical rearrange by qt creator  ui: clean up remux form markup  minor alphabetical rearrange by qt creator  ui: clean up update form markup  small whitespace fix ", "linked_issue_titles": "", "title": "clean up other ui form file markup"}
{"description": " when i was reading the online readme i missed this syntax cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc due to it being preceded by the note. i've rearranged the instructions for clarity. thanks for all that you do! ", "commit_messages": " improve formatting of step 2 for clarity  make the note an optional for improved instructions ", "linked_issue_titles": "", "title": "modify readme to clarify the manual way"}
{"description": " add comments documenting set_axis_is_at_home and homeaxis output \"a\" and \"b\" for scara axes in stepper::report_positions improve probe position output in log_machine_info use const args in set_current_from_steppers_for_axis and probe_pt specify 8-bit integers for extrapolate_one_point args other minor comment/spacing adjustments ", "commit_messages": " document set_axis_is_at_home  document homeaxis  patch sync_plan_position comment  stepper::report_positions patch  set_current_from_steppers_for_axis const arg  fix nozzle position description  tweak extrapolate_one_point  adjust comments, spacing  use const ref args in probe_pt ", "linked_issue_titles": "", "title": "some comments, const args, debug output tweaks"}
{"description": " references #14216. this finalizes the work on pr #19375 replaces the use of assert_raises* with pytest.raises in model_selection/tests/test_split.py #dataumbrella cc: (pair programming partner) @cycks ", "commit_messages": " replace assert_raises* by pytest.raise in model_selection/tests/test_split  ensure line 1391 and 1399 in the previous commit are not longer than 79 characters  tst use correct indenting style in test_split.py ", "linked_issue_titles": "", "title": "tst replaces assert_raises* by pytest.raises in model_selection/tests/test_split.py"}
{"description": " link to jira issue:  description above provides context of the change commit message starts with [airflow-6430], where airflow-nnnn = jira id* unit tests coverage for changes (not needed for documentation changes) commits follow \"how to write a good git commit message\" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. (*) for document-only changes, no jira issue is needed. commit message starts [airflow-xxxx]. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. ", "commit_messages": " [airflow-6430] - add tests for patch_table method  [airflow-6430] - add tests for run_extract method  [airflow-6430] - add tests for get_tabledata method  [airflow-6430] - add tests for run_table_delete method  [airflow-6430] - add tests for run_table_upsert method  [airflow-6430] - add tests for run_grant_dataset_view_access method  [airflow-6430] - add tests for get_dataset_tables_list method ", "linked_issue_titles": "", "title": "bigquery hook - add tests for bigquerybasecursor"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ", "commit_messages": " update index.d.ts  add missing functions to definition  add missing validation functions to definition and tests.  update json-schema-tests.ts  fix spaces ", "linked_issue_titles": "", "title": "add missing functions to json-schema definition"}
{"description": " the current code mix two different naming convention to define the name of the interface and class, which looks strange. this pr proposes to use \"taskassigner\" as the interface name and \"taskassignerimpl\" as the implementation class name. all relevant variable names have been renamed appropriately. ", "commit_messages": " merge ray master  rename interface and class for task assigner based on suitable pattern. ", "linked_issue_titles": "", "title": "rename the interface and class for task assigner based on suitable naming convention"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " finished accessibilityfeatures  removed old declaration for extensions only according to the docs  updated definitions of chrome.runtime  updated chrome.app.window typings  added missing docs to chrome.bluetooth  chrome.bluetoothlowenergy wip  added missing typings in chrome.filesystem  relocate webview methods  webview typings fixed and doc updates. tests updated.  set added types under window to optional  updated typings on some objects ", "linked_issue_titles": "", "title": "refined and more proper webview element types"}
{"description": " extension of #228. clarifies some of the language. allows for \"\"\"\\ as opening delimiter for multi-line basic strings. renames \"raw string\" to \"literal string\". ", "commit_messages": " add multiline and raw strings to toml.  refine spec for the four string variants. ", "linked_issue_titles": "", "title": "add mult-line and literal strings"}
{"description": " @rafaelks here are a few additions for the mobile apps. once you find out more information regarding the oauth items i will start working on getting them added. closes #7775 4f3c9d4 closes #7765 fb04102 closes #7764 fb04102 closes #7763 ae87222 /api/v1/channels.messages?roomid=general&query={ \"pinned\": true } closes #7762 ae87222 /api/v1/channels.messages?roomid=general&query={ \"starred._id\": { \"$in\": [\"${userid}\"] } } closes #7761 1914d7a closes #7760 25792e6 closes #7770 ae3f821 closes #7241 ae3f821 closes #7262 ae87222 in addition to the items above, direct message endpoints no longer require a user to know the room's id. instead you can now pass the query parameter username to the endpoints and it will assume you mean a direct message conversation between the authenticated user and the username provided. ", "commit_messages": " add the channels/groups/im.files endpoint  add a messages endpoint which supports pagination like the other endpoints. rework the direct messages endpoints to support username instead of room id  allow pinning, unpinning, starring, and unstarring via the rest api  fix #7775, return the unread properties  add rest api endpoints to list members in a channel  fix a few issues related to the integrations.  1. process_incoming_request can now return falsey (null, undefined, 0, false, etc) and nothing will be sent to the channel  2. integrations can post messages to channels without the user being in them (direct messages, etc)  3. users can't brute force check if a room exists by successfully sending a message there ", "linked_issue_titles": " [bug] posting messages via api as non member to private rooms or read only channels  cannot create direct message room via api  [rest api] members list  [rest api] files list  [rest api] starred messages list  [rest api] pinned messages list  [rest api] star a message  [rest api] pin a message  webhook: process_incoming_request: unable to skip/ignore requests without error (400) (#7374 re-open)  get unread message via rest api for rocket.chat ", "title": "additions to the rest api"}
{"description": " continues work on #3283 ", "commit_messages": " adjusts inline text state presentation for a11y  adjusts specificity of main content links  adjusts blockquote color scheme  temporarily unhides catastrophic css overrides  reverts text-decoration add  makes hash-link always visible  adds underline for topnav hover/focus/active ", "linked_issue_titles": "", "title": "docs rebuild - improves accessibility of topnav links and hash links"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " removing prompt verbage from selection binding options  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  adding a link to the search options article ", "linked_issue_titles": "", "title": "adding a link to the word search options details page"}
{"description": " this commit series essentially brings back dvb channel switching. basically, the commit messages contain everything, and i tried to be mostly atomic in my commits, but here a short summary (which sadly got almost as long as the summary of the commit messages): some refactoring to allow checking options for updates as suggested by @wm4 in #6781 . this also cleaned up the option mess in stream_dvb by finally keeping them cleanly in a separate struct. more refactoring, since stream_dvb accepts some configuration via the stream-uri and also via config parameters. now, the logic is in one place, and config parameters (if set) always win (e.g. you can finally set a program by name via dvbin-prog as expected!). polling the options for changes. done in streaming_read for lack of a better place, with a throttling since there's no need to react too fast. adding dvbin-channel-switch-offset. since the channel list is dynamically chosen depending on connected and selected adapters, and there is no communication backchannel, we now have a property to select the offset from the initially chosen channel. documentation updates! a user can now for example put this: h cycle dvbin-channel-switch-offset up k cycle dvbin-channel-switch-offset down q set dvbin-prog \"zdf hd\" in input.conf, and switch channels by pressing h and k, or tune to zdf hd explicitly by pressing q. channel switching also got a bit faster again due to some cleanups. comments, suggestions and a review very welcome. i am especially unsure if the throttling is really needed, or if there is a better place to poll. ", "commit_messages": " stream_dvb: use separated out options struct.  this also allows the use of m_config_cache_alloc  which allows to watch config updates.  stream_dvb: factor out logic to determine program and card.  this is now treated in dvb_parse_path consistently  instead of logic scattered over various functions.  this is a requirement to sensibly re-evaluate config  after options have been changed, since we have two ways  to configure the stream (decorated uri and config parameters).  stream_dvb: move stream->is_on initialization to state preparation.  notably, this allows to call dvb_streaming_start more than once,  simplifying e.g. channel switching.  also, get rid of unused timeout variable. ", "linked_issue_titles": "", "title": "bring back dvb channel switching"}
{"description": " unify @iycheng and @architkulkarni 's prs to use common code for parsing runtime_env. this is an incremental step towards the full runtime_env spec in  followups: replace working_dir / working_dir_uri with files. unify env vars vs job_config for specifying runtime config ", "commit_messages": " fix  wip ", "linked_issue_titles": "", "title": "incremental refactor of runtime_env for consistency"}
{"description": " this cl will add the ability to add a bottom to the search bar. related issues working example: cl/338056388 associated to b/170283545 i added a check for existence in search_test.dart before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. yes, this is a breaking change. if not, delete the remainder of this section. i got input from the developer relations team, specifically from: rami-a ", "commit_messages": " added bottom to search app bar  add test for bottom in search appbar ", "linked_issue_titles": "", "title": "add bottom to search bar"}
{"description": " description: this pr adds basic support for hue lightgroups. currently, storing lights in a group in hass causes hass to send multiple api calls when turning on or turning off, therefore, the lights don't turn on/off simultaneous. when sending the request to a group, the lights will turn on/off simultaneous. the new hue app doesn't provide a ui to create groups, but the old one does. also, some light fixtures (like philips hue beyond) have multiple light sources that are combined in a group automatically. there are still a few things worth mentioning: the api to get a group returns a any_on and all_on. i've used the any_on, since that mimics the current behaviour of a group in hass. the group api provides a state of a (random) single light in the group (in the action dict). by using this, you can control a group in the interface ui as if it would be one light. also, there is still a issue that i don't know how to solve: turning on/off a group doesn't update the state of the individual lights of that group in the ui, however, the update_lights() is executed and lights and lightgroups arrays are modified. i don't know how i can tell hass to update the state of the entities. related issue (if applicable):  pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " add support for hue lightgroup entity  don't filter on lightgroup and add properties for a group ", "linked_issue_titles": "", "title": "add support for hue lightgroups"}
{"description": " fixes #81314 this pretty much just changes the span highlighted in the lint from pat_sp to ident.span. there's however an exception, which is in patterns with shorthands like point { y, ref mut x }, where a suggestion to change just x would be invalid; in those cases i had to keep the pattern span. another option would be suggesting something like point { y, x: ref mut _x }. i also added a new test since there weren't any test that checked the unused lint with optional patterns. ", "commit_messages": " use identifier's span in unused lint  bless some tests  add regression test ", "linked_issue_titles": " span is too large for unused `rest @ ..` pattern warning ", "title": "highlight identifier span instead of whole pattern span in unused lint"}
{"description": " super minor tweaks to some icons (removing shadow outside of the colored areas, according to icon guidelines) adding the missing files for mouse highlighter and find my mouse to installer file linked issue: #14702 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " updated docs images  updated docs images  updated icon files  update product.wxs ", "linked_issue_titles": "", "title": "minor icon fixes and adding missing files to installer file"}
{"description": " updated tests with flag introduced in #6959 printing git info to deterministically identify commit the tests are run on. ", "commit_messages": " [hotfix] printing remote, branch, commit hash that is being tested  [flink-10678] disabled log checking in tests that fail jobs on purpose ", "linked_issue_titles": "", "title": "disabled log checking in tests that fail jobs on purpose 1.5-e2e"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. this pr adds some cypress tests for the /lean page. related to #38611 ", "commit_messages": " add tests for quotes on /learn  add tests for superblocks and blocks ", "linked_issue_titles": "", "title": "add e2e tests for /learn"}
{"description": " fixes #44153 (from 1.23.0) fixes #47486 (from 1.36.0) fixes #48010 (from 1.38.0) fixes #48027 (from nightly) fixes #48638 (from nightly) ", "commit_messages": " add test for issue-44153  add test for issue-47486  add test for issue-48010  add test for issue-48027 ", "linked_issue_titles": " rustc panic (reprise)  trait with associated function with \"where self:sized\" cannot be made into an object and results in compiler bug.  ice: unknown layout  ice: encountered ambiguity selecting `binder(<[type error] as bar>)` during trans, presuming due to overflow  `repr(packed)` triggers internal compiler error ", "title": "add some tests for fixed ices"}
{"description": " original pull-request #24870 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " add a test for materialized(distributed()) with join and group by  removejoin: remove joined columns  do not try convert columns that does not exists in materialized view  do not try convert columns that does not exists in the result block  convert 01890_materialized_distributed_join to .sh for explicit database for join  minor style changes in storagematerializedview::read, storagemerge::createsources ", "linked_issue_titles": "", "title": "fix \"missing columns\" exception when joining distributed materialized view"}
{"description": " this pr fixes a few of the issues with the latest update to the sandbox. first, it lowers the number of users in each aggregate session so there is no longer a warning from relay. second, it reduces the number of individual sessions that are sent which should help with the time it takes to create a demo org. finally, it makes the crash free rate better reflect the thresholds that are set. this pr also allows for the quick demo generation parameters to be an override instead of a copy of the \"normal\" generation parameters. grw-176 and grw-175 ", "commit_messages": " changed thresholds for crashing  sandbox fixes  tech changes  sandbox fixes ", "linked_issue_titles": "", "title": "fixes crash free rates and relay warning in sandbox"}
{"description": " actually fixing a quic stream limit issue.  also fixing an unrelated bug with clean stream shutdown occasionally causing spurious stream-close writes to a closed connection. risk level: high (changing connection pool limits) testing: new integration test docs changes: n/a release notes: n/a platform specific features: n/a fixes #18160 ", "commit_messages": " wip  quic: (mostly) fixing stream limit bug  quic: fixing stream limits bug ", "linked_issue_titles": " envoy crash when test http3 upgrade ", "title": "fixing the disconnect between quiche stream count and envoy"}
{"description": " noticed while working on #14400 that the optional catch-all handling was missing in namedregex. this whole file also seemed quite regex heavy so i took a look at the overall logic and changed a few things. it worked by regex escaping the whole route then unescape the dynamic parts. i changed it to only regex escape the static parts, this eliminates unnecessary back and forth escaping. it also makes the dynamic parts handling more readable. the whole logic is less reliant on regexes and just uses simple string manipulation to translate the route into a regex, i didn't measure anything but as an effect this should make it more performant. ", "commit_messages": " decode param before parse  wip  don't mutate in map ", "linked_issue_titles": "", "title": "update route regex for optional catch-all parameters in named regexes"}
{"description": " added network response checks to all curl http calls and all git clone calls. ", "commit_messages": " amazon: added status checks on all http and git requests, on error notified user and exit  amazon: minor changes to errors messages on git clone ", "linked_issue_titles": "", "title": "eosio build amazon network response checks"}
{"description": " during gsoc i extended smartplaylist rules to support implicit oring within a single rule and field. for that i added the possibility to select multiple values from the list of possible values for a browsable field. out of caution i removed the possibility to manually type into the value control of a browsable field because the user needs to follow a certain syntax to be able to specify multiple values which result in implicit oring. while this makes sense for operators like \"is\" and \"is not\" it doesn't make any senses for \"starts with\", \"ends with\", \"contains\" and \"does not contain\" where the user usually doesn't provide a fully matching value. therefore we need to allow manual typing in the value control. these changes add that functionality back. the syntax to define multiple values for implicit oring is to seperate the values by \" / \" (the spaces are mandatory because some scrapers e.g. provide genres like \"thriller/suspense\"). if the user has manually typed a value which does not match any actual value and then uses the \"browse\" button to view a list of available values, none of the values is pre-selected and selecting a value from the list results in the loss of the previously entered value. ", "commit_messages": " csmartplaylistrule: remove unneeded parameters in getlocalizedrule() and getparameter()  csmartplaylistrule: add setparameter() methods  cguidialogsmartplaylistrule: allow manual typing of the value of a browsable field ", "linked_issue_titles": "", "title": "restore possibility to type in the value field of a smartplaylist rule for browsable fields"}
{"description": " the example didn't wait for the runtime to be ready - i guess it was from back when synchronous startup was the default? i rewrote the example to use modularize. also it was missing an export of ccall. also rename extra_exported_runtime_methods to exported_runtime_methods as the \"extra_\" is no longer needed. ", "commit_messages": " fix node example. fixes #11314  nicer  fix ", "linked_issue_titles": "", "title": "fix node example in docs. fixes #11314"}
{"description": " fixed technical typo in plot_weighted_samples.py fixed a typo that said \"class weights\" when it meant \"sample weights\" which is an important technical difference. ", "commit_messages": " update plot_weighted_samples.py  fixed a typo that said \"class weights\" when it meant \"sample weights\" which is an important technical difference  fixed technical typo in  plot_weighted_samples.py ", "linked_issue_titles": "", "title": "doc fixed technical typo in plot_weighted_samples.py"}
{"description": " added phantom solder pcb variant and upcoming kbd8x hs pcb variants. for phantom solder, did not include multiple layout options as via is the expected use case. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " added config for phantom solder all layout via only  fixed matrix def  added kbd8x  changed info name ", "linked_issue_titles": "", "title": "added phantom solder pcb and kbd8x hs pcb variants"}
{"description": " do not mutate alpha in the render target (useful for transparent render targets). make non-lit behavior consistent with lit. ", "commit_messages": " masked mode now leaves destination alpha intact.  this prevents strange behavior with semi-transparent render targets,  which the model viewer team discovered when testing against the khronos  alpha test conformance model.  add mask smoothing to the unlit path. ", "linked_issue_titles": "", "title": "two fixes for masked blending mode."}
{"description": " steps towards getting rid of _silgen_name altogether, which is generally unsafe and not something we're interested in supporting in its current form. i left out dispatch and foundation for now because those have code owners active in the swift project. the \"platform\" overlay (darwin/glibc) has also been exempted for now because i didn't want to poke at any low-level import dependencies. there are a few downsides to all this: these headers get installed along with the shims even though they're only used to build the overlays, and only on apple platforms. i or someone else should go back later and split these new shim headers into their own folders with their own module maps. add separate cmake targets for each one, for better dependencies. don't install the headers on irrelevant platforms. overall, though, i think this is a safety and simplicity win. ", "commit_messages": " [sdk] use swiftprivate to remove _silgen_name from the appkit overlay.  [sdk] use an extra shim header to remove _silgen_name from xctest.  [sdk] use an extra shims header to remove _silgen_name from the os overlay.  [sdk] use perform(_:with:) to remove _silgen_name from gameplaykit.  this does require a dummy protocol for now; hopefully we can take it out  later.  [sdk] use existing ns_refined_for_swift to remove _silgen_name from scenekit.  [sdk] use an extra shim header to eliminate _silgen_name from objectivec.  [sdk] use an extra shim header to remove _silgen_name from safariservices.  [sdk] use an extra shims header to remove _silgen_name from the xpc overlay.  [sdk] fix circularity issues with overlay shim headers.  loading a clang module eagerly brings in overlays for anything it re-exports,  but this is a problem for these new \"shim header\" modules, which generally  import the underlying module for an overlay and are in turn imported by the  overlay. that means that when we try to import an overlay, we'll end up with  a circular reference before it's done loading all its dependencies. break the  cycle by not exporting anything from these modules, which are mostly just an  implementation detail anyway. ", "linked_issue_titles": "", "title": "remove _silgen_name from all apple overlays except dispatch and foundation"}
{"description": " the download-dashboards container has no option to set environment variables. this change allows variables to be set for proxies. dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " [stable/grafana] add env values for download dashboard images  [stable/grafana] update docs ", "linked_issue_titles": "", "title": "add env vars for download dashboard container"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. all the files i changed are in the same world language (for example: only english changes, or only chinese changes, etc.) my changes do not use shortened urls or affiliate links. new pr, the original is here #34797 ", "commit_messages": " fix(challenges): update challenge text and assertion test  fix(challenges): update assert test regex  fix(challenges): update regex, fix inline comment in code example ", "linked_issue_titles": "", "title": "fix/remove property references and update tests"}
{"description": " closes #12689 closes #9232 closes #6051 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " tst: test for 6051 read_csv with multiindex columns  tst: test for #9232  tst: tests for needs-test issues #12857, #12689 ", "linked_issue_titles": " bug: read multi-index column csv with index_col=false borks  bug: dataframe constructor incorrect with series input depending on name  err: invalid error reporting when comparing vs. none ", "title": "tests for needs-test issues #12857 #12689"}
{"description": " this pr addresses these github issues: #2709 - box3 class specification (axis aligned bounding box) #2708 - sphere class specifications #2706 - plane class specifications #2715 - vector3.minself, maxself - simplifies bounding box calculations in various places. the new classes work and i integrated them into both frustum.js and geometry.js. in integrating box3 and sphere into geometry for boundingbox and boundingsphere respectively, i did so in a way that didn't change the javascript data structures used -- there is still a radius on boundingsphere and there is still min/max on boundingbox.  it is just that these two member properties (boundingbox and boundingsphere) are now proper classes. i have made an effort to copy the existing style in threejs with naming conventions as well as code organization.  i believe these classes look like they belong in threejs. code reviewed by @chandlerprall (via irc) and @wvl (off list) ", "commit_messages": " implement box3.js and add to common.js - issue #2709  implement plane.js, add to common.js and update frustum.js to use it instead of vector4 - issue #2706  implement sphere.js class, add to common.js - issue #2708  improvements as a result of code review by @chandlerp  simplify sphere.js via use of vector3.distanceto*(), minimize code in plane.js  proposed vector3.minself, maxself - issue #2715  plane,box3,sphere improvements: static constructors, code simplficiation, optimizations.  box3 made more robust via true empty (+max_value,-min_value).  minor cleanup of box3 class + no longer modifying input parameter in clamppoint.  adopt sphere.js and box3.js in geometry.js.  polishing box3, plane and sphere.  change box3, plane and sphere declarations from frustum.js-style to vector3.js-style.  move away from static fromxxx-style constructors to setxxx style member functions widely used in threejs.  nickname consistency.  bug fixes.  all examples now run while using box3, sphere and plane. ", "linked_issue_titles": "", "title": "polished box3, sphere and plane classes for threejs/core"}
{"description": " some tests in windows may randomly take up to 5s, increasing to 10s. better name test results with its source job. @arcanis can you integrate this in your pr? let me know if you see any other blocker. we're also looking into fastening up these tests, ", "commit_messages": " increase timeout in windows, we're seeing tests failing randomly and others close to default 5 sec.  distinguish tests published from each job.  pass name as vmimage is not available  remove unnecessary detect unfinished tests.  using strategy var instead of parameter  use variables instead of strategy ", "linked_issue_titles": "", "title": "increase windows timeouts and better name test results"}
{"description": " this is a pretty obvious typo in retrospect. never hit it before, because in all non-defterm windows, the _startupactions always has one action. closes #11463 ", "commit_messages": " oh you gotta be  great cool these weren't needed ", "linked_issue_titles": " defterm window will not accept command palette *commandline mode* commands ", "title": "fix the wt action in defterm windows"}
{"description": " the older algorithm was pretty inefficient for big matches. fixes #29227. (on my computer, mir construction on this test case goes from 9.9s to 0.025s.) whereas before we had a loop like: for all outcomes of the test we are performing for all candidates check whether candidate is relevant to outcome we now do: for all candidates determine which outcomes the candidate is relevant to since the number of outcomes in this case is proportional to the number of candidates, the original algorithm turned out to be o(n^2), and the newer one is just o(n). this pr also does some minor speedups by eagerly mirroring all patterns, so that we can just pass around &pattern<'tcx>, which makes cloning cheaper. we could probably go a bit further in this direction. r? @aatch ", "commit_messages": " remove the mirroring for patterns and just convert them eagerly; then,  pass around references instead of boxed values to save on clone costs.  clone the candidates and match-pairs lazilly, instead of eagerly.  reorganize match construction to be o(n) instead of o(n^2). whereas  before we iterated over the test and each outcome thereof, and then  checked processed every candidate against this outcome, we now organize  the walk differently. instead, we visit each candidate and say \"here is  the test being performed. figure out the resulting candidates for each  possible outcome and add yourself into the appropriate places.\"  add regression test for #29227. ", "linked_issue_titles": "", "title": "change match desugaring in mir to be o(n) instead of o(n^2)"}
{"description": " two small improvements of compiler/rustc_lint/src/types.rs ", "commit_messages": " rustc_lint: remove unused to_string  in this instance, we can just pass a &str slice  and save an allocation.  make {u,}int_range functions a bit nicer  .into() guarantees safety of the conversion.  furthermore, the minimum value of all uints is known to be 0. ", "linked_issue_titles": "", "title": "fix two small issues in compiler/rustc_lint/src/types.rs"}
{"description": " my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add a command to format json files  change to work after rebase ", "linked_issue_titles": "", "title": "add a qmk format-json command that will format json files"}
{"description": " this one takes care of all the remaining methods that made use of the @_with_element decorator. primarily widgets, but also some miscellaneous remaining elements. one possible thing we could do differently is to namespace widgets somehow so it's more clear which of these return values and which do not, e.g. perhaps placing them in the streamlit.widgets.foo module  instead of streamlit.elements.foo i think we'll wait until a future part 4 to rename delta_generator to something that makes sense. but taking suggestions in the meantime! fixes #1765 ", "commit_messages": " extract _iframe and _html  extract audio and video  _pb2 to proto, part trois  fix typo while extracting video  extract checkbox, multiselect, select, radio  extract time_input, date_input, text_input, and text_area  extract empty and progress  extract number_input ", "linked_issue_titles": " documentation - api should not list element as a parameter. ", "title": "splitting up delta_generator, part 3!"}
{"description": " we merged the symbol and gen_sym argument as one now. i think we can delay bucketing support for predict as it seems the applications that need bucketing typically have their own customized predicting implementation. both char-rnn and neural translation do sampling at prediction time. ", "commit_messages": " refactoring: merge symbol argument with sym_gen in feedforward  update doc on gen_sym ", "linked_issue_titles": "", "title": "merge gen_sym with symbol argument in feedforward"}
{"description": " fixes #6731 -add test case for ruleschemametadata ", "commit_messages": " add more test case for hintmanager (apache#6712)  add more test case for hintmanager (apache#6712)  fixed the grammar errors  fix the test bug  delete hintmanager.close  add test case for ruleschemametadata(apache#6731)  revert \"delete hintmanager.close\"  this reverts commit c42e5303 ", "linked_issue_titles": " add test case for ruleschemametadata ", "title": "add test case for ruleschemametadata(#6731)"}
{"description": " adds shared module support for writing modules that work with cisco nexus devices over nxapi ", "commit_messages": " add initial support for cisco nxapi  this commit adds the shared module support for cisco nxapi.  the shared  module builds on top of the urls shared module.  the urls module provides  the http/s transport.  this module only supports the json request message  format.  fixes conditional statement for py24 compatibility  changes the nxapi argument spec to require url_password ", "linked_issue_titles": "", "title": "initial shared module support for nxapi"}
{"description": " returns a struct of libfeature and reduces to a single api call querying of compile-time features. followup on api comments on #13549 @szha please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " prototype for runtime feature detection  includes from diamond to quotes  add cpu feature and blas flavour flags  add blas flavour and cpu sse and avx flags  mxnet_use_lapack  fix c++ linting errors  expose runtime feature detection in the public c api and in the python api  refactor storage -> featureset  refine documentation  add failure case  fix pylint  address cr comments  address cr comments ", "linked_issue_titles": "", "title": "addresses comments in runtime feature discovery api"}
{"description": " this adds support for several features of chromium's logging system that were previously not exposed in electron. in particular: it's now possible to send chromium logs to a file. this can be done either by passing --log-file=.../path/to/file.log along with --enable-logging. passing --enable-logging=file without --log-file will send logs to a default path, electron_debug.log in the user-data directory. this is particularly relevant on windows, on which os it is not possible to collect log messages from child processes when logging to stderr. electron_enable_logging=[1|file] is equivalent to passing --enable-logging / --enable-logging=file electron_log_file=.../path/to/file.log is equivalent to passing --log-file=.../path/to/file.log we now support --log-level=n to set the minimum level of log messages printed. it's now possible to enable logging from javascript, if done in the first tick. logging switches added by app.commandline.appendswitch() will be read immediately after the first run of js. cc'ing @electron/wg-api npm test passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: added support for directing chromium logging to a file with --log-file=.../path/to/file.log. also, it's now possible to enable logging from javascript by appending command-line switches during the first js tick. ", "commit_messages": " feat: support electron_log_file environment vars.  adds support for two new environment variables, electron_log_file and  electron_log_level. if either of these is used, electron_enable_logging  is implied.  docs: document electron_log_file envvar ", "linked_issue_titles": "", "title": "bring --enable-logging functionality in line with chromium"}
{"description": " because v1/v0 message formats do not expect a header, ignore their presence when down-converting v2 messages that contain headers. added a test-case to verify down-conversion sanity in presence of headers. ", "commit_messages": " kafka-6739: when down-converting from v2 to v0/v1, broker must ignore any header present in the record.  added a test case to verify sanity when down-converting records containing headers.  add comment. ", "linked_issue_titles": "", "title": "ignore the presence of headers when down-converting from v2 to v1/v0"}
{"description": " split from #24768 retry-after is broken for post/put, and a very common retry behavior for service account api tokens not yet being available exposed that we don't tell clients to retry when a retry error is sent. @wojtek-t re: load failures ", "commit_messages": " allow statuserrors to be modified after creation  have the service account controller force retry  service account controller, when api token not found, now sends 500 with  retry-after: 1s. also change the apiserver to actually write the error.  print more data about an error for debugging  sometimes clients send unintelligible data to the server, provide a bit  more debugging in the returned error to make it easier to pin down where  the problem is from the user side.  reset input buffer on retry  retries were previously sending empty bodies to the server. ", "linked_issue_titles": "", "title": "fix the retry-after code path to work for clients, and send correct bodies"}
{"description": " with this pr we improve typing of the single-parameter bind method in --strictbindcallapply mode such that generic functions and overloaded functions are more accurately typed (i.e. we improve typing of calls to bind that bind just this and none of the function's parameters). previously, bind always erased type parameters and propagated only the last overload signature. now, when calling the single-parameter bind method on a function that has no explicitly declared this parameter (which turns out to be >99% of all observed uses of bind), we simply propagate the function type itself, thus preserving generics and overloads. the pr introduces two new conditional types in lib.d.ts: thisparametertype<t>: extracts the type of the this parameter of t, or 'unknown' if t has no 'this' parameter. omitthisparameter<t>: removes the 'this' parameter from t. if t has no explicitly declared this parameter, the result is simply t. otherwise, a new function type with no this parameter is created from t. generics are erased and only the last overload signature is propagated in this new function type. fixes #28582. fixes #28900. ", "commit_messages": " improve typing of 'bind' method on function types  accept new baselines  fix findallreferences for 'this' parameter declarations  update fourslash list of global types ", "linked_issue_titles": "", "title": "improve 'bind' typing in --strictbindcallapply mode"}
{"description": " extend s3 unit tests and fix regex that distinguishes between host and path based bucket references #4254 ", "commit_messages": " extend s3 unit tests to test whether uris are correctly distinguished between host and path style reference  fix the following issues with the regex to distinguish between path and host style s3 bucket references: 1) any host style reference with a key did ot match, 2) {expr}*.localhost always a match, 3) {expr}*.s3.{region} did not match  make edge.py use the existing util method instead of re-implementing the regex match itself  extend s3 unit tests with tests that distinguish between host and path style references  make edge.py use the existing util method instead of re-implementing the regex match itself  fix the following issues with the regex to distinguish between path and host style s3 bucket references: 1) any host style reference with a key did ot match, 2) {expr}*.localhost always a match, 3) {expr}*.s3.{region} did not match  extend s3 unit tests to test whether uris are correctly distinguished between host and path style reference ", "linked_issue_titles": "", "title": "s3 reference style detection fixes"}
{"description": " quick @cptspiff - before someone changes the projects :d tested on osx/ios/linux ", "commit_messages": " [cosmetic] - fix identation  [paplayer] - use dvdplayercodec for airtunes streams - now that we have the demuxer (thx gimli!!) - so we can get rid of bxacodec.cpp/.h  [bxacodec] - get rid of the now obsolete bxacodec ", "linked_issue_titles": "", "title": "remove bxacodec and use dvdplayercodec instead"}
{"description": " why invert colors? when using flameshot in dark environments on a regular basis it would be very useful to invert the colors in the capture, making the screenshot white(ish) background and dark text. thus, enhancing the usability of those screenshots in reports and prints without having to use additional tools or workarounds. also, it's been a feature request for quite a while (#689). how does it work? basically, i copied the savetool and made an inverttool, that inverses all pixels before saving the screenshot. the actual consists of four lines: qpixmap inverted = context.selectedscreenshotarea(); qimage img = inverted.toimage(); img.invertpixels(); inverted.convertfromimage(img); however, it turned out that flameshot requires to update quite a few places in order to add a tool. without much of a documentation i tried to stay close to how the savetool is setup. before merging i'd advise that someone with a way better understanding of this project looks at my modifications in order to spot potentially missing or even unnecessary code for this new tool to be integrated. example see the above mentioned issue for a video demo. here's a screenshot of the newly added button. usage after choosing the area and drawing markers, text, arrows etc. - use ctrl+i or the invert button to save the screenshot with inverted colors. notes this isn't a perfect solution. people might want to invert colors while still drawing stuff or see a review of the inversion before saving the capture. additionally, more filters could be added maybe (comment by @mmahmoudian). however, my qt knowledge isn't by far good enough to be able to help with those things. from my point of view, this invert tool is a good solution for the time being and could still be extended at a later point. alright, that's it - let me know if i missed something or should update anything. ", "commit_messages": " add invert tool to build commands  add icons for invert tool  integrate invert tool  add shortcut for invert tool  add invert tool  add translation for invert tool  run clang-format ", "linked_issue_titles": "", "title": "add a tool to take an inverted screenshot"}
{"description": " this pr expands the additional check in #37195 to also cover intersections with generic constituents. fixes #36637. ", "commit_messages": " consolidated extra property check with intersections  fix comment  add tests ", "linked_issue_titles": " when merging a generic object type with new optional properties, these properties are not type checked ", "title": "extra check in assignment of intersections with generic constituents"}
{"description": " the proposed pull request updates the definitions to conform to jquery.cookie version 1.4.1. since this library is deprecated and moved here, this should be one of the last pull requests for jquery.cookie. even though jquery.cookie was deprecated in favour of a jquery-less version, it's still beneficial for definitelytyped to have the most up to date definitions of it, since it is still heavily used. the only required addition was for the defaults property, which allows users to set defaults for cookie options.  jsdoc documentation was also added for all properties and methods.  this enables intellisense for editors that support. the jsdoc documentation uses snippets of documentation from the official jquery.cookie github repo as much as possible. the test file was also updated to test the defaults property. ", "commit_messages": " updated for version 1.4.1, jsdoc documentaiton  updated jquery.cookie.d.ts to conform to the latest version of jquery.cookie (1.4.1). this meant adding a defaults property to the jquerycookiestatic interface.  also added missing jsdoc documentation for better intellisense for editors that support it. the documentation uses the github repo documentation where possible.  updated to test new defaults property ", "linked_issue_titles": "", "title": "updated for version jq cookie v1.4.1, added jsdoc documentation"}
{"description": " this pr contains multiple commits; please look at the commit messages. make test-cmd what=kubeadm executes into a /hack rule that sources a /test/cmd script function that executes code in /cluster and then the result of the /cluster call is passed as a flag to an \"integration\" test in cmd/kubeadm/test . tempted to pull some git blame on this one, but let's leave it a mystery. fascinating... this is now simplified to make test-cmd executes a /hack/ rule that sets an environment variable and runs the same integration tests. unwanted scripts are deleted. also kubernetes/kubeadm#1383 is fixed by using another environment variable. open to alternative ideas on this one, but i don't see what else is possible...and this is for dry-run so... apply other minor cleanups to the tests too. fixes kubernetes/kubeadm#1383 does this pr introduce a user-facing change?: ", "commit_messages": " remove /cluster/kubeadm.sh and /test/cmd/kubeadm.sh  /cluster/kubeadm.sh is used to find the kubeadm binary.  this file is legacy and is removed.  remove /test/cmd/kubeadm.sh. this file contains a function that is used  to build kubeadm and invoke \"make test\". move the function contents  to hack/make-rules/test-cmd.cmd.  stop sourcing /test/cmd/kubeadm.sh in /test/cmd/legacy-script.sh.  also remove the --kubeadm-path invocation as this can be handled  with an env. variable directly.  cmd/kubeadm/test/cmd: refactor _test.go files  make getkubeadmpath() fetch the kubeadm_path env. variable.  panic if it's missing. don't handle the \"--kubeadm-path\"  flag. remove the same flag from the build bazel test rule.  don't handle \"--kubeadm-cmd-skip\" usage of this flag is missing  from the code base.  remove usage of \"kubeadmcmdskip\" as the flag \"--kubeadm-cmd-skip\"  is never passed.  kubeadm-init: allow overriding the dry-run temp directory  allow overriding the dry-run temporary directory with  an env. variable (kubeadm_init_dryrun_dir).  use the same variable in test/cmd/init_test.go.  this allows running integration tests as non-root. ", "linked_issue_titles": " tests are not passing with unprivileged user ", "title": "cleanup the kubeadm integration tests and related scripts"}
{"description": " allow calc() to specify a distance in the rasi format. for example: width:  calc(100%-10px); width: calc((100%-10em)/2); supports +-/*%. fixes: #1088 ", "commit_messages": " initial test to allow math in distances.  support + and -  needs spaces around + and -.  [theme] fix printing theme with math in distance.  [theme] use calc() syntax.  [theme] add * and /  to calc().  [theme] fix the precedense ordering in parsing. also avoid making copies.  [theme] don't print unneeded ().  [theme] add modulo to calc. ", "linked_issue_titles": " ability to combine distances in rofi theme files [request] ", "title": "add calc() support to distance in theme format."}
{"description": " description: update sound mode list and current sound mode only on main_zone to avoid xml parse errors related issue (if applicable): fixes #16724 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " add support for sound_mode for yamaha rxv media_player  catch parseerror exeption on surround_program for unsupported models  catch all exeptions from rxv  only get sound mode list / current sound mode on main_zone ", "linked_issue_titles": " yamaha rxv zone_2 not working anymore after update to 0.78.0 ", "title": "yamaha avr update and change sound mode only on main_zone"}
{"description": " description: as is, an error gets thrown when turn_on is called without an hs value. by adding an if statement, we only try to set rgb if an hs value is applied. related issue (if applicable): fixes #13519 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " handle turn_on situation when no color is set  as is, an error gets thrown when turn_on is called without an hs value. by adding an if statement, we only try to set rgb if an hs value is applied.  handle turn_on situation when no color is set ", "linked_issue_titles": " flux led/magiclight - unable to change brightness ", "title": "fix flux_led error when no color is set"}
{"description": " the keyboard manager editor allowed setting \"alt (left)\" -> \"alt\" and \"alt (right)\" -> \"alt\". this would make it so that when these were combined when opening the editor, they would be combined to \"alt\" -> \"alt\" and the editor would crash trying to present the error flyout. what is include in the pr: three changes related to this crash: 1 - don't combine the modifier keys to the combined key. 2 - catch the exception when trying to show an unavailable flyout when loading the window. 3 - don't allow the user to make mappings such as \"alt (left)\" -> \"alt\" or \"alt\" -> \"alt (left)\". verify that before you could set up \"alt (left)\" -> \"alt\" and \"alt (right)\" -> \"alt\" and it would crash the kbm editor if you saved and then try to reopen. after having that configuration saved, verify that the window no longer crashes when you try to open kbm editor. linked issue: #12978 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries ", "commit_messages": " [kbm editor] don't combine keys to same key  avoid crashes when flyouts can't be shown yet  disallow mapping of left or right key to combined ", "linked_issue_titles": "", "title": "fix crash when mapping left and right modifier to the combined key."}
{"description": " what do these changes do? a worker that is assigned a task and blocked in a ray.get should release its resources to allow another task to run. without this, with the following task, you cannot have a recursion deeper than the number of cores available: def recurse(i): if i == 0: return i return ray.get(recurse.remote(i - 1)) this is similar to #286, but for the raylet. ", "commit_messages": " [xray] throttle task dispatch by required resources  pass in number of initial workers into raylet command  workers blocked in a ray.get release resources ", "linked_issue_titles": "", "title": "workers blocked in a ray.get release their resources"}
{"description": " description: update upstream library to 0.10.7 adds hmip-miob the two main switches can be controlled (implemented) the two digital input channels cannot be read due to missing value in upstream lib the analog output can not be controlled (range of 0-10v) (not implemented, could be implemented in a follow up pr) pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#9190 checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly (example). new dependencies have been added to requirements in the manifest (example). new or updated dependencies have been added to requirements_all.txt by running ", "commit_messages": " update upstream dependency  add two switches ", "linked_issue_titles": "", "title": "add device hmip-miob to homematic ip cloud"}
{"description": " adding integration test class for stored procedures. providing a sql file to add stored procedure to mysql database. ", "commit_messages": " added sql file to insert stored procedures in the mysql database  added sql file to insert stored procedures in the mysql database  removed sql file, to move to resources folder  added named queries to foo model  added foo stored procedures tests  update readme.md - added link to stored procedure article ", "linked_issue_titles": "", "title": "bael-63 - add stored procedures with hibernate tests"}
{"description": " this is a spinoff of #48130 that generalizes the proposal to allow early termination with the composite aggregation when leading sources match a prefix or the entire index sort specification. in such case the composite aggregation can use the index sort natural order to early terminate the collection when it reaches a composite key that is greater than the bottom of the queue. the optimization is also applicable when a query other than match_all is provided. however the optimization is deactivated for sources that match the index sort in the following cases: multi-valued source, in such case early termination is not possible. missing_bucket is set to true i retained the commit from #48130 and merged the original idea that @howardhuanghua described in the pr to early terminate even when the sort is reversed in the leading source. ", "commit_messages": " optimize composite aggregation by index sorting  fix long ling issue  enhance comment  fix a reset issue  enhance test case  add reverse order test case  remove extra test case  adapt optimization to handle more than one leading source when index sort is applicable.  add index sort uts. ", "linked_issue_titles": "", "title": "optimize composite aggregation based on index sorting"}
{"description": " failure to create the suspend.target transaction probably doesn't happen in practice.  however it can be triggered simply by masking suspend.target.  i would aspire to not lock the user out of the system if they try to test suspend failure this way.  also fix the error case to handle cleanup for scheduled shutdown.  and scheduled shutdown needs to send preparetoshutdown in the first place, so we fix that first (in the previous commit). similarly, logind normally blocks suspend during shutdown, and vice versa.  but scheduled shutdowns failed to block suspend.  fix that first. (scheduled shutdown is a bit of mess.  i'm sure systemd-shutdown was simpler.  i don't see why it had to be replaced, but i don't want to drop the api at this point either). ", "commit_messages": " logind: remember to remove '/run/systemd/shutdown/scheduled'  logind: method_schedule_shutdown() already rejects empty type  don't test for an empty type afterwards.  this is not how you cancel  scheduled shutdowns - there's a separate method for that.  logind: add missing check for conflicting operation v.s. scheduled shutdown  > we don't want to shutdown while a suspend is running, and vice versa.  > this would be confusing and could lead to data loss in the worst case.    according to the above comment, if the conflicting operation is hung,  we don't want to force things when the admin has not passed a force option.  similarly if you're not an admin, you probably shouldn't get to sneak  around this check by using a scheduled shutdown instead of an unscheduled  one.  (and no-one so far thought it necessary to add such a permission in  polkit).  note that if the conflicting operation was _not_ hung, and we lost the  race with suspend, the system might not have shut down at the scheduled  time anyway.  which is no good if you were scheduling a power outage.  and scheduling a shutdown for an arbitrary time when the system is resumed,  does not seem a very useful semantic.  more likely, scheduled shutdowns are  useful on systems which do not use suspend, such as multi-user servers.  (in which case even polkit defaults likely don't let the users trigger  suspend).  logind: respect \"delay\" inhibitors in scheduled shutdowns  there is no justification not to wait an extra (default) 5 seconds, for  a more graceful shutdown of user programs.  again, you don't get to ignore  delay inhibitors for unscheduled shutdowns, short of  systemctl poweroff -f.  it is simplest if we move the test for m->shutdown_dry_run into  manager_scheduled_shutdown_handler().  however we need to not add such delays during a \"dry run\".  otherwise, we  would still have to be considered \"in progress\" for some seconds after our  admin has seen the final wall message.  if they go to poweroff, we would  have blocked them with a misleading error message.  note this poweroff  will still process delay inhibitors as needed.  if the admin planned to  use a more forceful method... eh.  it's their responsibility to assess  whether that's safe.  there is an argument that the alternative behaviour could be used (racily!)  to kludge around them not being able to shutdown to \"single user mode\".  if  we cared about that case, we would have easily preserved non-racy support  for it in shutdown.  additionally, though i think this code does read more easily by reducing  inconsistencies, we didn't come up with any use case for delay inhibitors  v.s. shutdown.[1]  the sigterm v.s. sigkill delay is more general, and we  allow a whole 90 seconds for it, not just 5.  so i don't think keeping this  approach bears a risk of significant damage.  [1]  logind: add missing resume signal when we fail to initiate sleep/shutdown  this fixed  as much as i was able to reproduce it in a vm, at least.  e.g. this signal might wake the screen back up, providing a more visible  indicator of suspend failure.  in my vm testing, it was also required in  order to unblock keyboard input in gnome-shell after the failed suspend.  at the same time, fix the error handling for scheduled shutdowns.  this now  mirrors the behaviour of when you use shutdown -k - it sends all the  scary messages about shutting down, \"but you'll have to do it [shut down  the system] yourself\".  it also avoids the risk of locking out the admin  (nologin file), in case they logged out for some reason (and they use  sudo instead of root).  not that i have any idea why you'd want to use shutdown -k, but the code  is easier to analyze if it rolls back on error (in the absence of any code  comment as to why that's not wanted). ", "linked_issue_titles": "", "title": "add missing resume signal when we fail to initiate sleep (and shutdown)"}
{"description": " fixes #267 the calculator currently only accepts exponential numbers like 2323e+12 and 23241e-12. the calculator should also accept 2323e12 or 334.232e12 in the scientific mode. modify the regex used to check exponentials modify onpaste(string^ pastedstring, viewmode mode) to accept exponentials without signs. add unit tests unit tests + manual testing in english, french and spanish. before/after ", "commit_messages": " add exponential without sign support  add unit tests  fix formatting  remove extra spaces ", "linked_issue_titles": " the calculator should accept exponential numbers without sign in scientific mode ", "title": "accept exponential numbers without -/+ sign."}
{"description": " these tests cover corner cases that were without test coverage on tornado/httputil.py there are just 2 lines in this file without test coverate yet: import doctest doctest.testmod() when __name__ == '__main__' is this feature still needed? considering now that tornado has unit tests and 'tornado.httputil.doctests' function is covered on runtests.py? ", "commit_messages": " add test to parse_multipart_form_data() on httputil when \"boundary\" parameter has quotes  add test to parse_multipart_form_data() when missing headers  add test to parse_multipart_form_data() when invalid content-disposition  add test to parse_multipart_form_data() when line does not end with the correct line break (\\r\\n)  add test to parse_multipart_form_data() when no \"name\" parameter is found ", "linked_issue_titles": "", "title": "add more tests to httputil.py"}
{"description": " correctly incref an intance's type. currently, if a heap-allocated type creates an instance through pyobject_{,gc}_new{var}, the type won't incref. this adds a change to pull the incref to the core pyobject_init{init} function to correctly incref heap-allocated types. this now means that heap-allocated types that add a custom tp_dealloc, should decref the instance types - just like the default tp_dealloc does. currently there are 10 heap-allocated types in cpython: pycursespanel_type in _curses_panel.c sslerror_type in _ssl.c example_type in _testmultiphase.c str_type in _testmultiphase.c tkapp_type in _tkinter.c tktt_type in _tkinter.c pytclobject_type in _tkinter.c xxo_type in xxlimited.c str_type in xxlimited.c null_type in xxlimited.c struct sequences in structseq.c out of those only the following 5 types allocate instances through pyobject_{gc}_new{var}: pycursespanel_type. action: added a decref in its tp_dealloc tkapp_type. action: removed the manual incref after allocation. tktt_type. action: removed the manual incref after allocation. pytclobject_type. action: removed the manual incref after allocation. xxo_type. no action: it inherits the default tp_dealloc which already decrefs the type. struct sequences. action: removed decref the type in the deallocation function. ", "commit_messages": " add incref to heap-allocated type objects  added news ", "linked_issue_titles": "", "title": "incref heap-allocated types in pyobject_init"}
{"description": " this is useful when it's possible to end iteration before scanning all headers, such as searching for a the first of a particular header. reverse iteration is useful for searching for the last of a particular header, and is used to reduce the number of headers processed when parsing out a cookie value. ", "commit_messages": " make headermap::iterate exit early  this is useful for things like searching for cookies, where it is  reasonable to break early.  support reverse iteration over a header map  should be helpful for cases where the last header sent overrides  previous ones.  use headermap reverse iteration to find cookies ", "linked_issue_titles": "", "title": "make headermap iteration exit early and add reverse iteration"}
{"description": " #39105 removed the normal unit testing from ci in favor of bazel, but the staging repos don't have build files in them because bazel choked on it.  this meant that unit tests weren't being run in ci (even though make test did it).  this restores the staging tests. @ixdy @spxtr since you were on the initial issue @liggitt @kubernetes/rh-cluster-infra thanks to @cheftako for finding it. ", "commit_messages": " fix up broken tests  restore unit testing for the staging repos ", "linked_issue_titles": "", "title": "restore unit testing for staging repos"}
{"description": " @rocketchat/core @twizzydizzy see #6144 comment by twizzydizzy we do not want passwords to be saved in mongodb when ldap is enabled (this might be made into an option in the backend, if not, they should not be saved by default) unless fallback-login is activated this means the passwords need to be erased (for ldap-flagged accounts) on disabling fallback login and stored on next login, when this feature is enabled this pr changes the password storage behaviour if ldap_login_fallback is enabled. the password will not be saved in mongodb. ", "commit_messages": " do not store password if ldap_login_fallback is off  restore whitespace ", "linked_issue_titles": "", "title": "do only store password if ldap_login_fallback is on"}
{"description": " i've been reading the book and noticed a few small grammatical and stylistic issues which i've rolled into this pull request. i'm not sure if i should do so many small, unrelated edits in a single pull request but it seems like a lot of overhead for each small edit. maybe one commit per edit but one pull request per file/section? feedback is very much appreciated as this is my first pull request ever! r? @steveklabnik rollup ", "commit_messages": " fixed backquotes and awkward borrowing clause  \"errors with\" is idiomatic in english  \"also ... as well\" is redundant  also \"to access\" is cleaner than \"for accessing\"  many small grammatical and stylistic changes  grammatical: \"here's\" should be \"here are\", \"rules\" is plural.  stylistic: \"rules for\" is more idiomatic than \"rules about\".  grammatical: no verb in \"one or the other\"; changed to \"it's one or the other\".  code: added implied fn main() { ... } because it is referenced in \"note: previous borrow ends here\"  semantic: \"but\" seems like the wrong word here, there is now, contrast, only further explanation. \"so\", \"thus\" or \"therefor\" is clearer.  grammatical: another misuse of \"here's\", should be \"here are\" (or possibly \"here're\").  grammatical: \"use\" should be capitalized. all other subheadings capitalize the first word.  fixed typo: term should be terms  two terms (input lifetime and output lifetime) so \"term\" needs to be plural.  took comment out of code block  no reason for a long comment in a code block when we could take it out, especially since it looks like it's using markdown (struct, & and lvl).  merging my book edits recent commits. ", "linked_issue_titles": "", "title": "small grammatical and stylistic edits to book"}
{"description": " previously some images were using jpg.js that could actually be decoded by the browser. they're now decoded using the browser then sent back to apply the needed color conversions. ", "commit_messages": " decode more jpegs using the browser if possible.  move comments. ", "linked_issue_titles": "", "title": "decode jpegs using browser when possible"}
{"description": " i hereby agree to the terms of the cla available at:  non-significant (changelog entry is not needed) detailed description (optional): part of #7512 it's needed to remove database and table name from path to data ", "commit_messages": " make data path relative  use arbitrary relative path in *mergetree  refactor storagefile construction  use relative paths in istorage::rename(...)  fixes ", "linked_issue_titles": "", "title": "use relative paths in storages"}
{"description": " clarifies plattform specific behaviour of preferences: on android, prior to flushing, changes to the preferences are not available to the user on ios changes are not synchronized between different preferences instances fixes #5558. ", "commit_messages": " clarify how preferences work on android.  add a note about preferences behaviour on ios. ", "linked_issue_titles": " preferences behaviour differs on android ", "title": "clarify plattform specific behaviour of preferences"}
{"description": " since #9319 proposed by gregory maxwell and released in v0.14, peers manually added through the -addnode config option or using the addnode rpc have their own separate limit of 8 connections that does not compete with other inbound or outbound connection usage and is not subject to the limitation imposed by the -maxconnections option. this pr updates the -addnode and -maxconnections config options and the addnode rpc help docs with this information. -addnode config option help $ bitcoind -h | grep -a5 addnode= -addnode=<ip> add a node to connect to and attempt to keep the connection open (see the addnode rpc help for more info). this option can be specified multiple times to add multiple nodes; connections are limited to 8 at a time and are counted separately from the -maxconnections limit. $ bitcoind -h | grep -a3 maxconnections= -maxconnections=<n> maintain at most <n> connections to peers (default: 125). this limit does not apply to connections manually added via -addnode or the addnode rpc, which have a separate limit of 8. addnode rpc help $ bitcoin-cli help addnode addnode \"node\" \"command\" attempts to add or remove a node from the addnode list. or try a connection to a node once. nodes added using addnode (or -connect) are protected from dos disconnection and are not required to be full nodes/support segwit as other outbound peers are (though such peers will not be synced from). addnode connections are limited to 8 at a time and are counted separately from the -maxconnections limit. ", "commit_messages": " doc: update addnode rpc help  doc: update -addnode config option help ", "linked_issue_titles": "", "title": "update helps for addnode rpc and -addnode/-maxconnections config options"}
{"description": " added it to gatsbyjs.org and it removed 20kb from our commons bundle! easy win for any website using lodash. ", "commit_messages": " add gatsby-plugin-lodash  make new packages default to 1.0.0  publish  - gatsby-plugin-lodash@1.0.1 ", "linked_issue_titles": "", "title": "add new gatsby plugin for lodash which adds their webpack & babel plugins to builds."}
{"description": " used shell_notifyicongetrect function to get the bounds of the application's tray icon. note that this only works with windows 7 or windows server 2008 r2 and later. i did not test this on windows xp. since even microsoft stopped supporting windows xp, i think decent support on modern os's is more important than supporting legacy systems. it would be nice if someone could check if no things got broken to badly though (is there an error when clicking the tray icon on windows xp?)... if so, could this be handled gracefully? fixes #1159 and related to #1500. ", "commit_messages": " added bounds payload to tray clicked event  used [shell_notifyicongetrect function](  note: only works with windows 7 and later.  related to #1159, #1500.  updated tray api docs to reflect changes in ce8aa07 ", "linked_issue_titles": " window position ", "title": "added bounds payload to tray clicked event on windows"}
{"description": " remove duplicate code in abstractconfig.java to make brief and clean remove code classutils.isprimitive(method1.getreturntype()) in abstractconfig.java at line 653 classutils.isprimitive(method1.getreturntype()) is already judge in method methodutils.isgetter follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. ", "commit_messages": " merge from dubbo master  merge from dubbo master  remove duplicate code ", "linked_issue_titles": "", "title": "[dubbo-4491]remove duplicate code in abstractconfig.java"}
{"description": " clean up various integration tests that referenced the integration_config.yml vars file. integration tests ", "commit_messages": " fix var_blending test temp dir usage.  fix filters integration test:  - fix use of output_dir.  - use localhost instead of testhost since we're only testing filters.  - fix fileglob test to actually test a directory that exists.  fix lookups integration test:  - fix use of output_dir.  - use localhost instead of testhost since we're only testing lookups.  fix ansible-runner test temp dir usage.  fix template and template_jinja2_latest test.  use the output_dir env var to get the output directory for the tests. ", "linked_issue_titles": "", "title": "clean up various integration tests."}
{"description": " add mbedtls lib support support custom openssl, sodium and mbedtls crypto lib path update libsodium to 1.0.12 in tests add libopenssl 1.1 to tests add mbedtls to tests add more ciphers to jenkins update config.json.example ", "commit_messages": " add mbedtls crypto wrapper.  add tests files for new aead ciphers  add custom lib path support  fix some typo  fix forbidden ip list  rm crypto lib build files  remove crypto source  add xchacha20 test config ", "linked_issue_titles": "", "title": "add mbedtls wrapper, custom crypto lib path, test files"}
{"description": " with these magic symbols, programs that link against the _concurrency module with a deployment target prior to ios 15 / macos 12 / watchos 8 will reference libswift_concurrency.dylib via rpath. fixes rdar://81187835. ", "commit_messages": " add magic symbols for concurrency.  extend and test install_name symbols for back-deployed concurrency.  with these magic symbols, programs that link against the _concurrency  module with a deployment target prior to ios 15 / macos 12 / watchos 8  will reference libswift_concurrency.dylib via rpath.  fixes rdar://81187835. ", "linked_issue_titles": "", "title": "add install_name symbols for back-deployed concurrency."}
{"description": " breaking changes rename circle to circular and rect to rectangular for consistency. the possible values should be adjectives, not nouns: -<skeleton variant=\"circle\"> -<skeleton variant=\"rect\"> +<skeleton variant=\"circular\"> +<skeleton variant=\"rectangular\"> last item of #21964. closes #21964 ", "commit_messages": " [skelton] rename variant circle -> circular  [skelton] rename variant rect -> rectangular  add skeleton section  update docs ", "linked_issue_titles": " [rfc] renaming api for consistency ", "title": "rename variant circle -> circular and rect -> rectangular for consistency"}
{"description": " description: when the target sonarr service is not available during setup, set the sensors to unavailable. since sonarr is a self-hosted solution, it makes sense that the user would know about the availability of the service, and that it would return. when the service becomes available again, the sensors will pick up the data. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " add exception handling to request call to prevent  failure in setup_platform if host is down ", "linked_issue_titles": "", "title": "add exception handling to sonarr"}
{"description": " refactoring of ramping code to make it as separate from the rest of the locust code at possible. added tooltips for the ramping form in the ui. ", "commit_messages": " added tooltips to ramping form  refactoring of ramping functionality to make it as separate at possible ", "linked_issue_titles": "", "title": "refactoring (separation) of ramping code; added tooltips for ramping form in ui"}
{"description": " thank you for contributing to kubernetes/charts. before you submit this pr we'd like to ", "commit_messages": " return ingressclass in notes  fix broken controller-hpa  bump chart version  expose volumename for chartmuseum  bump chartmuseum version  spelling ", "linked_issue_titles": "", "title": "fix a couple spelling errors"}
{"description": " from auto-308. the ci system has been running all tests for the serial test steps on eos:develop-boxed. the serial tests rely on container-level parallelization, so each step should only be running one test. this pull request fixes the develop-boxed bug, simplifies some of the ci code, makes the pipeline easier to debug, and folds some log segments in order to focus on the parts of the build process that the customer cares most about. the working directory was also changed from /workdir to /eos to support using the same container for multiple ci systems. see also pull request 9653 -- eos:develop-boxed pull request 9655 -- eos:blockvault pull request 9656 -- eos:develop pull request 9657 -- eos:release/2.0.x pull request 9658 -- eos:release/1.8.x none. none. none. ", "commit_messages": " remove dead code  evaluate $(pwd) at runtime so that it is easier to copy-pasta docker commands to a local machine  support paths with spaces and passing through multiple arguments  don't source ~/.bash_profile outside of the ci system  print even more commands before running them to make this bash spaghetti easier to debug  print test logs in realtime; organize following steps  fix shell string quoting issues  de-duplicate npm command ", "linked_issue_titles": "", "title": "fix serial test bug + simplification + ux"}
{"description": " languagecodeexpander can try to load language when trying to resolve language code. without this patch, every language load (even in local langinfo object) cause reset global locale. ", "commit_messages": " langinfo: fix: remove global object usage from non-static function  [win32] langinfo: undef function names on win32 ", "linked_issue_titles": "", "title": "langinfo - fix overriding default language when checking for language presence"}
{"description": " backports #26111 #26223 #26187 #26219 #26221 ", "commit_messages": " enable traffic director time tracer (#26111)  just update the timeout (#26223)  increase xds job timeouts (#26187)  revert grpc_xds_k8s job timeouts back to 120 mins (#26219)  revert grpc_xds_k8s_python timeout to 120mins (#26221)  seems to have been inadvertently increased in #26187 ", "linked_issue_titles": "", "title": "backport config update timeout change to v1.37.x"}
{"description": " --no-heap-copy is irrelevant to us since we don't use the packager tool, instead i fixed the createdatafile call. also included a patch that makes sure we always use out() and err() (implementing stdout and stderr) instead of console.log/warn. these functions are now always available since we bumped the minimum emscripten version. ", "commit_messages": " fix file preloading warning in html5 platform  use stdout/-err for all messages in html5 platform ", "linked_issue_titles": "", "title": "properly preload files, always use stdout/-err in html5 platform"}
{"description": " we do not presently stash files correctly when a file is added in the index and then modified in the working directory.  we are examining only the working directory with regard to the head, and without examining the index as well (with that file staged) we treat that file as untracked and thus do not include it in the workdir tree. correct that by using a diff that includes the index similar to git_diff_tree_to_workdir_with_index but with different special cases.  (git_diff_tree_to_workdir_with_index is aimed at producing something like git diff and so collapses some cases - we differ in that we want to ensure that we still pay attention to the workdir side when the index side is deleted.) ", "commit_messages": " diff_tform: remove reversed copy of delta merger  drop git_diff__merge_like_cgit_reversed, since it's a copy and  paste mess of slightly incompatible changes.  git_diff__merge: allow pluggable diff merges  stash tests: ensure we save the workdir file  ensure that when a file is added in the index and subsequently  modified in the working directory, the stashed working directory  tree contains the actual working directory contents. ", "linked_issue_titles": "", "title": "stash workdir correctly when added in the index, modified in the workdir"}
{"description": " longer-term, do we want to use numpy's new behavior?  update a little more background: consider two ndarrays in np<1.18 arr1 = np.array([1, 2, np.nan, 3, 4]) arr2 = np.array([1, 2, np.datetime64(\"nat\"), 3, 4], dtype=\"datetime64[ns]\") >>> np.sort(arr1) array([ 1.,  2.,  3.,  4., nan]) >>> np.sort(arr2) array([                          'nat', '1970-01-01t00:00:00.000000001', '1970-01-01t00:00:00.000000002', '1970-01-01t00:00:00.000000003', '1970-01-01t00:00:00.000000004'], dtype='datetime64[ns]') in numpy 1.18, the behavior of np.sort(arr2) is changing to put the nat at the end instead of at the beginning, to behave more like nan.  this breaks a few tests, which this pr fixes. side-note: as of now, 1.18 changes the behavior for datetime64, but not timedelta64. ", "commit_messages": " tst: fix test broken by np 1.18 sort change  nicer fix ", "linked_issue_titles": "", "title": "fix tests broken by np 1.18 sorting change"}
{"description": " layername buttons will grow/shrink to fill layer panel width. grows to a maximum of the draw width of the widest set layer name. also fixes #47 ", "commit_messages": " fix stbte_create_map declaration  stbte: layername button grows/shrinks  layer name buttons grow to fill box  stbte: update documentation/version 0.31  changed revision history, todo, credits, and readme ", "linked_issue_titles": " stbte_create or stbte_create_map ", "title": "layer name buttons grow with layer panel"}
{"description": " validate-modules sanity test now validates removal version numbers (similar to version_added validation), checks that removal collection versions are major releases, and not minor or patch releases, and checks that version_added collection versions are not patch releases: error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-deprecated-version: argument 'read_only' in argument_spec found in mounts has deprecated aliases 'ever' with invalid removal version '1.2.3.4': invalid semantic version '1.2.3.4' error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-deprecated-version: argument 'tmpfs' in argument_spec has an invalid removed_in_version number '1.2.3.4': invalid semantic version '1.2.3.4' error: plugins/modules/cloud/docker/docker_container.py:0:0: invalid-removal-version: ansiblemodule.argument_spec.mounts.options.read_only.deprecated_aliases.1: version ('1.2.3.4') is not a valid collection version (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: removal-version-must-be-major: ansiblemodule.argument_spec.mounts.options.read_only.deprecated_aliases.0: version ('1.3.0') must be a major release, not a minor or patch release (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: removal-version-must-be-major: ansiblemodule.argument_spec.published_ports.deprecated_aliases.0: version ('1.2.0') must be a major release, not a minor or patch release (see specification at  error: plugins/modules/cloud/docker/docker_container.py:0:0: version-added-must-be-major-or-minor: documentation.options.device_read_bps.suboptions.rate: version_added ('1.0.1') must be a major or minor release, not a patch release (see specification at  error: plugins/modules/cloud/misc/helm.py:0:0: removal-version-must-be-major: documentation.deprecated: removed_in ('3.1.0') must be a major release, not a minor or patch release (see specification at  (also removes some error codes from docs/docsite/rst/dev_guide/testing_validate-modules.rst which have been forgotten, or which haven't been reported anymore.) the pylint sanity test now checks that removal collection versions are major releases, and not minor or patch releases: error: plugins/modules/cloud/docker/docker_container.py:3445:8: removal-version-must-be-major: removal version ('3.1.0') must be a major release, not a minor or patch release (see specification at  the runtime-metadata code-smell sanity test now has stricter date validation (f.ex. yyyy-m-d no longer accepted), checks removal version numbers (semver version numbers for collections, strictversion for ansible-base), and checks that removal collection versions are major releases, and not minor or patch releases: error: meta/runtime.yml:0:0: expected iso 8601 date string (yyyy-mm-dd), or yaml date for dictionary value @ data['plugin_routing']['modules']['gcspanner']['deprecation']['removal_date']. got '2020-1-4' error: meta/runtime.yml:0:0: removal version must be a semantic version ( error: meta/runtime.yml:0:0: extra keys not allowed @ data['plugin_routing']['modules']['gcp_url_map']['deprecation']['extra_key']. got 'whatever' error: meta/runtime.yml:0:0: removal_version ('3.1.0') must be a major release, not a minor or patch release (see specification at  validate-modules sanity test pylint sanity test runtime-metadata code-smell sanity test ", "commit_messages": " validate removal versions.  should not be here anymore.  validate that removal collection versions and version_added collection versions conform to semver spec.  validate removal version numbers in meta/runtime.yml.  stricter validation for isodates (f.ex. yyyy-m-d is not allowed).  improve error reporting.  validate removal collection versions. ", "linked_issue_titles": "", "title": "improve version number validation, validate some semantic versioning properties"}
{"description": " commit log pegasus hoof: layout macro refactor (7c2da6c) renamed keymap to layout added layout_tkl_ansi macro white space changes (changed tabs for 2 spaces) pegasus hoof: keymap refactor (08d6f43) updated layout macro names changed to #include qmk_keyboard_h removed redundant kc_trns definitions white space changes (changed tabs to spaces) removed deprecated build script instructions from rules.mk files updated config.h to #pragma once pegasus hoof: configurator support (10fc65a) pegasus hoof: readme cleanup (6e4e932) reformat header and description paragraph fix hardware availability link (was 404) renamed filename to lowercase pegasus hoof: add layouts = tkl_ansi to rules.mk (ed1b987) ", "commit_messages": " pegasus hoof: layout macro refactor  - renamed keymap to layout  - added layout_tkl_ansi macro  - white space changes (changed tabs for 2 spaces)  pegasus hoof: keymap refactor  - updated layout macro names  - changed to #include qmk_keyboard_h  - removed redundant kc_trns definitions  - white space changes (changed tabs to spaces)  - removed deprecated build script instructions from rules.mk files  - updated config.h to #pragma once  pegasus hoof: configurator support  pegasus hoof: readme cleanup  - reformat header and description paragraph  - fix hardware availability link (was 404)  - renamed filename to lowercase  pegasus hoof: add layouts = tkl_ansi to rules.mk ", "linked_issue_titles": "", "title": "bpiphany pegasus hoof refactor, configurator support and readme cleanup"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: cure53/dompurify#367 if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. cure53/dompurify#367 ", "commit_messages": " [dompurify] publicly expose dompurify's interfaces and event names via the dompurify namespace.  [dompurify] update dompurify's sanitize method return types to reflect version 2.0.1 (support for trustedhtml types) ", "linked_issue_titles": "", "title": "expose dompurify typings on namespace and update types to better reflect version 2.0.1"}
{"description": " what do these changes do? adds support for running eager tf policies. blocking issues #5434 #5435 #4921 linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " attempt at eager + builder  tweaks  finished eager pg ", "linked_issue_titles": "", "title": "adds eager support with a generic tfeagerpolicy class"}
{"description": " the following code would throw exception before this fix because the value was not broadcast to the right shape . data = mx.nd.ones((2, 2))  # data.shape = (2, 2) value = mx.nd.array([3])  # value.shape = (1,) data[:] = value  # the value should be broadcast to shape (2, 2) first and then call copyto(data) ", "commit_messages": " fix ndarray assignment issue with basic index  uncomment useful code ", "linked_issue_titles": "", "title": "fix ndarray assignment issue with basic indexing"}
{"description": " i am reviewing our demo env carefully, fixed the following. service traffic should serialize and deserialize the time bucket, otherwise, there is a chance service_traffic-0 generated. service traffic should serialize and deserialize the time bucket, otherwise, there is a chance service_traffic-0 generated. make top n results more clear about the owner. previously, the same endpoint names of different services look the same. sync ui. fix service traffic equal and hashcode method. the time bucket is not a part of the entity attribute. ", "commit_messages": " make top n result more clear of owner.  remove virtual node service and service instance source generation.  sync ui. ", "linked_issue_titles": "", "title": "polish metrics logic, fix service traffic bug"}
{"description": " fix #5322 1.add port attribute in configcenterconfig 2.when using zookeeper and configcenterconfig is null, set port attribute. 3.when setting address attribute, set the relevant properties like registryconfig if (address != null) { try { url url = url.valueof(address); setusername(url.getusername()); setpassword(url.getpassword()); updateidifabsent(url.getprotocol()); updateprotocolifabsent(url.getprotocol()); updateportifabsent(url.getport()); updateparameters(url.getparameters()); } catch (exception ignored) { } } follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. ", "commit_messages": " fix #5322 ", "linked_issue_titles": " 2.7.4.1registryconfigsetport() ", "title": "[dubbo-5322]when using zookeeper and configcenterconfig is null,don't set port attribute."}
{"description": " from react-native 0.64, react-native-codegen allows defining aliases for object literal types. this change reflect it on the codegen. i don't know why microsoft.reactnative.sln still compiles as these new structs are used in the spec but implementations are not changed. it is interesting that no module implementations are using react_struct except alert and deviceinfo. alert doesn't check the spec class when registering. deviceinfo doesn't contain constants in the spec. i will fix them in separate commits. microsoft reviewers: open in codeflow ", "commit_messages": " split files  generate struct fields  update generated code  emit react_struct and react_field  make a new macro since react_struct cannot be used for nested struct  change files ", "linked_issue_titles": "", "title": "generate aliased struct for turbo module"}
{"description": " i hereby agree to the terms of the cla available at: ", "commit_messages": " update select.md  from final can be used not only with collapsingmergetree  update select.md  from final can be used not only with collapsingmergetree ", "linked_issue_titles": "", "title": "doc change. from final can be used not only with collapsingmergetree"}
{"description": " lb policies hold an arbitrary number of subchannels, with their corresponding fds. for performance reasons, not all of these fds can be linked to the call's pollset_set. however, they still need to be polled for the lb policies to be notified of changes in the subchannels's connectivity state. this pr leverages the background poller introduced in #12732 to poll the client_channel's interested parties very frequently in order to minimize delays in detecting subchannel activity. fixes #13081 #13080 #13128 #13159 reverts #13127 (re-enables tests) ", "commit_messages": " bg-poll very frequently to pick up subchannels's updates in lb tests  re-enabled all polling engines for lb tests ", "linked_issue_titles": "", "title": "make the bg poller poll very frequently in lb tests"}
{"description": " fixes #14771 @guardrex please check it out :) ", "commit_messages": " change endpoint from todo to todoitems  update all references to the previous endpoint ", "linked_issue_titles": " blazor webassembly sample references a previous version of the api tutorial ", "title": "update blazor webassembly sample to go at pair with the new webapi sample"}
{"description": " relands #26944 (was reverted in #27191) multicast_dns has landed internally, so this should no longer be an internal roll blocker. / fixes #23164 ", "commit_messages": " discover port over mdns - needs tests  appid parameter  case insensitive parameter comparison  cleanup printing  merge  update pub location to git for now  unintentional change  move vars, report error, remove requirespubspecyaml  stray blank lines  document class and move parameter  tests for discovery, roll back user interaction  remove unused import  use published package  newline  merge  fix checksum  opt in, only for ios for now  merge  merge  pubspec ", "linked_issue_titles": " teach flutter_tools how to use mdns to find the ios observatory port ", "title": "reland automatic discovery of observatory port for ios"}
{"description": " instead, generate them on demand. i'm not sure why we started to hard-code it, but i think it may have been just trickier to write? fixes #9605 ", "commit_messages": " automatically generate cxa_find_matching_catch handlers, avoid hardcoding a limit.  fix ", "linked_issue_titles": " error: undefined symbol: __cxa_find_matching_catch_24 ", "title": "avoid hardcoding a limit to the number of args to cxa_find_matching_catch"}
{"description": " the await for syntax seems to trick the command runner into thinking the task hasn't finished yet fixes #24261 ", "commit_messages": " remove await for ", "linked_issue_titles": " fuchsia attach can hang due to await for ", "title": "remove await for syntax from fuchsia log scanner"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < ", "commit_messages": " update outputinfo  update outputinfo ", "linked_issue_titles": "", "title": "update of the outputinfo interface for the sharp module"}
{"description": " avoid building swiftremotemirror for all targets by default. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " build-script: reduce the amount of debug output  cmake: rename an obscure is_host flag to host_library  cmake: pass down the host_library flag to _add_swift_library_single()  cmake: build target libraries together with the stdlib  this avoids building swiftremotemirror for all targets by default. ", "linked_issue_titles": "", "title": "build target libraries with stdlib"}
{"description": " amazingly, if you get the very latest visual studio 2015, it seems to work. (the initial visual studio 2015 does not work.) fixes #999 ", "commit_messages": " starting work on antique support  silencing some warnings (visual studio 2015)  continuing  cleaned one issue.  updating the singleheader  let us see what appveyor says. ", "linked_issue_titles": " vs2015, patch 3 (vs14.*) support. ", "title": "this might enable building the core library under visual studio 2015"}
{"description": " this pass consists of the following passes inside:: extract bright pass mip map blur pass combine pass ", "commit_messages": " bloom pass inspired from unreal  * extract bright pass  * mip map blur pass  * combine pass  resize function in bloom  resize function in bloom ", "linked_issue_titles": "", "title": "bloom pass - inspired from unreal engine"}
{"description": " improve clarity of the local option to formhelper#form_with and the configuration option that controls its implicit default. i brought this up in #41245. to summarize: the existing documentation is confusing because: the first line states the default behavior but that's misleading. the default behavior actually depends on a configuration option which might be different from the default in the project one is working in, and depends on the version of rails the project was generated by, and whether the default config has been changed during a subsequent upgrade, and whether the default config is overridden in the application config. the configuration option is named \"form_with_generates_remote_forms\" \"generates\" seems to indicate that it has something to do with the rails generator #form_with doesn't take a \"remote\" argument (like #form_for does) but the word \"remote\" is in the configuration option name it's inconsistent with its use of the terms \"remote\" and \"local\" and understanding it requires processing at least one double-negative my goal is to: document the option itself as a boolean, defining the behavior when two possible values are specified. reference the rails configuration option as a way to control behavior of this method when the local option is not provided to the method. document the default value of the configuration option to make it clear that the default value dependent on the version of rails. (this is most important because developers working in older applications may end up reading this documentation without realizing that the documentation is incorrect for their version of rails. also keep in mind that since the \"6.0 defaults\" are actually still part of the rails codebase, this documentation is referring to code/default values that are in the codebase, not code/default values that have been removed or changed completely.) closes #41245 ", "commit_messages": " clarify #form_with local option documentation  reword #form_with local option documentation ", "linked_issue_titles": " confusing documentation of formhelper#form_with and `form_with_generates_remote_forms` config ", "title": "improve documentation of formhelper#form_with local option [ci skip]"}
{"description": " the methods are always present, and not \"maybe undefined\" as currently declared in the declaration file. documentation:  the methods were declared as optional in order to fix the tests, where the mocks did not include the parse method. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " platform: the parse and tostring methods are not maybe present, they are definitely present.  platform: fixed the tests ", "linked_issue_titles": "", "title": "the parse and tostring methods are not maybe undef"}
{"description": " i have followed (at least) the pr section of the contributing guide. closes #17215 closes #16631 ", "commit_messages": " [docs] add margin between vertical slider examples (17215)  [slider] add track prop (#17215) ", "linked_issue_titles": " [slider] hide the track  [slider] reverse slider ", "title": "add support for removed and inverted track"}
{"description": " this fixes #980. this makes each component report user activity. the mediatechcontroller and player need to disable this. mediatechcontroller reports user activity manually as it also handles hiding and showing of the control bar. the tap test should only focus on taps. ", "commit_messages": " fix touch events.  make components listen to touch events themselves.  components can have a \"listentotouchmove\" property that would report  user activity on touch moves.  currently, the only problem left is that the mediatechcontroller emits  tap events to show/hide the controlbar but that causes the control bar  to not be hidden via a tap.  remove unused var  stop immediate propagation on tap events  make media tech controller only hide control bar.  enableuseractivity on component  disableuseractivity on mediatechcontroller and player.  mediatechcontroller does it manually.  remove listentotouchmove.  test is for tap events and not user activity ", "linked_issue_titles": " cant listen to touch events over the video element. ", "title": "enable listening for touch events above the player"}
{"description": " backport #13603 to 3-0-x. ", "commit_messages": " add api to return an unique id for page  fix double-freeing remote references  after the page does navigations, garbage collection can still happen in  the old context. this commit changes to store references to remote objects  by _pages_, instead of by _webcontents_. ", "linked_issue_titles": "", "title": "guard against double-freeing remote references (3-0-x)"}
{"description": " create react app is setting some default build infrastructure for react apps. we had an issue of deciding what's the default config is. now we support, create-react-app's settings as the defaults. that means, we could use react-storybook with create-react-app based projects without doing any webpack configurations. this comes with following core changes: add postcss based css loader. add file-loader for images and common types. add url-loader for shorter media files. do not pre-build manager(storybook ui) bundle. continue support for babel's stage-0 preset and add es2016 preset. ", "commit_messages": " match default setup same as create-react-app.  stop pre-building the manager  this allow us to customize the manager dynamically.  update manager for the production build.  remove building source-maps.  fix lint issues.  improve static file handling.  update dev docs.  use dist directory for the manager's source. ", "linked_issue_titles": "", "title": "update defaults to match create-react-app"}
{"description": " they are relative to the pixel density of the image. ", "commit_messages": " thresholding: change the window and tile size parameters to relative numbers  they are relative to the pixel density of the image.  fix a mismatch between tprintf format string and args ", "linked_issue_titles": "", "title": "change the window & tile size params to relative numbers"}
{"description": " this pr fixes #132651 ", "commit_messages": " editors - first cut base editor with view state  editors - make more view state management reusable  editors - more code alignments  editors - first cut view state support for side by side editors ", "linked_issue_titles": " allow to split an editor into two without creating separate tabs ", "title": "refactor editor view state to be reusable and adopt for side by side editor"}
{"description": " this change introduces the correct storage_spec parameters when calling recommenddatastores() method from the pyvmomi plugin. this fixes incorrect datastore cluster placement recommendations during an \"add disk\" scenario for the vmware_guest_disk module. fixes #67100 see related issue for full conversation. vmware_guest_disk ", "commit_messages": " fix sdrs recommendations  fixes storage drs recommendation call for add disk scenario  undo changes to whitespacing  undo changes to whitespacing (pt. 2) ", "linked_issue_titles": " vmware_guest and vmware_guest_disk modules fail to return storage drs recommendations when using datastore clusters ", "title": "vmware_guest_disk storage drs bugfix for get_recommended_datastore"}
{"description": " atm there are exactly two places where blockmanager.eval is called: dataframe._combine_match_columns and dataframe._combine_const.  this replaces the usage in _combine_match_columns with a dispatch-to-series implementation.  some output dtypes get changed (see edits in test_axis_select_reindex, test_pivot), and some errors get changed from valueerror to typeerror (see test_operators). the other usage of _data.eval will be removed separately; that turns out to be a lot more trouble because a bunch of dataframe behavior is currently incorrect (see #22017). this pr also: simplifies some of the special-casing in sparsedataframe; trying to move towards not having separate implementations for these methods dispatches _combine_match_index to avoid calling self.values when doing so would require coercing to object-dtype. ", "commit_messages": " avoid casting to object dtype in mixed-type frames  dispatch to series ops in _combine_match_columns  comment  docstring ", "linked_issue_titles": "", "title": "dispatch (some) frame ops to series, avoiding _data.eval"}
{"description": " just some updates to badges: uses the flat style for all badges that use shields.io adds lgtm.com badges (following all the alert fixes in recent prs that have now been merged. this should make it easier to track number of alerts.) ", "commit_messages": " :memo: use flat badges where possible  :memo: add lgtm.com badge in readme ", "linked_issue_titles": "", "title": "improvements to badges in readme"}
{"description": " bump go.d.plugin version to v0.29.0 component name packaging install this branch, ensure there are no errors, and go.d.plugin version is 0.29.0 ", "commit_messages": " packaging: update go.d.plugin checksums  packaging: bump go.d.plugin version to v0.29.0 ", "linked_issue_titles": "", "title": "update go.d.plugin version to v0.29.0"}
{"description": " remove both the active cluster and warming cluster if cds response told so. fixed both sotw and delta. risk level: mid since the bad behavior exist for long time. testing: fixed unit tests and integration test. added new integration test. fixes #13994 ", "commit_messages": " clean up ", "linked_issue_titles": " warming cluster is not removed at new cds response ", "title": "remove warming cluster if cds response desired"}
{"description": " i added the missing swift sections from the xcode release notes to changelog.md and formatted them for display on github. preview here they're not as granular by date as the previous sections, but at least the history is filled in. no code changes. / ", "commit_messages": " minor formatting tweaks to changelog.md  add missing xcode 6.1 and swift 1.1 release notes  add missing xcode 6.1.1 release notes  add missing xcode 6.3 and swift 1.2 release notes  add missing xcode 7.0 and swift 2 release notes  add missing xcode 7.1 and swift 2.1 release notes  update changelog.md formatting ", "linked_issue_titles": "", "title": "update changelog.md with missing content"}
{"description": " headers unneeded usings files need blank line at bottom fixed double returns returns after braces stylecop is commented out but still in the csproj's pr checklist applies to #5295 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? validation steps performed how does someone test & validate? ", "commit_messages": " headers  unneeded usings  files need blank line at bottom  fixed double returns  returns after braces  commenting out stylecop ", "linked_issue_titles": "", "title": "smaller stylecop fixes in wox.core and wox.infra"}
{"description": " restore \"jump to chart\" functionality from the alarms modal, that was lost when we prevented page scrolling when a modal is open. all chart names can now be searched with browser control-f (searching statsd metrics is now working) updated to fontawesome free 5.0.1 ", "commit_messages": " restore jump to start from the alarms modal  allow charts to be searched with browser control-f  updated to fontawesome-free-5.0.1 ", "linked_issue_titles": "", "title": "restore \"jump to chart\" from alarms modal"}
{"description": " make the cli arguments optional add early check for files count (bail when len(filenames == 0) add --dict argument (when set, this will use the first half of the file as a dictionary for the second half) example: benchmark using the first half of silesia files as the dict for the second half and compare the current hash to facebook:dev python automated_benchmarking.py --mode current --dict true --dir ~/silesia ", "commit_messages": " make arugments optional and add --dict argument  removing accidental print statement ", "linked_issue_titles": "", "title": "make arguments optional and add --dict argument"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): added support startswith, endswith, multisearchany, notlike for mergetreeindexfulltext. added support startswith, endswith, multisearchany for mergetreeindexset. added support empty, notempty, notlike for primary key. ", "commit_messages": " primary key and mergetreeindexfulltext support for string functions  minor style changes ", "linked_issue_titles": "", "title": "primary key, mergetreeindexfulltext and mergetreeindexset support for string functions"}
{"description": " this pr implements support for threads and cluster into redis-benchmark. multi-thread support by default, redis-benchmark will be launched in single-thread mode as usual. in order to launch it in multi-thread mode, you can use the --threads option, ie: redis-benchmark --threads 6 the command above will launch redis-benchmark with six threads. cluster support redis benchmark can now work with clusters. this can be done by using the --cluster option. the redis instance which redis-benchmark will connect to will be used as the cluster entry point. examples: redis-benchmark --cluster -p 7000 the line above will launch redis-benchmark in cluster mode and will use the instance with port 7000 as the cluster entry point. when launched in cluster mode, redis-benchmark will implicitly start in multi-threading mode too. by default, it will use one thread for each master node found in the cluster. anyway, you're free to change this default configuration by explicitly pass the --threads option, ie: redis-benchmark -p 7000 --threads 6 --cluster # if the cluster has three masters, use two threads per master node when launched in cluster mode, you can use the special {tag} placeholder inside the key names in order to let redis-benchmark use slot hash tags, in a similar fashion of the __rand_int__ placeholder. in this case, redis-benchmark will automatically replace the {tag} placeholder with the proper slot hash tag depending on which master node is querying. example: redis-benchmark -p 7000 --cluster get mykey:{tag} default redis-benchmark's tests already have the {tag} placeholder in their key name(s). you're free to mix the {tag} placeholder and the __rand_int__ placeholder in order to be sure that every thread uses random and different keys (remember to use the -r option to enable the key name randomization). example: redis-benchmark -r -p 7000 --cluster get mykey:{tag}:__rand_int__ when working in cluster mode, redis-benchmark will always fetch the cluster configuration before starting the test(s). anyway, if some slot is moved during the tests (ie. because of a resharding), after receiving an \"ask/moved\" reply error, redis-benchmark will fetch the cluster configuration again in order to update it. the configuration update will be atomically handled by threads. ", "commit_messages": " thread support for redis-benchmark.  added basic support for clusters to redis-benchmark.  redis benchmark: table-based slot hashtag placeholder replacement in cluster mode.  various changes to redis-benchmark thread and cluster support  - moved or ask replies are now handled in cluster mode.  - only the first slot per node is used in cluster mode.  - mutlithreading: reduced usage of mutexes in favor of atomic vars.  redis benchmark: configurable thread count in cluster mode and fixes  redis benchmark: fixed issued with config.hostip and code cleanup  redis benchmark: add {tag} to all default tests  redis benchmark: display 'save' and 'appendonly' configuration  redis benchmark: use atomic var for liveclients in 'createclient'  redis benchmark: update slots configuration after moved/ask reply  redis benchmark: fix default hset test key  redis benchmark: update help with threads/cluster options ", "linked_issue_titles": "", "title": "multithread support and cluster support"}
{"description": " introduces a new series of node settings xpack.security.authc.domains.<domain_name>.realms: <realm_name_list>. the setting sets the domain property on realm and realmconfig instances. the domain property ought be subsequently used in order to determine if two identical usernames are the same personas, and hence can share ownership (of profiles, keys, tokens, scrolls), even though they authenticated via different realms (but which are associated under the same domain). ", "commit_messages": " domain to realm  maybe  spotless  main  javadoc  nit ", "linked_issue_titles": "", "title": "introduce domain setting to associate realms"}
{"description": " the original author of #2522 hasn't returned to github in more than 2 months, so i'll take the courtesy of completing that pr. basically what's been proposed in the original pr, plus my own review suggestions applied. side change rewritten _include/video to use a case-when clause for the iframe src attribute, so other html attributes need not repeat for each video provider. #2522 ", "commit_messages": " enhance support for bilibili videos in responsive video helper, and add corresponding doc  apply @ibug's review in mmistakes/minimal-mistakes#2522 ", "linked_issue_titles": "", "title": "enhance bilibili video support (redo of #2522)"}
{"description": " for pyston some tests fail due to implementation details pyston/pyston#62 (no recursion limit and \"immortal\" objects), these are marked as skip. ", "commit_messages": " skip test for recursionerror on pyston, since it disables recursion checking  for pyston the refcount of \"immortal\" objects is set to ~infinity ", "linked_issue_titles": "", "title": "skip finite recursion and refcounting tests for pyston"}
{"description": " this also adds mathutils to the desktop jni bindings, which was missing (unless this was done on purpose?) ", "commit_messages": " add javadoc for colors  add javadoc for box  ad javadoc to mathutils  add mathutils to desktop jni bindings ", "linked_issue_titles": "", "title": "add javadoc for colors, box, and mathutils"}
{"description": " commit 9934a0a has changes that affect the global salt configs. everything else is azure specific. fixes #1731 #1485 ", "commit_messages": " deploy update  updates and formatting to azure scripts.  update cert generation for azure.  remove azure from icebox.  update readme.md  update azure.  bring azure guide up to date.  rearrange cluster sanity checks for azure.  merge readme changes. ", "linked_issue_titles": " azure deployment is broken with binary-deploy ", "title": "bring azure deploy scripts up to date"}
{"description": " the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " add variant zigbee  add variant zigbee  add variant zigbee (#196) ", "linked_issue_titles": "", "title": "add variant zigbee to github actions (ci and build)"}
{"description": " follow the advice from the readme. increase the version number in the header if appropriate.  this is still valid for the current version. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " fix optional types  fix optionals  fix optionals ", "linked_issue_titles": "", "title": "tabulator-tables  - minor fixes to optional types"}
{"description": " fix for the issue described in #2785. when serializing an dict or object, now the default value is used if the key or attribute is missing from the dict or object. previously a keyerror or attributeerror was raised. two tests failed after implementing the change, which was to be expected as they specifically targeted the behaviour of key or attribute being required even if default is set for the field (serializers.py, testnotrequiredoutput). they have been replaced by tests targeting the use of defaults when key or attribute is not present in the instance. deserialization seems unaffected. what isn't clear to me is what the rationale was of explicitly requiring the instance key/attribute to be present, even if a default is provided, so i'm wondering if there's a scenario i'm overlooking. ", "commit_messages": " default value will now be used when serializing if key or attribute is missing.  removed no longer needed tests.  added tests for using default when default is callable.  fixed field get_attribute(), now uses get_default() instead of default.  documentation update. ", "linked_issue_titles": "", "title": "allow required false and default"}
{"description": " rewritten nginx, phpfpm and apache modules to use wrappers on chart creation (methods: chart,  dimension, begin, set, end). created intermediate class simpleservice which is now a base for urlservice. as requested in #628, new logservice prototype was created which is also a child of simpleservice wrote new apache_cache module to parse apache mod_cache log file. i have done some basic test, but not on apache_cache. probably needs some more testing, which i will do when i find some time. ", "commit_messages": " rewrite apache, nginx and phpfpm plugins to use wrappers on chart creation  create simpleservice  move all url variables from simpleservice to urlservice  add check() method in simpleservice  logservice prototype  apache_cache python module  fix default apache url  error messages ", "linked_issue_titles": "", "title": "wrappers around charts creation + logservice"}
{"description": " a suggestion for improving docs. i spent a while trying to figure out where additional configmaps are uploaded to the halyard pod on a k8s spinnaker deployment so they could be used in config scripts, and this one line would've helped. i realize spinnaker is deployed on multiple kinds of infra, not just k8s, which is why i didn't mention a halyard pod, but maybe there's a better way to make this note generic. dco signed ", "commit_messages": " move the api_host variable to deck.yml, where it belongs  bump chart version for gate fix  merge remote-tracking branch 'upstream/master'  noting where additional config maps are written to disk may be helpful to beginners ", "linked_issue_titles": "", "title": "add note to spinnaker doc about destination path for additionalconfigmaps"}
{"description": " this is a port of #5605 for the 11.3 branch passing system test on branch builder ", "commit_messages": " minor:updates for new versions  minor:missing import for kafkaexception  minor:fixed parameter in test - result from bad cherry pick?  minor:update url to match new kafka packages location ", "linked_issue_titles": "", "title": "update streams upgrade system tests 0.11.0.3"}
{"description": " the onnx page is currently broken due to some name changes. the api reference is blank:  i fixed the overview table to link to things and now have the api reference appearing. i also updated the description text. sphinx won't render any shortcut references to the functions, so i'm calling them out the long way. when the python config for these onnx modules are updated we can try out the shorthand references and see if sphinx likes it or not. there are lint issues showing up in the docs build logs from these onnx files as well as many other files. i'll create a separate issues for these comments. ", "commit_messages": " update onnx api references  update descriptions ", "linked_issue_titles": "", "title": "update onnx api docs references"}
{"description": " fixes #12416 this pr detects a mismatch between cls and a checkpoint a user intends to load. however, it can't find a mismatch when a config doesn't contain the tokenizer's information. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " detect mismatch by analyzing config  fix comment ", "linked_issue_titles": " berttokenizer with bertjapanesetokenizer pretrained model generates unintended tokenization. ", "title": "add tokenizers class mismatch detection between cls and checkpoint"}
{"description": " i hereby agree to the terms of the cla available at:  i've translated half of the clickhouse documents into persian. they are: introduction getting started interfaces data types remaining pages: sql reference operations f.a.q the rest of these will be translated for the next few days. one thing is some sentences are very difficult to translate. i'm trying to improve the translation. thanks. ", "commit_messages": " initial translate fa. translate index.md  complete what is clickhouse? translate  translate distinctive_features to farsi  fix align  translate features_considered_disadvantages to farsi  translate performance page to farsi  translate ya_metrika_task page to farsi  translate getting_started.index.md to farsi  fix align  translate getting_started.example_dataset.ontime to farsi  translate getting_startet.example_dataset to farsi  translate command-line client interface to farsi  translate entire interfaces to persian  90% of data types category to persian  complete translate data type to persian ", "linked_issue_titles": "", "title": "translate clickhouse documents into persian"}
{"description": " description: scan_interval and interval_seconds (on device_tracker) will now work for any interval between 1 second and 1 day whereas without this they only work between 1 and 60 seconds. intervals are not always respected perfectly. for instance, if you want a 25 second interval it is rounded up to a 30 second interval. related issue (if applicable): fixes #5080 pull request in home-assistant.github.io with documentation (if applicable): example entry for configuration.yaml (if applicable): device_tracker: - platform: nmap_tracker hosts: 192.168.1.1/24 interval_seconds: 240 home_interval: 15 checklist: documentation added/updated in home-assistant.github.io if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " update scan_interval and interval_seconds max to 1 day vs. 60 seconds  format fixes ", "linked_issue_titles": " scan_interval doesn't allow intervals greater then 60 seconds. ", "title": "support longer-than-60-second scan_interval and interval_seconds"}
{"description": " not exactly my favorite fix. but everything else would lead to redoing the whole method. might break if there are different cores with different specifications? @koying @martijnkaijser @a4840639 ", "commit_messages": " fix debug bar not showing all cpus on android  code modernization ", "linked_issue_titles": "", "title": "show all cpus in debug overlay"}
{"description": " closes #242 removed redundant checks for null, when it will already be handled by calling 'delete' ", "commit_messages": " removal of null check  removed the redundant check for null which is already correctly handled  by used the delete  removal of null check  removed the redundant check for null which is already handled by using  delete ", "linked_issue_titles": "", "title": "removes redundant null pointer checks checks"}
{"description": " cleanup of ppo, appo, and dd-ppo code (equivalent to previous pg one): add type annotations. get rid of loss class. add comments and explanations to everything we do in ppo. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip  merge  \u0001 conflicts:  \u0001\trllib/evaluation/rollout_worker.py  wip. ", "linked_issue_titles": "", "title": "ppo, appo, and dd-ppo code cleanup."}
{"description": " this pr fixes the problem that in some server-side sdks no user data is attached to session data and so no users adoption metric information it solves this by calculating adoption based on sessions in addition to users adoption calculations ", "commit_messages": " added tests for calculating release adoption in sessions mode  added logic that allows adoption to be calculated either based on sessions or users  modified adoption calculation to return both users and sessions adoptoin  added sessions adoption to adoption calculation tests ", "linked_issue_titles": "", "title": "add session adoption to release-health"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. not adding any substantial changes ", "commit_messages": " addcustomattribute takes a string or a number  added brooks patton to contributors for new relic  bumped minor version ", "linked_issue_titles": "", "title": "newrelic functions addcustomattribute and addcustomattributes takes strings and numbers"}
{"description": " this should tidy up the javadoc generation and the hystrix-contrib project. ", "commit_messages": " use classpath, which is being changed by provided, instead of default  nebula-30 fixing javadoc arguments. using proper delegate in javadoc closure, add custom string option  nebula-28 preventing contrib project from being uploaded  nebula-31 ignore output from gradle maven ant tasks ", "linked_issue_titles": "", "title": "fixes for nebula-28, nebula-30, nebula-31"}
{"description": " this memoize shadowcreatepagepath in actions.createpage to avoid rerunning it for same inputs. this is not ideal, because we could have memoized potentially stale output, but webpack part of shadowing doesn't invalidate when there are changes in shadowing chain right now, so it's acceptable. this will need memo cache busting when webpack part will be looked at ", "commit_messages": " perf: memoize shadowcreatepagepath  more info ", "linked_issue_titles": "", "title": "memoize shadowcreatepagepath to fix performance regression"}
{"description": " this change adds infrastructure for geoshape making it accessible via the new scripting fields api. this does not add any methods outside of get at this point in time since it needs additional thought/discussion on what makes sense similar to geopoints. note that because geoshape does not support xcontent this is just a skeleton that currently supports getscriptdocvalues. ", "commit_messages": " add a geoshape field to the scripting fields api  add skeleton for painless allow list  add tests ", "linked_issue_titles": "", "title": "add support for geoshape to the scripting fields api"}
{"description": " add test to run 500 nodes 10k actors. we can bump this up later. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " add tests to nightly test  up;  up  up ", "linked_issue_titles": "", "title": "add x nodes y actors test to nightly tests"}
{"description": "", "commit_messages": " msa-757: smart gas-lock work with z-wave  msa-786: description from the app : \"with visible realtime energy usage status, have good energy habits and enrich your life\"  this app is specialized to show energy data which was grabbed from encored technologies' device that user installed at their home.  modifying 'timevalve smart'  added gentle wake up controller, updated smartapp  added gentle wake up controller, updated smartapp  update timevalve-smart.groovy  commenting out fingerprint temporarily to avoid potential conflicts with other devices as this devices is specifically for a korean deployment in ap01 - see dvcsmp-1425  msa-786: encored technologies : smart energy service  msa-757: timevalve smart  merging changes into stage ", "linked_issue_titles": "", "title": "merging changes into prod from staging"}
{"description": " the shortcut cmd + u or  ctrl + u is used to delete the content of current cursor back to the start of line, not always delete the whole line ", "commit_messages": " the shortcut cmd + u or the ctrl + u is used to delete the content of current cursor back to the start of line, not always delete the whole line  fixed ", "linked_issue_titles": "", "title": "fixed the description of ctrl + u"}
{"description": " added a couple mixdown utility methods. also added ability to start an encode via json string rather than the model. this is handy for a debug feature where you can copy a json job from the log and tweak it quickly to see what happens. added the .vs folder to .gitignore. ", "commit_messages": " some additions for mixdowns and ability encode from json string.  excluded .vs folder via gitignore. ", "linked_issue_titles": "", "title": "mixdown additions and direct json jobs"}
{"description": " this pr does the following: the list of predefined mime types to a dedicated file (so that it could be handled more easily) generate the list from the mime.types file of nginx fixes #254 ", "commit_messages": " move the list of default mime-types to a dedicated file (so that it coould be generated automatically)  build the default list of mime-types from that of nginx, using ", "linked_issue_titles": " even more mime types ? ", "title": "yet more mime-types by default"}
{"description": " re-enables dynamic bitrate that was disabled in #5165 and fixes a long-standing issue with the dynamic bitrate feature. as dynamic bitrate is calculated and applied when a packet is sent, it runs in the context of whatever thread is outputting a packet such as the audio output thread. that thread would then try to reconfigure the video encoder while the encoder thread could be in the middle of encoding. x264 handles this situation correctly, but nvenc (and possibly others) deadlock with no error visible to the user. this pr introduces a new encoder field, reconfigure_requested, which when set to true by an obs_encoder_update call, will cause the appropriate encoder thread (both regular and gpu) to call encoder->info.update before the next encode call. obs_encoder_update no longer calls encoder->info.update directly but still applies the settings. freezing output with no explanation is bad. disabling dynamic bitrate entirely is also bad. i changed dbr update interval to 1 second and limited my wan upload rate to between 1000-5000kbps. the current code, when run with nvenc, deadlocked after three minutes / 247 bitrate changes. the new code did not experience any issues after four hours / 20,162 bitrate changes. i also disabled jim-nvenc and tested ffmpeg nvenc dynamic bitrate still worked correctly. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " revert \"obs-ffmpeg, obs-qsv11: disable dynamic bitrate support\"  this reverts commit 1b29bfc88419515fa423804fac4411794c4df745.  libobs: defer reconfiguring encoders to the encode threads  fixes a long-standing issue with dynamic bitrate where the rtmp output  thread could try to reconfigure an encoder while the encoder is in the  middle of encoding. x264 seems to handle multithreaded calls well, but  nvenc would deadlock in this situation with no error visible to the  user. ", "linked_issue_titles": "", "title": "defer encoder reconfiguration to encode threads (fixes dynamic bitrate freeze)"}
{"description": " what do these changes do? added a documentation tutorial (with graphics) on profiling the performance of a basic ray example using python time, python cprofile, line_profiler (a third-party profiler), and the ray timeline web ui. there is an existing documentation page profiling.rst for ray developers, so i put mine's as a separate page user-profiling.rst under the same help section. no issue number. requested by @pcmoritz ", "commit_messages": " ray documentation - created new section 'profiling for ray users', opposed to current profiling section for ray developers. completed three sections 'a basic profiling example', 'timing performance using python's timestamps', and 'profiling using an external profiler (line_profiler).' left to-do two sections on cprofile and ray timeline visualization.'  ray documentation - fixed rst codeblock linebreaks in 'user profiling'  ray documentation - for user profiling, added section on cprofile  ray documentation - for user profiling, completed ray timeline visualization section, including graphical images  ray documentation - made user profiling timeline image larger, minor wording edits  ray documentation - minor wording edits to user profiling  ray documentation - user profiling- fixed broken link ", "linked_issue_titles": "", "title": "documentation- basic profiling for ray users"}
{"description": " fixes .app bundle crash (regression from #23244). add additional context updates (sdl fix linked in #23100 comment), main window content should always update correctly, splash screen is not fully fixed. fixes #23307, fixes #23496, related #22689 ", "commit_messages": " fix .app bundle crash on macos  fix initial blank screen on macos mojave (except splash). ", "linked_issue_titles": " osx 3.1 latest build crashes  current godot alpha crashes on mac osx(mojave) ", "title": "fix .app bundle crash and blank initial window"}
{"description": " currently, plasma running as thread actually has been enabled by default (because java launches ray using python scripts).  some critical functions like object spilling are also assuming that plasma store is running as a thread. so the outdated code path is no longer used and it is not functioning correctly. however, some c++ tests are using plasma store running as a process for testing, this is not good because they are not testing what we are currently using. this pr removes the outdated plasma store executable and migrates those tests. this also reduces the size of our wheel build. this pr may be required to pass some tests in #14924 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " remove plasma store executable & never used tests  lint ", "linked_issue_titles": "", "title": "remove code paths that contains plasma store executable"}
{"description": " this pull request introduces a new, temporary and experimental flag '-enable-astscope-lookup' that reimplements unqualified name lookup in terms of the new astscope data structure. there are some outright bugs in this new name lookup implementation, as well as a number of places where the implementation needs to perform more semantic analysis because we were relying on (weird, indefensible, but convenient) name lookup behavior to diagnose problems. ", "commit_messages": " [scope map] query the declarations introduced by a given ast scope.  introduce an operation that produces the set of local declarations  that are newly introduced by a given ast scope. this is a building  block of unqualified name lookup, which walks upward in the tree  (e.g., from children to parents) looking for declarations that have  been made visible at each step.  [name lookup] add a staging flag for astscope-based name lookup. ", "linked_issue_titles": "", "title": "introduce unqualified name lookup based on astscopes"}
{"description": " example project dependency upgrade. for  #11188 project dependency upgrade details springframework 4.3.20.release upgrade to 5.0.13.release springboot 1.5.17.release upgrade to 2.0.9.release mybatis 3.4.2 upgrade to 3.5.1 mybatis-spring 1.3.0 upgrade to 2.0.1 hibernate 4.3.11.final upgrade to 5.2.18.final project upgrade details example-core governance-spring-boot-example other-feature-example sharding-example/sharding-spring-boot-jpa-example sharding-example/sharding-spring-boot-mybatis-example transaction-example ", "commit_messages": " upgrade pom dependency management  upgrade governance-spring-boot-example  upgrade other-feature-example  upgrade sharding-example/sharding-spring-boot-jpa-example  upgrade sharding-example/sharding-spring-boot-mybatis-example  upgrade transaction-example  upgrade example-core ", "linked_issue_titles": "", "title": "example project dependency upgrade. (#11188)"}
{"description": " part of #643, covers test case for #565 ", "commit_messages": " add test  drop host header as well, so that header copying can be as simple as the prev. commit  drop transfer-encoding header passed from downstream (since the content is already decoded, and also not to require the header copying logic in rack apps to specifically drop the header when calling http_request) ", "linked_issue_titles": "", "title": "adjust request header handling, add tests"}
{"description": " this allows the configuration of the plugin to have multiple collections. also adapted the mapping feature to use a collection and then his mapping. it is also backwards compatible. ", "commit_messages": " bring my fork up to date  merge from master  merge remote-tracking branch 'upstream/master'  add multi collection functionality  change config in using site  adapt readme to the new functionality ", "linked_issue_titles": "", "title": "add multiple collections to the config"}
{"description": " allow dashboard sending cookies on all requests, fixes #477 allow netdata respect donottrack, according to #416 (comment) and instructions given at efforg/privacybadger#850 and efforg/privacybadger#781 this feature is disabled by default. to enable it set [global].respect web browser do not track policy = yes. when enabled the following will happen: for browsers sending the http header dnt: 1, the registry will refuse to serve them. all responses will have the http header tk: t (tracking), or tk: n (not tracking) depending on whether a cookie is used by netdata or not. allow netdata generate svg badges. a demonstration wiki page will be added once this is merged. ", "commit_messages": " allow cookies on all requests to support running netdata behind an authentication web server  added option and code to respect  added support for generating svg badges with chart data ", "linked_issue_titles": " dashboard.js - cross-domain authentication problems ", "title": "allow cookies on all requests; respect donottrack; generate svg badges"}
{"description": " adds operator sum(csr, axis=0) = dense and sum(csr, axis=1) tried 128*100m shape csr matrix and was able to perform sum along axis 0 and 1. density is 0.1% allocation fails for 128*100m for dense ndarray, for 1m and 10m the speedup for sparse operator is 300x for 1m and 1200x for 10m for density of 0.1%(uniform distribution) completes one todo in #8168 @eric-haibin-lin @reminisce @cjolivier01 @piiswrong ", "commit_messages": " add infer storage for sparse slice operator  remove unused files  indentation fix and add gpu test for fallback  change sum builtin to py_sum  add sum_axis(csr,axis=0)=dense and sum(csr,axis=1)=dense operator  documentation changes for sparse  add fallback unittest for keepdims and exclude ", "linked_issue_titles": "", "title": "operators for sum(csr, axis=0) and sum(csr, axis=1)"}
{"description": " i spotted a race condition on my previous pr #8104. the problem affects only the case of finite generators and has no effect on the infinite ones. this pr fixes the bug and updates the test to capture similar problems. please check the github comments on the code where i explain where the problem was and how i fixed it. feedback is always welcome! :) ", "commit_messages": " fixing race condition  check again for empty queue after detecting that all threads have finished.  updating the test to check for all set items ", "linked_issue_titles": "", "title": "fixing finite generator race condition"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. i am trying to follow all the steps but this is my first contribution to definitelytyped. ", "commit_messages": " update react-boostrap-table-next  update selectrowprops interface bgcolor property and some comas to semicolons.  updated bgcolor to have all possible types. ", "linked_issue_titles": "", "title": "update selectrowprops interface small change to bgcolor"}
{"description": " issue: #2537 implemented support in a11y-addon for delayed rendering of components by adding a \"re-run tests\" button within the panel. i also corrected the contrast of the addon's tabs (to 7:1) and added the number of violations and passes to each tab (because if you re-run, the number may change, but you wouldn't know until you navigated to the tab). there's a story called \"accessibility\" in cra-kitchen-sink that demonstrates a11y-addon with a regular button and with a button that doesn't render until 1s after the preview loads. in order to verify that it works, click the \"re-run tests\" button. (ideally, we would be able to verify that results are displayed in the tab.) ", "commit_messages": " implement pr #2537 ", "linked_issue_titles": "", "title": "handle a11y for components with delayed rendering"}
{"description": " this pr implements native filter and cross filter api simplification efforts introduced in apache-superset/superset-ui#1040 and apache-superset/superset-ui#1053 . the following changes are done: setdatamask hook now has new structure: { filterstate: { value: any, ...otherprops: any } ownstate: { ...otherprops: any } extraformdata: extraformdata } nested append_form_data and override_form_data fields in extraformdata type are moved up one level into the main filter object currentvalue removed from formdata now it passed in props.filterstate.value in superchart injected ownstate and filterstate fixed bug when remove cross filter from dashboard it's wasn't from dashboard metadata fixed bug that filter_select was attached to filterboxes fixed bug that when user just added cross filter without setting, it's scoping filter not appeared in filter badge migrate old filter set metadata to new format upgrade python code for legacy charts that depend on viz.py affected areas: native filters cross filters own state of charts filter sets test plan all frontend + backend unit tests have been updated, and a test for the migration has been added to ensure that both up and down migrations produce expected results. includes db migration (follow approval process in sip-59) runtime estimates and downtime expectations provided: only affects dashboards with filter sets. will only affect environments running the dashboard_native_filters_set feature flag ", "commit_messages": " refactor: updates usage of ownfilters to ownstate ", "linked_issue_titles": "", "title": "update datamask and extraformdata schema"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: v4.7.0 v4.7.1 v4.7.2 yaireo/tagify@7d7f683 yaireo/tagify@cd611a9 ", "commit_messages": " customize invalid tags messages  userinput setting  dropdown.toggle() method  test tagify.texts  bump version 4.7 ", "linked_issue_titles": "", "title": "update settings, bump version 4.7"}
{"description": " changelog: statefulset instead of deployment for slave component. separate pvc for each role (master, slave) related with these issues && pr: #2527 #2543 #2539 #2386 ", "commit_messages": " update redis image  delete blank lines  fix chart version  delete tailing spaces  new line  new line character in the end  fix persistance volume claim | pvc was pointing to a wrong claim  add image repos in chart's sources  create 2 pvc for master and slave components and update slave deployment to statefulset  bump to version 0.3.0 ", "linked_issue_titles": "", "title": "replace slave deployment to statefulset + create separate pvc for masters and slaves"}
{"description": " added to readme, releases, cars test route added to test_routes.py route with openpilot: bf43d9df2b660eb0|2021-09-23--14-16-37 thanks to community santa fe owner er3#3623 (discord id). ", "commit_messages": " add fingerprint: hyundai santa fe 2022  update lfahda_mfc: add 2022 hyundai santa fe  add car port: hyundai santa fe 2022  add test route: hyundai santa fe 2022  update releases.md  update cars.md ", "linked_issue_titles": "", "title": "add car port for 2022 hyundai santa fe"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: negomi/react-burger-menu@d174cd5 negomi/react-burger-menu@156e932 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update types to match version 2.6.8  add myself to definitions by ", "linked_issue_titles": "", "title": "add missing types to match v2.6.8"}
{"description": " this pr backports the following prs to 1.28: xds: fix duplicate lds update detection gracefully switch xds policy instances when cluster name changes. after this pr, to the best of my knowledge, #22400 is the only blocker for the 1.28 release. ", "commit_messages": " xds: fix duplicate lds update detection  gracefully switch xds policy instances when cluster name changes. ", "linked_issue_titles": "", "title": "backport #22388 and #22371 to 1.28"}
{"description": " if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. update ses options typings to match this version add version of createtransport to nodemailer which accepts ses transport as options remove templatesender from transport type since this doesn't seem to exist any more query: there seem to be two versions of nodemailer-ses-transport around, one merged in with nodemailer and one separately. the separate one seems to be what the typings are based on, but the combined one seems to have been updated more recently. first pr - typescript wasn't working for me with these packages so i thought i would try to fix it for everybody - any advice appreciated. ", "commit_messages": " update ses transport types to match current nodemailer  updated tests  updated version number ", "linked_issue_titles": "", "title": "update ses nodemailer typings to match current implementation"}
{"description": " in case of a new cheat sheet, you have used the cheat sheet template. all the markdown files do not raise any validation policy violation, see the policy. all the markdown files follow these format rules. all your assets are stored in the assets folder. all the images used are in the png format. any references to websites have been formatted as text the ci build of your pr pass, see the build status here. ", "commit_messages": " add note about imdsv2  add toc ", "linked_issue_titles": "", "title": "add toc and note about aws imdsv2"}
{"description": " renamed matrix keymap to layout_numpad_4x4 keymaps refactored: #include qmk_keyboard_h matrix renames readability updates added info.json file added layouts = numpad_4x4 to rules.mk ", "commit_messages": " matrix refactor: rename keymap to layout_numpad_4x4  keymap refactor: qmk_keyboard_h, matrix renames, readability  configurator support  add numpad_4x4 layout to rules.mk ", "linked_issue_titles": "", "title": "roadkit refactor and configurator support"}
{"description": " related to #59255 this pr would begin to issue a deprecation warning when running a date range, date histogram, or auto date histogram over a boolean field.  this is currently permitted, but is unlikely to be what the user intended to do, as a histogram over the values [0, 1] is not terribly useful.  one possible way users could encounter this situation would be an index pattern that includes indexes with different mappings. ", "commit_messages": " deprecate running date histogram on booleans  deprecate running histogram on booleans ", "linked_issue_titles": "", "title": "deprecate date aggregations on boolean fields"}
{"description": " hi, this pr adds a note about the default weight initializer to the tf.layers.dense and tf.layers.dense docstrings to clarify how the default weights are initialized as discussed in #9744 . ", "commit_messages": " add docstring note about dense weight initializer  add docstring note aboutthe dense class weight initializer ", "linked_issue_titles": "", "title": "add a note about how weights are initialized in dense/dense to the docstrings"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " updated google-libphonenumber utils function with formatoutofcountrycallingnumber that was missing  updated spaces ", "linked_issue_titles": "", "title": "added missing formatoutofcountrycallingnumber function to definitions of google-libphonenumber"}
{"description": " seems like i was too optimistic in assuming connections would always come in the same order! also consistently named conns to relationships throughout the file, added myself as an author and clarified a couple of comments. @mrdoob i also came up against an issue where a single skeleton is shared between two meshes - is this something that is supported in three.js? ", "commit_messages": " minor fixes  added author ", "linked_issue_titles": "", "title": "fbxloader minor animation fix and refactor"}
{"description": " after discussion, i added falling back to fetch based pinging when the websocket fails to connect. i also added an example of how to proxy the ondemandentries websocket when using a custom server. fixes: #6296 ", "commit_messages": " add falling back to fetch based pinging when failing to connect  to ondemandentries websocket  add warning letting user know why we are falling back to fetch  add example of proxying ondemandentries websocket  using custom server ", "linked_issue_titles": " hmr reloading page every 10 seconds ", "title": "add falling back to fetch based pinging for ondemandentries"}
{"description": " this change fixes 2 symptoms: \"can't find view with tag x\" that sometimes is thrown when closing a secondary window. this is due to a race between a spurious root view size change notification and the removerootview command coming from js. leak of the ui elements/related structures of a secondary dispatcher thread when a view is closed (by means of a window.current.close()) just after the \"await rootview.stopreactapplicationasync()\". this is due to a 1-0-1 pattern that confuses the os into detecting \"secondary thread not used anymore, so it can be killed\", when subsequent cleanup phase in the native hierarchy does need that thread again. in the new code the root view cleanup is carefully choreographed: detaching the root view has to complete before calling unmountapplication, so removerootview is guaranteed to follow rather than to race. stopreactapplicationasync now waits for the cleanup of the whole chain, up to nativehierarchymanager. ", "commit_messages": " fix race condition during close window by making sure \"unmountapplicationcomponentatroottag\" is called after detaching the root view.  this should fix \"can't find element with tag x\" exceptions during window closing.  fixed a close window issue that may trigger a leak if the hosting view is closed too fast.. ", "linked_issue_titles": "", "title": "fix some race conditions/leaks in some \"close window\" multi-window scenarios"}
{"description": " when using native, we should use the old menu for this release while we sort out electron issues ", "commit_messages": " add the old menu back for native menus  make menu labels match ", "linked_issue_titles": "", "title": "bring back the old menu due to electron 2.0 issues"}
{"description": " then flowed it throughout the compiler, finding and fixing a handful of bugs relating to underscore-prefixed identifiers in the process. includes a test for two (new) cases noticed - diagnostics from conflicting symbols from export *'s, and enums with underscore prefixed member emit. i mentioned this while talking among the team last week. this can be done in place of/alongside #16868. additionally, this fixes #15334, #14268, #11902, and #3268. (each should also now exist as a test case in this pr, too) the shape of this brand is also rather unique compared to others we've used. instead of just an intersection of a string and an object, it is that union-ed with an intersection of void and an object. this makes it wholly incompatible with a normal string (which is good, it cannot be misused on assignment or on usage), while still being comparable with a normal string via === (also good) and castable from a string. summary: __string is used to represent a string whose leading underscore have been escaped (if present) or a string representing an internal compiler symbol name, such as \"__call\". to escape a string in this way, call escapeleadingunderscores. to unescape such a string, call unescapeleadingunderscores. strings of this kind are used to represent symbol names and identifier text, to allow for internal symbol names to cohabitate the same symbol table as normal members without being in conflict. the brand on this type is structured such that it is castable and comparable with normal strings, but a normal string cannot be used in its place and it can not be used in place of a normal string (to prevent escaped text from leaking out via diagnostic messages and the like). the union member enabling this is the member intersected with void, which makes it incompatible with anything asking for a string. ", "commit_messages": " created a branded type for escaped strings  then flowed it throughout the compiler, finding and fixing a handful of  bugs relating to underscore-prefixed identifiers in the process.  includes a test for two cases noticed - diagnostics from conflicting  symbols from export *'s, and enum with underscore prefixed member emit.  correctly double underscores wrt mapped types  add fourslash tests for other fixed issues ", "linked_issue_titles": " properties prefixed with double-underscore cannot be accessed in mapped type mappings ", "title": "created a branded type for identifier-escaped strings"}
{"description": " given a schema like this, flatc now outputs a warning about the duplicate attribute: warning: duplicate.fbs(5, 36): warning: attribute already found: priority namespace mygame; attribute \"priority\"; table monster (priority:1, priority:2) { } root_type monster; ", "commit_messages": " added missing endtable() call to verifyobject()  verifyobject called verifytablestart() but not endtable(). this made verifier::verifycomplexity() increase depth_ with each table, not with the depth of tables.    merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  added check to verifyalignment    add getstringview (convenience function to get string_view from a string returning an empty string_view on null pointer) like getstring, getcstring  merge remote-tracking branch 'remotes/upstream/master'  # conflicts:  #\tinclude/flatbuffers/flatbuffers.h  merge remote-tracking branch 'remotes/upstream/master'  flatc should warn, when an attribute is attached more than once.  flatc.exe -b duplicate.fbs  warning: duplicate.fbs(5, 36): warning: attribute already found: priority  duplicate.fbs:  namespace mygame;  attribute \"priority\";  table monster (priority:1, priority:2) {  }  root_type monster; ", "linked_issue_titles": "", "title": "flatc should output a warning, when an attribute is attached more than once"}
{"description": " this makes sure both the systemd services are enabled by default in the install instructions because the rpm packages do not do this, unlike the deb packages. if docker is not enabled then it will not restart on system boot allowing containers with restart policies to be started.  again, this is not an issue for deb based systems because they do this in the install scripts but it is a general expectation that rpm based systems require the user to manually enable these services. ", "commit_messages": " enable docker socket and service on fedora  make sure that the users enable both the socket and service for docker  as part of the default install instructions.  if both are not enabled  docker will not start at boot and restart containers.  state that docker supports fedora 24 ", "linked_issue_titles": "", "title": "enable docker.socket and docker.service in fedora install docs"}
{"description": " removed duplication of faces, vertices, and normals; meshcollider works directly on source mesh (was this very loose coupling there for a reason?) face4 intersection is done through 2 raytriangle calls -> todo: make rayquad function? in addition to distance, raycastnearest returns index of the face the ray collides with (handy to use as uniform in fragmentshaders to e.g. color the \"hit\" face differently) ", "commit_messages": " removed duplication of vertices, faces, and normals from meshcolliderwbox, and pass mesh directly to meshcollider constructor  meshcollider takes original mesh as argument. meshcollider's raymesh extended to support face4 faces (implemented as two raytriangle calls)  fix for face4 raymesh (raytriangle typo). raycastnearest resturns index of face in addition to distance.  raytriangle for face4 type now really fixed ;) ", "linked_issue_titles": "", "title": "expanded collision for meshes to include face4 faces"}
{"description": " this option is stable, since it was added in kubernetes v1.12.0 (sep 2018). the previous $(kubectl config current-context) command may cause bugs after switching contexts. ", "commit_messages": " use --current flag for kubectl kcn alias  this option is stable, since it was added in kubernetes v1.12.0 (sep 2018). the previous $(kubectl config current-context) command will cause bugs after switching contexts.  fully document kcn alias ", "linked_issue_titles": "", "title": "use --current flag in kcn alias"}
{"description": " fixes #3667. i tried to come up with examples that are somewhat real-world, not too complicated and that showcases some of prettier's strengths. ", "commit_messages": " playground: add graphql example  playground: add markdown example  playground: add flow example  playground: add less example  playground: add vue example ", "linked_issue_titles": "", "title": "add playground examples for all languages"}
{"description": " update english grammatical_error_correction.md correct task description. add new best-published results. improve dataset descriptions. fix incorrect links. split results into restricted and unrestricted settings for fairer comparisons. use acl anthology or official proceedings links instead of arxiv links. ", "commit_messages": " update grammatical_error_correction.md  corrected the task description, added two settings for fairer comparison of state-of-the-art  update grammatical_error_correction.md, new sota  new sota added  update links in grammatical_error_correction.md  update grammatical_error_correction.md ", "linked_issue_titles": "", "title": "fixing links and descriptions, and adding new results for grammatical error correction (gec)"}
{"description": " addresses #2711 enables the hc-dark theme on all platforms. improves color contrast to aaa standard on many elements that weren't previously meeting it. resolves visual bugs, such as synthetic-focus misplacement and action bar duplicate icons differentiates the selection of text from current line and find/word matching works well in mac osx even when os-level accessibility features are enabled, such as increasing contrast. note: a css rule used (mix-blend-mode: difference;) currently works in all browsers but opera, ie and edge, so it will not be ideal for the online monaco editor without suitable shims.  let me know if we need to address this; we can do that now or in the future. ", "commit_messages": " enable high-contrast theme on all platforms.  removed unused variable per hygiene.js  inverting selection, for higher contrast.  wip  fixed inversion selection bug from z-index  removed gitter on tree hover high-contrast  moved high contrast inverted effect to its own stylesheet  improved selection hilights for hc-dark theme  changed hc-dark orange color to be aaa compliant with high contrast  aaa compliance with comment token  fixed focus on search input hc-dark theme  removed ghosting bug on activity bar hc-dark theme  aaa compliant scrollbars hc-dark  aaa compliance for current line ", "linked_issue_titles": "", "title": "enabling high contrast dark theme on all platforms + hc-dark improvements"}
{"description": " this adds platform dependent checks to lower the buffer sizes on android to use less memory. it also reduces the normal defaults as perf testing showed we didn't need to be as high. this adds system properties for overriding the defaults, rx.ring-buffer.size and rx.indexed-ring-buffer.size fixes #1820 ", "commit_messages": " rxringbuffersize (128 default, 16 on android)  - changing from 1024 to 128 based on perf tests  - platform dependent check for android to set to 16 to reduce memory usage  indexedringbuffersize (256 default, 8 on android)  - changing from 512 to 256 based on perf tests  - platform dependent check for android to set to 8 to reduce memory usage (use cases on android should rarely if ever hit the use case with merge that requires the higher buffer sizes for performance) ", "linked_issue_titles": "", "title": "reduce ring buffer default sizes (and lower for android)"}
{"description": " correct negative sampling for wav2vec2forpretraining. previously padded feature vectors could be sampled which would give the model bad signals during pretraining. this pr makes sure that a padded feature vector cannot be sampled as a \"negative\" vector. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " fix_torch_device_generate_test  remove @  finish  correct script  correct script ", "linked_issue_titles": "", "title": "padded vectors should not allowed to be sampled"}
{"description": " allow apps to create direct messages; implements getmembers; allow apps to search for direct message rooms based on usernames; ", "commit_messages": " allow apps to create direct messages  implement getmembers;  adds ability to search direct rooms by usernames ", "linked_issue_titles": "", "title": "add more methods to deal with rooms via rocket.chat.apps"}
{"description": " makes the bootstrap timeout configurable increase the bootstrap timeout to 15 minutes. for replica sets with a lot of data, 5 was too low. fixes the error replsetreconfig got badvalue: found two member configurations with same host field when initial join fails part way through. adds publishnotreadyaddresses: true to service since the tolerate-unready-endpoints annotation is deprecated. adds a new service for use by clients that only returns ready endpoints. this resolves clients connecting to pods that are crashing or in the process of joining. users will need to update their applications to the new service to take advantage of this functionality, but they can continue to use the old service and it won't break anything. note that i could not add a discovery service and keep the existing service for clients since servicename in statefulset is not an editable field. fixes #9459 fixes #9266 i tested a new install and upgrade from the previous chart version dco signed ", "commit_messages": " [stable/mongodb-replicaset] fix failure to join replica set  [stable/mongodb-replicaset] fix clients accessing unready endpoints ", "linked_issue_titles": " [stable/mongodb-replicaset] make init timeout configureable  [stable/mongodb-replicaset] unable to join replica set after failure ", "title": "fix joining replica set after failure"}
{"description": " what did you implement: the docs link to cognito user pool triggers aws documentation is only a guide on the incoming events and doesn't contain the actual trigger names. i added a link to the cloudformation documentation that does contain those triggers. how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " changing event link  added words ", "linked_issue_titles": "", "title": "adding cognito user pool trigger documentation link"}
{"description": " pep 8 compliance cleanups for python.d modules with names starting with d, e, f, g, and h. relevant: #4167 ", "commit_messages": " python.d/dnsdist.chart.py pep 8 cleanup  * converted tabs in indentation to spaces (this is why the diff looks  huge).  * fixed container literal formatting.  * general cleanup regarding blank lines.  python.d/dns_query_time.chart.py pep 8 cleanup  fixed container literal formatting.  python.d/dockerd.chart.py pep 8 cleanup  fixed overly long lines and trailing empty line.  python.d/dovecot.chart.py pep 8 cleanup  made string literals use consistent quoting and fixed container literal  formatting.  python.d/elasticsearch.chart.py pep 8 cleanup  fixed container literal formatting.  python.d/exim.chart.py pep 8 cleanup  fixed string quoting and container literal formatting.  python.d/fail2ban.chart.py pep 8 cleanup  fixed string quoting and container literal formatting.  python.d/freeradius.chart.py pep 8 cleanup  fixed quoting of strings and formatting of container literals.  python.d/go_expvar.chart.py pep 8 cleanup  fixed formatting of conainer literals.  python.d/haproxy.chart.py pep 8 cleanup  make string quoting consistent and fix formatting of container literals.  python.d/httpcheck.chart.py pep 8 cleanup  fixed quoting of strings and formatting of container literals. ", "linked_issue_titles": "", "title": "python.d pep 8 cleanup, modules d-h"}
{"description": " this pr adds tests with the sanitizers run by cran on package submissions. see this blog post for a lot more background. the tests take 22 minutes to run, so in this pr i'm proposing that we add them as a manual test that can be triggered by a comment (copying @strikerrus 's great work on #3424 ). this can be triggered by commenting /gha run r-sanitizers-check on a pr. how this makes lightgbm better catches issues like memory violations in lib_lightgbm allows us to catch issues in ci to improve the likelihood of cran accepting submissions of the r package ", "commit_messages": " [ci] add r ci job with ubsan  stuff  fix command  stuff  update template  fail on errors  spaces  trigger by comment ", "linked_issue_titles": "", "title": "add test on r package with sanitizers"}
{"description": " adds support for ssm parameter resolution for cloudformation. there are still some issues with the flow for parameter initialization which will need a bit more refactoring in the future but for now it adds the ssm string parameter support without rewriting too much of the core cfn logic. some other changes: started adding new tests in a new cloudformation test subdir for integration tests since we'll have to add more cfn tests here in the near future. the exiting unittest tests will be moved there in the near future as well and split up where necessary. added new fixtures for cleanup (might make sense to encapsulate them in a utils fixture to avoid too many parameters in the unit tests) minor type hint additions support for change set types (\"create\"/\"update\") and corresponding errors. \"import\" is not yet supported, but a corresponding todo was added. ", "commit_messages": " add cloudformation test for create changeset  change set stack state should be review_in_progress initially  refactor create_change_set and related utils and add tests  add logs client and fix timeout in tests  add helper fixtures for checking and cleaning stacks  implement ssm string parameter resolving for cloudformation ", "linked_issue_titles": "", "title": "support resovling ssm parameter values in cloudformation"}
{"description": " with this commit, three won't crash anymore when calling fromgeometry with an empty geometry as argument. ", "commit_messages": " mrdoob/three.js dev into lowfab/three.js dev  check whether geometry has any faces before accessing faces[0] ", "linked_issue_titles": "", "title": "handle empty geometry in buffergeometry.fromgeometry"}
{"description": " dp= lets you properly attach to child processes now. fixed issues around it. ref rizinorg/cutter#1894 ", "commit_messages": " add process selection to linux native debug ##debug  previously, dp= wouldn't fully switch to the given process since it was  treated like dpt thread switching, leaving the debugger in an undefined state.  fix linux_set_options error ##debug  previously, setting options would fail sometimes since pt_attach's attach  sigstop wasn't hit before reaching linux_set_options.  allow debug plugins to modify pid/tid on select ##debug  previously, when using dp=, the debug plugin would set a new tid based  on the requested pid, but r_debug_select would set the old tid as dbg->tid,  resulting in issues interacting with the current thread. this could also  be an issue when the requested pid/tid is invalid and the plugin selects  something else. ", "linked_issue_titles": "", "title": "linux native debug process selection fixes"}
{"description": " summary added the op batch_normalization in the numpy backend. related issues pr overview added the function in the numpy backend added the numpy implementation in the docs added tests. this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) ", "commit_messages": " finished the functions.  started doing the test function.  added the batch_normalization operation to the numpy backend. ", "linked_issue_titles": "", "title": "added batch_normalization in the numpy backend."}
{"description": " fixes #21947 i replaced the sentence descriptions for possible choices of parameter include_boundaries in the documentation of function check_scalar with interval notations. the members are discussing which interval notation to use. i went ahead and made changes as per the english notation. will make changes, if members decide to go ahead with other notation. ", "commit_messages": " add interval notation in check_scalar doc ", "linked_issue_titles": " add interval notation for include_boundaries parameter for the function check_scalar ", "title": "doc add interval notation for include_boundaries in documentation check_scalar"}
{"description": " this bumps gnutls to last stable v 3.3.10 and enables gnutls support in ffmpeg on android (again). i can't remember the exact reason why it was disabled for gotham - some unresolved symbols or the locking callbacks maybe - but it should be fixed with moving ffmpeg to depends. i've been running this on adt-1 for a while and didn't notice issues related to it. it also got some user testing, see ", "commit_messages": " [android] re-enable gnutls in ffmpeg  [depends] bump gnutls to last stable version 3.3.10  [depends] fix nettle dylib target  [depends] fix gmp makefile ", "linked_issue_titles": "", "title": "enable gnutls support in ffmpeg"}
{"description": " remove compatibility module from actioncontroller, either by cleaning up code that is going to be deprecated in 3.2, or by moving code to their right places inside actioncontroller modules. i'm sending a second pull request for 3-2-stable branch deprecating most of the methods inside this module. please let me know if something should be improved. thanks. ", "commit_messages": " remove old compatibility methods not being used  remove constant already defined in exceptions module  remove other old compatibility constants  remove rescue_action from compatibility module and tests  remove relative url root setting from env var  this is already being set by rails configuration.  remove deprecated logic to render templates starting with /  render :template => \"/foo/bar\"  rename test class and fix tests to keep consistency  based on 50d23bc2bd3653b3c66e480c22ae97c5f7fd7f62.  move render :nothing and :text => nil options to ac::rendering  refactor render nothing/text => nil logic, and move to right place  options :nothing and :text => nil should be handled by  actioncontroller::rendering instead.  remove method missing handling when action is not found, use action missing instead  do not create a method_missing method to handle not found actions, use  the action_missing method provided by rails instead.  move render_to_body logic to return a spaced string to ac::rendering  this seems to be required only when calling render :partial with an  empty collection from a controller. this call happens to return no  content, letting the response body empty, which means to rails that it  should go on and try to find a template to render based on the current  action name, thus failing hard.  although tests keep all green, we need to check a better way to fix  this.  remove deprecated default_charset= from ac::base  this should be set globally as a configuration, using  config.action_dispatch.default_charset instead  move protected instance variables definition, kill compatibility module  bring back rendering templates that start with / in nested structures  update changelog ", "linked_issue_titles": "", "title": "action controller refactor - remove compatibility module"}
{"description": " in the scenario that we have multiple ray clusters with processes running on the same node, we want to make sure that each cluster's dashboard only contains metrics from the processes in its cluster. the ray reporter process collects node-level metrics about ray workers, but some of the ray worker processes running on a given node could belong to other ray clusters (the way workers are currently identified is through a process name-prefix, and we will eventually want to make more structured). we could have, in theory, gotten a list of relevant worker process ids via an rpc call; however this would have have added strain to the core system. for the time being at least, i have placed the relevant changes on the front end. there is a concept now of clusterworkers, which is a subset of the workers in a given node's stats. this clusterworkers subset is calculated by looking at the process ids of the workers in the raylet stats that the reporter fetches for the dashboard. the data is then used to filter the worker values that are being passed into various parts of the ui, such as node details table data and data aggregation rows. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip  wip  wip  add an idea of cluster workers versus all workers on a node. we do not want to show workers on the dashboard that are on a node belonging to our cluster, but that do not themselves belong to the cluster because the node hosts more than one ray cluster. ", "linked_issue_titles": "", "title": "dashboard only shows workers in its cluster"}
{"description": " when using flow-offloading with [luci-app-pptp-server] installed, [luci-app-pptp-server] rules will forward all the traffic which the protocol name includes ppp, which means pppoe traffic also will be forwarded. to solve this problem, iptables need to add return rules when matching pppoe. thanks to @lga1150 ", "commit_messages": " update pptpd.include  if not return pppoe traffic, it will make flow-offload rules has no effect. ", "linked_issue_titles": "", "title": "fixed conflict with flow-offloading rules"}
{"description": " new keyboard tgr 910 ce (note this is different than the 910) with via keymap added in. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " initial commit for tgr 910 ce  got firmware working on the 910 ce  add via support  add iso and all layouts  update information about resetting the board  fixup default keymap to have a second layer  fixup default keymap  add via enabled keymap  cleanups and adding community layout support  add caps lock led support and backlight  add qmk configurator support ", "linked_issue_titles": "", "title": "new keyboard: tgr 910 ce"}
{"description": " system indices should be hidden from users. since they are already restricted indices, a users that can't view restricted indices already can't see or access them, but they should also be hidden for superusers or users that are otherwise granted advanced privileges. to the greatest degree possible, we apply hidden settings in the transport layer, so that the system can create an index or alias that is set to visible, for example, when operating in a mixed cluster mode. however, in the case of aliases created by templates, we hide the alias in the service layer. this change has broken a number of tests that were relaying unnecessarily on wildcard searches. in general, the fix for these issues was to apply expand_wildcards=open,hidden to the request. ", "commit_messages": " force system indices to be hidden in indexmetadata  hide system data streams ", "linked_issue_titles": "", "title": "all system indices are hidden indices"}
{"description": " the patch fixed the errors when using bash and cmder is installed under a directory with spaces in the path, e.g. c:\\users\\foo bar\\cmder . please review. thanks. the first commit fixed errors i encountered (in v1.3.0), while the second commit fixed similar issues. note: the development branch (the base) is behind master, in fact, pre v1.3.0.  should i stick with merging to it? ", "commit_messages": " fix bash login when ${cmder_root} has spaces.  e.g., if ${cmder_root} is /c/users/foo bar/cmder,  the following errors will occur:  bash: pushd: /c/users/foo: no such file or directory  bash: [: /c/users/foo: binary operator expected  bash: /c/users/foo: no such file or directory  further fix bash login when ${cmder_root} has spaces.  inspecting the script uncovers similar problems elsewhere  not encountered in my initial testing. they are fixed accordingly. ", "linked_issue_titles": "", "title": "fix bash login when $cmder_root has spaces"}
{"description": " this reinstates the use of direct adjacency information when gathering constraints, effectively reverting 54bdd7b. one-way constraints get added but aren't traversed. fixes the regression tracked by rdar://problem/54274245. ", "commit_messages": " [constraint graph] reinstate the adjacencies of constraint graph nodes.  reinstate the list of adjacencies in each constraint graph node,  effectively reverting  dfdd352d3d236851a0e5b7fb93d1286966032089. exclude one-way constraints  from this computation; we'll handle them separately.  [constraint graph] use adjacency info for constraint gathering.  this reinstates the use of direct adjacency information when gathering  constraints, effectively reverting  54bdd7b840721523f363e343d7b25997a8a332fe.  fixes the regression that commit caused, which is tracked by  rdar://problem/54274245. ", "linked_issue_titles": "", "title": "reinstate the use of adjacency information for constraint gathering"}
{"description": " this pr finishes to clean up some old references to sphinx in the setup or makefile and updates the contributing guide/docs readme to explain to users how to build the docs with our new tool or how to write them. fixes #14762 ", "commit_messages": " clean up sphinx  update contributing guide  update docs readme ", "linked_issue_titles": " make docs failing ", "title": "post sphinx-clean up and contributing guide updates"}
{"description": " fixes two small bugs: fix platform import on linux using python3 $ mitmproxy -t --host mitmproxy: transparent mode not supported on this platform. using python3 sys.platform returns linux instead of linux2 (python2). this causes the platform import to fail on python3. substitute tilde with user's home. delivering the cert ~/.mitmproxy/mitmproxy-ca-cert.pem using mitm.it fails because the tilde is not replaced with the user's home directory. ", "commit_messages": " fix platform import on linux using python3  using python3, sys.platform returns \"linux\" instead of \"linux2\" using  python2. this patch accepts \"linux\" as well as \"linux2\".  substitute tilde with user's home.  when downloding the mitmproxy certificate using mitm.it, '~' currently  is not expanded causing a filenotfoundexception. this patch uses  expanduser() to replace the initial tilde with the user's home. ", "linked_issue_titles": "", "title": "fix platform import, substitute \"~\" with user's home"}
{"description": " for #2927. ", "commit_messages": " [docs] flatbutton - revert linkbutton example, and document linkbutton & href props  [docs] floatingactionbutton - flatten example code, document linkbutton & href props  [docs] raisedbutton - add title & description to examples, document linkbutton & href props  [docs] radiobutton - add description to example, document 'checked' prop as internal ", "linked_issue_titles": "", "title": "flatbutton, fab - document linkbutton & href, raisedbutton, radiobutton - add title & description to examples"}
{"description": " earlier changes to the stm32f1 serial isr has eliminated hanging due to serial overflows when using serial 1-5 for marlin or dgus communication. these changes missed the following two usages of serial, which could still hang: malyan lcd, which hard-coded serial1 in its cpp file. tmc hardware serial to resolve this, several changes were made: add malyan_lcd_serial_port to configuration.h. update stm32f1 hal.h to handle this new port like it does for other ports which may control the printer. always instantiate all mserial ports (1-3 or 1-5, depending on board) to allow them to be easily used from pins files. make emergency parser optional in mserial class, so it won't be enabled for malyan_lcd or tmc. update all stm32f1 pins files to use mserial instead of serial. add static asserts that detect anything using serial classes, since they can cause the board to hang. avoid potentially unsafe hangs when using hardware serial for a malyan lcd or tmc uart communication. these configurations are for an skr e3 dip with tmc 2209 drivers and a malyan lcd attached to the tft port. using this i was able to reproduce hangs while printing prior to this change, even though this is using softwareserial for the tmc drivers. configurations_malyan.zip #18358 ", "commit_messages": " update malyan lcd to use mserial on stm32f1, and try to prevent use of non-mserial ports.  add configuration.h option. ", "linked_issue_titles": "", "title": "fix more stm32f1 serial hangs due to overflows"}
{"description": " when i pulled in the default starter to build my website, one of the first things i changed was to add more html landmarks. so that everyone can benefit from this accessibility improvement, i added main and header elements to the default and blog starters. that way, screen reader users can navigate gatsby sites by landmarks. more information: ", "commit_messages": " add header and main landmarks to blog starter  these improve accessibility for screen reader users, along with the existing html footer element.  add header and main landmarks to default starter ", "linked_issue_titles": "", "title": "add landmarks to default & blog starters"}
{"description": " you probably don't want to look at the changes, it's huge, instead look at the individual commits. this pr updates the bullet wrapper to version 2.82 rev 2704, but doesn't add the new functionality (like featherstone and mlcp). it only updates the existing functionality of the wrapper with the bug fixes of 2.82. it also includes some additional changes i had pending, closes #826 closes #836 and closes #837. tested on win64 and android. this pr is mostly to check the others builds on jenkins, therefor will merge myself. i will try to create the swig interface for the new functionality tomorrow. ", "commit_messages": " update bullet source to 2.82 rev2704  more bullet source updates (rev2704)  fix build + add callbacks + add btsimplexsolverinterface  swig generated files  include original files to reference custom patch  re-apply: fixed btscalar to not use sse on ios simulator  update vs project ", "linked_issue_titles": " contactlistener generates a lot of garbage, pool btcollisionobjectwrappers!  filtering collisions using a broadphase filter callback  convex hull distance ", "title": "update to 2.82 rev 2704"}
{"description": " this incorporates the ideas of #2434 ", "commit_messages": " dvdplayer: move canseek/canpause to seekable interface  dvdplayer: disable seeking and pause for udp/rtp and seek for tcp  dvdplayer: move navigator state into imenus  this allow bluray navigator to make use of it eventually ", "linked_issue_titles": "", "title": "disallow seeking for udp and some interface improvements in dvdplayer"}
{"description": " gdb catches sigint and by default doesn't pass it to process. but it passes sigterm ", "commit_messages": " dbms: fix build  basedaemon: change terminate signal to sigterm.  gdb catches sigint and by default don't pass it to daemon ", "linked_issue_titles": "", "title": "terminate sends sigterm instead of sigint"}
{"description": " handles #7158 ", "commit_messages": " completion list for a class extending another class should contain members from base class  handles #7158  give the class element completion on typing keywords like public, private, readonly  also when name of the function is location, make sure we are actually looking at the same symbol before using the declaration to get signature to display  tune the completion list for static and private modifiers  do not show inherited members in completion for when writing private member  show only static inherited members when writing static member ", "linked_issue_titles": "", "title": "when writing class elements show completion with allowed keywords and inheritted properties"}
{"description": " as per  this is the initial machinery to setup the l10n infrastructure for markdown documentation. a new \"docs-l10n\" target will take care of generating, updating and then building .pot and .po files, and later on the final .md. this commit includes the .pot for all current .md docs; they can be feed directly to mozilla verbatim if wanted. please note that po4a only provides the orig.md -> .pot -> l10n.po -> l10n.md flow. the l10n.md -> l10n.html generation is not currently built in the makefile, as no language has been enabled. ", "commit_messages": " use po4a to provide translatable documentation  this commit add a new \"docs-l10n\" make target which uses po4a to:  * create .pot (po templates) from markdown doc  * update templates and po for enabled languages  * generate translated markdown for completed (> 80%) translations  currently, no language has been activated.  generate initial translatable templates for documentation  these files are automatically genereated by make docs-l10n (via po4a),  which will also take of updating them if the original .md changes. ", "linked_issue_titles": "", "title": "initial po4a setup for translatable markdown documentation"}
{"description": " our eventual goal is to completely remove unboundgenerictype. one of the places where we return an unboundgenerictype is from getdeclaredtype(). this pr begins the preparations for removing getdeclaredtype() by replacing calls with getdeclaredinterfacetype() when the declaration is known to be non-generic, in which case it returns the same thing. ", "commit_messages": " ast: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  sema: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  sil: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  clangimporter: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  ide: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  irgen: replace some calls to getdeclaredtype() with getdeclaredinterfacetype()  frontend: replace some calls to getdeclaredtype() with getdeclaredinterfacetype() ", "linked_issue_titles": "", "title": "replace trivial calls to getdeclaredtype() with getdeclaredinterfacetype()"}
{"description": " this is a series of updates to the tokenizer and tokenizer docs in order to sync the docs and the current tokenizer implementation. a new tokenizer function makes debugging the tokenizer a bit easier by implementing a slow debugging version that returns labels for each token about the pattern or rule matched, based on the pseudo-code in the docs. there are some minor changes to tokenizer to bring it in sync with the intended behavior based on the docs. while updating the pseudo-code in the docs, it made sense to make a working version to check the details, so i expanded that just a bit to add some better debugging functionality. i think keeping this in sync with the actual tokenizer will be a similar amount of effort to keeping the pseudo-code in the docs in sync. instead of being in the tokenizer itself, it could also be an example/demo script that takes nlp.tokenizer as an argument, but i liked being able to implement unit tests that compared its behavior to the actual tokenizer. i wish that it were easier to add tests for more of the tricky cases, since i haven't formally tested that the behavior is identical for all of the unusual test cases. it's also kind of unsatisfying that it doesn't handle whitespace tokenization, but this isn't usually a source of confusion for users and i think adding it would make the pseudo-code harder to read, and it's already a bit too long. i wouldn't be opposed to adding it, though. fixes #4573, fixes #4645. edited: implements explain() method that returns a list of (pattern_string, token_string) tuples to avoid the hacky displacy usage. easy displacy integration is postponed to a future pr. outdated description of displacy integration: in the initial version, the information is stored in a doc with the debugging information saved on the tags. this is a bit hacky since there's no way to mark the doc as not-for-actual-use, but it makes for easy visualization. alternatively, the labels could also be stored on a custom attribute and the visualization would require a few extra steps. i also tried visualizing the labels as entity spans, but the default entity visualization was pretty hard to read with labels on every token. with custom templates, it could be made a bit more readable and having the information as spans might be better than as hacky tags. (or there could be a \"tag\" visualization where you can specify which attribute to display?) docs, enhancement. i have submitted the spacy contributor agreement. ", "commit_messages": " expose tokenizer rules as a property  expose the tokenizer rules property in the same way as the other core  properties. (the cache resetting is overkill, but consistent with  from_bytes for now.)  add tests and update tokenizer api docs.  update hungarian punctuation to remove empty string  update hungarian punctuation definitions so that _units does not match  an empty string.  use _load_special_tokenization consistently  use _load_special_tokenization() and have it to handle none checks.  fix precedence of token_match vs. special cases  remove token_match check from _split_affixes() so that special cases  have precedence over token_match. token_match is checked only before  infixes are split.  add make_debug_doc() to the tokenizer  add make_debug_doc() to the tokenizer as a working implementation of  the pseudo-code in the docs.  add a test (marked as slow) that checks that nlp.tokenizer() and  nlp.tokenizer.make_debug_doc() return the same non-whitespace tokens  for all languages that have examples.sentences that can be imported.  update tokenization usage docs  update pseudo-code and algorithm description to correspond to  nlp.tokenizer.make_debug_doc() with example debugging usage.  add more examples for customizing tokenizers while preserving the  existing defaults.  minor edits / clarifications. ", "linked_issue_titles": " prefix_search overriding token_match in tokenizer  custom tokenizer token_match doesn't seem to take proper precedence ", "title": "add tokenizer explain() debugging method"}
{"description": " i hereby agree to the terms of the cla available at:  changelog category: detailed description / documentation draft: by adding documentation, you'll allow users to try your new feature immediately, not when someone else will have time to document it later. documentation is necessary for all features that affect user experience in any way. you can add brief documentation draft above, or add documentation right into your patch as markdown files in docs folder. if you are doing this for the first time, it's recommended to read the lightweight contributing to clickhouse documentation guide first. ", "commit_messages": " add files in ru docs  add ru translation  edit en text ", "linked_issue_titles": "", "title": "edit and translate to russian"}
{"description": " travis use latest platformio v.4.2. changes neede in platformio.ini backward compatible the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.6.1 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " update .gitpod.yml  update  update platformio.ini  update platformio.ini ", "linked_issue_titles": "", "title": "fix platformio.ini syntax for v.4.2 (and travis compile fail)"}
{"description": " corrects errors in the qmk configurator implementation, and enables community layout support. current layout_tkl_ansi shown; layout_tkl_iso similar:  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " correct layout_tkl_ansi data  number row was positioned 0.25u too low.  correct layout_tkl_ansi macro  - remove position k027 (right half of split backspace)  - remove position k096 (right portion of split right shift)  correct layout_tkl_iso macro  - remove position k027 (right half of split backspace)  - remove position k096 (right portion of split right shift)  enable community layout support  add layout_tkl_ansi_split_bs_rshift and layout_tkl_iso_split_bs_rshift ", "linked_issue_titles": "", "title": "linworks fave87 layout macro refactor"}
{"description": " extract interaction constraints from split evaluator. the reason for doing so is mostly for model io, where num_feature and interaction_constraints are copied in split evaluator.  also interaction constraint by itself is a feature selector, acting like column sampler and it's inefficient to bury it deep in the evaluator chain.  lastly removing one another copied parameter is a win. enable inc for approx tree method. as now the implementation is spited up from evaluator class, it's also enabled for approx method. removing obsoleted code in colmaker. they are never documented nor actually used in real world.  also there isn't a single test for those code blocks. unifying the types used for row and column. as the size of input dataset is marching to billion, incorrect use of int is subject to overflow, also singed integer overflow is undefined behaviour.  this pr starts the procedure for unifying used index type to unsigned integers.  there's optimization that can utilize this undefined behaviour, but after some testings i don't see the optimization is beneficial to xgboost. related to #4732 . ", "commit_messages": " extract interaction constraints, enable it for approx.  * extract interaction constraints from split evaluator.  the primary reason for doing so is that it copies the num_feature parameter,  which makes serialization and parameter validation difficult.  also, as it  should be used for selecting feature, like column sampler, instead of computing  weight.  * clean up for colmaker.  remove support for parallel_option and cache_opt.  now we use whatever  settings that are default before this pr.  as these parameters are never  documented nor actually maintained.  * enable for approx.  remove the implementation in split evaluator.  mention in doc. ", "linked_issue_titles": "", "title": "extract interaction constraint from split evaluator."}
{"description": " with #18777 it's no longer necessary to update the shadow camera bounds every frame because the the xy dimensions are always based on the longest edge of the frustum. this pr moves the shadow bounds update into updatefrustums which only gets called when the camera frustum changes in order to reduce the work needed to update every frame. it also removes the need to pass matrixworld into update and instead just uses the member cameras matrixworld. temporary live link:  @vhawk ", "commit_messages": " separate shadow bounds update from update  remove need to pass camera matrix world to update  remove unnecessary shadow camera updates ", "linked_issue_titles": "", "title": "remove unnecessary logic in \"update\""}
{"description": " when image is not specified, but the container needs to be re-created for some reason (restart, configuration changed, etc.), currently simply nothing happens (without any user feedback). this is a consequence of #41678, which simply does not run the configuration check when image is not specified. this pr replaces the change in #41678 with slightly more sophisticated code: if the container doesn't exist yet, a (useful) error is returned because image is really needed in this place. if the container already exists, the container's image id is used for recreation. fixes #21188, fixes #27960. docker_container ansible version 2.8.0 ", "commit_messages": " don't simply ignore container in present() if image is not specified.  use image from existing container for recreation if not specified. ", "linked_issue_titles": " restarting container with non-default log driver fails with \"no command specified\"  docker_container state: stopped is broken (fails and removes container) ", "title": "fix behavior when image is not specified"}
{"description": " the main difference is level 19 using btultra strategy (which is now badly named, since it's no longer reserved for --ultra levels anymore) so that we can make level 19 a \"strongest compression level at window size <= 8 mb\". several other levels have been updated, to reflect improvements in intermediate strategies, and smooth the speed/compression curve on a slightly larger scale, due to level 1 being faster, and level 19 being stronger. ", "commit_messages": " update compression levels for large inputs  update table for 128 kb blocks  update table levels for blocks <= 16k  also : allow hlog to be slighly larger than windowlog,  as it's apparently good for both speed and compression ratio.  updated compression levels for blocks of 256kb ", "linked_issue_titles": "", "title": "update table of compression levels"}
{"description": " refactoring no if relevant, link to documentation update: n/a summary rename variables from async to future proof names no other information based on review feedback from #3166 ", "commit_messages": " fix lint issues  rename variable for future compatibility  fix lint issues  rename variable for future compatibility  fixup eslint issues  rename variable for future compatibility ", "linked_issue_titles": "", "title": "rename async for future compatibility"}
{"description": " commit message: log xds control plane server identifier on change this is already exported as a stat but it's useful for post-hoc debugging if it shows up in the logs. risk level: low testing: ran affected tests docs changes: n/a release notes: n/a platform specific features: none ", "commit_messages": " add logging of control plane identifier  this only affects grpc_mux_impl. the corresponding change to  new_grpc_mxu_impl will be made in a future commit.  add remote identity logging for new_grpc_mux_impl  this will help diagnose issues when envoy connects to a load-balanced  xds endpoint with multiple serving backends. ", "linked_issue_titles": "", "title": "log control plane identifier on change"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes:  regarding the last checkbox above: there are additional types added in the newer version of nunjucks which i haven't added here, so i suppose this change doesn't bring it up to date with the newest version? but further than this i have a bigger concern about the versioning here. there are also the previously defined extend types which are incorrect:   ^ these are definitions for an instance method which does not exist (its static, as my new types show). as such if you try to call extend on an instance of the loader class as the existing type definition defines it, you will just get a runtime error because extend is not defined. i think it would be best to remove those incorrect types, but i'm not quite sure what the procedure would be in terms of versioning. removing those would technically be a breaking change, but the code that it breaks would just be failing at runtime currently. i hope someone can advise what i should do if i am to remove the incorrect type. the definetelytyped documentation on versioning is mum on the issue of a breaking change that doesn't correspond to a new major version for the typed package. for now i haven't removed the incorrect type from the loader class, i've only added the correct type for the static version of the method that actually does exist. ", "commit_messages": " fix incorrect extend type  add test for documented loader extension approach ", "linked_issue_titles": "", "title": "fix incorrect loader extend type in type definition"}
{"description": " closes #40951 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry ", "commit_messages": " times in ewm groupby: sort times in according to grouping; add missing support for times in numba implementation; fix bug in cython implementation  add gh issue id to tests ", "linked_issue_titles": " bug: issues with groupby ewm and times ", "title": "various groupby ewm times issues"}
{"description": " description: #17415 was merged to dev but not master.  since then the init.py has been updated to reflect other changes.  this pr brings the previous pr and current together.  previous #17415 was being tested and i can confirm is valid.  @awarecan sorry about the delay and misunderstanding.  i have also updated the services.yaml to reflect the correct id to use.  i will submit another pr to update documentation. also, the request sync timeout was set to 5s.  routinely the service would sync but throw an error indicating that  \"could not contact google for request_sync\".  this was not the case.  the service did sync and new devices would show up.  however google was not responding within the 5s timeout threshold.  i tested up to 10s and sometimes the same thing would happen.  a safe value ended up being 15s.  i have a very large amount of devices sync'd to ga (200+) and this is likely the reason for googles response taking longer than 5s. related issue (if applicable): fixes #17380 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): request_sync: description: send a request_sync command to google. fields: agent_user_id: description: \"optional. only needed for automations. specific home assistant user id (not username, id in configuration > users > under username) to sync with google assistant. do not need when you call this service through home assistant front end or api. used in automation script or other place where context.user_id is missing.\" checklist: ", "commit_messages": " fix google assistant request sync service call  more descriptive services.yaml  update services.yaml ", "linked_issue_titles": " google_assistant.request_sync at homeassistant start ", "title": "update google assistant services description and request sync timeout"}
{"description": " this pr replaces the shardrouting argument in abstractsearchasyncaction#onfirstphaseresult with the more contained string nodeid argument, as that is the only info retrieved from it. the shardid can also be read directly from the sharditerator that's already provided as an argument, plus there is no need to create new instances of shardid by providing the index and the int shard_id separately, the whole shardid should be passed around when possible. the searchshardtarget constructor that takes shard_id and index separately stays only for testing purposes. ", "commit_messages": " replace shardrouting argument in abstractsearchasyncaction#onfirstphaseresult with more contained string nodeid  there is no need to pass in shardrouting if the only info read from it is the current node id, the shard id can be read directly from the sharditerator that's already provided as an argument.  avoid creating a new shardid when creating a searchshardtarget in snapshotsservice ", "linked_issue_titles": "", "title": "don't carry shardrouting around when not needed in abstractsearchasyncaction"}
{"description": " add more information in trace-api-plugin responses for better usage. add transaction_mroot, action_mroot and schedule_version in block trace; add status, cpu_usage_us, net_usage_words, signatures and transaction_header in transaction trace. see #9005 for release/2.0.x version ", "commit_messages": " add more info in block trace & transaction trace.  remove unused include; remove unnecessary copy when caching traces.  add receipt check; remove unnecessary constructors  fix wrong index ", "linked_issue_titles": "", "title": "[develop]add more info in trace-api-plugin"}
{"description": " new server session monitor for sau (simultaneously active users), which will provide important informations for dau (active daily users) and mau (monthly active users). the monitor is based on meteor server sessions and will store the data in a new collection: rocketchat_sessions. the approach of this implementation will deal with connection events, such as onconnection and onclose, as well as dealing with account events, such as onlogin and onlogout. the sau monitor will use the meteor server sessions to update the session activities in db. the monitor will ping the active sessions every minute, updating the lastactivityat field on session documents. the session lifecycle is stored per day, so when the server date is changed, the current sessions will be created on the new day. this behaviour is designed to facilitate the collector process, which will aggregate the session life cycle and store it in another collection of statistics. the regular(non-mobile) session documents will look like the doc below: { \"_id\" : \"xsm2orqtspwgyoqt2\", \"year\" : 2018, \"month\" : 7, \"day\" : 20, \"instanceid\" : \"lpvdxjh8fydy6qsyz\", \"sessionid\" : \"ystqpjsifhffxwdis\", \"userid\" : \"uk294ojdzhyfqk53p\", \"ip\" : \"127.0.0.1\", \"host\" : \"localhost:3000\", \"browser\" : { \"name\" : \"chrome\", \"version\" : \"67.0.3396.99\", \"major\" : \"67\" }, \"os\" : { \"name\" : \"mac os\", \"version\" : \"10.13.6\" }, \"createdat\" : isodate(\"2018-07-20t17:06:32.480z\"),  //when the session is created \"lastactivityat\" : isodate(\"2018-07-20t17:10:01.166z\"), //when the session monitor updates current sessions in bucket storage \"loginat\" : isodate(\"2018-07-20t17:06:32.491z\"), //user login \"logoutat\" : isodate(\"2018-07-20t17:10:07.311z\") //user logout } the mobile session documents will look like the doc below: { \"_id\" : \"yloj68zja6wfnft3b\", \"day\" : 26, \"instanceid\" : \"lpvdxjh8fydy6qsyz\", \"month\" : 7, \"sessionid\" : \"wtrw5snha7wfudxaz\", \"year\" : 2018, \"ip\" : \"200.34.239.117,127.0.0.1\", \"host\" : \"d16877f6.ngrok.io\", \"os\" : { \"name\" : \"ios\", \"version\" : \"11.4.1\" }, \"device\" : { \"type\" : \"mobile\" }, \"app\" : { \"name\" : \"rc mobile\", \"version\" : \"v3.0.2\", \"bundle\" : \"(202)\" }, \"createdat\" : isodate(\"2018-07-26t18:57:49.475z\"), \"userid\" : \"uk294ojdzhyfqk53p\", \"loginat\" : isodate(\"2018-07-26t18:57:49.812z\"), \"lastactivityat\" : isodate(\"2018-07-26t18:58:03.834z\"), \"closedat\" : isodate(\"2018-07-26t18:58:03.834z\") } this new feature is being implemented in 3 steps: model design (sessions) monitor implementation this pr will close the issue number: #11461. once the implementation is approved, we need to think about the creation of a cron job that will collect the data every day, aggregating the data and storing in two other collections: sau and mau. ", "commit_messages": " initial implementation on server session monitor.  session model created.  session model design done. ", "linked_issue_titles": "", "title": "collect data for monthly/daily active users for a future dashboard"}
{"description": " closes #43704 description of render trimming and maximums bug: pd.options.styler.render.max_columns = 5 pd.options.styler.render.max_rows = 5 df = dataframe(np.random.rand(10,10)) df.columns = pd.multiindex.from_product([[0,1,2,3,4], [0,1]]) df.index = pd.multiindex.from_product([[0,1,2,3,4], [0,1]]) df.index.names, df.columns.names = [\"a\", \"b\"], [\"c\", \"d\"] df.style.hide([(0,0), (0,1), (1,0)], axis=1).hide([(0,0), (0,1), (1,0)], axis=0) pre #44248 after #44248 (merged) after this pr ", "commit_messages": " col trim on headers  col trim on index names  # conflicts:  #\tpandas/tests/io/formats/style/test_style.py ", "linked_issue_titles": " bug: styler render trimming does not work with `hide_columns` ", "title": "styler hide compatible with max_columns"}
{"description": " reduces checkstyle errors for patterns: naked-objects null-object object-mother object-pool observer queue-load-leveling changes involved java docs reordering imports indentations line length issues ", "commit_messages": " reduces checkstyle errors in naked-objects  reduces checkstyle errors in null-object  reduces checkstyle errors in object-mother  reduces checkstyle errors in object-pool  reduces checkstyle errors in observer  reduces checkstyle errors in queue-load-leveling ", "linked_issue_titles": "", "title": "resolves checkstyle errors for naked-objects null-object object-mother object-pool observer queue-load-leveling"}
{"description": " this pr transforms the slots inside the slider as standalone styled components. this will allow us to support back the classes prop on this component. plaground for testing the classes prop here - ", "commit_messages": " add emotion peer dependencies  fixed types & tests  prettier  extract components ", "linked_issue_titles": "", "title": "extract slots as standalone components"}
{"description": " this pr: integrates zero-infinity revamps the configuration process, instead of the confusing to users sometimes-we-override-values, sometimes-we-don't - all values are now explicit unless they are set to auto, then and only then the trainer will set them to the correct or recommended values. massively revamps the way the configuration is done. now splitting the config parsing into 2 phases - one happening at the very end of trainingarguments and then a weak ref global module var is created which can then be queried by various transformers components w/o needing to change any apis. the global object cleanly goes away when trainingarguments goes out of scope. users no longer need to make any special calls - just need to ensure the  trainingarguments object is created before model.from_pretrained() is called (like we do in all examples). phase 2 happens during train where we get a few variables that weren't there during trainingarguments, so the config gets completed here. ds_config is now passed to zero.init in from_pretrained under zero-3 since it now needs several configuration values - this is in preparation for fp32 and other important features. adds new tests for zero-inf and configuration. adds a minor fix in  get_regression_trainer if you're testing this pr please make sure you install deepspeed master branch: git clone  cd deepspeed pip install -e . important changes please note a major change is that now only params that are set to auto will get automatically overriden/set to the correct/recommended values, everything else is left as is. this is to avoid the previously confusing behavior of never being quite sure what gets overridden and what not despite the logger telling what it did override. the new behavior is completely unambiguous. see: examples zero2 zero3 it's ready to release now. 0.3.15 just has a debug print that is loud, fixed in their master. ", "commit_messages": " adding z-inf  revamp config process  up version requirement ", "linked_issue_titles": "", "title": "zero-infinity integration plus config revamp"}
{"description": " i've been working on this on and off for the past few days, thought we could open it for more participation, but i've created a spanish translation of the list, and will continue work until it's done. then the task of maintaining parity will begin. i wonder if there is an easier way to do this, i was working on it in a branch for just a day, and it there was lot of drift. also noteworthy, i did a lot of grammar checks on the english list as well because translating to spanish highlights very well where some of the english errs. so edits were done frequently on both, often at the same time. i decided now was good enough to push it, since it's reached parity with the brazilian portuguese copy. ", "commit_messages": " first commit for spanish branch  beggining translation  first chunk of translation  dusting off the cobwebs, and changing minor bits to account for this being a translation of another document.  continuing work on the table of contents  finished tables of contents  now onto the software itself.  beggining audio and some grammar:  audio is starting, but also working on grammar up top.  audio section completed  moving through chat clients  trying to maintain rough equivalence.  catching up to master from lewisvo  grammar in both lists  continuing translation.  grammar in both files  continuing translation, but also noticing issues with the english translation.  more side by side grammar fixing:  fixing one, improves the other!  updating links  links for macbuntu outdated, will be outdated again in a month. must remember to update these!  adjusting and fixing links  well we've reached parity with the portuguese translation, it's time to bring this branch into the fold.  spanish merging into the fold ", "linked_issue_titles": "", "title": "created a partial spanish translation:"}
{"description": " added nullabletraits template to represent potential null value. also, modified outputs for empty object and array values in pretty-print mode. now, they are emitted as {} and [] instead of: { } [ ] ", "commit_messages": " [jsonserialization] add ability to emit 'null' value  [jsonserialization] compact output for empty objects and arrays  now, they are represented as {} and [] instead of:  {  }  and  [  ]  [jsonserialization] add basic unit tests for jsonserialization ", "linked_issue_titles": "", "title": "add ability to emit 'null' value."}
{"description": " currently parse-time lookup diagnoses these, so we need to implement it in sema to prepare for disabling parse-time lookup. there are two cases: local declarations inside a bracestmt are now handled via the same checkredeclarationrequest used for type and global members, because we visit them as part of typecheckdecl(). for this, i added a new finishlookupinbracestmt flag to astscope::lookuplocaldecls(); when set, this stops the lookup at the innermost bracestmt, because for purposes of re-declaration checking we only want to consider other declarations with the same name contained in the same bracestmt. this is because shadowing of local declarations from outer scopes is, in fact, permitted. generic parameters, function parameters and pattern bindings in statements get their own bespoke check. this one is simpler, since we have all the declarations in a sequence; we just iterate over sequence looking for duplicate names. while we're here, delete a couple of bits of dead code as well. ", "commit_messages": " ast: remove unused unqualifiedlookupfactory::consumer field  ast: remove unused nameddeclconsumer class  sema: remove dead code from checkredeclarationrequest::evaluate()  astscope: add finishlookupinbracestmt parameter to astscope::lookuplocaldecls()  this will be used to implement re-declaration checking for local  declarations. currently this is handled by parse-time lookup.  to make it work with astscope, we need to perform lookups that  look into the innermost local scope only; for example, this is  an invalid redeclaration:  do {  let x = 321  let x = 123  }  but the following is fine, even though both vardecls are in the same  *declcontext*:  do {  let x = 321  do {  let x = 123  }  }  sema: check for re-declarations in local context in checkredeclarationrequest  sema: check for duplicate parameter and generic parameter names when parser lookup is off  the existing redeclaration checking can be extended for declarations in  local scope, but it won't catch these. ", "linked_issue_titles": "", "title": "implement re-declaration checking for declarations in local context"}
{"description": " uploaded files had wrong download links when the deploy had a sub directory. this misbehavior was caused by the wrong usage of the rtrim method, the 2nd parameter is a list of chars, not a string (this method was inspired by php) ", "commit_messages": " switched from rtrim to replace  removed subdirectory start ", "linked_issue_titles": "", "title": "broken download link on uploaded files"}
{"description": " the result of the code example at  a change to the website. i have submitted the spacy contributor agreement. i ran the tests, and all new and existing tests passed. --> no code or tests were changed. ", "commit_messages": " fixed token span in pattern matcher example  contributor agreement ", "linked_issue_titles": "", "title": "fixed the token span in the text about the rule-based matching example"}
{"description": " as discussed in #15109. this reverts 7e1ed1f. ", "commit_messages": " revert \"units: make systemd-repart.service installable\"  this reverts commit 7e1ed1f3b29162df25064b33dc55ac8cf432bb0b.  systemd-repart is not a user service that should be something people  enable/disable, instead it should just work if there's configuration for  it. it's like systemd-tmpfiles, systemd-sysusers, systemd-load-modules,  systemd-binfmt, systemd-systemd-sysctl which are nops if they have no  configuration, and thus don't hurt, but cannot be disabled since they  are too deep part of the os.  this doesn't mean people couldn't disable the service if they really  want to, there's after all \"systemctl mask\" and build-time disabling,  but those are os developer facing instead of admin facing, that's how it  should be.  note that systemd-repart is in particular an initrd service, and so far  enable/disable state of those is not managed anyway via \"systemctl  enable/disable\" but more what dracut decides to package up and what not.  units: run systemd-repart only if there's configuration for it ", "linked_issue_titles": "", "title": "make systemd-repart static again, but condition it out if no config"}
{"description": " fixes #5881 the path to python.exe on windows needs to change depending on whether it is installed via the boards manager or git (similar to the compiler paths).  adjust accordingly. an empty \"python\" directory will be created by the boards-manager installer in linux to avoid \"tool not available\" errors, and it will contain a symlink to the real system python executable. tested under linux git, linux board-manager, windows git, and windows board-manager. ", "commit_messages": " fix packaged python paths for windows  fixes #5881  the path to python.exe on windows needs to change depending on whether  it is installed via the boards manager or git (similar to the compiler  paths).  adjust accordingly.  add python-placeholder to make boardsmanager happy  an empty \"python\" directory will be created by the boards-manager  installer.  required because all archs need all tools defined.  make the placeholder include a symlink for \"python\" ", "linked_issue_titles": "", "title": "fix boards-manager install issues on linux and windows"}
{"description": " extends #4011 by three lines. i know we have multiple wallet support in theory, but until it actually appears, a static should be fine. ", "commit_messages": " make ccryptokeystore::unlock check all keys.  ccryptokeystore::unlock has a loop to attempt decrypting each key which  only executes once, likely due to a simple mistake when the code was  originally written.  this patch fixes the behavior by making it check all keys. it also adds  a fatal assertion in the case some decrypt but some do not, since that  indicates that the wallet is in some kind of really bad state.  this may make unlocking noticeably slower on wallets with many keys.  dont run full check every time we decrypt wallet. ", "linked_issue_titles": "", "title": "make ccryptokeystore::unlock check all keys (but only once)"}
{"description": " previously i pushed changes to test pip packages, but in the test script i did not add the path to where i actually added the dockerfiles. this commit fixes that. see a jenkins run against my branch:  @sandeep-krishnamurthy ", "commit_messages": " clean install script  add test for pip installations  remove debug statements & comments  make test runnable as script and from framework  fix path to dockerfiles  merge changes from origin ", "linked_issue_titles": "", "title": "fix script by adding path to dockerfile"}
{"description": " ref #13326. refactor rewrite-test logic to support one case supports multi database dialects modify rewrite test case ", "commit_messages": " support multi database in one rewrite test case  support multi database in one rewrite test case  support multi database in one rewrite test case  fix checkstyle ", "linked_issue_titles": "", "title": "refactor rewrite test logic for one case supports multi database dialects"}
{"description": " i am so sorry for this low-level mistake, i will check more carefully next time. ", "commit_messages": " enhancement agent kafka report plugin  1. new options to support multi skywalking cluster use same kafka cluster(plugin.kafka.mm_to_source_alias,plugin.kafka.mm_to_source_separator)  2. resolve agent has no retries if connect kafka cluster failed when bootstrap  update enum value for kafkaconnectionstatus  add namespace support for kafka reporter plugin  ajust code style  support namespace for kafka fetcher  support namespace for kafka fetcher  update for kafka topic namespace  update agent.config ", "linked_issue_titles": "", "title": "fix a bug that bad namespace spell in agent.config"}
{"description": " i was having issues with running acceptance tests on my machine and the error message for retryexception was not helpful in determining the issue. the underlying error is eaten up and not logged. i added an option to timedretrypolicy called log_original_error  so we can log the original error in some circumstances such as running acceptance tests. i decided to do this instead of always logging the error since we probably don't always want it. ", "commit_messages": " add option to timedretrypolicy to log original error  adds line ", "linked_issue_titles": "", "title": "log the original error for selenium when starting chrome"}
{"description": " it's and alternative fix for jenkins-35206. this fix may be merged together with #2385, because that pr will be still useful for garbage statuses coming from api calls. - fallback to unknown install state in the case of corrupted xml - fallback to the unknown state if the status does not exist anymore (e.g. plugin has been disabled) - unit tests @reviewbybees @kzantow ", "commit_messages": " [jenkins-35206] - add unit tests for the deserialization logic  [jenkins-35206] - install state should be robust against messed statuses when deserializing objects ", "linked_issue_titles": "", "title": "make the installstate object deserialization robust against corrupted files"}
{"description": " description: this pr adds a shutdown method to the apilistener and calls it where appropriate during server termination. previously there would be a crash due to use after free of objects in thread local storage by streams in the apilistener. funny enough the flakes reported in #9746 happened due to this. risk level: low testing: new unit and integration test. without appropriate termination the new integration test repros the stacktrace reported in #9746. ", "commit_messages": " first pass  unit test  fmt  better comments  newline ", "linked_issue_titles": "", "title": "add shutdown method and call during server termination"}
{"description": " hello, after discovering this tool via this video, i have taken a look at the ssti detection patterns used for the differents supported templating engines. based on that, i have added the missing expressions for the following engines: dot.js dust.js thank you very much in advance. ", "commit_messages": " add the expression for the dot engine  add the expression for the dust engine ", "linked_issue_titles": "", "title": "add the expression for the \"dot.js\" and the \"dust.js\" template engines"}
{"description": " change applies the latest loc patch, and bumps the minor version to 2. contains the fixes for #515 and #539 . microsoft reviewers: open in codeflow ", "commit_messages": " apply latest loc patch  update minor version to 2 by request ", "linked_issue_titles": "", "title": "apply latest loc patch and update minor version"}
{"description": " closes #32960 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry xref #34872 ", "commit_messages": " enh: allow non-consolidation in constructors  mypy fixup  enh: allow non-consolidation in constructors  bug: respect copy=false in constructing dataframe from dict  whatsnew  clean test ", "linked_issue_titles": " dataframe change alters original array used in creation ", "title": "honor copy=true when passing dict to dataframe"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update lolex typings.  bugfix in tsconfig.json - non-existing compiler option. ", "linked_issue_titles": "", "title": "update lolex typings with nexttick() and new clock.install() signature"}
{"description": " summary copied jsdoc comments from js package repo to typings, so that comments would show up in vscode tooltips properly. also fixed some inaccuracies in these comments. template checklist test the change in your own code. (compile and run.) does not apply, no definitions modified add or edit tests to reflect the change. (run with npm test.) same as above avoid common mistakes. same as above follow the advice from the readme. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: here and here if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. does not apply if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. does not apply ", "commit_messages": " added comments to api endpoint methods  * comments copied from spotify-web-api-node repo  added doc comments to oauth flow response models  removed types from @param & @returns ", "linked_issue_titles": "", "title": "added doc comments to api methods and some reponse interfaces"}
{"description": " issue: #7499 module format docs: #7498 ", "commit_messages": " cli templates: ember => module format  cli templates: marko => module format  cli templates: mithril => module format  cli templates: rax => module format  cli templates: riot => module format  cli templates: svelte => module format ", "linked_issue_titles": "", "title": "update sb init to module format for ember/marko/mithril/rax/riot/svelte"}
{"description": " support pausing amqp consumption when producer is paused. all unprocessed transactions consumed from amqp will be rejected with re-queue option. adds to the ability to resume from being paused on startup added via #10541. epe-1185 select one: select any that apply: ", "commit_messages": " update test to actually use amqp queue for transactions and test paused producer resuming  make hard-coded block_interval explicit  support pausing production by rejecting/requeueing amqp trx back to amqp ", "linked_issue_titles": "", "title": "amqp pause production, rejects with requeue"}
{"description": " try to make the layout match the way it does for the other index classes, similar to what we're doing with series/dataframe tests ", "commit_messages": " directories for categorical and range eindexes  dirs for categorical and range index tests ", "linked_issue_titles": "", "title": "directories for categoricalindex, rangeindex tests"}
{"description": " mapped types can circularly reference themselves (because member resolution is deferred), but array and tuple type instantiations cannot. this causes an issue when a circular homomorphic mapped type is instantiated for an array or tuple type as we now create array and tuple instantiations for such mappings (see #26063). with is pr we quickly detect and stop the runaway recursion that can occur by substituting errortype for the instantiation. we would eventually do this after 50 levels of nested instantiations, but exponential recursive fan-out could keep us from ever getting there. fixes #27881. ", "commit_messages": " allow discriminant property to contain some non-unit types  discriminant must include at least one unit type and no instantiable types  accept new baselines  add tests  accept new baselines  handle circular mapped type instantiations for arrays and tuples  add regression test  accept new baselines ", "linked_issue_titles": "", "title": "fix circular mapped type instantiations for arrays and tuples"}
{"description": " just submitting this pull request into a new supports branch, which we could use to make everything all, er, supportsy. see #818. i've added a function called nativecssdetect() (which does the work) and a couple of examples in the form of the flexbox and flexboxlegacy tests. these give the correct results using the native api in firefoxaurora and opera 12.14 and give the correct results using normal feature detection in chrome. notes: the function currently only supports the f(prop, value) interface, not the f(any old condition string) interface, because the former seemed much more useful it also takes 2 additional boolean args to specify whether or not to test all prefixed variants of the property and value respectively i've put in a fallback to the at-rule, because opera 12.14 only partially implements the javascript api (the part the implemented would have been fine for this actually, but hey) i expect we'd actually want to integrate this with testallprops() / testprops(), so for most tests we can just extend them to e.g.: return testpropsall('flexwrap', 'wrap'); i'll have a go at a version integrated into testallprops() and testprops(). early feedback very welcome. ", "commit_messages": " initial version of nativecssdetect() - only accepts a string e.g. '(flex-wrap:reverse)'; would quite like to overload the interface  revised version of nativecssdetect - this time only allows (prop, value) interface, because it's probably more common. also updated flexbox and flexboxlegacy tests to show how it could be used. ", "linked_issue_titles": "", "title": "first crack at an attempt to use css.supports() internally (#818)"}
{"description": " via-supporting keymaps for both solder and hotswap think6.5 pcbs. disables mousekey support to make the firmware fit. uses layout_all on the solder board since it supports things like iso, split left shift, split backspace and a 7u bottom row. uses layout_65_ansi_blocker on the hotswap board since the layout is fixed. tested with via v1.2.4 and a solder think6.5. i also committed the via json definitions to the keymap dir, for reference. i'll also commit those to via's keyboards repo. i also updated the usb vendor and product ids for both boards, since via needs those to identify the board properly. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " via support for think6.5  via support for think6.5 hotswap  via works better with separate layout options  remove the colours used to help develop it in kle  pay better attention to the json linter ", "linked_issue_titles": "", "title": "via support for the think6.5"}
{"description": " this change separates the signal handling trigger in the eval loop from the \"pending calls\" machinery.  there is no semantic change and the difference in performance is insignificant. the change makes both components less confusing.  it also eliminates the risk of changes to the pending calls affecting signal handling.  this is particularly relevant for some upcoming pending calls changes i have in the works. ", "commit_messages": " do not clear an existing error when handling signal failures.  factor out make_pending_calls().  add _pyruntimestate.ceval.signals_pending.  add _pyruntimestate.ceval.pending.busy.  handle signals (mostly) separately.  explicitly handle signals and pending calls separately in the eval loop.  move \"busy\" back into make_pending_calls().  handle the pending calls flag exclusively in make_pending_calls().  simplify. ", "linked_issue_titles": "", "title": "stop using the \"pending calls\" machinery for signals."}
{"description": " this is the second batch of incidental integration tests, sourced primarily from cloud integration tests. there will be overlap with existing cloud integration tests until collection migration is completed. integration tests ", "commit_messages": " initial copy of incidental tests.  update incidental test aliases.  rewrite target references for renamed targets.  add incidental tests to ci.  update sanity tests for incidental cloud tests.  copy contrib files into test.  update paths in test.  add support plugins.  update plugin to work around missing deps.  update sanity ignores. ", "linked_issue_titles": "", "title": "second batch of incidental integration tests."}
{"description": " move on with md2charactercomplex, gyroscope and morphblendmesh. ", "commit_messages": " jsm: added module and ts file for gyroscope.  jsm: added module and ts file for morphblendmesh.  jsm: added module and ts file for md2charactercomplex. ", "linked_issue_titles": "", "title": "added more module and ts files"}
{"description": " the memory used by pt run was increasing on consecutive launches. one of the reasons for this to happen was that all the image icons were cached. even though the code had an upperlimit on the maxcached values which was set to 5000, this part of the code was never called unless powertoys was closed. therefore, since all the icons were being cached, the size of the dictionary continued to increase. work around- instead of caching all images and increasing the size of the dictionary, the following changes have been made - reduce the number of cached images to 50. if the number of images increase over the permissible factor (set to 2) of the cached images (ie. 2 * 50), then the ones which are infrequently used would be removed from the dictionary and there be 50 images that are cached. this ensures that the dictionary size is always less than 100. pr checklist applies to #2047. cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx validation steps performed the changes in this pr can be validated by following these steps - take snapshots of the memory usage by using the diagnostic tools of visual studio (debug -> windows -> diagnostic tools). take the first snapshot after all the dlls are loaded and the memory utilization is stabilized. take the next memory snapshot after many queries (don't have to execute an application). the aim is to just load many icons. compare the second snapshot by setting the first one as the baseline. search for memory size diff in bytes for concurrent dictionary with value imagesource. compare this value to that obtained without the changes in this pr, to get the results as shown in the following images. before this change (after about twenty searches)- after this change (after about twenty searches) - outstanding tasks even though this fixes the issue partially, the memory consumed by pt run is still high. it starts off with 160/170 mb and after first launch goes up to 230/250 mb, following which it increases a little on each run. another area where the memory utilization can be improved is the dictionary<int64, weakreference>. the following snapshots are after searching for a few apps using pt run - it seems like this is related to the resourcedictionary of the ui components. the number of elements in this dictionary and the components that they are referring to seem to increase on each run. this needs further investigation. additional information i tried to set a hard limit on the heap size using runtime.config.json and system.gc.heaphardlimit. i did not notice any drastic differences in the garbage collection when the limit was set to values ranging from 20 mb to 200 mb. also, this might differ from system to system so i did not go down this route. references - ", "commit_messages": " reducing storage of images  added task.run  cleaned up code and added comments  renamed variable  refactored code ", "linked_issue_titles": "", "title": "partial fix for memory issue - limiting the number of imagesources cached"}
{"description": " in the tomorrow dark theme, the code is jammed up against the gutter. we should be able to use padding on the scroll view and have the editor gracefully handle. this: not this: here are some changes that need to happen in order to make this happen. ", "commit_messages": " use padding in the pixel left calculation  now themes can specify padding in the scroll-view so the text isn't  jammed up against the  properly reset the size of layers on resize  otherwise, when a theme has padding in the scroll-view, it will be  scrollable all the time (width:100%). ", "linked_issue_titles": "", "title": "handle themes with padding on the scroll view"}
{"description": " the same error happen here again (#6785 (comment)) if someone has access to the site and can run the tests and check if they need to be changed ", "commit_messages": " [utlis] add extract_attributes for extracting html tags attributes  [brightcove] add support for brightcove in page embed(fixes #6824) ", "linked_issue_titles": "", "title": "add support for brightcove in page embed(fixes #6824)(fixes #5946)"}
{"description": " this pr addresses many problems with module graph loading introduced in #5029, as well as many long standing issues. \"modulegraphloader\" has been wired to \"moduleloader\" implemented on \"state\" - that means that dependency analysis and fetching is done before spinning up ts compiler worker. basic dependency tracking for ts compilation has been implemented. errors caused by import statements are now annotated with import location. fixes #1692 fixes #5080 fixes #5419 fixes #5815 fixes #5900 ", "commit_messages": " move bundle specific logic to main.rs  deduplicate caching of compiled files ", "linked_issue_titles": " cache invalidation when recompiling a module  report original file and line for unsupported scheme when compiling  import error backtraces  `@ deno-types` + import map does not resolve jsx types.  unable to import javascript files from tsx ", "title": "ts compiler and module graph"}
{"description": " i've taken @mikemaccana's commit, then added more hints to multiple --host and then copied the changes to the markdown. closes #5372 ", "commit_messages": " - unix://path/to/socket should read unix:///path/to/socket like the rest of the documentation (a slash was missing)  - mention that [] options may be specified multiple times on the usage page  docker-dco-1.1-signed-off-by: mike maccana <mike.maccana@gmail.com> (github: mikemaccana)  docker-dco-1.1-signed-off-by: mike maccana <mike.maccana@gmail.com> (github: svendowideit)  add a reference to multiple -h options, and update the other example of -h option  and copy changes to the cli.md file  docker-dco-1.1-signed-off-by: sven dowideit <svendowideit@fosiki.com> (github: svendowideit) ", "linked_issue_titles": "", "title": "docs tweaks to socket options"}
{"description": " description: adjusted tradfri module to use  pytradfri 2.x interface added support for the whole range of white spectrum lightbulbs, instead only 3 predefined values provided by ikea app correctly set minimum and maximum supported light temperatures checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. ", "commit_messages": " [light.tradfri] support for pytradfri version supporting full white spectrum  [light.tradfri] checkout pytradfri master  developer docker image adjusted  [light.tradfri] pytradfri 2.2 support for white spectrum bulbs  * upstream/dev: (113 commits)  fix fitbit error when trying to access token after upgrade. (#9183)  upgrade sendgrid to 5.0.1 (#9215)  upgrade pyasn1 to 0.3.3 and pyasn1-modules to 0.1.1 (#9216)  directv: extended discovery via rest api, bug fix  (#8800)  bayesian binary sensor (#8810)  add cloud auth support (#9208)  abode push events and lock, cover, and switch components (#9095)  lint sonarr tests  upgrade pymysensors to 0.11.1 (#9212)  refactor rfxtrx (#9117)  issue #6893 in rfxtrx (#9130)  support for season sensor (#8958)  add counter component (#9146)  fix and optimize digitalloggers platform (#9203)  prevent error when no forecast data was available (#9176)  add \"status\" to sonarr sensor (#9204)  fix worldtidesinfo #9184 (#9201)  update pushbullet.py (#9200)  fix dht22 when no data was read initially #8976 (#9198)  prevent icloud exceptions in logfile (#9179)  ...  removed fix already included in dev  style adjusted ", "linked_issue_titles": "", "title": "full range of  white spectrum lightbulbs support"}
{"description": " establish module state convert types to heap types and add them to module state add multi-phase init support ", "commit_messages": " add empty module state  convert encoder and decoder types to heap type  convert reader and writer types to heap type  convert multibytecode type to heap type  support multi-phase init  add news  fix type names ", "linked_issue_titles": "", "title": "adapt _multibytecodec to multi-phase initialization"}
{"description": " we added support for dutch to spacy. this pull request includes the actual additions to the spacy code to add the language class. we built the language data (vocab data and pos/ner tagger) on a small corpus (1000 articles from wikipedia), this is available at  the models are not yet very good and we think they could easily be improved further by using a better corpus. the dependency parser has not yet been trained. we documented the process, as well as the next steps in the spacy-dutch repository. this repository also contains scripts to regenerate language data from new corpora. contributers: dafne van kuppevelt, janneke van der zwaan, willem van hage (netherlands escience center). contributer agreement signed by rob van nieuwpoort, director of technologies of the netherlands escience center. motivation and context we work on multiple projects that involve dutch text, and we would like to use spacy for our analyses. by documenting carefully how we construct the language data, we hope this helps others to add new languages. possibly, our description could also be integrated in the spacy documentation. how has this been tested? we added a new test for the language dutch. we ran this test in python 2.7 and 3.5 environments and they passed. there are hardly any interactions with these additions to the rest of the code. to check the sanity of the language data and models, we inspected the outcome for some example sentences and we calculated the performance of the models.  details can be found in the spacy-dutch repository screenshots (if appropriate): types of changes bug fix (non-breaking change fixing an issue) new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my code follows spacy's code style. my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. ", "commit_messages": " add directory and initial (empty) files for language dutch  added language class and some language data (with some todos) for dutch  added nl module for dutch  added language dutch to init file  update dutch language data  - use dutch tag map  - remove tokenizer exceptions  update language data with tag map from ud_dutch  merge github.com:explosion/spacy into dutch  merge github.com:explosion/spacy into dutch  fixed bug in init_model so that it runs for dutch  signed contributer agreement by rob van nieuwpoort ", "linked_issue_titles": "", "title": "support for dutch in spacy"}
{"description": " suppose we have: package-a package-b package-c the following works as expected: lerna bootstrap --ignore=package-@(a|b) the message is: ignoring packages that match 'package-@(a|b)' and the following packages are bootstrapped: package-c the following does not work as expected: lerna bootstrap --ignore=package-{a,b} the message is: ignoring packages that match 'package-a,package-b' and the following packages are bootstrapped: package-a (incorrect) package-b (incorrect) package-c the latter glob is expanded to an array even before reaching filterpackage in packageutilities. (notice the difference in messages). however, the logic regarding negation (i.e. maybenegate) was only within glob.some, which would not work in the case that glob.length > 1. this pr changes the boolean reducer depending on the desired negation (i.e. array.prototype.some for the standard case, and array.prototype.every for the negated case. ", "commit_messages": " add failing test  fix ignore with certain globs ", "linked_issue_titles": "", "title": "fix --ignore flag when globs are expanded to an array"}
{"description": " this allows a mismatching href and as value when the params are manually provided in the href's query. this mismatching can occur when you are using the new experimental custom-routes feature and you are rewriting to a dynamic route we currently aren't able to parse the params automatically since we don't ship the custom-routes to the client so we can't find where the as value is pointing to client-side x-ref: #9700 (comment) ", "commit_messages": " allow mismatch href and as when manually provided ", "linked_issue_titles": "", "title": "allow mismatching href and as when manually provided"}
{"description": " form validation follows comma-separated list of media types defined on newly-added admin setting. this pr also fixes a known vulnerability where a given user could upload files of any type with drag-and-drop (for this particular test we are accepting image/png only): good file bad file closes #1058 closes #756 ", "commit_messages": " added \"fileupload\" settings group  providing access to settings subscription in order to setup client-side upload objects  applying newly-added file upload settings.  updating jalik:ufs and jalik:ufs-gridfs  blocking drag and drop file uploads of any kind. ", "linked_issue_titles": "", "title": "added settings for file upload type and size limit"}
{"description": " this change will help to distinguish h264 and hevc via mask form usage and help to update ui for hevc support ", "commit_messages": " adjustment to report qsv availability in mask form  ui adjustment for mask usage ", "linked_issue_titles": "", "title": "report in mask form for supported codec(s)"}
{"description": " this pr adds a new api that creates the follow index and starts the follow changes from leader index into the newly created follow index. the api looks the same as the existing follow index api, with the big difference that it creates the follow index. the create and follow api, creates a follow index based on the indexmetadata of the leader index, then waits for the shards to become available and the delegate to the existing follow index api. relates to #30102 ", "commit_messages": " added create and follow api.  renamed followexisting* internal names to just follow*  and fixed tests ", "linked_issue_titles": "", "title": "add create and follow api"}
{"description": " this pull request fixes [jenkins-15408]. the problem is caused by a bug in reopenablerotatingfileoutputstream, as is demonstrated by the unit test testrotation() failing (on windows only). this pull request fixes the issue and thereby the unit test. this also contributes to fixing [jenkins-12768]. ", "commit_messages": " fixed reopenablerotatingfileoutputstream to work on windows ", "linked_issue_titles": "", "title": "rotation of slave launch logs on windows"}
{"description": " carry of pr #20902 allow the docker daemon to run inside a user namespaced parent process.  original patch by @hallyn; i've added a change to revert to \"real\" chroot when inside a userns that came about since the original patch. i have tested this capability inside lxc running an ubuntu:xenial image with a binary built from this pr patchset.  to successfully run the docker daemon i used the following command line: dockerd -d -s vfs --oom-score-adjust=0 inside a user namespace, writing to the oom_score_adj special proc file fails, and i can't get any backend driver to work outside of vfs. i cannot run the docker engine inside of a runc container with user namespaces enabled due to how the /sys/fs/cgroups mount is handled under runc. therefore it is hard to write a test that integrates well with our ci system without requiring a working lxc setup until we solve this problem in runc. ", "commit_messages": " don't create devices if in a user namespace  if we are running in a user namespace, don't try to mknod as  it won't be allowed.  libcontainer will bind-mount the host's  devices over files in the container anyway, so it's not needed.  the chrootarchive package does a chroot (without mounting /proc) before  its work, so we cannot check /proc/self/uid_map when we need to.  so  compute it in advance and pass it along with the tar options.  use real chroot if daemon is running in a user namespace  the namespace unshare+pivot root is not possible when running inside a  user namespace, so fallback to the original \"real\" chroot code.  docker-dco-1.1-signed-off-by: phil estes <estesp@linux.vnet.ibm.com> ", "linked_issue_titles": "", "title": "allow engine to run inside a user namespace"}
{"description": " in order to maintain a cleaner commit history, i made a new branch and will be closing the other pr. this is the only way i see of giving this work a cleaner commit history. @larson-carter ", "commit_messages": " create check-suite.yml  update readme.md ", "linked_issue_titles": "", "title": "create github action to run tests"}
{"description": " this adds an error message that can help better identify the issue when an old/invalid state instance is used when createstate is called. related issues fixes #11975 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " init  added error message to assert  removing unrelated changes ", "linked_issue_titles": " better error message for assertion '_state._widget == null': ", "title": "error message for createstate assertion"}
{"description": " as we work on reusing microsoft.reactnative source files in the desktop rn project, having pch files in the root folder makes it difficult to use local for the desktop project pch files because it picks them up fro the microsoft.reactnative project. in this change we move the microsoft.reactnative pch files into a pch subfolder and add the subfolder path to the includes path for the microsoft.reactnative project. after that, other projects will not see our pch files unless they explicitly add the new path to their include paths (which they better not to do). microsoft reviewers: open in codeflow ", "commit_messages": " move pch files into a pch subfolder.  change files ", "linked_issue_titles": "", "title": "move microsoft.reactnative pch files in a pch subfolder"}
{"description": " what did you implement: closes #3018 how did you implement it: i added a build.ps1 that mirrors the behavior of the build.sh bash script. of note, the zipdirectory method doesn't allow creating a zip in the file that it's zipping, so i create it in root and then copy it back to the publish. how can we verify it: on a windows machine, run serverless create -t aws-csharp ./build.ps1 # note that a deploy-package.zip is created in bin/release/netcoreapp1.0/publish serverless deploy # succeeds, deploys the package zip serverless invoke -f hello # returns \"hello world\" response todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources enable \"allow edits from maintainers\" for this pr change ready for review message below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " add \build.ps1 and update tests&docs  remove chmod doc line, not necessary ", "linked_issue_titles": "", "title": "add b\build.ps1 and update tests&docs"}
{"description": " what did you implement: updated docs closes #xxxxx how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " updating branch  spotinst - reformatting docs to be more readable ", "linked_issue_titles": "", "title": "spotinst - reorganizing guide structure for readability"}
{"description": " in some caffe prototxt,the layer type of convolutiondepthwise is \"depthwiseconvolution\",using the caffe2ncnn tool generate the ncnn.param file maybe loss the group_num param. ", "commit_messages": " add armv7 int8 conv3x3s1,using vaddw to replace vadd and vmovl  fix the caffe2ncnn  bug that \"depthwiseconvolution\" loss group num param ", "linked_issue_titles": "", "title": "fix the caffe2ncnn that \"depthwiseconvolution\" loss group num param"}
{"description": " [this is the forward port of #2134 changes relative to the version committed on 1.0-maint: mapping of new commands to features: borg export-tar and borg diff use manifest.operation.read borg recreate uses manifest.operation.check borg debug dump-manifest uses manifest.no_operation_check as all other debug commands. ] this should allow us to make sure older borg versions can be cleanly prevented from doing operations that are no longer safe because of repository format evolution. this allows more fine grained control than just incrementing the manifest version. so for example a change that still allows new archives to be created but would corrupt the repository when an old version tries to delete an archive or check the repository would add the new feature to the check and delete set but leave it out of the write set. this is somewhat inspired by ext{2,3,4} which uses sets for compat (everything except fsck), ro-compat (may only be accessed read-only by older versions) and features (refuse all access). this implements #1806 ", "commit_messages": " add minimal version of in repository mandatory feature flags.  this should allow us to make sure older borg versions can be cleanly  prevented from doing operations that are no longer safe because of  repository format evolution. this allows more fine grained control than  just incrementing the manifest version. so for example a change that  still allows new archives to be created but would corrupt the repository  when an old version tries to delete an archive or check the repository  would add the new feature to the check and delete set but leave it out  of the write set.  this is somewhat inspired by ext{2,3,4} which uses sets for  compat (everything except fsck), ro-compat (may only be accessed  read-only by older versions) and features (refuse all access).  add tests for mandatory repository feature flags.  permit manifest version 2 as well 1 one. ", "linked_issue_titles": "", "title": "add minimal version of in repository mandatory feature flags. (master)"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " updated type declarations  and since the root file had a .prettierrc i ran prettier on it  new tests  also ran prettier here as well ", "linked_issue_titles": "", "title": "updated definitions to include changes since v1.2"}
{"description": " change implemented schema validation using valijson added manifest schemas for preview and v1 manifests changed manifest object model to better reflect v1 manifests changed manifestlocalization to be std::map based for easier future locale processing implemented merge logic for multiple file manifests validation existing tests and added new tests validated all 3000+ manifests currently in winget-pkgs passed manifest validation note: after this change, we might need to revisit and relax restrictions in some of v1 manifest schemas as i found around 300+ manifests in current winget-pkgs will fail in new restrictions imposed by v1 manifest schemas microsoft reviewers: open in codeflow ", "commit_messages": " vcxitems for valijson  vcxitems for schemas  initial check  second check  working snapshot  fix  preview compatibility fix  v2 compatibility fix  working snapshot 2  new tests ", "linked_issue_titles": "", "title": "implement v1 manifest  and schema validation"}
{"description": " reopening #28009 (after addressing comments on the closed pr) adds documentation to the guides about how to get session middleware back when using the api_only flag. without this, it's not clear that session middleware has special cases to handle with the api_only flag. hopefully will help people avoid this problem: ", "commit_messages": " document how to add session middleware back  without this, it's not clear that session middleware has special cases to handle with the api_only flag  clarify session management middleware sections  addresses some comments in original pr for docs on using session management middleware in api apps ", "linked_issue_titles": "", "title": "document how to add session middleware to an api app"}
{"description": " while streaming from obs on an unstable connection, i have found instances where obs will hang until it is force quit. during some testing with arut/nginx-rtmp-module proxying connections i found that when the obs that was streaming to nginx-rtmp-module had network issues it would cause the obs to hang and never recover. i eventually identified that the server was sending a netstream.publish.badname status message that was never handled. more information from adobe about that error can be found on their site. i would like obs to not hang when there are network glitches. i tested this on macos by making a build on my macbook pro and did the following: from the nginx config: application stream { live on; publish_notify on; play_restart on; } steps: turn off wifi and connect the macbook pro via ethernet start obs via the command line start a custom stream to an nginx-rtmp server disconnect the ethernet plug it back in 10 seconds later i checked the logs and status bar to see if the system reconnected. it would not reconnect when using obs in master but would reconnect when using this branch. bug fix (non-breaking change which fixes an issue) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " obs-outputs: handle rtmp netstream.publish.badname response  adobe media server and nginx-rtmp can return this status response to a  publisher if the key is already being used to publish.  obs-outputs: log unhandled rtmp status responses  rtmp status responses that are not handled are currently silently ignored  making it difficult to identify issues. ", "linked_issue_titles": "", "title": "handle netstream.publish.badname from rtmp server"}
{"description": " your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description i fixed the 2 last critic error discover by lgtm. is a false positif, cmd is type ut8 and can't overflow because the standart defined his value between 0 and 255. but i add a condition to prevent regression. add a threshold of 5000 ->  test plan run the test suite closing issues work on #16493 ", "commit_messages": " remove useless cast  fix lgtm error root/libr/socket/socket_http_server.c  add regression prevention if ", "linked_issue_titles": "", "title": "fix 2 last critic error lgtm"}
{"description": " if an override b.f() is more visible than a base method a.f(), it is possible that an override c.f() of b.f() cannot see the original method a.f(). in this case, we would encounter linker errors if we referenced the method descriptor or method dispatch thunk for a.f(). make this work by treating b.f() as the least derived method in this case, and ensuring that the vtable thunk for b.f() dispatches through the vtable again. fixes rdar://problem/48330571, ", "commit_messages": " silgen: support vtable thunks for 'modify' accessors  when checking if a vtable override is abi compatible with the  base class method, make sure to check yields too.  also, add support for coroutines to vtable thunks, using code  that i've copy and pasted and tweaked from witness thunks.  (it would be nice to combine witness thunks and vtable thunks  into a single code path for 'method thunks', but that requires  some additional refactoring, so live with the copy and paste  for now).  sema: remove dead code concerning 'default constructible' classes  we used to try to emit a 'default initializer' in a class with a superclass,  as long as the superclass was 'default initializable', meaning it had at  least one designated initializer where all parameters had a default  expression.  however this code path was never taken, because the designated initializer  inheritance mechanism supercedes it. probably it became dead once we  implemented inheritance of initializers with default arguments.  irgen: more precise check lines for test/irgen/weak_import_native.swift  sema: don't emit stubs to override inaccessible superclass initializers  there was a behavioral difference between binary modules and textual interfaces.  since a binary module includes information about all members, including private  and internal members, we would emit overrides for all designated initializers  when subclassing a class, including those we cannot access.  this was problematic because then we reference the superclass initializer's  method descriptor, which had to be forced to have public linkage so that the  subclass could reference it.  however a textual interface only includes public members so any such  initializers were simply dropped. the irgen hack is thus no longer necessary  when textual interfaces are used.  in reality neither behavior is correct because the presence of inaccessible  initializers should inhibit the inheritance of any designated initializer;  however i'm going to try to fix that separately since it is a source breaking  change and thus needs to be staged in as a warning. the latter fix is  tracked by <rdar://problem/51249311>.  stdlib: managedbuffer.init(_donotcallme:) was abi in swift 5 and should be @usablefrominline  irgen: remove hack giving method descriptors of open class initializers public linkage  this was done even for non-public inits because subclasses would always  override the base class's designated initializers, even if they were  inaccessible.  this is an abi break, however in practice the only affected class  initializer was managedbuffer.init(_donotcallme:()), and we can just  make it @usablefrominline.  silgen: correctly emit vtables when an override is more visible than the base  if an override b.f() is more visible than a base method a.f(), it is  possible that an override c.f() of b.f() cannot see the original method  a.f().  in this case, we would encounter linker errors if we referenced the  method descriptor or method dispatch thunk for a.f().  make this work by treating b.f() as the least derived method in this  case, and ensuring that the vtable thunk for b.f() dispatches through  the vtable again.  fixes <rdar://problem/48330571>, < ", "linked_issue_titles": "", "title": "correctly emit vtables when an override is more visible than the base [5.1]"}
{"description": " add a new symbolic function broadcast_tensors() to support exporting torch.broadcast_tensors() function. this is required by exporting torch.distribution.normal() function. add a new symbolic function normal() to support exporting torch.distribution.normal() function. add relative tests for normal and uniform ops as well. ", "commit_messages": " enable the support to torch.distribution.normal op  add tests for test_dist_uniform. ", "linked_issue_titles": "", "title": "enable aten:normal op and add tests for aten:uniform op."}
{"description": " please, could you take a look at this code? @greens @mablewiczs @mgoralczyks @dczarneckas @pkacprowiczs @mmateusiaks ", "commit_messages": " new dth for dome mouser  dth improvement, bug fix  small improvement, adjusted checkinterval, changed icons, removed some comments ", "linked_issue_titles": "", "title": "wwst-1636 new dth for dome mouser - dmmz1"}
{"description": " this pr is for code changes as well as a spec for #1043 closes #1043 cla signed. if not, go over here and sign the cla requires documentation to be updated this pr includes the code changes that enable users to set an initial position (top left corner) and launch maximized. there are some corner cases: multiple monitors. the user should be able to set the initial position to any monitors attached. for the monitors on the left side of the major monitor, the initial position values are negative. if the initial position is larger than the screen resolution and the window is off-screen, the current solution is to check if the top left corner of the window intersect with any monitors. if it is not, we set the initial position to the top left corner of the nearest monitor. if the user wants to launch maximized and provides an initial position, we launch the maximized window on the monitor where the position is located. testing: to test: check-out this branch and build on vs2019 launch terminal, and open settings. then close the terminal. add the following setting into json settings file as part of \"globals\", just after \"initialrows\": \"initialposition\": \"1000, 1000\", \"launchmode\": \"default\" my test data: i have already tested with the following variables: 1. showtabsintitlebar true or false 2. the initial position of the top left corner of the window 3. whether to launch maximized 4. the dpi of the monitor test data combination: non-client island window (showtabsintitlebar true) three monitors with the same dpi (100%), left, middle and right, with the middle one as the primary, resolution: 1980 * 1200, 1920 * 1200, 1920 * 1080 launchmode: default in-screen test: (0, 0), (1000, 500), (2000, 300), (-1000, 400), (-100, 200), (-2000, 100), (0, 1119) out-of-screen: (200, -200): initialize to (0, 0) (200, 1500): initialize to (0, 0) (2000, -200): initialize to (1920, 0) (2500, 2000): initialize to (1920, 0) (4000 100): initialize to (1920, 0) (-1000, -100): initialize to (-1920, 0) (-3000, 100): initialize to (-1920, 0) (10000, -10000): initialize to (1920, 0) (-10000, 10000): initialize to (-1920, 0) (0, -10000): initialize to (0, 0) (0, -1):  initialize to (0, 0) (0, 1200):  initialize to (0, 0) launch mode: maximize (100, 100) (-1000, 100): on the left monitor (0, -2000): on the primary monitor (10000, 10000): on the primary monitor left monitor 200% dpi, primary monitor 100% dpi in screen: (-1900, 100), (-3000, 100), (-1000, 100) our-of-screen: (-8000, 100): initialize at (-1920, 0) launch maximized:  (-100, 100): launch maximized on the left monitor correctly left monitor 100% dpi, primary monitor 200% dpi in-screen: (-1900, 100), (300, 100), (-800, 100), (-200, 100) out-of-screen: (-3000, 100): initialize at (-1920, 0) launch maximized: (100, 100), (-1000, 100) for client island window, the test data is the same as above. issues: if we set the initial position on the monitor with a different dpi as the primary monitor, and the window \"lays\" across two monitors, then the window still renders as it is on the primary monitor. the size of the window is correct. ", "commit_messages": " spec version 1 for set terminal initial position  fix the spec title  add a new function to read initial position properties  test version - 9-6  spec for code review updates  code change 9-11  temporary changes 9 12  enable setting an initial position for terminal and maximization launch  remove empty lines  remove empty lines ", "linked_issue_titles": " be able to set an initial position for the terminal ", "title": "enable setting an initial position and maximization launch for terminal"}
{"description": " added ability to export as newline separated json (nsj) as well as appropriate language. also added language to import.py that indicates nsj is already accepted as an import type. ", "commit_messages": " add export support for new-line separated json  added comments in export and import and refactoring export  refactor launch_writer ", "linked_issue_titles": "", "title": "add ability to export as newline separated json (nsj)"}
{"description": " add large tensor support to optimizers and 1 activation function hard_sigmoid adam_update ftml_update mp_sgd_mom_update mp_sgd_update rmsprop_update rmspropalex_update sgd_mom_update sgd_update signsgd_update signum_update nagmom mp_nagmom lamb mp_lamb ftrl adagrad please feel free to remove inapplicable items for your pr. all changes have test coverage: code is well-documented: to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change modified:   src/operator/optimizer_op-inl.h modified:   src/operator/tensor/elemwise_unary_op.h tested hard_sigmoid with lt input : pass >>> import mxnet as mx >>> mx.nd.hard_sigmoid(data=mx.nd.random_normal(shape=(1, 2**32 + 1))) [[0.9424413 0.6548008 0.7086881 ... 0.53579605 0.37985992 0.20645571]] <ndarray 1x4294967297 @cpu(0)> rest of the *_update functions can't be tested with random_normal inputs as they give nans as result (even for shape < 2**32) hence not tested. but they don't give a segmentation fault (which previously was the problem due to lack of large tensor support). ", "commit_messages": " fix hard sigmoid  change int i to index_t i for all kernel map functions ", "linked_issue_titles": "", "title": "add lt support for nn optimizers and 1 activation function"}
{"description": " offscreen render, mouse and keyboard event sending functionality using the content api. this relies on my other pull-request successfully being merged into native-mate, because the offscreen-render callback sends the image data in a uint8clampedarray, and i couldn't return that without the things i added to native-mate. ", "commit_messages": " offscreen render support base  setoffscreenrender and api docs added  mouse event handling and keyboard event handling (not totally working yet)  conflicts:  atom/browser/api/atom_api_window.h  atom/browser/native_window.cc  key event sending update.  changed stringarray options to regular js objects with boolean values for better readability from the js side  reset native-mate to the original repo  resetting debug changes  whoops, missed a line last time. ", "linked_issue_titles": "", "title": "adding support for offscreen render and keyboard/mouse event sending to browser-window."}
{"description": " addresses part of #12927 and part of #9250 this pr renames file.py into _file.py in the sklearn.cluster module. in particular, please note that: i rename dbscan_.py into _dbscan.py. same for optics_ and mean_shift_ i renamed k_means_.py into _k_means.py. since _k_means.pyx already existed, i had to rename it too. i chose _k_means_fast.pyx but no strong opinion. same for hierarchical. ping @adrinjalali \t@thomasjpfan \t@rth \t@glemaitre. again, lint issue can be ignored and are triggered by new files being created. ", "commit_messages": " first files  some more  some more ", "linked_issue_titles": "", "title": "mnt make files private for cluster module"}
{"description": " made py3 fixes to conf.py.  docs now compile on py3 (good job @phaebz, @kermit666 and joris). also worked around recent breaking change to ipython ipython/ipython#4504, which somewhat deflates my theory that by having our own copy we can avoid having other packages changes break our build (they can, if they change the packages it depends on). ", "commit_messages": " bld/doc: fix conf.py on py3  bld/doc: fix ipython_directive to workaround ipython/4504 ", "linked_issue_titles": "", "title": "fix ipython directive, py3 and recent ipython changes"}
{"description": " this pr performs a bit of maintenance on various np.dtype methods (see the individual commits). most prominently is a fix to signature of __mul__, which had a few problems: multiplication by 0 does not return none. multiplication of a flexible dtype returns a flexible dtype; not necessarily just void. in principle any object implementing the __index__ protocol is a valid multiplication value; not just integers. ", "commit_messages": " sty: use the pipe operator to represent unions in np.dtype  enh: use the concrete mappingproxytype class over the mapping abc  maint: removed a duplicate attribute  maint: fixed the signature of dtype.__mul__  * multiplication by 0 does not return none  * multiplication of a flexible dtype returns a flexible dtype; not just void  * in principle any object implementing the __index__ protocol is a valid multiplication value; not just integers.  maint: set the return-dtype of dtype.base and dtype.subdtype to any  whether the return dtype is equivalent to the initial dtype depends on whether the initial dtype is structured or if it has fields of a fixed size  tst: update the dtype typing tests ", "linked_issue_titles": "", "title": "misc typing maintenance for np.dtype"}
{"description": " see bitcoin/bitcoin#4735 (the dependency on cfeerate moving shouldn't matter here) ", "commit_messages": " remove print() from core functions  break dependency on util.  move strprintf define to tinyformat.h  this avoids a dependency on util.h if just tinyformat is needed.  remove all other print() methods  all unused. ", "linked_issue_titles": "", "title": "remove print() from core classes"}
{"description": " my work is based on the work that was done to add --numstat. mind the singular and plural forms of the output. add a field of shortstat in struct opts and follow the things --numstat do. remove the corresponding information from the projects.md regards, he sun ", "commit_messages": " add the --shortstat flag to examples/diff.c  fix the output format of diff ", "linked_issue_titles": "", "title": "examples/diff:add the shortstat flag to examples/diff.c"}
{"description": " this should fix #912. it was righteously mentioned by @bakkot. ", "commit_messages": " add fix for parens of binaryexpression with instanceof op embedded into arrowfunctionexpression.  add new test :rocket:. ", "linked_issue_titles": " omited parentheses for objectexpression of binaryexpression enclosed into arrowfunctionexpression ", "title": "fix binary expression instanceof in arrow function expression"}
{"description": " this fixes a flaky test:  i also took this opportunity to convert the package manager spec to javascript and use async and await instead of waitsfor. ", "commit_messages": " convert package-manager-spec to js  use async/await in package-manager-spec ", "linked_issue_titles": "", "title": "fix flaky package manager spec"}
{"description": " took the latest version from  the previous version of this file is no longer compatible with grpc 1.7.x/1.8.x and causes compilation errors. ", "commit_messages": " updateed cpp_generator.cc to be compatible with the latest grpc version  preserved the original license ", "linked_issue_titles": "", "title": "updated cpp_generator.cc to be compatible with the latest grpc version"}
{"description": " creating a new page on hosting a sample asp .net core in container using docker compose @rick-anderson  edit: internal review url ", "commit_messages": " create docker-compose-https.md  docker compose draft.  use right env variable format in compose file ", "linked_issue_titles": "", "title": "hosting an asp.net core image with docker compose"}
{"description": " fixes #4817. when the --update-checksums flag is set, yarn would know to ignore a checksum mismatch between yarn.lock and the repository, and instead update the yarn.lock file with the proper checksum(s). added new tests. to manually check this: change one or more of the package checksums in yarn.lock delete node_modules (optionally also run yarn cache clean) run yarn => checksum mismatch error will be received. run yarn --update-checksums => will install successfully and fix the damaged checksums in yarn.lock ", "commit_messages": " test(cli): update package checksum  update package checksum when there is a checksum mismatch between the repo and the lockfile  feat(cli): update package checksum on mismatch  provide the option to update the package checksum when there is a mismatch between the repo and the  local yarn.lock file  4817 ", "linked_issue_titles": " moving repositories without recreating yarn.lock? ", "title": "add --update-checksums to cli install"}
{"description": " we are adding dispatchcommand to the export of react native renderers. right now product code is calling uimanager.dispatchviewmanagercommand which we need to get rid of to migrate to fabric. this export will work for fabric and paper and will be called via generated code in react native for each view manager command. for facebook employees, you can see more information here: ", "commit_messages": " add dispatchcommand to the public export of the react native renderers  fixup invalid check ", "linked_issue_titles": "", "title": "add dispatchcommand to react native renderers"}
{"description": " this field has been deprecated in favor of of the match_subject_alt_names field which provides more flexible matching. san list can still be specified via transport_socket_options's san list override and verified via verifysubjectaltname risk level: low testing: local test on linux (bazel test //test/...) ", "commit_messages": " remove support for v2 verify_subject_alt_name field  remove support for v2 verify_subject_alt_name field ", "linked_issue_titles": "", "title": "remove support for verify_subject_alt_name in certificatevalidationcontext"}
{"description": " add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " credit-key files including tests  fixing tslint errors  made file prettier ", "linked_issue_titles": "", "title": "add a typed version of the creditkey-js package"}
{"description": " that pass optimizes load and store offsets, turning a load of (x + y) into a load of x with a load offset of y, where y is a small enough constant. by setting global_base, we can ensure that valid memory locations start above a certain value, avoiding overflows that would invalidate using a load/store offset. this wastes a little static storage space which is then never touched, but it doesn't take space in the wasm file (we emit data segments without it). the cost is only in somewhat larger constants for static global locations, which might take more room as lebs, and a little wasted ram at runtime. the benefit, on the other hand, is using load/store offsets in more places, saving code size and compile time, and appears much bigger in practice. on asm2wasm we always did this, whereas with the wasm backend we did the bad half, but not the good half... by mistake. that is, we set global_base higher, but still never ran the optimization for it. all this pr does is fix that, that is, it does not change global_base - so this pr regresses nothing, and just helps. specifically, with this pr we shrink the final wasm by over 1% (e.g. on hello libc++). in theory the wasm backend could optimize such things (in which case we would not need to raise global_base). but it doesn't seem to do so in all cases, see #7715  the constant value of 1024 has been used in asm2wasm in practice for a long time, and seems slightly better than other reasonable values (i re-measured now on the wasm backend). ", "commit_messages": " wip [ci skip]  fix  comment ", "linked_issue_titles": "", "title": "use --post-emscripten pass with wasm backend"}
{"description": " this pr includes only the changes i had to make to services.sh in order to get e2e working in #3651. @bgrant0607 ", "commit_messages": " extra echo in services.sh e2e test to get it to pass  adds trailing semi-colon as per pr comment ", "linked_issue_titles": "", "title": "fixes endpoint propagation failure in services e2e"}
{"description": " module.instantiatewasm is a callback the user provides, and then the user is in change of fetching and instantiating the wasm. in that code path emscripten never sees the wasm binary, which means we cannot create a wasmoffsetconverter. with this pr we will not hang on startup, and we will still detect problems, but the sanitizer's own stack traces will mark function names as \"unknown\". that will limit the santizer's usefulness, but they do still detect errors, and the browser's own stack traces may be enough to diagnose things. fixes #13424 ", "commit_messages": " fix #13424  typo ", "linked_issue_titles": " offset-converter and caller-provided instantiatewasm hooks ", "title": "avoid using wasmoffsetconverter when module.instantiatewasm"}
{"description": " the other day i noticed the service module behaving strangely if i only specified enabled=yes and left out the state argument (it would enable the service but error out the first run). here's my attempt at cleaning up this code path a little. please review. tested on centos 6.3 ", "commit_messages": " changed the service module to terminate early if only changing the enabled state.  expanded the documentation slightly.  additional example in service documentation. ", "linked_issue_titles": "", "title": "service module changed to terminate early if only enabled specified"}
{"description": " the correlative issues: #4439 #4455 ", "commit_messages": " remove unnecessary null check  before instance of (#4321)  add zookeeper maven dependency so that on change registery can run the demo (#4352)  polish apache/incubator-dubbo#4347 : dubbo+nacos throw classnotfound  polish apache/incubator-dubbo#4330 : add @com.alibaba.dubbo.config.annotation.service support  [dubbo-4355] fix dubbo.jar do not contain \"serialization-protobuf-json\" module issue (#4356) (#4364)  * include protobuf-json jar to dubbo  polish apache/incubator-dubbo#4330 : optimization  [dubbo-4299]fix npe when pojoutils realize null element in collection(#4299) (#4300)  * fix npe when pojoutils realize null element in collection(#4299)  * add unit tests for bugfix of pojoutils npe(#4299)  * revert import (#4299)  fix qos configuration cannot work after added 'qos-enable' style support (#4378)  fixes #4377  polish apache/incubator-dubbo#4330 : refactor code  polish apache/incubator-dubbo#4409 : [enhancement] @enabledubboconfig reduces the duplicated dubboconfigconfiguration registration  allow @service and @reference to merge attributes form annotations in lower levels of the annotation hierachy. (#4078)  * allow @service and @reference to merge attributes form annotations in lower levels of the annotation hierachy.  * remove author information & not introduce all dependencies for test  format file: pom.xml of bom module (#4376)  synchronized local variables or parameters should be set to final (#4325)  * synchronized local variables or parameters should be set to final  * remove unused import  fix bug about nacos (#4308)  * fix bug  * add trim  polish apache/incubator-dubbo#4330 : add @com.alibaba.dubbo.config.annotation.reference support  polish apache/incubator-dubbo#4353 : in dubbo-2.7.2, dubbo + nacos throw 404 error  polish apache/incubator-dubbo#4439 : nacos regsitry supports the wildcard service name  # conflicts:  #\tdubbo-demo/dubbo-demo-annotation/dubbo-demo-annotation-consumer/pom.xml  #\tdubbo-demo/dubbo-demo-annotation/dubbo-demo-annotation-provider/pom.xml  #\tdubbo-demo/dubbo-demo-xml/dubbo-demo-xml-consumer/pom.xml  #\tdubbo-demo/dubbo-demo-xml/dubbo-demo-xml-provider/pom.xml  #\tdubbo-registry/dubbo-registry-nacos/src/main/java/org/apache/dubbo/registry/nacos/nacosregistry.java ", "linked_issue_titles": "", "title": "nacos registry enhancement & register reference bean"}
{"description": " closes #22905 closes #18338 closes #19420 closes #21184 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " tst: fixed timezone issues post datetimearray  test dataframe.stack with tz data  test merge_asof with by_col tz-aware  datetimeindex.to_period converting to utc  lint ", "linked_issue_titles": " bug: unstacking multiindex with datetime tz-aware data raises valueerror: cannot create a datetimetzblock without a tz  df.stack() on single column datetime with timezone causes loss of timezone  bug: merge_asof with tz-aware datetime \"by\" parameter raises  bug: to_period behaves different between timestamp and datetimeindex with timezones ", "title": "fixed timezone issues post datetimearray refactor"}
{"description": " description: adding support for homematic slo (outdoor brightness sensor) danielperna84/pyhomematic#176 i added the device to discover_sensors and added the unit_of_measurement & icon checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " add ipbrightnesssensor  add illumination unit & icon ", "linked_issue_titles": "", "title": "adding support for hmip-slo (outdoor brightness sensor)"}
{"description": " this pull request adds some rules to our wap project that suppress existing rules that were removing vital files. closes #2625 i even added a validation phase! ", "commit_messages": " wap: add some workarounds to ensure that terminal continues to build  fixes #2625.  make sure that cpprest_2_10.dll exists (sanity) ", "linked_issue_titles": " vs2019.3 wapproj changes broke our precarious packaging situation ", "title": "add some workaround to ensure that our package builds on 16.3"}
{"description": " description: i am proposing a few small changes to the feedreader component: moved the code that regularly updates the feed into own method so that subclasses can override this behaviour. the default feedreader is still updating at the top of the clock. moved the maximum entry filter into own method so that subclasses can override this behaviour and filter the feed differently. the default feedreader is still chopping off the feed after 20 entries. made the previously hard-coded event type configurable so that subclasses can introduce their own event type schema. the default feedreader is still publishing as feedreader. introduced a dedicated feed id attribute so that subclasses can introduce their own feed id schema. the default feedreader is still using the feed url as its id. breaking change: currently, parsing the feed is considered a failure if the bozo flag in the underlying feedparser is set. the bozo flag is set if the initial parsing fails, however, the library then tries a less restrictive approach parsing the feed which may still succeed. this change in the feedreader component still logs a message if the bozo flag is set, but then tries to access the feed to see if entries are present. as a bonus, i added unit tests for the feedreader component which are currently missing altogether. the background for all the changes above is a planned extension (already work in progress) to transform the geo_rss_events sensor into a component which will then be based on the feedreader component. if preferable, i can separate the non-breaking changes from the breaking changes. related issue (if applicable): n/a pull request in home-assistant.github.io with documentation (if applicable): n/a example entry for configuration.yaml (if applicable): configuration options have not changed. checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: ", "commit_messages": " moved regular updates definition to own method to be able to override behaviour in subclass  moved filter by max entries to own method to be able to override behaviour in subclass  event type used when firing events to the bus now based on variable to be able to override behaviour in subclass  feed id introduced instead of url for storing meta-data about the feed to be able to fetch the same feed from different configs with different filtering rules applied  keep the status of the last update; continue processing the entries retrieved even if a recoverable error was detected while fetching the feed  added test cases for feedreader component  better explanation around breaking change ", "linked_issue_titles": "", "title": "make feedreader component more extendable"}
{"description": " this is the same change as #4029, but updated per @fat: we don't take pulls against gh-pages, you need to change the docs in the -wip branch original description from #4029: two of the three apps listed are for linux/windows.  i adjusted the wording to clarify, as i originally skipped this section because i'm not using os x. just a simple change. note: this is just a pull request for the gh-pages branch. ", "commit_messages": " two of the three apps are for linux/windows; adjust accordingly  compiled; ignoring bootstrap.css change to avoid conflicts ", "linked_issue_titles": "", "title": "adjust wording for apps (on 2.1.0-wip)"}
{"description": " fixes rdar://problem/47220065. ", "commit_messages": " sema: fix crash when override checking encounters circularity  getinterfacetype() will return an errortype if the declaration is currently  being validated, which can happen if override checking triggers associated  type inference.  i believe this is <rdar://problem/47220065>.  ast: fix crash in getcontextsubstitutions() when a class has a malformed superclass type  it is possible for getsuperclassdecl() to return a non-null type, while  getsuperclass() returns an errortype. in this case, getcontextsubstitutions()  could crash because the walk of the superclass chain via getsuperclass()  might not find the context class.  instead of crashing in asserts builds, let getcontextsubstitutions()  silently build an invalid substitution map here, just as it does in no-asserts  builds.  silgen: add regression test for ", "linked_issue_titles": "", "title": "a couple of small circularity fixes"}
{"description": " cherry picked from commit cc3e43c original pr #49940 issue #49608 /lib/ansible/modules/windows/setup.ps1 ", "commit_messages": " fix facts memtotal_mb rounding on vmware and swaptotal_mb conversion from kb to mb  (cherry picked from commit cc3e43cb2051d210ebb7dfbea2cd3674b1ecf616)  add changelog fragment ", "linked_issue_titles": "", "title": "fix memtotal_mb rounding on vmware and swaptotal_mb conversion from kb to mb"}
{"description": " converted our bug template to the new issue forms syntax. this will enable more structured data on incoming bugs, that looks like this: you can try out any of the new templates from this pr here. microsoft reviewers: open in codeflow ", "commit_messages": " basic conversion of bug report markdown to yaml  copying a known-working yaml issue template  convert simple bug report to issue templates  syntax cleanup  just trying to get issue templates to work  slowly building back issue template  adding textareas  add issue markdown  add environment commands, remove markdown  refine environment commands  further refine environment prompts, test markdown  uniqueness of issue template  try to bring back markdown with link  add back troublershooting note  fix troubleshooting markdown  embded links in text  remove test yamls ", "linked_issue_titles": "", "title": "use issue forms for bug template"}
{"description": " closes #10233 closes #12610 previously, the message count for every room is increased upon message addition but is not updated upon the deletion of a message #12610. so, upon the removal of messages, the message count of rooms shows the wrong message count. now the message count of each room is updated upon message deletion, which makes the message count of each room error-free. so it will be better if we sum up the four values(4 different types of rooms: privategroupmessages, channelmessages, directmessages, livechatmessages) to get the exact total message count. ", "commit_messages": " [fix] message count of private and public channels upon deletion/pruning  [fix] message count statistics for admin info page ", "linked_issue_titles": " message count in statistics is strange  not displayed the number of users and messages in private and public channels on the page /admin/rooms ", "title": "wrong message count statistics in admin info page"}
{"description": " update spanish translations and fix some grammar mistakes. jira: none ", "commit_messages": " complete and fix the spanish translation on setup  correct the random names, fixing the denominations, translate of the english words, and fixing random and incorrect denominations like \"cabinet\" or \"distribuciones\".  complete and fix the spanish translation on setup ", "linked_issue_titles": "", "title": "update spanish translation of usetup."}
{"description": " this pull request changes the default app to allow you to launch http/file urls or html files directly in a window from the command line. this will allow you to test pages and sites directly in electron without having to create the standard app boilerplate around waiting for the app to be ready, creating the browser window, and loading the url. you'll now be able to do: electron  electron ./site/index.html electron file:///users/me/sites/page.html ", "commit_messages": " use const for fs/path requires  extract helper function to load specified app  add support for launching http url directly  add support for launching html files directly  support opening file: urls directly  loadpackagepath -> loadapplicationpackage  tweak help message for new path options ", "linked_issue_titles": "", "title": "launch url or html file directly"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint whatwg-streams provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " [whatwg-streams] make stream classes generic  [whatwg-streams] add transform streams ", "linked_issue_titles": "", "title": "make classes generic, add transform streams"}
{"description": " description [] fixes #22951  build fails on ubuntu 21.10 from (presumably) clang behavior changes and missing includes (the includes may not be required on macos compiler) verification [] performed a complete build on ubuntu 21.10 successfully ", "commit_messages": " fix compile on ubuntu 21.10  add missing c++17 optional refs in ui ", "linked_issue_titles": " compilation fails in ubuntu 21.10 presumably due to clang version behavior change ", "title": "fix build failures in ubuntu 21.10"}
{"description": " change change telemetrytracelogger to be per context add parent activity id concept to replace the subexecutionid send summary event upon each telemetrytracelogger destruction validation due to lack of test infra support for telemetry, i manually run and see telemetry events and also set breakpoints to verify the summary events. microsoft reviewers: open in codeflow ", "commit_messages": " snap1  infra done  log summary event  send summary event  fix tests  fix selected installer telemetry ", "linked_issue_titles": "", "title": "make telemetry logger per context and send summary event on destruction"}
{"description": " use black to auto-format all .py files. update flake8 config to exclude very large files (lemmatization tables etc.) update code to be compatible with flake8 rules fix various small bugs, inconsistencies and messy stuff in the language data update docs to explain new code style (black, flake8, when to use # fmt: off and # fmt: on and what # noqa means) once #2932 is merged, which auto-formats and tidies up the cli, we'll be able to run flake8 spacy actually get meaningful results. at the moment, the code style and linting isn't applied automatically, but i'm hoping that the new github actions will let us auto-format pull requests and post comments with relevant linting information. enhancement, code style i have submitted the spacy contributor agreement. ", "commit_messages": " auto-format test  ignore e731 in flake8  lambda vs. def  auto-format spacy/bin  auto-format top-level modules  auto-format spacy/displacy  auto-format top-level modules  auto-format spacy/tokens  flake8: ignore python artifacts and big files  mostly lemmatizer lookup tables and similar  auto-format spacy/lang ", "linked_issue_titles": "", "title": "tidy up and auto-format .py files"}
{"description": " i hereby agree to the terms of the cla available at: ", "commit_messages": " update system.md  added some system queries (1st attempt).  update system.md  added some system queries (1st attempt).  update system.md  added some system queries (1st attempt). ", "linked_issue_titles": "", "title": "doc change. added some system queries (1st attempt)."}
{"description": " users should be aware that these documents aren't actively maintained by the netdata team. i also cleaned up the beginning of the pfsense installation procedure. i didn't implement any of the suggestions from #9499, as those are more complex and forward-thinking. just trying to stop the short-term support issues. component name area/docs area/packaging ", "commit_messages": " add notice about community-maintained  update netdata version ", "linked_issue_titles": "", "title": "add notices to freebsd/pfsense docs that they are community-supported"}
{"description": " tests have been failing recently on the master branch because the ./meteor self-test create test runs out of memory. the release-1.6 branch contains a few commits that successfully limit memory usage by forcing garbage collection periodically (throttled to once every 500ms). this pr back-ports those commits to master, which i hope will fix the failing tests. ", "commit_messages": " allow programmatic garbage collection via gc().  throttle requestgarbagecollection to once per 500ms.  with meteor 1.6 / node 8, i noticed _buildlocalpackages taking multiple  seconds on initial server startup and restart, and the problem seems to be  that we call the global.gc function too often. this wasn't a problem in  previous versions of node, as far as i know, but it makes sense to heed  the comment in tools/utils/gc.js, now that it matters. ", "linked_issue_titles": "", "title": "enable throttled garbage collection (borrowed from release-1.6)."}
{"description": " this pr syncs portable-simd in up to rust-lang/portable-simd@a838552 in order to address the type inference breakages documented on nightly in #90904 by removing the vector + scalar binary operations (called \"autosplats\", \"broadcasting\", or \"rank promotion\", depending on who you ask) that allow {scalar} + &'_ {scalar} to fail in some cases, because it becomes possible the programmer may have meant {scalar} + &'_ {vector}. a few quality-of-life improvements make their way in as well: lane counts can now go to 64, as llvm seems to have fixed their miscompilation for those. {i,u}8x64 to __m512i is now available. a bunch of #[must_use] notes appear throughout the module. some implementations, mostly instances of impl core::ops::{op}<simd> for simd that aren't {vector} + {vector} (e.g. {vector} + &'_ {vector}), leverage some generics and where bounds now to make them easier to understand by reducing a dozen implementations into one (and make it possible for people to open the docs on less burly devices). and some internal-only improvements. none of these changes should affect a beta backport, only actual users of core::simd (and most aren't even visible in the programmatic sense), though i can extract an even more minimal changeset for beta if necessary. it seemed simpler to just keep moving forward. ", "commit_messages": " use new bitmask intrinsics with byte arrays  update contributing.md for the fact that travis is no longer used  update contributing.md for the fact that travis is no longer used  sprinkle the crate with #[must_use]  fix outdated workflow badge  fix outdated workflow badge  attempt to support to 64 lanes  impl deref.rs<&self> for simd<t, _>  instead of implementing each \"deref\" pattern for every single scalar,  we can use type parameters for simd operating on &self.  we can use a macro, but keep it cleaner and more explicit.  impl assign.rs<u> for simd<t, _>  instead of implementing {op}assign traits for individual scalar type args  to simd<_, _>, use parametric impls that reassert the bounds of the binary op.  generically implement horizontal_{and,or,xor}  uncomment avx512 byte vector conversions  resolves my comment in #197, at least for now; #187 is pending but since these are already here, just commented, it seemed to make sense to me to re-enable them anyway.  impl unary.rs for simd<{i,u}{8,16,32,64,size}, _>  in order to assure type soundness, these \"base\" impls  need to go directly on simd<t, _> for every scalar type argument.  a bit of cleanup of ops.rs is still warranted.  drop splats for simd<t, _>  unfortunately, splatting impls currently break several crates.  rust needs more time to review possible mitigations, so  drop the impls for the impl add<t> for simd<t, _> pattern, for now.  impl op<&'_ rhs> for &'_ lhs  merge portable-simd#195 - portable-simd:trait-ops  generic core::ops for simd<t, _>  in order to maintain type soundness, we need to be sure we only implement an operation for simd<t, _> where t: simdelement... and also valid for that operation in general. while we could do this purely parametrically, it is more sound to implement the operators directly for the base scalar type arguments and then use type parameters to extend the operators to the \"higher order\" operations.  this implements that strategy and cleans up simd::ops into a few submodules:  - assign.rs: core::ops::*assign  - deref.rs:  core::ops impls which \"deref\" borrowed versions of the arguments  - unary.rs: encloses the logic for unary operators on simd, as unary ops are much simpler  this is possible since everything need not be nested in a single maze of macros anymore. the result simplifies the logic and allows reasoning about what operators are valid based on the expressed trait bounds, and also reduces the size of the trait implementation output in rustdoc, for a huge win of 4 mb off the size of struct.simd.html! this addresses a common user complaint, as the original was over 5.5 mb and capable of crashing browsers!  this also carries a fix for a type-inference-related breakage, by removing the autosplatting (vector + scalar binop) impls, as unfortunately the presence of autosplatting was capable of busting type inference. we will likely need to see results from a crater run before we can understand how to re-land autosplatting.  merge commit 'a8385522ade6f67853edac730b5bf164ddb298fd' into simd-remove-autosplats  force splatting in simd test ", "linked_issue_titles": "", "title": "sync portable-simd to remove autosplats"}
{"description": " if we issue check table statement on distributed table, segment fault error will occur. the problem is that shard_info.pool could be null and we shouldn't create rmoteblockinputstream on null connections. ", "commit_messages": " rebase master  fix check distribute_table crash issue ", "linked_issue_titles": "", "title": "fix check table distributed_table crash issue"}
{"description": " update checkhashable to verify that different values hash differently -- we can do this with hash(into:) because we can eliminate hash collisions by trying different seeds. switch minimalhashable* types to use _hash(into:) as the primary hashing interface. ", "commit_messages": " [test] minimaltypes: move ==, < definitions into the corresponding type (nfc)  [test] minimalhashable{value,class}: implement customstringconvertible  this makes it easier to understand failure traces in test logs. ", "linked_issue_titles": "", "title": "review & update hash testing to use hasher's new features"}
{"description": " implement an interface for services to register metrics. metrics property is optional to interface ibroker for now, so it was implemented only on networkbroker that is currently using it.. localbroker doesn't have it, we can figure something out later the better way to implement in both brokers. how to test or reproduce types of changes new feature (non-breaking change which adds functionality) checklist i have read the contributing doc changelog ", "commit_messages": " add metrics to services  add ddp-streamer metrics  temp localbroker metrics ", "linked_issue_titles": "", "title": "add metrics capability to services"}
{"description": " the term aggregation is misleading. bundled edges is a better definition for this type of edge. closes #962 ", "commit_messages": " renamed aggregation to bundled edges in src  renamed aggregation to bundled edges in color schemes  updated docs  updated manual tests ", "linked_issue_titles": " rename \"aggregration\" edge to something better understandable ", "title": "rename aggregation edge to bundled edges"}
{"description": " fixes #2412 . note that the qps family of tests will still not build, as these use numerous banned features (lambdas, local templates) . however, this should enable all of the other tests and c++ library to build in gcc 4.4 . ", "commit_messages": " remove lambda function with lambda capture to allow building with pre-lambda  compilers  remove brace initialization for gcc-4.4 compatibility ", "linked_issue_titles": "", "title": "fixes for older c++ compilers (remove lambdas, brace init, and nullptr ambiguity)"}
{"description": " this code change achieves witching from using docvalue_fields and _source extraction to using the fields api. it helps simplify the ql code, but does also come with a small drawback which will become visible in fieldhitextractortests where some tests are not needed anymore. any query (especially sql) on fields that have _source disabled, but are indexed (accessible through docvalue_fields), will not be possible anymore. this pr, also, improves bwc checks when it comes to running queries in a mixed-versions cluster (a rolling upgrade scenario) by using a minimum compatibility version when creating a search request against es and re-trying the request if the search proves to be executed on at least one incompatible shard. the retrial happens on a node that has an older version, the original request (sql/eql request) being sent through transport layer. the node receiving the retried request will re-parse it and create another query dsl to be sent to es. addresses #67727. prs in this merge: #68467 #68602 #68745 ", "commit_messages": " integrate \"fields\" api into ql (#68467)  adapt nested fields extraction from \"fields\" api output to the new un-flattened structure (#68745)  ql: retry sql and eql requests in a mixed-node (rolling upgrade) cluster (#68602) ", "linked_issue_titles": "", "title": "\"fields\" api implementation in ql"}
{"description": " there was a problem with missing processes and values were 30% less in apps.cpu chart than in system.cpu chart. collect data for all processes and threads (it was collected without threads) take into account different units for cpu time in freebsd eliminate spikes fixes #4037 fixes #3245 component name apps.plugin cpu time statistics for processes in freebsd is represented in microseconds, not in ticks. ", "commit_messages": " read all threads  fix cpu time factor for freebsd ", "linked_issue_titles": "", "title": "fix process statistics collection for freebsd in apps.plugin"}
{"description": " this pull requests makes np.complexfloating generic with respect to np.floating. the main advantage of this is to make it easier to access the .real/.imag type of np.complexfloating sub-classes as is illustrated below. examples from typing import typevar import numpy as np floattype = typevar('floattype', bound=np.floating) def get_real(complex_value: 'np.compexfloating[floattype]') -> floattype: return complex_value.real ", "commit_messages": " enh: make np.complexfloating generic w.r.t. to np.floating  tst,maint: fixed an incorrect type comment ", "linked_issue_titles": "", "title": "make np.complexfloating generic w.r.t. np.floating"}
{"description": " be able to execute only specific tests. this is inspired by  you can replace temporarily tinytest.add or tinytest.addasync by tinytest.only or tinytest.onlyasync so only the tests added using only* are going to be executed. this is helpful when only a few tests are failing, so you can focus on them. there are small updates to the readme as well. ", "commit_messages": " introducing only and onlyasync to tinytest  introducing only and onlyasync to tinytest (removing debug logs)  adding support to onlyasync also in  testasyncmulti ", "linked_issue_titles": "", "title": "tinytest adding new api: only and onlyasync"}
{"description": " shippable.yml, ansible-test, integration tests ", "commit_messages": " switch tests from rhel 7.5 to 7.6.  (cherry picked from commit 6745ee7cc86c50f79b24fb701d1e4680320a576b)  remove ci platform: freebsd/10.4  (cherry picked from commit e6ffc4f89a27853e2ce983bc51a982b5a138d1bd)  support skip of platforms by version in tests. (#48826)  * support skip of platforms by version in tests.  previously a remote platform could be skipped completely using the alias:  skip/{platform} such as skip/rhel  now a specific platform version can be skipped using the alias:  skip/{platform}{version} such as skip/rhel7.6  this feature is available for platforms specified with the --remote option.  * add skip by version to the docs.  (cherry picked from commit 8066acc90c13595039812bd8f9eb1fcaaca1a890)  add --raw option to ansible-test shell command.  it is currently supported only with the --remote option.  this makes it easier to troubleshoot new instances which are not  yet supported by the setup scripts used by ansible-test.  (cherry picked from commit 0826a008039c45f4fcf2d428c9267decdaeb7de2)  fix ansible-test skip warning message.  (cherry picked from commit 3b705efc93fdf6553c05d139dfb49fe6a5aa6483)  fix lookup_passwordstore test skipping. (#49178)  * fix lookup_passwordstore test skipping.  skip all of rhel instead of specific versions.  skip all of centos < 7 instead of specific versions.  this makes the test more robust when testing newer versions.  tests could be executed on rhel if epel was installed during the test.  (cherry picked from commit 704dae2cda5ef3a7303b37de7bb0004f0a2ba581) ", "linked_issue_titles": "", "title": "backport test infra updates and test fixes."}
{"description": " change udp_server interface to pass in desired socket receive/send buffer size, and set them during socket preparation. set socket option so_rxq_ovfl to enalbe counting packets dropped in receive buffer. ", "commit_messages": " adjust receiv buffer via setsockopt for udp_server's listening socket.  since this socket is used for all incoming traffic, its current buffer  1mb is appearantly too small. change it to 10 mb for now.  change to pass in value ", "linked_issue_titles": "", "title": "change udp_server receive/send buffer size and set so_rxq_ovfl"}
{"description": " this pr adds two experimental components to be used for internal focus management handling. furthermore, this pr fixes a bug with scope component refs correctly detaching. tabfocuscontainer contains tabbable keyboard focus to within its children, where tabbing gets wrapped to the beginning. tabbablescope collects host components that are keyboard tabbable so that tabfocuscontainer can handle the tab navigation through said components. ", "commit_messages": " initial commits  [react-interactions] add focuscontain and tabbablescope ui components ", "linked_issue_titles": "", "title": "add tabfocuscontainer and tabbablescope ui components"}
{"description": " regarding suggestion after pr #19966 about a need to comment the modified line. ", "commit_messages": " initial commit  update base 20.06.2021  merging branch 'main' into issue_#19949 (after updating fork's base).  in corrected_std func use kr dummy var hope to please the linter  add comment in corrected_std  explain the kr variable  resolve a merge conflict. don't understand why it was there ", "linked_issue_titles": "", "title": "doc fixes typo and comment in example plot_grid_search_stats.py"}
{"description": " this pr wants @colinfinck to fix the whs x64 tester. ", "commit_messages": " [win32nt_apitest] add tests for truncated and extended handle to ntgdideleteobjectapp test  [win32k] fix an assert to ignore the upper 32 bits of a passed in gdi handle ", "linked_issue_titles": "", "title": "fix handling of upper 32 bits of gdi handles on x64"}
{"description": " as a result of discussion in #45403 i've come to conclusion that this is in fact a documentation issue and not a functional issue with the module (which is supported by #45403 (comment)). i also have in mind that i'd rather not be making functional changes to this module but instead, get started on the new api module (as in #41875). anyway, hopefully this does some good to help people use this module right now. linode ansible version ", "commit_messages": " attempt to explain linode_id a bit better.  don't include in any example that creates a linode.  based on comments in  >  add simple creation example. show how to pass linode_id. ", "linked_issue_titles": "", "title": "clarify how to create/delete linode machines with linode_id."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " add types for @woocommerce/woocommerce-rest-api  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "add type definitions for @woocommerce/woocommerce-rest-api"}
{"description": " when parsing for ansi color codes, succeeding codes will remove previous colors instead of adding new classes while ignoring existing ones. this will fix #70416. also added some unit tests and modified one existing one to account for the change. ", "commit_messages": " remove existing ansi colours when adding new ones  avoids color conflicts by removing previous colors when new ones added.  fixes #70416.  modify / add tests for succeeding ansi color codes  note: modifies interference test behavior; prior test  asserted undesired behavior. ", "linked_issue_titles": " debug console doesn't properly handle succeeding color escape sequences ", "title": "correctly handle succeeding ansi color codes (fix #70416)"}
{"description": " this change migrates a number of remaining maplike<t> entries to map<t>, as well as adds a number of additional functions for working with both maplike<t> and map<t>. the changes in the compiler itself add an additional performance improvement, shaving another ~400ms off of the total emit time of monaco and angular. this also disables the tslint restriction on use of the in operator, as offline performance tests i've run show that using in is faster than both hasownproperty and obj[key] when merely testing for the presence of a key. the in operator also works better when paired with delete, which is faster at removing entries from a map<t> than setting the entry to undefined. ", "commit_messages": " migrated more maplikes to maps  migrate additional maplikes to maps. ", "linked_issue_titles": "", "title": "migrate more maplikes to maps"}
{"description": " use itemgroup to print vars properties trivial change for build debugging purposes only. upgrades the custom vars target to use collections of msbuild items instead of manually adding a new message task for each msbuild property to print. informational adding new properties to the vars target resulted in a lot of boilerplate code. microsoft reviewers: open in codeflow ", "commit_messages": " use itemgroup to print vars properties  move items into target  rename jsengineitems  pad vc metadata to a multiple of 4 (32)  add customitems group ", "linked_issue_titles": "", "title": "categorize vars target's items"}
{"description": " this pr introduces a new doc on the writing process for the gatsby docs. it's been on the to-do list for a while as we've engaged with contractors and team members, and pulls together information into one outcome-driven place (writing greenfield docs). in particular, this doc was written to help the process of writing learning materials for topics that aren't well known or understood as that's been a blocker for some writers in the past. it also takes the opportunity to educate contributors about our standards and conventions throughout the discovery and content writing process. feedback welcome! n/a n/a ", "commit_messages": " feat: add new post on gatsby docs writing process  fix: add proper nouns to style guide  feat: additional links, markdown syntax + a11y ", "linked_issue_titles": "", "title": "new doc on gatsby's docs writing process"}
{"description": " the fix in #6297 doesn't work where the child to insert before is an element rather than a component, e.g. the video element. check if the child to insert before is an element, as well as checking if it has an el_ change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) ", "commit_messages": " fix: consider children that are elements in addchild  add test ", "linked_issue_titles": "", "title": "addchild with index should allow for children that are elements"}
{"description": " since @staars builded the ccloader tasmota driver to flash the zigbee module cc253x and the bt module cc2541 it is usefull to have the firmwares in the repo. the pull request is done against the latest dev branch the code change is tested and works on tasmota core esp8266 v.2.7.4.7 the code change is tested and works on tasmota core esp32 v.1.0.4.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " ccloader firmware cc2541  zigbee 2530 firmware  del ", "linked_issue_titles": "", "title": "ccloader firmware for zigbee and bt"}
{"description": " these changes resolve all issues described in #8593 except for the linker issue. ", "commit_messages": " fix compiler error due to mismatched braces (broken in f5fd897c1d)  endian.h is not available on qnx  add support for 64 bit qnx builds  fix compiler error with brace initializer (conflicts with #8492)  fix compiler error for empty default ctor for std::atomic<int> variables ", "linked_issue_titles": "", "title": "fix qnx 7.0 support #8593"}
{"description": " i hereby agree to the terms of the cla available at:  this makes a minor improvement to the deltasum function (that is backwards compatible) and adds a new function called deltasumtimestamp. the small improvement is to eliminate one of the state bools. i realized that having both seen_first and seen_last is unnecessary. since both bools would always have the same value, removing one of them is backwards compatible with old deltasum state data. the new function, deltasumtimestamp, works similarly but also keeps track of the timestamp of the first value seen and the last value seen. i found that in materialized views that were ordered by a tostartoffiveminute bucket, the merges were happening in a random order, so the delta sums were all incorrect. by storing the timestamp of the first and last value that is added to a particular deltasumtimestamp state, we can properly order them during merges. this makes it work well in materialized views. big thanks to clickhouse devs for taking my prs. as always any and all feedback is appreciated. new aggregate function deltasumtimestamp for summing the difference between consecutive rows while maintaining ordering during merge by storing timestamps ", "commit_messages": " remove uneeded bool in deltasum impl  add deltasumtimestamp aggregatefunction, docs&test  improve deltasumtimestamp doc ", "linked_issue_titles": "", "title": "add deltasumtimestamp + docs, tests & minor improvement to deltasum"}
{"description": " this pull request fixes a number of things related to the annotations of various np.generic subclasses: 3434da8 & e171b2b: adds previously missing types to the constructors. 3434da8: adds missing builtin baseclasses to the likes of np.str_ and np.float128. 8f2c26d: make np.datetime64 a subclass of np.generic (again), thus partially reverting numpy/numpy-stubs#31 (comment). the issues encountered in the linked comment have been partially addressed by explicitly defining a few __r<op>__ methods. once the, currently untyped, magic methods in np._arrayorscalarcommon have been annotated then the remaining issues will likelly resolve themselves. d6b0c70: per the discussion in #17172 this limits the np.generic.real and .imag properties to numeric np.generic subclasses. on the side of caution i've also included np.object_ and np.void, as the latter two may or may not contain numeric types (any thoughts on this?). ", "commit_messages": " maint: added missing types to various generic constructors  maint: added missing builtin super-classes to a number of generics  maint: explicitly define real and imag for a number of generic subclasses  maint: make datetime64 a generic subclass (again)  maint: removed the supportsint protocol from complexfloating constructors  tst: add tests for the new generic constructors ", "linked_issue_titles": "", "title": "fix various issues with the np.generic annotations"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them: there's a pr with incomplete typings create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. ", "commit_messages": " adding typings for url-parse  fixup! import urlsearchparams types  adding typings for parse function  changes to tsconfig and tslint  fixes to the type definitions  adding missing tslint file ", "linked_issue_titles": "", "title": "adding type definitions for url-parse npm package"}
{"description": " opened for issue #1462 this pr fixes the assertequals parameter order in the arrange-act-assert module. assertequals should be expected,  actual. currently these are reversed and in the incorrect order. ", "commit_messages": " corrected assertequals order for expected, actual.  corrected assertequals order for expected, actual. ", "linked_issue_titles": "", "title": "fixes issue #1462 - unit test assertequals parameters are reversed"}
{"description": " quoting @colindekker on #26822: the underlying packages of remote-redux-devtools, redux-devtools-instrument has received an update to support redux 4.x so currently when using redux 4.x , typescript compilation breaks because this type definition uses redux 3.x's genericstoreenhancer instead of the redux 4.x storeenhancer tyoe. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " chore: bumped redux version to 4.x & correct genericstoreenhancer import  redux 4 typings uses generic parameter defaults  as of typescript 2.3 there is [support for generic parameter defaults]( ", "linked_issue_titles": "", "title": "bumped redux version to 4.x & correct (generic)storeenhancer import & typescript 2.3"}
{"description": " this pr is following my own intuition that rustfix should never inject bugs into working code (even if that comes at the expense of it failing to fix things that will become bugs). fix #56327 ", "commit_messages": " do not lint dyn tokens under macros.  the existing keywordidents lint blindly scans the token stream for a  macro or macro definition. it does not attempt to parse the input,  which means it cannot distinguish between occurrences of dyn that  are truly instances of it as an identifier (e.g. let dyn = 3;)  versus occurrences that follow its usage as a contextual keyword (e.g.  the type box<dyn trait>).  in an ideal world the lint would parse the token stream in order to  distinguish such occurrences; but in general we cannot do this,  because a macro_rules definition does not specify what parsing  contexts the macro being defined is allowed to be used within.  so rather than put a lot of work into attempting to come up with a  more precise but still incomplete solution, i am just taking the short  cut of not linting any instance of dyn under a macro. this prevents  rustfix from injecting bugs into legal 2015 edition code.  some tests illustrating where the revised lint does and does not apply.  regression test for rust-lang/rust#56327. ", "linked_issue_titles": " edition compatibility lints: warning about `dyn` in a macro incorrectly ", "title": "skip dyn keyword lint under macros"}
{"description": " you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information i used the script written by @remitamine at #6497 (comment) to remove all extractors with age limit over 17. i then checked to see if it missed anything with grep -rvil age_limit youtube_dl/extractor | grep porn and yourporn.py showed up. i tried every sexy keyword i could think of and also found camtube.py cammodels.py camwithher.py ", "commit_messages": " [yourporn] add missing age limit  [camtube] add missing age limit  [cammodels] add missing age limit  [camwithher] add missing age limit ", "linked_issue_titles": "", "title": "add missing age limit to a couple of sites"}
{"description": " this will allow users to set the numexecutors for jenkins on startup after helm install without having to change the config.yaml file or using the jenkins ui to configure the numexecutors. will allow users to easily use values.yaml file for everything instead of having to make specific changes to other template files. dco signed ", "commit_messages": " update values.yaml  add variable for numexecutors so users can change for config file.  update config.yaml  allow config num executors to use variable from values file  update chart.yaml  update chart version and bumped.  update readme.md  update readme for new variable ", "linked_issue_titles": "", "title": "add numexecutors as a variable in values file"}
{"description": " not sure if anybody is going to read it there, but we can point to it if people don't do it ;) the naming and location comes from git, not sure if that breaks your ascetic sensibilities, @tanoku. maybe we should ask the pending prs to start doing it to get the ball rolling. ", "commit_messages": " conventions: update error code names  readme: add rules about writing release notes as they happen ", "linked_issue_titles": "", "title": "add notice about release notes"}
{"description": " has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? ", "commit_messages": " wip on integrating with vue  yarn lock  no need to return props from setup  use useresult for more concise and better type safety  fix regression  wip: migrate to apollo  wip: mostly working with pollinterval  apollo -> urql ", "linked_issue_titles": "", "title": "integrating urql w/ unified context branch"}
{"description": " closes #9906 done the cross linking as mentioned in the issue linked above. i have reviewed my changes in staging (look for the latest deployment event in your pull request's timeline, then click view deployment). for content changes, i have completed the self-review checklist. ", "commit_messages": " add further reading links  fixes github#9906  fix link  add further reading links  fixes github#9906  linking  fixes github#9906  linking  linking  added further reading section ", "linked_issue_titles": " add \"further reading links\" between end-user and org guides for codespaces ", "title": "adds further reading links to certain codespaces docs"}
{"description": " the repcode handling logic was slightly off in the original version of this api - this pr aims to fix it by: 1) keeping track of a dedicated repcode array, and 2) persist the repcodes array through each block. i've aimed to make the handling logic as clear to read as possible since we will need a similar process in the sequence compression api. test plan: manual spot checking (roundtrips silesia.tar with compression api) modify the unit test. previously, it turns out that setting the litprobability field to something like 0.5 in the rdg_genbuffer() function would almost always cause the unit test to fail. with this pr, it no longer does. ", "commit_messages": " overhaul repcode handling logic  improve unit test  fix incorrect repcode setting  let block reps persist ", "linked_issue_titles": "", "title": "improve repcode handling in sequence extraction api"}
{"description": " #5603 what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) it's submitted to the dev branch for v2.x (or to a previous version branch), not the master branch when resolving a specific issue, it's referenced in the pr's title (e.g. fix #xxx[,#xxx], where \"xxx\" is the issue number) if adding a new feature, the pr's description includes: ", "commit_messages": " simply fix inject extends ", "linked_issue_titles": "", "title": "merge inject when extending a component"}
{"description": " matrix keymap renamed to layout for both hardware configurations (alvicstep and stapelberg) added layout_pretty to both configurations all keymaps refactored to use qmk_keyboard_h include, and new matrix names includes default_pretty keymap, a duplicate of default keymap modified to use new layout_pretty matrix added info.json file for configurator support fixed a missing accent in the stapelberg readme ", "commit_messages": " matrix refactor  keymap refactor  configurator support  stapelberg readme formatting fix (missing grave accent) ", "linked_issue_titles": "", "title": "kinesis refactor and configurator update"}
{"description": " since we only call one parsing function (i.e. parsebraceitemlist, parsedecl, or parseexprorstmt), the parser stops at the end of the node anyways. it's not necessary to limit the lexer to set an artificialeof. as a ground work, modify the parser to not parse the body if the completion happens in the signature don't restore the parser position after the second pass because it's just not necessary. the parser here lives only for the single second pass. use getresultinterfacetype() to get the result type in typecheckfunctionbodyuntilrequest. so we can type check the body without type checking the signature of the func decl. (this change is actually not needed but i think this is an improvement) ", "commit_messages": " [sema] use getresultinterfacetype() to get the result type  in typecheckfunctionbodyuntilrequest. so we can type check the body  without typechecking the signature.  [codecompletion] don't use temporary lexer in the second pass  since we only call one parsing function (i.e. parseabstructfunctionbody,  parsedecl, or parsestmtorexpr), the parser stops at the end of the node.  it's not necessary to limit the lexer to set an artificialeof.  to minimize the parsing range, modify the parser to *not* parse the body  if the completion happens in the signature.  [codecompletion] don't restore the parser position after the second pass  this is just not necessary. this parser lives only for the single second  pass. ", "linked_issue_titles": "", "title": "stop using temporary lexer in the second pass"}
{"description": " contrib/inventory/apstra_aos.py ansible version ansible 2.3.0 (inventory_blueprint e1900d7755) last updated 2017/02/14 16:37:40 (gmt -700) config file = configured module search path = default w/o overrides i added a new type of output format for the apstra dynamic inventory when a blueprint name is provided. the inventory now support both device and blueprint mode. the main difference is the value used as the inventory_hostname. in device mode we are using the serial_number in blueprint mode we are using the node name as defined in the blueprint. in addition to that i also added the ability to provide parameters with environment variables in addition to the ini file. i updated the description to explain these changes ", "commit_messages": " add a new output format when a blueprint name is provided  add author name ", "linked_issue_titles": "", "title": "inventory/apstra_aos - add a new output format when a blueprint name is provided"}
{"description": " adding types declaration for module slashy   add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " add splashy types definitions  add splashy test ", "linked_issue_titles": "", "title": "add types declaration for module splashy"}
{"description": " updates the terminal's scroll response to new output. the terminal will not automatically scroll if... a selection is active, or the viewport is at the bottom of the scroll history #2529 - spec #3863 - implementation closes #980 closes #3863 requires documentation to be updated updates the _scrolloffset value properly in terminalcore when the cursor moves. we calculate a new _scrolloffset based on if we are circling the buffer and how far below the mutable bottom is. we specifically check for if a selection is active and if the viewport is at the bottom, then use that as a condition for deciding if we should update _scrolloffset to the new calculated value or 0 (the bottom of the scroll history). manual testing. though i should add automated tests. new output new output when circling new output when circling and viewport is at the top ", "commit_messages": " naive implementation (but it works)  add behavior for multiple flags  now this works with the circling buffer!  remove my lazy enum approach  update the schema ", "linked_issue_titles": " feature request: pause output or scrolling on click (and make it a setting)  feature request: preserve scroll position while not \"at bottom\" ", "title": "implement preventing auto-scroll on new output"}
{"description": " #35776 broke importing inaccessible extern crates, which should work with a warning (c.f. #31362). fixes #36747, fixes #37020, and fixes #37021. r? @nrc ", "commit_messages": " support importing inaccessible extern crates with a warning again.  add regression test. ", "linked_issue_titles": " ice when documenting crate that triggers pr 31362 warning  regression: unresolved import  regression: no method in scope ", "title": "fix importing inaccessible extern crates (with a warning)"}
{"description": " with the removal of the (standalone) firefox building code in pr #9566 (a year and a half ago), these files are now completely unused. hence it doesn't really make sense to keep building them as part of gulp locale, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). with the removal of the (standalone) firefox building code in pr #9566 (a year and a half ago), these files are now completely unused in the github repository[1]. hence it doesn't really seem necessary to keep fetching them with gulp importl10n, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise). the patch also allows an additional simplification, for the gulp locale and gulp mozcentral commands, since it's now possible to stop writing l10n files to the extensions/firefox/ folder and instead just copy them similar to other build targets. update l10n files ", "commit_messages": " [firefox] stop building the metadata.inc/chrome.manifest.inc files during gulp locale (pr 9566 follow-up)  with the removal of the (standalone) firefox building code in pr 9566 (a year and a half ago), these files are now completely unused.  hence it doesn't really make sense to keep building them as part of gulp locale, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise).  [firefox] stop fetching the chrome.properties files during gulp importl10n (pr 9566 follow-up)  with the removal of the (standalone) firefox building code in pr 9566 (a year and a half ago), these files are now completely unused in the github repository[1].  hence it doesn't really seem necessary to keep fetching them with gulp importl10n, and the existing files in the l10n folder can also be removed (thanks to version control, they're easy enough to restore should the need ever arise).  the patch also allows an additional simplification, for the gulp locale and gulp mozcentral commands, since it's now possible to stop writing l10n files to the extensions/firefox/ folder and instead just copy them similar to other build targets.  ---  [1] they're obviously still used in mozilla-central, for fallback messages displayed through pdfstreamconverter.jsm, but that doesn't make it necessary to keep them *here* as far as i'm concerned.  update l10n files ", "linked_issue_titles": "", "title": "remove unused addon l10n files (pr 9566 follow-up)"}
{"description": " what do these changes do? this is the first step for implementing a offline data i/o api: what works: # generate experiences rllib train --env=cartpole-v0 --run=pg --config='{\"output\": \"s3://bucket/data\"}' # consume experiences rllib train --env=cartpole-v0 --run=dqn \\ --config='{\"input\": \"/tmp/data\", \"input_evaluation\": \"simulation\"}' # consume experiences from s3 files rllib train --env=cartpole-v0 --run=dqn \\ --config='{\"input\": [\"s3://bucket/f1\", \"s3://bucket/f2\"], \\ \"input_evaluation\": \"simulation\"}' # consume experiences from different sources rllib train --env=cartpole-v0 --run=dqn \\ --config='{\"input\": {\"sampler\": 0.5, \"/tmp/data\": 0.5}}' what's next: trajectory postprocessing and multi-agent support add a non-batched input format counterfactual evaluation (also need some way to get the reward timeline) documentation #3363 ", "commit_messages": " output io  evaluator support  stub  update  return spec  json writer  no clip act  os  json writer working  smart open  paginate  writer  io working  wip  wip  wip  compression options  add tests ", "linked_issue_titles": "", "title": "basic offline data io api"}
{"description": " fixes #7849. enhance geturl() method. add switch case for oracle  in datasourceconnectionurlutil. add switch case for sqlserver   in datasourceconnectionurlutil. add switch case for mariadb   in datasourceconnectionurlutil. add unit case. add unit case  for oracle in datasourceconnectionurlutiltest . add unit case  for sqlserver in datasourceconnectionurlutiltest . add unit case  for mariadb in datasourceconnectionurlutiltest . ", "commit_messages": " enhance geturl support oracle, sqlserver, mariadb  add test case for oracle, sqlserver, mariadb  modify code style ", "linked_issue_titles": " support more databases for datasourceconnectionurlutil ", "title": "enhance  datasourceconnectionurlutil and add test case"}
{"description": " #86255 introduced a 30% regression in page faults and a 3% regression in max-rss in the ctfe-stress benchmarks. that's most likely happened because it separated allocation from initialization of the vec which defeats the zero-optimization. currently there's no allocation api that is fallible, zeroing and returns a slice, so this pr introduces one and then uses that to solve the problem. in principle vec.resize(len, 0) could be optimized to use alloc::grow_zeroed where appropriate but that would require new specializations and new plumbing in rawvec. ", "commit_messages": " add box::try_new_zeroed_slice()  currently there is no api that allows fallible zero-allocation of a vec.  vec.try_reserve is not appropriate for this job since it doesn't know  whether it should zero or arbitrary uninitialized memory is fine.  since box currently holds most of the zeroing/uninit/slice allocation apis  it's the best place to add yet another entry into this feature matrix.  use zeroed allocation instead of eagerly initializing the memory ", "linked_issue_titles": "", "title": "use zeroed allocations in the mir interpreter instead eagerly touching the memory"}
{"description": " i responded to #721 with a brief summary of all the features, and was asked to update the readme with the summary. this pr does that. this also expands a couple of the sections at the start of the doc. i think they make thing clearer, but also a bit more verbose. if you like, we can drop those edits, and just keep the features list, though i think a link to the usage readme, is clearer than a link to available here, and is still just as terse. ", "commit_messages": " expanded the features section.  this commit expands the features section to offer a summary of all currently available features, and updates the doc's intro too.  made the link to the usage readme more specific.  this makes the hypertext of the link in the main readme to the usage readme less ambiguous. ", "linked_issue_titles": "", "title": "update the main readme to summarise all the features."}
{"description": " this is my initial pass at supporting coroutine mocking via a new mock subclass, coroutinemock. it can be used to mock out coroutines and have them validate as coroutines: >>> mock = coroutinemock() >>> asyncio.iscoroutinefunction(mock) true test that a coroutine was awaited: class testtests(unittest.testcase): def test_assert_awaited(self): async def main(): mock = coroutinemock() with self.assertraises(assertionerror): mock.assert_awaited() await mock() mock.assert_awaited() asyncio.run(main()) also awaited_with, awaited_once_with, etc. things that i could use advice on: some of the code has been borrowed by asynctest ( inspect.iscoroutine will return false for coroutinemock objects. this is because the check is isinstance(object, types.coroutinetype), and coroutinetypes are concrete. i've looked into using something like, register, but it doesn't work here, so i need someway to make a mock look like a types.coroutinetype but i am unsure how. in coroutinemockassert tests, i have asyncio.events._event_loop_policy unset because it causes the env to change when running tests if it is not unset. there is probably a better way to do this where the environment doesn't get polluted? i plan on working on getting more example test cases for the coroutinearguments test section, would be happy for advice though. and i will be writing up the documentation once the code has settled. ", "commit_messages": " initial commmit adding asyncio mock support.  adding async support to the mock library.  removes superfluous changes.  cleans up comments.  fixes inspect and attribute error issues.  fixes test_unittest changing env because of version issue.  removes newlines from inspect.  removes unneeded comment and newlines.  fixes async tests. removes inspect fix.  fixes environment test issue.  adds argument tests. ", "linked_issue_titles": "", "title": "adds asyncmock for asyncio mock library support"}
{"description": " this pr collects some changes that turn out to be necessary for implementing depnodes based on stable hashes (see #42294). the commits are self-contained and mostly straightforward. the most interesting change here is the introduction of defindices for things that are not part of the ast: some pieces of crate metadata now have a defindex too.  r? @nikomatsakis ", "commit_messages": " ich: make stablehashingcontext work with any tyctxt, not just the global one.  ich: add some hashstable implementations.  incr.comp.: make workproductid opaque so we don't accidentally rely on being able to reconstruct obj-file names from one.  allocate defindices for global crate metadata.  this allows for treating global crate metadata the same as regular metadata with regard to incr. comp. ", "linked_issue_titles": "", "title": "some preparatory refactorings for hash-based depnodes"}
{"description": " fixes #35524 (80% solution) this pr makes the parser parse @link tag and the language service offer symbols for entity names found at the beginning of those tags. links are stored redundantly with comment text, so they're only used to provide (1) a span to an editor to format in some way (2) a symbol for the declaration of the link's target. future prs parse # as type-space element access: class#method. as well as, possibly, the normal ts syntax class[\"method\"], which doesn't currently parse either. open questions i parse @see {@link ...} as a @see with no reference and a link in its comment text. i think that's ok. i intentionally do not parse { @link x}, with a space separating { and @. i saw this only twice in my corpus, but @amcasey points out that it's easy to support with an additional skipwhitespace call. i originally skipped it because i had slightly less lookahead when the next token after { was @, but that made the code unreadable, so i dropped it. resolved questions i introduced jsdoctext and jsdoclink nodes into the ast, which better reflects the semantic relation of comments to their tags. it is more expensive, though, it means that jsdoc comment text is treated as a first-class member of the parse tree now. ", "commit_messages": " initial scribbles  compiles but provides spans instead of location pairs  probably need to fork the services/server types and provide a conversion  with session.tofilespan. not sure where to put the conversion.  switch to documentspan  in theory this is already better supported, but not sure practise bears  that out.  builds w/protocol types + conversions  cleanup:better names and scrub todos  fix test harness too  misc  1. simplify protocol after talking to @mjbvz.  2. add more tests.  3. initial notes about where to add parsing.  parse and store links in the compiler  the text of the link is still stored in the comment text, but that's now  kept in an object instead of just a string. each link has the parse for  the entity reference, if there is one.  needs lots more tests -- this just makes all the existing jsdoc tests  pass.  more tests and some fixes  fix other failing tests  fix bad merge  polish parser  improve names and array types  slight tweaks ", "linked_issue_titles": " editor support for @see and {@link} in jsdoc comments tags ", "title": "editor support for link tag"}
{"description": " bugfix : legacy spring annotation-driven issues on placeholder. refactor: the binder for dubbo's config beans in order to adapter for spring framework and spring boot 1.x/2.0 enhancement : extraction of the ops methods for spring boot acutator run test-cases follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. ", "commit_messages": " update  merge remote-tracking branch 'upstream/master'  manually merge pull request #1486, to make travis ci and codecov work after apache incubator transition.  polish alibaba/dubbo#1306  merge remote-tracking branch 'dubbo_remote/master'  2.5.x merge to master  optimize imports  optimize imports ", "linked_issue_titles": "", "title": "spring framework / spring boot enhancements"}
{"description": " fix 8808 first of all, thank you for your contribution! :-) please makes sure that these checkboxes are checked before submitting your pr, thank you! make sure that you propose pr to right branch: bugfix for master, feature for latest active branch feature-x.x. make sure that you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. extra checklist: if isbugfix : make sure that you add at least one unit test for the bug which you had fixed. elif isnewfeature : update api docs for the component. update/add demo to demonstrate new feature. update typescript definition for the component. add unit tests for the feature. ", "commit_messages": " anchor scroll supports complete href link  anchor scroll supports complete href link, e.g.  anchor scroll supports complete href link - test  anchor scroll supports complete href link, e.g. ", "linked_issue_titles": "", "title": "bugfix for 2.x stable - anchor scroll supports complete href link"}
{"description": " this pr adds an additional ocr_lang argument to the __init__ method of layoutlmv2featureextractor  which specifies which teserract model to use when applying tesseract ocr. fixes #14511 @nielsrogge ", "commit_messages": " added the lang argument to apply_tesseract in feature_extraction_layoutlmv2.py, which is used in pytesseract.image_to_data.  added ocr_lang argument to layoutlmv2featureextractor.__init__, which is used when calling apply_tesseract  updated the documentation of the layoutlmv2featureextractor ", "linked_issue_titles": " layoutxlmprocessor applies the english tesseract model ", "title": "layoutlmv2featureextractor now supports non-english languages when applying tesseract ocr."}
{"description": " prior to this pr, something broke the signatures of wrapped dg methods. this was reflected in docs.streamlit.io (where things like st.text(body) were written as st.text()) and in the python console (e.g. help(st.text)). it was probably broken in ides too. that's because we use some magic to make our signatures cleaner, and something broke that magic. i fixed that now and added tests. ", "commit_messages": " fix signatures of wrapped dg functions  lint ", "linked_issue_titles": "", "title": "clean signatures of wrapped deltagenerator methods"}
{"description": " first of two prs to separate array casting/inference out of index.__new__.  once both are in place, we'll be able to do all inference/casting up-front and simplify the constructor quite a bit.  we'll also be able to look into sharing code between index/series/array, and address a handful of outstanding issues with the index constructor. ", "commit_messages": " ref: refactor array casting out of index.__new__  docstrings ", "linked_issue_titles": "", "title": "separate casting out of index.__new__"}
{"description": " this updates the include/exclude configs to output/remove files in the traces correctly and adds tests for the configs. related issues linked using fixes #number errors have helpful link attached, see contributing.md related issues linked using fixes #number errors have helpful link attached, see contributing.md make sure the linting passes by running yarn lint ", "commit_messages": " use micromatch for excludes and add tests  update compiled ", "linked_issue_titles": "", "title": "update include/exclude handling for output tracing"}
{"description": " description: this pr adds support for custom stream queries per device and media type to media_extractor. example entry for configuration.yaml (if applicable): media_extractor: default_query: worst customize: media_player.kd55x8507c: video: bestvideo music: bestaudio playlist: worstaudio[ext=mp4] default query if no settings provided is  best. user can override default value or set custom query per device and media type. examples: bestvideo - best video only stream best - best video + audio stream bestaudio[ext=m4a] - best audio stream with m4a extension worst - worst video + audio stream bestaudio[ext=m4a]/bestaudio[ext=ogg]/bestaudio - best m4a audio, otherwise best ogg audio and only then any audio more about format queries  but: my settings: media_extractor: default_query: best customize: media_player.kd55x8507c: video/videoonly: bestvideo video/best: best audio/best: bestaudio[ext=m4a] my chromecast device (sony bravia with android tv) does not support these media content types  it supports media_content_type attributes like: video/blablabla audio/blablabla my service call data is: {\"entity_id\": \"media_player.kd55x8507c\", \"media_content_id\": \" checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " add support for different stream formats  encapsulate logic inside mediaextractor class ", "linked_issue_titles": "", "title": "add support for custom stream queries for media_extractor"}
{"description": " ander's work on destructuring assignment has incorporated two features : emitting default parameters and emitting rest parameters. this pull request is to add test cases for these two features. ", "commit_messages": " add tests covering emitting default parameters natively in es6  add tests covering emitting rest parameters natively in es6 ", "linked_issue_titles": "", "title": "add tests for rest and default"}
{"description": " following #28413, #28396, and #28395, these are all pretty straightforward refactors. arithmetic_op, comparison_op, and logical_op are going to become the ops that we call block-wise.  hopefully also pandasarray will use them directly. other follow-ups i have in mind: move should_extension_dispatch and dispatch_to_extension_op so we dont need runtime imports get rid of eval_kwargs entirely, they're not really necessary at this point see if we can use numexpr for comparison/logical ops docstrings address inconsistencies in when we call extract_array address inconsistencies in how series methods handle __finalize__ and alignment simplify logical_op's na_op ", "commit_messages": " ref: implement logical and comparison array ops  implement arithmetic_op ", "linked_issue_titles": "", "title": "implement arithmetic, comparison, logical ops on arrays"}
{"description": " a number of regressions were patched also.     the ubl g29 p2 and p4 press and hold had stopped working.   it is very possible this is broken in the bugfix_v1.1.x branch also. the main purpose of the pull request is to get the 3-point mesh tilting to use the lsf algorithm just like the grid based mesh tilt.   this simplifies the logic and reduces the code size some what.   but the real reason to do it is the 3-point case can be solved exactly.    and by feeding these numbers into the lsf algorithm it provides a way to check all that code for 'correctness'. ", "commit_messages": " fix regression of x & y on max7219 debug led's  make g29 p1 and g29 p2 changes available to everybody.  back to default configurations for pull request ", "linked_issue_titles": "", "title": "convert ubl mesh tilting to all use the same algorithm"}
{"description": " fix issue #642 (aztec decoding: incorrect decoding of codes with u/s b/s). this is a 1-line addition to core/src/main/java/com/google/zxing/aztec/decoder/decoder.java add test case core/src/test/resources/blackbox/aztec-1/dlusbs.png and matching .txt change number of test cases. the original code fails tests for core on the added test case; the source change fixes that. ", "commit_messages": " update decoder.java  add files via upload  dlusbs.png and dlusbs.txt is a test case for the d/l [digit] u/s b/s sequence, which should end in upper mode, not digit mode ", "linked_issue_titles": " core: aztec decoding incorrect for codes with u/s b/s ", "title": "return to upper mode after u/s b/s sequence."}
{"description": " .s16 sign extends on loads, but it seems to be the same as .u16 on stores. since our ir doesn't support primitives for integers smaller than 32 bits, implement the logic manually. in the future we might want to handle 16 and 8 bit operations at its respective level on the ir and use 32 bits operations on the decompilation step when the target api doesn't support smaller integers. while we are at it, abstract the code to avoid repeating logic. used by pc builder simulator used by doom 2016 ", "commit_messages": " shader/memory: implement ldl.s16 and lds.s16  shader/memory: move unaligned load/store to functions  shader/memory: implement unaligned ldl.s16 and lds.s16  shader/memory: implement stl.s16 and sts.s16 ", "linked_issue_titles": "", "title": "implement ldl.s16, lds.s16, stl.s16 and sts.s16"}
{"description": " a fix for #8398. ", "commit_messages": " core: when we can't enqueue onfailure= job show full error message  let's ask for the full error message and show it, there's really no  reason to just show the crappy errno error.  core: don't trigger onfailure= deps when a unit is going to restart  this adds a flags parameter to unit_notify() which can be used to pass  additional notification information to the function. we the make the old  reload_failure boolean parameter one of these flags, and then add a new  flag that let's unit_notify() if we are configured to restart the  service.  note that this adjusts behaviour of systemd to match what the docs say.  fixes: #8398  update news to explain new onfailure= behaviour ", "linked_issue_titles": "", "title": "trigger onfailure= only if restart= is not in effect"}
{"description": " the issue was: if someone mentions an user that is not following the thread, that user (the user mentioned) would not get a notification. also fixes #14019 by always using the sender as the email from ", "commit_messages": " fix sending notifications to mentions on threads  always use the sender name as email from field ", "linked_issue_titles": " mentions email inside discussions uses the wrong name property ", "title": "fix sending notifications to mentions on threads and discussion email sender"}
{"description": " this pull request add the support of can iso-tp address extensions in the socket module by enhancing getsockaddrarg and getsockname. note to core developpers : i believe this pull request should be backported back to python 3.3 where socketcan support have been added. ", "commit_messages": " added support for can_isotp protocol  added unit tests for can isotp  updated documentation for iso-tp protocol ", "linked_issue_titles": "", "title": "bpo-30987 - support for iso-tp protocol in socketcan"}
{"description": " pylint rule unused-import isn't prompting error anymore - removing disabled rule from charts and connectors modules. test plan requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " removed disabled pylint rule unused_import from dao.py in charts module  removed disabled pylint rule unused_import from connector_registry.py in connectors module ", "linked_issue_titles": "", "title": "reenable pylint rule unused-import in charts and connectors modules"}
{"description": " previously, if you attempted to run a spec window and an atom process was already running it would run the specs in the already running process which prevented the spec output from being seen. this also updates the bundled version of apm to include apm test. ", "commit_messages": " remove initialization repetition from a second atom process  run test processes separately  update apm to include apm test ", "linked_issue_titles": "", "title": "always launch atom as a separate process (when just running specs)"}
{"description": " this fixes #1551. servers now respond to unparseable arguments with the invalid_argument status and the text of the deserialization error, instead of crashing. ", "commit_messages": " added failing tests for server bad argument handling  fixed server to handle invalid arguments without breaking ", "linked_issue_titles": " node rpc server cannot recover from malformed requests ", "title": "handle invalid arguments sent to the node server"}
{"description": " this pr adds rate limits to post /api/users and post /api/users/:user_id. it's currently static, but we can make it configurable if needed. also changed tests not to use rate limits (except for the tests that need them). ", "commit_messages": " add rate limits for user resources.  disable rate limiting in tests (except for tests that need it). ", "linked_issue_titles": "", "title": "add rate limits to user creation/update"}
{"description": " added a new style guide rule for \"prefer the hooks api as the default\", plus an example of looking up action stack traces in the essentials tutorial. also switched all the \"default explanation\" expanders in the style guide to use an mdx component, and added back some margin between paragraphs inside those explanations. ", "commit_messages": " add style guide link to header as \"best practices\"  tweak styling for style guide detailed explanation paragraphs  add \"use hooks api\" style guide rule  add action stack trace example ", "linked_issue_titles": "", "title": "add \"use hooks\" style guide rule and \"action stack trace\" tutorial example"}
{"description": " tested it out and works nicely. things which are not very nice and would like to get feedback: naming of methods in groupservice.ts, notice that the setting is named showtabs so i was trying to be consistent with that currently the editorgroupservice does not react on showtabs changed in the configuration - the partservice does that and lets the editorgroupservice know. the alternative would be the editorgroupservice does this but then needs to check the part service if zen mode is active (which would require an additional method in part service) fixes #17207 ", "commit_messages": " editorgroupservice: managing of tabs visibility  zenmode: hide tabs ", "linked_issue_titles": " zen mode could have an option to show only the current tab ", "title": "isidorn/tabs in editor group service"}
{"description": " made few corrections changes for easy navigation and easy reading ", "commit_messages": " fix url bug caused by typo  update url with the new correct source  fix broken url caused by dead source  made adjustment to the docs for easy navigation ", "linked_issue_titles": "", "title": "updated the docs in deploying-to-gatsby-cloud"}
{"description": " this is a small improvement for mapactions and mapmutations helpers. it allows users to pass functions in the helpers so that reducing some redundant method definitions. the feature is like a counterpart of passing function in mapstate. for example: const vm = new vue({ store, template: <input @input=\"oninput\"> methods: mapactions({ oninput (dispatch, event) { // first argument is as same as this.$store.dispatch dispatch('inputtext', { text: event.value }) } }) }) the above code is equivalent with the below (note that inputtext is a bit redundant since it is just an bridge method between oninput and the action): const vm = new vue({ store, template: <input @input=\"oninput\"> methods: { ...mapactions(['inputtext']), oninput (event) { this.inputtext({ text: event.value }) } }) }) in addition, this syntax is more effective when we map namespaced modules. methods: mapactions('some/module', { oninput (dispatch, event) { // dispatch is already namespaced here. // so the below line will call some/module/inputtext action. dispatch('inputtext', { text: event.value }) } }) i did not implement this syntax for mapgetters because we already can do the same thing with mapstate. close #750 ", "commit_messages": " feat: allow to pass function value in mapactions/mapmutations  feat: extend mapactions/mapmutations types for function usage ", "linked_issue_titles": "", "title": "allow to passing functions in mapactions/mapmutations (fix #750)"}
{"description": " this pr fixes the behavior re: pathprefix identified in #8155. essentially: uses withprefix helper in all programmatic navigation removes manual prefix in onclick handler in link adds a number of unit tests and e2e tests ", "commit_messages": " fix: prefix navigate calls with pathprefix  fixes #8155  test: fix unit tests and add a few new ones  e2e: update integration tests ", "linked_issue_titles": "", "title": "use path prefix in navigate/replace/push calls"}
{"description": " we already have a page in docs  i have updated the existing page with content from site-showcase-submissions and set the link as available. i also think it would be better if we add a redirect for site-showcase-submissions to submit-to-site-showcase @shannonbux @jlengstorf @m-allanson ", "commit_messages": " pulling from master  pull from source  updating submit to site showcase ", "linked_issue_titles": "", "title": "updating 'submit-to-site-showcase' stub in docs"}
{"description": " new toggle is added into fancyzones settings to enable/disable snapping windows to zones across monitors when moving windows using windows snap hotkeys. references pr checklist validation steps performed manually tested for correct functionality and regressions on single and multi-monitor environment. ", "commit_messages": " make moving window across monitors optional  update tests ", "linked_issue_titles": "", "title": "make snapping windows using windows snap hotkeys across monitors optional"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. continuation of #36041 after pr was closed because of inactivity. ", "commit_messages": " update typings to styled-system v5  update system usage to include all properties  correct jsdoc comment spacings  actually correct jsdoc comment format  correct and test jsdoc comment spacing locally  the last three commits all have to do with correcting jsdoc spacing, but  unfortunately, the first two did not correct the issue. this commit  corrects the issue and is tested locally. i would prefer to squash all  these commits into the first, but will leave them for now.  update styled system typings  add createparser and createstylefunction functions  update types/styled-system/index.d.ts  update gridtemplateareasprops interface  add textshadow and shadows style functions  merge remote-tracking branch 'upstream/master'  fix shadows   ", "linked_issue_titles": "", "title": "update typings to v5 (continued)"}
{"description": " i hereby agree to the terms of the cla available at:  add connection pool for postgresql table/database engine and dictionary source. should fix #21444. ", "commit_messages": " add connection pool  add test  better ", "linked_issue_titles": " postgresql engine: pqxx, new command started while previous is active ", "title": "add connection pool for postgres engine"}
{"description": " with this pr we improve type argument inference by inferring from the contextual type of a generic function call to the return type of the generic function. for example: function emptyarray<t>(): t[] { return []; } let a1: string[] = emptyarray();  // string inferred for t let a2: number[] = emptyarray();  // number inferred for t previously the two assignments above would error because {} was inferred for t. we now infer from the contextual type (i.e. the type of the variable to which the function result is assigned). a more elaborate example: function arrayfilter<t>(f: (x: t) => boolean): (a: t[]) => t[] { return a => a.filter(f); } function arraymap<t, u>(f: (x: t) => u): (a: t[]) => u[] { return a => a.map(f); } function compose<a, b, c>(f: (x: a) => b, g: (x: b) => c): (x: a) => c { return x => g(f(x)); } const positives: (a: number[]) => number[] = arrayfilter(x => x >= 0); const lengths: (a: string[]) => number[] = arraymap(s => s.length); const evenlengths: (a: string[]) => number[] = compose(arraymap(s => s.length), arrayfilter(x => x % 2 === 0)); let a1 = positives([1, 2, -3, 4, -5]);            // [1, 2, 4] let a2 = lengths(['a', 'bb', 'ccc', 'dddd']);     // [1, 2, 3] let a3 = evenlengths(['a', 'bb', 'ccc', 'dddd']); // [2, 4] inferences made from generic function return types have lower priority than inferences made from arguments to the generic function. for example, the type of s is inferred as string (not object) in the following: function filter<t>(a: t[], f: (x: t) => boolean): t[] { return a.filter(f); } let a: object[] = filter(['a', 'bb', 'ccc', 'dddd'], s => s.length > 2); this pr is a precursor for inferring higher order function types when no inferences can be made for one or more type parameters. const wrapper = compose(x => [x], y => ({ p: y }));  // (x: {}) => { p: {}[] } we currently infer (x: {}) => { p: {}[] }, but ideally we'd infer <a>(x: a) => { p: a[] }. that's next on the list. fixes #15680. ", "commit_messages": " revise type inference data structures  initial implementation of return type inference  clean up implementation  accept new baselines  fix fourslash test  fix linting errors  inferencecontext is-a typemapper instead of has-a typemapper  move return type inference to infertypearguments function  add tests  accept new baselines ", "linked_issue_titles": "", "title": "infer from generic function return types"}
{"description": " fix the title/link for \"supported platforms\", which got lost in a previous toc reorg. move \"code signing\" under \"application distribution\", because it's unclear what the difference between \"packaging\" and \"distribution\" is, and also this was the only item under \"packaging\". cc: @electron/wg-docs-tools pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " docs: fix link to supported platforms in toc  docs: move code signing under the distribution heading ", "linked_issue_titles": "", "title": "reorganize application distribution links in table of contents"}
{"description": " description: this change adds support for multiple disks to be configured and monitored. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3678 example entry for configuration.yaml (if applicable): sensor: - platform: hddtemp host: 192.168.1.2 disks: - /dev/sda - /dev/sdb checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " add support for multiple disks.  merge upstream  fix lint error. ", "linked_issue_titles": "", "title": "add support for multiple disks to be monitored."}
{"description": " we were modifying the passed in dictionary in-place in order to handle an edge case of working_dir. this was causing failures in serve as the passed dictionary was stored and used for more deployments in the future. this modifies the logic to not modify the dictionary and instead pass along the parent's working dir as a separate parameter. closes #18403 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix validation logic  working ", "linked_issue_titles": " [runtime_env] [serve] updating deployment that uses working_dir causes backend_state.update() to fail ", "title": "don't modify passed runtime_env dictionary when validating"}
{"description": " this pr: ports test_trainer_distributed to run with pytest - it will skip if gpus < 2. includes various improvements via refactoring now 3 use cases of distributed testing by extending testcaseplus with a whole set of convenient features: feature 1: a set of fully resolved important file and dir path accessors. in tests often we need to know where things are relative to the current test file, and it's not trivial since the test could be invoked from more than one directory or could reside in different sub-directories. this class solves this problem by sorting out all the basic paths and provides easy accessors to them: pathlib objects (all fully resolved): test_file_path - the current test file path (=__file__) test_file_dir - the directory containing the current test file tests_dir - the directory of the tests test suite examples_dir - the directory of the examples test suite repo_root_dir - the directory of the repository src_dir - the directory of src (i.e. where the transformers sub-dir resides) stringified paths - same as above but these return a string, rather than a pathlib object test_file_path_str test_file_dir_str tests_dir_str examples_dir_str repo_root_dir_str src_dir_str feature 2: get a copy of the os.environ object that sets up pythonpath  correctly, depending on the test suite it's invoked from. this is useful for invoking external programs from the test suite - e.g. distributed training. def test_whatever(self): env = self.get_env() # now call the external program, passing env to it all these are also documented in testing.rst. fixes: #8058 @sgugger, @lysandrejik, @sshleifer ", "commit_messages": " move the helper code into testing_utils  port test_trainer_distributed to work with pytest  improve docs ", "linked_issue_titles": " [testing] port test_trainer_distributed to run with pytest ", "title": "port test_trainer_distributed to distributed pytest + testcaseplus enhancements"}
{"description": " i hereby agree to the terms of the cla available at:  references to gcc 9 replaced to gcc 10 in build instructions (all languages). detailed description / documentation draft: as gcc 9 is not supported, build instructions now correctly require to install gcc 10. ", "commit_messages": " development instructions updated to gcc 10 from gcc 9  reverted tiny mistake added in previous commit. more reference to gcc 9 replaced ", "linked_issue_titles": "", "title": "hrissan/dev instructions gcc 9 to gcc 10"}
{"description": " also fixes a race condition that's common with slow connection @miloskozak i think this will cover most of the issues you had with defined mode ", "commit_messages": " support for using stored apisecret in denied mode and add auth headers to report requests  use status.json instead of status.js and wait for it to load ", "linked_issue_titles": "", "title": "support for using stored apisecret in denied mode to load settings"}
{"description": " fixes #128786 ", "commit_messages": " create helper class for event with reply pattern in terminal  part of #128786  adopt requeststore in pty host  support timeout in requeststore  fixes #128786  docs  move request store to common  add request store test ", "linked_issue_titles": " add a maximum timeout for resolve variable/detach instance requests in pty host ", "title": "add requeststore helper, adopt in ptyhost and add timeout support"}
{"description": " cleanup in the examples/csharp directory: make the helloworld example using dotnet cli the default (helloworld-from-cli -> helloworld) mark the original helloworld using the legacy .csproj project as \"still fully supported but legacy\" (helloworld -> helloworldlegacycsproj) convert routeguide to the new-style .csproj projects (leads to simplification and easier maintenance) update the readmes accordingly. note: after this is merged and the release is cut, i'll need to do a pass on grpc.io site to make sure the docs there capture the new directory names from this pr. ", "commit_messages": " convert route_guide to .netcore project  move helloworld -> helloworldlegacycsproj  make new-style .csproj helloworld the default  rename route_guide -> routeguide  upgrade c# helloworld and routeguide to v1.13.1  update the readme files  upgrade helloworldlegacycsproj to grpc1.13.1 ", "linked_issue_titles": "", "title": "cleanup and update c# examples"}
{"description": " call the luaoc bridge function , when the oc function return type is bool, i get the returntype from const char *returntype = [methodsig methodreturntype]; is \"b\". platform : ios 10.3. ", "commit_messages": " update remote repo  revert \"update remote repo\"  this reverts commit c92200d0ac4203c32048ea902e92535dcb4d0935.  returntype bool ", "linked_issue_titles": "", "title": "luaoc static function return type bool"}
{"description": " this pr simplifies zca whitening by not forming the covariance matrix or the full diagonal matrix. instead it uses the svd of the data itself and broadcasting division, which is mathematically equivalent but faster and more numerically stable. tested numerically by the following import numpy as np import numpy.random as npr import numpy.linalg as linalg def princomps_old(flat_x): sigma = np.dot(flat_x.t, flat_x) / flat_x.shape[0] u, s, _ = linalg.svd(sigma) principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + 1e-5))), u.t) return principal_components def princomps_new(flat_x): n_examples = flat_x.shape[0] u, s, vt = linalg.svd(flat_x / np.sqrt(n_examples)) s_expand = np.hstack((s, np.zeros(vt.shape[0] - n_examples, dtype=flat_x.dtype))) principal_components = (vt.t / np.sqrt(s_expand**2 + 1e-5)).dot(vt) return principal_components x = npr.randn(64, 784) #a batch of mnist data flat_x = x - x.mean(axis=0) print(np.allclose(princomps_old(flat_x), princomps_new(flat_x))) #true ", "commit_messages": " implemented zca_whitening without forming covariance matrix or explicit call to diag for eigenvalues  made principal_components self.principal_components ", "linked_issue_titles": "", "title": "improvements to numerical stability and performance for zca whitening"}
{"description": " add or update assignment expression documentation for: faq - design reference - expressions reference - lexical analysis  automerge-triggered-by: @matrixise ", "commit_messages": " (docs) add := to list of operators  (docs) add operator precedence for := to reference - expressions  (docs) replace faq for \"why can't i use an assignment expression?\"  (docs) remove docs todo ", "linked_issue_titles": "", "title": "additional documentation for assignment expressions"}
{"description": " change #82216 removed now deprecated target x86_64-sun-solaris from ci, thus making it no longer possible to use $ rustup target add x86_64-sun-solaris to install given target (see #85098 for details). since there should be a period of time between the deprecation and removal, this pr brings it back (while keeping the new one as well). please, correct me if i am wrong; my assumption that these docker scripts are being used to build artifacts later used by rustup might be incorrect. closes #85098. ", "commit_messages": " update docker to build the deprecated target alongside the new one  improve comment ", "linked_issue_titles": " `x86_64-sun-solaris` target was removed without warning in rust 1.52 ", "title": "bring back x86_64-sun-solaris target to rustup"}
{"description": " wavm tends to cause significant memory usage even when fixes like #6983 are in place. this pr includes two changes that reduce the memory usage of wavm by a large margin. first: avoid generation of debug information; this was actually done at a per-wasm-opcode resolution so it was very memory intensive and also tended to wedge things in to a global cache that would never be freed. second: free the wavm module after we no longer need it once a moduleinstance is created from it ", "commit_messages": " remove generation of debug info from wavm code generation  generation of debug info consumes a massive amount of memory and quite a bit of it seems to get lodged in the global llvmcontext meaning it becomes a leak in the current design of wavm. removing this as we don't need it  don't hold on to wavm module object any longer than needed  after creating a moduleinstance from a module, we really don't need to hold on to the module any longer. it's a memory sink. refactor the one instance we needed the module and free it after that ", "linked_issue_titles": "", "title": "reduction of wavm memory usage"}
{"description": " fixes #16733 this small pr updates the description of the sub-sample size to take into account the addition of the max_samples parameter in version 0.22. ", "commit_messages": " update description of random forest estimators regarding sub-sample size  use backslashes for max_samples ", "linked_issue_titles": " description of bootstrapping for randomforest estimators ", "title": "doc update docstring of rfs regarding max_samples"}
{"description": " haven't tested this yet. letting jenkins do the work. @caisq fyi. note that we should keep our docker hub images on ubuntu 16.04 because that fixes the bugs users encounter. note for others looking at this change: we're downgrading to ubuntu 14.04 for official releases so that it links against the older version of glibc and allows for wider compatibility. ", "commit_messages": " revert \"update ci docker images to ubuntu 16.04\"  this reverts commit d7dc1304053428849f47981f3e77ad1fe88d59dd.  fix the old dockerfile  delete trusty add-apt-repository  fixes  upgrade protobuf ", "linked_issue_titles": "", "title": "switch back to ubuntu 14.04 for our releases."}
{"description": " entry 1: update contributing.md to reflect current maven version requirement ", "commit_messages": " update contributing.md  the build no longer works with maven 3.5.3.  if you try it, you end up with this:  [info] --- maven-enforcer-plugin:3.0.0-m2:enforce (display-info) @ jenkins-parent ---  [warning] rule 0: org.apache.maven.plugins.enforcer.requiremavenversion failed with message:  3.5.4+ required to use incrementals.  [info] ------------------------------------------------------------------------  [info] reactor summary:  [info]  [info] jenkins main module 2.199-snapshot ................. failure [ 44.098 s]  update contributing.md ", "linked_issue_titles": "", "title": "update documented maven requirement: 3.5.3 -> 3.5.4"}
{"description": " the project filters bar chart doesn't have min heights and the 1pt values look kinda odd because there are so many: it's super annoying to get project filters working in dev, so i just faked some data. i added a bunch of zeroes into the fake data and it looked like this: you can see that all of the zero databits are sandwiched together at the bottom. after this pull, the fake data looks like this: the reason this happens is because previously, min-heights were applied as css and weren't factored into the stacking of the bars. if there were multiple bars with min-heights, they would just stack on top of each other and whatever bar was last would be on top. this doesn't seem like an ideal behavior to me, so rather than try to replicate it, i'm just adding things here and there to make the old stuff look semi dece. ", "commit_messages": " add minheights for project filters chart  search for specific classname and apply 1  use legacy browsers as it has a better color b) ", "linked_issue_titles": "", "title": "min heights for project filters"}
{"description": " as discussed in #3554 the tokens in the tokenizer have to be shifted if adding a new token into aka resizing an embedding layer other than the last one. of course this applies only for an adaptiveembedding with more than one layer. this implementation adds a function to move an added token in the tokenizer to a specific position. this is closely related to the pr #4759 ", "commit_messages": " fixed resize_token_embeddings for transfo_xl model  merge remote-tracking branch 'upstream/master'  fixed resize_token_embeddings for transfo_xl.  added custom methods to transfoxlpretrainedmodel for resizing layers of  the adaptiveembedding.  updated docstring  fixed resizinhg cutoffs; added check for new size of embedding layer.  added test for resize_token_embeddings  fixed code quality  fixed unchanged cutoffs in model.config  fix resize tok transfo xl  added feature to move added tokens in tokenizer.  fixed code quality  merge remote-tracking branch 'upstream/master'  added feature to move added tokens in tokenizer.  fixed code quality ", "linked_issue_titles": "", "title": "added feature to move added tokens in vocabulary for transformer-xl"}
{"description": " breaking change: state off is now state standby. affects user defined scripts, automations, etc. description: similar changes as roku integration #28148 currently, if service media_player.select_source is called when entity is in standby mode, ps4 will be turned on first and then will change source. this pr would allow this feature to be accessible from the ui, as the select source dropdown is not available if using state off.  state standby is also the more accurate state. related issue (if applicable): fixes # pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist ", "commit_messages": " change state off to state standby  update docstring ", "linked_issue_titles": "", "title": "change ps4 state off to state standby"}
{"description": " x] add or edit tests to reflect the change. (run with npm test.) x] follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. none of the above apply; this is a simple syntax error, possibly caused by a change in a dependency, unsure. when i compile with the latest typescript it fails with an error that it can't extend passport.strategy and suggests \"implements\" instead -- this change works and fixes the problem. ", "commit_messages": " created feature branch update_passport_facebook  fix compile error in typescript 3.4; passport.strategy is an interface and must be implemented, not extended ", "linked_issue_titles": "", "title": "fix compile error w/ passport-facebook, latest passport typings, typescript 3.4"}
{"description": " see jenkins-56499. entry 1: issue, there is a synchronized method on api token usage stat, which will cause thread hang on changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) ", "commit_messages": " update apitokenstats.java  remove the synchronized on method updateusageforid if token usage stats diabled  update apitokenpropertyconfiguration.java  change the default value for api token usage stats to false ", "linked_issue_titles": "", "title": "remove synchronized on method updateusageforid for api token usage stat"}
{"description": " the idea is that the ci job checks if the user forgot to run the amalgamation script. update: see also #106 and #509 also, it sets the date to be locale/timezone independent. to make it be reproducible, the date is picked from the git commit instead of the current time. ", "commit_messages": " output date in a locale independent way  add ci for checking amalgamation ", "linked_issue_titles": "", "title": "detect if amalgamation is needed"}
{"description": " what did you implement: re-work for #2861 and #2907 added top level commands to the framework core. serverless plugin serverless plugin - shows list of sub commands serverless plugin install - downloads plugin and automatically adds to serverless.yml. serverless plugin uninstall - removes the plugin from serverless.yml file serverless plugin list - list all available/known plugins from the plugin repo serverless plugin search - search for match out of list. how did you implement it: i have restored the code from #2907 and applied some slightly updates, but the basic spec has not changed how can we verify it: please run the following commands serverless plugin list serverless plugin search --query / -q {query string} serverless plugin install --name / -n {plugin name} serverless plugin uninstall --name / -n {plugin name} todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " initial commit for adding plugin command  add if-check to uninstall  update using chai-as-promised  add tracking method  add document ", "linked_issue_titles": "", "title": "add plugin command to provide for users how find and install / uninstall"}
{"description": " as noted in #61890 (comment) and #62295 (comment), the 1.10 changes to the openstack cloud provider node name computation (in #58502, #61000, and #61890) broke existing deployments that provisioned instances with credentials matching their instance names. it also did not account for version skewed kubelets, which can run 1.8 and 1.9 versions against a 1.10 master, and still register based on instance name. this pr reverts the incompatible changes to restore pre-1.10 behavior. further improvements to handle instances with names that cannot be used as node names are tracked in #62295 /assign @dims /sig openstack restores the pre-1.10 behavior of the openstack cloud provider which uses the instance name as the kubernetes node name. this requires instances be named with rfc-1123 compatible names. ", "commit_messages": " revert \"specify dhcp domain for hostname\"  this reverts commit da5ccf7fb72666de47113442eaca7d2efd5fb507.  revert \"split out the hostname when default dhcp_domain is used in nova.conf\"  this reverts commit 9a8c6db448f200ddd9a06813affab804b183de20.  revert \"openstack: register metadata.hostname as node name\"  this reverts commit eaac0f5489de823f9e5805c53855560ae1a64156. ", "linked_issue_titles": "", "title": "restore pre-1.10 openstack instance naming behavior"}
{"description": " there are 2 proposed fixups in discussions in #23280 which i have not implemented: an overhaul to return types and an option type for the two *chainstate functions: #23280 (comment) the change reintroduces stringy return types and is quite involved. it could be discussed in a separate pr. passing in the unix time to verifychainstate instead of a callback to get the time: #23280 (comment) i'm not sure it matters much whether it's a callback or just the actual unix time. also, i think verifydb can take quite a while, and i don't want to impose that the function have to \"run quickly\" in order to have it be correct. if reviewers feel strongly about either of the two fixups listed above, please feel free to open a pr based on mine and i'll close this one! ", "commit_messages": " node/chainstate: use max_future_block_time  docs: make loadchainstate comment more accurate  style-only: rename *chainstate return values  init: use clang-tidy named args syntax ", "linked_issue_titles": "", "title": "post-\"chainstate loading sequence coalescence\" fixups"}
{"description": " this is the work to fix #4677. currently, it caches middleware instances per player in an object whose keys are player ids and the value is an array of arrays. the inner array associates middleware factories and the middleware instances. tests need to be added and updated as well. change has been verified in an actual browser (chome, firefox, ie) ", "commit_messages": " cache mw instances per type, player, and factory in that order  associate mw factories with instances per player id  clear mw cache on player dispose ", "linked_issue_titles": " middleware gets recreated on source change, duplicating event handlers bound within ", "title": "cache middleware instances per player"}
{"description": " what did you implement: closes #5398 how did you implement it: in #5594, cleanvariable does not clean whitespaces if variable is double-quote string literal. atter this pr, it also does not clean whitespace if variable is single-quote string literal. how can we verify it: npm install -g exoego/serverless#single-quote-fallback sls deploy below and confirm it completes successfully. service: aws-nodejs provider: name: aws runtime: nodejs8.10 functions: hello: handler: handler.hello events: - schedule: ${env:schedule, 'rate(2 hours)'} - schedule: ${env:schedule, \"rate(3 hours)\"} todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " add tests for #5398  do not remove spaces in single-quote literal. ", "linked_issue_titles": "", "title": "preserve whitespaces in single-quote literal fallback"}
{"description": " there was a regression at some point where the files under static/ were not properly prebuilt into the less cache causing them to be recompiled on the fly during runtime. this would slow down the very first launch of atom on a machine before ~/.atom/compile-cache would be populated. it would also slow down the first launch after an update whenever a stylesheet under static/ had been changed. this saves ~500ms off of the very first atom launch on a machine by not having to compile the following less files on the fly: static/atom.less static/text-editor-shadow.less node_modules/atom-space-pen-views/stylesheets/select-list.less you can see this slow down by deleting ~/.atom/compile-cache/less and then restarting atom with --safe. ", "commit_messages": " don't include fallback imports for static files  precompile atom-space-pen-views stylesheets ", "linked_issue_titles": "", "title": "fix static .less prebuilt cache"}
{"description": " added documentation in readme, man page, man page markdown, and main-conf.c in usage and print_nmap_help functions. ", "commit_messages": " update readme.md  added grepable format information.  added more command line options  added json, list, grepable, and interactive.  generated new man page using ronn  based on updated markdown file.  additional output options  add additional help documentation  added serval flags to usage and nmap_help functions:  output flags for xml,binary,json,list,grepable  added --output-format and --output-file  added --banners  added --connection-time ", "linked_issue_titles": "", "title": "added documentation for recently added flags"}
{"description": " removing some left over files in react-native-win32 from a documentation solution that isn't being used in the new code location. microsoft reviewers: open in codeflow ", "commit_messages": " remove remanents of old doc format  change files ", "linked_issue_titles": "", "title": "remove remnants of old doc format"}
{"description": " this patch set adds and fixes a variety of things, such as: adds the cluster-level authentication api adds bucket index management api adds the full-text search api adds missing events from bucket class adds specific event definitions for query response classes adds much more test code from the documentation fixes a lot of function definitions this patch set does not bring these definitions fully in-line with 2.4.5, but it gets them much closer. many definitions are written directly from the sdk's source code, because the sdk docs don't cover a lot of uses. java docs have been used in many places where the node sdk docs were missing. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).     increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " couchbase: fix bucket key parameter types  documentation says key type is string or buffer, not any.    couchbase: add connect/error events to bucket interface  couchbase: add optional properties for errors  \"code\" was not optional, but it is definitely not included on all errors.  i've added two more properties that i've seen in the couchbase source code.  couchbase: add enough features to get the front-page sample working  the first page of the couchbase documentation contains the code that is now  in couchbase-tests.ts (except that i've left out the underdocumented  cluster.authenticate() call). for this, i've added the index management  methods on the bucket manager interface as well as specific definitions  for the events on the query response interfaces.  couchbase: add authenticator api  it's marked \"uncommitted,\" but it's in the main page sample, so...  couchbase: add the basic full-text search api  needs some fixes to the bucket query call, but that will be fixed here in a  bit.  couchbase: split query api, add searchquery + ftsqueryresponse.meta props  several important fixes.  couchbase: add fts facet and sorting capabilities  couchbase: add more samples, make query callbacks optional  the samples force us to recognize that the query callbacks are optional.  couchbase: add version number and add me  even though this doesn't cover everything in the latest sdk, that's the  version i based my changes on. ", "linked_issue_titles": "", "title": "lots of missing things from v2.4.5 sdk"}
{"description": " these are some minor edits i made when experimenting with the superkoalio file. they do not change any functionality, but i figured i might as well propose them for the master. ", "commit_messages": " spelling fixes in comments  use mathutils clamp over manual implementation  remove unused but instantiated vector2 ", "linked_issue_titles": "", "title": "spelling fixes and cleanup in superkoalio test"}
{"description": " improved reporting of where the missed slot is when it reports incomplete rounds. added tracking of timestamps on blocks to identify when a slot is missed. this is the release/2.0.x version of #9000 ", "commit_messages": " improved reporting of where the missed slot is when it reports incomplete rounds.  added the timeslot time to the failure information. ", "linked_issue_titles": "", "title": "improved reporting in nodeos_forked_chain_lr_test - 2.0.x"}
{"description": " continuation of the work for the fs polyfill in support of #3403. specifically this adds internal implementations of the directory classes used in node and exported by yet to be implemented deno fs polyfill methods fs.opendir(), fs.opendirsync(), or fspromises.opendir(). ", "commit_messages": " feat: additional node fs polyfill support for directories ", "linked_issue_titles": "", "title": "continuation of node fs polyfill with directory support"}
{"description": " even if the good opengl version is available, framebuffer support is done as an extension, not in the native opengl. this fix should bind dynamically all the framebuffers methods from the correct arb/ext.  ref: tito@kivy, kivy/kivy@c76fed7 fixing include paths to be able to compile cocos2d-x using external visual studio solution. this way we can have completely separate vs solution containing our project + referencing original cocos2d-x projects, without need to copy all the files. ", "commit_messages": " opengl access violation fix  revert \"opengl access violation fix\"  this reverts commit 7eb0e3397d1468e042b75ab4e0d6a2b83206d343.  opengl access violation fix ", "linked_issue_titles": "", "title": "opengp framebuffer access violation fix + fixing include paths"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). there's not a lot of documentation on this feature on the website but it works for me in a production site. increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " missing comment  merged upstream  missing comment  merge master  merged  add iteratee property shorthand for uniq in underscore  undo bad commit  can also pass array of array of data to chartist ", "linked_issue_titles": "", "title": "chartist - add another possible series type to ichartistdata"}
{"description": " closes #1136 hopefully everything is okay here, this is my first pr so let me know if not! ", "commit_messages": " fixed typos in errors.js  revert \"fixed typos in errors.js\"  this reverts commit 99085af24c0440f9c0d723cfcc560d2cf2e90b85.  fixed typos in errors.js ", "linked_issue_titles": " typo in cli error for deps about docker ", "title": "fix typos in cli errors.js"}
{"description": " sub pr #7229 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " add constants.java  optimize the constants to the utils package for the client module ", "linked_issue_titles": "", "title": "optimize the constants to the utils package for the client module. part 5"}
{"description": " fixes #6579 fixed also aws partition references in few other spotted places. confirmed there's no issues in changes by running all integration tests against pr ", "commit_messages": " fix: support differet aws partitions  fix: ensure necessary iam role for handling existing cognito pools  fixes #6579 ", "linked_issue_titles": "", "title": "ensure needed access roles when handling existing cognito pools"}
{"description": " this pr converts many but not all of the uses in the codebase. as a result building rust issues a lot of warnings. i didn't have time to fix all those...i'll try to fix more but i thought it made sense to post the pr anyway. ", "commit_messages": " declare &foo[] to be obsolete syntax. modify the obsolete mechanism to  support warnings.  replace all uses of &foo[] with &foo[..] en masse. ", "linked_issue_titles": "", "title": "make &foo[] syntax issue a warning (but still work)"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " rewrite with es6 modules, update definitions  remove unused dom compile option  remove any from test  add space after header ", "linked_issue_titles": "", "title": "rewrite with es6 modules, update definitions, add missing properties"}
{"description": " basically, a config constant was not type declared in a way that makes the next typescript compiler happy. this pr aims to fix that by separating the type and the value. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: mholt/papaparse#494 ", "commit_messages": " update  update upstream changes  update upstream changes  separate type and value for node_stream_input  add test for node_stream_input  format ", "linked_issue_titles": "", "title": "fix node_stream_input for typescript/next test"}
{"description": " i wanted to start using vscode. it wasn't easy. i wrote some tasks that allow us to build the various flavors of openconsole and windows terminal from one of the tasks. i also wrote a task that allows registration of the loose windows terminal package and a shortcut one to launch it. also it was grinding away at its own intellisense forever because it was indexing obj, bin, packages, etc. i excluded those. things should be easier now for folks in general. i expect we'll make more task types in the future. ", "commit_messages": " initial revision of getting f5 to work in vscode.  clean/build/deploy things are working. use attach for debug because appxs are launched in an interesting way. check in the settings so the intellisense doesn't get overeager at reading millions of bin/obj/packages/etc files.  make building a bit more complex with selections, revert openconsole script change to use inbox powershell not pwsh. ", "linked_issue_titles": "", "title": "create settings/tasks definitions for vscode builds and registration"}
{"description": " right now, rnn.compute_output_shape returns the same output shape for all the cell states when return_state=true. however, in a stacked rnn, the states could come from different cells with different number of units. since _keras_shape is set with the output of compute_output_shape (in _add_inbound_node), _keras_shape (and also k.int_shape) will be wrong for these cell state tensors. for example, the following simple seq2seq model will fail before this fix: encoder_in = input((none, 5)) encoder_out, *state = rnn([lstmcell(16), lstmcell(32)], return_state=true)(encoder_in) decoder_in = input((none, 5)) decoder_out = rnn([lstmcell(16), lstmcell(32)])(decoder_in, initial_state=state) because state_spec of the decoder is computed based on incorrect _keras_shapes. valueerror: an initial_state was passed that is not compatible with cell.state_size. received state_spec=[<keras.engine.topology.inputspec object at 0x1225dbeb8>, <keras.engine.topology.inputspec object at 0x1225db7b8>, <keras.engine.topology.inputspec object at 0x1225ea588>, <keras.engine.topology.inputspec object at 0x1225ea4a8>]; however cell.state_size is (32, 32, 16, 16) ", "commit_messages": " fix: compute_output_shape for stacked rnn cells with different number of units  test for compute_output_shape ", "linked_issue_titles": "", "title": "fix stacked rnn compute output shape"}
{"description": " test that strings that contain embedded null characters are passed to udf's consolidate \"test param\" tests to reduce the amount of boilerplate code test more error conditions when building udf arguments, and returning udf values handle pyfloat_asdouble() errors ", "commit_messages": " test that str params with embedded null chars are passed to sqlite functions  refactor most set param tests ", "linked_issue_titles": "", "title": "expand test suite for sqlite udf's"}
{"description": " simplify reference handling and merge two connection object members: remove superfluous pyobject * member isolation_level from connection object (self->begin_statement carries the information we need) introduce get_begin_statement() helper for converting isolation level to begin statement simplify sqlite3.connection.__init__ by using get_begin_statement use ac to remove reference handling for the isolation level parameter ", "commit_messages": " remove connection isolation_level  factor out get_begin_statement()  use get_begin_statment() in connection __init__  clean up ", "linked_issue_titles": "", "title": "simplify isolation_level handling in sqlite3"}
{"description": " this pr offers a fix for pr 16162's problem with causing td3 tests to fail/timeout often. pr 16162 added a sleep to _nextvaluenotready causes td3 tests to become flakey. this pr removes that sleep from the c'tor of _nextvaluenotready, but keeps the sleep in place inside impala's learner_thread such that the original issue should remain fixed. see also this discussions here:  i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " wip.  wip. ", "linked_issue_titles": "", "title": "having added sleep to _nextvaluenotready causes td3 tests to become flakey."}
{"description": " after re-reading the changes i made on the last pr, i felt like it needed more elaboration. hopefully, you'll find this more accurate. ", "commit_messages": " elaborate more on 2.2  elaborate more on 2.2 ", "linked_issue_titles": "", "title": "elaborate on 2.2 (use only built-in error object)"}
{"description": " this pr develops the tests for tf.data kernel implementations in c++. it designs a test base class and adds the tests for rangedataset and mapdataset. ", "commit_messages": " add the test base for tf.data c++ kernels  add the test for rangedataset kernel  add the test for mapdataset kernel ", "linked_issue_titles": "", "title": "add the tests for some tf.data kernels"}
{"description": " dtst saves all trace sessions to binary file. the format of binary file is simple serialized sessions. dtsf restores all trace sessions from binary file. ", "commit_messages": " add memory diff dump function  add base snapshot dump  add resotring function  fixed some bugs  fixed code format ", "linked_issue_titles": "", "title": "add dtst and dtsf commands for save and restore sessions."}
{"description": " adds getstringview as a convenience function to get string_view from a string returning an empty string_view on null pointer. ", "commit_messages": " added missing endtable() call to verifyobject()  verifyobject called verifytablestart() but not endtable(). this made verifier::verifycomplexity() increase depth_ with each table, not with the depth of tables.    merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  added check to verifyalignment    add getstringview (convenience function to get string_view from a string returning an empty string_view on null pointer) like getstring, getcstring ", "linked_issue_titles": "", "title": "add getstringview like getstring, getcstring"}
{"description": " this speeds up the compilation time of main.swift in the benchmark suite from taking a minute or two to about a second. nfc. starts a string perf test suite called stringtests which is off-by-default, but allows us to place some lower-level targeted benchmarking. ", "commit_messages": " [benchmark] speed up compilation time of suite  this speeds up the compilation time of main.swift in the benchmark  suite from taking a minute or two to about a second. nfc.  [benchmark] add string test suite (off by default)  starts a string perf test suite called stringtests which is  off-by-default, but allows us to place some lower-level targeted  benchmarking. ", "linked_issue_titles": "", "title": "speed up compilation time; add string benchmarks"}
{"description": " cherry-pick from master roll crbug:  npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none ", "commit_messages": " disable calculatenativewinocclusion on win ci  update appveyor.yml ", "linked_issue_titles": "", "title": "fix visibility tests on windows"}
{"description": " fix dependencies in benchmarks fix a wrong library search directory order when building swift-frontend with bootstrapping rdar://85911944 ", "commit_messages": " cmake: fix dependencies in benchmarks  with libswift the compiler invocation also depends on the core libraries, because the compiler executable needs them.  rdar://85911944  cmake: fix a wrong library search directory order when building swift-frontend with bootstrapping ", "linked_issue_titles": "", "title": "fix two bootstrapping related problems"}
{"description": " @renne optional compiler directives added to support output function of mcp23008/mcp23017 using sensor29 command. need to add defines to user_config.h //    #define use_mcp230xx_output // enable mcp23008/mcp23017 output support through sensor29 commands (+1k code) //    #define use_mcp230xx_displayoutput // enable mcp23008/mcp23017 to display state of output pins on web ui (+0k2 code) sensor29 commands are extended as follows: sensor29 pin,pinmode,pullup pin = pin number of mcp device (0 to 7 for mcp23008 and 0 to 15 for mcp23017) pinmode = 5 for output (1 through 4 already documented in wiki) pullup = 0 default to low on power-up/reset pullup = 1 default to high on power-up/reset if save_state (setoption0 == 1) is enabled, then pull-up is ignored during reset/power-up and last known state will apply once pin is in pinmode 5 the followng commands turn pin on and off sensor29 pin,on    // turn pin on sensor29 pin,off   // turn pin off sensor29 pin,t     // toggle current state of pin ", "commit_messages": " mcp23008/mcp23017 - extend sensor29 command to enable output  mcp23008/mcp23017 - extend sensor29 command to enable output  add mcp230xx_output and use_mcp230xx_displayoutput to user_config.h ", "linked_issue_titles": "", "title": "mcp23008/mcp23017 - extend sensor29 command to support output"}
{"description": " add eps for roi_perspective_transform op avoid dividing zero. ", "commit_messages": " track_official_repo  track offical update  push before pull  pull before pr  pull before push  pull before push  pull before push  pull before push  pull before push  pull before push  pull before pr.  pull before pr  pull before pr  pull before pr  fix_roi_transform_bug ", "linked_issue_titles": "", "title": "fix roi_perspective_transform op dividing zero bug"}
{"description": " this pr adds logic to check whether a credential file exists and if we are in headless mode, it will skip the \"activation\" phase. added unit tests in the cli_test ", "commit_messages": " do not create credential file in headless mode  linter ", "linked_issue_titles": "", "title": "do not automatically create credential file when in headless mode (#467)"}
{"description": " currently, the runtime isn't reset following a redirect or a send_file, so any time taken to process those actions is added to the time for the subsequent request. ", "commit_messages": " escape regex in controller_runtime_test to actually check that the activerecord message appears  reset activerecord::logsubscriber runtime at the start of each request  previously the runtime was reset implicitly when #cleanup_view_runtime was called at the end of most requests. however, this doesn't happen when the request redirects, or send_file is called.  consequently, the activerecord runtime recorded in the logs included the time taken for both the current request and the previous redirect.  explicitly resetting at the start of each request ensures that this can't happen, no matter what occurs previously. ", "linked_issue_titles": "", "title": "activerecord::logsubscriber.runtime should be reset at the start of each request"}
{"description": " the kubelet always clears reason and message in generateapipodstatus even when the phase is unchanged. it is reasonable that we preserve the previous values when the phase does not change, and clear it when the phase does change. when a pod is evicted, this ensures that the eviction message and reason are propagated even in the face of subsequent updates. it also preserves the message and reason if components beyond the kubelet choose to set that value.  if reason/message are changed (due to preemption -> eviction) the most recent value is preserved. to preserve the value we need to know the old phase, which requires a change to convertstatustoapistatus so that both methods have access to it. fixes #103623 the reason and message fields for pod status are no longer reset unless the phase also changes. ", "commit_messages": " kubelet: preserve reason/message when phase changes  the kubelet always clears reason and message in generateapipodstatus  even when the phase is unchanged. it is reasonable that we preserve  the previous values when the phase does not change, and clear it  when the phase does change.  when a pod is evicted, this ensurse that the eviction message and  reason are propagated even in the face of subsequent updates. it also  preserves the message and reason if components beyond the kubelet  choose to set that value.  to preserve the value we need to know the old phase, which requires  a change to convertstatustoapistatus so that both methods have  access to it.  kubelet: avoid allocating multiple times during status  noticed while reviewing this code path. we can assume the  temporary slice should be about the same size as it was previously.  kubelet: make condition processing in one spot  the list of status conditions should be calculated all together,  this made review more complex. readability only. ", "linked_issue_titles": " [failing test] [sig-node] inodeeviction [slow] [serial] [disruptive][nodefeature:eviction] when we run containers that should cause diskpressure should eventually evict all of the correct pods ", "title": "ensure that reason and message are preserved on pod status"}
{"description": " also contains some cleanup and doc comment additions so i could make sense of the code. fixes #73109 closes #73175 r? @matthewjasper ", "commit_messages": " improve instance docs  validator: print mir instance on failure  remove adjustment::derefmove  it does the same thing as deref now  shim.rs: improve docs a bit  shim.rs: call fnptr, not self  the call terminator only works with fndef and fnptr types.  it happened to work with self so far because it was always  substituted with the real type before being used. ", "linked_issue_titles": " ice: -zvalidate-mir: broken mir in libcore ", "title": "avoid creating call terminators calling self"}
{"description": " also fixed the issue of ( ", "commit_messages": " issue #1712: adding getting dpi support for ios and android.  issue #1712: adding win32 support.  issue #1712: moved ccdevice.cpp to platform/win32.  issue #1712: getting dpi support for blackberry.  issue #1712: updating project setting for blackberry.  issue #1712: adding empty ccdevice.cpp for linux, mac and marmalade.  issue #1712: getting dpi support for linux.  fixed #1712: adding default dpi for marmalade and mac since i don't know how to get dpi for these platforms. ", "linked_issue_titles": "", "title": "adding a class named \"ccdevice\" and getting dpi suport for android, ios, win32, linux, blackberry."}
{"description": " json-iterator indented encoding was not stdlib-compatible for objects with custom marshaljson implementations. this pr switches to use the json stdlib for pretty-printing json encoding as preparation for moving off of json-iterator. hoisted from #105030 for early review/merge apimachinery: pretty-printed json and yaml output is now indented consistently / /sig api-machinery ", "commit_messages": " use stdlib json encoder for yaml and pretty-json marshaling  fix pretty-printed fixtures  compact pretty-printed compatibility fixtures when decoding ", "linked_issue_titles": "", "title": "use json stdlib for pretty-printer encoding"}
{"description": " adds a per-profile setting for setting the audio sound for the bell. the setting is bellsound, it accepts a path. we'll use the file at that path as the sound for the bell. if it doesn't exist, then oh well, so sound for you. it'll also secretly accept an array of paths. if you provide an array, it will pick one at random. closes #8366 i work here tests - lol this is the hackathon, i'm just messing around requires documentation to be updated i'm not suggesting that anyone go to this post and download a zip full of honk.mp3s. i'm definitely not suggesting you add it to your settings like \"bellsound\": [ \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk1.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk2.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk3.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk4.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk-muffled1.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk-muffled2.mp3\", \"c:\\\\users\\\\migrie\\\\downloads\\\\memes\\\\honks\\\\honk-muffled3.mp3\" no, don't do that. honk-001.mp4 it surprisingly works elevated we should probably accept env vars in these paths we may only want one mediaplayer per terminal, rather than one per pane we may want to validate the paths, and discard ones that don't exist. alternatively, meh ", "commit_messages": " it honks  many honks  oh yea, it was that easy  allow a single item as a list with length 1 ", "linked_issue_titles": " specify an audio file for the audible bell ", "title": "enable changing the bell sound"}
{"description": " hi, from the feedback of my beta testers i made these changes to exasol: *) new object type connections is now supported *) added \"visibleif\" checks to verify the user has sufficient privileges to access the meta tables for users, connections and roles objects. *) reformat source using dbeaver formatter kind regards karl ", "commit_messages": " new con object; users only show if sufficient privs  added connection object and added fields to user object ", "linked_issue_titles": "", "title": "new database object connection and privilege checks added"}
{"description": " fixes #6017 microsoft reviewers: open in codeflow ", "commit_messages": " make alert track its xamlroot's size changes  change files ", "linked_issue_titles": " resizing window when alert's contentdialog is open breaks focus trap zone and overlay (xaml islands only) ", "title": "alert should track its xamlroot's size"}
{"description": " implement time_parse(<time_str>, <pattern_str>) function which allows to parse a time string according to the specified pattern into a time object. the patterns allowed are those of java.time.format.datetimeformatter. supersedes: #55095 closes #54963 ", "commit_messages": " issue #37303 - invalid variance fix  testcase added for #37303  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  sql: implementing time_parse function for parsing strings  review comments fixes  localtime to offsettime  added docs for time_parse ", "linked_issue_titles": " sql: implement time_parse ", "title": "implement time_parse function for parsing strings into time values"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. ", "commit_messages": " translate task #1 - #4  add translation of zhang-suen-thinning and markov algorithm ", "linked_issue_titles": "", "title": "translated some chinese curriculum files"}
{"description": " fixes: #1616 this issue is caused when we insert a value into the array, it will try to calculate an offset this way we can maintain focus when we add/remove elements. i've found a  test where checking for olddom effectively fails focus so this is not the way to go. seems like removing the focuselement is having some side-effects :/ a more effective approach would be to see if the node we are comparing to has an old version or not. <-- this is also faulty.... removed my fix since it introduced a faulty scenario in the new focus test i added. we'll need a more reliable way to check for offsets (which is hard with checking on .type) or reintroduce .focuselement. the only thing that could fix it in both scenario's according to me is when we could say hey this element is a new one (inserted). that way we could say olddom for this new element is null. this is because the algo notices we have an offset but doesn't know where so it starts looking for the first type match and sets the olddom to that (which didn't used to work like that) but now it does.... the full erroneous scenario is as follows: we render our ui correctly we add an element on position 1 of the array while diffchildren when we arrive at our last button we notice that there is no corresponding child we loop over the children button1 is now on position 2 (where button 2 was) they are equal on type button button2 is now on position 3 (where button 3 was) they are equal on type button button3 is now on position 4 (empty), this loops over the array to find the first button occurrence which in this case is button1. this will trigger the olddom setting since oldchild.type won't be a button and thus make button3 use the olddom of button1 switching their position wondering if it's better to revisit the focus approach where when inserting it constructed an erroneous parentvdom.childnodes. in the end it all boils down to offsets being hard to manage without keys. ", "commit_messages": " tests: add big test for multiple scenarios  feat: don't compare when there is no olddom present ", "linked_issue_titles": " position of last child changes on state change ", "title": "- don't compare when oldvnode has no dom"}
{"description": " fixes to the visibility of views move container to workspace <name> rewrote workspace{,_output}_{prev,next} and patched that into workspace_by_name so it works with the move command ", "commit_messages": " refactored workspace_next/prev  refactored view visibility  - replace visibilty mask integers with an enum  - set output's visibilty mask on creation  - added update_visibility to manually update a containers visibility (e.g. when it moved to an invisible workspace)  added \"move container to workspace\"  makes the previous commit actually testable  changed workspace_{outout_,}{next,prev} to return workspace  so it can be reused for \"move container to workspace next\" ", "linked_issue_titles": "", "title": "implemented \"move container to workspace\""}
{"description": " a while ago i submitted a pr to make vertical centering of the arrows dynamic to the arrow height, using transform translate. since ie8 doesn't support transforms, i thought i'd include the old fixed position offset using margin top, but use the \\9 hack on the value to make it only apply to ie8. i guess there was an issue with gulp, and a pr to remove the \\9 merged, causing the offset to register with all browsers, and making the arrows slightly off center. the gulp issue is curious to me, because bootstrap uses the \\9 method, but i also appreciate that \\9 is a clumsy trick, and my feeling is that if someone is using ie8 they can suffer a slightly off center arrow, in the interest of modernity and simplicity as such, i removed the fallback in this pr. ", "commit_messages": " removed style for ie8 fallback  removed style for ie8 fallback  removed style for ie8 fallback ", "linked_issue_titles": "", "title": "correct issue with vertically centering arrow"}
{"description": " added docker ee specific fixes/work arounds so that the moby integration tests can be used against it. ", "commit_messages": " match not implemented error check to others  protect environment for system integration tests  do not use deprecated call for apiclient ", "linked_issue_titles": "", "title": "docker ee integration test fixes"}
{"description": " description: starling bank are switching to v2 of their api. this pr updates the home assistant integration to use the new api. non-breaking change. no documentation update required. checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " bump starlingbank to v2 api  fixed incorrect call ", "linked_issue_titles": "", "title": "update starling bank integration to v2 api"}
{"description": " closes #19705, closes #20084. pushes scipy minimum version to 1.1.0. pushes numpy minimum version to 1.14.5. pushes matplotlib minimum version to 2.2.2 for compatibility with python3.7 drop 3.6 builds. configure azure builds to run on ubuntu focal 20.04 lts. adds one bionic 18.04 lts azure build with scipy from conda-forge and python 3.7 move the linux 32bit build from ubuntu to debian 10 as debian still support 32bit and is distributed with python 3.7. before i start fixing the version conflicts, please, let me know if the defined set of builds fits your requirements. thanks. maybe ping ... @ogrisel , @thomasjpfan , @rth ? ", "commit_messages": " push scipy min version to 1.0.0  update all ubuntu images to 20.04 focal.  add ubuntu images 18.04 bionic and scipy fron conda-forge.  fix conditions.  pin python 3.6 for ubuntu bionic.  change pipeline name. ", "linked_issue_titles": " [rfc] minimal scipy version for 1.0 (or 0.26) release  drop python 3.6 support for 1.0 ", "title": "ci push scipy minimum version to 1.1.0. remove python 3.6 from builds."}
{"description": " for 1/2 the plugins in x-pack, the integtest task is now a no-op and all of the tests are now executed via a test, yamlresttest, javaresttest, or internalclustertest. this includes the following projects: security, spatial, stack, transform, vecotrs, voting-only-node, and watcher. a few of the more specialized qa projects within these plugins have not been changed with this pr due to additional complexity which should be addressed separately. related: #60630 related: #56841 related: #59939 related: #55896 ", "commit_messages": " most of security  security internalcluster  finish up security  security:qa  spatial  stack  transform  vectors  voting-only-node  watcher - internalclustertest  watcher qa ", "linked_issue_titles": "", "title": "convert second 1/2 x-pack plugins from integtest to [yaml | java]resttest or internalclustertest"}
{"description": " ultimately, this is caused by the sway_abort that does not exit in this case. it calls wlc_terminate, which itself does not exit if there is not current display. added some very minor fix here and there while browsing through the code ; they each have their separate commit. ", "commit_messages": " removed p as a valid cli option  the get-socketpath long option had an undocumented short alternative  as p. it has been removed.  however, the code in the options array is still the 'p' char.  no options when using sway as ipc client  sway used to attempt sending an ipc command composed of every argument  after the first non-option argument encountered.  now, raises an error if an option is encountered before the intended command.  some options such as -h or -v take effect when parsing, so they still  apply.  fixed swaymsg command name in sway(5) doc ", "linked_issue_titles": "", "title": "fix segfault when trying to use sway as ipc without a sway instance"}
{"description": " added a sentence for clarity on sorted union bonfire. (the previous commit is simply me updating my local copy to match the master here.) ", "commit_messages": " updated description for sorted union bonfire for clarity.  updating local branch. ", "linked_issue_titles": "", "title": "update description on union sort bonfire challenge for clarity"}
{"description": " fix #24208 offset option can be function (popper.js) add support for calculate and dynamically change offset position for dropdown menu. function call always when call popper.js modifierfn. with this code i can change any dropdown position as on picture const dropdownmegatoggle = $('.dropdown-toggle--mega'); dropdownmegatoggle.dropdown({ offset: function(data) { let popper = data.popper; let reference = data.reference; let w = $(window).width(); let buttonoffset = dropdownmegatoggle.offset(); popper.top = 100; reference.width = w / 2; // f*cking popper.js crutch popper.left = w / 2 - popper.width / 2 - buttonoffset.left; return data } }); fix : #24223 ", "commit_messages": " offset option can be function (popper.js)  fix...add function type for offset option ", "linked_issue_titles": "", "title": "offset option for dropdown can be function"}
{"description": " arguments for tasks that are ready to dispatch can get evicted before the task gets dispatched to a worker. this pr moves these tasks back to the waiting queue. it also adds an index for the dispatch tasks to speed up lookup when there are many tasks queued. this pr modifies the clustertaskmanager class to call directly into the taskdependencymanager to wait for/cancel task dependencies. this is so that the clustertaskmanager can cancel the task dependencies once the task is dispatched (or removed), instead of canceling the first time that the arguments become ready. fixes some new flakiness in test_array. i noticed that the test still fails with a mysterious objectlosterror, but this other error also seemed to show up when the new scheduler is disabled. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " add index for tasks to dispatch  task dependency manager interface  unsubscribe dependencies and tests  nodemanager ", "linked_issue_titles": "", "title": "move tasks from ready to dispatch to waiting on argument eviction"}
{"description": " description: this pr adds support for recording history to an apache kafka topic. related issue (if applicable): home-assistant/home-assistant.io#9836 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): apache_kafka: ip_address: localhost port: 9092 topic: home_assistant_1 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. ", "commit_messages": " add support for apache kafka  simplified  revert \"simplified\"  this reverts commit fde4624e07a44edcaa728666777e7cfd789d68f6.  revert \"revert \"simplified\"\"  this reverts commit 5ae57e64c29f9e1cdbba6545420f4c2003d664e2.  completed  updated requirements  updated .coveragerc ", "linked_issue_titles": "", "title": "add support for recording history to apache kafka"}
{"description": " this pr changes the type key and type shortcut behavior to hold enter to accept instead of hold and release, so that it is consistent with the esc behavior. it was also observed that in tab ordering for remap keyboard and remap shortcuts windows the cancel key would get highlighted before ok which is not in the left to right order, so that has been swapped. pr checklist applies to #2661 (closes #2661) cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments the onaccept lambda was split into two parts, onpress and onrelease in onpress we perform all the accept logic followed by detectkeybox.hide() but we do not perform the resetuistate and unregisterkeys() the resetting of ui state along with disabling the key delay handler is done in onrelease. because of this, we stop swallowing input only when enter key is released, and this allows us to avoid the issue where pressing enter triggers the type key button again. onpress is performed in case of the long press delay handler (along with the primary button color change even though that would appear for just a few milliseconds but the user can notice it) onrelease is performed in case of the key release delay handler so that when user lets go of enter key everything in the kbm state is cleared up we define onaccept as onpress followed by onrelease so that primary button click behavior remains unchanged validation steps performed used ok and cancel options from the type key/shortcut screen by clicking with mouse and also using hold enter and hold esc. ", "commit_messages": " changed to hold enter  changed code such that hold enter does not trigger a re-open  fixed tab ordering ", "linked_issue_titles": " [kbm] hold enter and hold esc to dismiss should be consistent with each other ", "title": "kbm - change behavior to hold enter to accept rather than hold and release"}
{"description": " hashes the deployment names in the cluster snapshot.  this is necessary because the cluster snapshot automatically converts all keys to camelcase, which can lead to collisions for consumers of a snapshot if two deployments have different names which map to the same name when converted to camel case (e.g. my_deployment, my_deployment and mydeployment). previously, for an unversioned deployment, the internal version hash was being exposed in the actor metadata.  this pr changes it to say \"unversioned\" in this case. closes #17870. closes #17872 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " show \"unversioned\" in actor metadata  hash deployment names  update test ", "linked_issue_titles": " [serve] deployment names converted to camel case in cluster snapshot  [serve] [dashboard] snapshot exposes internal hash of unversioned actor's version number ", "title": "fix formatting bugs in cluster snapshot"}
{"description": " the module only checks for existance of the database when dropping. added a check also when creating a database. more importantly, added the ability to change the owner if the database exists but is not the same as the owner specified. ", "commit_messages": " check for database ownership  bugfix in sql query ", "linked_issue_titles": "", "title": "allow change of ownership and checks for existing database"}
{"description": " add a possibility to add a start search index in array.find(). also adds a rfind function to search backwards in the array (this mimics the string.rfind() function). closes #5020. ", "commit_messages": " add 'from' argument to array.find()  add 'rfind' function to array  add documentation for array.find and array.rfind ", "linked_issue_titles": "", "title": "add array.find(what, from) and array.rfind(what, from)"}
{"description": " this should add support for the ssh+git:// and git+ssh:// protocol schemes. the behavior is to pass directly through to the ssh:// protocol scheme. so, as atrocious as this is, this is a protocol that people use. from everything i can tell, they're both functionally identical to ssh:// and are treated as such in this pr. here is an example of it being used in the linux kernel git core ", "commit_messages": " updating http parser to accept a + in the schema  handle git+ssh:// and ssh+git:// protocols support ", "linked_issue_titles": "", "title": "support for ssh+git and git+ssh protocols"}
{"description": " this pr makes backends take in a starlette request instead of a flask request.  for the servehandle api, serverequest has been modified to match starlette request instead of flask request.  all docs and code samples have been updated. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " support starlette request in web request  add long string to test  lint  lint  clean up prints  lint ", "linked_issue_titles": " [serve] support starlette request type ", "title": "migrate from flask.request to starlette request"}
{"description": " add a o(n^2) and a o(n*log(n)) solution for the problem. ", "commit_messages": " add longest increasing subsequence solution in c++  add more efficient solution to longest increasing subsequence problem in c++ ", "linked_issue_titles": "", "title": "add longest increasing subsequence in c++"}
{"description": " @rocketchat/core the latest release 0.63 made a change that made all contextual bars to be scrolling with the button instead of the button being a sticky. this was suppose to be a fix to user info tab. reverted the style changes in contextual-bar.css file and fixed user info tab with a wrapper. ", "commit_messages": " revert contextual bar style  fix user info with a wrapper ", "linked_issue_titles": "", "title": "button on user info contextual bar scrolling with the content"}
{"description": " allowing for the lack of a function row, and the addition of some keys in the center, this layout approximates the default qwerty keyboard layout of kinesis's line of advantage keyboards. the main difference between this and the default is the remapping of most of the thumb keys. ", "commit_messages": " added keymap variant to approximate kin adv  moving around modifiers to match ka better ", "linked_issue_titles": "", "title": "keymap to approximate kinesis advantage line of keyboards"}
{"description": " drupal's json:api module supports includes, a method for including relationships data. this pr adds very simple and basic support for creating gatsby data out of the data in the included property of the json:api result. this way only data that is used is included in gatsby, without having to fetch all data for a certain resource type. see #21379 for the full motivation. updated documentation in the readme.md of the gatsby-source-drupal plugin. addresses #21379 ", "commit_messages": " add support for drupal json:api includes.  update readme with info about includes support. ", "linked_issue_titles": "", "title": "add drupal json:api includes support"}
{"description": " add inlinecollapsed={true|false} prop for menu, handle icon size, text display and submenu inside menu, and auto tooltip for menu item. use context to pass collapsed prop from layout.sider to menu. don't need customized css code anymore. close #6484 ", "commit_messages": " add menu[inlinecollapsed] prop  inline menu should not trigger handleclick  add tooltip for collapsed menu item  add documentation for inlinecollapsed  menu will get collapsed status from layout.sider ", "linked_issue_titles": "", "title": "better collapsed sider and menu"}
{"description": " bael-1265: using lambdas instead of anonymous classes ", "commit_messages": " code for test article: different types of bean injection in spring  adding junits for test article: different types of bean injection in spring  bael-1265: adding junit for article  bael-1265: closing executorservice in junit  merge remote-tracking branch 'upstream/master'  bael-1265: using lambdas instead of anonymous classes ", "linked_issue_titles": "", "title": "radutamas/bael 1265 update junit with lambdas"}
{"description": " fixes #1491 this pr and #1456 both provide datasets for sentiment analysis. but seems both good. ", "commit_messages": " add early draft of imdb.py and unit test  add imdb_test.py  add imdb and unit test ", "linked_issue_titles": "", "title": "add imdb dataset without need of nltk"}
{"description": " this pr is an alternative to #23903. it bumps the existing copyright headers as we did every year, and adds the missed copyright headers. a small fix has been applied to the copyright_header.py in order to prevent such weird bumping as 2021 --> 2021-2017. ", "commit_messages": " script: fix copyright_header.py  this change prevents updating copyright years from \"2021\" to  \"2021-2017\".  scripted-diff: bump copyright headers  -begin verify script-  ./contrib/devtools/copyright_header.py update ./  -end verify script-  commits of previous years:  * 2020: fa0074e2d82928016a43ca408717154a1c70a4db  * 2019: aaaaad6ac95b402fe18d019d67897ced6b316ee0  scripted-diff: insert missed copyright headers  -begin verify script-  ./contrib/devtools/copyright_header.py insert contrib/guix/libexec/build.sh  ./contrib/devtools/copyright_header.py insert contrib/guix/libexec/codesign.sh  ./contrib/devtools/copyright_header.py insert contrib/tracing/log_raw_p2p_msgs.py  ./contrib/devtools/copyright_header.py insert contrib/tracing/log_utxocache_flush.py  ./contrib/devtools/copyright_header.py insert contrib/tracing/p2p_monitor.py  ./contrib/devtools/copyright_header.py insert test/lint/lint-files.sh  -end verify script- ", "linked_issue_titles": "", "title": "insert and bump copyright headers"}
{"description": " closes #34966 tests added / passed (all tests passed except those which were auto-cancelled for taking too long) ensure all linting tests pass, see here for how to run them whatsnew entry allows default resolvers to be used with input resolvers in pandas.dataframe.eval. previously cases such as this would break: import pandas as pd df = pd.dataframe({'a':[0,1,2], 'b':[7,8,9]}) d = {'c': 5} df.eval('a+b*c', resolvers=[d]) with pandas.core.computation.ops.undefinedvariableerror: name 'a' is not defined as explained in #34966. following this update, the above works as expected. added a test similar to the above: tests.frame.test_query_eval.testdataframeeval.test_eval_resolvers_combined ", "commit_messages": " bug: default+input resolvers in df.eval, gh34966  allow default resolvers to be used with input resolvers in dataframe.eval. resolves gh34966  add whatsnew entry ", "linked_issue_titles": " doc: confusing 'resolvers' kwarg documentation for dataframe.query() ", "title": "allow use of both default+input resolvers in df.eval, gh34966"}
{"description": " this adds the ability to enable, disable and toggle the state of the combo feature without having to recompile if want to disable the feature. this makes it useful, if you have modes where combos are actually in the way (such as when gaming). thread on reddit my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " add ability to enable/disable combos  update documentation for combo feature ", "linked_issue_titles": "", "title": "allow combo feature to be enabled/disabled live"}
{"description": " updated this comparison doc to account for asp.net core 3.0 preview 4.    the compare doc uses an include called benefits.md which was also updated.  minor updates overall. current published version of this doc: ", "commit_messages": " updated to v3 preview 4 for core + framework comparison  update to v3 preview 4 for core + framework compare ", "linked_issue_titles": "", "title": "v3 preview 4 update to core vs 4.x compare"}
{"description": " add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: new component pr include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " added props for upsell  removed patch version ", "linked_issue_titles": "", "title": "update gestalt types to be in sync with 14.28"}
{"description": " please refer to the individual commit messages for additional details. ", "commit_messages": " [messagehandler] convert the deletestreamcontroller helper function to a \"private\" method instead  [messagehandler] add a non-production/testing check to ensure that wrapreason is called with a valid reason  there shouldn't be any situation where reason isn't either an error, or a cloned \"error\" sent via postmessage. ", "linked_issue_titles": "", "title": "some additional (small) clean-up of the code"}
{"description": " two charts (timeseries table and mixed timeseries (via echarts)) do not currently have advanced analytics, but were tagged as though they do. this pr removes the tag for timeseries table in two spots - in the repo (why is this even here?) and in the superset-ui plugin (why is this not the one we're using?). it also removes it from the relevant part of the echarts plugin. brings in the 0.17.83 release for this change. before: after: go to the viz gallery, select the advanced analytics tag, and make sure these two don't show up. includes db migration (follow approval process in sip-59) ", "commit_messages": " removing aa tag from timetablechartplugin  package bump for echarts (removes aa tag there)  package-lock bump for new echarts plugin ", "linked_issue_titles": "", "title": "remove advanced analytics tag for 2 charts"}
{"description": " follow-up on #37577 (comment) restricted indices (currently only .security-6 and .security) are special internal indices that require setting the allow_restricted_indices flag on every index permission that covers them. if this flag is false (default) the permission will not cover these and actions against them will not be authorized. however, the monitoring apis were the only exception to this rule. this exception is herein forfeited and index monitoring privileges have to be granted explicitly, using the allow_restricted_indices flag on the permission, as is the case for any other index privilege. ", "commit_messages": " w00p w00p  test monitoring on restricted indices for monitoring collector  breaking change note ", "linked_issue_titles": "", "title": "remove implicit index monitor privilege"}
{"description": " currently numbers in <label> et. al. are interpreted as localized string lookups.  this means if the skinner actually wants a number in a label they have to do complicated stuff. this is a workaround until we remove the number interpretation and force use of $localize[] post-gotham.  with refactored code it's a 2-liner, so not exactly a maintenance burden. ", "commit_messages": " [info] factor out parsing of [] so it can be used to parse other strings  [info] [] parsing can use the new replacestring() function  [info] adds [] to info labels, allowing skinners to specify a number. required as by default numbers are taken as a reference into localized strings.  in future, this will be dropped in favour of [] only being used as this will benefit translation ", "linked_issue_titles": "", "title": "allow use of $number[] to specify a number in xml tags"}
{"description": " description: now that we take tags as a vector of statname pairs, change the other args to also pass via statname. this will reduce redundant converstions between string and statname and also reduce acquisition of the symbol table lock. risk level: low testing: //test/... docs changes: n/a release notes: n/a ", "commit_messages": " initial commit  format and fix empty metricimpl constructor.  encapsulate encoding of default-constructed statname.  rename member var for consistency ", "linked_issue_titles": "", "title": "cleanup apis and avoid extra conversions between statname and string."}
{"description": " fixes: #8673 when the inferred path already exists, throw generic error to provide better error message. ", "commit_messages": " throw an error if the inferred output path already exists.  simplify file exists check ", "linked_issue_titles": " deno 1.6 compile getting error: is a directory (os error 21) ", "title": "throw error when the inferred output path already exists during compile"}
{"description": " simpler and more straight forward code for computing the arg_list string. improve appearance of __new__ in help(). ", "commit_messages": " cleaner way to build the arg list with a trailing comma when required  fix appearance of __new__ in help() ", "linked_issue_titles": "", "title": "minor improvement to the namedtuple implementation"}
{"description": " we have had a plyicon native viewmanager for awhile but no ts wrapper for using it. we've run into cases where multiple repos are registering the native component but only 1 can do it.  having the wrapper lets us centralize that. while adding an example showing how to use this with the emoji font i found that emsize is kind of needed there but wasn't in how we use it internally, so i added that as something optional that can be set, and refactored iconviewmanager to use a shadownode. in the future we can rename iconviewmanager to glyphviewmanager and move around folders and names but until we have a strategy for non-lean core stuff i'm leaving it where it is. microsoft reviewers: open in codeflow ", "commit_messages": " conver iconviewmanager to use shadownode, add emsize prop  add glyph helper component ", "linked_issue_titles": "", "title": "add <glyph> component and example"}
{"description": " original pull-request #32584 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix  rabbitmq fix ", "linked_issue_titles": "", "title": "cherry pick #32584 to 21.12: rabbitmq fix"}
{"description": " make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, \"[airflow-xxx] my airflow pr\"  here are some details about my pr, including screenshots of any ui changes: support (exclusively) official slack library v2. retain existing functionality and interface slightly change structure (eg remove some properties) remove a redundant check that was made in both hook and operator this pr addresses issue #8433 tests.operators.test_slack_operator tests.hooks.test_slack_hook.slackhooktestcase commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from \"how to write a good git commit message\": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (\"add\", not \"adding\") body wraps at 72 characters body explains \"what\" and \"why\", not \"how\" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 ", "commit_messages": " add support for slackclient v2  code style  update tests  update tests ", "linked_issue_titles": "", "title": "update slack operator to support slackclient v2"}
{"description": " this pr adds support for the organization feature at auth0 so that people using typescript can use it in a type-safe way. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " add types for auth0 organizations  add tests  fix typescript issues  rename types to explicitly mention organizations  update formatting  bump version ", "linked_issue_titles": "", "title": "add support for organizations in auth0"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " added ecore types.  little fix.  little marks.  fixed default export.  import/export marks.  fixed default export.  marks.  test.  test.  -deleted wrong def econtent in eobject  -marks in epackage and epackageregistry  interface resource, parse, second parameter 'loader' has to be optional. ", "linked_issue_titles": "", "title": "marks for interface resource, parse method."}
{"description": " this pr adds support to the stable/mongodb chart to be deployed as a replica set configuring primary, secondary and arbiter nodes. other changes: when deploying in replica-set mode, it uses stateful-sets with headless-svc and volumeclaimtemplates for persistence. when using replica-set mode, pod-disruption-budgets are configurable too it allows to overwrite the default config file with a config map replica set parameters are configurable through values.yaml two values.yaml availables, values.yaml and values-production.yaml please do not merge until i say the contrary as i need to make publish the new version of the docker image. ", "commit_messages": " refactor mongodb chart to support replica set  update pullpolicy ", "linked_issue_titles": "", "title": "refactor mongodb chart to support replica set configurations"}
{"description": " updated stop-only to the version that only finds describe.only, context.only and it.only and does not find \".only\" in comments add npm run warn-only precommit and npm run stop-only prepush ", "commit_messages": " chore: upgrade stop-only and catch them  run stop-only first on precommit  just warn on precommit .only  testing  testing done  run stop-only on git prepush hook ", "linked_issue_titles": "", "title": "update stop only and catch em"}
{"description": " since many widget classes use sprite & scale9sprite at the same time, when the user change scale9enabled properties, we removed the previous added sprites and re-added them again. now the ui::scale9sprite supports setscale9enabled method, so i changed the old implementation. in this pr, i also had fixed some minor bugs of ui::scale9sprite and added the tests ", "commit_messages": " refactor getscale9enabled to isscale9enabled  refactor uibutton  refactor imageview  refactor slider control  refactor loadingbar  refactor layout  fix minor bugs of uislider and remove unused header include in listview ", "linked_issue_titles": "", "title": "refactor ui::widgets to use ui::scale9sprite instead of extension::scale9sprite"}
{"description": " this pull request addresses issue #6170 (and the issues mentioned in there - #800 and #3876). adds support for the following: zeroes in the episode portion of the filter, including episode #0 for specials e.g. 1x00;. open-ended filters now match future seasons e.g. 1x01-; will match all episodes from season 2 and later. this is issue #3876 which had been closed. matches episodes specified like 1x01 in the article title (this is an extension of issue #800). it looks like this also fixes #2749 (although i'm not convinced there was an actual problem there, but the use case works with this pull request). note: this pull request includes a commit (ee0359c) which has been factored out to allow all the pull requests i am submitting to merge without conflicts. ", "commit_messages": " rss parse torrent episodes like 1x01 as well as s01e01. closes #2749.  --hg--  branch : magao-dev  rss allow infinite range to extend beyond current season. closes #800, #3876, #6170.  --hg--  branch : magao-dev  rss episode filter refactoring and logging (prep for later commits).  --hg--  branch : magao-dev  allow episode zero (special) and leading zeroes in rss episode filter.  --hg--  branch : magao-dev ", "linked_issue_titles": " rss episode filter \"single number\" don't work ", "title": "rss episode filter improvements. closes #800, #2749, #3876, #6170."}
{"description": " now rpms created with grunt will respect the --install-dir flag. also, the rpm summary uses the grunt description variable. this is a partial implementation of issues discussed in pr #5339 . resolving icons in the atom.desktop file using the system icon path will be taken care of in another pr. also, automated builds of rpm packages for upload to atom.io should now build against '/usr' instead of '/usr/local'. ", "commit_messages": " fixes rpm install path and icon location  this makes atom a better desktop citizen relocating to where the usual install  directory is (like on the debian package) and also fix the icon using absolute  paths, breaking icon-themes.  depend on $path to find executable in atom.desktop  with the atom atom executable now located in /usr/bin instead  of /usr/local/bin, it should always be available as part of the  system path. thus hardcoding the filepath is not needed. also, this  increase the flexibility of relocating the rpm at installation time  (not just build time) since the user or sys admin need only make  sure that the atom executable is in the system path and the  atom.desktop file will work correctly.  place atom.png icons in standard system locations  this is so that the atom.desktop file will be able to find the  \"atom\" icon when requested. this adds the dependency of imagemagick  to convert atom.png to varying resolutions, although, only during  the rpm build process (not during actual install). so the result  is ultimatly no different for the end user.  also, fixed an absolute path from the rpm build process and made  it relative. it was hardcoded in the spec file to  \"/tmp/atom-build/atom/*\", so builds that were made elsewhere would  have broken when attempting to package into an rpm. now rpm packaging  should work from a build made anywhere. also needed to modify  script/mkrpm so that it copies the build files in such a way that  they can more easily be dealt with in the spec file in a relative  way.  add linux icons  add linux icons  revert \"fixes rpm install path and icon location\"  this reverts commit b92e6f5a2dc111d5f681a1c8db19115b370c63cc.  remove some hardcoded paths from atom.spec.in  also, fix a couple lines in atom.spec.in that either weren't  really doing anything or were inconsistent with the rest of the  script.  mkrpm honors the '--install-dir' option of grunt  also, atom.spec now uses the description provided by grunt instead  of hardcoding its own description.  automated rpm package builds to '/usr'  this is instead of the default of '/usr/local'. targeting '/usr'  is more in line with what most rpm distros expect. ", "linked_issue_titles": "", "title": "make atom.spec.in use grunt variables"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " update uishell components.  fix lint errors. ", "linked_issue_titles": "", "title": "update uishell components for 7.10.x"}
{"description": " relands #74469 and incorporates #77959 from @cyanglaz   + additional changes in 829756e, 28f74e4. the last two commits handle this situation: it doesn't generate generated_main.dart if there isn't need for it. that is, no plugin uses dartpluginclass in the pubspec. generated_main.dart is deleted if there  isn't any platform resolution.  this is the case if you delete a plugin from pubspec.yaml and then hot reload/restart. use the new target in all cases. fixes #52267 ", "commit_messages": " always regenerate dartpluginrestrant  fix typo in name  tests  review  remove extra imports  fix windows tests  remove debugging logs  fix  revert \"reverts \"implement dartpluginclass support for plugins #74469\" (#78623)\"  this reverts commit 5efc7169ebd621f3501d4c7d12ab2e10cbe9eb74. ", "linked_issue_titles": " implement dartpluginclass support for plugins ", "title": "reland the dart plugin registry"}
{"description": " #1308 fix some spelling errors of method names in file named 'utilall.java' these changes seem trivial, but it's an international project and i think the right naming helps other developers understand it. the utilall.computeeclipsetimemilliseconds was modified to utilall.computeelapsedtimemilliseconds (i think this method is to calculate the elapsed time by giving the start time.) 'computnextmorningtimemillis' was modified to 'computenextmorningtimemillis ' 'computnexthourtimemillis' was modified to 'computenexthourtimemillis ' 'computnextminutestimemillis' was modified to 'computenextminutestimemillis ' 'computnexthalfhourtimemillis' was modified to 'computenexthalfhourtimemillis ' nothing. follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. ", "commit_messages": " hotfix: fixed a spelling error for a method name.  hotfix: fixed some spelling error for methods ", "linked_issue_titles": "", "title": "fix some spelling errors of method names."}
{"description": " updated vs props and makefiles of googlemock to reflect the new location of googletest. please refer to issue #772 ", "commit_messages": " changed the gtestdir marco value to reflect the new dir of googletest.  updated the value of gtest_dir to reflect the googletest dir. ", "linked_issue_titles": "", "title": "fixed googletest dir issue for building googlemock."}
{"description": " i added a new link to a git course that my team worked on. it's a free course, based on github. i also changed the order of links on the git section to meet the alphabetical order. ", "commit_messages": " adding new git course and putting in alphabetical order  mentioning author ", "linked_issue_titles": "", "title": "added new git course link"}
{"description": " d05e816 : the current block in graphviz output is highlighted even when graph.gv.current is false. added a logical check to fix it. f5e3f60 : else if blocks are off by one indentation level ", "commit_messages": " fix filling current block when graph.gv.current=false  fix incorrect indentation ", "linked_issue_titles": "", "title": "fixes to graphviz related code"}
{"description": " this pull request fixes the following: fixes the wp8 shader compiler by adding missing files to project fixes the allocatortest by deleting the objects created in the first test pass before starting the second test pass. fixed mutex_init for winrt and wp8 added base/allocator to wp8 and universal app projects updated libcoco2d dll name from 3.3 to 3.4 removed unused files. ", "commit_messages": " removed 3dexport.h as it no longer exists  removed unused winrt ccplatformdefine.h  added missing files  added base/allocator files  used createmutexex for winrt and wp8  delete first pass of allocations before starting second pass  updated dll name from 3.3 to 3.4  added base/allocator files ", "linked_issue_titles": "", "title": "wp8 and windows 8.1 universal app fixes"}
{"description": " adds an integration test that demonstrates that the previous hosts retry host predicate works. risk level: low testing: n/a docs changes: n/a release notes: n/a platform specific features: n/a ", "commit_messages": " host pred: add integration test for previous host predicate  adds an integration test that demonstrates that the previous host retry  predicate can be used to avoid retrying the same host.  format  spelling ", "linked_issue_titles": "", "title": "add integration test for previous hosts"}
{"description": " control: add adctrajectory speed_fallback when full_stop. control: reset integral when gear_neutral or full_stop. control:reset the station pid after switching from reverse to forward. localization: compensate the translation between imu and center. ", "commit_messages": " control:reset the station pid after switching from reverse to forward  fix [idg-apollo-4330].  the station pid parameter is reset in reverse gear, but the station pid  is not reset after switching from reverse to forward, only the speed pid  parameter is reset  solution:  reset the station pid after switching from reverse to forward  control: reset integral when gear_neutral or full_stop.  fix [idg-apollo-4329].  move too fast after shifting or when entering self-driving.  cause:  after shifting or entering autonomous driving, no integral zeroing  is carried out, resulting in excessive initial control when re-entering control  solution:  reset integral when gear_neutral or full_stop.  localization: compensate the translation between imu and center.  fix [idg-apollo-4350].  the lateral control error is too big.  cause:  the translation between the imu and vehicle center is not compensated  for localization, thus the publish location of the vehicle is not  correct.  solution:  add the translation between imu and vehicle center when calculating the  location of the vehicle.  control: add adctrajectory speed_fallback when full_stop.  fix [idg-apollo-4361].  the car cannot stop immediately during the parking phase.  cause:  in the parking phase, the adctrajectory type changes to speed_fallback,  resulting in failure to access fullstop.  solution:  add adctrajectory speed_fallback when full_stop. ", "linked_issue_titles": "", "title": "improve control performance and compensate imu translation for localization."}
{"description": " augments #6697 to emit readonly modifier in declaration file for get-only accessors in classes. ", "commit_messages": " emit readonly in declaration file for get-only accessors in classes  adding more test cases  accepting new baselines ", "linked_issue_titles": "", "title": "readonly in declaration files (part 2)"}
{"description": " i added a feature #248, which enables to submit with keyboard (ctrl+enter or cmd+enter) on script console. but the feature included a multi submit bug, so i fixed it. in addition, i move the code written in script console jelly to hudson-behavior.js. hereby, shortcut key on script console can be used at any other place, for example scriptler-plugin. ", "commit_messages": " handling shortcut key only when firing 'keydown' event  move handling code to behavior rule file ", "linked_issue_titles": "", "title": "fix multi submit with shortcut key"}
{"description": " cherry-picking this pr to 5.3 to unblock performance for #32041 ", "commit_messages": " aliasanalysis: better handling of init_enum_data_addr and init_existential_addr.  look \"through\" those instructions when trying to find the underlying objects.  (cherry picked from commit c7c2c139af1d7db455ee918ee2af02f8ea422a6c)  aliasanalysis: consider a take from an address as an write  currently we only have load [take] in ossa which needed to be changed.  (copy_addr is not handled in membehavior at all, yet)  even if the memory is physically not modified, conceptually it's \"destroyed\" when the value is taken.  optimizations, like temprvalueopt rely on this behavior when the check for may-writes.  this fixes a memorylifetime failure in temprvalueopt.  (cherry picked from commit 547d527258bfdb9b64132dd96fcb4744d0cabfaa)  aliasanalysis: handle copy_addr in membehaviorvisitor.  only let copy_addr have side effects if the source or destination really aliases with the address in question.  (cherry picked from commit c82f78b218530c2fb02fe1b475c266e21b199cda)  siloptimizer: a new \"templvalueopt\" optimization pass for copy_addr  optimizes copies from a temporary (an \"l-value\") to a destination.  %temp = alloc_stack $ty  instructions_which_store_to %temp  copy_addr [take] %temp to %destination  dealloc_stack %temp  is optimized to  destroy_addr %destination  instructions_which_store_to %destination  the name templvalueopt refers to the temprvalueopt pass, which performs a related transformation, just with the temporary on the \"right\" side.  the templvalueopt is similar to copyforwarding::backwardpropagatecopy.  it's more restricted (e.g. the copy-source must be an alloc_stack).  that enables other patterns to be optimized, which backwardpropagatecopy cannot handle.  this pass also performs a small peephole optimization which simplifies copy_addr - destroy sequences.  copy_addr %source to %destination  destroy_addr %source  is replace with  copy_addr [take] %source to %destination  (cherry picked from commit 9e92389fa59fedf03940dadee49d155899630c99) ", "linked_issue_titles": "", "title": "a new \"templvalueopt\" optimization for copy_addr"}
{"description": " this pull request allows flying shuttle to collect metrics from both compilation pipelines to ensure pages are invalidated when branched code logic is evaluated. by side effect, flying shuttle will now invalidate pages when _document changes. ", "commit_messages": " add flying shuttle plugin to server compilation  ignore build artifacts in flying shuttle manifest  add comments explaining what's going on  emit shuttle manifest after both compilations ", "linked_issue_titles": "", "title": "server file inclusive flying shuttle"}
{"description": " reported in #42740 ec2_group ansible version ", "commit_messages": " fix spurious changed=true when int is passed as tag  fix for all aws module using compare_aws_tags  handle improperly stringified protocols and allow inconsistency between none/-1 on non-tcp protocols ", "linked_issue_titles": "", "title": "fix ec2_group for numbered protocols (gre)"}
{"description": " cherry-picking #27198. the first commit is new because we don't have typecheckstorage.cpp in the 5.1 branch. the second commit is from the original pr. explanation: we were rejecting the following valid code: @propertywrapper struct foo<value> { var wrappedvalue: value } class bar { // error: class stored properties not supported in classes; did you mean 'static'? @foo static var bool: bool = true } the problem here was that we were using the backing variable's static spelling, which is not present (because we haven't created its pattern binding at the time we access the spelling), so the check was falling down to calling getcorrectstaticspellingfordecl() which returned class as the spelling since the context is a class. we should be using the original variable's static spelling instead (we already use its static-ness to decide whether the backing variable should be static or not, might as well use its static spelling too). scope: property wrapper usage inside a class issue: sr-11478 testing: swift ci risk: low. this allows code that was previously rejected (incorrectly) reviewed by: @jrose-apple ", "commit_messages": " [codesynthesis] when creating the pattern binding for the backing variable, use the original property's static spelling  [test] adds some tests ", "linked_issue_titles": "", "title": "fix a bug with static property wrapper being rejected in a class"}
{"description": " adds a bash script to automate changing into each of the examples/ directories and try to run npm i and gatsby build. this script is useful for trying to identify which of the example sites aren't working with the latest version of gatsby (using the next tag). some caveats: this script is slow. it currently takes hours to run, because it's building each example individually. some of the builds will fail because the folder structure for that example is different. e.g., examples/creating-source-plugins/ contains multiple gatsby sites, each in their own folder. this script won't catch all those edge cases. it's mainly an attempt to handle all the easy cases, while identifying individual failing examples that need to be investigated manually. examples/readme.md sc-38579 ", "commit_messages": " chore: delete outdated recipes examples  revert \"chore: delete outdated recipes examples\"  this reverts commit 2dcb7858e149c754f9d31b7d9e8b03d7dd1fca31.  wip: attempt a build script in node (works for small subsets of examples)  chore: replace node build script with bash script (fixes parallelization crashing)  chore: improve documentation in build script ", "linked_issue_titles": "", "title": "add a bash script to test building out examples"}
{"description": " seems that 1 or 2 channel tracks come in directly as pcm_int_lit while >2 channel tracks are wrapped in ms acm to preserve channel mapping. ", "commit_messages": " dev  dev  add 16 bit audio handling for pcm int little and a_ms_acm tracks with pcm int little ", "linked_issue_titles": "", "title": "add 16 bit pcm audio track detected including ms acm for >2 channels"}
{"description": " if the flutter_tool's .packages is missing, run pub get offline in the directory. makes #41681 a bit better, though it still crashes on the first run. ", "commit_messages": " workaround for cache issue  fix imports ", "linked_issue_titles": "", "title": "handle missing .packages file in the flutter tool for prebuilt artifacts"}
{"description": " since majority of es6 feature will have to emit for es5, es3, this pull request is to re-factoring emitjavascript such that we will have separate functions for emit a node in native es6 and down-level es5/es3 without having to check the compileroption.target for every kind of node. ", "commit_messages": " refactoring emitter for emit es6 features natively  refactoring emitter for emit es6 features natively  conflicts:  src/compiler/emitter.ts ", "linked_issue_titles": "", "title": "re-factoring emitter for emitting es6 feature natively and down-level"}
{"description": " what's in this pull request? this pr fixes the build for powerpc64le, and fixes a couple of tests. even with this pr, there are still two failing tests on powerpc64le, and working \"out of the box\" is dependent on the following commit being merged into swift-llvm/stable: apple/swift-llvm@d7ad443 resolved bug number: (sr-) n/a before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " use \"powerpc64{le}\" instead of \"ppc64{le}\"  a mix of \"powerpc64\" and \"ppc64\" existed, causing build failures.  standardise on \"powerpc64\" and \"powerpc64le\", which are commonly used in  target triples, such as those generated by config.guess.  use tiocsti instead of tiocgwinsz in glibc test  validation-test/stlib/glibc.swift was failing on powerpc64le due to the  missing tiocgwinsz symbol.  since (from what i can tell) this is just a  random tty ioctl, replace it with a different ioctl that should be more  commonly defined.  fix persistentvector test for powerpc64{le}  this test has a check for 32/64bit, include powerpc64{le} in this check. ", "linked_issue_titles": "", "title": "powerpc64{le} build and test fixes"}
{"description": " -- some cleanup performed -- buildall.sh script -- generate_protos.sh script that regenerates proto files (as a result, it turned out lots of generated files are out of data, so i regenerated them when possible) these files are handcrafted, so i left them as they are for now: csharp/src/protocolbuffers.test/testprotos/unittest.cs csharp/src/protocolbuffers.test/testprotos/unittestcustomoptions.cs csharp/src/protocolbufferslite.test/testprotos/unittest.cs csharp/src/protocolbufferslite.test/testprotos/unittestlite.cs ", "commit_messages": " add buildall script for mono  draft of generate_protos.sh  got rid of the outdated mono subdirectory  rename fieldpresence to correct name  regenerate some proto files after clscompliance has been dropped  remove c# files not referenced in any project  regenerated unittestdropunknownfields.cs  regenerated unittestextraslite.cs  regenerated unittestimportpubliclite  regenerated unittestimportlite.cs ", "linked_issue_titles": "", "title": "c# generate_proto.sh and buildall.sh scripts"}
{"description": " there are a few tiny packages that seem like they might be out of place. this pr moves their contents around so that they vanish. joegallo@galactic:~/code/elastic/elasticsearch $ for dir in $((find x-pack -type d -name ilm; find x-pack -type d -name slm) | grep src | sort | sed -e \"s/^\\\\.\\\\///g\" | grep -v -e '(^docs|^client)' | grep -v build | grep -v -e '(qa|test)'); do echo $dir $(ls $dir/*.java | wc -l); done x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm 83 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/slm 8 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/slm 1 # tiny! x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ilm 85 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/slm 4 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/slm 2 # tiny! x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/ilm 15 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/slm 8 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/core/ilm 1 # tiny! x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/ilm 18 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm 5 after joegallo@galactic:~/code/elastic/elasticsearch $ for dir in $((find x-pack -type d -name ilm; find x-pack -type d -name slm) | grep src | sort | sed -e \"s/^\\\\.\\\\///g\" | grep -v -e '(^docs|^client)' | grep -v build | grep -v -e '(qa|test)'); do echo $dir $(ls $dir/*.java | wc -l); done x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ilm 83 x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/slm 9 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/ilm 85 x-pack/plugin/core/src/test/java/org/elasticsearch/xpack/core/slm 6 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/ilm 15 x-pack/plugin/ilm/src/main/java/org/elasticsearch/xpack/slm 8 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/ilm 19 x-pack/plugin/ilm/src/test/java/org/elasticsearch/xpack/slm 5 ", "commit_messages": " move snapshotretentionconfigurationtests  to o.e.xpack.core.slm, so it will match snapshotretentionconfiguration  move snapshotlifecyclestats  to o.e.xpack.core.slm, so it will match snapshotlifecyclemetadata and  snapshotlifecyclepolicy  move lifecyclepolicytestsutils  move lifecyclepolicytestsutils (again)  it seems more at home with all its callers in  x-pack/plugin/ilm/src/test ", "linked_issue_titles": "", "title": "tidy up some ilm and slm packages"}
{"description": " we built an rl environment within and motivated by openai gym framework and we would be happy to share the link in gym docs. ", "commit_messages": " opensim as one of the external environments  typo in 'environments' ", "linked_issue_titles": "", "title": "info about the osim-rl environment added to external environments"}
{"description": " follows #43686 closes #43637 closes #43644 closes #43703 tests added / passed whatsnew entry (note part of the bug seems to have been created by hiding levels which is a new feature in 1.4.0). this pr has two parts: addressing the bug fixes as per above. the key change made here was to add a single line: if r not in self.hidden_rows: in the loop, and in _translate_latex update for the new object structure that is input to it. refactoring the code so that the main part of the code is now easier to grok: def _translate(...): # calls _translate_header() # callls _translate_body() def _translate_header(...): # calls _generate_col_header_row() # calls _generate_index_names_row() def _translate_body(...): # calls _generate_trimmed_row() # calls _generate_body_row() and tests were update and comprehensive tests for the issues added. ", "commit_messages": " ignore hidden rows in loop  add latex 43644 test  add latex 43644 test ", "linked_issue_titles": " bug: `styler.to_latex` does hide rows after `hide_index([subset])`  bug: styler hide_index hide_columns misaligns multiindex  bug: styler render trimming rows does not work with `hide_index` ", "title": "styler multiindex hiding indexes and columns alignment"}
{"description": " i don't think this is quite complete yet but this is the initial implementation for making boolean attributes like muted set the property video.muted = {{boolean}} and the attribute video.setattribute('muted', 'muted') when changing the value. also, in html5's createel, we were setting/updating attributes for various properties but we were only setting the attributes and not also the properties but also autoplay was happening first rather than last which caused autoplay to fail because muted and playsinline weren't necessary set by that time. ", "commit_messages": " fix: pull out boolean attributes and have them set/check both attribute and property  set initial attributes for both props and attrs in correct order  add a comment about settingsattrs ordering ", "linked_issue_titles": "", "title": "make boolean attributes set and check both the associated property and the attribute"}
{"description": " this fixes the name of the --max-tasks-per-child parameter whose name was changed in celery 4.x and adds a --max-memory-per-child of 1/4 of total memory. port of mozilla#364 ", "commit_messages": " fix celery worker cli parameter name that was changed in celery 4.x.  set celery worker --max-memory-per-child to 1/4th of total system memory. ", "linked_issue_titles": "", "title": "fix celery worker --max-tasks-per-child for celery 4.x."}
{"description": " there is an error message when compile with latest build tool for android. /godot_dev/platform/android/java/src/com/google/android/vending/expansion/downloader/impl/downloaderservice.java:575: error: the wifi_service must be looked up on the application context or memory will leak on devices < android n. try changing  to .getapplicationcontext()  [wifimanagerleak] mwifimanager = (wifimanager) getsystemservice(context.wifi_service); ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ explanation for issues of type \"wifimanagerleak\": on versions prior to android n (24), initializing the wifimanager via context#getsystemservice can cause a memory leak if the context is not the application context. change context.getsystemservice(...) to context.getapplicationcontext().getsystemservice(...). 1 errors, 0 warnings this pr will fix the error and update to latest gradle. ", "commit_messages": " fix possible memory leak for android  /godot_dev/platform/android/java/src/com/google/android/vending/expansion/downloader/impl/downloaderservice.java:575: error: the wifi_service must be looked up on the application context or memory will leak on devices < android n. try changing  to .getapplicationcontext()  [wifimanagerleak]  mwifimanager = (wifimanager) getsystemservice(context.wifi_service);  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  explanation for issues of type \"wifimanagerleak\":  on versions prior to android n (24), initializing the wifimanager via  context#getsystemservice can cause a memory leak if the context is not the  application context. change context.getsystemservice(...) to  context.getapplicationcontext().getsystemservice(...).  1 errors, 0 warnings  update to latest gradle ", "linked_issue_titles": "", "title": "fix possible memory leak for android and update gradle"}
{"description": " add or edit tests to reflect the change. types/chrome/test/index.ts doesn't have any tests for chrome.commands at all, so i didn't make any changes so far. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: chrome.commands ", "commit_messages": " run prettier  add missing 'tab' parameter ", "linked_issue_titles": "", "title": "add missing 'tab' parameter to chrome.commands"}
{"description": " this pr adds code snippet testing to the security apis that were missing this info and removes these exceptions from the build.gradle file. related to #30665 ", "commit_messages": " [docs] enabled testing in authenticate api  [docs] adds more tests for security apis ", "linked_issue_titles": "", "title": "adds testing for security apis"}
{"description": " this updates ansible-pull as described in issue #2464 and the ansible-pull docs to conform to current available options and usage. ", "commit_messages": " help ansible-pull work better in bootstap environment  add option to specify inventory.  no default is defined since  ansible-playbook already does this and it allows an ansible.cfg in the  git repository to take precedence.  overall, this should help ansible-pull work with less setup in advance,  which should be helpful in kickstart scenarios.  much of this was  discussed in issue #2464.  update ansible-pull documentation  remove errant and unneeded import of ansible.constants ", "linked_issue_titles": "", "title": "updates to ansible-pull and ansible-pull docs"}
{"description": " we want to deprecate jenkins and move the tests to travis. this pr is still wip. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " [tune] sort test execution  create tune py_test directives ", "linked_issue_titles": "", "title": "move jenkins tests to travis"}
{"description": " closes #30590 tests added / passed n/a passes black pandas n/a passes git diff upstream/master -u -- \"*.py\" | flake8 --diff n/a whatsnew entry n/a decided to add all valid strings for all the types in the table about dtypes.  i didn't want to decide which ones to leave out, and if we want to leave some of them out, we should decide whether they should be removed from the code as well (e.g., 'sparse[int, 0]') had to reformat the table so it would look nice, by splitting the list of strings into multiple lines (e.g., a merged cell) ", "commit_messages": " doc: add strings for dypes in basic.rst ", "linked_issue_titles": " doc: add info on dtype strings ", "title": "add strings for dtypes in basic.rst"}
{"description": " this pull request implements following changes add hindi translation for weather report, morning, noon, evening, night add hindi translation for help file and could you please add your name to the translators list? (see above) closes: #429 ", "commit_messages": " feat(translation): hindi translation for we-lang  feat(translation): add hindi translation for help file ", "linked_issue_titles": " hindi translation ", "title": "hindi translation for we-lang and help file"}
{"description": " as part of the extensible values source work, this pr extracts some of the hard-coded valuessource types from valuessourceconfig. related to #42949 ", "commit_messages": " rename valuessourcetype -> builtinvaluessourcetype  extract empty/script/missing behavior from valuessourceconfig  pull valuessourcetype out as an interface  javadoc for (new) valuessourcetype  move withscript vs under bytes  todo notes for points that are still confusing ", "linked_issue_titles": "", "title": "extract empty/script/missing valuessource behavior to an interface"}
{"description": " query results api response should include the bare minimum fields if this is an api call (dashboard, query) and not an authenticated user. we need to move the serialization logic into redash.serializers and apply the relevant checks. ", "commit_messages": " avoid catching errors on text widgets' load(), as they don't have a visualization and therefore do not return any promise  throw error when failing to load widgets on public dashboards - in case something needs to be done with it at a later time, and it's the right thing to do anyway  use promise.resolve instead of checking for undefined  call serialize_query_result instead of directly calling to_dict  filter unneeded query result fields for unauthenticated users  test for serialization filtering ", "linked_issue_titles": "", "title": "query result api response shouldn't include query information for non authenticated users"}
{"description": " i2c slave might stil have something to send when esp826 starts i2c, thus keeping the bus stuck. happens e.g. when power failure/reset during transmission. thanks to work of drmpf there is a solution. implemented as separate method (wire.status()) so as not to interfere with existing. method (status)returns one of the five statuses. 0 or i2c_ok is ok. other status codes are for hanging scl or hanging sda usage: wire.begin();                                 //like normal if (wire.status() != i2c_ok) serial.writeln(error_msg);                 //something wrong with i2c bus //that cannot be recovered. //perform power cycle //or search for other masters on bus; ", "commit_messages": " i2c bus reset with info to user  i2c slave might stil have something to send when esp826 starts i2c, thus  keeping the bus stuck.  happens e.g. when power failure/reset during transmission.  thanks to work of drmpf there is a solution.  implemented as separate method so as not to interfere with existing.  usage:  wire.begin();  if (wire.status() != i2c_ok) serial.writeln(\"something wrong with i2c  bus that cannot be recovered. perform power cycle or search for other  masters on bus.\";  i2c bus reset with info to user ", "linked_issue_titles": "", "title": "i2c bus reset with status info to user, re issue 1025"}
{"description": " reverted changes in genericaliasobject.c to commit 463c7d3 (right before pep 612) via a clean git checkout 463c7d3d149283814d879a9bb8411af64e656c8e -- genericaliasobject.c. implemented pep 612 behavior only in collections.abc.callable in pure python. pr 1/2, another update to typing.py is coming later, but that's not urgent. the intention of this change is to conform more strictly to pep 612. specifically, this snippet: as before, parameters_expressions by themselves are not acceptable in places where a type is expected  the current implementation leaks extra behavior into all builtin genericalias types just for the sake of collections.abc.callable, which is out of the scope of the pep. since there is no need to support paramspec in other places, it's valid to not have them in __parameters__ of all builtin generics. except for collections.abc.callable. this will also speed up builtin genericalias as it has to do less checks, and reduce the amount of confusing code in genericalias (though it defers that to collections.abc.callable.) ", "commit_messages": " revert genericaliasobject.c to prior to pep 612  implement pep 612 behavior in collections.abc.callable  simplify the python logic a little ", "linked_issue_titles": "", "title": "change pep 612 implementation to pure python"}
{"description": " the hacks for gl are not just ugly, but also bad for code size in some cases, it turns out (apparently closure will not optimize as much in their presence). this is a step towards #8421, the changes for which end up causing closure to emit worse code if not for this pr. ", "commit_messages": " reorder when we render the pre js code in jsifier.js. doing it after libraries means we can know at pre render time which library code is included  remove some closure ignores, which are bad for code size ", "linked_issue_titles": "", "title": "remove some closure compiler hacks"}
{"description": " this update is needed for docker#330 (which currently has the regression introduced by moby/libnetwork#241) bump libnetwork to 92d1fbe1eb0883cf11d283cea8e658275146411d full diff: moby/libnetwork@09cdcc8...92d1fbe relevant changes included (omitting some changes that were added and reverted in this bump): moby/libnetwork#2433 fix parseip error when parseip before get addressfamily fixes moby/libnetwork#2431 parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0] moby/libnetwork#2289 this was a regression introduced in moby/libnetwork#2416 fix hardcoded af_inet for ipv6 address handling moby/libnetwork#2440 bump hashicorp go-sockaddr v1.0.2, go-multierror v1.0.0 bump hashicorp/go-multierror v1.0.0, add errwrap v1.0.0 full diff: hashicorp/go-multierror@fcdddc3...v1.0.0 bump hashicorp/go-sockaddr v1.0.2 full diff: hashicorp/go-sockaddr@6d291a9...v1.0.2 relevant changes: hashicorp/go-sockaddr#25 add android os hashicorp/go-sockaddr#28 add go.mod ", "commit_messages": " bump lib network to 92d1fbe1eb0883cf11d283cea8e658275146411d  full diff:  relevant changes included (omitting some changes that were added _and_ reverted in this bump):  - docker/libnetwork#2433 fix parseip error when parseip before get addressfamily  - fixes docker/libnetwork#2431 parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0]  -  - this was a regression introduced in docker/libnetwork#2416 fix hardcoded af_inet for ipv6 address handling  - docker/libnetwork#2440 bump hashicorp go-sockaddr v1.0.2, go-multierror v1.0.0  bump hashicorp/go-multierror v1.0.0, add errwrap v1.0.0  full diff:  bump hashicorp/go-sockaddr v1.0.2  full diff:  relevant changes:  - hashicorp/go-sockaddr#25 add android os  - hashicorp/go-sockaddr#28 add go.mod ", "linked_issue_titles": " parseip error ip=[172 17 0 2 0 0 0 0 0 0 0 0 0 0 0 0] ", "title": "bump libnetwork and dependencies to 92d1fbe1eb0883cf11d283cea8e658275146411d"}
{"description": " account for x and y probe offset when indicating current position [] on grid when displaying mesh map. also, adjust the default safe home position to be on a grid point to allow easy validation, i.e. we expect the grid z offset value at the home position to be very close to 0, depending on how reproducible the z probing is. after doing a g29 p1, the mesh topology displayed using g29 t would show larger than expected z errors when compared with the z height displayed on the lcd screen. this turned out to be due to the code for finding the nearest mesh point to the current nozzle position not taking the x and y z probe offsets into account. this fix makes it easier to verify the mesh using the lcd readout z value. ", "commit_messages": " account for x and y probe offset when indicating current position on grid when displaying mesh map.  try to home on a grid point to better allow checking mesh center ", "linked_issue_titles": "", "title": "ubl g29 t current position fix"}
{"description": " we need this to address issue #565 (which is blocking merging c# into master). this also reveals that despite style guide says that repeated fields should use name in plural form, the generated code doesn't really reflect that (in sense providing sane names for the generated members). correct naming of fields in addressbook.proto (\"phones\" and \"persons\") results in code that's a bit wierd (e.g. method addpersons adds a single person)  @jskeet  fyi ", "commit_messages": " update addressbook.proto to proto3  fix c++ example  fix python example  fixed java example ", "linked_issue_titles": "", "title": "update addressbook.proto and examples code to proto3"}
{"description": " see  this makes it possible to build a bitcode enabled ios app if you're using a local engine built with bitcode. the plan here is to make this a bit more accessible to early adopters who want to test it. they can test it by either using flutter build aot --target-platform=ios --bitcode --profile --local-engine=ios_profile, or by setting enable_bitcode to true in their xcode project (and building with a local engine).  we're not yet vending engine binaries with bitcode - i'd like to enable this as a hidden flag for now that people can start testing and validating. @jonahwilliams mentioned this should get analytics - i'm not really sure how to do that but would be happy to add some. this also really wants an integration test, but that would be very expensive to do right now - we'd have to checkout the engine sources for the framework commit, build them (and we can't use goma), and then use a local engine.  i've added some unit tests to the parts of the build system i changed, except for xcode_backend.sh which isn't really testable (i've tested it manually). related issues part of #15288 i added the following tests: tests that building aot with and without bitcode support makes the expected invocations and modifies the generated assembly as expected. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " bitcode start  merge  temp  merge  ?  wire up bitcode arg, cleanup  revert enable_bitcode for all projs  revert dev and examples  revert templates  more  tests  tests ", "linked_issue_titles": "", "title": "enable bitcode compilation for aot"}
{"description": " see #5841 -- i used a version of path.relative that should work on all platforms. ", "commit_messages": " fix css url rewriting for application deployed under a sub path  fixes #5837  use a reproduced pathrelative in css minifier  we can't use plugin.fs here so we'll keep replicating stuff. ", "linked_issue_titles": "", "title": "mquandalle fix path minifiers css"}
{"description": " change this change fixes the case when opensource returns a nullptr.  the command will now inform the user depending on the case: there are no sources, so we suggest adding one. there are sources, but the requested source did not match one.  we list the configured sources. testing manually confirmed all cases. ", "commit_messages": " fix attempting to search when no source value is returned  be helpful in case a bad name was used ", "linked_issue_titles": "", "title": "fix crash when opensource returns nullptr"}
{"description": " r? @oli-obk  fixes rust-lang/miri#449 ", "commit_messages": " miri engine: lazily allocate memory for locals on first write  make storagelive lazy as well  fix miri engine debug output for uninitialized locals  initialize unsized locals when copying to the for the first time  implement by-value object safety ", "linked_issue_titles": "", "title": "unsized locals and by-value dyn traits"}
{"description": " when we select a color for the tab, we update the foreground color of the text so that it maintains acceptable contrast with the new tab color. however, we weren't also updating the foreground color of the close button. this is understandable though, because apparently this wasn't fixable until mux 2.4 arrived. i'm not a xaml expert, but i know that setting this key only works when we're using mux 2.4, so i'm assuming something about the tabview implementation changed in that release. this pr is marked as a draft until #5778 is merged, then i'll re-target to master. #5778 - pr to move to mux 2.4 this bug was introduced with the tab color picker in #3789 closes #5780 i work here a light tab color: a dark tab color: ", "commit_messages": " move to microsoft.ui.xaml 2.4.0  this fixes #5780, but it _only_ works on mux 2.4 apparently. ", "linked_issue_titles": " tab close button doesn't color properly when changing tab color ", "title": "update the tab's close button color to match the tab text color"}
{"description": " fixes tree reduction failing on new instance type p3dn.24xlarge, which was raised here: dmlc/gluon-nlp#520 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change adds a fallback for cudadevicegetp2pattribute topology information to use cudadeviceenablepeeraccess when the former is inconsistent across instance types. fixes tree reduction breaking when cudadevicegetp2pattribute provides wrong information. on p3dn.24xlarge using cuda 9.0, we observe that the cudadevicegetp2pattribute topology looks different compared to when we use cuda 9.0 with p3.16xlarge: // check that all p2p connections are detected by getp2pattribute // if yes, then continue as before // if not, then fallback to using cudadeviceenablepeeraccess saved in p2p_matrix //   (from enablep2p() in src/kvstore/comm_tree.h) // // we have observed that with cuda 9.0 p3.16xlarge: // //   0 2 2 3 3 1 1 1                . v v v v . . . //   2 0 3 2 1 3 1 1                v . v v . v . . //   2 3 0 3 1 1 2 1                v v . v . . v . //   3 2 3 0 1 1 1 2                v v v . . . . v //   3 1 1 1 0 2 2 3                v . . . . v v v //   1 3 1 1 2 0 3 2                . v . . v . v v //   1 1 2 1 2 3 0 3                . . v . v v . v //   1 1 1 2 3 2 3 0                . . . v v v v . // //        matrix                       p2p_matrix // cudadevicegetp2pattribute   cudadeviceenablepeeraccess // // here, they are correctly detected, because the 2s and 3s correspond to // links that have p2p connections between them. however for cuda 9.0 p3dn.24xlarge: // //   0 2 2 1 1 1 1 1                . v v v v . . . //   2 0 1 2 1 1 1 1                v . v v . v . . //   2 1 0 1 1 1 2 1                v v . v . . v . //   1 2 1 0 1 1 1 2                v v v . . . . v //   1 1 1 1 0 2 2 1                v . . . . v v v //   1 1 1 1 2 0 1 2                . v . . v . v v //   1 1 2 1 2 1 0 1                . . v . v v . v //   1 1 1 2 1 2 1 0                . . . v v v v . // //        matrix                      p2p_matrix // cudadevicegetp2pattribute   cudadeviceenablepeeraccess // // the fastest connections (3 i.e. double nvlink) are not recognized as being a //   connection ", "commit_messages": " add fallback for gpu topology detection using cuda 9.2  add fallback for gpu topology detection using cuda 9.2  add log  update 3rdparty to master  add fallback for gpu topology detection using cuda 9.2  add log  update 3rdparty to master  bring 3rdparty packages to upstream/master  rebase to master ", "linked_issue_titles": "", "title": "fix tree reduction on new instance type p3dn.24xlarge"}
{"description": " updated to a more efficient version of bubble sort by adding decrements after loop and changing loop type. ", "commit_messages": " updated to more efficient version if array size is scaled.  changed loop from \"for\" to \"do-while\". added decrement at end of do loop to decrease size of array tested after each iteration.  updated to more efficient version if array size is scaled. ", "linked_issue_titles": "", "title": "bubble sort updated to efficient version"}
{"description": " there are multiple terminology such as checkpointxxx savingxxx and model for the checkpointmanager feature which makes it confusing. also, it's more accurate to change frequency to interval since freq = 1 / interval. this pr makes adjustment to the docs and terminology. ", "commit_messages": " [jvm-packages] move cache files to tmp dir and delete on exit  [jvm-packages] update docs and unify terminology ", "linked_issue_titles": "", "title": "update docs and unify the terminology"}
{"description": " the @types/eureka-js-client package was missing the definitions for the requestmiddleware function definition. according to the docs, this is an optional property, and as such has been marked as a nullable field. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added requestmiddleware hook  contributor list addition  marking requestmiddleware as nullable  marked all eurekaconfig props as nullable  reverted eureka-js-client version format  added middleware interface to prevent original eurekaconfig fields from being nullable ", "linked_issue_titles": "", "title": "added custom request middleware hook definition"}
{"description": " this imports in.h, in6.h and l2tp.h from kernel-5.0. fixes #12300. ", "commit_messages": " linux: move netdevice.h from shared/linux to basic/linux  as the header linux/if_arp.h includes linux/netdevice.h.  linux: also import linux/in.h and in6.h from kernel-5.0  now linux/in.h has better conflict detection with glibc's  netinet/in.h. so, let's import the headers.  note that our code already have many workarounds for the conflict,  but in this commit does not drop them. let's do that in the later  commits if this really helps.  linux: also import l2tp.h from kernel-5.0  the l2tp_attr_udp_zero_csum6_{tx,rx} attributes are introduced by  6b649feafe10b293f4bd5a74aca95faf625ae525, which is included in  kernel-3.16. to support older kernel, let's import the header.  fixes #12300. ", "linked_issue_titles": " systemd-242 unable to build with kernel 3.14 (l2tp_attr_udp_zero_csum6_tx missing) ", "title": "import more headers from kernel-5.0"}
{"description": " this shouldn't be merged until we're ready to attempt the initial full deploy, which could break beyond what we can ensure in tests. since this introduces a lot of additional ci i'm trying to keep the window of enforcing 3.8 tests passing in addition to 3.6 to just 3.8 tests at a minimum. the ideal situation is we merge this, deploy 3.8 to great success, then remove all of 3.6. but if the 3.8 deploy doesn't go well, we should keep enforcing 3.6 + 3.8 tests passing. note, visual snapshotting is disabled on 3.8, and when we make the switch to it i'll enable it in the pr and don't think there'll be any differences. gonna need to change repo settings again for these new check titles. and again when 3.6 is removed. ", "commit_messages": " move query-valid-python-version to lib, add sanity check for sentry_python_version mismatch  remove sanity check since sentry_python_version is only set if direnv succeeds; chicken egg  revert \"remove sanity check since sentry_python_version is only set if direnv succeeds; chicken egg\"  this reverts commit d69ad1e990f2bb42c6e57e54bdd820a5ba2484ec.  fix: let sentry_python_version override get-pyenv-version  fix  evan you happy now?  fix, lol  [skip ci] evan pls  few small ci updates  go away unboundlocal  is this going to be 2x2 instances?  fix: can't use psycopg-binary 2.9.x in 3.8 with django 2.2  revert \"fix: can't use psycopg-binary 2.9.x in 3.8 with django 2.2\"  this reverts commit d7a4765b1d84969a5123190e89f3d6a3d5634d18.  change to explicitly test only 3.6.13 for now, also adopt  python-version 3.6.13 matrix everywhere  add 3.8  make check titles consistent by making python version come first ", "linked_issue_titles": "", "title": "add required testing on python 3.8.12"}
{"description": " per the discussion on the issue tracker, the behavior of the pure python implementation of datetime, date and time are out of whack with the equivalent from _datetimemodule.c. since the c version is almost certainly what's being used almost everywhere, this shouldn't have any real behavioral changes. the equivalent bug in pypy3 has been fixed for some time. ", "commit_messages": " add failing test for pure python datetime subclasses  bring pure python (datetime|date|time).replace behavior in line with c ", "linked_issue_titles": "", "title": "make (datetime|date|time).replace return subclass type in pure python"}
{"description": " with this we are changing the webpack devtool to eval in the development and we no longer use source map. source map with babel is always problematic and cra don't use it. also, it takes time longer than other eval. we also can't use cheap sourcemap devtools because of chrome has some bugs on it. we also cleanup some source map based error enhancements we did and how we handle errors. ", "commit_messages": " change the dev time devtool to eval.  now we don't use source-map and all the helpers used for that.  source map is slow and cheap source maps doesn't work well in chrome.  we also remove error enhancements which is also based on source-maps.  additionally, we now simplified the client side error handling  and always throw the actual error so we can check it from the console.  simply error handling and always log the stack to the console. ", "linked_issue_titles": "", "title": "devtool change and error handing"}
{"description": " fixes issue #6884 #6884 closes #6884 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " add randomenv example to examples folder.  convert warning into error message when using an lstm in a non-shared-vf network (after the warning, the program would crash).  lint.  fix issue #6884. lstm + non-shared vf nn + ppo crashes when using a tuple action space.  lint ", "linked_issue_titles": " [rllib] using lstm model raises valueerror (tuple obs_space, similar to #3367) ", "title": "lstm + non-shared vf + ppo + tuple actions"}
{"description": " this pull request is for install openpose under jetpack 3.3, cuda 9,  cudnn 7 and opencv 3. i have made changes to files and tested on my jetson tx2 ", "commit_messages": " add files to install openpose under jetpack 3.3  add installation instructions for jetpack 3.3 ", "linked_issue_titles": "", "title": "add files for install openpose under jetpack 3.3"}
{"description": " which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # ", "commit_messages": " added support for eplus  no message  no message  added replicator port  removed replicator config from nodes  added http version  condition to avoid duplication  allowing replicator to run in all nodes  bug fix for nginx  updated inactiveservercleaner plugin logic  support for configmap to bootstrap artifactory  * art-ha-nginx-bugfix:  updated inactiveservercleaner plugin logic  bug fix for nginx  # conflicts:  #\tstable/artifactory-ha/chart.yaml  #\tstable/artifactory-ha/readme.md  #\tstable/artifactory-ha/templates/artifactory-plugin-inactiveservercleaner.yaml  #\tstable/artifactory-ha/templates/artifactory-primary-statefulset.yaml  #\tstable/artifactory-ha/templates/nginx-deployment.yaml  configmap support for nginx.conf  updated readme.  updated artifactory version  node affinity support  fixed case  # conflicts:  #\tstable/artifactory/chart.yaml ", "linked_issue_titles": "", "title": "bumped version + added support for nginx configmap"}
{"description": " previously, we have three-layer storage abstraction which actually is not necessary. this pr update it to two-layer abstraction. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " simpler store  format ", "linked_issue_titles": "", "title": "simplify the workflow storage layer"}
{"description": " no functional changes, let's just make nspawn easier to maintain. ", "commit_messages": " nspawn: split out mount related functions into a new nspawn-mount.c file  nspawn: split all port exposure code into nspawn-expose-port.[ch]  nspawn: split out network related code to nspawn-network.[ch]  nspawn: split out cgroup related calls into nspawn-cgroup.[ch]  nspawn: split out machined registration code to nspawn-register.[ch]  nspawn: split out --uid= logic into nspawn-setuid.[ch]  nspawn: remove nspawn.h, it's empty now  nspawn: sort and clean up included header list  let's remove unnecessary inclusions, and order the list alphabetically  as suggested in coding_style now. ", "linked_issue_titles": "", "title": "split up nspawn.c into multiple smaller .c files"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. add it to notneededpackages.json. ", "commit_messages": " prettier  feat(point): add x, y value ", "linked_issue_titles": "", "title": "add x,y value of point"}
{"description": " an ownershipintroducingvalue is a value with owned ownership that is not a result of forwarding ownership from some other value. it is similar to the notion of \"rc identity\" that we talk about in the low level arc optimizer. i am adding this support so given a specific value, we can walk up the def-use graph and find all of the ownership introducing values (what one would call in the low level arc optimizer an \"rc identity set\"). as an example, consider the following sil: %0 = @owned $(klass, int) %1 = @owned $klass (%2, _) = destructure_tuple %0 %3 = tuple(%1, %2) in this case, the set of ownership introducing values for %3 would be (%0, %1). in order to implement phi elimination, i need to be able to ascertain all of the owned value introducers for a specific incoming value so i can see if i can convert all of the liveranges associated with the incoming value could be converted to guaranteed if we could flip the phi argument. ", "commit_messages": " [ownership] add a new construct: ownedvalueintroducer for dealing with non-forwarding owned values at a higher level.  this is a similar concept to \"rc-identity\" that we talk about in the low level  arc optimizer. the main idea is that all owned values in a program can be  partitioned into two different kinds of values:  1. introducer values that exist independently of any other local values in the  function. it is a point of truth from which the owned objects lifetime extends  from and is in a certain sense an initialization (in a category theoretic sense)  in the lifetime of the underlying object that we are manipulating.  2. forwarding values do not represent an object lifetime that is \"truly\"  independent of any other value locally: its liveness comes from passing on  liveness from some introducer or some other forwarding value.  the reason why i am adding this new construct is that i am beginning to  implement a new form of arc optimization that enables us to convert @owned sil  phi arguments to @guaranteed phi arguments. as part of that, i need to have a  way to in a systematic way finding the underlying incoming values (using the  logic used to determine forwarding in the ownership verifier).  this is the first part of that effort, defining the ontology we are going to  work with. keep in mind this is just a seed ontology, if i missed any \"owned  introducers\" (i am sure i did), feel free to add them.  [ownership] implement getsingleownedvalueintroducer and getallownedvalueintroducers().  these enable robust walking up the def-use ossa graph to find the value that  introduces an independent underlying owned value, looking through forwarding  insts. ", "linked_issue_titles": "", "title": "add an \"applysite\" like wrapper for ownershipintroducingvalues and add utilities for finding them."}
{"description": " task ids are a way to express a relationship between related internal requests. this change preserves the task id for internal requests of the startdatafeedpersistenttask, similarly to how rollupjobpersistenttask does it. relates #52314 ", "commit_messages": " datafeedjob task id ", "linked_issue_titles": "", "title": "preserve task id for ml datafeed"}
{"description": " i added the \"mark all as complete\" checkbox as requested by @boushley and also added the \"press enter to save this task\" tooltip on the input field. ", "commit_messages": " add \"mark all as complete\" checkbox bound to a writeable computed observable and minor code cleanup.  add the \"press enter\" tooltip that appears after a delay when the user has entered a value and stops typing ", "linked_issue_titles": "", "title": "add \"mark all as complete\" checkbox and \"press enter\" tooltip."}
{"description": " this pr fix the ship bug with chain fork and stride enabled. select one: select any that apply: ", "commit_messages": " fix ship truncate problem with stride  fix truncate problem when there's gap in catalog  avoid unnecssary reopen files ", "linked_issue_titles": "", "title": "fix ship truncate problem with stride - 2.1"}
{"description": " this patch is adding integration tests for the grafana_datasource module. grafana_datasource.py ", "commit_messages": " add setup_grafana role for integration tests  grafana_datasource: add integration tests for elastic datasource  grafana_datasource: add integration tests for influxdb datasource  grafana_datasource: add integration tests for postgres datasource  grafana_datasource: add integration tests for cloudwatch datasource ", "linked_issue_titles": "", "title": "add integration tests for grafana_datasource module"}
{"description": " here a new attribute @main is added. the type or extension that it is added to must have a static function () -> void or () throws -> void visible from the attribute. if it does, that function will be called at process launch. the same restrictions that apply to the existing @uiapplicationmain and @nsapplicationmain apply to the new attribute as well. ", "commit_messages": " added executable entry-point via @main type.  when a type (class, enum, or struct) is annotated @main, it is required  to provide a function with the following signature:  static func main() -> ()  that function will be called when the executable the type is defined  within is launched.  @main: added $main func to @main type.  previously, the function was being added to the list of top level decls  in the source file as that list was being iterated, leading to iterator  issues.  here, the function is instead added to the nominal type decl which is  decorated with @main.  doing so requires calling the $main function with  the metatype for the nominal type.  the workaround for the iterator invalidation issue which had been  applied previously, namely changing the type of the decls member of  sourcefile from std::vector<decl *> to smallvector<decl *, 16> is  reverted.  @main: allowed attribute on extensions.  previously the @main attribute could only be applied to  nominaltypedecls.  here, that limitation is lifted so that the attribute  can be applied to extensiondecls.  @main: enable main function to throw.  se-0281 was accepted with the modification that the main function should  be allowed to be throwing.  here support for enabling that is added.  support is implemented in two steps:  (1) the $main wrapper function is modified to be throwing  static func $main() throws {  return try main()  }  whenever the main function is throwing (it remains non-throwing when  $main is not throwing).  (2) the @main entry point is modified to be  sil [ossa] @main : $@convention(c) (int32, unsafemutablepointer<optional<unsafemutablepointer<int8>>>) -> int32 {  entry(%argc : $int32, %argv : $unsafemutablepointer<optional<unsafemutablepointer<int8>>>):  %the_main_type = metatype $@thin themaintype.type  %the_main_func = function_ref @themaintype.main() : $@convention(method) (@thin themaintype.type) -> @error error  try_apply %the_main_func(%the_main_type) : $@convention(method) (@thin themaintype.type) -> @error error, normal success, error failure  success(%_ : $()):  %success_code_builtin_int32 = integer_literal $builtin.int32, 0  br bb1(%success_code_builtin_int32 : $builtin.int32)  failure(%error : @owned $error):  %_ = builtin \"errorinmain\"(%error : $error) : $()  end_lifetime %error : $error  %error_code_builtin_int32 = integer_literal $builtin.int32, 1  br bb1(%error_code_builtin_int32 : $builtin.int32)  exit(%code_builtin_int32 : $builtin.int32):  %code = struct $int32 (%code_builtin_int32 : $builtin.int32)  return %code : $int32  }  whenever the main function is throwing (and consequently $main also is).  in the non-throwing case, (a) the try_apply instruction is replaced with an  apply instruction, (b) the body of the success block is appended to the  entry block, and (c) the success and failure blocks are removed. ", "linked_issue_titles": "", "title": "attribute to add an entry point to a type."}
{"description": " new features others tensor transforms on gpu normalize to_grayscale vflip hflip crop center_crop pad rotate resize ", "commit_messages": " add to_grayscale, normalize  add rotate  add vfip and hflip  add crop center_crop  add utils  add utils  update utils, add raise for some cases  add padding, support constant, reflect, replicate, circular same as paddle.pad  update rotate  using utils func in [v|h]flip  add get-image-[n,c,w,h] axis utils  add get-image-[n,c,w,h] axis utils  align  update  remove default value in utils func  add assert for pad  update assert paddle image  support rotate fill func  raise valueerror for pad ", "linked_issue_titles": "", "title": "support transforms for paddle tensor image"}
{"description": " i hereby agree to the terms of the cla available at:  disallow building uniqxxxxstates of other aggregation states detailed description / documentation draft: fixes #24461 affects all releases so i it should be backported but i'm unsure how the process works. ", "commit_messages": " disallow building a uniqxxxxstate on top of another aggregation state  fixes  add tests for chained unique*state ", "linked_issue_titles": " crash when chaining different uniq*state ", "title": "fix crash when chaining uniqstates"}
{"description": " fixes #12771 bugfix yes no, but a deprecation filename has been moved from the asset modules generator options to the parser options. the old option will still work, but is deprecated and should be removed from docs module.parser.asset.filename or rule.parser.filename (for type asset) also in module.parser[\"asset/resource\"].filename removed: module.generator.asset.filename and module.generator[\"asset/resource\"].filename ", "commit_messages": " update tooling  move filename processing from asset generator to parser  remove memory leak from asset generator ", "linked_issue_titles": " webpack 5 memory leak in watch mode ", "title": "fix memory leak in asset generator"}
{"description": " this is #39785 with one additional small but important thing in linking.cpp fixed -- that fixes the test that failed over there about the tbd entries. thank you @douggregor for the work! pulling here to get a toolchain going and this merged over the weekend. fix a few minor issues in the type checker and silgen to properly cope with distributed functions defined within extensions of distributed actors. while here, centralize the logic that adds the \"remote\" function. ... and since this uncovered a problem with the mangling for distributed functions, fix that, too. fixes rdar://84325525. ", "commit_messages": " add support for distributed functions in extensions of distributed actors.  fix a few minor issues in the type checker and silgen to properly cope with  distributed functions defined within extensions of distributed actors.  while here, centralize the logic that adds the \"_remote_\" function.  fixes rdar://84325525.  add test case  use a non-conflicting mangling for distributed thunks.  distributed thunks were using the same mangling as direct method  reference thunks (i.e., for \"super\" calls). although not technically  conflicting so long as actors never gain inheritance, it's confusing  and could cause problems in the future. so, introduce a distinct  mangling for distributed thunks and plumb them through the demangling  and remangler.  [distributed] fix dist thunk mangling in linking.cpp as well ", "linked_issue_titles": "", "title": "add support for distributed functions in extensions of distributed actors (fixed linking too)"}
{"description": " resolve #78836 revert #74559 this reverts the change to use segment ordinals in composite terms aggregations due to a performance degradation when the field is high cardinality. ", "commit_messages": " revert \"update docs that composite agg no longer uses global ords (#74754)\"  this reverts commit ec799ab27e32470d6abbb1897d38693654fbe0a9.  revert \"avoid global ordinals in composite aggregation (#74559)\"  this reverts commit 5cfcb2f4dbcb52fae24ba44574f8eaf1bcf2299b.  conflicts:  server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/compositevaluescollectorqueue.java  server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/ordinalvaluessource.java  server/src/main/java/org/elasticsearch/search/aggregations/bucket/composite/termsvaluessourcebuilder.java  server/src/test/java/org/elasticsearch/search/aggregations/bucket/composite/singledimensionvaluessourcetests.java ", "linked_issue_titles": "", "title": "revert 74559 (avoid global ordinals in composite)"}
{"description": " the waitfor.js example does not work, because the twitter account used in the example doesn't exist and twitter changed the structure of their page. this should work now, i used the senchainc account as in the tweets.js example. i made some further changes to the example to display the ui change that was waited for and to exit the program if an error occurs. also added a coffeescript version. the pizza.js  example did loop through item and length as well, leading to undefined being output. (the coffeescript version does the right thing :-) ...) ", "commit_messages": " use spaces throughout.  use an existing twitter account and update name changes in new twitter.  use shorter default timeout.  don't throw error on timeout, use phantom.exit instead.  change meaning of message parameter to show what has happenend.  add coffeescript version of waitfor.js.  loop only through divs, not length and item. ", "linked_issue_titles": "", "title": "fixes for waitfor and pizza examples"}
{"description": " docker hub uses standard docker layer caching to cache artifacts between builds. this is different from e.g., travis, which mounts home directory folders from a cache it downloads / uploads out of line. currently, all of our builds start with a fresh maven image which has no cache at all, so every build downloads the world. we can prepare a zipkin-builder image which contains a package cache to speed up our downstream builds. after the first version of this image is pushed, i'll point the dockerfiles to use it instead of maven. this builder image would have no value if code changes caused it's docker cache key to be invalidated (the docker cache key is the file hashes computed for a given copy command, etc), so we use a special .dockerignore file to exclude as much as possible. some of the linked issues in the comments provide more background on this approach (ideally copy would accept inclusions / exclusions as arguments but there seems to be no desire to implement that in dockerfile). in this pr, i have added a skiplens property that can be used in the build to not build lens. it's used here, but i think it could be useful in general development since i know i've found myself waiting for a zipkin-lens build to finish despite not needing lens for the particular dev task. the zipkin-builder image has a special dockerignore file that attempts to only copy in pom.xml and package.json files into the build context. this means that the result of a maven build is only invalidated when these change, which is rare. this means that there would be two scenarios: a master commit that only contains code changes (no changes to pom or package.json). the zipkin-builder and zipkin builds would be started together. zipkin-builder would end without doing anything since it's cache key, which does not include code, is unaffected. zipkin will build and not download the world since it uses zipkin-builder's cached repositories. a master commit that does change pom or package.json. the zipkin-builder and zipkin builds would be started together. zipkin-builder would start from scratch, downloading the world. zipkin will start and will use the latest, now outdated, zipkin-builder when building. this means it won't download the world, but only the new dependencies since the previous one. this is pretty fast, since i notice that the majority of the world is maven itself with all its plugins, and those don't change so often. after these builds finish, following commits would go back to scenario 1 until a next set of dependency updates. downstream projects zipkin-aws and zipkin-gcp will download more stuff on scenario 1. while it'd be possible to prepare builders for each of them, i think the delta in dependencies is small enough that we don't need to worry about that (the prime culprits, maven and spring-boot will be in zipkin-builder for use by all the buildz). while it's a bit annoying having this extra image, once it's set up it should all manage itself automatically so hopefully it is not too complex. ", "commit_messages": " try adding a builder image.  finish  comment ", "linked_issue_titles": "", "title": "add a builder docker image to use when building other images."}
{"description": " performance optimization others getblob is very often used function and majority of it is executed under critical section so it is good to optimize it as much as possible. in this pr we add assumption that objects in cache are there e.g. we instruct compiler to generate code layout in favour of situation that objects are cached. performance improvement is x < 1% on mobilenetv1_int8 clx ", "commit_messages": " first set of fixes  - make more likely to getblob find a blobs  - lint ", "linked_issue_titles": "", "title": "make getblob assuming elements are cached"}
{"description": " small follow-ups to  #19935: removal of unused keyidhasher  class (comment in 19935) removal of an outdated comment, which referred to an old problem with the no longer supported boost 1.46 and boost::unordered_map, now replaced by std::unordered_map. (comment in 19935) ", "commit_messages": " refactor: remove unused keyidhasher  doc: remove outdated comment  no longer relevant because boost 1.46 is no longer supported and  std::unordered_map is used instead of boost::unordered_map in ccoinsmap. ", "linked_issue_titles": "", "title": "hasher cleanup (follow-up to 19935)"}
{"description": " #243 added a single-endpoint configuration option for an elasticache replication group that used dns polling to determine when a failover had occurred. this had the drawback of requiring the application to ensure the jvm did not cache dns lookups. additionally, it left the read slave(s) of the replication group unused; only the master node would ever be queried. this pr adds an elasticachereplicationgroupserversconfig (such a long class name!) for the specification of all nodes in the replication group (as auto-discovery is unsupported in redis elasticache). a new elasticachereplicationgroupconnectionmanager then uses info replication to determine the role of each node and polls each node at a configurable interval (default: 1000ms - same as cluster polling) to determine if the role has changed. example code: public static void main(string[] args) { config config = new config(); config.useelasticachereplicationgroupservers().addnodeaddress(args); redisson r = redisson.create(config); r.flushdb(); ratomiclong al = r.getatomiclong(\"testlong\"); while (true) { try { system.out.println(system.currenttimemillis() +\":\"+ al.addandget(1)); } catch (throwable t) { system.out.println(\"exception: \" + t); t.printstacktrace(system.out); } try { thread.sleep(1000); } catch (interruptedexception ignored) {} } } output (foo-002 is promoted while program runs): java -jar test.jar foo-001.cache.amazonaws.com:6379 foo-002.cache.amonaws.com:6379 1441997395811:1 1441997396819:2 1441997397822:3 ... 1441997422911:31 exception: org.redisson.client.redisexception: readonly you can't write against a read only slave.. channel: [id: 0xddd6cc97, /10.0.x.x:42009 => foo-001.cache.amazonaws.com/10.0.y.y:6379] command: commanddata [promise=defaultpromise@644b9548(incomplete), command=rediscommand [name=incrby, subname=null], params=[testlong, 1], codec=org.redisson.client.codec.stringcodec@469956b0] ... 1441997435035:32 1441997436041:33 ... note exception still occurs for the command that was pending against foo-001 when failover happened, but will succeed on retry after the failover has been detected. ", "commit_messages": " elasticache replication group server configuration  uses \"info replication\" to determine which node is master and which are  slaves.  no need to invoke slavedown(). also some non-functional cleanup ", "linked_issue_titles": "", "title": "master / slave configuration for elasticache replication group"}
{"description": " add more tests for generatedkey delete invalid class named datasourceservice.java ", "commit_messages": " fix bug waittoleratetimedifferenceifneed  add maxtoleratetimedifferencemilliseconds = 10  rename to  assertgeneratekeywithmultiplethreads()  add assertgeneratekey()  rename to  assertgeneratekeywithsinglethread()  modify assertgeneratekeywithmultiplethreads()  add assertgeneratekey1()  rename to assertgeneratekeywithclockcallback()  add assertgeneratekey3()  rename to assertgeneratekeywithclockcallbackbeyondtoleratetime()  modify assertgeneratekeywithclockcallbackbeyondtoleratetime()  add assertgeneratekey2()  use     @sneakythrows  rename to assertgeneratekeybeyondmaxsequencepermillisecond() ", "linked_issue_titles": "", "title": "add some tests for generatedkey"}
{"description": " this p.r. adds a new optional argument to tools/test.py: --images_out_dir if specified, detection results will be plotted on the images and saved to the specified directory. it is only applicable to single gpu testing and used for debugging and visualization. you don't need a gui available in your environment for using this option. this should be an alternative solution to some issues requesting this feature (#2407 #2240 #1405) the show_result method of basedetector has been refactored to use mmdet.apis.inference. i'm not sure if this was the right approach because there was a todo comment regarding the merge. ", "commit_messages": " use apis/inference in detectors show_result  add images_out_dir arg to test apis  include --images_out_dir in assertion  fix single class parsing  remove single class hack  move import  add example of saving results ", "linked_issue_titles": "", "title": "add option to save the result images of running tools/test"}
{"description": " see #315. pipe and redirection are working well in my linux and windows computer. ", "commit_messages": " use os.execl to \"run\" subcommand on unix  see  use subprocess on windows  os.execl has strange behavior on windows. ", "linked_issue_titles": "", "title": "use os.execl to \"run\" subcommand on unix ( close #315 )"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixed wrong argument types for aggregate functions with low cardinality arguments. #4919 ", "commit_messages": " remove lowcardinality from aggregate function argument types. #4919  added test. #4919 ", "linked_issue_titles": "", "title": "fix types for aggregate functions with low cardinality arguments."}
{"description": " @ctiller @nicolasnoble @tbetbetbe @murgatroid99: this is a lot of code, but aside from license headers and path renames it's a straight copy out of google-internal source control. except at the end with the tossed-in addition of the stock_pb2 file. that's temporary and todoed appropriately. ", "commit_messages": " fill out the foundation package.  add the _framework.common package.  it's rather unimpressive at the moment with just  one module.  add the _framework.base package.  add the _framework.face package. ", "linked_issue_titles": "", "title": "bring the rest of python rpc framework into grpc."}
{"description": " keep redirectcontroller links consistent as discussed in  change links from github.com to api.rubyonrails.org details keep redirectcontroller links consistent there are two links defined to redirectcontroller, with backticks and without them. this commit removes the link without backticks for the sake of consistency as discussed here. change links from github.com to api.rubyonrails.org the guide's guidelines do not mention anything against linking to the github repo, but it describes how to link to api.rubyonrails.org works. so i guess that it's better to link \"api.rubyonrails.org\" when is possible, for instance: classes, modules, and methods. ", "commit_messages": " keep redirectcontroller links consistent.  there are two links defined to redirectcontroller, with backticks and  without them.  this commit removes the link without backticks for the sake of  consistency as discussed here:  change links from github.com to api.rubyonrails.org  the guide's guidelines do not mention anything against linking to the github  repo, but it describes [how to link][] to api.rubyonrails.org works.  so i guess that it's better to link \"api.rubyonrails.org\" when is possible,  for instance: classes, modules, and methods.  [how to link]: ", "linked_issue_titles": "", "title": "fix links inconsistency on active storage overview guide [ci-skip]"}
{"description": " description: add an option to control the percentage of requests we apply fault to using http headers. see #10648 for more details. risk level: low, new functionality. testing: added unit tests docs changes: updated release notes: updated ", "commit_messages": " implement abort request percentage request  format fixes  fix typo  add support for 2 more headers  update docs  update version history ", "linked_issue_titles": "", "title": "control % of requests faults are applied to with http headers"}
{"description": " others others migrate 2.0 api example for gradients and append_backward update api into paddle 2.0 in sample code variable --> tensor refine to display doc zh doc pr: paddlepaddle/docs#2685 ", "commit_messages": " modify sample code  variable -> tensor ", "linked_issue_titles": "", "title": "[api 2.0]migrate api example for gradients/append_backward/program_guard"}
{"description": " i started with @gjedeer 's work and then worked on making tor support more tightly integrated.  since downloadmanager does not let you set the proxy settings, i wrote a basic, custom download manager for downloading over tor.  this does not touch the video streaming at all, so with \"use tor\" enabled, video streaming will not go over tor.  that'll require exoplayer, i think. ideally, newpipe would represent the state of tor in the ui somehow.  orbot will broadcast out the status, and its easy to receive that with a broadcastreceiver.  the open question is how to represent the state of tor in the ux.  the states are off, starting, on, stopping. ", "commit_messages": " test tor code  use httpsurlconnections since youtube.com always uses https  this helps enforce that the connection is encrypted. if for whatever reason  an unencrypted connection is created, an exception will be thrown.  add a title plus summary to \"use tor\" preference  if orbot is installed, then default to using tor  if the user has not changed the \"use tor\" preference, then the default  should be to use tor if orbot is installed. the user can still override it  by going an unchecking \"use tor\".  setup tor at app start, and config immediately when pref is changed  this adds an application subclass to get the oncreate() method, which is  called once at the first start up of the app, before any activity starts.  tor is configured there to ensure it is setup before anything happens.  this also moves the \"use tor\" pref listener to a more appropriate place.  whenever an activity resumes and tor is enabled, request it start  this makes sure that orbot is running when the user expects it to be. if  newpipe is configured to use tor, then going to a newpipe screen should  ensure tor is running.  checking on \"use tor\" when orbot is not installed starts install  if the user turns on \"use tor\" and they are missing orbot, bring them to  the screen to install tor.  android provides global vars for the actual download directories  download files via tor when tor is enabled  downloadmanager does not let you set its proxy or change how it connects to  the internet.  so we have to make a custom one, unfortunately.  this is a  very basic downloader with none of the special sauce that makes the  built-in downloadmanager handy.  make progress notification for tor downloader  (closes #39) ", "linked_issue_titles": "", "title": "tor support for all except streaming"}
{"description": " your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description so when i was working on #17434 i've seen that the read macros have hardcoded little endian and hot fixed that, now i've fixed rest of the hardcoded endianity that was left and added test on big endian ppc64 binary ", "commit_messages": " add line info test, fix rest of endianity problems  add dwarf tests for big endian  add ppc64 register mapping ", "linked_issue_titles": "", "title": "fix big endian dwarf parsing ##bin"}
{"description": " the interesting part of prophetnet is its decoder which can do n-gram causal language modeling. so it could be very interesting to load a pre-trained prophetnet decoder model into an encoder-decoder design with - let's say - a longformer encoder for long-range sequence modeling. due to some narrow-minded thinking on my part, this didn't work previously. from transformers import encoderdecodermodel encoderdecodermodel.from_encoder_decoder_pretrained(\"allenai/longformer-large-4096\", \"microsoft/prophetnet-large-uncased\") as one can see none of pre-trained decoder weights are loaded into the model. the reason is because prophetnetforcausallm was badly modularized in prophetnetforcausallm. merging this pr would make it possible to load any prophetnet decoder into an encoder-decoder model and fine-tuning an \"build-it-yourself\" encoder decoder would become much easier, e.g.: from transformers import encoderdecodermodel import torch model = encoderdecodermodel.from_encoder_decoder_pretrained(\"allenai/longformer-large-4096\", \"microsoft/prophetnet-large-uncased\") input_ids = torch.tensor([10 * [1]]) labels = torch.tensor([10 * [0]]) loss = model(input_ids, decoder_input_ids=labels, labels=labels).loss loss.backward() the above use-case might also be interesting for @ibeltagy actually. breaking changes this does introduce a pretty heavy breaking change to prophetnetforcausallm. however, the only reason this class was created was to make it useable with encoderdecodermodel and this arguably failed a bit the first time since it made it way too difficult to load pretrained prophetnet models into the encoderdecodermodel. i guess i see this more of solving a bug then \"new design\". also there are no pre-trained prophetnetforcausallm models on the model hub and i highly doubt anybody has really used this class. i want to use the same pattern for bartforcausallm and t5forcausallm, so it'd be great to get this merged even though there are some breaking changes. ", "commit_messages": " improve  finish ", "linked_issue_titles": "", "title": "make prophetnetmodel really compatible with encoderdecoder"}
{"description": " in test_runtime_env_complicated.py there is a test that installs an environment while starting other tasks, and checks that the installation does not block the other tasks.  the assert was that ray.get() on the task should return in less than 0.1 seconds.  but in the wild, we've observed a time of 0.157s here  this pr bumps the timeout from 0.1s to 1.0s.  since environments take at least 10-40 seconds to install, even when ray is already in the pip cache, the test still behaves as intended, though if we make future optimizations that bring the env installation under 1 second, this test may start to pass spuriously. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " bump 0.1s timeout to 0.5s  bump to 1.0 ", "linked_issue_titles": "", "title": "partially deflake test_runtime_env_complicated by bumping 0.1s timeout to 0.5s"}
{"description": " correct default return value for softap fix eclipse debug level handling ", "commit_messages": " fix strange eclipse bug debuglevel not accepted when internal name to short?  merge remote-tracking branch 'remotes/esp8266/master'  correct default return value for softap ", "linked_issue_titles": "", "title": "correct default return value for softap + fix eclipse debug level handling"}
{"description": " op(rank_loss) error message enhancement for both c++ and python, and provide unittest. op(similarity_focus) error message enhancement for both c++ and python, and provide unittest. op(squeeze) error message enhancement for c++. ", "commit_messages": " enhance rank_loss error message, test=develop  enhance similarity_focus error message, test=develop  enhance squeeze error message, test=develop ", "linked_issue_titles": "", "title": "op(rank_loss, similarity_focus, squeeze) error message enhancement"}
{"description": " related issue (if applicable): fixes # the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.5 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " use arduino esp32 1.0.5 (= espressif32 @ 3.1.0)  use for esp32 stage git version  disable esp32 stage as default core  use esp32 1.0.5 release ", "linked_issue_titles": "", "title": "use esp32 1.0.5 core (release)"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " add blob & file type for readfile api  blob -> file ", "linked_issue_titles": "", "title": "addblob & file type for readfile api"}
{"description": " fixes #170 by merging in props to link. also fixes the docs to mention that classname can be passed, which was already being merged in link. ", "commit_messages": " [added] support for extra props in links, fixes #170  updated link docs to include the mention of aditional props ", "linked_issue_titles": " dangerouslysetinnerhtml ", "title": "merge props passed to link #170"}
{"description": " should have been only unit tests but then i realized that aspect ratio for none responsive chart was totally broken. so i decided to clean up the whole canvas initialization process and i hope to not have broken too many things :) this pr includes: correctly handles aspect ratio on chart creation (see unit tests for the many cases) properly restore initial canvas render size and overridden style on destroy fix default aspectratio for radar chart and associated samples move most of the canvas initialization in the core.controller.js new test/core.controller.tests.js currently testing ar and responsiveness (see screenshot below) new command switch to run specific tests (gulp unittest --inputs=test/core.controller.tests.js) more details in commit messages ", "commit_messages": " gulp command switch to run specific test files  add the --inputs command switch to the unittest and unittestwatch tasks, to be able to run unit tests from the specified files only (e.g. gulp unittest --inputs=test/core.element.tests.js;test/core.helpers.tests.js).  fix initial aspect ratio when not responsive  when responsive is false and no canvas height explicitly set, the aspectratio option wasn't applied because of the canvas default height. prevent the retinascale method to change the canvas display size since this method is called for none responsive charts, but instead make the resize() responsible of these changes. also, as discussed some time ago, moved most of the core.js logic into core.controller.js. clean up the destroy process and make sure that initial canvas values are properly saved and restored.  fix radar default aspect ratio and samples  now that the aspect ratio is correctly handled, fix samples for charts with aspect ratio of 1 which was vertically too large. also fix the default aspect ratio for radar charts which wasn't applied when creating a chart directly using new chart(ctx, { type: 'radar' }). ", "linked_issue_titles": "", "title": "fix aspect ratio and add responsive unit tests"}
{"description": " it was pointed out in #23030 that we might be able to get rid of our weak linking of getauxval() (have_weak_getauxval) entirely, with only android being a potential holdout: i wonder if it's time to get rid of have_weak_getauxval. i think it's confusing. either we build against a c library that has this functionality, or not. we don't do this weak linking thing for any other symbols and recently got rid of the other glibc backwards compatibility stuff. unless there is still a current platform that really needs it (android?), i'd prefer to remove it from the build system, it has caused enough issues. after looking at android further, it would seem that given we are moving to using std::filesystem, which requires ndk version 22 and later, and getauxval has been available in the since api version 18, that shouldn't really be an issue. support for api levels < 19 will be dropped with the ndk 24 release, and according to one website, supporting api level 18+ will cover ~99% of devices. note that in the ci we currently build with ndk version 22 and api level 28. the other change in this pr is removing the include of headers for arm intrinsics, from the check for strong getauxval() support in configure, as they shouldn't be needed. including these headers also meant that the check would basically only succeed when building for arm. this would be an issue if we remove weak linking, as we wouldn't detect getauxval() as supported on other platforms. note that we also use getauxval() in our rng when it's available. i've checked that with these changes we detect support for strong getauxval() on alpine (muslibc). on linux, previously we'd be detecting support for weak getauxval(), now we detect strong support. note that we already require glibc 2.17, and getauxval() was introduced in 2.16. this is an alternative / supersedes #23030. ", "commit_messages": " build: remove arm includes from getauxval() check  then the check will work on platforms other than arm.  build: remove support for weak linking getauxval()  it was [pointed out in #23030](  > i wonder if it's time to get rid of have_weak_getauxval. i think it's confusing. either we build against a c library that has this functionality, or not. we don't do this weak linking thing for any other symbols and recently got rid of the other glibc backwards compatibility stuff.  > unless there is still a current platform that really needs it (android?), i'd prefer to remove it from the build system, it has caused enough issues.  after looking at android further, it would seem that given we are moving to using std::filesystem, which [requires ndk version 22 and later](  the other change in this pr is removing the include of headers for arm intrinsics, from the check for strong getauxval() support in configure, as they shouldn't be needed. including these headers also meant that the check would basically only succeed when building for arm. this would be an issue if we remove weak linking, as we wouldn't detect getauxval() as supported on other platforms. note that we also use getauxval() in our rng when it's available.  i've checked that with these changes we detect support for strong getauxval() on alpine (muslibc). on linux, previously we'd be detecting support for weak getauxval(), now we detect strong support. note that we already require glibc 2.17, and getauxval() was introduced in 2.16.  this is an alternative / supersedes #23030. ", "linked_issue_titles": "", "title": "improve gexauxval() detection, remove getauxval() weak linking"}
{"description": " the following commits allow micropython to build on openbsd. among other things, fixes #27. ", "commit_messages": " malloc.h is obsolete.  on openbsd map_anonymous is called map_anon.  fix undefined termcap symbols on openbsd.  e.g.:  /usr/lib/libreadline.so.4.0: undefined reference to tgetnum'  /usr/lib/libreadline.so.4.0: undefined reference to tgoto'  /usr/lib/libreadline.so.4.0: undefined reference to tgetflag'  /usr/lib/libreadline.so.4.0: undefined reference to tputs'  /usr/lib/libreadline.so.4.0: undefined reference to tgetent'  /usr/lib/libreadline.so.4.0: undefined reference to tgetstr'  tested on linux too, works.  mention that gnu make is required.  does not build with bsd make. ", "linked_issue_titles": " malloc.h is obsolete ", "title": "make micropython build on openbsd."}
{"description": " this adds an initial dataset.stats() framework for debugging dataset performance. at a high level, execution stats for tasks (e.g., cpu time) are attached to block metadata objects. datasets have stats objects that hold references to these stats and parent dataset stats (this avoids stats holding references to parent datasets, allowing them to be gc'ed). similarly, datasetpipelines hold stats from recently computed datasets. currently only basic ops like map / map_batches are instrumented. todo placeholders are left for future prs. in addition, we also collect statistics about iterator timings (time spent waiting / processing / in user code). here's a sample output of getting stats in one of the most advanced use cases: iterating over a split of a dataset pipeline in a remote task: import ray import time def pause(x): time.sleep(.0001) return x ds = ray.data.range(10000) ds = ds.map(lambda x: str(x + 1)) pipe = ds.repeat(5).map(pause).random_shuffle_each_window() @ray.remote def consume(p, stats=false): for x in p.iter_batches(): if stats: print(p.stats()) a, b = pipe.split(2) ray.get([consume.remote(a), consume.remote(b, true)]) (consume pid=723600) == pipeline window 2 == (consume pid=723600) stage 0 read: 200/200 blocks executed in 0.13s (consume pid=723600) * wall time: 117.63us min, 6.6ms max, 413.57us mean, 82.71ms total (consume pid=723600) * cpu time: 116.3us min, 6.48ms max, 380.74us mean, 76.15ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 1 map: 200/200 blocks executed in 0.3s (consume pid=723600) * wall time: 294.12us min, 2.55ms max, 918.35us mean, 183.67ms total (consume pid=723600) * cpu time: 292.68us min, 829.32us max, 554.42us mean, 110.88ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.41s (consume pid=723600) * wall time: 8.06ms min, 18.29ms max, 9.37ms mean, 1.87s total (consume pid=723600) * cpu time: 572.05us min, 3.43ms max, 992.16us mean, 198.43ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.85ms (consume pid=723600) * in format_batch(): 15.28ms (consume pid=723600) * in user code: 429.99us (consume pid=723600) * total time: 18.07ms (consume pid=723600) (consume pid=723600) == pipeline window 3 == (consume pid=723600) stage 0 read: [execution cached] (consume pid=723600) stage 1 map: [execution cached] (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.46s (consume pid=723600) * wall time: 7.97ms min, 27.64ms max, 9.79ms mean, 1.96s total (consume pid=723600) * cpu time: 592.86us min, 1.75ms max, 1.01ms mean, 201.85ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.2ms (consume pid=723600) * in format_batch(): 10.03ms (consume pid=723600) * in user code: 292.8us (consume pid=723600) * total time: 11.86ms (consume pid=723600) (consume pid=723600) == pipeline window 4 == (consume pid=723600) stage 0 read: [execution cached] (consume pid=723600) stage 1 map: [execution cached] (consume pid=723600) stage 2 map: 200/200 blocks executed in 0.42s (consume pid=723600) * wall time: 8.04ms min, 16.93ms max, 9.48ms mean, 1.9s total (consume pid=723600) * cpu time: 662.75us min, 3.33ms max, 972.26us mean, 194.45ms total (consume pid=723600) * output num rows: 50 min, 50 max, 50 mean, 10000 total (consume pid=723600) * output size bytes: 456 min, 456 max, 456 mean, 91200 total (consume pid=723600) * tasks per node: 200 min, 200 max, 200 mean; 1 nodes used (consume pid=723600) (consume pid=723600) stage 3 random_shuffle_todo: 0/0 blocks executed in -1s (consume pid=723600) (consume pid=723600) dataset iterator time breakdown: (consume pid=723600) * in ray.wait(): 1.18ms (consume pid=723600) * in format_batch(): 9.98ms (consume pid=723600) * in user code: 284.75us (consume pid=723600) * total time: 11.78ms (consume pid=723600) (consume pid=723600) ##### overall pipeline time breakdown ##### (consume pid=723600) * time stalled waiting for next dataset: 2.74ms min, 701.09ms max, 491.05ms mean, 1.96s total (consume pid=723600) * time in dataset iterator: 315.69ms (consume pid=723600) * time in user code: 1.21ms (consume pid=723600) * total time: 5.0s ", "commit_messages": " wip  wip  wip  format  wip  wip  wip  remove  fix  add todo  wip  fix  wip  fix  update ", "linked_issue_titles": "", "title": "initial stats framework for datasets"}
{"description": " @robmadole so this could be merged because upgrading.md and changelog.md are not part of the build system. i'm repeating this so maybe the next time i will remember :) ", "commit_messages": " fix link to upgrading guide  remove caravan code from the table  caravan code didn't change and was not supposed to change because f8ff  is the last available code in the pua ", "linked_issue_titles": "", "title": "bugfix/fix changelog and upgrading guide"}
{"description": " this updates the release notes for the breaking changes to -usehd option and the getinfo rpc. also, bumps the manpages to current master. ", "commit_messages": " doc: bump manpages to 0.15.99  doc: update release notes for 0.16.0 ", "linked_issue_titles": "", "title": "update release notes and manpages for 0.16"}
{"description": " reverts #16535 and #16751 in an effort to fix #17008 and #17006, skips a runtime_env test. ", "commit_messages": " revert \"[core] iterate over entire dispatch queue instead of returning when worker unavailable (#16535)\"  this reverts commit 54d66ac6378ece17d609fae349230ca1bb341742.  revert \"[core] [runtime env] [tests] add c++ unit test for dispatch queue nonblocking behavior (#16751)\"  this reverts commit 13a133817b48a127830778972a71f034029573df. ", "linked_issue_titles": " [placeholder] actor creation tasks very infrequently hang (<0.05% of the time) ", "title": "reverts full dispatch queue iteration prs."}
{"description": " description: first step to configurate lovelace from the ui, adding id's to cards in ui-lovelace.yaml related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " id is added to cards without id in ui-lovelace.yaml when loaded  hound  remove ui-lovelace.yaml ", "linked_issue_titles": "", "title": "adding id to lovelace cards in ui-lovelace.yaml"}
{"description": " case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. ", "commit_messages": " create electronic-json-storage.d.ts  create electronic-json-storage-tests.ts  update electronic-json-storage-tests.ts  update electronic-json-storage-tests.ts ", "linked_issue_titles": "", "title": "type definitions and tests for electron-json-storage"}
{"description": " bug fixes others fix and enable test_multiprocess_dataloader_static random fail fix #25265 not need to keep order if there is only 1 place check thread_done_event on read queue timeout reduce data shape to reduce share memory use for ci only have 64m in /dev/shm tested 1000 times locally, test script as follows: export cuda_visible_devices=0,1 for i in {1..1000} do echo $i make test args=\"-r test_multiprocess_dataloader_static -v\" done ", "commit_messages": " fix test_multiprocess_dataloader_static random fail. test=develop  enable test. test=develop ", "linked_issue_titles": "", "title": "fix test multiprocess dataloader static"}
{"description": " partly extracted and inspired by  the problem in #38226 is that in some corner cases multiple calls to endsnapshot were made concurrently, leading to non-deterministic behavior (beginsnapshot was triggering a repository finalization while one that was triggered by a deletesnapshot was already in progress) fix by: making all endsnapshot calls originate from the cluster state being in a \"completed\" state (apart from on short-circuit on initializing an empty snapshot). this forced putting the failure string into snapshotsinprogress.entry. adding deduplication logic to endsnapshot also: streamlined the init behavior to work the same way (keep state on the snapshotsservice to decide which snapshot entries are stale) closes #38226 note: i ran a few thousand iterations of the snapshotresiliencytests for these changes and they came back green, ", "commit_messages": " fix concurrent ending step 1  reenable test  nicer  worsk  worsk  bck  add asserts  add asserts  remove pointless assert  cleaner ", "linked_issue_titles": " testabortedsnapshotduringinitdoesnotstart fails with classcastexception ", "title": "fix concurrent snapshot ending and stabilize snapshot finalization"}
{"description": " i wasn't aware, but it seems like next doesn't do a fresh build every time next build is run -- unchanged files that have already passed through babel are skipped on subsequent runs. unfortunately, that breaks message extraction (via babel-plugin-react-intl) in this example: on subsequent runs it'll fail to extract messages in unchanged files, leaving the list of strings shorter than it should be (or just completely empty)! this pr fixes that case by simply removing the .next directory before building. it also relaxes the requirement in the helper script forbidding duplicate message ids -- they're allowed if their corresponding messages are identical, which is the same rule enforced by babel-plugin-react-intl on a per-file basis. ", "commit_messages": " remove next folder before build in with-react-intl  relax message id requirement in with-react-intl ", "linked_issue_titles": "", "title": "fix message extraction script on consecutive builds"}
{"description": " this pr adds support for prepending sass code before the actual entry file. it's common for developers to import their sass mixins and variables once on their project config so they don't need to import them on every file that requires it. frameworks like gatsby and nuxt.js already support that handy feature. the way it works is: /// next.config.js module.exports = { experimental: { sassoptions: { prependdata:  /// scss code that you want to be /// prepended to every single scss file. , }, }, } fixes #11617 and duplicates ", "commit_messages": " add support for sass-loader's prependdata option  add integration tests ", "linked_issue_titles": " global sass imports don't work when you use variables, mixins, functions, etc! ", "title": "add support for sass-loader prependdata option"}
{"description": " update of the rgb_led struct layout to a more efficient layout. this improves the key to led lookup complexity from o(n) to o(1), in addition, the usage of the data in the effects is simpler as it removes the need to hoist grabbing data from the struct to use in the effect and allows the compiler to optimize the loop easier. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " initial conversion of the rgb_led struct  converting last keyboard & updating effects to take advantage of the new structure  new struct should not be const  updated docs ", "linked_issue_titles": "", "title": "per led (key) type rgb matrix effects - part 2)"}
{"description": " nesting does not currently work if you set depth to something greater than one. the reason is that self.opts.depth doesn't get set on nestedmodelserializer instances before the instance checks for relationship fields within itself, so those relationship fields do not get instantiated as nestedmodelserializers themselves. def get_fields(self): # add in the default fields default_fields = self.get_default_fields() for key, val in default_fields.items(): if key not in ret: ret[key] = val for key, field in ret.items(): field.initialize(parent=self, field_name=key) return ret when get_default_fields() is called, relationship fields are instantiated as nestedmodelserializers by get_nested_field() if self.opts.depth is set. so with depth=2 let's say you have base_instance, nested_instance_level1, and nested_instance_level2. when nested_instance_level1 is instantiated by base_instance, nested_instance_level2 should also get instantiated in that moment because field processing all happens on init. in other words, when get_default_fields() is called on base_instance, all the nested instances are supposed to get instantiated recursively at that time. however, field.initialize() doesn't get called in base_instance until after get_default_fields. this means that self.opts.depth is not set on nested_instance_level1 when it calls its own get_default_fields, so its relationship fields don't get instantiated as nestedmodelserializers.  base_instance has no trouble instantiating nested_instance_level1 because we pass in \"depth\" through the serializer's meta options. the result is that only the first nesting level gets serialized no matter what you put for depth in the meta options. so two commits here. one reimplements depth handling by setting the depth on the nestedmodelserializer definition in get_nested_field(), ensuring each instance always has self.opts.depth available on instantiation. the other modifies @gkappel's depthtest so that it tests two levels of nesting. ", "commit_messages": " changed depthtest to have depth=2  changed definition of nestedmodelserializer to correct depth handling ", "linked_issue_titles": "", "title": "fix nesting issue with depth >=2"}
{"description": " chart, dashboard, owners, database endpoints are paginated with page_size 20 by default and setting page size to 2000 to get the full list of result change format for start date from dec 18, 2020 to 12/18/2020 01:03:44 pm  test plan manual testing requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " fix: start date format for executation log  fix: paginated query ", "linked_issue_titles": "", "title": "fix start date format and paginated query"}
{"description": " make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. add some description to dubbo-website project if you are requesting to add a feature. if this contribution is large, please follow the software donation guide. ", "commit_messages": " fix addr cache bug  fix router chain loop err ", "linked_issue_titles": "", "title": "fix semaphore usage error when calculating address."}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add attachmentdata to multipart insert method  add attachment insert method return type ", "linked_issue_titles": "", "title": "add attachment type and insert attachment method return type"}
{"description": " fixes #17693 added a test for pr #17713 closes #17713 ready for review ", "commit_messages": " fixed value error for incremental pca  fix flake8 under-indent error  fix flake8 e127  one more flake8 under-indent correction  fixed parenthesis and order of operations for mean_correction  added test for fix incremental pca value error ", "linked_issue_titles": " incremental pca - valueerror: array must not contain infs or nans ", "title": "added test for incremental pca value error fix"}
{"description": " added support to the high-level rest client for the create snapshot api call.  this required several changes to toxcontent which may need to be cleaned up in a later pr.  also added several parsers for fromxcontent to be able to retrieve appropriate responses along with tests. ", "commit_messages": " progress on parsers.  parsing successful with tests.  more progress.  more progress.  more progress.  more progress.  added docs tests.  docs fixes. ", "linked_issue_titles": "", "title": "add create snapshot to high-level rest client"}
{"description": " issue fixed: #3872 eventbridge trigger on localstack defaults to default event bus even though a new one is passed. ", "commit_messages": " add cfn support: kms::alias  fix issues when deploying sls template with custom event bus  * update event::rule service model  * update serverless and plugin version  * update integration test  issue fixed:  #3872 eventbridge trigger on localstack defaults to default event bus even though a new one is passed. ", "linked_issue_titles": "", "title": "fix sls deploy event with custom bus"}
{"description": " for #3947. keep same style with junit's assertthat ", "commit_messages": " use static method for sqlstatementassert  add expected for sqlstatementassert.assertsqlstatement  rename sqlstatementassert.assertsqlstatement() to assertion()  add assertmessage for assertion  remove useless sql case id  use static assert for parametermarkerassert & tableassert  use static assert for projectionassert  use static assert for groupbyassert  use static assert for orderbyassert  use static assert for paginationassert  use static assert for predicateassert  use static assert for insertnamesandvaluesassert  use static assert for altertableassert  rename package of parametermarkerassert ", "linked_issue_titles": "", "title": "use static method for sqlstatementassert.assertis"}
{"description": " xxxxx xxxxx xxxxx follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. run mvn clean install -dskiptests=false & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. ", "commit_messages": " add sync connect to avoid connect failed error  support echo service ", "linked_issue_titles": "", "title": "support triple echo and fix conn bug"}
{"description": " backport pr #31442 to beta ", "commit_messages": " split dummy in region inference graph into distinct source and sink nodes.  why do this: the regiongraph representation previously conflated all  of the non-variable regions (i.e. the concrete regions such as  lifetime parameters to the current function) into a single dummy node.  a single dummy node leads dfs on a graph 'a -> '_#1 -> '_#0 -> 'b to  claim that '_#1 is reachable from '_#0 (due to 'a and 'b being  conflated in the graph representation), which is incorrect (and can  lead to soundness bugs later on in compilation, see #30438).  splitting the dummy node ensures that dfs will never introduce new  ancestor relationships between nodes for variable regions in the  graph.  regression tests for issue #30438.  fix #30438. ", "linked_issue_titles": "", "title": "split dummy-idx node to fix expand_givens dfs"}
{"description": " various changes in support of 5 extruders (augmenting #6264) this should do the trick, completing 5 extruder support. i searched throughout the code for \"e3\" / \"e3\" and made sure that \"e4\" / \"e4\" is also included. if we want to compile a list of changes required to bump the number of extruders, combine this commit with those from #6264. config formatting cleanup apply added ubl options to all configuration_adv.h files ", "commit_messages": " macros to print floats, hiding imprecision  apply ubl mesh bounds to remaining configs  updates to support 5 extruders  patch configs comment formatting ", "linked_issue_titles": "", "title": "more patches for 5 extruders"}
{"description": " feature_segwit.py has tests for some legacy wallet behavior, but otherwise does not really need the legacy wallet. those parts now require --legacy-wallet to be provided (as with other legacy wallet tests). other parts of the test are changed to work with descriptor wallets as well. ", "commit_messages": " tests: use descriptors for feature_segwit multisig setup  when setting up the multisig addresses in feature_segwit.py, use  descriptors rather than addmultisigaddress.  tests: restrict feature_segwit legacy wallet import tests  a portion of feature_segwit deals with the legacy wallet ismine and  import behavior. this is now hidden behind --legacy-wallet  tests: add feature_segwit.py --descriptors to test_runner.py ", "linked_issue_titles": "", "title": "reduce feature_segwit.py usage of the legacy wallet"}
{"description": " this pr changes a bunch of internal code related to data handling, but does not change public apis. adds a new object git_pool which is a paged memory allocator converts attrs and diffs to use git_pool allocator for strings converts revwalk to use git_pool for its lightweight commit objects imports new hashtable implementation from  adds two wrappers for khash tables - git_khash_str and git_khash_oid converts all usage of git_hashtable to khash tables the net effect of these changes is that we should be more memory efficient for small allocations in a number of cases, plus some of the issues with the cuckoo hashing in git_hashtable should go away (e.g. before the khash change, i could not successfully revwalk the core git repo). a note on git_pool usage: it is most appropriate to use pool allocation only when you do not have to free individual objects and want to bulk free everything when you are done. so, for example, all of the small strings that result from loading in a .gitattrbutes file or all of the lightweight commit objects that must be kept in memory during a revwalk are good scenarios. ", "commit_messages": " implement git_pool paged memory allocator  this adds a git_pool object that can do simple paged memory  allocation with free for the entire pool at once.  using this,  you can replace many small allocations with large blocks that  can then cheaply be doled out in small pieces.  this is best  used when you plan to free the small blocks all at once - for  example, if they represent the parsed state from a file or data  stream that are either all kept or all discarded.  there are two real patterns of usage for git_pools: either  for \"string\" allocation, where the item size is a single byte  and you end up just packing the allocations in together, or for  \"fixed size\" allocation where you are allocating a large object  (e.g. a git_oid) and you generally just allocation single  objects that can be tightly packed.  of course, you can use it  for other things, but those two cases are the easiest.  convert attrs and diffs to use string pools  this converts the git attr related code (including ignores) and  the git diff related code (and implicitly the status code) to use  git_pools for storing strings.  this reduces the number of small  blocks allocated dramatically.  convert revwalk to use git_pool  this removes the custom paged allocator from revwalk and  replaces it with a git_pool.  moving power-of-two bit utilities into util.h  adding stash to hashtable implementation  adding a small stash of nodes with key conflicts has been  demonstrated to greatly increase the efficiency of a cuckoo  hashtable.  see:    for more details.  import khash.h from attractivechaos/klib  convert hashtable usage over to khash  this updates khash.h with some extra features (like error checking  on allocations, ability to use wrapped malloc, foreach calls, etc),  creates two high-level wrappers around khash: git_khash_str and  git_khash_oid for string-to-void-ptr and oid-to-void-ptr tables,  then converts all of the old usage of git_hashtable over to use  these new hashtables.  for git_khash_str, i've tried to create a set of macros that  yield an api not too unlike the old git_hashtable api.  since  the oid hashtable is only used in one file, i haven't bother to  set up all those macros and just use the khash apis directly for  now. ", "linked_issue_titles": "", "title": "memory pools and khash hashtables"}
{"description": " some requests can reference index names on a remote cluster, yet most don't. when (locally) authorizing requests that can not reference remote indices, the security code takes a (cached) shortcut to first check if the request is authorized for any index, before doing the in-detail authorization on the actual indices. this pr moves the \"allows remote indices\" property to the indices request away from security code, with the goal that it's useful to non-security code as well (rather than duplicating it in the other places). nb it's rare that non-security code filters requests of different types by this property, if that exists at all. but conceptually i don't think the security code should decide which requests reference remote indices. ", "commit_messages": " make allows remote indices a request property ", "linked_issue_titles": "", "title": "move \"allows remote indices\" to a request property"}
{"description": " @rocketchat/core closes #7408 this feature allows someone with \"view-room-administration\" permission to list all groups with the api call /api/v1/groups.list similar modifications should be done in the other groups api calls to ensure users with the proper permissions can do the same thing via api than with the web interface (such as delete & modify groups) ", "commit_messages": " fix #7408  indent fixes ", "linked_issue_titles": "", "title": "allows admin to list all groups with api"}
{"description": " case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. ", "commit_messages": " added missing attributes for noble peripheral  added new contributor name for reference ", "linked_issue_titles": "", "title": "added missing attributes for noble peripheral class"}
{"description": " with the 'receiver' as an argument and static dispatch. part of ufcs implementation (#16293). r? ", "commit_messages": " allow passing self as an argument to methods  part of ufcs (#16293)  tests  allow self as an arg in extension methods  tests ", "linked_issue_titles": "", "title": "allow calling methods like functions"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add types for ackextension and timesyncextension  use new type definitions in tests ", "linked_issue_titles": "", "title": "add cometd 4.0.0 types for  ackextension and timesyncextension"}
{"description": " add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ok, so this is weird, but this functionality isn't actually documented. segment support told our team about it. include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add updated types for id  add tests ", "linked_issue_titles": "", "title": "update user().id() method to reflect undocumented functionality"}
{"description": " updates xcode_backend.sh to use (mostly) assemble apis. this almost completes the migration, though i still need to move the asset unpack step - this is slightly more complicated due to the module format. should have no new external behavior, but does allow us to more easily wire up new features like font-subset, dart-defines, and obfuscation (which was never implemented for ios?) fyi @dnfield fixes #32925 ", "commit_messages": " [flutter_tools] move ios to assemble  fix dependencies and paths ", "linked_issue_titles": " re-implement existing ios and android build in terms of --legacy flutter assemble targets ", "title": "migrate xcode_backend.sh to flutter assemble"}
{"description": " see the commit messages for more details. ", "commit_messages": " locking system overhaul, add condition variables  this commit simplifies the locking system: ccriticalsection becomes a  simple typedef for boost::interprocess::interprocess_recursive_mutex,  and ccriticalblock and ctrycriticalblock are replaced by a templated  cmutexlock, which wraps boost::interprocess::scoped_lock.  by making the lock type a template parameter, some critical sections  can now be changed to non-recursive locks, which support waiting via  condition variables. these are implemented in cwaitablecriticalsection  and waitable_critical_block.  cwaitablecriticalsection is a wrapper for a different boost mutex,  which supports waiting/notification via condition variables. this  should enable us to remove much of the used polling code. important  is that this mutex is not recursive, so functions that perform the  locking must not call eachother.  because boost::interprocess::scoped_lock does not support assigning  and copying, i had to revert to the older critical_block macros that  use a nested for loop instead of a simple if.  condition variable for outbound connection slots  keep a global counter for noutbound, protected with its own waitable  critical section, and wait when all outbound slots are filled, rather  than polling.  this removes the (on average) 1 second delay between a lost connection  and a new connection attempt, and may speed up shutdowns. ", "linked_issue_titles": "", "title": "condition variables instead of polling"}
{"description": " this extends the current matthews_corrcoef to handle the multiclass case. also fixes #7929 and #8354 the extension is defined here:  (pdf is behind a paywall, but the author has a website with details here  and my implementation follows equation (2) in this paper:  the new implementation can handle both the binary and multiclass case. i've left in the original binary case implementation for now (it is a bit faster and more clear as to what is going on). i've added new tests that inspect properties of the multiclass case as well as ensure that the multiclass case reduces to the binary case. there's not much else to say. this is a pretty straight forward change. ", "commit_messages": " added support for multiclass mcc  cleaned up implementation and referenced original paper  accidently added temporary work ", "linked_issue_titles": " why am i getting 32 bit response for confusion_matrix when all the inputs are 64 bit? ", "title": "added support for multiclass matthews correlation coefficient"}
{"description": " resolve binding pattern before using it fail early if pattern binding is incorrect ", "commit_messages": " [csgen] resolve binding pattern before using it  this change makes constraint generation logic consistent with  how patternbindingentryrequest::evaluate handles pattern binding  entries.  [csgen] fail early if pattern binding is incorrect  it's possible for typechecker::typecheckpattern to produce  either no type or type containing error. that should be detected  early and immediately fail constraint generation. ", "linked_issue_titles": "", "title": "a couple of improvements to pattern binding handling"}
{"description": " this pull request fixes three problems we found in buildkite pipeline 3.0. the first is a missing skip_mac variable on the brew updater step, causing that step to fail any builds started with skip_mac='true'. the second problem was that the contracts builder step had a timeout of 10 minutes, but took about 10 minutes to run. the default timeout for that step has been increased to 30 minutes. the third is that contract builders were incorrectly using the pinned u18 dockerfile. this is changed to the unpinned u18 dockerfile to match the current contracts pipeline. tested buildkite build 16702 buildkite beta build 1839 none. none. none. ", "commit_messages": " add $skip_mac to \"brew updater\" step  increase timeout of \"ubuntu 18.04 - contract builder\" step from 10 to 30 minutes ", "linked_issue_titles": "", "title": "increase contracts builder timeout + fix $skip_mac"}
{"description": " the documentation said gcc >= 8 was needed to build serenity but my current 8.3.0 didn't work. after testing i noticed gcc >= 9 was necessary so i updated the documentation. gcc-9 is only available on debian testing so i added instructions for switching to and from debian testing as well. ", "commit_messages": " documentation: serenity requires gcc 9 or higher  gcc 8.3.0 (which is the current version in debian 10 stable) seems to  fail at building ak. new people might get stuck when they try to run  make inside the ./build folder and fail at building serenity.  documentation: debian gcc-9 installation instructions  we already have installation instructions for ubuntu but not yet for  debian. gcc-9 is not available on debian stable so instructions for  switching to and from debian testing are added. ", "linked_issue_titles": "", "title": "updated gcc version requirement in buildinstructions.md"}
{"description": " during our perf test against elasticsearch, we noticed two synchronized block in the call stack of fetching doc values, which i think is necessary and cause a serious gc issue for us, especially when \"size\" param is large and fetch docvalue fields. there is a synchronized block for getting from fielddatacaches map, which is unnecessary when cache != null. and getforfield method is called for every hit thus blocking at here impact performance a lot. we suggest changing to double checked locking and only do synchronize when cache==null. we see threads waiting on getforfield method in our jfr recording. gradle test all passed in my local. for reference, below is a sample query we used for testing: { \"stored_fields\": \"_none_\", \"docvalue_fields\": [\"user_number\"], \"size\": 33000, \"query\": { \"bool\": { \"must\": [ { \"match_all\":{} } } } } this pr links to #27350 @jasontedor @s1monw ", "commit_messages": " double checked locking  assign to cache  one line  add comment ", "linked_issue_titles": "", "title": "reduce synchronization on field data cache"}
{"description": " i found a few instances http urls and made them into https urls. don't worry, i've tried and tested the new urls and they all work . in the obscure case that you go to one of these urls, i just want to let you know, rest assured, that someone spent half an hour tracking down http urls that should be https that aren't, and manually converting them to https, for your protection (psh, it's not like most browsers these days do it automatically). ", "commit_messages": " update http to https in solarized  upgrade http to https for 'burger in your shell'  upgrade http to https for tmux.github.io ", "linked_issue_titles": "", "title": "a few minor http to https upgrades"}
{"description": " this creates two new documents. \"jsx in depth\" attempts to describe all of jsx, covering the occasionally-relevant edge cases and weird bits. it should be a document you can go to, to get your weird jsx questions answered. \"react without jsx\" just explains how to use react without jsx. some docs in the old site are now obsoleted. \"jsx spread attributes\" and \"jsx gotchas\" along with a number of the jsx-specific tips are just part of \"jsx in depth\" now. i just removed the translations of the no-longer-there docs. dunno what else to do with them. thanks @spicyj for answering a zillion of my jsx questions in person this afternoon ;-) but still i'm sure i am mis-explaining some things here, so i'd appreciate a sharp-eyed review of this content. ", "commit_messages": " get started on jsx  fix the conflict  change title to make downloading easier  react without jsx  be nicer to jsx haters  another chunk of docs  jsx in depth, last bit  roll some tips into the jsx section  fix some subtitles ", "linked_issue_titles": "", "title": "jsx in depth and react without jsx"}
{"description": " stm32h743iit6 arm cortex-m7 run in 400mhz ltdc + onborad sdram + onboard qspi flash direct drive 7 inch (1024 * 600) tft screen (tft_color_ui is now available.  other ui will be compatible and added later) ", "commit_messages": " stepper driver anti reverse protection  biqu-bx variants  sync upstream bugfix-2.0.x  delete anti protect to avoid conflict becasue of upstream will be added first  restore config  stm32h7 spi reg error ", "linked_issue_titles": "", "title": "btt skr-se-bx (stm32h743iit6 arm cortex m7) and biqu_bx_tft70"}
{"description": " just truncate name internally as in iphone to load font with path but you still need to add all fonts to .plist file another version #7557 that load font directly by path you don't even need to add it to plist file merge only one ", "commit_messages": " load font v2  mac fonts tests ", "linked_issue_titles": "", "title": "mac custom font fix v2"}
{"description": " introduces fontconfig, an object that isolates font-related settings in our profiles users can now define font settings in their json as so: \"font\":{ \"face\": \"consolas\", \"size\": 12 } backwards compatible with the currently expected way of defining font settings in the json, note however that upon hitting 'save' in the sui, these settings will be rewritten to the font-object style in the json (as above). #1790 closes #6049 cla signed. if not, go over here and sign the cla documentation updated. if checked, please file a pull request on our docs repo and link it here: #xxx i work here existing functionality works, new functionality works ", "commit_messages": " initial  complete ", "linked_issue_titles": "", "title": "group font options in the json into a single object"}
{"description": " per discussion, adds context=default to file module to specify a return to default selinux context.  drops implicit behavior of reverting selinux context if se* options are removed. ", "commit_messages": " add context=default option to file module  this adjusts behavior of file module such that removal of se* option  does not revert the file's selinux context to the default.  in order to  go back to the default context according to the policy, you can use the  context=default option.  add example playbook of file module's selinux capabilities  add another example to file_secontext.yml  demonstrate what happens when there is no default context in the policy. ", "linked_issue_titles": "", "title": "update secontext behavior in file module"}
{"description": " demo.mov proof of concept for \"wizard\" workflow. features: a super simple reactive store <stepcontainer> and <step> abstraction example usage: <template> <step-container :currentstep=\"step\"> <step :stepnumber=\"1\"> step 1 </step> <step :stepnumber=\"2\"> step 2 </step> </step-container> <button @click=\"step++\"> next step </button> </template> <script> export default { setup() { return { step: ref(1) } } } </script> just need to wrap your component inside <step> and pass a stepnumber prop. it uses a render function - this is a good use case for a render function, since we dynamically filter ctx.props. i think we should use templates where we can, since they give us lots of nice optimizations. ", "commit_messages": " add basic store  add step container and steps  update yarn lock ", "linked_issue_titles": "", "title": "step abstraction wizard for unified gui"}
{"description": " remove trailing whitespace as per the policy established by the meteor style guide. correct a minor spelling error in the find_upwards() comments. ", "commit_messages": " remove trailing whitespace  as per the \"whitespace\" section of the meteor style guide, remove trailing whitespace.    fix spelling error in find_upwards() comments ", "linked_issue_titles": "", "title": "remove trailing whitespace + fix misspelling"}
{"description": " these are unlikely to cause practical issues but after bootstrapping with fuck; fuck shellcheck gave me an error in my bashrc. ", "commit_messages": " fix shellcheck sc2046  further reading:  fix shellcheck 2068  further reading: ", "linked_issue_titles": "", "title": "fix a couple small shellcheck errors"}
{"description": " this pull request introduces /cc to search for instruction while ignoring case. (/ci is occupied but searching immediate value). this pr will help fixing rizinorg/cutter#1594 $ r2 -n /bin/true 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x00001425   # 2: jmp rax 0x00001473   # 2: jmp rax 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x0000528b   # 2: jmp rcx 0x00001425   # 2: jmp rax 0x00001473   # 2: jmp rax 0x00004d0b   # 2: jmp rsp 0x00004d5b   # 2: jmp rsp 0x0000528b   # 2: jmp rcx ", "commit_messages": " introducing /cc for case insensitive  use r_str_ncasecmp ", "linked_issue_titles": "", "title": "introducing /cc for case insensitive instruction search"}
{"description": " add a unit test to callback pattern. assert that the callback method is called using a counter ", "commit_messages": " add unit test to show that the callback method is called.  add unit test to show that the callback method is called. ", "linked_issue_titles": "", "title": "add unit test to callback method"}
{"description": " right now we would mark sitepage as dirty because we generate contentdigest using updatedat field which isn't passed to sitepage node. ", "commit_messages": " don't mark sitepage dirty if just updateat changed  run queued queries only after oncreatenode api ", "linked_issue_titles": "", "title": "don't mark sitepage node as dirty if node data didn't change"}
{"description": " github-pull: #20403 rebased-from: c46c18b github-pull: #20403 rebased-from: 2498b04 github-pull: #20403 rebased-from: 99d56e3 github-pull: #20403 rebased-from: ca8cd89 ", "commit_messages": " wallet: refactor getclosestwalletfeature()  don't upgrade to hd split if it is already supported  it is unnecessary to upgrade to feature_hd_split if this feature is  already supported by the wallet. because upgrading to feature_hd_split  actually requires upgrading to feature_pre_split_keypool, users would  accidentally be upgraded to feature_pre_split_keypool instead of nothing  being done.  fixes the issue described at    wallet: fix and improve upgradewallet result responses  wallet: fix and improve upgradewallet error responses ", "linked_issue_titles": "", "title": "upgradewallet fixes, improvements, test coverage"}
{"description": " this requires making several types trivial and properly initialize them whenever they are called. we can't enable this code-base wide yet due to microprofiler invoking ub on some structures. ", "commit_messages": " core: silence wclass-memaccess warnings  this requires making several types trivial and properly initialize  them whenever they are called.  core/cmake: enforce wclass-memaccess  treat -wclass-memaccess as an error. ", "linked_issue_titles": "", "title": "silence wclass-memaccess warnings and enforce it"}
{"description": " with this pr we always defer resolution of conditional types when one or both of the check and extends types are generic (as determined by typeflags.instantiable). now, only when neither is generic do we perform further assignability checks to see if we can resolve a conditional type. fixes #28824. ", "commit_messages": " resolve conditional type only when check and extends types are non-generic  accept new baselines  add regression test  accept new baselines ", "linked_issue_titles": " nested `exclude` has unexpected behavior ", "title": "defer resolution of conditional types with generic check or extends types"}
{"description": " closes #31469 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " reg: dataframe.__setitem__(slice) is positional, closes #31469  whatsnew ", "linked_issue_titles": " regr: __setitem__ with integer slices on int/rangeindex is broken (label instead of positional) ", "title": "dataframe.__setitem__(slice, val) is positional"}
{"description": " this pr makes the changes needed for #891. it also updates the documentation to reflect the change. ", "commit_messages": " mark command as optional for docker run  docs: mark command as optional for docker run ", "linked_issue_titles": "", "title": "891 mark command as optional for docker run"}
{"description": " khronos webgl group recommend the following sequence when compiling and linking shaders: compileshader(x) compileshader(y) linkprogram(z) check for link errors (and display compilation errors as required). i.e. don't check the shader compilation status unless the link fails. this allows any inherent parallel ability of the browser to be exploited (chrome does overlap shader compilation with main thread execution) and requires fewer webgl calls, but also makes supporting the upcoming khr_parallel_shader_compile extension much easier, and reduces jank when compiling complex shaders. tested with chrome, ff, ie11, and edge. ", "commit_messages": " move error checking and display  add new webgl enum  remove redundant param  mereg  only get errors when required  minor optimisations ", "linked_issue_titles": "", "title": "rework shader compile/link error checking"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #18766 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " node: remove redundant widen of query type to any  node: rename url types for clarity  node: add and share parsedurlquery type ", "linked_issue_titles": "", "title": "remove redundant widen of query type to any + tidy up"}
{"description": " removes the ios8 compat setting and makes ios8 compat behavior the default one adds a setting which allows the user to disable video/pictures airplay capabilities which defaults to on by disabling the new setting from 2. and in combination with the bumped libshairplay from this pr all ios9 users can restore at least music streaming features. though ios9 users will loose any sort of metadata when streaming music (no progress/duration info, no album thumb, no artist, no album, no title). thats as far as we can get atm for ios9 clients. @martijnkaijser is it a problem to reuse those language ids? i guess until the language addons are synced users would get the old text for this setting - right? ", "commit_messages": " [depends/shairplay] - updated libshairplay to the current master which supports ios9 clients (also bumped on win32)  [airplay] - evaluate the new \"enable airplay video and pictures\" setting - this allows the ios9 users to restore at least music streaming capabilities (by disabling video/pictures support)  [settings] - make the ios8 compatibility setting a \"enable airplay video and pictures support\" setting  [airplay] - make ios8 compatibility mode the new default and don't use a setting for it  [airplay] - fixed broken \"stop\" for stopping picture streaming via airplay ", "linked_issue_titles": "", "title": "restore ios 9 music streaming capability"}
{"description": " fix #9627 tensor core example:  enabling tensor core for float16 cudnn conv has been tested to provide significant speedup. ", "commit_messages": " enable tensor core for conv cudnn  fix cpplint error ", "linked_issue_titles": " need to add tensor core support for conv cudnn op ", "title": "enable tensor core for cudnn conv"}
{"description": " support for multiple pid default values was recently added, but the configuration option was never documented in configuration.h. makes this feature discoverable to users. n/a #17738 ", "commit_messages": " add multiple pid defaults to configuration  add test for multiple pid defaults ", "linked_issue_titles": "", "title": "add multiple pid defaults to configuration.h"}
{"description": " adds buck files for nuclide integration support fixes some pzstd includes and shortens the tests a little bit ", "commit_messages": " improved zstd_compressblock_opt_extdict_generic  job_number -eq 9  .travis.yml: test jobs 12-15  .travis.yml: optimized order of short tests  .travis.yml: different tests for \"master\" branch  fixed  improved #232 fix  add buck files for nuclide support  clean imports and shorten tests  * dev:  updated news  fixed msan warnings in legacy decoders  fix cmake build  updated news  edits as per comments, and change wildcard 'x' to '?'  fix visual studios project  fix pool.c threading.h import  fix zstdmt_compress.h include  fixed commented issues  updated format specification to be easier to understand  improved #232 fix  fixed  .travis.yml: different tests for \"master\" branch  .travis.yml: optimized order of short tests  .travis.yml: test jobs 12-15  job_number -eq 9  improved zstd_compressblock_opt_extdict_generic  revert unnecessary change to logging.h ", "linked_issue_titles": "", "title": "add buck files for nuclide integration"}
{"description": " note that i have changed the security handshaker code to accept a read buffer containing leftover bytes read by the generic handshakers, but i haven't bothered to allow passing leftover bytes from the security handshaker to the transport code.  i think that shouldn't be necessary, because the security handshakers all create wrapped endpoints, so they handle the leftover bytes internally.  (of course, this issue will go away once we get around to converting the security handshakers to use the new api.) this is yet another small piece of #7507. ", "commit_messages": " change handshaker api to use a read buffer to pass leftover bytes read  between handshakers.  updated tests.  clang-format ", "linked_issue_titles": "", "title": "change handshaker api to support passing leftover bytes read between handshakers."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. hello! naver whale is chromium based browser. this browser has a slightly different extension api than the existing browser. check this this code is based on chrome/index.d.ts. removing and adding some definition. the comment i added are in korean. because it only supports korean in official documents. ", "commit_messages": " add new package: naver-whale  change ts version ", "linked_issue_titles": "", "title": "adding types for naver whale extension"}
{"description": " i hereby agree to the terms of the cla available at:  fix cannot find column error for queries with sampling. was introduced in #24574. fixes #26522 ", "commit_messages": " fix unknown column bug in sampling.  fix unknown column bug in sampling. ", "linked_issue_titles": " 21.7+ cannot find column in source stream in a query with sampling ", "title": "fix unknown column with sampling"}
{"description": " been using these types on a project for work for the last ~3 weeks. have been going well so far! ", "commit_messages": " added stripe-node typings for webhook verification  - see example on the stripe-node github for webhook signing here:  updated stripe-node types version ", "linked_issue_titles": "", "title": "stripe-node updated typings for webhook verification"}
{"description": " added a bigquery operator to transfer data to google cloud storage. also added a hook for gcs, and an operator to download files from gcs to local file system. ", "commit_messages": " add bigquery to google cloud storage operator.  more documentation for bigquery to gcs operator. ", "linked_issue_titles": "", "title": "bigquery and google cloud storage operators"}
{"description": " since esp32 build variants are normal builds. activating esp32 build variant selection moved to platformio_tasmota32.ini so all esp32 standard definitions are there. all variants can now be builded without changing setup files. platformio_override.ini is now needed only for special use cases the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " update platformio.ini  make selecting esp32 versions possible  without using override file ", "linked_issue_titles": "", "title": "move esp32 build variants selection out of pio override file..."}
{"description": " we are checking device names in addition to major/minor numbers to ensure we distinguish devices from each other. fixes #10841 component name diskstats module of proc plugin check if all diskstats charts are available for all disks in the system. verify if the names of charts and families are correct. ", "commit_messages": " check disk name in mountinfo  check disk name when searching for the disk  check disk name on renaming ", "linked_issue_titles": " incorrect disk identification in the diskstats plugin ", "title": "check device names in diskstats plugin"}
{"description": " hello, i already made a pr some time ago (pr #1713) that allows to install module from .tgz packages (generated with the npm pack command). but there is a little issue: when updating a package with the pm2 install foo.tgz command, it does not updates the package and it starts a new instance of the already installed package. this pr fixes this issue. regards, ", "commit_messages": " do not display output on pm2_silent  pm2_silent  upgrade yamljs to 0.2.7  npm publish 1.1.1  fix: allows to update an installed module from a tgz package ", "linked_issue_titles": "", "title": "allows to update packages from tarball generated with 'npm pack'"}
{"description": " this pr is for the gatsby-image plugin. placeholders and layout-adjusting elements are unnecessary in the accessibility tree, so i have removed them using the aria-hidden attribute. this prevents assistive technologies from recognizing blank elements.   fixes #20181 ", "commit_messages": " fixed  fixed index and added testing ", "linked_issue_titles": " [gatsby-image] fluid image has a blank accessibility element ", "title": "added aria-hidden attribute to layout elements"}
{"description": " this will resolve issues around circular dependency management. it will also make sure that the integration_test package is tied tightly to api changes in the flutter sdk at a specific version. @nturgut @yjbanov @jonahwilliams ", "commit_messages": " migrate integration_test to flutter repo  run the tests ", "linked_issue_titles": "", "title": "move package:integration_test to flutter/flutter"}
{"description": " hello, i humbly request that my nordic layout for the ut47 be merged with the main repository. i've played around with it and made some changes i think would be valuable to other nordic ut47 users out there. a basic description of the layout, in addition to a somewhat large .png file with an overview of the keymap is included in the readme.md file. as a side note: my experience with keymap files is quite limited, and there is a chance that my code can be trimmed (especially at the top in the definitions), any suggestions are welcome. thank you for your time! ", "commit_messages": " pulling updated master  add files via upload  added a nordic layout for ut47  update readme.md  update readme.md  update readme.md  update readme.md  update readme.md  update readme.md  update readme.md  add files via upload  update to readme and keymap files  update readme.md  changed cover image  update readme.md  typo fix  delete config.h  delete keymap.c  delete readme.md  delete rules.mk ", "linked_issue_titles": "", "title": "adding a nordic layout for ut47"}
{"description": " fixes #8827 some baselines unrelated to the changes i made have been modified or even deleted. for example report an error when compiler-options input is empty object.errors.txt was deleted but i can't seem to locate the test even in master. ", "commit_messages": " add new error for rest parameters  add error message for rest parameter properties ", "linked_issue_titles": "", "title": "new rest parameter properties error message"}
{"description": " use public paths in module augmentation test documented module augmentation / we have a notion of what we consider \"public paths\". however, this does not apply to type imports which makes it harder to teach (\"ok here, but not ok there\"). since we already make types public by documenting that the paths are public we might as well export them directly which means we can simplify how we teach public paths. the existing patterns continue to work but are more likely to break during refactoring. the patterns we now document are tested in ci and therefore a lot more robust. implementation choices separate script does not slow down test:unit allows parallel testing (which we haven't set up for mocha) can be included in test suite that runs with typescript nightlies ", "commit_messages": " [core] simplify module augmentation  test in ci ", "linked_issue_titles": "", "title": "support public paths in module augmentation"}
{"description": " with this pr, when a node is the left hand expression of a property access, element access, or call expression, and the type of the node includes type variables with constraints that are nullable, we fetch the apparent type of the node before performing control flow analysis such that narrowings apply to the constraint type. for example: type item = { (): string; x: string; } function f1<t extends item | undefined>(obj: t) { if (obj) { obj.x;     // ok obj[\"x\"];  // ok obj();     // ok } } prior to this pr, the property access, element access, and call expressions above were errors. fixes #14091. fixes #14415. ", "commit_messages": " obtain apparent type before narrowing type variables  new behavior only for type variables with nullable constraints  add tests ", "linked_issue_titles": "", "title": "improve type guards for type variables"}
{"description": " please merge both commits separate. first commit: refactored the api layer: do not handle api response after pipelining this has a big underlying problem each task in the pipeline can modify the options e.g. add a proper permission context if we chain after the pipeline, we don't have access to the modified options object and then we pass the wrong options into the tojson function of a model the tojson function decides what to return based on options this is the easiest solution for now, but i am going to write a spec if we can solve this problem differently if we want to use the tojson function to determine which model fields to return, we cannot do that without this change! note: i thought about a util for the response format, but i decided against at the moment, because i am not sure if we have to change a fundamental concept of how the api works (who returns what, who returns json, how do we guarantee that the options object is everywhere accessible, how are headers generated etc.). see for example this here - it only happens because the outer api level wants to add headers based on the state of a model. second commit: removed bypassing option filtering in user model the tests were red on the first and i investigated why i had to create a pr with both commits, because the second commit is a result of the correctness of the first commit the logic in the user model bypasses filtering options! that is wrong, because if we filter out certain options e.g. include the tests from the previous commit fail because of this if we don't fix this logic, the tests won't pass, because as said, you can bypass certain logic e.g. remove roles from include this has worked before, because we passed the wrong options via the api layer was introduced here 014e2c8, because of #6122 add proper tests to proof that these queries work!! ", "commit_messages": " refactored the api layer: do not handle api response after pipelining  no issue  - this has a big underlying problem  - each task in the pipeline can modify the options  - e.g. add a proper permission context  - if we chain after the pipeline, we don't have access to the modified options object  - and then we pass the wrong options into the tojson function of a model  - the tojson function decides what to return based on options  - this is the easiest solution for now, but i am going to write a spec if we can solve this problem differently  removed bypassing option filtering in user model  no issue  - the logic here bypasses filtering options!  - that is wrong, because if we filter out certain options e.g. include  - the tests from the previous commit fail because of this  - if we don't fix this logic, the tests won't pass, because as said, you can bypass certain logic e.g. remove roles from include  - this has worked before, because we passed the wrong options via the api layer  - was introduced here  - add proper tests to proof that these queries work!! ", "linked_issue_titles": "", "title": "api layer refactoring && avoid bypassing filtering options in user model"}
{"description": " updated the pinout for the rgb led strips for the saturn60 updated the layouts because there were major changes to the pcb electrical matrix added more keymaps to cover the main layouts and updated via keymap updated the info.json file for the qmk configurator to support the new available layouts my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " added iso, utilitarian layouts and updated rgb pin position  added info.json and added updated keymaps  [keymap] updated tsangan keymap and added birgus special ", "linked_issue_titles": "", "title": "titan60 led and keymap updates"}
{"description": " this pr has two changes to the pins_cohesion3d_remix.h file: an sd card section was added.  if sdsupport and lpc_sd_onboard are enabled in the config files then the onboard sd card will be available to both the usb virtual disk and to marlin.  the lcd's sd card can not be made available because this card uses the same spi pins for both sd cards. a fysetc minipanel 12864 section was added.  a custom exp2 cable is required because the sck and mosi on the card's exp2 connector are shared with the onboard sd card.  if rgb operation is required then a custom exp1 cable is needed because the card's exp1 connector doesn't run signals to the rgb pins.  all custom pins come from the ethernet connector. also added logical pin maps for the ethernet, exp1 and exp2 connectors. ", "commit_messages": " 1) enable onboard sd card acess, 2) add fysetc minipanel 12864 pins  set the neopixel pin to the correct pin ", "linked_issue_titles": "", "title": "cohesion 3d remix onboard sd card, fysetc minipanel"}
{"description": " to fix some ci failures. for details see the commit messages ", "commit_messages": " cmake: fix a libswift bootstrapping problem with -enable-array-cow-checks  the checks must not be enabled in the first 2 bootstrapping stages.  revert \"disable cow checks for some bots to unblock ci\"  this reverts commit fb77d2ea4e25bb6822e78e274c9c05a3a67073be.  cmake: clean bootstrapping modules when compiling with boostrapping-with-hostlibs  in this build mode there must not be a swiftmodule in the bootstrapping directories.  in case such a module is there from a previous \"bootstrapping\" build, give a warning and remove it.  build-presets: don't fully bootstrap when doing a check-incremental on the stdlib ", "linked_issue_titles": "", "title": "fix some problems related to bootstrapping"}
{"description": " really simple so don't need a readme notes ", "commit_messages": " added definitions for source-map-support  added definitions for detect-indent  added definitions for open  added definitions for exit  added definitions for mkdirp  added definitions for gracefull-fs  added definitions for jsesc  added definitions for assertion-error  added definitions for buffer-equal ", "linked_issue_titles": "", "title": "added definitions for a batch of small npm modules"}
{"description": " fixes a failure of proj.android/build_native.py when there are spaces in the folder path. ", "commit_messages": " updates  fixed failure in call to make when the android app folder contains spaces in the path. ", "linked_issue_titles": "", "title": "android build_native.py with spaces in path"}
{"description": " this pr resolves the issue #35628. the two places where there were descriptions about returned params were inconsistent. i have made them consistent w.r.t. code. ", "commit_messages": " untracked files  merge remote-tracking branch 'upstream/master'  stack dump detached  gradient doc changed ", "linked_issue_titles": "", "title": "gradient doc changed to accurately show the returned params"}
{"description": " backport 46062 - fix calling deprecate with correct arguments to 2.6 basic.py ansible version ansible 2.6.7 ", "commit_messages": " fix calling deprecate with correct arguments (#44726)  this fixes #44702  (cherry picked from commit 66eec42f53462e931030b26011054acdcb1febcc)  backport pr#44726 - fix deperecate call ", "linked_issue_titles": "", "title": "backport/2.6/44726 fix calling deprecate with correct arguments"}
{"description": " (replaces #369) fixing several merge issues: sidebar width:  selectbox on sidebar:  deck height:  graphviz charts are centered instead of left-aligned a lot of elements are now wider than they used to be. sidebar color vegalite chart width broken message_deduping.py e2e test bad media breakpoint in sidebar.tsx get dataframe(..., height=foo) working again ", "commit_messages": " fix cypress test  fix margin problem  restore defaultpropsfor deckglchart  restore padding  fixing popover  fix sidebar widget z-index without hack  center icons  fix \"for teams\" url  temporary fix for graphviz chart alignment.  don't use two-letter class name \"oi\" for open iconic as it can clash with styletron  fix sidebar color when screen is narrow  fix left and right padding in main content area.  fix sidebar expand/collapse icon color.  fix vegalite chart dimensions  fix message_deduping e2e test, and rename .stfullscreenframe to .fullscreenframe since it's not an st element. ", "linked_issue_titles": "", "title": "fix broken code from typescript pr"}
{"description": " this pr makes the tf transfoxl model compliant with amp. all the slow tests are passing as well for these models. these two models cannot be xla compliant for now, as it seems that tf.where cannot be used in xla if the x and y parameters are none. see the _get_global_attn_indices method which has this case. i have opened an issue on the tf repo in order to ask if it is an expected behavior or a bug. ", "commit_messages": " fix amp  apply style ", "linked_issue_titles": "", "title": "making tf transfoxl model compliant with amp"}
{"description": " this pr adds three things, refactors the socket and h2o_conn_t, adding get_peername callback to obtain the peer address (instead of providing a pointer to struct sockaddr) adds get_sockname callback to obtain the local address the fastcgi handler uses get_sockname callback to build server_addr and server_port properties of fcgi_params amends #346 ", "commit_messages": " provide callback for obtaining peer address _and local address_  emit server_addr and correct server_port to fcgi_params ", "linked_issue_titles": "", "title": "provide getsockname and getpeername wrappers (send server_(addr|port) to fastcgi)"}
{"description": " note that this is an api change for 5.0.0, but fixes compatibility with the 4.1 branch. see pull request #2971. ", "commit_messages": " add rowattributes getter to pageiterator  [sw]: cherry-picked commit from 4.1 branch  format code with clang-format ", "linked_issue_titles": "", "title": "add rowattributes getter to pageiterator and format code"}
{"description": " going through the tests in tests/scalars, tests/indexes/datetimes, tests/indexes/timedeltas, tests/indexes/period, there is a lot of duplication and a lot of thematically inappropriate placement.  this is a natural result of tests being added over the years. one result of this, though, is that its easy to miss certain corner cases (#17991, #7996). there are two things i'd like to do here.  first is gather tests specific to tslibs modules so they can be self-contained.  this pr starts that for tslibs.parsing. second is to go through tests.indexes centralize arithmetic tests, deduplicate where needed (#18026).  this is a big task without an immediate payoff, so i want to get the go-ahead before jumping in. tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " move tests specific to tslibs.parsing  whitespace cleanup ", "linked_issue_titles": "", "title": "separate tests specific to tslibs modules"}
{"description": " step 1 in the compatibility steps for the manylinux / pip10 conversion next step - drop vendored pip9, patch and vendor pip10 ", "commit_messages": " drop cacert.pem copy task from vendor script  update patched version of pip-tools for vendoring  update piptools patch  update patches  revendor piptools for update ", "linked_issue_titles": "", "title": "update piptools (work in progress)"}
{"description": " in setup where resources are distributed into nested stacks, api gateway resource may not be present in main stack. with #7663 we've changed behavior, and assume there's no api gateway if it doesn't appear in main stack. still it broke for services relying on e.g. serverless-plugin-split-stacks plugin. this patch ensures that if there are http events configured we unconditionally attempt to find the rest api id and it's deployment. additionally improved configuration check to be based on deployment id and not just rest api id (if there's no deployment, then we're also incapable on applying any stage settings) ", "commit_messages": " fix(aws api gateway): improve configuration validation  confirm on deployment not just rest api  fix(aws api gateway): fix handling stage settings when in nested stack  uncoditionally search for rest api if http events are configured ", "linked_issue_titles": "", "title": "fix handling of stage specific setting for split stacks case"}
{"description": " it seems that all bounds in type aliases are entirely ignored, not just type bounds. this extends the warning appropriately. i assume this should be made a hard error with the next epoch? i can't see any reason to accept these programs. (and suddenly enforcing these type bounds would be a breaking change.) ", "commit_messages": " clarify 'trait bounds ignored' wording  warn about more ignored bounds on type aliases ", "linked_issue_titles": "", "title": "warn about more ignored bounds in type aliases"}
{"description": " this series of commits deals with broken links to the source code. it also refactors some repetitive codes from rustdoc. the most important commit, 1cb1f00, describes the rationale; this will fix a half of #16289. other commits are reasonably independent to each other and can be made into indiviudal prs at the request. notes on the broken source links as of bda97e8 (i've used this to check the pr works as intended), there are 281 (!) such broken links. they can be further classified as follows: 178 links to incorrect item types. this is the first half of #16289, and this pr fixes all of them. 89 links to redirect pages. they are not technically \"broken\" but still doesn't give a source code. i have a fix for this in mind, which would make a redirect page slightly fat. 14 links to incorrect defid in the gotosrc parameter. this is #15309, and affects many liballoc reexports in libstd but nothing else (curiously). i'm yet to track this down; might be a metadata bug (not sure). 0 links to the crate reexported as a different name. this is the second half of #16289, and seems not hard to fix but i'm running out of time. prevalence of this kind of bugs calls for a full link verifier integrated into the testing process. :s ", "commit_messages": " rustdoc: fixed a missing rendering of foreignstaticitems.  rustdoc: refactored various uses of itemtype.  in particular, itemtype variants are no longer reexported. since  we already do namespace them via item_type mod, it's fine.  rustdoc: removed foreign{function,static} item types.  they are just (unsafe) functions and static items to most users  and even compilers! the metadata doesn't distinguish them, so rustdoc  ended up producing broken links (generated ffi.*.html, links to  fn.*.html). it would be best to avoid this pitfall at all.  rustdoc: avoid rendering foreign items to the sidebar.  otherwise the generated documentation is 30% larger. the sidebar  renders an entry for each item to all items, so large modules have  o(n^2) items rendered in the sidebars. not a correct solution, but  at least it works. ", "linked_issue_titles": "", "title": "remove foreign{function,static} item types"}
{"description": " previously: a node was considered an orphan if there were no inbound edges of any kind. however, all edges could be cyclic, with no path to the root. now: if the graph has a root node and there is a path to the root node, then it will not be considered an orphan. test plan: added unit tests note: this slows bundling down by 2.5x, but so far bundling seems to be the only thing impacted on the initial build. we will follow with performance optimization for bundling. ", "commit_messages": " isorphanednode checks for path to root  iterate nodes to copy instead of traversing ", "linked_issue_titles": "", "title": "isorphanednode checks if there is a path to the root"}
{"description": " resolves #150. this pr introduces a solution to the long-standing problem of wanting to use @apply with classes that don't exist in the same css tree. this issue most commonly comes up when someone is working with vue and wants to use @apply in the <style> block of a single file vue component. it seems like basically every vue project is setup to run postcss on every <style> block independently instead of on the final concatenated css, which means if you have 100 components, tailwind is run 100 independent times, and each run is isolated and can't see any of the classes in the other runs. this pr solves this by always generating all of tailwind's utilities (including those registered by plugins) and using it as a fallback table for @apply if the class can't be found. i'm not ready to fully commit to this without getting folks to try it out and report feedback, so this pr only enables this functionality if you add an experiments key to your tailwind config file: module.exports = { // ... experiments: { shadowlookup: true } } because this is an opt-in experiment, it's going to remain undocumented outside of this pr for now, and i reserve the right to yank it or break it without following semver, so please don't rely on this functionality for production sites right now, just test it out locally and give me your feedback. ", "commit_messages": " fallback to shadow table  refactor duplication  only enable shadow lookup if shadowlookup experiment is enabled ", "linked_issue_titles": " consider not relying on previously defined mixin in file for \"@apply\" ", "title": "allow @apply-ing utility classes that aren't explicitly defined but would be generated"}
{"description": " description: reland: #67155 fixes analysis error caused by landing of material migration, and g3 error caused by moving of fuchsia lib. ", "commit_messages": " [null-safety] migrate app dependencies of flutter driver  remove wrong headers  update analysis_options.yaml comment  update web smoke test  fix cirrus yaml  fixes for material migration and g3 ", "linked_issue_titles": "", "title": "migrate app side flutter driver to null-safety"}
{"description": " this pr adds the abilility to override custom extension attributes during merging. this will only work for attributes that are writable, i.e. attributes registered with a default value like default=false or attribute that have both a getter and a setter implemented. token.set_extension('is_musician', default=false) doc = nlp(\"i like david bowie.\") with doc.retokenize() as retokenizer: attrs = {\"lemma\": \"david bowie\", \"_\": {\"is_musician\": true}} retokenizer.merge(doc[2:4], attrs=attrs) assert doc[2].text == \"david bowie\" assert doc[2].lemma_ == \"david bowie\" assert doc[2]._.is_musician enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " add helper to check if underscore attr is writable  allow overwriting extension attributes during merging (see #3314)  validate extensions first and fix bulk merge  fix whitespace  support custom attributes in retokenizer.split ", "linked_issue_titles": "", "title": "allow setting of custom attributes during retokenization (closes #3314)"}
{"description": " also covers all related articles (bael-3976) all tests pass (all manual) added docker command line in comments in each test to be up and runing quickly upgraded code and dependencies to spring-data-elasticsearch-4.0.0 (released last week) and elastic search 7.6.2. caot be more up to date than that. ", "commit_messages": " upgraded libs, moved to resthighlevelclient  fixed tests  fixed tests  fixed format  removed articleservice  fixed most tests  fixed mapping and tests  fixed formatting according to eclipse formatter  upgrade to 4.0.0.release  added back elasticsearch dependency  removed unecessary dependencies  removed unecessary dependencies ", "linked_issue_titles": "", "title": "bael-3676 fix failing manual test in sping-data-elasticsearch module"}
{"description": " pr for issue #3788 current implementation adds a new jsxnamespace compile option that can specify the jsx namespace (factory) when jsx mode is react. --jsx react --jsxnamespace mydomlib results in emits being mydomlib.createelement i was thinking an alternative would be to just use the existing --jsx option where \"preserve\" and \"react\" are special reserved values. in this setup the above would be achieved by just doing -- jsx mydomlib ", "commit_messages": " initial check in - support other jsx factories issue #3788  - added jsxnamespace compile option  - when jsx mode is \"react\", jsxnamespace optionally specifies the emit namespace for react calls, eg \"--jsxnamespace mydomlib\" will emit calls as mydomlib.createelement (instead of react.createelement)  - symbol specified by jsxnamespace must be present, else compile error is generated (same handling as is done for react symbol when no jsxnamespace is specified) ", "linked_issue_titles": "", "title": "support for other jsx factories"}
{"description": " fixes issue: #2528 added search parameters for the following files: binomial coefficient boolean parenthesization box stacking coin change edit distance ", "commit_messages": " add search parameters for binomial coefficient  add search parameters for boolean parenthesization  add search parameters for box stacking  add search parameters for coin change  add search parameters for edit distance ", "linked_issue_titles": "", "title": "add search parameters for some dp problems"}
{"description": " i had somehow missed #4510 and was a bit surprised to find out about this undocumented hack to get featuregroup to work. thinking about it, i think the approach in itself is sane, but the real problem lies in the naming of the event property - layer is very specific to featuregroup's utilization of the property. on the other hand, there's probably a lot of code out there that use this property, so i'm going for deprecating this property, although actually removing it is not something we need to do soon. instead, i added two properties: sourcetarget - this is the original target of the event, the object it was first fire on before any propagation occured propagatedfrom - this is exactly the same as the current layer; that is, the previous object in the chain of object propagating the event (to be honest, i don't feel 100% about the name of this property, so feel free to suggest a better one) ideally, we should have made this analog to the dom's target and currenttarget, but we already use the property target with the same semantic as the dom's currenttarget, so that will unfortunately not work. ", "commit_messages": " add sourcetarget and propagatedfrom to events  also documents events' target, sourcetarget, propagatedfrom  and layer properties.  fixes #4510.  use propagatedfrom, which is equivalent of the original code ", "linked_issue_titles": "", "title": "clean up and document event propagation properties"}
{"description": " let security_connector mange the pending handshakes on server side remove tcp argument in handshake_done callback signature add a security_connector_shutdown api add a handshake_shutdown api to shutdown tcp do nothing if handshake_done with ok status and null endpoint ", "commit_messages": " move pending tcp management from server to connector  make security_connector manage pending handshaker, while handshaker owns tcp  format ", "linked_issue_titles": "", "title": "refactor security connector and handshake"}
{"description": " allow using a custom host name for endpoints and health checks. this enables auto host re-write to work with eds risk level: low, new opt in field. testing: unit tests docs changes: inline docs in the protocs. release notes: added to version_history.rst fixes #10408 ", "commit_messages": " code  test  fromat fix  format  unit test  version history ", "linked_issue_titles": " eds: support auto host re-write ", "title": "introduce hostname for endpoints and health checks"}
{"description": " easy answers to where tslib.ints_to_pytimedelta and tslib.normalize_date belong, so this moves those. starts populating the tslibs.__init__ namespace; leaves updating imports for later. cleans up a couple of unnecessary imports elsewhere. ", "commit_messages": " move ints_to_pytimedelta, normalize_date, fixup imports and tests  extra import ", "linked_issue_titles": "", "title": "implement tslibs.__init__, move easy bits of tslib"}
{"description": " description: adds rtsp stream support for uvc (unifi video client) integration. returns 1 of the 3 rtsp uris that already existed in the camera object; prioritizes highest quality rtsp stream from the available enabled streams. **pull request with documentation for home-assistant.io (if applicable): not needed. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: ", "commit_messages": " add support_stream to supported_features.  implement stream_source with channel rtsp uris.  add tests for stream support.  make stream_source async.  removed unused import. ", "linked_issue_titles": "", "title": "add rtsp stream support for uvc (unifi video client) integration"}
{"description": " adds a websocket command to fetch the openzwave network statistics local tests pass. your pr cannot be merged unless tests pass i have followed the development checklist the code has been formatted using black (black --fast homeassistant tests) i have reviewed two other open pull requests in this repository. ", "commit_messages": " add network_statistics websocket command  add tests ", "linked_issue_titles": "", "title": "add ozw network_statistics websocket command"}
{"description": " i hereby agree to the terms of the cla available at:  changelog category: translation for #9983 ", "commit_messages": " docsup-1062 (#112)  * added first draft  * minor fixes  * fixed anchors  * yet another fixes  * and the minorest fixes  * apply suggestions from doc review  * fixed terminology in ru (access entity, throws exception)  * fixed typo  * fixed typo  fixed link.  clickhousedocs-626: fixed links. ", "linked_issue_titles": "", "title": "en review, ru translations for rbac docs"}
{"description": " this updates the gles rendering methods to use cpicturebuffer like the gl rendering method does. this will be needed for getting and transferring colourspace information ", "commit_messages": " linuxrenderergles: update yuvbuffer to cpicturebuffer  renderermediacodec: update yuvbuffer to cpicturebuffer  renderervaapigles: update yuvbuffer to cpicturebuffer  renderervtbgles: update yuvbuffer to cpicturebuffer ", "linked_issue_titles": "", "title": "update rendering method to use cpicturebuffer"}
{"description": " this pr will begins the first steps of moving dashboard into spa while using the new dashboard api's dashboard/:id/charts and /dashboards/:id. thanks for @suddjian for the pairing! :) test plan updates to existing tests and end tests as need. requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " add hook for future async api calls  test to see conflict  add async middleware and update reducers  working async dashboard load  implement getcharts api  add user permissions to explore and dashboard bootstrap data  integrate api calls with getinitial state  update namings  accept an id or a slug in the dashboard charts api  add permissions function  fix merge ", "linked_issue_titles": "", "title": "refactoring dashboard to use api's instead of bootstrapdata"}
{"description": " hi, this pull request fixes issue #1002 by adding a new cmake flag nv_caffe and #ifdef where needed to distinguish between the standard caffe and nvcaffe. this has been tested with the official nvidia docker image nvcr.io/nvidia/caffe:18.12-py2. do you think it would be possible to test this automatically using travis too? i'm happy about any feedback. ", "commit_messages": " add flag to use nvcaffe instead normal caffe  add installation details for nv_caffe flag ", "linked_issue_titles": "", "title": "add support for nvidia nvcaffe"}
{"description": " small addition, we need to set priorities for a couple of our deployments, such as keycloak. @unguiculus it adds priorityclassname as a field to the values and template, this allows us to prioritize keycloak deployment over other applications on our cluster, as they depend on keycloak for logging in anyway. dco signed ", "commit_messages": " added priorityclassname as option  added docs and changed values.yaml  bump keycloak chart version ", "linked_issue_titles": "", "title": "add priorityclassname as option to keycloak"}
{"description": " this pr is a first cut at support multiple-block returns. it changes the data model to allow multi-block returns, but does not implement it yet for any tasks. part 1/3 of #18317 skipping test test_dataset_pipeline.py::test_pipeline_actors is blocked on #19659 ", "commit_messages": " wip  wip  wi  wip  wip  wip  fix shuffle  wip  wip  update  update  update  format  update  updae ", "linked_issue_titles": "", "title": "initial pass at support multiple-block returns for read and transform tasks"}
{"description": " backport of #40725 this can wait until 2.6.0 is released before merging into stable-2.6. win_group_membership ansible version 2.6 ", "commit_messages": " refactor/fix win_group_membership to use sids for internal comparisons (#40725)  * refactor win_group_membership to use sids for comparisons instead of name parsing  * carry over previous doc cleanup changes  * remove trailing whitespace from docs  (cherry picked from commit bcb49f25752be489e00a71836aecd0ae1b8fcef4)  added changelog fragment ", "linked_issue_titles": "", "title": "win group membership sid refactor 2.6"}
{"description": " follow the advice from the readme. avoid common mistakes. ", "commit_messages": " add correct options for collection.set method.  issue #18593.  make collection.slice method  min parameter optional to match documentation.  issue #18593.  allow sync to accept a collection as it's second argument.  allow sort option for backbone collection.add and push.  issue #18593. ", "linked_issue_titles": "", "title": "issue #18593.  various fixes for backbone."}
{"description": " messing around with github actions, trying to see if this is possible: we will run checks only on the submitted project euler solution and not all. improve project euler validate solutions script i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " update validate solution script to fetch one solution  update workflow file with the updated pe script ", "linked_issue_titles": "", "title": "validate only submitted project euler solution"}
{"description": " adds the tensortransfer instruction in the same block as the corresponding graph_op instruction. also updates the naming logic to make sure names are unique across all devices. in the send_recvs.swift example, the name for the while block in the cpu and tpu turned out to be the same causing a runtime error in tensorflow. resolves sr-8372. ", "commit_messages": " add tensortransfer instruction to the same block as the graph operation.  bugfix to niquify names.  updated the tests to run loop canonicalization. ", "linked_issue_titles": "", "title": "fix the code that inserts tensortransfer instructions to respect dominance"}
{"description": " adjust the filtering on data endpoint when a context parameter is used. for a requested time range (t1, t2) filter out the matching charts when their  last_entry_t < t1 is true component name database ", "commit_messages": " test fix for k8s  remove charts that have data before the \"after\" point in time  remove incognito rrdr dimension flag ", "linked_issue_titles": "", "title": "fix the context filtering on the data query endpoint"}
{"description": " remove cluster's and listener's tls_context since we are using transport socket's tls_context/ refactor the sslsockettest : centralize the server configuration in one place --configureserverandexpiredclientcertificate function. note: the test could be further refactored by leveraging this function i modified, but i feel that is not worth the large amount of effort and current code also provides a bit flexibility of configuration (e.g. specifies various config like cert_hash, cert_spki in place) move createprotocoltestoptions to unnamed namespace. even though superiority of unnamed namespace over static is more applied to user-defined types rather than variables and functions (i.e. static no longer deprecated in standard and should do the same thing for latter two), it is still good to keep it in the unnamed namespace like other internal helper functions . also, unnamed namespace should be encouraged for such usage in general risk level: low testing:  local tests and ci run (all tests passed) ", "commit_messages": " remove tls context  deprecate tls_context in listener and cluster in favor of transport  socket  fix typo  format ", "linked_issue_titles": "", "title": "deprecate cluster's and listener's tls_context in favor of transport socket"}
{"description": " i was going through the gatsby themes tutorial and ran into issues with the referenced theme-ui components being deprecated  i updated the css and code samples accordingly. ", "commit_messages": " update with changes from gatsby  merge remote-tracking branch 'upstream/master'  update docs to no longer use deprecated theme-ui layout and instead use theme-ui components ", "linked_issue_titles": "", "title": "update building a theme docs to no longer use deprecated theme-ui components"}
{"description": " fixes  my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " apply human-friendly formatting to info.json  correct layout_all data  corrects the layout data for the layout_all macro. ", "linked_issue_titles": "", "title": "nix studio oxalys80 configurator layout data correction"}
{"description": " issue: partially related to #4903 today we have an option to extend  webpack config by providing the function like this: module.exports = (basicconfig, mode, defaultconfig) => { /*...*/ } where defaultconfig is a few rules bigger than a basicconfig. i think it brings more confusion rather a benefit. reduced the basicconfig and changed to the signature to: module.exports = ({ config, mode }) => { /*...*/ } why object? because it's much easier to extend and deprecate in the future. removed a minor prop (defaultconfigname) that is passed forme the frameworks to core. this prop is kinda not needed. ", "commit_messages": " remove \"defaultconfigname\" prop and use \"defaultconfig\" as a single config to be extended  rename configtype to mode ", "linked_issue_titles": "", "title": "core - simplify custom webpack config"}
{"description": " while trying to match function types, detect and fix any missing arguments (by introducing type variables), such arguments would get type information from corresponding parameters and aid in producing solutions which are much easier to diagnose. diagnostic only supports closures at the moment, but could be easily expanded to other types of situations e.g. function/member calls. ", "commit_messages": " [cssimplify] further restrict tuple splat behavior  issingleparam used to return true regardless of type of  the identified single parameter, but splat only makes sense  if such type is a tuple or a type variable which could later  be resolved to tuple. otherwise it makes it hard to diagnose  missing arguments.  [constraintsystem] fix missing arguments  while trying to match function types, detect and fix any missing  arguments (by introducing type variables), such arguments would  get type information from corresponding parameters and aid in  producing solutions which are much easier to diagnose.  [constraintlocator] add special locator for synthesized arguments  [cssimplify] while attempting to synthesize missing arguments account for \"implode\" case  in situations like this:  swift  func foo(_: (int, int) -> void) {}  foo { $0.0 + $0.1 }    parameters are expected to be a single tuple by mistake, to account  for that solver can generate n new arguments and bind a single existing  argument to tuple formed from them. ", "linked_issue_titles": "", "title": "diagnose missing arguments in closures via fixes"}
{"description": " previously, there could be deadlock when many spilling/restore objects happen concurrently. imagine all io workers are occupied to restore objects while the object store is about to oom. the put request will fail, and the plasma store needs to spill objects, but all io workers are already occupied by restore ops. this pr fixes this issue by having a separate pool for spill/restore workers. it basically removes the concept of io workers (it will be just an internal concept within worker pool abstraction) and introduces spillworker and restoreworker. this pr doesn't actually allow users to set a separate pool size for spill/restore workers. i think having the same size for both pools is fine for now, and implementing it in the future upon demand is trivial. it also introduces tests for io worker methods within worker pool (which we didn't have for some reason). #11789 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " in progress.  add status  in progress. ", "linked_issue_titles": "", "title": "introduce spillworker & restoreworker pool to avoid io worker deadlock."}
{"description": " restores similar behavior to make rules, where: the step order was always the same, e.g. the testsuite order in make check make check-stage1-{cfail,rpass} would always run cfail before rpass ./x.py test--stage 1 src/test/{compile-fail,run-pass} is now equivalent r? @alexcrichton ", "commit_messages": " rustbuild: use a btreemap for the ruleset for determinism.  rustbuild: sort rules by the order of matching cli paths. ", "linked_issue_titles": "", "title": "use deterministic step ordering and respect path order on the command-line."}
{"description": " this is the same pr as #12569, which was intended to fix an exception when syncfs encounters a directory which already exists. modifications to the original pr: i have squashed the commits because the final diff was only one line. i hope this is fine with you @vinnyog. a new test has been added (which is what prevented #12569 from getting merged). closes #12562. ", "commit_messages": " use mkdirtree in idbfs.syncfs to avoid a crash when syncing existing directories  add test for syncfs with an already existing directory ", "linked_issue_titles": " idbfs syncfs should not throw error when directory timestamps change ", "title": "fix syncfs with existing directories"}
{"description": " you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: searched the bugtracker for similar pull requests read adding new extractor tutorial read youtube-dl coding conventions and adjusted the code to meet them checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information the  niconico extractor has been broken following site changes, and also served files that couldn't be downloaded in a single yt-dl run because the server cancelled the download in the absence of a regular heartbeat post. the corresponding module in yt-dlp has been actively maintained and additional search extractors have been implemented, as well as adding support for the heartbeat function for downloads. this pr adapts the current version of the yt-dlp module to yt-dl conventions, in particular replacing f'strings' and yield from. the playlist limit in download tests from yt-dlp is implemented. additionally, if the optional threading module is available, the heartbeat function is enabled for dmc-type downloads. this requires a small change to downloader/__init__.py credit goes to @cxwudi, @animelover1984 and @pukkandan for recent changes on the yt-dlp version, and see also below for other contributors. the pr should fix these issues where extraction failed: resolve #29225 resolve #29974 resolve #30003 resolve #30316 resolve #30395. the pr should fix these issues where downloading needed a heartbeat: resolve #14582 resolve #19261 resolve #24093. ", "commit_messages": " [test:download] only extract enough videos for playlist_mincount  [niconico] back-port extractor from yt-dlp  add nico search extractors, fix extraction ", "linked_issue_titles": " [niconico] downloading long videos requires heartbeat signals  unable to download from nicovideo.jp  [niconico] support encrypted official videos  nicovideo.jp issue  unable to download from nicovideo (niconico)  nicovideo; unable to find url  niconico dl not working  [niconico]unable to find video url ", "title": "back-port extractor and add new search extractors from yt-dlp"}
{"description": " additionally report deprecations at earliest possible moment ", "commit_messages": " fix(aws api gateway): ensure to log deprecation at initialization stage  chore: register \"aws alexa\" commit message scope  refactor(aws alexa): remove obsolete condition  fix(aws alexa): ensure to log deprecation at initialization stage  fix(aws cloudfront): ensure to log deprecation at initialization stage  fix: ensure to log deprecation at initialization stage  fix(analytics): ensure to send payload when having all meta ", "linked_issue_titles": "", "title": "ensure to report all deprecations"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> the subtitlestyle prop is missing. it's in the material ui docs and the property works, but i'm getting a ts compiler error because its not in this typings file. ", "commit_messages": " adds props to gridtile  removes the children prop that i added ", "linked_issue_titles": "", "title": "adds missing subtitlestyleprops to gridtile"}
{"description": " this pr fixes #121493. the main issue here is that we can't use color alone to signify state (see 1.4.1), so we have to update our focus state to invert the colors (just like in our list widget) to improve the focus state. originally i was scoping this to the quick pick but then also saw that the suggest widget relies on these colors, so i went ahead and updated those as well. this updates: default focus foreground & background colors for quick pick/suggest items focused highlights/labels/icons/keybindings to pass color contrast introduces: list.focushighlightforeground which defaults to the current highlight color quickinputlist.focusforeground which defaults to list.activeselectionforeground editorsuggestwidget.selectedforeground which defaults to list.activeselectionforeground dark theme is almost unnoticeable as the colors were close, but the light theme has the more noticeable changes. also, since the focus bg is so strong here i was unable to find an alternate color that worked for highlights (when filtering) so for now i set that color to be white. open to feedback on all of these changes. dark light other themes ", "commit_messages": " update quick pick focused state  add listfocushighlightforeground ", "linked_issue_titles": " quick pick focused item does not meet color contrast of 3:1 ", "title": "update quick pick list widget focus colors"}
{"description": " we should support safe c++ worker api according the doc, this pr remove some dependencies on ray core, such as: errortype, workertype, language, tasktype, buffer, localmemorybuffer, rayobject, taskarg, taskargbyreference, taskargbyvalue. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " remove coreworkerprocess  remove some enum dependency of ray core  begin to move arguments.h  remove dependence of ray::taskarg  remove some dependency of ray core ", "linked_issue_titles": "", "title": "remove some api dependencies on ray core"}
{"description": " closes #32380 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry i deprecated the squeeze keyword. i think i got every points this keyword was used. i hope that i considered every point necessary to deprecate a keyword. i tried to use other points were a keyword was deprecated as example. ", "commit_messages": " start deprecating squeeze option in groupby  deprecate squeeze option  change issue number in whats new  run flake diff ", "linked_issue_titles": " deprecate groupby() squeeze option ", "title": "32380 deprecate squeeze in groupby"}
{"description": " the completion suggester ignores the original weight of the suggestion when duplicates are removed. this change fixes this bug and keeps the best weighted suggestion among the duplicates. it also removes the custom implementation of the top docs suggest collector now that  closes #35836 ", "commit_messages": " iter  iter  remove obsolete javadocs ", "linked_issue_titles": " skip_duplicates ignores weight ", "title": "fix duplicate removal when merging completion suggestions"}
{"description": " as discussed in 2cb51f7. i haven't implemented the symlink, because it was previously broken for os x as well (the shared library had an .so extension) and i'd rather prefer pushing the users to do the right thing. if you think i should do otherwise, please comment. ", "commit_messages": " fixed dll name on windows in xgboost.libpath  added support for os x to xgboost.libpath ", "linked_issue_titles": "", "title": "fixed shared library loading in the python package"}
{"description": " also adding tests for fixed ices ", "commit_messages": " syntax: parse global paths in patterns  closes #6449  rustc: prevant an out of bounds access in typeck  closes #7092  rustc: fix a dynamic borrow error in resolve  closes #8208  closes #10980  test: add a test for fixed issue #10763  closes #10763  test: add test for fixed issue #11736  closes #11736  test: add a test for fixed issue #11844  closes #11844  rustc: avoid out of bounds in check_match  closes #12116  rustc: avoid an unwrap() in check_match  closes #12369  test: add a test for fixed issue #12567  closes #12567  test: add test for fixed issue #12796  doesn't close #12796 because the error message is awful. ", "linked_issue_titles": "", "title": "fix a number of compiler ices"}
{"description": " this will allow experimenting with the remove to string transformer before we're ready to turn it on by default. this doesn't work for web yet since we use dart2js instead of the frontend_server for producing kernel fixes #53174 ", "commit_messages": " work on wiring up extra gen snapshot options  add gradle test ", "linked_issue_titles": " enable the usage of  --delete-tostring-package-uri in the flutter tool ", "title": "expose extra frontend options through build apk/ios/macos"}
{"description": " this pr removes gltf rigged simple model which seems no longer necessary. #13571 btw, i think we can also remove outlined box model. (what's this model for?) what do you think? ", "commit_messages": " remove riggedsimple model from gltf extension example.  remove gltf riggedsimple model. ", "linked_issue_titles": "", "title": "remove gltf rigged simple model"}
{"description": " moves the python tests to the python subdir. adds a libbcc.a target for those statically inclined. ", "commit_messages": " move python tests to tests/python  they didn't quite make sense where they were. at one point 'cc' meant  compiler, and yes they were testing the compiler. now lets use the  convention that different tests/ subdirectories test different bindings  (c, python, other).  add libbcc.a compilation and test binary  this creates a new static library target for bcc. add one trivial c test  case that links against it. ", "linked_issue_titles": "", "title": "move cc/*py tests to python subdir and introduce c standalone test binary"}
{"description": " this passes make check on my osx machine. pcwalton should probably review this. ", "commit_messages": " add realloc method to rust_kernel  allocate rust_ivec buffers out of the kernel pool  the duplication of upcalls is due to the fact that the runtime is  shared between stage0/rustc and stage1/rustc. once snapshots are  updated, they should be de-duplicated. ", "linked_issue_titles": "", "title": "allocate ivecs out of the kernel pool"}
{"description": " this is a continuation of the tidying up of the keyboard code. there is something a bit funny about the handling of the backslash character in windows. i suspect this is because the backslash key is in a different place on german keyboards. can someone with a german keyboard check the backslash still works on windows. note i've put the work in a branch (jr-keyboard) to avoid a git wtf award when i inevitably click the \"merge now and don't ask for confirmation\" button ", "commit_messages": " change order of key lookup to allow actions to be mapped to numeric  keypad keys  include multimedia keys in the global key map. this completes the changes  to cbuttontranslator::translatekeyboardstring.  ignore case of key names in keyboard.xml  vk_keymap[vk_oem_102] was set to xbmck_less and in the us layout that  xbmc uses, it should be xbmck_backslash.  tidy up xbmc_keysym.h  add enum for the ckey.vkey values used in xbmc  use windows keyboard layout not the us layout ", "linked_issue_titles": "", "title": "tidy up and comment keyboard handling"}
{"description": " refs: #34157 creating this for discussion. idea is to make it easier for extensions to work with patterns that should be relative to the workspace. we typically ask for a string for the pattern and now we could add an or-type for a workspace relative pattern described by workspacepattern. the pattern will be matched against the provided base folder and can be relative (e.g. not starting with the workspace path or **). export interface documentfilter { /** * a language id, like typescript. */ language?: string; /** * a uri [scheme](#uri.scheme), like file or untitled. */ scheme?: string; /** * a glob pattern, like *.{ts,js}. */ pattern?: string | workspacepattern; } export interface workspacepattern { base: workspacefolder; pattern: string; } before doing more polish, @jrieken @dbaeumer for initial input. ", "commit_messages": " introduce irelativepattern and use in extension api  :lipstick: ", "linked_issue_titles": "", "title": "introduce irelativepattern and adopt in documentfilter/filewatcher/filesearch"}
{"description": " this pr adds the scriptcode to the list of preferred locales as well as provides a new locale resolution algorithm that considered the preferred locale list instead of just the default (first) locale. locale resolution algorithm: i would like to have opinions on overhead vs time complexity of dart data structures. the algorithm i use first places all of the app's supported locales into a series of hashmaps, keyed by \"substring-hashes\" of their properties. for example, consider the locale zh-hant_tw. this locale is broken into zh, zh-hant, zh_tw, and zh-hant_tw. each of these four go into a corresponding hashmap that maps unique \"substrings\" to the first instance of that combination. with this system, both zh-hant_tw and zh-hant_hk map to the same locale when only considering languagecode and scriptcode and acts as if we chose the first occurrence. then, we loop over all preferred locales and match against the 4 hashmaps in order of most specific to least specific. to emulate the behavior of selecting a more specifically matched but less preferred locale, we delay matching by only a languagecode and nothing else until the next locale in the user's preferred locale is considered and does not have a better match. in the case of the default (first) locale, since the default locale is usually highly preferred over any secondary locale, we make an exception to the above rule and allow matches by only language code to resolve instantly. breaking changes this pr potentially introduces breaking changes to the localization bindings api. the localeresolutioncallback breaking change (from supporting list<locale> instead of a single locale) has been avoided by providing a higher priority localelistresolutioncallback that is called before the current one if it is provided. however, there are other places (see binding.dart) where the api is likely going to have to change to pass the list around instead of the single locale on the observers and callbacks there. ", "commit_messages": " define localelistresolutioncallback  locale list resolution  working locale resolution system for locale lists ", "linked_issue_titles": "", "title": "new locale resolution algorithm to use full preferred locale list, include scriptcode in locale."}
{"description": " i've never heard the term \"oneshot\" modifier key before. i've only heard of the terms \"sticky key\" or \"dead key\". so when i was searching through the qmk docs, i couldn't find this feature. i think updating the docs as proposed will assist for other people searching as well. ref: issue #212 ", "commit_messages": " update glossary; oneshot key = sticky/dead key  update advanced_keycodes; oneshot = sticky/dead keys ", "linked_issue_titles": "", "title": "add the words \"sticky/dead keys\" to \"one shot\" docs sections"}
{"description": " this pr fixed two bugs with imageviewer, related to image rotations: the image looked shrank after rotation due to the window not being updated properly. the window is resized even if the image is small enough to rotate within the window. ", "commit_messages": " imageviewer: use the same function to resize the window  imageviewer used two different logic to resize the display window, which  leads to confusing behaviour for rotate function. now all the resizing  behaviour goes through the existing resize_window function.  imageviewer: do not return early when the scale is not changed  when the image is rotated, the scale is still the same, but the window  needs to be still resized.  imageviewer: do not resize the window if the image fits into the window ", "linked_issue_titles": "", "title": "preserve the aspect ratio on rotate"}
{"description": " built on #10864, which should be reviewed & merged first ", "commit_messages": " reduce server memory usage  (this needs more testing/analysis to prove that it's safe)  switch from a lock free stack to an mpscq protected by a spinlock for incoming requests. the mpscq is unbounded and so needs (much) less memory allocated up front.  memory_profile_test shows this reduces initial server creation cost from 4mb to 1.5kb.  merge github.com:grpc/grpc into serve_fries  increase default cq count from 1 to num_cpus ", "linked_issue_titles": "", "title": "switch default cq count for thread manager to num_cpus"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " feat(mongoose): added flag for new url parser  feat(mongoose): added test for usenewurlparser flag  feat(mongoose): bumped up mongoose version ", "linked_issue_titles": "", "title": "added flag for usenewurlparser in connectionoptions"}
{"description": " hi david, i added a few options in regards to security of websites. this is mainly targeting http headers. with the urls to scanning services one would be able to tweak and improve their site(s) easily. regards, joki ", "commit_messages": " add http header of content type options  add websites for security scans  check hsts preload status and eligibility  add x-frame-options (xfo) section  provide link captions  add rfc 7034 ", "linked_issue_titles": "", "title": "add a few security-related entries"}
{"description": " improve the aclk sync thread shutdown sequence sets a shutdown in progress flag so that no more commands will be accepted and the current queue of the commands will be ignored adds a -w parameter to check database for corruption and also attempt to fix it. adds a -w parameter to compact the database during startup if a database corruption is detected, it will attempt to fix it automatically (only applies to the dimension and chart tables) parameters added (in netdata -h) -w check-sqlite-database        check metadata database integrity and exit. -w fix-sqlite-database          check metadata database integrity, fix if needed and exit. -w compact-sqlite-database      reclaim metadata database unused space and exit. component name aclk sync, database stop the agent and execute in turn to simply check the database execute netdata -w check-sqlite-database to check and fix if needed the database execute netdata -w fix-sqlite-database to compact the database execute netdata -w compact-sqlite-database a sample output of a corrupted database would look like this when -w check-sqlite-database is executed 2021-11-24 23:28:28: netdata info  : main : running database check on /home/stelios/netdata-staging/netdata/var/cache/netdata/netdata-meta.db 2021-11-24 23:28:28: netdata info  : main : checking table chart 2021-11-24 23:28:28: netdata info  : main : ---> row 4300 missing from index sqlite_autoindex_chart_1 2021-11-24 23:28:30: netdata info  : main : ---> row 439125 missing from index sqlite_autoindex_chart_1 2021-11-24 23:28:30: netdata info  : main : ---> non-unique entry in index sqlite_autoindex_chart_1 2021-11-24 23:28:31: netdata error : main : errors reported -- run with -w fix-sqlite-database 2021-11-24 23:28:31: netdata info  : main : checking table dimension 2021-11-24 23:28:39: netdata info  : main : ---> row 1350373 missing from index ind_d1 2021-11-24 23:28:41: netdata info  : main : ---> row 1744253 missing from index ind_d1 2021-11-24 23:28:42: netdata error : main : errors reported -- run with -w fix-sqlite-database ", "commit_messages": " set a flag to do aclk sync thread shutdown  attempt to dequeue a cmd in case the queue is full and someone is blocked  drop tables and recreate instead of deleting  add commands to check the database -w check-database, fix-database, compact-database  split the database setup to config and cleanup part  add checks during database setup and cleanup to detect corruption to the dimension and chart tables  add full database check and refactor code ", "linked_issue_titles": "", "title": "add commands to check and fix database corruption"}
{"description": " i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #2583'. ", "commit_messages": " hill cipher implementation in java  determinant of a matrix  delete hillcipher.java  add files via upload  delete determinantofmatrix.java  determinantofmatrix  finding determinant of a matrix.  inverse of a square matrix  this feature finds inverse of a matrix using gaussian elimination.  update inverseofmatrix.java  sparcity of a matrix ", "linked_issue_titles": " calculate sparcity of a given matrix. ", "title": "sparcity of a matrix [hacktoberfest]"}
{"description": " this pr contains the following changes: unify the file / directory watcher functions in tsc and tsserver; for inferred projects, add the ability to detect newly added tsconfig.json files in from the same directory up to the root path; for configured projects, add the ability to detect implicitly added/removed source files (e.g., when the tsconfig.json file doesn't have a files array, and source files are added to or removed from the directory) from the same directory down recursively. (fix #5076, #4643) for tsconfig.json file without a files array, also added support to detect file addition / removal under tsc --watch. (fix #4553) points worth notice: inferred projects and configured projects have different kinds of directory watchers: for inferred projects, the sole purpose of a directory watcher is to detect newly added tsconfig.json files; and the addition normally happens from the current path up. also, it doesn't matter which project the watcher belongs to, all inferred projects can share one set of watchers if their root files happen to be in the same folder. for configured projects, each project has a recursive directory watcher of the path where its config file is located at. it does matter which project the watcher belongs to. currently the recursive watchers are supported in node 4.0 for both osx and windows. if the node version is before that, the recursive watcher might not work reliably. ", "commit_messages": " change filewatcher in sys for node 4  unify the node filewatcher in sys.ts and server.ts  bug fixes  temp save  redesigned directory watchers  add directory watcher to tsc  use fs.watch for all directory watchers and some bug fixes  update comments  incorporating changes from #3780  merge branch microsoft/master ", "linked_issue_titles": "", "title": "add directory watcher for tsserver and tsc"}
{"description": " deepchecks is a python package for comprehensively validating your machine learning models and data with minimal effort. this includes checks related to various types of issues, such as model performance, data integrity, distribution mismatches, and more. ", "commit_messages": " update readme.md  update readme.md ", "linked_issue_titles": "", "title": "add deepchecks to python -> general purpose machine learning"}
{"description": " there unfortunately was a copy'n'paste problem with some of the integration idempotency tests, which did force some change because command changed. after fixing this, it turned out that init and shm_size have no idempotency checks. (extracted from #48546) docker_container ansible version 2.8.0 ", "commit_messages": " fix tests: use same command if not testing command option.  fix idempotency of init option.  fix shm_size idempotency (it is included in inspect results from docker api version 1.22 on). ", "linked_issue_titles": "", "title": "fix tests and idempotency for init and shm_size"}
{"description": " commit message: in order to speed up eds, don't necessarily visit every proto field to count its validity as warningvalidationvisitor does. this yields a ~30% speed improvement in processing very large updates in eds. risk level: medium, new feature behind a command line flag. testing: unit and bechmark tests. docs changes: these are probably wrong, thus the draft-ness. release notes: eds can now ignore unknown dynamic fields, for a ~30% improvement in update processing time. behind --ignore-unknown-dynamic-fields ", "commit_messages": " add the ability to ignore unknown fields in eds.  repair some merge damage and move the conditional down a layer as htuch requested. ", "linked_issue_titles": "", "title": "optionalize counting of unknown fields"}
{"description": " changes to provide api in objective-c to the values and names for enums. ", "commit_messages": " sync to thomasvl/protobuf head  added new api to gpbenumdescriptor to enable introspection of enum values.  refactored implementation so that this contains a minimum of added code.  clarified comments regarding behavior in the presence of the alias_allowed option.  added unit tests for new functionality and for the alias case.  oops, fixed spelling error.  more commentsmithing.  addressed tom's comment on the pull request.  noticed two more instances of fixes in the earlier commit. ", "linked_issue_titles": "", "title": "add ability to introspect list of enum values"}
{"description": " i was doing some looking around sema and i noticed how large the method exprrewriter::coercecallarguments was. being a good citizen, i refactored out an obvious subroutine into (you guessed it!) a subroutine! ", "commit_messages": " [gardening] refactor out computation of a callee's level into its own helper function.  exprrewriter::coercecallarguments is a huge function that is difficult to reason  about. this just moves an obvious subroutine into a real subroutine.  [gardening] cleanup control flow in computecalllevel to reduce indentation level. ", "linked_issue_titles": "", "title": "refactor computation of call level into subroutine from exprrewriter::coercecallarguments"}
{"description": " using cmake, nvidia's nvc++ adds the -a compiler flag (\"strict\"), causing compilation error if newlines are missing from the end of source files. nvc++ (not to be confused with nvcc) is detected as the pgi c++ compiler and this patch may therefore also apply to that. proposed changes involve newlines, only. ", "commit_messages": " allow compilation with nvc++  add newlin to color_sinks.cpp ", "linked_issue_titles": "", "title": "allow compilation with nvc++ (and possibly pgi)"}
{"description": " this is to add a tower_settings module which provides the ability to get, modify tower settings, which are at /api/v2/settings/all. new module pull request tower_settings ansible version devel ", "commit_messages": " add the tower_settings module  add tower_settings module ", "linked_issue_titles": "", "title": "add 'tower_settings' module for managing ansible tower settings"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " mapbox-gl: geolocatecontrol support v0.39.0  :warning: breaking changes  geolocatecontrol breaking changes  the option watchposition has been replaced with trackuserlocation  the camera operation has changed from jumpto (not animated) to fitbounds (animated). an effect of this is the map pitch is no longer reset, although the bearing is still reset to 0.  the accuracy of the geolocation provided by the device is used to set the view (previously it was fixed at zoom level 17). the maxzoom can be controlled via the new fitboundsoptions option (defaults to 15).  new option showuserlocation to draw a \"dot\" as a marker on the map at the user's location  mapbox-gl: support pitch-alignment v0.39.0  add new icon-pitch-alignment and circle-pitch-alignment properties ", "linked_issue_titles": "", "title": "geolocationcontrol and pitch-alignment support v0.39.0"}
{"description": " currently plugin just resolves url() paths relative to the main sass entry file. resolve-url-loader adds the ability to use paths relative to the file where the url() is being used. by default if not configured in the gatsby-plugin-sass, the loader is not being used, but you can activate it and also configure resolve-url-loader plugin with the options it provides. usage has been also documented in the readme.md of the gatsby-plugin-sass fixes #7776, #6438 ", "commit_messages": " using resolve-url-loader if configured in the options  documenting how to use resolve-url-plugin plugin  fixing small typo ", "linked_issue_titles": " how to use resolve-url-loader with gatsby-plugin-sass in v2? ", "title": "add option to enable resolve-url-loader"}
{"description": " when parsing an ignore or attribute file, we should skip a utf8 bom. fixes #5071 ", "commit_messages": " ignore: test we can handle an ignore file with bom  ensure that we can read and parse an ignore file with a utf8 bom.  ignore: skip utf8 bom in ignore file ", "linked_issue_titles": " .gitignore parsing: bom not skipped ", "title": "skip utf8 bom in ignore files"}
{"description": " fixes for a few outstanding issues. shap contribution dependency plots (an alternative to partial dependency plots). so far only 1d dependency plots are implemented, and no ggplot version. e.g., for a specific class in multiclass classification: set.seed(123) x <- as.matrix(iris[, -5]) is.na(x[sample(nrow(x) * 4, 30)]) <- true # introduce some missing values - will be shown in purple mbst <- xgboost(data = x, label = as.numeric(iris$species) - 1, nrounds = 20, max_depth = 2, eta = 0.1, subsample = .5, nthread = 2, objective = \"multi:softprob\", num_class = 3, verbose = 1) # for class 1 (versicolor) xgb.plot.shap(x, model = mbst, trees = seq(from=1, by=3, length.out=20), target_class = 1, top_n = 4, n_col = 2, col = rgb(0, 0, 1, 0.5), pch = 16, pch_na = 17) ", "commit_messages": " [r] fix predict contributions for data with no colnames  [r] add a render parameter for xgb.plot.multi.trees; fixes #2628  [r] update rd's  [r] remove unnecessary dep-package from r cmake install  silence type warnings; readability  [r] silence complaint about incomplete line at the end  [r] initial version of xgb.plot.shap()  [r] more work on xgb.plot.shap  [r] enforce black font in xgb.plot.tree; fixes #2640  [r] if feature names are available, check in predict that they are the same; fixes #2857  merging upstream changes ", "linked_issue_titles": "", "title": "maintenance nov 2017; shap plots"}
{"description": " related to #49553 but i don't think it'll fix it currently, rustdoc doesn't expose proc-macros all that well. in the source crate, only their definition function is exposed, but when re-exported, they're treated as a macro! this is an awkward situation in all accounts. this pr checks functions to see whether they have any of #[proc_macro], #[proc_macro_attribute], or #[proc_macro_derive], and exposes them as macros instead. in addition, attributes and derives are exposed differently than other macros, getting their own item-type, css class, and module heading. function-like proc-macros are lumped in with macro_rules! macros, but they get a different declaration block (i'm open to tweaking this, it's just what i thought of given how function-proc-macros operate): proc-macro attributes and derives get their own pages, with a representative declaration block. derive macros also show off their helper attributes: there's one wrinkle which this pr doesn't address, which is why i didn't mark this as fixing the linked issue. currently, proc-macros don't expose their attributes or source span across crates, so while rustdoc knows they exist, that's about all the information it gets. this leads to an \"inlined\" macro that has absolutely no docs on it, and no [src] link to show you where it was declared. the way i got around it was to keep proc-macro re-export disabled, since we do get enough information across crates to properly link to the source page: until we can get a proc-macro's docs (and ideally also its source span) across crates, i believe this is the best way forward. ", "commit_messages": " handle proc-macros as macros instead of functions  disable proc-macro re-export inlining  proc-macros don't emit their attributes or source spans across crates.  this means that rustdoc can't actually see the docs of a proc-macro if  it wasn't defined in the active crate, and attempting to inline it  creates an empty page with no docs or source link. in lieu of attempting  to fix that immediately, this commit forces proc-macro re-exports to  never inline, which at least creates usable links to complete  documentation.  add test for proc-macro re-export ", "linked_issue_titles": "", "title": "give proc-macros their own pages"}
{"description": " gatsby-transformer-json is a great plugin to parse raw json. although the plugin works perfectly with well-structured json files, it's faile to read and parse some type of files like topojson. the \"troubleshooting\" section within plugin's readme suggests rewriting the data, which not possible most of the time. trying to import those files directly inside a js file results in adding them to the app bundle and that would increase the size of all pages, as i discovered in #16651 issue. related to #16651 ", "commit_messages": " add another usecase for using the static folder  editing ", "linked_issue_titles": "", "title": "importing json files correctly outside graphql"}
{"description": " this pr backports fixes and improvements for gbm and drm prime to leia. #15949 #15922 #15946 #15963 #15964 #16184 #15928 all prs may not be needed, but would be good to include in kodi v18.3 / libreelec 9.2. ping @lrusak build and runtime tested with libreelec on a asus tinkerboard s. ", "commit_messages": " cwinsystemgbm: only lock the front buffer if something is rendered  cdrmutils: rework modifiers flag selection  cdrmutils: fallback to drmmodeaddfb2 if drmmodeaddfb2withmodifiers fails  gbm: override processinfo and use deinterlace half by default on arm  videobufferdrmprime: extract class  videobufferdrmprime: extract interface  videobufferdrmprime: add map/unmap callbacks  dvdvideocodecdrmprime: getpicture only works for drm_prime pix fmt  dvdvideocodecdrmprime: update process info in get format callback  cdrmutils: explicitly set the caps we want (atomic brings them in)  ceglfence: add class to help with egl sync objects  crendererdrmprimegles: use ceglfence to sync rendering  crendererdrmprimegles: update vbo's to be similar to clinuxrenderergl  crendererdrmprimegles: add override methods for erenderfeature and escalingmethod ", "linked_issue_titles": "", "title": "backport fixes and improvements for gbm and drm prime"}
{"description": " clang tidy remove performance-unnecessary-value-param as error but keep as warning because clang-tidy can auto-fix it. trie tree fixed general code quality iso c++11 standard conformity fixes lgtm alert closes #1057 added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines ", "commit_messages": " attempt to fix trie-tree code  clang-tidy fixes  remove performance-unnecessary-value-param as error - this has auto-fix  make test() static ", "linked_issue_titles": "", "title": "fixed trie_tree for code quality and docs & clang-tidy error check"}
{"description": " i went till i hit the next major roadblock: mutation observers. this library is used by youtube. details in the individual commits. ", "commit_messages": " libweb: check if scripting is disabled before running script  this is not a full check, it's just enough to prevent script execution  in domparser.  libweb: add domparser  this allows you to invoke the html document parser and retrieve a  document as though it was loaded as a web page, minus any scripting  ability.  this does not currently support xml parsing.  this is used by youtube (or more accurately, web components polyfills)  to polyfill templates.  libweb: make clone_node capable of cloning document fragments  used by web components polyfills.  libweb: use the element factory in clone_node  it was directly creating a new element object instead of creating the  appropriate element.  for example, document.body.clonenode(true) would return an element  instead of an htmlbodyelement.  libweb: add the cloning steps in clone_node  this will be used in htmltemplateelement later to clone template  contents.  this makes the clone functions non-const in the process, as the cloning  steps can have side effects.  libweb: make adopted_from no longer take a const document reference  nodes implementing the adoption steps can modify the passed in  document, for example htmltemplateelement does so to adopt it's  contents into the new document.  libweb: implement the cloning steps for <template> elements  libweb: implement the adoption steps for <template> elements  while i'm here with the cloning steps, let's implement this too.  libweb: make wrappergenerator generate nullable wrapper types  previously it was not doing so, and some code relied on this not being  the case.  in particular, set_caption, set_t_head and set_t_foot in  htmltableelement relied on this. this commit is not here to fix this,  so i added an assertion to make it equivalent to a reference for now.  libweb: implement node.contains  used by web components polyfills. ", "linked_issue_titles": "", "title": "implement/fix a bunch of stuff required by web components polyfills"}
{"description": " my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add kk980  fix  fix config.h  modified readme.md  fix  modified format.  modified image.  modified rules.mk  modified rules.mk + #  pull  fix info.json: keys dislocation ", "linked_issue_titles": "", "title": "fix info.json (keys dislocation) for qmk_web_configurator of kk980."}
{"description": " translate almost files but next 3 files are yet. content-tracing-ko.md - 50% app-ko.md - 0% browser-window-ko.md - 0% to avoid confusion i removed 2 files(app-ko, browser-window-ko). (thanks for dalinaum) and remove remote buffer section in both remote.md(en, ko) files as section is outdated. ", "commit_messages": " fix typos, update some files  update apis, check grammars  revert \"update apis, check grammars\"  this reverts commit d1eb971263f72deae84541d12b3bdd6d5972365a.  revert \"revert \"update apis, check grammars\"\"  this reverts commit 5e083473e7b4d3a6014d35e68618594765151afe.  update changes as upstream  prepare update forked repo  update as upstream  translate little files into korean  fix typos, improve grammer  update as upstream, fix typos  update as upstream  translate web-view-tag-tag-ko.md, improve grammer  update as upstream  update as upstream, translate 2 files, fix some typos  fix some typos, update as upstream  translate more files, fix outdated remote.md section  translate content-tracing(50%), remote docs.  fix remote buffer section as outdated.  merge remote-tracking branch 'atom/master' ", "linked_issue_titles": "", "title": "translate docs to ko #3, fix outdated section"}
{"description": " @akien-mga i've alleviated the life of kinematic character by healing the jumping problem joking apart i've fixed it that was caused by untreated shape scaling, i've also removed the useless error code reported during shape deletion. fixes #15417 ", "commit_messages": " fixed bullet collision shapes scale  removed useless error print on bullet shapes ", "linked_issue_titles": " kinematic character 3d demo shows buggy kinematicbody/gridmap collisions with bullet ", "title": "fixed #15417 kinematics char jumping"}
{"description": " #2111 imageviewmanager: changed image to reactimage/canvas moved all image related files to their own folder. reactimage: canvas wrapper to play nice with reactimagebrush overrides arrangeoverride to provide reactimagebrush the available size (needed for 'center' and 'repeat' reactimagebrush: xamlcompositionbrushbase that switches source brush based on resizemode uses compositioneffectbrush for 'repeat' resizemode bordereffect: header-only implementation of win2d-like bordereffect (used in windows::ui::composition apis) includes effectbase as we will probably need to add more effects in the future (e.g. blur) microsoft reviewers: open in codeflow ", "commit_messages": " move imageviewmanager to its own folder  add bordereffect impl  switch from image to canvas  add reactimagebrush (name tbd)  wip: couple of fixes  add reactimage canvas wrapper ", "linked_issue_titles": "", "title": "implement 'center' and 'repeat' resizemodes"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " updated xrmstatic properties page, utility, and panel  to match the pattern that mobil was doing, and be defined as interfaces.  this also makes allows for variables to easily be tyepd i.e. var p: xrm.page.  also retyped getinitalvalue for booleans and optionsetvalues to be their correct respective types.  fixed linitng issues and fixed header so it could be parsed by the dt bot  fixed other lint-ing issues.  not sure what to do about the header being unparsable.  added commas, maybe that will help?  fix for @types/xrm missing context.getversion #16528.   also fixed td bot parsing of definitions by making one line, and updating tslint to allow for the long line.  moved to one line.  merge update ", "linked_issue_titles": "", "title": "@types/xrm - fix for  missing context.getversion #16528"}
{"description": " update metal driver to use new samplergroupinfo. we're no longer keeping track of which textures / samplers are already bound to the command encoder as the process was error-prone and isn't worth the effort for now. also fixed a memory leak when creating a new depth texture inside of createrendertargetr. fixes #1008 ", "commit_messages": " fix memory leak  rework enumeratesamplerbuffers ", "linked_issue_titles": " ios hello-pbr example is crashing in metaldriver::draw ", "title": "fix metal sampler binding and memory leak"}
{"description": " this pr revises our logic for building cfa graphs for try-catch-finally statements. two changes are implemented by this pr: previously we'd include every cfa node in the try block as a possible antecedent in the exception case. now we only include cfa nodes representing assignments and array mutations. previously we didn't consider the possible effects in the finally block of exceptions in the catch block. we now do. fixes #34797. ", "commit_messages": " revise creation of control flow graph for try-catch-finally statements  add tests  accept new baselines ", "linked_issue_titles": " throw in catch causes type narrowing in finally block ", "title": "fix control flow analysis in try-catch-finally"}
{"description": " fixes rdar://problem/46973064. ", "commit_messages": " sema: add a pretty stack trace entry when checking error handling  sema: fix crashes when a call of a closure value is missing a 'try'  two problems here:  - the interpolatedstring instance variable was not always initialized before  being checked for null  - in the non-null case, we were assuming the result of callexpr::getcalledvalue()  was non-null, but it's null if the callee is not a function declaration  fixes <rdar://problem/46973064>. ", "linked_issue_titles": "", "title": "fix crashes when a call of a closure value is missing a 'try' [5.0]"}
{"description": " this pr adds a new api into the kubelet server which could return statistical information about a container. such information is retrieved through cadvisor rest api. this pr introduced the following third party dependencies: cadvisor because we need to use some data structure there and its client library. testify for its mock library objx because testify depends on it. the test coverage now for pkg/kubelet is improved from 58.1% to 59.9% the current code is not wired with kubelet now. will add it in another pr. ", "commit_messages": " add cadvisor into third_party  add /containerstats  gopath...  testify  unit test for cadvisor  more unit test for getcontainerstats()  more unit test  unit test for getcontainerstats() ", "linked_issue_titles": "", "title": "letting kubelet retrieve container stats from cadvisor"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " feat(ali-oss): add types of refresh token  fix(ali-oss): change comment length ", "linked_issue_titles": "", "title": "add def of refresh token in options"}
{"description": " somehow the code was dropped somewhere along the road... ", "commit_messages": " add jwt token creds test_case  the jwt code was dropped somewhere in a merge. put it back  add a jwt test case for interop test  formatting ", "linked_issue_titles": "", "title": "put back c++ jwtcredentials code and add a test case in interop test."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " update prettier 400col width  update for 4.3 ", "linked_issue_titles": "", "title": "tabulator-tables - update for version 4.3"}
{"description": " this pr is second version for fixing #10751. first version is #10811. please see #10751 about original problem. in master, uuid default functions are not dumped to db/schema.rb, because they are not extracted to postgresqlcolum. in first version, i modified postgresqlcolum.extract_value_from_default method to return a function name string when default argument is uuid generator. but i've understood this was wrong approach, because extract_value_from_default method must extract value. ", "commit_messages": " fix typo.  migration dump uuid default functions to schema.rb. fixes #10751. ", "linked_issue_titles": "", "title": "dump uuid default functions to schema.rb [2nd version]. fixes #10751."}
{"description": " this pr fixes #7164. the context menu entries \"evaluate expression\" and \"set execution point to line\" are now only enabled when a debug session is active. other than that, it was possible to run the program while a debug session is active. after the program finishes, the stop button gets disabled. this makes it impossible to exit the debug mode. i have disabled the run button while the debug mode is active. this is my first pr to an open-source project, so please let me know if i did something wrong :) ", "commit_messages": " hackstudio: disable run button while debugging  this commit disables the run button while we  are in debug mode. otherwise the stop button  gets disabled when we run the program while  we are in debug mode. this would prevent us  from exiting the debug mode.  hackstudio: disable debug specific context entries  context menu entries like evaluate expression and  move execution to line action should only be enabled  when a debug session is running. otherwise they should  be disabled. ", "linked_issue_titles": " hackstudio: debugger context menu items should be disabled when not debugging ", "title": "disable debugging context menu entries"}
{"description": " the health was not checking the size returned by fread, so it could work with less data than available. considering that the next steps would be to parser the json content, this mean that it would not start correctly the silencers. component name health to test whether everything is ok, run the script to test stopping in sometime before a reset command, stop and restart the netdata. it cannot display the error message of the code, instead it must give the info message. ", "commit_messages": " health_alert  the file health/healht.c on line 56 did not check the return of the fread  , so netdata could work with incomplete data  health_alert  the free functions was initially called in a wrong place. ", "linked_issue_titles": "", "title": "health could not read properly the health silencers file"}
{"description": " fixes #1358 there were 2 issues: files were deleted, but a few of them were re-created during cleanup. chart and host directories were not deleted. both are fixed now. ", "commit_messages": " strip binaries in makeself packages  properly cleanup deleted files of obsolete charts from disk; fixes #1358 ", "linked_issue_titles": " ephemeral containers - netdata does not cleanup ", "title": "delete files of obsoleted charts, from disk"}
{"description": " what types of changes does your pr introduce? put an x in all boxes that apply improve a description ", "commit_messages": " add loremify  add loremify, an lorem ipsum generator.  add trello  - adds the awesome trello app;  - improve description of loremify, geting off redudancy since the list is for mac os x.  add trello  - adds the awesome trello app;  - improve description of loremify, geting off redudancy since the list is for mac os x.  update the trello description  - add the word kanban at the description. ", "linked_issue_titles": "", "title": "add word 'kanban' for trello description."}
{"description": " #3068 hook up property keyboarddismissmode in scrollviewmanager. -when manipulation starts and if keyboarddismissmode is on-drag, issue tryhide though sip event handler. -some tweak to sip event handler code to be able to share in the rnw's code base, and call getforuicontext instead of getforcurrentview on newer build. -add logic to only hook up coreinputview when element is in the tree, otherwise we may get null uicontext and results in crash. microsoft reviewers: open in codeflow ", "commit_messages": " revert \"revert \"support scrollview keyboarddismissmode\" (#3692)\"  this reverts commit 55ef15e59835abc086f256b08e79bd9c87d419e8.  properly support scrollview keyboarddismissmode  change files ", "linked_issue_titles": "", "title": "support scrollview keyboarddismissmode - with crash fixed"}
{"description": " description: add wrapper around newly allocated slotimpl. this was missed in pr 8135. which means newly created tls are deallocated in the old way( destructed on owner destruction possible race, but the race window is really small, see issue #7902 ) risk level: medium testing: n/a docs changes:  n/a release notes: n/a ", "commit_messages": " resolve the life-cycle race between a slotimpl and callbacks pointing to it.  add minor comment  fixes for feedbacks from matt  fix format  add tidy error fixes  fixes for matt feedbacks, 2  fixes for feedbacks matt 3  fix clang-tidy errors.  refactor out the schedule-cleanup-callback complexity by firing a post callback on destruction of the ref-count shared_ptr  fix header order  fix comment  add more comment to the tls  if only i know how to run typo ci locally  add wrapper around new slot ", "linked_issue_titles": "", "title": "add the missing wrapper around slotimpl allocation."}
{"description": " get pixel color for a full window and connect functionality to ui. the copy to clipboard button and rgb values update with the mouse movement. references pr checklist detailed description of the pull request / additional comments current mouse input issue on a second monitor due to different dpi settings. validation steps performed checked color conversion with online hex to rgb conversions. ", "commit_messages": " implement get pixel within wpf window  added dpi awarness  small fix  [intern] added dpi awarness  thread with mouse color on full screen  merge ui xaml  remove dpi awareness settings  backend connection complete and clipboard added ", "linked_issue_titles": "", "title": "add get pixel logic and connect to ui"}
{"description": " added additional assertion that input image is not empty. ", "commit_messages": " fix gpu test for demosaicing:  check that input images was loaded correctly  added additional check in cv::gpu::demosaicing that source is not empty ", "linked_issue_titles": "", "title": "fix for gpu demosaicing test"}
{"description": " make use of rpc arena to avoid protobuf copying and destructing which are really expensive for complicated structures. this is a split of #17828 #17805 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " s1  up ", "linked_issue_titles": "", "title": "cpu improvement of protobuf in gcs"}
{"description": " reported in #750. includes fix to the test, which wasn't catching this bug. ", "commit_messages": " fix: tests now catch bug reported in #750 (in hdf5 output layer)  fix: both data and label now copied correctly in hdf5 output layer ", "linked_issue_titles": "", "title": "fix for bug in hdf5 output layer"}
{"description": " jenkins-20023 this change moves jenkins.docli() to own rootaction. ", "commit_messages": " [jenkins-20023] add support for java -jar jenkins-cli.jar help <cmdname>  [jenkins-20023] display detailed cli command info via jenkins ui  [jenkins-20023] generate usage for cli commands registered via climethod annotation ", "linked_issue_titles": "", "title": "make cli interface help more accesible"}
{"description": " this pr consists of 2 fixes. the first fix is in verifier.cc, as discussed in #44852. the second fix is for retrieving axis_value data in arg_min_max.cc. since the axis could be of type int64, it will cause an issue when retrieving it as int32 on big endian machines - it only retrieves the first 4 bytes which are the most significant bytes on big endian machines. retrieve it as int64 at first and then convert it to int32 will be safer and more consistent. edit: push another fix for lsh_projection_test, as discussed in #44982. ", "commit_messages": " change return type of getintptr() and correct endainness when needed  fix unguarded data type conversion from int64 to int in arg_min_max.cc  fix a typo ", "linked_issue_titles": "", "title": "fix for tf lite verifier, arg_min_max op and lsh_projection_test on big endian machine"}
{"description": " what do these changes do? fork() api will fork an actor handle explicitly that we could use it to do a other ray.calls. for serializer, we implicitly do fork when serializing recursively. for example: class myobject { private rayactor actor; } class myobject { private myobject1 obj1; } class myobject1 { private rayactor actor; } if the actor object actor is a field of another object obj(myobject), when we pass  obj by ray.call, the obj.actor's handleid will be changed to another id. n/a ", "commit_messages": " change the way to generate actor handle id.  lint ", "linked_issue_titles": "", "title": "allow actor handle to be serialized without forking"}
{"description": " update ndarrayiter api doc with csrndarray inputs update document for kv.init, kv.push add test for #7676 preview: ", "commit_messages": " update doc for ndarrayiter  update kvstore doc. remove int64 restriction for row_ids in rowsparse pull  add exception test for sparse op ", "linked_issue_titles": "", "title": "update doc for sparse related apis"}
{"description": " re-enabling some warnings that are required per sdl - going towards #6918. c4996, c4700, and c4611 were no longer needed. c4244 fixed with an explicit static cast to int. the only remaining suppressions blocking us from sdl compliance are coming from folly(4244 and 4267 being set off from toascii.h), which i will address next. ", "commit_messages": " restore c4700  restore c4996  restore c4611  c4244 local fix & restore  change files ", "linked_issue_titles": "", "title": "restoring warnings for sdl compliance"}
{"description": " runtime tested on rpi4 with justboom dac, justboom digi and hifiberry digi-pro that's it from my side, i think i'm through all the i2s cards i have here ", "commit_messages": " asoc: justboom-dac: use modern dai_link style  asoc: rpi-wm8804-soundcard: use modern dai_link style ", "linked_issue_titles": "", "title": "justboom-dac, rpi-wm8804-soundcard: use modern dai_link style"}
{"description": " review with \"hide whitespace changes\" is recommended. remove requireraw mock remove requiredemo mock (but make sure attempting to render a non-existent demo throws) skip transpiling code created by loader this was fairly expensive to do with large markdown files and we don't really need it. we can write es5 code directly instead. test plan ie 11 \"works\" localized content ssr and csr \"works\": ", "commit_messages": " preparemarkdown only handles markdown  [docs] remove requireraw mock ", "linked_issue_titles": "", "title": "remove mocks of require.context in markdown loader"}
{"description": " this is a hodge-podge addressing a few of the items in #17652.  individual commits should be item-specific(ish). remove unused lib.arrmap de-privatize _checknull_with_nat fix a couple of c warnings caused by timedelta_struct remove period._comparables ", "commit_messages": " remove unused func  remove unused period._comparables  fix c warnings, whitespace; remove unused func  de-privatize _checknull_with_nat ", "linked_issue_titles": "", "title": "cross off a few tslibs-todos"}
{"description": " the second part in a series of prs for adding annotation to np.core.multiarray. the improvements introduced by this pr fall in one of the following two categories: the addition of literal int-values for constants such as np.may_share_exact. the addition of dtype-support to the array constuctors that were recently moved from _asarray to multiarray (xref #18642). examples from typing import type_checking import numpy as np if type_checking: # note: revealed type is 'literal[0]' reveal_type(np.may_share_bounds) # note: revealed type is 'numpy.ndarray[any, numpy.dtype[numpy.floating*[numpy.typing._64bit*]]]' reveal_type(np.asarray(1, dtype=np.float64)) ", "commit_messages": " maint: move 9 constants from np to np.core.multiarray  maint: move 4 array constructors from np.core._asarray to np.core.multiarray  enh: use literals for the constants when possible  enh: add basic dtype-support to 4 array constructors  enh: allow array and empty_like to pass through subclasses if dtype=none  tst: update the typing tests for np.core.multiarray ", "linked_issue_titles": "", "title": "add annotations to np.core.multiarray part 2/4"}
{"description": " here are my copyedits to the byterun chapter. nothing major, mostly just typo fixes and formatting changes. there are three queries in the pr, on (new) lines 144, 314, and 393. ", "commit_messages": " started editing -- fixed em-dashes, standardized headers, etc...  copyedits  end of first pass  edits and changes to header levels  final pass edits ", "linked_issue_titles": "", "title": "copyedits to byterun interpreter chapter"}
{"description": " backport #2402, #2416, #2419 and #2708 into 0.10 release branch. also bumps c# and core version. ", "commit_messages": " remove chatty log messages on windows  zero-out channel after creation  better socket kick for windows.  now calling tcp_shutdown will in fact close the socket, which cascades into properly cleaning out all the pending requests.  the tcp_server_windows's shutdown logic had to be rewritted (simplified) in order to take this into account.  fix race in server shutdown  pick up nuget package version from cmdline param and fix nuget build  introduce version.cs as single source of truth of grpc c# version  make build_packages.bat provide version of grpc.native.csharp_ext dependency ", "linked_issue_titles": "", "title": "backport c# related fixes to 0.10 branch."}
{"description": " run lint for python and coffee scripts in the cibuild. ", "commit_messages": " :lipstick: fix violations against pylint.  add wrapper script for pylint.  run pylint in cibuild.  skip the check for lib.github.  add coffeelint to dependencies.  add wrapper script for coffeelint.  do not warn about 80 columns in coffeelint, it's not required. ", "linked_issue_titles": "", "title": "lint python and coffee scripts"}
{"description": " since the endianness of test dataset is little-endian, conversions are required on big-endian machines.  related issue is also written in #1730 this pr fixes small part of the issue, and we need to convert more to pass all onnx tests by pytest. however, this enables all of onnx-mlir test to pass. the test cases are written in test code i would like to hear your comments or suggestions about this approach. ", "commit_messages": " added big-endian support by converting little-endian data in numpy_helper  convert byte ordering only in test which uses little-endian data (removed previous modification to numpy_helper.py)  removed unnecessary modification for onnf test  removed unnecessary blank ", "linked_issue_titles": "", "title": "convert endianness of test dataset to pass tests of onnx-mlir on big-endian machines"}
{"description": " ref: kubernetes/org#2456 as a part of cleaning up inactive members (those with no activity within the past 18 months), this commit removes the following people from various owners files: @balajismaniam @gmarek @jianhuiz @madhusudancs @mbohlool @nikhiljindal @csbell this pr replaces #99073, #99075 and #99077 / /assign @liggitt ", "commit_messages": " *: move balajismaniam to emeritus_approvers  *: move gmarek to emeritus_approvers  *: remove jianhuiz from reviewers  *: remove madhusudancs from reviewers  owners_aliases: remove csbell from feature-approvers  *: remove mbohlool from reviewers  *: remove nikhiljindal from owners ", "linked_issue_titles": "", "title": "remove inactive members from owners - jan 2021"}
{"description": " they (security measures) are good in general, however there are some (valid) usages that require turning these off. gui screenshot webui screenshot ", "commit_messages": " update options dialog layout in webui  add option to control webui clickjacking protection  some users actually want embedding webui into their custom build iframe.  closes #7370. ", "linked_issue_titles": "", "title": "add options to control webui security measures"}
{"description": " since mi desk lamp isnt used by most users make it off by default the code change pass travis tests. your pr cannot be merged unless tests pass ", "commit_messages": " 6.4.1.16  update to 6.5.0.4  make mi desk lamp default off  mi desk lamp can be activated in my_user_config.h by setting uncommenting //#define rotary_v1 ", "linked_issue_titles": "", "title": "midesk lamp not default activated"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. cc:/ @peombwa @ddyett @zengin ", "commit_messages": " merge  from definitelytyped/master  update local definatelytyped  update typings to 1.13  fixed linting errors ", "linked_issue_titles": "", "title": "update microsoft-graph typings to 1.13"}
{"description": " reduce many overheads in saving and loading multi-threading save and load still use text format. binary format will be added after this pr. both saving and loading are about 10x faster now. ", "commit_messages": " remove protobuf  add version number  remove pmml script  use float for split gain  fix warnings  refine the read model logic of gbdt  fix compile error  improve decode speed  fix some bugs  fix double accuracy problem  fix bug  multi-thread save model  speed up save model to string  parallel save/load model  fix some warnings. ", "linked_issue_titles": "", "title": "speed up saving and loading model"}
{"description": " this patch adds a new class_mode to keras.preprocessing.image.imagedatagenerator.flow_from_directory method. this new class_mode is 'identical' and it allows to generate minibatches where the target values are identical to input values. it makes working with autoencoders trivial. this issue has been described in #4260. the patch also contains tests that ensure that the input images are not the same numpy array as target images. ", "commit_messages": " identical class_mode code.  new directory iterator testing function ", "linked_issue_titles": "", "title": "add a directory iterator option to allow to work easily with autoencoders (issue #4260)"}
{"description": " when we moved from the workflow trigger event pull_request to pull_request_target (which we changed to allow forks to run visual snapshots), it resulted in a change of the pull request base sha. instead of relying on the github context for the merge base, we should use git merge-base to find the base sha. the merge base sha is then used to use a three-way comparison for prs (comparing the pr head sha against latest master and the merge base). ", "commit_messages": " add merge base output for job --> input to action-visual-snapshot  move to visual-diff job ", "linked_issue_titles": "", "title": "fix merge base for visual snapshots"}
{"description": " this pr includes a test that i've enabled in #13358 and another test that we've discussed in #13462 as well as some random cleanup while i'm at it. ", "commit_messages": " update dom fixture lockfile  bring back onsubmit bubble test  i found a test that was written more than 5 years ago and probably never  run until now. the behavior still works, although the api changed quite  a bit over the years.  seems like this was part of the initial public release already:    add test to make sure interim native events are prevented  for more information, see #13462  make sure all dom mutations are cleaned up ", "linked_issue_titles": "", "title": "improve test harness of submit events"}
{"description": " closes #2732 ", "commit_messages": " update data for nc 6/21  update data for nc 6/21  update data for nc 6/21  update data for nc 6/21  update data for nc 6/21  update data for nc 6/21  update data for nc 6/21 ", "linked_issue_titles": " nc, ms, or, ri state and county data not updated for 6-21 ", "title": "2732 update june 21 data for nc"}
{"description": " 1/ updates nimble to the release version 1.1.0 2/ adds mqtt discovery for homeassistant users under 'setoption19 1' yes, i know this is the 'old' way, but the 'new' way is unsuited to tasmota discoverable sensors this also adds publish of each sensor on a separate topic, not related to the publishing tasmota (only if setoption19). 3/ removes ble stats from /sensors mqtt (never should have been there) - publishes instead to /ble 4/ sets the default address filter in ble to 0 - public static addresses only this hides random addresses created by mobiles.  if you want these (e.g. you want to hear covid announcments), do bleaddrfilter 1.  most users will not want to see them. 5/ add mi32option5 if mi32option5 1 then only mi devices which have blealias defined for them will be heard by mi.  all devices are removed at the point of setting 1. related issue (if applicable): fixes # the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works on tasmota core esp32 v.1.0.5-rc6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " nimble release 1.1.0  ha discovery via mqtt for ble mi sensor devices  update nimble to 1.1.0 release.  remove ble stats from sensor, publish in ble.  set default address filter to 0  add ha mqtt discovery to mi ", "linked_issue_titles": "", "title": "update nimble to release verison 1.1.0 + adds mqtt discovery for mi sensors using new ble"}
{"description": " meta: mark the other image file formats as binary in .gitattributes we had rules for .png and .jpg files, but we have not maintained the list as support for other file formats has been added. to test these changes test files have been committed for each of these formats. this change updates the list with all of the binary image file types i was able to find in the tree at the time of writing. meta: cleanup stale rules from .gitignore the wild card rules at the top of the .gitignore came from a time when the build wrote back to the git repository and placed files right next to the source. (original commit that introduced them 37c27e2, they were later consolidated into the root .gitignore in 802d4dc) we have since moved to cmake, and these rules have become obsolete, and they just cause issues where we need to go and add negations for these rules in order for things to work. a previous change attempted to remove the top wild card rules (pr #4565) but it was later reverted, as they forgot to remove the top ignore everything rule '*', so all files were ignored. this change just removes all of these rules that no longer make sense, restoring a bit of sanity. .o,.d,*.a rules were also from when the build wrote to the repository, they are now defunct. the same goes for the *endpoint.h and cmakefiles rules. the lowercase build directory can be removed as we've standardized on the uppercase 'build' directory as the root of the build output dir. ", "commit_messages": " meta: cleanup stale rules from .gitignore  the wild card rules at the top of the .gitignore came from a time when  the build wrote back to the git repository and placed files right next  to the source. (original commit that introduced them 37c27e2e, they were  later consolidated into the root .gitignore in 802d4dc) we have since  moved to cmake, and these rules have become obsolete, and they just  cause issues where we need to go and add negations for these rules in  order for things to work.  a previous change attempted to remove the top wild card rules (pr #4565)  but it was later reverted, as they forgot to remove the top ignore  everything rule '*', so all files were ignored. this change just removes  all of these rules that no longer make sense, restoring a bit of sanity.  *.o,*.d,*.a rules were also from when the build wrote to the repository,  they are now defunct. the same goes for the *endpoint.h and cmakefiles  rules.  the lowercase build directory can be removed as we've standardized on  the uppercase 'build' directory as the root of the build output dir.  meta: mark the other image file formats as binary in .gitattributes  we had rules for .png and .jpg files, but we have not maintained the  list as support for other file formats has been added. to test these  changes test files have been committed for each of these formats.  this change updates the list with all of the binary image file types i  was able to find in the tree at the time of writing. ", "linked_issue_titles": "", "title": "cleanup stale rules form .gitignore + update .gitattributes"}
{"description": " as the new textcat_multilabel component has been released as part of v3, it should be documented in some more detail as well. v3 migration guide warning note on textcat architectures warning note on \"normal\" textcat to point to changed functionality in comparison to v2 added the component to some lists of built-in components added the link to the api sidebar. unfortunately it splits over 2 lines though (cf image). @ines: wat do you think? docs update i have submitted the spacy contributor agreement. ", "commit_messages": " add multi-label textcat to menu  add infobox on textcat api  add info to v3 migration guide  small edits  further fixes in doc strings  add infobox to textcat architectures  add textcat_multilabel to overview of built-in components  spelling ", "linked_issue_titles": "", "title": "textcat scoring fix and multi_label docs"}
{"description": " doc fixes and limiting options to supported services ", "commit_messages": " update documentation for rax module  only list the services supported  don't put in unncessary required: false  use better formatting for the example  only accept supported services for rax module  even though others are possible, fail early on unsupported ones. ", "linked_issue_titles": "", "title": "minor fixes to the rax module"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < ", "commit_messages": " update test  added missing axis field ", "linked_issue_titles": "", "title": "added missing axis field to hover options"}
{"description": " vendoring: vishvananda/netlink 734d02c libnetwork  ed311d0 update check-config.sh to check for optional modules needed for secure datapath fixes #22185 fix for moby/libnetwork#1247 fixes crash at boot when xfrm modules are missing or are not autoloaded for the bugs with an issue open, refer to the issue description. for the crash, move the following file somewhere else and boot the daemon: /lib/modules/$(uname -r)/kernel/net/xfrm/xfrm_user.ko - more info about the crash originally reported offline by @fxdgear and @lk4d4 on  antegros and gentoo linux erro[0001] could not create netlink handle on initial namespace: protocol not supported panic: runtime error: invalid memory address or nil pointer dereference goroutine 1 [running]: panic(0x1467cc0, 0xc420012100) /home/moroz/go/src/runtime/panic.go:500 +0x1a1 github.com/vishvananda/netlink.(*handle).linkbyname(0x0, 0xc42085a6c0, 0xf, 0x20220c0, 0x68b249, 0x20220b8, 0x68b0d9) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/vishvananda/netlink/link_linux.go:759 +0x37 github.com/docker/libnetwork/drivers/bridge.newinterface(0x0, 0xc4205f7f40, 0xc4202a0f28) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/interface.go:41 +0xb9 github.com/docker/libnetwork/drivers/bridge.(*driver).createnetwork(0xc42061c000, 0xc4205f7f40, 0x0, 0x0) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/bridge.go:628 +0x39d github.com/docker/libnetwork/drivers/bridge.(*driver).populatenetworks(0xc42061c000, 0x5, 0x1645258) /home/moroz/project/workspace/src/github.com/docker/docker/vendor/src/github.com/docker/libnetwork/drivers/bridge/bridge_store.go:48 +0x1e8 ", "commit_messages": " vendoring vishvananda/netlink 734d02c  vendoring libnetwork  ed311d0 ", "linked_issue_titles": "", "title": "update check-config.sh, netlink and libnetwork vendoring"}
{"description": " based off #19946 ", "commit_messages": " [v1.x] migrate to use ecr as docker cache instead of dockerhub (#19654)  [v1.x] update ci build scripts to install python 3.6 from deadsnakes repo (#19788)  * install python3.6 from deadsnakes repo, since 3.5 is eol'd and get-pip.py no longer works with 3.5.  * set symlink for python3 to point to newly installed 3.6 version.  * setting symlink or using update-alternatives causes add-apt-repository to fail, so instead just set alias in environment to call the correct python version.  * setup symlinks in /usr/local/bin, since it comes first in the path.  * don't use absolute path for python3 executable, just use python3 from path.  disable unix-gpu-cu110 pipeline for v1.x build since we now build with cuda 11.0 in windows pipelines. (#19828)  [v1.x] for ecr, ensure we sanitize region input from environment variable (#19882)  * set default for cache_intermediate.  * make sure we sanitize region extracted from registry, since we pass it to os.system.  [v1.x] address ci failures with docker timeouts (v2) (#19890)  * add random sleep only, since retry attempts are already implemented.  * reduce random sleep to 2-10 sec.  [v1.x] ci fixes to make more stable and upgradable (#19895)  * test moving pipelines from p3 to g4.  * remove fallback codecov command - the existing (first) command works and the second always fails a few times before finally succeeding (and also doesn't support the -p parameter, which causes an error.)  * stop using docker python client, since it still doesn't support latest nvidia 'gpus' attribute. switch to using subprocess calls using list parameter (to avoid shell injections).  see  * remove old files.  * fix comment  * set default environment variables  * fix gpu syntax.  * use subprocess.run and redirect output to stdout, don't run docker in interactive mode.  * check if codecov works without providing parameters now.  * send docker stderr to sys.stderr  * support both nvidia-docker configurations, first try '--gpus all', and if that fails, then try '--runtime nvidia'.  fix cd  fix cudnn version for cu10.2 buiuld  war the dataloader issue with forked processes holding stale references (#19924) ", "linked_issue_titles": "", "title": "attemp to fix cd for v1.8.x"}
{"description": " i hereby agree to the terms of the cla available at:  changelog category: documentation for  #17832 ", "commit_messages": " edited original article  added russian translation  minor fixes  fixed typos  resolving symling issue  resolving symlink issue  fixed a mistake  minor improvements ", "linked_issue_titles": "", "title": "edited and translated to russian"}
{"description": " the validate parameter was missing from the constructor's signature (it was already documented in the text lower down, but missing from the signature). clarify that the style parameter is for the fmt parameter, not for log messages. on my first read of the documentation i thought this was saying that logging had built-in support for {format} style log messages. ", "commit_messages": " doc: logging.formatter: add missing validate argument  this is already documented in the text lower down, it was just missing  from the constructor's signature.  doc: logging.formatter: clarify what the style parameter is for  i found this confusing: on my first read of the documentation i thought  this was saying that logging had built-in support for {format}  style log messages. ", "linked_issue_titles": "", "title": "add missing validate parameter, clarify style parameter"}
{"description": " skydive is a network analyzer tool, which helps in analyzing sdns and network and with this pr ansible api and lookup modules are added to query skydive objects using skydive python client. opened new pr closing the earlier skydive pr #50136 new module pull request skydive ", "commit_messages": " skydive node and edge module  skydive node and edge module  skydive node and edge module ", "linked_issue_titles": "", "title": "pr to include support for skydive node and edge modules with ansible"}
{"description": " what do these changes do? rllib agents now declare their resource requests to tune, so as a user you don't have to. also add a --queue-trials option to tune, which will allow a trial to be scheduled even if it somewhat exceeds the resource capacity of the cluster. this should allow rllib to work with autoscaling clusters in many cases. couple caveats: if the cluster has 0 gpus it won't queue, this is to avoid hangs forever if the cluster would not add more gpus in the future. it's possible some odd shaped resource requests will queue but not trigger auto-scaling, or remain infeasible after autoscaling (e.g. request num cpus greater than the max any single machine can offer). this can be mitigated by just using big machines and setting the autoscaling threshold lower. ", "commit_messages": " updates  updates  updates  updates  updates  updates  updates  updates  updates  updates  updates ", "linked_issue_titles": "", "title": "automatically determine rllib resources and add queueing mechanism for autoscaling"}
{"description": " a common user feedback for rllib developers is that its learning curve is quite steep. this pr aims to start a clean-up and code clarification process with the example of the pg algorithm. adds experimental jsonschema checking. adds lots of comments to algo code. adds readme.md to pg directory, linking to the correct doc section(s). minor other cleanups (docstrings, type annotations, etc..). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  wip.  wip.  wip.  wip. ", "linked_issue_titles": "", "title": "first attempt at cleaning up algo code in rllib: pg."}
{"description": " added an algorithm to approximate the area under a curve i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. ", "commit_messages": " a recursive insertion sort  added doctests and typehints  added arc length and numerical integration calculators  fixed doc test  fixed some conversion errors  fixed some commenting  deleted numerical integration to allow 1 file per push  changed string formatting method  added program to calculate trapezoidal area under curve  deleted files ensure 1 pull request per file  file name changed ", "linked_issue_titles": "", "title": "area under a curve algorithm"}
{"description": " the role management api documentation ( this change was discussed briefly in #32635 (comment) ", "commit_messages": " [docs] split roles apis into separate pages  [docs] addresses gradle errors  [docs] fixes get roles api examples  [docs] small edits ", "linked_issue_titles": "", "title": "splits the roles api documentation into multiple pages"}
{"description": " for issue #97. once you create a request, just run r.request.curl for the curl command. for example: >>> import requests >>> r = requests.get(\" >>> r.request.curl 'curl -l -x get -h \"accept-encoding:gzip\" -h \"user-agent:python-requests.org\" \" still have the following to do: oauth ", "commit_messages": " first commit of curl command from request  using build_url and also including headers  ive never seen anyone use the --'s unix command options  small cleanup  more small cleanup  adding check when _enc_data in none  whitespace ", "linked_issue_titles": "", "title": "issue #97 - turn a request into a curl command string"}
{"description": " fix the issue #12825 in the file python/mxnet/ndarray/contrib.py, the two functions then_func and else_func don't accept any parameter. the following example works. import mxnet as mx a, b = mx.nd.array([1]), mx.nd.array([2]) pred = a * b < 5 then_func = lambda: (a + 5) * (b + 5) else_func = lambda: (a - 5) * (b - 5) outputs = mx.nd.contrib.cond(pred, then_func, else_func) print (outputs[0]) please feel free to remove inapplicable items for your pr. tiny changes. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change fix example for mxnet.nd.contrib.cond fix typo in src/engine/{engine.cc, threaded_engine.h} ", "commit_messages": " fix typo in src/engine  fix example for mx.nd.contrib.cond ", "linked_issue_titles": "", "title": "fix example for mxnet.nd.contrib.cond and fix typo in src/engine"}
{"description": " in visual studio, we currently trigger directory watchers when saving an open file. in projects with sufficiently large dependencies (i.e., the asp.net core angular template), this causes the module resolution cache to be entirely invalidated, thereby triggering a seconds-long updategraph operation to occur. this change aims to prevent this scenario by checking if the file whose change triggered the directory watcher is still open and, if so, not invalidating the cache. ", "commit_messages": " stop invalidating resolution when file stays open  add test ", "linked_issue_titles": "", "title": "stop invalidating module resolution cache when saving an open file"}
{"description": " /area code-organization deviceplugin and pluginregistration are external facing apis. currently we are forcing folks to import them from k8s.io/kubernetes which is not optimal. we should instead make them available from the k8s.io/kubelet repo to make it easier for them. related to #82437 does this pr introduce a user-facing change?: external facing apis in pluginregistration and deviceplugin packages are now available under k8s.io/kubelet/pkg/apis/ ", "commit_messages": " move pkg/kubelet/pluginregistration and deviceplugin  change-id: i06adcb43bd278b430ffad2010869e1524c8cc4ff  update bazel build files  change-id: ia3917cec1453c0b22a958faf8c22bccd79242d14 ", "linked_issue_titles": "", "title": "move external facing kubelet apis to staging"}
{"description": " add in a chart for the vault-operator which issue this pr fixes: fix as pr based off of the etcd-operator ", "commit_messages": " starting work on the vault operator  get us some chart-y goodness!  starting work on the vault operator  get us some chart-y goodness!  vault operator chart lints  time to see if it works?  vault operators deploys!  need to test on a real k8s instance, now  starting work on the vault operator  get us some chart-y goodness!  vault operator chart lints  time to see if it works?  vault operators deploys!  need to test on a real k8s instance, now  don't set the etcd-operator to cluster-wide  cuz that'd be bad, mmkay?  validated to be awesome!  last step is to update docs  updated readme with all of the values  updated values  things noticed while documenting them ", "linked_issue_titles": "", "title": "introducing the vault operator chart"}
{"description": " this runs git diff in the current repo and applies any git patches as code review comments on github. this allows authors to batch apply any auto lint/formatting suggestions and allow gh workflows to run after applying them. the previous method had the github actions token commit the changes, which does not allow workflows to trigger. see ", "commit_messages": " rm other workflows  testing ", "linked_issue_titles": "", "title": "git patch --> github review suggestion"}
{"description": " enable structural opaque types by default remove the -enable-experimental-structural-opaque-types frontend flag ban opaque types in parameter position, per the acceptance decision of se-0328. note that this restriction applies to some appearing anywhere in the parameter type, including positions that do not consume values from the caller, e.g. func test() -> ((some p) -> void) -> void { ... } resolves: rdar://85275081 ", "commit_messages": " [frontendoptions] enable structural opaque result types and remove  the -enable-experimental-structural-opaque-types frontend flag.  [sema] ban opaque types in parameter position. ", "linked_issue_titles": "", "title": "enable structural opaque result types."}
{"description": " this is part 2 of the 3 major pull requests i plan to do for adding tvos (appletv4) support to mainline. this basically allows us to compile kodi core for arm64 targets. i think its pretty straight forward. once this is in jenkins can build ios builds for arm64 (by simply manually building ios with arm64 cpu set). i plan to do beta, rc and final releases for ios 32bit and 64bit aswell once this is in (for krypton then). cydia supports providing both builds and doesn't allow to install the 64bit one on 32bit devices so this would be save. @wsnipex and maybe @koying or whoever is interested in looking it over. thx to @mrmc and @linusyang once again for finding the needed bits. @linusyang i think you have a much easier live in the future once this was merged (with your custom 64bit builds hehe). ", "commit_messages": " [darwin/support] - cleaned up osx and ios support scripts  [darwin/support] - some cleanups for the codesign script, added codesigning of python eggs (by extracting, signing, repackaging them) ", "linked_issue_titles": "", "title": "make kodi core arm64 aware"}
{"description": " this is an easy place to start, and these functions are probably safe. please review with it in mind that i want to add more fuzz tests later. while the fuzz tests are included in cpython and compiled / tested on a very basic level inside cpython itself, the actual fuzzing happens as part of oss-fuzz ( (this will be necessary sometimes because e.g. the fuzz test should never enter python's interpreter loop, whereas some apis only expose themselves publicly as python functions.) the corresponding oss-fuzz pr adding cpython to oss-fuzz is google/oss-fuzz#731 this particular set of changes is part of testing python's builtins, tracked internally at google by b/37562550. btw, i think the code here is pretty questionable, and am not happy with how complex it is to add a new fuzz test. i'd appreciate input on how to make this friendlier.  i'm also new to cpython and c/c++ development as a whole and suspect i've done everything wildly wrong. (in particular, i think the fuzzer should be written in c, but can't figure out how to make that compile -- see commit cb9cdc0). ", "commit_messages": " add basic fuzz tests for a few common builtin functions.  this is an easy place to start, and these functions are probably safe.  please review with it in mind that i want to add more fuzz tests later.  while the fuzz tests are included in cpython and compiled / tested on a  very basic level inside cpython itself, the actual fuzzing happens as  part of oss-fuzz (  include the tests in cpython is to make sure that they're maintained  as part of the cpython project, especially when (as some will) they  use internal implementation details in the test.  (this will be necessary sometimes because e.g. the fuzz test should  never enter python's interpreter loop, whereas some apis only expose  themselves publicly as python functions.)  this particular set of changes is part of testing python's builtins,  tracked internally at google by b/37562550.  remove fuzzing of hash() per comment by kcc / oss-fuzz-team.    move llvmfuzzertestoneinput into cpython and tweak how test discovery occurs.  i'm still not happy with how many times i need to repeat the fuzz test name.  this can go wrong way too easily. :/  move the fuzzer to c++ so that it builds.  it's possible there's a way to compile this with clang and then link it with  clang++, but i don't know how to do that.  specifically, compilation fails with this:  $cc $cflags \\  -d _py_fuzz_one -d _py_fuzz_$fuzz_test \\  -wno-unused-function \\  $($out/bin/python3-config --cflags) -g -o1 \\  $fuzz_dir/fuzzer.c -o $out/$fuzz_test -lfuzzingengine \\  $($out/bin/python3-config --ldflags)  with errors like:  /usr/local/bin/../include/c++/v1/new:234: undefined reference to operator delete(void*)'  but it works just fine with this:  $cxx $cxxflags \\  -d _py_fuzz_one -d _py_fuzz_$fuzz_test \\  -wno-unused-function \\  $($out/bin/python3-config --cflags) -g -o1 \\  $fuzz_dir/fuzzer.c -o $out/$fuzz_test -lfuzzingengine \\  $($out/bin/python3-config --ldflags)  presumably there are ways to do this in c, so for expediency i'm doing it in c++  right now, with the minimal possible c++ changes (extern \"c\"), so that if i need  to change it back to c in code review, it won't be too hard.  run the fuzz smoke tests on a little more input, just for kicks.  (i.e. just to get increased confidence we won't immediately crash on fuzzing.)  i'm using s# because i'd like to minimize the diff between python 2 and 3.  make the _fuzz module optional. ", "linked_issue_titles": "", "title": "add fuzz tests for float(str), int(str), unicode(str)"}
{"description": " general reference: #2339 description: change css output file name to style.css fix test against css file update documentation after output file rename bump package.json after running npm run build documents change in changelog.md i have read the contributing document. additional notes as i noticed, the styling for boilerplate come from the npm package called main.css and it seems to be a bit confusing on a first look. since that package is strongly connected to this project, we might consider: rename it to something that will not affect filename e.g.: html5-boilerplate-styling reorganize repositories to use scoped packages (with @ symbol) e.g.:  @html5-boilerplate/styling ", "commit_messages": " change css output file name to style.css  fix test against css file  update documentation after output file rename  bump 'package.json' after running build ", "linked_issue_titles": "", "title": "rename main.css to style.css in build process"}
{"description": " these used to make sense when we had static allocations in js. we'd use the \"bump\" to track the total size, which was increased by the js compiler, and at runtime we'd have static_base and statictop. now that we disallow static allocations from the js compiler, we don't need them. note that we do still track \"staticbump\" in the metadata from finalize. that is the total size of static memory from lld, which never changes. we use it to compute where the stack begins (which determines the rest of memory layout). in principle since all that layout was done by lld, we could just receive it from there instead of computing it in emscripten.py. perhaps finalize should return the value of __heap_base and other relevant globals? is there a list of all of them? see #11860 ", "commit_messages": " remove static_bump setting and statictop variable  remove static* runtime vars  fix  fix test ", "linked_issue_titles": "", "title": "remove static* js vars and static_bump setting"}
{"description": " removes mentions of asm.js and other unneeded things, and focuses on hopefully more useful content. also fixes the aspect ratio of some of the pngs, which were converted oddly from the svg. this affected the landing page on github ", "commit_messages": " wip [ci skip]  more ", "linked_issue_titles": "", "title": "improve the main emscripten landing pages"}
{"description": " as per my observations based on error stack and googling the things: animal sniff plugin is a bit strict on getting the signatures right especially when the complied java version is different than the target version and there is method signature changes. error: java.lang.nosuchmethoderror: java.nio.bytebuffer.mark()ljava/nio/bytebuffer; maybe these are existing issues but there were caught now at compile time after we upgraded the plugin. as this is blocking the maven release for version 8.10.14, reverting the release commit as well as it contains new dependency jars generated. eg: tools/java/java-build/target/java-build-1.0-snapshot-jar-with-dependencies.jar ", "commit_messages": " revert \"metadata updates for release 8.10.14 (#2354)\"  this reverts commit 6e2bbb0c05fece3d1dfcd19cb12b27d03acfde4b.  revert metadata updates for release 8.10.14 (#2354) as the dependency jars generated has issues reported by animal-sniff plugin  revert \"'animal-sniffer-maven-plugin' changes: version is upgraded and extracted into root pom.xml (#2349)\"  this reverts commit e7c4f396917ca64e7618f7dd4788aee509d42332.  making changes back that we mistakenly reverted falsehood commit ", "linked_issue_titles": "", "title": "reverting animal sniff plugin version update pr #2349 and release pr of 8.10.14 #2354"}
{"description": " issue: #1796 fixed the jest incompatibility with mock-fs by switching to jest.mock() unit tests should pass ", "commit_messages": " chore(package): update jest to version 21.0.1  closes #1796  remove mock-fs and replace it with jest.mock() ", "linked_issue_titles": "", "title": "update jest to the latest version"}
{"description": " fixes #991 assign equation colors starting with the first unused color manual tests ", "commit_messages": " fix two pane crash on closing window  merge master  recycle equation colors ", "linked_issue_titles": " equation colors should be recycled as soon as they are no longer in use to maximize contrast ", "title": "recycle equation colors when no longer in use"}
{"description": " that pass is a pure optimization: it removes calls to atexit when they would be ignored anyhow (exit_runtime == 0). this removes a warning in atexit's implementation that was never actually called before: we used to always run that pass, so if exit_runtime == 0 then we never had any calls to atexit anyhow. now that we only run the pass when optimizing, leaving that warning would be a noticeable change (and it broke some tests actually!) so just remove it. with that, this is essentially nfc except that non-optimized builds may be a little larger (containing calls to atexit that end up doing nothing). helps webassembly/binaryen#3043 ", "commit_messages": " run --no-exit-runtime only when optimizing. see  remove a warning that was never actually shown ", "linked_issue_titles": "", "title": "only run --no-exit-runtime when optimizing"}
{"description": " merge with contrib: opencv/opencv_contrib#2506 relates #16736 opencv_contrib's sift.cpp history. todo: (backlog #16736) 2 disabled sift tests (backlog #16736) fix c++ compatibility? cv::xfeatures2d::sift::create() (problem is due msvs ambiguous errors) fix python bindings compatibility? cv.xfeatures2d.sift_create() (backlog #16736) fix java bindings compatibility? org.opencv.features2d.sift.create() fix samples / docs allow_multiple_commits=1 ", "commit_messages": " [move sift.cpp] fixed contrib code to match the hal  original commit:  [move sift.cpp] fixed hal headers location  original commit:  [move sift.cpp] fix overflow issue when computing diagonal  - with big images the int multiplication can overflow  original commit:  [move sift.cpp] update sift.cpp  original commit:  [move sift.cpp] optimize sift with avx2  original commit:  [move sift.cpp] parallelize calcdescriptors and builddogpyramid. simplify 2 lines of avx2 instructions  original commit:  [move sift.cpp] multithreading findscalespaceextremacomputer. sort the keypoints afterwards to make the output stable  original commit:  [move sift.cpp] use tls instead of mutex in sift  original commit:  [move sift.cpp] remove unnecessary _mm256_round_ps  original commit:  [move sift.cpp] updated internal calls to linear resize to use bit-exact version  original commit:  [move sift.cpp] xfeatures2d: apply cv_override/cv_final  original commit:  [move sift.cpp] opencv: use cv::autobuffer<>::data()  original commit:  [move sift.cpp] xfeatures2d: use updated tls api  original commit:  [move sift.cpp] merge pull request opencv/opencv_contrib#2301 from ab-dragon:conditionally_compute_dog_pyramid  build dog pyramid if useprovidekeypoints is false  the builddogpyramid operation need not be performed unconditionally. in cases where it is not needed, both memory and speed performance can be improved  original commit:  [move sift.cpp] sift: perf tests and trace regions  original commit:  [move sift.cpp] sift: avoid inplace calls of gaussianblur  - should unlock ipp optimizations  original commit:  features2d(sift): code from nonfree module  features2d(sift): patent expiration note  merge upstream branch  [move sift.cpp] refactored xfeatures2d in the same style as features2d  original commit: ", "linked_issue_titles": "", "title": "move sift to main repository"}
{"description": " when running a custom install of chrome, and not downloading chromium (with the puppeteer_skip_chromium_download, image snapshots are unable to start up.  i ran across this issue when running storyshots inside a docker container already containing a chrome installation. add a config parameter to use a chrome executable path, instead of downloading chromium inside of puppeteer.  if no parameter is selected, defaults to undefined and operates as normal. add a parameter and check if it references the correct chrome.  in my case: /usr/local/bin/chrome ", "commit_messages": " feature: add config to supply executable chrome path to puppeteer  update readme ", "linked_issue_titles": "", "title": "feature/config custom chrome executable path"}
{"description": " upgrade typescript example to chakra ui v1 upgrade to react 17 patch some missing parts and fix broken icons in non typescript example add example how to persist color mode when you refresh the page:  source: ", "commit_messages": " upgrade to chakra ui v1  update theming in chakra ui example to match v1  fix icons  set container height to fill screen height ", "linked_issue_titles": "", "title": "update chakra ui examples to v1"}
{"description": " fixes #87718 the problem was that synth_type_param_count was already subtracted from named_type_param_count, so this ended up being subtracted again. this caused expected_min to overflow, and ultimately resulting in weird and wrong behaviour. i've also added another test not present in the original issue but caused by the same bug. ", "commit_messages": " fix overflow when calculating expected_min in generics diagnostics  add regression tests ", "linked_issue_titles": " ice: 'assertion failed: num_missing_args > 0', compiler/rustc_typeck/src/structured_errors/wrong_number_of_generic_args.rs:234:17 ", "title": "explicit_generic_args_with_impl_trait: fix min expected number of generics"}
{"description": " fixes googleapis/google-cloud-ruby#1327 this only fixes the immediate bug on the client side. it looks like this is still an issue on the server side but thinking that can be done in a follow up pr. it looks like the crash happens because there are stack-allocated things that are reachable through ruby finalizers. normally these stack-allocated objects are safe because their scope is local to the function they're used in. but in the case that a thread is killed during the middle of this rpc function call, finalizers wind up hitting use-after-free errors (only on os x) when they reference something on the killed (and apparantly freed) thread's stack. in general it looks like it's not safe to put anything on stack that's reachable through ruby finalizers. looking into this: slight variation of repro in that issue that just falls off of main while there's an active rpc on a child thread, so that same crash happens under lldb: greeter_server.rb tweaked to: def say_hello(hello_req, _unused_call) sleep 10 helloworld::helloreply.new(message: \"hello #{hello_req.name}\") end greeter_client def main stub = helloworld::greeter::stub.new('localhost:50051', :this_channel_is_insecure) user = argv.size > 0 ?  argv[0] : 'world' thd = thread.new do message = stub.say_hello(helloworld::hellorequest.new(name: user)).message p \"greeting: #{message}\" end sleep 3 end under lldb on os x: first the client starts an rpc and calls run_batch. in here, it stack allocs run_batch_stack it then initializes the run_batch_stack and sets the recv_data_buffer of the \"c-core\" batch pointing to a member of that run_batch_stack lldb shows: (lldb) breakpoint set --file rb_call.c --line 697 breakpoint 2: where = grpc_c.bundlegrpc_run_batch_stack_fill_ops + 663 at rb_call.c:697, address = 0x0000000102102c67 (lldb) continue process 38291 resuming process 38291 stopped * thread #5: tid = 0x50844, 0x0000000102102c67 grpc_c.bundlegrpc_run_batch_stack_fill_ops(st=0x00000001034ffd00, ops_hash=4304184960) + 663 at rb_call.c:697, name = 'greeter_client*', stop reason = breakpoint 2.1 frame #0: 0x0000000102102c67 grpc_c.bundlegrpc_run_batch_stack_fill_ops(st=0x00000001034ffd00, ops_hash=4304184960) + 663 at rb_call.c:697 694 \t            &st->recv_metadata; 695 \t        break; 696 \t      case grpc_op_recv_message: -> 697 \t        st->ops[st->op_num].data.recv_message.recv_message = &st->recv_message; 698 \t        break; 699 \t      case grpc_op_recv_status_on_client: 700 \t        st->ops[st->op_num].data.recv_status_on_client.trailing_metadata = (lldb) print &st->recv_message (grpc_byte_buffer **) $3 = 0x00000001034fffb8 then continue until segfault: (lldb) continue process 38291 resuming process 38291 stopped * thread #1: tid = 0x50821, 0x000000010213deab grpc_c.bundleprocess_data_after_md(exec_ctx=0x00007fff5fbff3f0, bctl=0x0000000102808690) + 59 at call.c:1202, queue = 'com.apple.main-thread', stop reason = exc_bad_access (code=1, address=0x1034fffb8) frame #0: 0x000000010213deab grpc_c.bundleprocess_data_after_md(exec_ctx=0x00007fff5fbff3f0, bctl=0x0000000102808690) + 59 at call.c:1202 1199\t                                  batch_control *bctl) { 1200\t  grpc_call *call = bctl->call; 1201\t  if (call->receiving_stream == null) { -> 1202\t    *call->receiving_buffer = null; 1203\t    call->receiving_message = 0; 1204\t    finish_batch_step(exec_ctx, bctl); 1205\t  } else { where the 0x1034fffb8 address in exc_bad_access (code=1, address=0x1034fffb8) is pointing the earlier &st->recv_message ", "commit_messages": " add test in that sends a sigint to client while its making an rpc ona  child thread - segfaults on mac  allocated run batch stack on the heap  conform test to formatter  malloc run_batch_stack after type checks  wording fix in comments ", "linked_issue_titles": "", "title": "handle dropped ruby threads during active calls - client side"}
{"description": " my submission is formatted according to the guidelines in the contributing guide all changes have been squashed into a single commit ", "commit_messages": " added litelink in url shorteners  corrected ordering in url shorteners ", "linked_issue_titles": "", "title": "added litelink for url shorteners"}
{"description": " future releases of atom-shell will be published to the releases page, instead of uploading to s3. ", "commit_messages": " add process.getcurrentstacktrace(), returning v8::getcurrentstacktrace().  add a simple wrapper of github api.  accept still-preview apis.  correctly deal with api errors.  create new release note or get the existing one when uploading.  :lipstick: find the release even when commit isn't tagged.  handle the assets uploading in the github api library.  upload the asset after release note is created.  silence the output of upload script.  upload both atom-shell and node's headers.  publish the release after the uploading is end.  get the body of release with current $editor.  :lipstick: fix cpplint warnings. ", "linked_issue_titles": "", "title": "upload atom-shell's binaries with releases api"}
{"description": " this also rewrites the hello world example to use the generated code. this resolves #5418. note: code generated here will only work if using a copy of protoc patched with protocolbuffers/protobuf#1274. the modified example depends on the \"google-protobuf\" npm package, which has not yet been published. code generated by this generator is not api-compatible with code dynamically generated by grpc using protobuf.js. most importantly, request and response objects must be protobuf message objects, not plain javascript objects. i chose a couple of names kind of arbitrarily: service code from \"filename.proto\" is generated in \"filename_grpc_pb.js\" if \"name.proto\" contains a service \"greeter\", then the client constructor is require('name_grpc_pb.js').greeterclient and the service definition is require('name_grpc_pb.js').greeterservice. ", "commit_messages": " created a node grpc plugin  rewrite node greeter example to use generated code  minor change to node generator, and add a folder ", "linked_issue_titles": " node.js protoc plugin ", "title": "create a protoc plugin for node.js grpc"}
{"description": " some minor parts of ast and hir were not visited by the visit::walk_xxx methods - some identifiers, lifetimes, loop labels, attributes of exported macros - but nothing as serious as in, for example, #28364. added a convenience macro for visiting lists (including options) removed some pre-deref-coersions &** noise from visitors r? @nrc ", "commit_messages": " fill in some missing parts in the default ast visitor  + add helper macro for walking lists (including options)  fill in some missing parts in the default hir visitor ", "linked_issue_titles": "", "title": "fill in some missing parts in the default ast and hir visitors"}
{"description": " this is mostly to get the grunt work of the way. this is split up into multiple commits to hopefully make it more manageable to review. note that these are not full implementations, and the bindings mostly get the low hanging fruit. also implements some attributes that i kept out because they had dashes in them. therefore, this closes #2905. ", "commit_messages": " libweb: make all existing html elements \"final\"  libweb: add all html elements between a and f  libweb: add all html elements between l and q  libweb: add all html elements between s and v ", "linked_issue_titles": " libweb: some attributes may have a dash in them ", "title": "add all currently missing html elements"}
{"description": " preview : ", "commit_messages": " add percpu to export module  correct an issue on quiet mode, refresh time is not take into account  add system and uptime to the export module  avoid crach on olds kernels (issue #554)  change documentation - add color keyword (issue #527)  add docker plugin ", "linked_issue_titles": "", "title": "add docker plugin on angularjs web ui"}
{"description": " i am working to get all languages in grpc/grpc to share a common set of proto files. this is the first in a series of prs to fix #526 ", "commit_messages": " moving test.proto to an outer directory so others can depend on it.  move .proto files up for reuse ", "linked_issue_titles": " proto proliferation ", "title": "move proto files up the tree to prepare for sharing."}
{"description": " #3599 the goal was to match the behavior of $near in tests to mongo as close as possible in tests. as such, all the tests i added or updated have been run on server mongo before i started fixing the code. here's the issues i discovered: in mongo, sort as an option overrides $near sort completely and does not use $near as a tie-breaker. when using $near to query an array with an update, mongo always uses the first matching index to update. mongo and minimongo differ in the behavior of observe and applying changes. this seemed out of scope and possibly not an issue for this ticket. mongo does not throw an error on find with $near when it's not a top-level operator like \"{$and:{$near\". instead, it throws an error on fetch(). as such, i thought the current behavior of minimongo (throwing an error on find) is acceptable. ", "commit_messages": " sort overrides $near sort - minimongo (#3599)  using $near to query with an update (#3599)  more test cases for update with $near (#3599)  comment grammar (#3599) ", "linked_issue_titles": "", "title": "match $near behavior in minimongo to mongo"}
{"description": " this pr makes sure that no mask_indices are predicted for padded tokens and thus ensures that the loss for padded tokens is always ignored.  training run is started for wav2vec2 in flax. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " fix_torch_device_generate_test  remove @  x::qxx  xmerge branch 'master' of  :wqa:merge branch 'master' of  :wmerge branch 'master' of  :wqa:\tmerge branch 'master' of  start adding tests  correct wav2vec2 pretraining ", "linked_issue_titles": "", "title": "correctly pad mask indices for pretraining"}
{"description": " a paragraph in the contribution guidelines, following a comment by @reshamas #12878 (comment) ", "commit_messages": " doc: instructions for stalled prs  doc: topic -> sections  the goal of this change is to make it easier to find the corresponding  information. ", "linked_issue_titles": "", "title": "how to deal with stalled pr"}
{"description": " depends on #19882 the transactions table only included the sampling key clause in april (for on prem). there is no possible migration there without migrating to a new table. people may have already created that table and there is no support for data migrations in snuba yet. if we start having users using tracing/preformance on prem, who created the table long before that they may run into troubles when they have enough data in the transactions table to trigger the sampling rate. snuba would reject those queries. this honors the flag introduced in #19882 ", "commit_messages": " disable sampling on tag facet  remove option ", "linked_issue_titles": "", "title": "fix(discover) honor discover2.tags_facet_enable_sampling when applying sampling"}
{"description": " fixes #5484 this change prepares us to use rntester as the primary app for end-to-end ui integration tests.  currently we use our own app inside e2etest.  this will limit us as we'd need to create test pages from scratch.  we already have a lot of potential test coverage with rntester, and we can add whatever pages we want to it as well, so let's use rntester instead. this change moves the 6 existing test pages over to rntester and makes the necessary changes to the test app to load rntester instead of the current app. microsoft reviewers: open in codeflow ", "commit_messages": " first batch of changes  change files  lint ", "linked_issue_titles": " convert existing e2e test pages to rntester pages ", "title": "move e2etest pages into rntester"}
{"description": " closes #21063 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry the _gotitem implementation for dataframe seems a little strange so there may be a more comprehensive approach, but this should prevent the issue for the time being didn't add whatsnew yet since none existed for 0.23.1. happy to add if we are ok with this fix ", "commit_messages": " added test for failure  prevented unlimited recursive aggregation  lint fixup ", "linked_issue_titles": " segfault in dataframe.apply with duplicate column names and multiple aggfuncs ", "title": "prevent unlimited agg recursion with duplicate col names"}
{"description": " fixes #6769 when vswhere is missing (or we fail to find msbuild tools), we fail to print an error message before exiting microsoft reviewers: open in codeflow ", "commit_messages": " print error message when vswhere is missing  change files ", "linked_issue_titles": "", "title": "print error message when vswhere/msbuild tools are missing"}
{"description": " for #69955 ", "commit_messages": " quick omni - very basic first registry  quick omni => quick access  quick access - very basic first help entries  quick access - operate on picker from providers  quick access - test coverage  quick access - implement help provider  quick access help bugixes  quick access :lipstick:  quick access - contribute help for standalone and workbench separately  quick input - allow to set aria-label  quick access - improved help grouping  quick access - allow provide to return disposable and cancel token properly  quick access - implement \"go to line\"  quick access - implement view handler ", "linked_issue_titles": "", "title": "first cut quick access providers"}
{"description": " this fix carries #35609, and removed the getblkioweightdevices as it is not compiled in windows. this fix closes #35609. ", "commit_messages": " remove import of opencontainers/runc in windows  we are planning to remove supports for non-linux platform in  runc (  import here is the only thing that i found in docker that is windows-related  so fixing this would remove the rest of windows code in runc.  this changes some functions in daemon_windows to be the same as  daemon_unix to use runtime-spec public api instead of runc.  remove getblkioweightdevices in daemon_windows.go as it is not needed ", "linked_issue_titles": "", "title": "carry #35609 (remove import of opencontainers/runc in windows)"}
{"description": " changed a method call to comply with coding conventions adding a pair of parenthesis to eliminate a warning given when postgres specs were run. warning was: \"/vagrant/rails/activerecord/test/cases/adapters/postgresql/uuid_test.rb:63: warning: ambiguous first argument; put parentheses or even spaces\" ", "commit_messages": " changing method call according to coding conventions  fix to remove warning on postgres adapter test.  warning was: \"/vagrant/rails/activerecord/test/cases/adapters/postgresql/uuid_test.rb:63:  warning: ambiguous first argument; put parentheses or even spaces\" ", "linked_issue_titles": "", "title": "fix to remove warning in postgres adapter test"}
{"description": " like the view method, the subject methods now accept an optional result tensor. the pr includes two new unit tests : expand and repeattensor. also fixes #59. ", "commit_messages": " initial commit for harmonized expand/expandas  expand unit test pass  expand/view doc++  initial commit for harmonized repeattensor  repeattensor unit test  harmonized repeattensor works (unit tested)  repeattensor doc updated ", "linked_issue_titles": " torch.repeattensor() doesn't work with non-contiguous tensor ", "title": "harmonized expand, expandas and repeattensor"}
{"description": " close the file handlers before deleting the logging handlers so that there is no resource warning. since the handlers are a weakreference i tried to close them by calling self.close on __del__ but not all handlers have the lock attribute which resulted in attributeerror. shutdown handles the attributeerror and other scenarios but it will be a much cleaner if we close the handlers during weakref deletion instead of calling shudown which might miss some places. additionally shutdown is also registered at exit which should clean up the current handlers i hope but doesn't handle the ones that were deleted. attached tests and a news entry. kindly correct me if i am wrong on the approach since this is my first non-easy pr and i would like some help on this fix hoping the fix will not be much complex. ", "commit_messages": " close resources before deleting logging handlers  add news entry ", "linked_issue_titles": "", "title": "close resources before deletion of logging handlers"}
{"description": " adds support for via configurator to the southpaw fullsize by switchplate peripherals. adds support for via configurator to the southpaw fullsize my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " begin work on spfs, migrating ancient config  qmk breaks if there's a dash in the board name  update info.json  make indicator leds work  build a readme  change title to match official gb thread name  add an ansi wkl layout for simplicity  adjustments as per pullreq recommendations  remove unused functions from other keymap  add via configurator support  remove layers to fix via  re-add extra via layers since it seems to work now  replace tabs with spaces  update readme.md ", "linked_issue_titles": "", "title": "add via configurator support to southpaw fullsize"}
{"description": " in #19910, it was pointed out that raising an exception from a future callback would cause the channel spin thread to terminate. if there are outstanding events on the channel, this will cause calls to channel.close() to block indefinitely. this commit ensures that the channel spin thread does not die. instead, exceptions will be logged at error level. this pr fixes #19910. ", "commit_messages": " gracefully handle errors from callbacks.  in  raising an exception from a future callback would cause the channel spin  thread to terminate. if there are outstanding events on the channel,  this will cause calls to channel.close() to block indefinitely.  this commit ensures that the channel spin thread does not die. instead,  exceptions will be logged at error level.  remove todo  remove line of dead code ", "linked_issue_titles": " python channel close can deadlock when keepalive timeout happens ", "title": "gracefully handle errors from future object callbacks."}
{"description": " continue pr #5057 ", "commit_messages": " refactor physicscontact inherits from eventcustom; simplify emitting collision events  fix compile error  remove the workaround cast  conflicts:  cocos/physics/ccphysicscontact.h  issue #3716: refactor physics contact  closed #3716: edit lua support ", "linked_issue_titles": "", "title": "physicscontact should be inherited from eventcustom, it will simplify the logic of emitting collision events"}
{"description": " makes progress on #404 replace utstring_printf with std::snprintf for formatting instead of string concatenation note that std::snprintf requires c++11 ", "commit_messages": " removed unnecessary utarray include  removed ut_string from logging  fix formatting ", "linked_issue_titles": "", "title": "remove ut string from logging"}
{"description": " this pr is quite large as it sets the foundation for the changes needed to enable stricter type checking when sending our telemetry events. there are plenty more locations in the code that i haven't touched as this pr was starting to get out from under me, but this gives plenty of examples of what stricter type checking would look like. this will replace gdpr comments with typings which will force the event sent to match the classification provided. this is part of the work for #75527 ", "commit_messages": " added command line information to display details about collected telemetry  telemetry tooling exploration  changing telemetry calls to be strongly typed ", "linked_issue_titles": "", "title": "initial strict typing support for telemetry events"}
{"description": " since we've now switched to using travis' native caching feature. cc: @xhmikosr ", "commit_messages": " rm travis env vars for giving savage access to defunct custom caching system  reverts a1c170ed373d9076ecf76d264220a6a636239f17  rm travis env vars used for defunct custom caching system  reverts part of 42697a4ecb2c034c9e88e245932b3914dfd1206c ", "linked_issue_titles": "", "title": "remove travis env vars used for defunct custom caching system"}
{"description": " this pr fixes #85058 ", "commit_messages": " distinguish context key factory from type  improvements to context keys  introduce false & true context keys (#85058)  fixes #85058: handle ismac, islinux, iswindows directly ", "linked_issue_titles": " consider keybinding platform context keys on start up ", "title": "special handling for ismac, iswindows, islinux"}
{"description": " @rocketchat/core closes #4371 this adds translatable names and descriptions to the permissions also this pr will sort alphabetically  the en.i18n.js file update: display the technical permission name too ", "commit_messages": " work in progress  translate permissions names  and add descriptions to them  remove prefix from the i18n strings (not sorted)  clean up code ", "linked_issue_titles": "", "title": "real permissions names and descriptions"}
{"description": " chrome_version.h is generated dynamically by bootstrap.py, so it shouldn't be in version control (git). ", "commit_messages": " update from original  remove chrome_version.h from git  chrome_version.h is dynamically generated by bootstrap.py so it  shouldn't be in git  add chrome_version.h to gitignore ", "linked_issue_titles": "", "title": "fix create_chrome_version_h so it will generate chrome_version.h only if needed"}
{"description": " adds the ability to set the lift off distance between the sensor and the surface. currently the default is set to 0x02 (please refer to the datasheet). using #define pmw3360_liftoff_distance xxx will allow the user to set the wanted distance. e.g. #define pmw3360_liftoff_distance 0x27 tested and working add lift off distance change my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " sensor code add  update documentation ", "linked_issue_titles": "", "title": "add configuration of pmw3360 lift off distance"}
{"description": " commit 87a5346 cherry-picked changes into the 17.03 branch to make the client skip auto-removing containers on api 1.25 and up. some changes got lost during that cherry-pick, resulting in 17.03 clients to not fall back to the old behavior when connecting to api version 1.24 or below. this patch addresses this issue for the 17.03 branch by copying the hostconfig.autoremove property to a local variable before it is overridden in containercreate(). this change is not needed on \"master\" (17.04-dev), which does not have this problem. thanks to @jlhawn  for finding this bug. i also added integration tests in a second commit (32dbb5c), so that we can merge those tests to master ", "commit_messages": " [17.03.x] fix autoremove on pre 1.25 api  commit 87a53468b230e6592c547f29f6279a640e368445 cherry-picked  changes into the 17.03 branch to make the client  skip auto-removing containers on api 1.25 and up.  some changes got lost during that cherry-pick,  resulting in 17.03 clients to not fall back to  the old behavior when connecting to api version  1.24 or below.  this patch addresses this issue for the 17.03  branch by copying the hostconfig.autoremove property  to a local variable before it is overridden  in containercreate().  this change is not needed on \"master\" (17.04-dev),  which does not have this problem.  thanks to josh hawn for finding this bug.  add integration tests for client- and daemon-side auto-remove ", "linked_issue_titles": "", "title": "fix autoremove on older api"}
{"description": " as explained in here, the current computation for precision matrix which uses the inverse of covariance matrix might lead to some instability problem. i think that it is better to compute prec matrix based on scale_tril. ", "commit_messages": " stable precision matrix ", "linked_issue_titles": "", "title": "make precision matrix computation in mvn stable"}
{"description": " fixes #1034 reverts the change that introduced an itemrepeater in place of a listview because of a crashing bug when used with the applicationview api. see microsoft/microsoft-ui-xaml#2011. it is worth noting that i tried to use an itemscontrol instead of a listview but ran into stackoverflow errors for some reason. if anyone can figure out the root cause i think using an itemscontrol would be preferred. launch 2 instances of calculator in graphing mode, ensure that the second instance does not crash on launch make sure equation list and variable list still function as expected ", "commit_messages": " replace itemrepeater with listview  allow animations  undo temp key change  remove animation ", "linked_issue_titles": " multi instance graphing calculator causes crash ", "title": "work around crash by replacing itemrepeater with listview"}
{"description": " the unused ignorecache setting has been removed and so you can't run puppet through this module anymore on puppet 6. 475d69d ", "commit_messages": " make puppet module useable on puppet 6 (#46044)  the unused ignorecache setting has been removed and so you  can't run puppet through this module anymore.  see pup-8533 /  (cherry picked from commit 475d69da69d81947c61b47902d198c40e3c72dce)  changelog ", "linked_issue_titles": "", "title": "backport/2.7/46044 make puppet module useable on puppet 6"}
{"description": " mostly so that ctpc works on the arm split branch. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " initial refactor of ergo42 to split common  prevent fallthrough for diode_direction ", "linked_issue_titles": "", "title": "refactor ergo42 to use split_common"}
{"description": " fix issue identified with current scheme for capturing onblock transaction traces. see #9135 (comment) & #9135 (comment) the previous scheme would report an onblock trace for the case where a block is aborted with a valid onblock followed by a non-aborted block with an invalid onblock. added new controller signal block_start for plugins to use to know when a new block starts. added an is_onblock to trace.hpp so this code does not have to be duplicated across various plugins. develop version of #9170 ", "commit_messages": " add is_onblock so logic does not have to be duplicated accross multiple plugins  verify block_num of on_block trace to account for possible aborted block followed by a block with no onblock. also moved is_onblock to trace.hpp  add new block_start signal  use new block_start signal as reliable way to clear out cached transaction state  use new block_start signal as reliable way to clear out cached transaction state  use clear_cache method ", "linked_issue_titles": "", "title": "fix onblock trace tracking - develop"}
{"description": " what do these changes do? the new gcs allows the user to request notifications on specific keys in a table or log. if the key is empty, then no notification is received. this pr adds an empty notification when the client subscribes to an empty key, so that the client can do a read simultaneously with the subscribe. this may impact gcs throughput since extra responses are returned. ", "commit_messages": " publish an empty notification for empty keys  add failure callback to table::subscribe, add unit test for new behavior ", "linked_issue_titles": "", "title": "publish a notification for empty keys in the gcs"}
{"description": " in this docs are broken or wrong links and i added a note #14228 ", "commit_messages": " update(docs): mark gatsby internal docs for update  update(docs): mark gatsby internal docs for update ", "linked_issue_titles": "", "title": "mark more gatsby internal docs for update"}
{"description": " added fast path rendering for textblocks when possible. currently textblocks are created using inlines in react-native, even when the textblock doesn't have any nested children, which negatively affects performance in uwp. more documentation here. modified from #2777 avoided editing from text.js so don't need to fork code from react-native. instead edited rawtextviewmanager and textviewmanager. microsoft reviewers: open in codeflow ", "commit_messages": " added parent nodes to rawtextmanager, added fast text ability for interpolation  undo textinput changes, removed comments  removed map and used reactinstance instead  removed blank space and unneeded include  removed unneeded concrete casting ", "linked_issue_titles": "", "title": "fast path text from native code"}
{"description": " this pr gets rid of the unnecessary 'run automatic scan' button from the content setting dialogs. it also unifies the behaviour across media types (in particular brings music in sync) ", "commit_messages": " changed: make the music set content dialog behave as the video one  it now asks if you want to refresh content if the scraper was changed  changed: get rid of the 'run automatic scan' button from the content setting dialogs ", "linked_issue_titles": "", "title": "get rid of the 'run automatic scan' buttons in the content dialogs"}
{"description": " currently, if someone tries to pass value that does not implement debug or display to a formatting macro, they get a very verbose and confusing error message. this pr changes the error messages for missing debug and display impls to be less overwhelming in this case, as suggested by #85844. i was a little less aggressive in changing the error message than that issue proposed. still, this implementation would be enough to reduce the number of messages to be much more manageable. after this pr, information on the cause of an error involving a debug or display implementation would suppressed if the requirement originated within a standard library macro. my reasoning was that errors originating from within a macro are confusing when they mention details that the programmer can't see, and this is particularly problematic for debug and display, which are most often used via macros. it is possible that either a broader or a narrower criterion would be better. i'm quite open to any feedback. fixes #85844. ", "commit_messages": " improve errors for missing debug and display impls  update test stderr files ", "linked_issue_titles": " reduce verbosity of e0277 for `debug` and `display` ", "title": "better errors for debug and display traits"}
{"description": " fixes #75884. this is best reviewed one commit at a time. r? @guillaumegomez originally i tried to do a much broader refactoring that got rid of init_lints altogether. my reasoning is that now the lints aren't being run anymore (after #73566), there's no need to ignore them explicitly. but it seems there are still some lints that aren't affected by setting lint_mod to a no-op: deny(pub_use_of_private_extern_crate) deny(const_err) warn(unused_imports) (there are possibly more, these are just the ones that failed in the rustdoc test suite). some of these seem like we really should be warning about, but that's a much larger change and i don't propose to make it here. so for the time being, this just adds the unknown_lints and renamed_or_removed_lints passes to the list of lints rustdoc warns about. ", "commit_messages": " minor refactors  rename debugging_options -> debugging_opts to match rustc  this way the rustdoc field names are the same as the rustc field names. ", "linked_issue_titles": " rustdoc does not warn about unknown, renamed, or removed lints ", "title": "warn about unknown or renamed lints in rustdoc"}
{"description": " add owners file update logo add hlftoolsversion and mounttls options. update persistence in line with helm best practices. none ", "commit_messages": " add owners file  add hyperledger fabric logo  add hlftoolsversion to values.yaml  add mounttls to values.yaml  update persistence according to helm best practices  bump version up ", "linked_issue_titles": "", "title": "update owners + bug fixes and best-practices"}
{"description": " i hereby agree to the terms of the cla available at:  data type nested now supports arbitrary levels of nesting. introduced subcolumns of complex types, such as size0 in array, null in nullable, names of tuple elements, which can be read without reading of whole column. detailed description / documentation draft: continuation of #14963. this closes #18826. ", "commit_messages": " allow to read subcolumns of complex types  better storing info about subcolumns  allow to extract subcolumns from column  better subcolumns for arrays  allow to read subhcolumns from other storages  fix rename of columns  fix storagelog  avoid double reading of subcolumns  fix alters of nested  fixes related to nested  implement nested with multiple nesting  implement nested with multiple nesting  implement nested with multiple nesting  implement nested with multiple nesting ", "linked_issue_titles": " cannot access named tuple element by its name using dot ", "title": "allow nested with multiple nesting and subcolumns of complex types"}
{"description": " fixes a number of issues: headings underliners now have the correct length newline+tabs in descriptions are replaced by two newlines to make a proper paragraph properly parse internal hyperlinks in constants description fix broken internal links due to missing newlines show method header even when it has no description, to have something to reference in hyperlinks last part of and thus closes #3064. ", "commit_messages": " sync classes ref with code  enhance xml to rst converter  fixes a number of issues:  - headings underliners now have the correct length  - newline+tabs in descriptions are replaced by two newlines to make a proper paragraph  - [br] are replaced by two newlines, making a proper paragraph  - properly parse internal hyperlinks in constants description  - fix broken internal links due to missing newlines  - show method header even when it has no description, to have something to reference in hyperlinks ", "linked_issue_titles": " write a documentation exporter to restructuredtext format ", "title": "enhance xml to rest converter"}
{"description": " in order to work with the existing hasteimpl and plugin system of react-native, the built npm package should have all the haste modules in the libraries folder.  currently they are split across the libraries folder and lib/libraries, which causes us to require a custom haste impl, which the default rn getplugins infrastructure doesn't pick up. this will also be a requirement in 0.60 when react-native drops haste entirely. in order to do this i moved the existing js flow files in libraries into src/libraries. added a build step that copies the js files from src/libraries into libraries. modified the ts build to output the transformed js files in the libraries folder instead of the lib/libraries folder microsoft reviewers: open in codeflow ", "commit_messages": " move vnext/libraries to vnext/src/libraries  build vnext/src/libraries directly to vnext/libraries ", "linked_issue_titles": "", "title": "consolidate built files into libraries folder"}
{"description": " original pull-request #16504 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " shrink sequence gtid set  when use mysql master -> mysql slave -> clickhouse materializemysql  engine  and mysql slave enable slave_parallel_worker the gtid in .metadata won't  shrink.  like this:    update mysqlgtid.cpp  update mysqlgtid.h  shrink sequence gtid set ", "linked_issue_titles": "", "title": "cherry pick #16504 to 20.8: shrink sequence gtid set"}
{"description": " while working with the tft refactoring, i had to do a lot of tests with the tft init code. but is very annoying to flash and re-flash to do simple tests. i wanted a way to talk to marlin, and it execute my custom code. so i created a support for a custom gcode that is used only for devs. i named it m9999. the code of m9999 is what the dev need, when he needs it. this way, i could create my own test code, and do a lot of testing sending commands to marlin, without need to flash every time. when enable marlin_dev_mode and dev_custom_gcode, the developer can write custom code in the file: marlin/src/gcode/dev_custom_gcode.h. after the initial skeleton, i added this file in the .gitignore, so it won't be committed by mistake. easier to test marlin when developing! enable: dev_custom_gcode marlin_dev_mode ", "commit_messages": " new custom gcode to help developers test their code while working in marlin  to avoid devs commit their custom tests ", "linked_issue_titles": "", "title": "support for debug codes - dnnn"}
{"description": " fixes #16675. following the suggestions in this ticket this pr improves the error message when users try to use dynamic imports while having es2015 as module in the compiler options. ", "commit_messages": " make error message for dynamic imports when module is es2015 more helpful  accept baselines for new import call expression error in es2015 ", "linked_issue_titles": "", "title": "better error message for dynamic import with es2015 modules"}
{"description": " it is fine to resolve the types of exported classes in es6: export class c { } var c = new c() but not for commonjs exported classes: module.exports.c = class { } var c = new c() // should error jsdoc type aliases are an exception since they are always exported implicitly, not by [property] assignment to module.exports or exports. fixes #24492 ", "commit_messages": " fix resolution of exported types in commonjs  it is fine to resolve the types of exported classes in es6:  js  export class c {  }  var c = new c()    but not for commonjs exported classes:  js  module.exports.c = class {  }  var c = new c() // should error    fixes #24492  all jsdoc type aliases are available locally in commonjs modules ", "linked_issue_titles": " in js, crash on incorrect type reference of a module.exports property assignment ", "title": "fix exported type resolution in commonjs"}
{"description": " this adds a callback when an object store node runs out of memory to choose objects to spill, after first attempting to make space through eviction of objects not currently referenced. since spilling is asynchronous, the object store client must try to create the object again. once the object spilling is complete, the object creation will succeed. a todo is to modify the object store to respond to the client asynchronously. this is so that, in the case that we can definitely make enough space by spilling other objects, the object store client does not have to retry the create call on a timer and we do not block the object store while the objects are being spilled. this pr also introduces some changes to the way configs are passed around the cluster to accommodate passing around the object spilling config, which is a json string. long-term, we should have a less brittle way to pass around arbitrary config values. closes #9849. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " automatic spill  object spilling enabled flag  fix config issues ", "linked_issue_titles": " [object spilling] automatically spill objects on outofmemory ", "title": "add policy to automatically spill objects on outofmemory"}
{"description": " i was fiddling around on the menus in this pr: #12024 i was finding it strangely tedious to have to click the global nav menus to open them. hover-opening seemed lie it'd be more natural. not sure others will agree, but if they do, we can merge this pr after that one. curious what others think, e.g. @junlin test plan requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " hover opens menus  hover opens menus  linting, removing some styles i added  moving usestate up (non-conditional)  just a tweak to prevent a conflict. ", "linked_issue_titles": "", "title": "global nav menus open on hover"}
{"description": " hope this is fine. i replaced the star import in tests.serializers as \"explicit is better than...\" (and code validators like pyflakes don't work very well with them). i also added a test that makes sure that all fields from the fields meta-attribute are passed as expected. ", "commit_messages": " bye bye star import  added test that makes sure that fields with  dictionaries as data are returned as expected and  not turned into string representations  added test for modelserializer meta fields  returning as expected ", "linked_issue_titles": "", "title": "tests for pull #358 \"return dictionaries as is\""}
{"description": " when a page is auto prerendered we delay updating the aspath until after mount to prevent breaking hydration. to prevent the url from flashing this moves the populating of aspath into the router fixes: #8749 ", "commit_messages": " prevent updating url when delaying aspath ", "linked_issue_titles": " prerendered pages incorrectly edit router state during hydration ", "title": "prevent url from being updated while aspath is delayed"}
{"description": " tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry oversight from my other pr syncing 3.9 builds ", "commit_messages": " update actions-39.yaml  update azure-windows-39.yaml  update actions-39-slow.yaml ", "linked_issue_titles": "", "title": "add numba back to 3.9 env"}
{"description": " follow up for this comment on pr #12745. previously i was tracking base time for all fibers, regardless of whether they were inside of a profiler, because the place where i started the timer didn't yet know if it was in a profilemode. i could move where i start/stop the timer somewhere else- where it would know- but this approach seemed simpler. it has a small potential downside of not measuring \"base\" time for the profiler component itself- but i think this is okay because (1) that time should be minimal and (2) it isn't really actionable for a developer. questions should i remove the conditionals around stopbaserendertimerifrunning? (is it worth having them?) caveats we pause/resume the global render timer even outside of a profilemode tree. this only updates a single numeric value though; it doesn't modify any attributes on a fiber. ", "commit_messages": " conditionally start/stop base timer only within profile mode tree  added test to ensure profilertimer not called outside of profiler root ", "linked_issue_titles": "", "title": "only measure \"base\" times within profilemode"}
{"description": " document how to set up so11y for cluster add label filter to aggregate metrics from dedicated labels. update self.yaml add ui template for so11y. ", "commit_messages": " fix some issues for so11y  update ui ", "linked_issue_titles": "", "title": "update prometheus fetcher for so11y"}
{"description": " mcu that supports emergency_parser. add emergency_parser to lpc tests & update emergency_parser comment in configuration_adv.h to call out the other non-supported platforms. catch potential build-breaking changes from being merged like #17953. #17955 and prs #17953 & #17961 ", "commit_messages": " add emergency_parser to lpc tests  update emergency_parser comment  emergency_parser has not been implemented for esp32, stm32f1/4/7, or teensy 3.5/3.6 mcus. ", "linked_issue_titles": "", "title": "add emergency parser to lpc tests"}
{"description": " fixes #10507 to silence the futurewarning in categoricalencoder, i replace str with np.str_ in calls to np.issubdtype as @rth proposed. n/a ", "commit_messages": " replace str with np.str_ in calls to np.issubdtype  add test  fix futurewarning in tests ", "linked_issue_titles": " futurewarning in categoricalencoder due to np.issubdtype ", "title": "fix futurewarning in categoricalencoder due to np.issubdtype (#10507)"}
{"description": " based on the discussion in the pitch, tweak concurrentvalue checking for functions: collapse all of the logic about concurrently-executing local functions into a simple \"local capture\" check don't require the parameter and result types of a @concurrent function (type) to conform to concurrentvalue. ", "commit_messages": " [concurrency] simplify checking for local functions.  treat them as local captures and require them to be @concurrent.  [concurrency] don't diagnose non-concurrentvalue parameters/result type of @concurrent functions.  thanks to jordan rose and john mccall, who pointed out why this checking was unnecessary.  as a drive-by, ensure that we diagnose parameter references properly. ", "linked_issue_titles": "", "title": "improve concurrentvalue checking for functions"}
{"description": " hey, this is continuation of work done by @drogus. basically it moves actionview outside of actionpack to its own directory. av still remains dependency on ap, i will be working on this in coming weeks. however, after discussing it with @drogus, both of us agreed that it would be good to have those commits in master. (they are basically just moving files, not much changes is code itself) because: @kaspth is working on his gsoc loofah project - it touches actionview so it will be super hard to solve conflicts either for him or me once one of our branches get merged. it'll be hard for me if somebody will make some changes in master to rebase it. / ", "commit_messages": " add bare actionview gem to the root directory  this commit creates structure for action view gem and is first of a  series of commits extracting action view from action pack.  move actionpack/lib/action_view* into actionview/lib  actionview version should be 4.1.0  move template tests from actionpack to actionview  remove unneeded files  add actionpack as actionview's development dependency  actionview still relies on actionpack in some of the tests.  remove unneeded test fixtures in av  copy company test fixture to av (fixes failing test)  remove digestor fixtures from ap  they were moved to actionview/ and are not used in actionpack  fix digestor tests  remove require to ap stuff that left  template test were moved to av ", "linked_issue_titles": "", "title": "extract actionview to separate directory"}
{"description": " ticks three checkboxes in #8982. ", "commit_messages": " libjs: replace string const& with stringview in various temporal aos  this is especially helpful where we already pass stringview literals  and only compare them with others, e.g. overflow and largest/smallest  unit, in which case there's no need to actually allocate a string.  libjs: implement temporal.plaintime.prototype.tostring()  libjs: implement temporal.plaintime.prototype.tolocalestring()  libjs: implement temporal.plaintime.prototype.tojson() ", "linked_issue_titles": "", "title": "implement temporal.plaintime.prototype.to{string,localestring,json}()"}
{"description": " see #3445 ", "commit_messages": " modify borg check unit test so it \"hangs\", see #3444  it doesn't infinitely hang, but slows down considerably.  (cherry picked from commit a68d28bfa4db30561150c83eb6a0dca5efa4d9e8)  check --repair: fix malfunctioning validator, fixes #3444  the major problem was the ('path' in item) expression.  the dict has bytes-typed keys there, so it never succeeded as it  looked for a str key. this is a 1.1 regression, 1.0 was fine.  the dict -> stabledict change is just for being more specific,  the check triggered correctly as stabledict subclasses dict,  it was just a bit too general.  (cherry picked from commit e09892caec8a63d59e909518c4e9c230dbd69774) ", "linked_issue_titles": "", "title": "fix for borg check --repair malfunction, #3444 (master)"}
{"description": " fixes #2130 by taking inspiration from #2466 changes inputtypes, audio, video, input, postmessage and daturi tests to use the addtest function isntead of adding the values directly to the modernizr object. that way they also provide a css class. ", "commit_messages": " refactor audio- and video- to be more like csscolumns-tests. that way they also provide a css class.  refactor inputtype tests to be more like csscolumns-tests. that way they also provide a css class.  refactor postmessage tests to be more like csscolumns-tests. that way it also provides a css class.  refactor datauri tests to be more like csscolumns-tests. that way it also provides a css class. ", "linked_issue_titles": " modernizr.inputtypes no class set. ", "title": "use addtest for some tests like inputtypes"}
{"description": " this refactors the gcsactormanager to remove some of its dependencies. this also adds a unit test for checking that the actor is dead after node death vs worker death. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " parametrize test  regression test and logging  test no restart after actor deletion  unit tests  refactor to subscribe to and lookup from worker failure table  refactor actormanager to remove dependencies  revert \"regression test and logging\"  this reverts commit 835e1a9091b51ca8efb00392d4cc4a665145de24.  revert \"parametrize test\"  this reverts commit f31272082831ba1a494816dd5511d87b24eca4c9.  revert \"test no restart after actor deletion\"  this reverts commit 114a83de14329aa6ab787c80cd5757cf074a9072.  doc  merge  revert \"refactor to subscribe to and lookup from worker failure table\"  this reverts commit 6aa13a05178d0b9aa1db9dee5c978c911b74fa3a. ", "linked_issue_titles": "", "title": "actor manager refactor and unit tests"}
{"description": " doesn't effect typing speed by using the \"absolute positioning flexbox repaint hack\" ", "commit_messages": " use flexbox to arrange panes  rename .row and .column to .pane-row and .pane-column  bootstrap's .row and .column css was influencing our pane rows and  columns.  use absolute divs to limit repaints on keypresses ", "linked_issue_titles": "", "title": "this replaces custom pane resizing with flexbox"}
{"description": " according the source code there are missed required parameter 'el: raphaelelement' in methods insertafter() and insertbefore() methods of raphael.d.ts ", "commit_messages": " update raphael.d.ts  add required parameter 'el: raphaelelement' to insertafter() and insertbefore() methods  update raphael.d.ts  add required parameter 'el: raphaelelement' to raphaelset.insertbefore() and raphaelset.insertafter() ", "linked_issue_titles": "", "title": "rapaelelement' to insertafter() and insertbefore() methods"}
{"description": " upgrade abseil submodule and bazel dependency to 20210324.2 abseil/abseil-cpp@278e0a0 i've reverted the podspec change since that needs some additional work that @veblush is working on. the podspec will be upgraded once that is done. ", "commit_messages": " update submodule abseil-cpp to abseil lts 20210324, patch 2  update bazel dependencies and generate projects ", "linked_issue_titles": "", "title": "upgrade abseil to lts 20210324, patch 2"}
{"description": " with this pr i'm looking to add some features to serenityos chess that are present in most popular chess platforms, which would make the program more capable. this includes: + copy board state as fen string + replay moves and navigate move history with arrow keys + import games using pgn files to replay and analyze them + highlight squares and draw arrows on the board for illustration please notify me about any issues you may (and probably will) find, i'm glad to get to them as soon as possible and try to resolve them.   : ) ", "commit_messages": " chess: change keyboard shortcuts  use some better keyboard shortcuts that make more sense and are more  common, instead of random function keys.  chess: added ability to copy board state as fen  you can now copy the board state as forsyth-edwards notation. you can  then paste this into other chess programs/games, or into ours when  it gets implemented.  chess: add ability to replay moves  this patch allows the user to go back and forward in move history  to replay moves from the game. this is view-only however, and as soon  as a move is made the board returns to it's current state. this will  work well for replaying games loaded in with pgn files, once that's  implemented.  chess: added abilty to import pgn files  this patch allows the user to load games using pgn files. the parsing  is not complete and has a bunch of work left to be done, but it's  okay for our use case here. it can load all of the games our pgn  exporter can save. as the chess program impoves so can the pgn parser.  chess: added ability to put markings on the board  with this patch you can use right-click to mark a square on the board.  you can add modifier keys to the click to change to alternate color  (with ctrl) or secondary color (with shift). if you right-click and  drag from one square to another you will create an arrow. the  markings go away as soon as you left-click on the board or the board  state changes.  note: the arrows sometimes look weird, and horizontal ones get cut  off. they also don't account for alpha. this is not a bug in  chess code, rather, likely in the fill_path() function that's  used to draw the arrows. if anyone might know what's up with  that i urge you to take a look. :) ", "linked_issue_titles": "", "title": "add fen copy, replay functionality, pgn import, board markings"}
{"description": " you use react native more, the more native parts you will touch. need more advanced articles about this part. ", "commit_messages": " add two articles about writing native component in ios  add two articles about writing native component in ios ", "linked_issue_titles": "", "title": "more article about native component"}
{"description": " fixes #11269. fixes #12865. see also #9499 allow a callable to be passed to refit in *searchcv to balance score and model complexity. this interface adds flexibility in identifying the \"best\" estimator. the function passed to parameter refit incorporate of which metric to optimise. hence users can use multi-metric evaluation with this interface. 2 test cases added: test_refit_callable() add an example of choosing the mode with the least mean_test_score test_refit_callable_multi_metric() test the same example in a multi-metric evaluation setting added documentation describing this feature to users(see additions in _search.py under model_selection directory) added a example(plot_grid_search_refit_callable.py) of demonstrating the usage of this interface under examples/model_selection/ this implementation passes all test suites by running make checklist: rewrite test case for refit=callable using simple dummy refit function. rewrite test case for refit=callable using similar example in multi-metric eval settings add functions in _search.py to pass the above tests documentation polishing ", "commit_messages": " allow for refit=callable in *searchcv to balance score and model complexity #11269.  update comments in test case #11269  add test cases and add multi-metric scoring support ", "linked_issue_titles": " allow for refit=callable in *searchcv to balance score and model complexity  allow gridsearchcv() to account for model variance to select .best_estimator_ ", "title": "allow for refit=callable in *searchcv to add flexibility in identifying the best estimator #11269"}
{"description": " basically, my change was very simple - switch from sum operations to subtraction to avoid type casting in checks and type overflow during flieloginputstream work, especially in cases where property log.segment.bytes was set close to the integer.max_value and used as a position inside nextbatch() function. all related unit tests are working as intended. no new tests (probably) required. ", "commit_messages": " slightly improved batch position checks, extended type to avoid overflow errors  second approach to the batch position checks overflow problem, avoiding unnecessary type conversion. ", "linked_issue_titles": "", "title": "improved fileloginputstream batch position checks in order to avoid type overflow related errors"}
{"description": " this attempts to fix the annoying new add-ons being disabled thing in pvr. it removes the clients table from pvr, and uses the standard add-ons table for ids now instead, and only disables new add-ons when they don't have a user set configuration. add-ons won't be disabled when they have the following in addon.xml in the pvr extension point (this only applies to pvr add-ons): needs_configuration=false it also stops the add-ons from being disabled when the database is reset. ping @jalle19 you had another pr for this some time ago, can you test this please ", "commit_messages": " added: caddondatabase::getaddonid()  [pvr] changed: removed the special clients table for pvr, and use the add-on ids from the addonmanager  [pvr] changed: no longer disable all new add-ons when creating a new pvr db  [pvr] fixed: don't disable all new add-ons by default, only the ones that need configuration  by default, all add-ons are marked as needing a configuration. overrule in addon.xml, by adding needs_configuration=false to the pvr extension point ", "linked_issue_titles": "", "title": "fix add-ons new being disabled"}
{"description": " we currently have windowsbrush code in the microsoft fork of react-native. this change ports that code into react-native-windows as forked files, to help get us off the microsoft fork. also added a test page to rntester as there is currently no test code that uses windowsbrush. addresses #3788 microsoft reviewers: open in codeflow ", "commit_messages": " merge  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  move windowsbrush stuff over from fork  added rntester page  change files ", "linked_issue_titles": "", "title": "port windowsbrush code into react-native-windows"}
{"description": " this cleans up that code and makes us only include what we need. this doesn't help builds with metadce, that removed unneeded stuff anyhow, but does help other levels, and the python code is also cleaner this way i think. it also helps a lot in modes that can't use metadce like main module (see test updates). this also uncovered a minor bug with tempret0 which we need for dynamic linking, and wasn't being imported. before we just happened to work since we imported all the library functions anyhow. ", "commit_messages": " only emit necessary things in asmlibraryarg in the wasm backend  wip [ci skip]  fix  cleaner  python3 fix  cleanup  nicer  nicer  remove unused var  fix ", "linked_issue_titles": "", "title": "stop importing all libraryfunctions into the wasm module in the wasm backend"}
{"description": " addresses one of the files in issue #8278 make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow \"how to write a good git commit message\" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. ", "commit_messages": " added small test for bigquery sensor  removed file from missing_test_files ", "linked_issue_titles": "", "title": "added test for bigquery sensor"}
{"description": " r? @manishearth  note that the commit e898015 doesn't exist like this in the clippy repo. i didn't want to do a full sync, because this would've included at least one new lint, which i wanted to avoid a week before beta is branched. this just reverts one commit from the last sync. ", "commit_messages": " revert \"pass clippy args also trough rustflags\"  special sync of 'e89801553ddbaccdeb2eac4db08900edb51ac7ff' ", "linked_issue_titles": "", "title": "revert change from last sync"}
{"description": " fixes below warnings using raw strings and !=. fixes isalive attribute error. ./glances/config.py:108: deprecationwarning: invalid escape sequence \\ self.re_pattern = re.compile('(\\.+?\\)') ./glances/outputs/glances_curses.py:700: syntaxwarning: \"is not\" with a literal. did you mean \"!=\"? if p is not 'load': ./glances/amps/glances_systemd.py:20: deprecationwarning: invalid escape sequence \\/ \"\"\" ./glances/amps/glances_systemv.py:20: deprecationwarning: invalid escape sequence \\/ \"\"\" ./glances/amps/glances_nginx.py:20: deprecationwarning: invalid escape sequence \\/ \"\"\" ./glances/amps/glances_default.py:20: deprecationwarning: invalid escape sequence \\/ \"\"\" new feature: no fixed tickets: #1585 ", "commit_messages": " fix deprecationwarning regarding invalid escape sequence. fix syntaxwarning regarding literal comparison.  use is_alive instead of isalive for python 3.9 compatibility. ", "linked_issue_titles": "", "title": "fix warnings and improve python 3.9 compatibility."}
{"description": " this is xref #27700 (comment) closes #13420 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " remove \\n from docstring  fix conflicts  merge remote-tracking branch 'upstream/master'  add test for issue 13420 ", "linked_issue_titles": " dataframe.groupby(grp, axis=1) with categorical grp breaks ", "title": "add tests for groupby categorical values with axis=1"}
{"description": " the module defaults for gcp aren't up-to date with the current gcp modules, breaking the module defaults functionality for a lot of gcp_* modules. in pr #60172 the gcp facts modules were changed to info modules. but the module defaults weren't updated, and still refer to the to the removed gcp_*_facts modules instead of gcp_*_info. not all existing gcp modules are present in the module defaults this pr changes all the gcp_*_facts references into gcp_*_info, and adds the missing gcp_* modules to the module defaults for gcp module defaults for gcp following playbooks throws an error about missing arguments, despite the fact that they are present in the module_defaults - name: setup gcp components hosts: localhost connection: local gather_facts: no module_defaults: gcp_compute_instance_info: zone: europe-west1-b group/gcp: project: project-name-123456 auth_kind: serviceaccount service_account_file: \"../credentials.json\" scopes: -  tasks: - name: load instance info gcp_compute_instance_info: filters: - name=test-instance-1 register: test_instance - name: setup gcp components hosts: localhost connection: local gather_facts: no module_defaults: group/gcp: project: project-name-123456 auth_kind: serviceaccount service_account_file: \"../credentials.json\" scopes: -  tasks: - name: create an instance gcp_filestore_instance: name: test_object zone: us-central1-b tier: premium file_shares: - capacity_gb: 2660 name: share1 networks: - network: default modes: - mode_ipv4 state: present play [setup gcp components] ****************************************************************************************************************************************************************************************************************** task [load instance info] ******************************************************************************************************************************************************************************************************************** fatal: [localhost]: failed! => {\"ansible_facts\": {\"discovered_interpreter_python\": \"/usr/bin/python\"}, \"changed\": false, \"msg\": \"missing required arguments: zone, auth_kind\"} play recap *********************************************************************************************************************************************************************************************************************************** localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0 play [setup gcp components] ****************************************************************************************************************************************************************************************************************** task [create an instance] ********************************************************************************************************************************************************************************************************************* fatal: [localhost]: failed! => {\"ansible_facts\": {\"discovered_interpreter_python\": \"/usr/bin/python\"}, \"changed\": false, \"msg\": \"missing required arguments: auth_kind\"} play recap *********************************************************************************************************************************************************************************************************************************** localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0 ", "commit_messages": " renamed gcp_*_facts to gcp_*_info  added missing gcp modules to gcp module defaults group ", "linked_issue_titles": "", "title": "add missing gcp modules to module defaults"}
{"description": " added support for new wireless receiver with oled display to comet46 keyboard. the oled related code was based on those of the crkbd and helix. the keymaps \"default\" and \"satt\" have been modified to support oled. the previous \"default\" keymap was renamed to \"default-rgbled\" files were modified to follow the code style of this project checklist: my code follows the code style of this project. i have read the contributing document. ( ", "commit_messages": " add oled support for comet46  fix length of char \"name\" of keylogger.c  update ssd1306  fix rules.mk  update led-receiver keymap  update oled related code  add mod_state_reader & modify led_state_reader  update oled related files  update kemaps  update readme  change default-oled-display to default  add osm compatibility to mod_state_reader  code formatting  use progmem to store code_to_name  clean up satt keymap  rename default-led keymap to defult-rgbled ", "linked_issue_titles": "", "title": "comet46 add support for oled"}
{"description": " i've changed the way the and input component decides whether there is an error or not. input doesn't have any state related to errors any more. instead the error is hold completely inside props. some examples: // this will show an error <input name=\"input\" error=\"this is an error\" /> // these will not show an error <input name=\"input\" /> <input name=\"input\" error={undefined} /> <input name=\"input\" error={null} /> this is more declarative than having to call seterror and removeerror and allows components to use the input more concisely. additionally i also made type=\"text\" default for the input (although this is something debatable). ", "commit_messages": " make type optional and fall back to 'text'  fix tabs -> spaces  make error prop more declarative  also respect error={null} on input ", "linked_issue_titles": "", "title": "make input component more useful (respects error prop declaratively)"}
{"description": " a port of #12412 to 1.3.x branch. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " infer dtype in symbolblock import from input symbol  fix lint issues and make existing tests pass  add tests for importing a fp64 model into symbol block  fixing failing test for test symbol block  set context in unit tests  add tests for fp16, add default dtype in infer_param_types  use tmp directory as root for loading from model zoo to avoid race condition  fixing naming and parameter selection in test case  fixing failing gpu tests  make unit test more deterministic to get param name  override cast in symbol block, handle grouped symbol  handle multiple symbolic input usecase  add tests to verify behavior of symbolblock.cast ", "linked_issue_titles": "", "title": "infer dtype in symbolblock import from input symbol (v1.3.x)"}
{"description": " fixes #52671 reverts return_timestamps from nxos, ios, iosxr #50261, #52670, #50323, #50095 timestamps can be implemented in task using ", "commit_messages": " revert \"nxos_command:run_commands results failure when commands array size >1 (#52670)\"  this reverts commit 0df5b92af37d43da20125dc418f1cb92390a8a25.  revert \"added timestamps to nxos_command module (#50261)\"  this reverts commit e1509433144572e5010d0ced72a2129600dd8bd4. ", "linked_issue_titles": " nxos_command:run_commands is broken when return_timestamps set to false ", "title": "revert nxos, ios, iosxr return_timestamps"}
{"description": " #2749 returned the negative levels to pre-#1562 behavior. i.e., skipping stepsize positions every iteration. this pr emulates #1562-like stepping by applying the stepsize skip every other position. this pr addresses #2827. benchmarks silesia.tar on gcc-10: silesia.tar on clang-13: status i believe this pr is ready for merge. ", "commit_messages": " stagger application of stepsize in zstd_fast  this replicates the behavior of @terrelln's zstd_fast implementation. that  is, it always looks at adjacent pairs of positions, and only applies the  acceleration every other position. this produces a more fine-grained  acceleration.  decompose step into two variables  this avoids an additional addition, at the cost of an additional variable. ", "linked_issue_titles": " compression ratio for --fast=2 and higher became significantly worse. expected? ", "title": "stagger stepping in negative levels"}
{"description": " guards against min/max being macros. sometimes, particularly when microsoft's windows.h is included, min/max are defined as macros, interfering with use of std::numeric_limits::min() and the like.  to guard against this, the function name is wrapped in an extra set of parenthesis, which inhibits function-style macro expansion. two separate commits here: one for document.h and one for test code. ", "commit_messages": " guard against min/max being macros in document.h  sometimes, particularly when microsoft's windows.h is included, min/max  are defined as macros, interfering with use of  std::numeric_limits::min() and the like.  to guard against this, the function name is wrapped in an extra set of  parenthesis, which inhibits function-style macro expansion.  guard against min/max macros in tests too ", "linked_issue_titles": "", "title": "guard against min/max being macros in a cross-compiler way"}
{"description": " issue: #9261 before this pr, every c++ completionqueue object creation ended up calling grpc_init  which acquires a mutex g_init_mu to increment the number of grpc-init invocations. this is ok if the number of completion queues being created was small. however, in case of c++ synchronous server, a completion queue is create for every call. this ends up making g_init_mu one of top created mutexes in sync servers. this pr makes calling grpc_init optional when creating c++ completionqueue objects. it is always set to true by default but if a c++ completionqueue  is being created by passing a grpc_completion_queue * pointer i.e the following constructor (which is what sync c++ server calls when creating a per-call completion queue), it is okay to not call grpc_init. class completionqueue : private grpclibrarycodegen { .. explicit completionqueue(grpc_completion_queue* take); .. } this change is safe because if we got a grpc_completion_queue * structure, we must have already called grpc_init(). benchmark results i added a new benchmark bm_createdestroycpp2 (didn't previously include it as a part of the pr because i thought it is trivial - but on a second thought, i think it is a good idea :)) locks are down from 3 to 1 on master (with bm_createdestroycpp2 temporarily ported): sreek@sreek-dev:~/workspace/grpc (master) $ bins/counters/bm_cq --benchmark_filter=bm_createdestroycpp2 run on (12 x 3501 mhz cpu s) 2017-03-29 10:54:34 benchmark                     time           cpu iterations ----------------------------------------------------------- bm_createdestroycpp2        215 ns        215 ns    3230778 locks/iter:3 atm_cas/iter:0 atm_add/iter:3 allocs/iter:1 on this pr branch: sreek@sreek-dev:~/workspace/grpc (init-free-cq) $ bins/counters/bm_cq --benchmark_filter=bm_createdestroycpp2 run on (12 x 3501 mhz cpu s) 2017-03-29 10:56:15 benchmark                     time           cpu iterations ----------------------------------------------------------- bm_createdestroycpp2        160 ns        160 ns    4413813 locks/iter:1 atm_cas/iter:0 atm_add/iter:3 allocs/iter:1 ", "commit_messages": " do not call grpc_init() for per-call-completion-queues created by a c++  synchronous server  do not call grpc_init() for per-call-completion-queues created by a c++  synchronous server ", "linked_issue_titles": "", "title": "do not call grpc_init() for per-call-completion-queues created by a c++ sync server"}
{"description": " this pr is to fix: the link of tf.contrib.learn.estimator. as we can see in the note section of kernel method tutorial, the two below highlighted link was broken and i can see from the latest source code the second one was fixed while the first one wasn't pointed to the correct place; note: this document uses a deprecated version of ${tf.estimator}, which has a ${tf.contrib.learn.estimator$different interface}. it also uses other contrib methods whose ${$version_compat#not_covered$api may not be stable}. the accurate link of input function section. it should be @{$get_started/premade_estimators#create_input_functions$this section on input functions} instead of #input_fn. ", "commit_messages": " fix several broken links in kernel method tutorials  forgot to save when rebase master  fix different interface link in kernel method ", "linked_issue_titles": "", "title": "fix two external anchor link in kernel method tutorial"}
{"description": " unregister when exiting react only to actual device insertion/removal, ie do not reenumerate the usb bus to find a cec adapter when a cd is inserted... i don't see any risk here, but doing a pr since we're close to release. ", "commit_messages": " [win] properly filter wm_devicechange message to reenumerate usb bus only on usb hid device insertion and removal  [win] cosmetics for previous commit (d2377c86) ", "linked_issue_titles": "", "title": "fix a couple device notifications issues"}
{"description": " add support for group layers when parsing json output from tiled as requested in issue #4099.  along the way, i believe i discovered some problems with the way phaser parses infinite tiled maps and fixed those as well.  infinite map layers might still have 'offsetx' and 'offsety' properties but these were previously being ignored.  they are now accounted for properly. i have tested all these changes against the phaser3-examples both visually and with the 'tester' script and everything that worked before the changes works the same as after my changes.  i added several tests to the examples repo in my local working copy that tested groups and an infinite map to ensure those parts work as well.  those examples are not a part of this pr as they were on top of the examples repo and not this one. here is a quick summary of changes: added logic to each of the layer type parsers (tiled, object, and image) to account for group layers. added a file with a single function that creates the important state that needs to be inherited from a group. uses an iterative approach to traversing the group hierarchy with a stack rather than recursion. all hierarchy is flattened to a single array of layers and the group layers are discarded after they are accounted for. layer names are prepended with any containing group names separated by slashes ('/') updated documentation for the tilemap gameobject to mention support for layers and the renaming that can occur. updated error reporting when an invalid tile layer name is requested in order to pre-empt any confusion surround the renaming of layers.  now lists the valid layer names. ", "commit_messages": " support for tiled groups and infinite map fixes  - added support for tiled group layers (issue #4099)  - fixed some layer offset bugs for infinite maps  updates for supporting group layers  - updated documentation to mention support for groups and naming layers  - added more verbose output when an unknown layer name is specified  > error output now lists the valid layer names  - added functions to return array of tile, object, or image layer names ", "linked_issue_titles": "", "title": "support for tiled layer groups"}
{"description": " i've added the option to specify the button field of the webmouseevent that was being sent, because without that my example (selecting text with sent events) didn't work - i also set the text and unmodifiedtext fields on char and rawkeydown events, because without that the actual \"typed\" key didn't appear in my inputs. i also set the type of the keycode to char16 and removed the failing condition on an undefined vkey, because without this i wouldn't have been able to type characters other than the ones on the english keyboard. ", "commit_messages": " adding option to specify the button of webmouseevent.  added text and unmodifiedtext setting when sending char type keyboard events, and made the type of the character read char16, so i can simulate char events from non-english origins.  added documentation about the changes ", "linked_issue_titles": "", "title": "option to specify button on a mouseevent and text on a keyboardevent when using sendinputevent"}
{"description": " added save and reset buttons. added warning message for unsaved settings. #1564 - settings ui epic ", "commit_messages": " add settings ui string localization (#7833)  <!-- enter a brief description/summary of your pr here. what does it fix/what does it change/how was it tested (even manually, if necessary)? -->  moved all strings into resources file for localization.  <!-- other than the issue solved, is this relevant to any other issues/existing prs? -->  <!-- please review the items on the pr checklist before submitting-->  * [ ] closes #xxx  * [x] cla signed. if not, go over [here](  * [ ] tests added/passed  * [ ] documentation updated. if checked, please file a pull request on [our docs repo](  * [ ] schema updated.  * [x] i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx  <!-- provide a more detailed description of the pr, other things fixed or any additional comments/features here -->  <!-- describe how you validated the behavior. add automated tests wherever possible, but list manual validation steps taken as well -->  add save button ", "linked_issue_titles": "", "title": "add save button to settings ui"}
{"description": " this ports the following utilities to libmain: allocate aplay asctl bt this also adds a syscall wrapper for gethostname which is used by the bt utility. ", "commit_messages": " allocate: port to libmain :^)  aplay: port to libmain  asctl: port to libmain :^) ", "linked_issue_titles": "", "title": "port to libmain + add sycall wrapper for gethostname"}
{"description": " closes #23878 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " bug/tst - do not multiply period diff result by freq scaling factor  tst - reference issue number in test ", "linked_issue_titles": " bug: non-standard frequency period arithmetic ", "title": "bug - remove scaling multiplier from period diff result"}
{"description": " this fixes #1054.  this is a strange interaction between the following: convenience method like request.get() called the result of url.parse(x) passed as the uri option the request results in a cross-protocol redirect. ", "commit_messages": " add test for regression introduced in c052e9c  when the result of url.parse() is passed to one of the convenience  methods like request.get(), then cross-protocol redirects will fail  later on.  see #1054.  fix #1054 ", "linked_issue_titles": " failing https redirect since version 2.41.1 ", "title": "fix redirects when passing url.parse(x) as url to convenience method"}
{"description": " the following pr is a clumsy way to implement #11940 basically i've replicated the readme logic as well trying to generalise it whenever possible. i'd love to get your thoughts as well some hints about how to test this, eventually. i put some notes in the code - i hope you might clarify those points. // ", "commit_messages": " added changelogurl to local extension rapresentation  propagate the changelog url from the zip file if any  add getchangelog method to iextension and its impl  display the changelog nav bar  generalise and resuse markdown rendering function  get changelog url in installed extension as well  provide correct localized strings ", "linked_issue_titles": "", "title": "provide a changelog tab when this file is bundled in the package"}
{"description": " still running into issues running ti on ubuntu 18.04 even though successful compilation. ", "commit_messages": " update readme and fix execute_process  updated readme with 18.04 instructions  added commands from hyperlink  added instructions for cuda 10.1 install  updated ubuntu 18.04 instructions ", "linked_issue_titles": "", "title": "updating ubuntu 18.04 quick start instructions"}
{"description": " description: adds the 'lx' unit for the light sensor (e.g xiaomi aquara illumination sensors). related issue (if applicable): fixes #14129 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " add support for light sensors with lx unit  add test for light sensor with 'lx' unit ", "linked_issue_titles": " homekit doesn't support light sensors with unit 'lx' ", "title": "add support for light sensors with 'lx' unit to homekit"}
{"description": " @adichat ", "commit_messages": " add anagram_search js file  add instructions  rewrite instructions for js implementation  add two helper function skeletons and main function  add functionality to remove white spaces and build a character count hash table  add functional code  add tests ", "linked_issue_titles": "", "title": "add javascript solution for anagram search"}
{"description": " refer to #542 . with this, we can get rid of mingw in windows. and it is easier to build r-package in osx as well. also, it is easier to build gpu version for r-package in windows. @laurae2 any comment?  can you also help to test the new build? ", "commit_messages": " add r's library file to vs project and cmake.  support using dll built by vs.  better search for the library file. ", "linked_issue_titles": "", "title": "compile r package by custom tool chain."}
{"description": " please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues fix apache/skywalking-ui#119 ", "commit_messages": " update doc for ui deploy ", "linked_issue_titles": " move the deploy document to skywalking repo ", "title": "update doc for ui deploying"}
{"description": " follow-up to #4463. at minimum, we want to run python and c++ tests. in particular, we want to ensure that the generated python wheel is broadly compatible, e.g. on following platform combinations: windows server 2008 r2 without gpu windows server 2012 r2 with gpu + cuda 9.0 windows server 2016 with gpu + cuda 10.0 windows server 2019 with gpu + cuda 10.1 ", "commit_messages": " add cmake option to use bundled gtest from dmlc-core  consistently apply openmp flag to all targets  build xgboost with gtest ", "linked_issue_titles": "", "title": "add python and c++ tests for windows gpu target"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). #17239 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. jquery can export jquerystatic if global.document is available. module.exports = global.document ? factory( global, true ) : function( w ) { if ( !w.document ) { throw new error( \"jquery requires a window with a document\" ); return factory( w ); }; this also corrects the factory signature and makes the import form import * as $ from 'jquery'; possible. ", "commit_messages": " [jquery] false | false = false  [jquery] factory() is not a global.  [jquery] fix export. ", "linked_issue_titles": "", "title": "module should export factory or jquerystatic"}
{"description": " add retext-spell in order to spell-check our docs and fix a couple of spelling errors. also add an update-dictionary script to make adding new words to the dictionary easier. motivation being able to auto-check words means that we can keep the gatsby style easier. method i created dictionary.txt by running retext-spell once and then extracting/sorting the \"mispelled\" words. i looked over the file by hand to find any obvious misspellings, brand name capitalizations, and locale-specific spellings and applied them. there's more stuff that we can improve/regularize, such as putting filenames and code in backticks, but i can leave it to follow-up prs and community maintainers. todo make sure that emoji are spell-checked correctly. script to update dictionary if new words are used. caveats if \"new words\" are used, they have to be added to the dictionary. i'll write a script to enable that but it may get cumbersome having to constantly update the dictionary with new words (or it might catch some misspellings more, who knows!) follow-up prs backticks on function names like usestaticquery backticks on package names (e.g. gatsby-source-filesystem) standardize more brands and term names: gatsby/gatsbyjs graphql \"cms\" (we have like five different ways we pluralize cms) ", "commit_messages": " try to get spelling to work  more stuff  try again  this was a mustako  this was a mistake  make a dictionary  revert old docs  updated dictionary  fix some spelling errors  fix some spelling errors  update dictionary  fix some more typos  more stuff  more stuff  more stuff  more stuff  go through entire list ", "linked_issue_titles": "", "title": "add retext-spell to check spelling"}
{"description": " add a new keymap for kbd67/hotswap, designed for people who both code and have to write math in non-latex environments on os x. checklist: my code follows the code style of this project. i have read the contributing document. ( tested on a physical kbd67. ", "commit_messages": " custom keymap.  fix magic layer, enable unicode.  update readme.  make unicode config change keymap-local. ", "linked_issue_titles": "", "title": "new kbd67/hotswap keymap for writing both code and math"}
{"description": " this fixes the problem described in  the last commit makes sure that the order of the list in the musicvideo library node when accessed through the music library is the same as the default order in the video library. right now it's alphabetical which imo doesn't make much sense. this only happens when accessed through the music library because when accessed through the video library we use the custom library node defined in library://video/musicvideos/ instead of videodb://musicvideos/ which is used by the music library. i'm happy to drop the last commit if it isn't accepted for gotham. ", "commit_messages": " cvideodburl: fix option name \"artistid\" instead of \"actorid\" for musicvideos  videodb: don't duplicate join statements in musicvideo album sql queries  videodatabasedirectory: make sure to translate all ids in the path of a grouped node into url parameters (fixes #14333)  fix predefined sorting of musicvideo nodes (when accessed through the music library) ", "linked_issue_titles": "", "title": "only show albums of the selected musicvideo artist"}
{"description": " fixes #3927 component name external bash collector module apcupsd. add chart for online flag with 0/1. only send that metric when the reported ups stats are invalid. ", "commit_messages": " add chart for online status for bug #3927  add chart for online status for bug #3927 ", "linked_issue_titles": " apcupsd: connection loss further collects data, but it should stop ", "title": "apcupsd add check for ups online"}
{"description": " i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. related #2786 ", "commit_messages": " fix typehints in project_euler/problem01  squashed commit of the following:  commit 6801d073b31bf702814861cd3b07b634ca295bfa  author: archaengel <god11341258@gmail.com>  date:   mon oct 5 16:40:10 2020 -0700  fix typehints in project_euler/problem01  commit 29afc3af114abd1b99dc3f7c8fc99128229db131  author: archaengel <god11341258@gmail.com>  date:   mon oct 5 15:06:34 2020 -0700  add typehints and default argument for project_euler/problem_01  add default args, typehints, and expand variable names for pe prob 02  add style improvements for first solution of pe problem 02  add default arg and typehints for second solution of pe problem 02  add default arg for third solution of pe problem 02  add style improvements for 1st soln of pe problem 03  add default arg and typehints for 2nd soln of pe problem 03  add default arg for 3rd soln of pe problem 03  remove unnecessary newlines  remove unnecessary newlines  fix end of file for 2nd soln in pe problem 03  add style improvements to solutions for pe problem 04 ", "linked_issue_titles": "", "title": "add style improvements to solutions for project euler problem 04"}
{"description": " mysqlnd_field_type_name is not used anywhere. my research turned up nothing. it looks like a leftover from some previous functionality. either i am too dumb to understand or get_parameter_metadata is just dead code. i can't see any references to this method anywhere. stat triggers is a functionality that doesn't seem to be used anywhere. it doesn't look like it harms performance, but if nobody uses it then it might be prudent to just drop this functionality and have cleaner code. ", "commit_messages": " remove mysqlnd_field_type_name  remove get_parameter_metadata  drop mysqlnd statistics triggers  this functionality is not used productively in php and it's not used in  any of the extensions to my knowledge. since it looks like this functionality  isn't required by anyone, let's clean up mysqlnd and drop it. ", "linked_issue_titles": "", "title": "mysqlnd refactoring (remove mysqlnd_field_type_name, get_parameter_metadata, and mysqlnd stat triggers)"}
{"description": " in this commit i have: added javadoc to every file except for the java files in the \"heap\" package i took the files with spaces and renamed them so they don't have spaces let me know what you think and my work so far. ", "commit_messages": " in this commit i have:  added javadoc to every package except for \"heaps\"  i have also deleted these files in my commit ", "linked_issue_titles": "", "title": "javadoc and no spaces in file names"}
{"description": " i have followed (at least) the pr section of the contributing guide. closes #29338 problem: with inputprops={{ classname: browser-default }} on a textfield component, input element has two of the same classname: browser-default. before: code sandbox:  after: code sandbox: ", "commit_messages": " [inputbase] handle classname item in inputprops separately  [inputbase] add test ", "linked_issue_titles": " [textfield] classname passed in `inputprops` is added twice to `input` element ", "title": "do not repeat the same classname"}
{"description": " this pr is related to #1956. vs 2019 has been released recently and the latest cmake 3.14.1 supports it. therefore we can reorder generators (and platform toolsets) to try to build lightgbm with vs 2019 firstly. due to that cmake dropped the possibility to specify architecture inside generator name (win64), we can set it via -a option, which was presented in cmake since 3.1 and we require >=3.8 for windows (it's shorter and better than setting cmake_generator_platform directly and allows to handle all generators in the same way). i'm doubt about only one thing: whether we need to specify -t host= option or not. its default behavior differs in vs 2019 compared to all other versions: 2019: by default this generator uses the 64-bit variant on x64 hosts and the 32-bit variant otherwise. 2017: by default this generator uses the 32-bit variant even on a 64-bit host. this option controls the following: -- check for working cxx compiler: c:/program files (x86)/microsoft visual studio/2017/enterprise/vc/tools/msvc/14.16.27023/bin/hostx86/x64/cl.exe -- works |------| ^ | v |------| -- check for working cxx compiler: c:/program files (x86)/microsoft visual studio/2017/enterprise/vc/tools/msvc/14.16.27023/bin/hostx64/x64/cl.exe -- works refer to  remaining things: add a link to msvc redistributable 2019 here; it's still unavailable from ms support site done!; add a bullet for matching boost binaries with vs 2019 here; latest 1.70.0b1 doesn't contain 14.2 version. upd: ... but 1.70 does: ", "commit_messages": " set platform via a option  style hotfix  updated r installation script  updated python installation script  updated ci test script ", "linked_issue_titles": "", "title": "better compatibility with visual studio 2019"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " upgrade to viewer v7.2  release notes:  upgrade to viewer v7.4  release notes:  added getdefaultgeometry method  added getdefaultgeometry method  added missing methods to navigation class:  - getworldpoint  - screentoviewport  added missing method to viewer3dimpl class:  - viewporttoray  added missing methods to navigation and viewer3dimpl classes  getdocumentnode returns any rather than object  added interface to specify api endpoint  move properties to top of the class  update type definitions for viewer. ", "linked_issue_titles": "", "title": "add missing members and properties"}
{"description": " this pr changes (delete as applicable) nothing, it's a bug fix i don't understand why this works, but for some reason in tween.js, the play method needs this.parent.**manager.**makeactive(this); when state is pending_remove or remove.  however, when this.parentistimeline in the play method, this.parent.makeactive(this); is sufficient. ", "commit_messages": " #3190 tweens/timeline parent.makeactive missing ", "linked_issue_titles": "", "title": "fix #3190 tweens/timeline parent.makeactive missing"}
{"description": " i fixed some of the style errors flake8 was showing from the changes we made yesterday.  i also excluded the setup.py file, which i suppose isn't necessary since we are only testing flake8 on 3.6 and the reason for exclusion was a 2.7 issue.  i've also added build stages so the style test only runs after all of the pytest suites run.  seemed complicated but it works. ", "commit_messages": " added flake8 back in and added jobs for style and unit tests  lets see if these build stages work  this is annoying  fixed some style issues  added some steps to the build process  trying a different config to see if that works  build-matrixes?  this is complicated  matrix setup  ugh  well it works for 2.7 help me ken!  only running pyflakes on 3.6, test next build step on 2.7 and 3.6  try again  fingers crossed  fingers crossed x2  fix parsing error  make it pretty  final before merge ", "linked_issue_titles": "", "title": "re-enable flake8 testing, add build stages to travis testing"}
{"description": " prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  returns a reference to the eventemitter, so that calls can be chained. ", "commit_messages": " update in return type of \"on() event\" method.  now the return type from the \"on\" methods that are part of \"events\" are \"this\". now attach events to some object is chainable.  added ready event on chainable method. ", "linked_issue_titles": "", "title": "johnny five - add return type to \"on() event method\" according to its parent class."}
{"description": " three small datatype-related fixes that most importantly make 24-bit flacs sound correct. no more playback noise! libaudio: rescale integer samples correctly in flac loader the flac samples are signed, so we need to rescale them not by their bit depth, but by half of the bit depth. for example, a 24-bit sample extends from -2^23 to 2^23-1, and therefore needs to be rescaled by 2^23 to conform to the [-1, 1] double sample range. this makes all flac files sound double as loud, which is expected behavior. libaudio: fix overflow on 24-bit flac lpc data when computing sample values from a linear predictor, the repeated multiplication and addition can lead to very large values that may overflow a 32-bit integer. this was never discovered with 16-bit flac test files used to create and validate the first version of the flac loader. however, 24-bit audio, especially with large lpc shifts, will regularly exceed and overflow i32. therefore, we now use 64 bits temporarily. if the resulting value is too large for 32 bits, something else has gone wrong :^) this fixes playback noise on 24-bit flacs. ", "commit_messages": " libaudio: use size_t in loops  this is more idiomatic :^)  libaudio: rescale integer samples correctly in flac loader  the flac samples are signed, so we need to rescale them not by their bit  depth, but by half of the bit depth. for example, a 24-bit sample  extends from -2^23 to 2^23-1, and therefore needs to be rescaled by 2^23  to conform to the [-1, 1] double sample range.  libaudio: fix overflow on 24-bit flac lpc data  when computing sample values from a linear predictor, the repeated  multiplication and addition can lead to very large values that may  overflow a 32-bit integer. this was never discovered with 16-bit flac  test files used to create and validate the first version of the flac  loader. however, 24-bit audio, especially with large lpc shifts, will  regularly exceed and overflow i32. therefore, we now use 64 bits  temporarily. if the resulting value is too large for 32 bits, something  else has gone wrong :^)  this fixes playback noise on 24-bit flacs. ", "linked_issue_titles": "", "title": "fix 24-bit flac audio and related issues"}
{"description": " checklist closing issues: #issue i wrote some lines in the radare2book i found that the original mips.gnu assembler is using some really old binutils codes, so i migrate some new mips support components from the current master branch of binutils-gdb, fit them into radare2's old headers and make some adjustments to let them act like before. i run \"make tests\" before pr and found nothing is broken for now. ", "commit_messages": " refresh old files with current binutils codes(copyrights notes are not updated for now)  add remain components from binutils-gdb  update original copyright messages  modify mips disassembler to match output style  try to fix wrong jalx argument decoding ", "linked_issue_titles": "", "title": "improve mips support(mips.gnu) by migrating new codes from binutils"}
{"description": " cherry pick #37340 to 5.5 re-apply #37531 ", "commit_messages": " revert \"future-proof the layout of asynctask.\"  this reverts commit 7eb105236a10107fa63db325bc3fc0ccfc3f547c.  [tasklocals] enable sync functions to bind task-locals; keep storage in tls  [tasklocals] propagate task-locals through async{} ", "linked_issue_titles": "", "title": "pick task locals in sync functions, reapply asynctask layout"}
{"description": " add support mks mini12864 v3 for robin e3p board and fix pin add mks mini12864 v3 pin define for mks robin e3p board add support read card file by lcd (sd on lcd) mks_robin_e3/e3d, mks_robin_nano_v2, mks_robin_e3p, mks_robin_nano_v3 board, if use mks mini12864 v3 add #define lcd_screen_rot_180 function (default: disable) ", "commit_messages": " bugfix 2.0.x  bugfix 2.0.x  bugfix 2.0.x  bugfix 2.0.x  bugfix 2.0.x  add support mini12864 v3 for e3p board ", "linked_issue_titles": "", "title": "mks mini12864 v3 for robin e3p, etc."}
{"description": " this fixes the problem that the application crashes when dragging a file to a non-valid index in the table. at the same time the file will be opened in this case. i add a signal/slot to communicate with extendtablewidget and mainwindow and validate index after drop anything. ", "commit_messages": " add signal if file dropped  check if index is valid  send signal and return if index is invalid and file was dropped  connect dropsignal to fileopen ", "linked_issue_titles": "", "title": "source trigger patch file drop"}
{"description": " description: this patch adds support for controlling roller shades through the cover component on the lutron platform. pull request in home-assistant.github.io with documentation (if applicable):  as with the lutron light component, no configuration is necessary (or available) as shades are detected automatically. checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. ", "commit_messages": " adding support for lutron radio ra2 shades as cover components.  adding initial version of the lutron shades component. ", "linked_issue_titles": "", "title": "adding support for lutron covers"}
{"description": " fixes accidental breaking change introduced in 1.5.0. we can probably fix this in an even more robust/intelligent way but this should fix it for 99.9999% of people as-is. ", "commit_messages": " add failing test  only wrap with variants if rules don't already contain any variants  remove stale test ", "linked_issue_titles": "", "title": "support manual @variants in addcomponents for <1.5 backwards compat"}
{"description": " hi this is part of #51430. i'm a first time contributor, so i started with a small task adding a bit of documentation for from impls. ", "commit_messages": " added comment for from trait implementation: boxed string slice to string  added comments for trait implementations. ", "linked_issue_titles": "", "title": "add documentation for from impls"}
{"description": " this is #3170, but with prop iteration inlined into patchdomelement() so that the loop can be reused to capture special prop values. ", "commit_messages": " (restructure) prevent terser 5 from inlining functions  we are heavily reliant on reduce_funcs, which was removed in terser 5, but [will be added back in 5.2.2 or 5.3](  in the meantime, we have to disable reduce_vars to prevent function inlining, although this has a large size cost since it also prevents variable inlining.  create .ignore-me  delete .ignore-me  create ignore-me.js  update to microbundle 0.13.2 to get terser 5.7  update package exports to drop es5-esm build  remove temp file  remove node-13-exports workaround  remove references to preact.module.js  remove all .module.js files  fix coverage reporting and babel transpilation  [test] manually inline diffprops  remove unused import  update microbundle to allow turning off function inlining  small size tweak for createcontext  inline prop iteration into patchdomelement and reuse the loop to capture special prop values. ", "linked_issue_titles": "", "title": "restructure prevent terser inlining (alt)"}
{"description": " what do you think about creating a file just for frameworks alone? now only for js it exists.. we could differentiate the resources for programming languages & frameworks? ", "commit_messages": " removed explore flask link - not free  sorted things..  sorting..:bowtie: ", "linked_issue_titles": "", "title": "removed false link and sorted things.."}
{"description": " alternate to #27955 (can't push to their remote) but with a more robust distance measurement. closes #27955 distance of 90 was correct for a clock width of 260 as found in previous versions ( repro: @eps1lon please find the issue reproduced here:  when you click/drag the selector over one of the outer numbers (0-12) you will realize that unless you add a significant buffer to the inner circle, it will select/snap to the inner numbers (13-24) instead. ", "commit_messages": " fix hours distance value  distance of 90 was correct for a clock width of 260 as found in previous versions. now that clock_width = 220, the distance needs to be reduced by the same ratio to ~76.15 or 76 in order to get the correct time value.  robust distance detection ", "linked_issue_titles": "", "title": "fix to narrow hover area for am hours in am/pm clock"}
{"description": " the fix itself is worthless. the main goal here is to check in an interesting test case. rdar://problem/31302713 ", "commit_messages": " sema: narrow fix for a circular protocol conformance checking case  we go to look at the conforming protocols of an associated type  but we haven't built the generic environment for the associated  type's protocol yet.  in the test case given, we find the conformance later via a  different path, so everything continues to work.  substitutionmap::lookupconformance() is hopefully getting a  makeover soon, and this hack will go away.  fixes <rdar://problem/31302713>.  ast: repent for my sins by adding new assertions  since the previous fix is essentially a hack to dodge an  assertion, i'm adding stronger assertions to  abstracttypeparamdecl::getsuperclass() and  getconformingprotocols(). ", "linked_issue_titles": "", "title": "workaround for issue with multi-file fake recursive conformance"}
{"description": " minimal fix to ensure that all returns have line numbers. skipping news as i think pep 626 is covered well enough already. i expect this to be a temporary fix for 3.11, as we will implement a proper fix for line number propagation. ", "commit_messages": " guarantee that line number is set for returns.  add test for linenumber of return in nested try statements.  remove misleading comment ", "linked_issue_titles": "", "title": "force return_value bytecodes to have line numbers"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " fix invalid table maxheight prop type  add tests and remove erroroneous patch version ", "linked_issue_titles": "", "title": "fix incorrect type in table component maxheight prop"}
{"description": " while cleaning up the visual studio project i noticed that there are a few view related files scattered in the xbmc root directory (i.e. xbmc/) which could be moved into their own directory (and for linux into their own library) to clean things up a bit and make them easier to find. if accepted this will need some xcode work. ", "commit_messages": " move view related files into new view folder and lib  [win32] update vs project files ", "linked_issue_titles": "", "title": "move all view related files into xbmc/view"}
{"description": " i really hope i don't have to do this again and this fixes the seo issue once and for all... ", "commit_messages": " 4.0, 4.1 and 4.2 docs: add canonical tag.  fix duplicate example by redirecting it.  fix redirect. ", "linked_issue_titles": "", "title": "add canonical tag for 3.3, 3.4, 4.0, 4.1 and 4.2 and fix a few redirects"}
{"description": " adding space to -l flag causes swiftc  to produce abstract error. this pr aims at improving usability to -l flag by allowing it to take a space. resolves sr-14122. ", "commit_messages": " -l flag accepts space and emits without space to llvm frontend  add tests to check if adding space doesn't break invocation ", "linked_issue_titles": "", "title": "improve usability of -l flag"}
{"description": " added a new python script for testing amqp cases select one: select any that apply: ", "commit_messages": " amqp tests python  updates to make back node work  removed test not relevant for this change  fixed comments, took out commented and unnecessary code  took out unneeded key copying  took out extraneous wallet operations  took out extraneous setting of amqp address  added amqp-tests to cmake file  upped timeout  fixed cmake conflict  added create ampq queue  added -rabbit to test name  set number of producers to 3 to avoid timeouts ", "linked_issue_titles": "", "title": "added a new python script for amqp specific tests - develop"}
{"description": " meta: exclude libwasm parser.cpp from sonar cloud static analysis we need to exclude this file from analysis for now, as there is a bug in the sonar-runner tool where it crashes when trying to understand the use of ak::variant in libwasm/parser/parser.cpp see #10122 for details + link to the bug report to sonar cloud. meta: remove unused caching from sonar cloud configuration i was experimenting with using caching while doing the initial prototype of the sonar cloud workflow. however the cache size for the static analysis data ended up being large enough that it would put us over the git hub actions limit. given that we currently only run this pipeline once a day, it seems reasonable to just remove caching. if in the future we decide to run the pipeline on every pr, caching would become crucial as the current un-cached analysis time is around 1 hour and 50 minutes. if we did this we would need to move the pipeline to azure devops where we have effectively infinite cache available. ", "commit_messages": " meta: remove unused caching from sonar cloud configuration  i was experimenting with using caching while doing the initial prototype  of the sonar cloud workflow. however the cache size for the static  analysis data ended up being large enough that it would put us over the  git hub actions limit. given that we currently only run this pipeline  once a day, it seems reasonable to just remove caching.  if in the future we decide to run the pipeline on every pr, caching  would become crucial as the current un-cached analysis time is around  1 hour and 50 minutes. if we did this we would need to move the pipeline  to azure devops where we have effectively infinite cache available.  meta: exclude libwasm parser.cpp from sonar cloud static analysis  we need to exclude this file from analysis for now, as there is a bug in  the sonar-runner tool where it crashes when trying to understand the use  of ak::variant in libwasm/parser/parser.cpp  see #10122 for details + link to the bug report to sonar cloud. ", "linked_issue_titles": "", "title": "work around crash in sonar cloud static analysis"}
{"description": " documentation for the email and jira watcher actions provide example keystore commands to store sensitive data, like passwords. this corrects those keystore commands to include the required add keyword. also includes a supporting update to encourage use of keystore for secure credentials. resolves #40132 ", "commit_messages": " correct keystore commands for email and jira actions for watcher  update depcrecation note to recommend keystore for secure creds ", "linked_issue_titles": " docs for keystore commands for email and jira actions incorrect ", "title": "correct keystore commands for email and jira actions in watcher"}
{"description": " as discussed in #2461 , dropped the 'lib' prefix from shared library name in mingw as well. python package works with mingw again. added apveyor ci for mingw and python i don't think it is necessary to run two appveyor jobs for jvm; and, perhaps, can live without a debug job for msvc2013 some 'g++ 4.8 or higher' defines seemed to (unintentionally?) miss versions above 4 ", "commit_messages": " for mingw, drop the 'lib' prefix from shared library name  fix defines for 'g++ 4.8 or higher' to include g++ >= 5  fix compile warnings  [appveyor] add mingw with python; remove redundant jobs ", "linked_issue_titles": "", "title": "shared library prefix and appveyor ci"}
{"description": " this pr refactors the previous pipeline into a format that is inline with openexr uncompressing pipeline, and adds support to rle compression format. setting up for a future pr that adds support for dwaa and dwab compression. by filling the output array with white color, #17887 exposed an incorrect offset in the decoding algorithm. the first pixel line was being shifted up, this was also fixed. refactors into openexr uncompress pipeline. adds rle compression support. fixes line indexing. adds support for float32 pixeltype - except for piz_compression dev example pr example you can see the example no longer shows that white line on the bottom of the image, since the indexing is now correctly handled. ", "commit_messages": " exrloader: refactor  exrloader: clean up ", "linked_issue_titles": "", "title": "rle support and uncompress refactor."}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " add sentence class to brill tagger  update natural package version  run prettier, remove patch version ", "linked_issue_titles": "", "title": "add sentence class for tagger to natural package"}
{"description": " this makes it possible to specify the default android overscroll indicator using themedata. internal feedback has requested we add this to ease migration to the new default behavior. i am hesitant to pile on to themedata again, we have ben trying to prune it lately, but i do not think adding a scrollbehaviortheme is appropriate for this case/migration period.  related issues/changes #87839 #82906 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " add theme support for choosing overscroll indicator  docs ", "linked_issue_titles": "", "title": "add theme support for choosing android overscroll indicator"}
{"description": " credit goes to @alex-700 who found this while trying to fix a suggestion in clippy. while if, try, for and await expressions get the span of the original expression when desugared, while loops got the span of the scrutinee, which lead to weird code, when building the suggestion, that randomly worked:  i'm wondering, if desugaringkind should get a variant whileloop and instead of using the span of the ast::exprkind::while expr directly, a new span with self.mark_span_with_reason should be used, like it is done with for loops. there was some fallout, but i think that is acceptable. if not, i need some help to find out where this can be fixed. ", "commit_messages": " use correct span on while (let) lowering  update_tests ", "linked_issue_titles": "", "title": "fix span of while (let) expressions after lowering"}
{"description": " this fills out the rest of the blend modes for premultiplied alpha using the design of @westlangley. this does this by renaming the existing premultipliedalpha blend mode: three.premultipliedalphablending = 6; and instead calling it: three.premultipliedalphanormalblending = 6; and then adding these following modes: three.premultipliedalphaadditiveblending = 7; three.premultipliedalphasubtractiveblending = 8; three.premultipliedalphamultiplyblending = 9; this also adds the ability to use custom blending modes with premultiplied alpha - which i am sure would be useful in the future: three.premultipliedalphacustomblending = 10; i've updated the relevant examples as well. ", "commit_messages": " add the rest of the blending modes to premultipliedalpha mode.  # conflicts:  #\texamples/webgl_materials_transparency.html  #\tsrc/renderers/webgl/webglstate.js  some more upgrades of dev to match the premultiplied multiple blend modes. ", "linked_issue_titles": "", "title": "additive, subtractive, multiply, custom premultipliedalpha blend modes"}
{"description": " this pr makes the following changes: remove logicalkeyboardkey.keylabel make physical/logicalkeyboardkey.debugname getters make physical/logicalkeyboardkey() factory constructors, which cache non-predefined instances. reasons: it has been planned to remove keylabel because it brings confusion to usage, and complexity to expanding code related with logical keys. the keylabel is a duplicate information to flutterid. it is possible to construct an instance with the same flutterid and different keylabel, but what does it even mean? an alternative way is to keep keylabel as a getter, but for now it doesn't seem necessary. the keylabel is not used anywhere in keyboard-related algorithms, nor does it seem like a necessary part for client-side processing. since flutterid is the deciding property for a logical key, keylabel only serves for explanation. it's like another debugname but available at run time. with debugname being turned into a getter, the logical/physicalkeyboardkey classes no longer needs to override hashcode and operator ==. this allows the key instances to be used in a const context and removes a linter exception (prefer_const_literals_to_create_immutables), such as const <logicalkeyboardkey>[ logicalkeyboardkey.keya, logicalkeyboardkey.keyx, ]  // this would trigger compiler error before <logicalkeyboardkey>[ const logicalkeyboardkey.keya, const logicalkeyboardkey.keyx, ]  // this would trigger linter error i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " impl  fix fuchsia key ", "linked_issue_titles": "", "title": "remove keylabel and debugname from logical/physicalkeyboardkey"}
{"description": " find in this picture the process that used most of the cpu: yes, i know it is torrents, but the legend does not help. when there are many dimensions, the legend requires quite some focus to find the most important one. the solution well, before this pr the dashboard decides for the number of fraction digits, based on each number alone. it used no fraction digits for values above 1000, 1 fraction digit for values above 100, 2 fraction digits for values above 10, etc up to 4 fraction digits. this pr tries something different. it decides the number of fraction digits for all dimensions of a chart, based on the visible y-range of the chart! the algorithm for deciding the number of fraction digits is the same, but all the dimensions get the same, so the numbers are easily distinguishable. let's see: a lot better. what is nice, is that when you click on a dimension to select it, the y-range of the chart changes, so the detail on the numbers changes too immediately: so, netdata has a small range and 2 fraction digits: but x, has a bigger range and 1 fraction digits: if the range is too small, you still get up to 4 digits (this chart ranges from 0.9995 to 1.0048): side effects there are always side effects: before this pr, this chart did not have any fraction digits. it is annoying i know, but i made a little change to make it easier to accept it: before this pr values from 1 to 100 would get 2 fraction digits. after this pr, values 1 to 10 get 2, but 10 to 100 get 1. this makes it a little bit less annoying. this pr also fixes an issue where charts were randomly loosing some legend information (date and units). also, chart y-axis labels are now using the same formatting as the legends: ", "commit_messages": " fixed an issue where units and date were randomly not rendered on charts  removed debugging strings  legends now have uniform but dynamic number of fraction digits ", "linked_issue_titles": "", "title": "uniform but dynamic number of fraction digits at the legends"}
{"description": " about awd format :  in short, it's a lightweight format, faster to load, faster to parse than all ascii/utf based 3d formats. a first draft version of parser is available on this fork  (has been developed to run with modified version of three.js) the first step is to cleanup the actual version, in order to make it work on the actual dev branch, with minimal features : parse geometries as buffergeometry parse meshes instance as mesh parse containers as object3d find a way to handle meshes with multi-materials (away3d feature) next steps : handle primitives support for morph and skeletal animations lights and cameras materials and embed textures? ... ", "commit_messages": " quickely add awdloader  fix awdloader  cleanup awdloader + added sample page with simple awd scene  start support for texture loading  basic material support + external texture loading ", "linked_issue_titles": "", "title": "support for awd format (away3d)"}
{"description": " new features apis add nansum api x = np.array([[float('nan'), 0.3, 0.5, 0.9], x = paddle.to_tensor(x) out1 = paddle.nansum(x)  # [2.7] out2 = paddle.nansum(x, axis=0)  # [0.1, 0.5, 0.5, 1.6] out3 = paddle.nansum(x, axis=-1)  # [1.7, 1.0] out4 = paddle.nansum(x, axis=1, keepdim=true)  # [[1.7], [1.0]] ", "commit_messages": " add nansum api ", "linked_issue_titles": "", "title": "add nansum api to math"}
{"description": " this pr adds my layout for the chimera ortho and planck keyboards. i've had these changes pending for a good while, hence why there's two layouts in one pr. both of these are the same layout, hence the same branch and singular pr. if there's an issue with this, let me know and i'll split things up into two pr's. don't think there's much else worth mentioning here. ", "commit_messages": " clone default chimera-o layout  make changes for base layer  enable mouse suppport flag  implement majority of dad layout  add mouse movement keys  fine tune mouse control and fix tap toggle  fix mouse button locations  set adpater led colors for layers  increase responsiveness of key taps  update layout for thumb comfort  rename layout and add readme  add comments to keymap ", "linked_issue_titles": "", "title": "add dcompact layout for chimera ortho and planck keyboards"}
{"description": " the nearbygpscoordinate function uses coordinate[0] and coordinate[1] as a string array, not a single string. the function worked when i used \"[\"0\", \"0\"] as unknown as string\" as the input, which means it actually should have a string array. hope this can be approved to fix this issue. as mentioned in the commit message, i also changed the test to reflect the usage. ", "commit_messages": " changed type of coordinate to string[] from string. the function itself uses coordinate[0] and coordinate[1] as latitude and longitude, so the old type led to a typeerror when you tried to input the coordinate array.  the test has been changed to reflect the change in input.  changed the type of faker.address.nearbygpscoordinate's parameter coordinate from string[] to readonlyarray<string>. ", "linked_issue_titles": "", "title": "changed faker.address.nearbygpscoordinate() coordinate parameter type from string to readonlyarray<string>"}
{"description": " add set -ex to build scripts as well as bazel flags for incompatible versions. also change dockerfile for debian-based docker container ", "commit_messages": " change debian jessie backports url  add set -ex to some scripts for debugging  add two bazel flags ", "linked_issue_titles": "", "title": "changes to build files for patch release"}
{"description": " build successful:  i hope in the future we will be able to drop requirements_rtd.txt completely, but now pip still fails to resolve conflicts with preinstalled old (1.8.5) sphinx and latest breathe. ", "commit_messages": " update requirements_base.txt  update requirements_rtd.txt ", "linked_issue_titles": "", "title": "simplify rtd config and use latest sphinx"}
{"description": " closes #9109 thanks, @dimazuien! cy.request() now accepts a generic in typescript for specifying the type of the request body make the type of response body of cy.request generic. why was this change necessary? => generic helps users write type-safer code. what is affected by this change? => n/a any implementation details to explain? => n/a ", "commit_messages": " fix  better name. ", "linked_issue_titles": " generic for cy.request response body ", "title": "can specify the responsebody type of cy.request"}
{"description": " fix two issues that would case crashes for programs using swift concurrency in back-deployed scenarios: cannot back-deploy mangled names including isolated parameters. exclusivity checking was broken in some cases (rdar://83064974). don't refer to the isa mask any more; we don't back-deploy far enough for it to matter. make sure we set rpaths properly when linking. implement  swiftnativensobject in the back-deployed libswift_concurrency and swizzle it in to back-deployed @objc actor types. ", "commit_messages": " always use the same tls context as the runtime for back-deployed concurrency  the exclusivity checking support for concurrency relies on having access  to the thread-local set of active memory accesses. teach the  back-deployed concurrency library to use the same tls context as the  runtime, which fortunately hasn't change. this fixes the  concurrency exclusivity-checking test in back-deployed configurations  that's tracked by rdar://83064974.  (cherry picked from commit 27472854174f77a03265875a171069c213c4d78f)  cannot back-deploy mangled names including isolated parameters.  isolated parameters were introduced with concurrency, so don't mangle  names including them in back-deployed code.  (cherry picked from commit 24c761b74a1a8828e1109f76b8c4da0b3272a849) ", "linked_issue_titles": "", "title": "concurrency back-deployment fixes for exclusivity, isolated parameters, @objc actors"}
{"description": " i made the mistake of writing the method result::unwrap as fn unwrap_err(&self) -> t { unwrap(self) }. this patch fixes that bug, and also does some cleanup of time.rs. ", "commit_messages": " fix option::unwrap_err.  switch chain calls to use option::chain method ", "linked_issue_titles": "", "title": "fix a bug in result::unwrap_err (and minor cleanup)"}
{"description": " use the family argument (and others) when creating the kube-load-balancer-source-cidr in proxy-mode=ipvs. this is needed when the family is not the default \"family inet\", that is for a ipv6-only clusters. fixes #68338 release note: ", "commit_messages": " fix issue #68338  the ipset kube-load-balancer-source-cidr is not recogized as  a hash set  fix issue #68338 ", "linked_issue_titles": " the ipset kube-load-balancer-source-cidr is not recogized as a hash set ", "title": "include all used hash types in compare when creating ipsets"}
{"description": " this change aggregates events sending, and reports them at most once per second. also i've added events for viewing a query/widget/visualization, when looking at a dashboard. ", "commit_messages": " report events at most once per second  report event for viewing widget/visualization/query ", "linked_issue_titles": "", "title": "make sure events are reported at most once per second"}
{"description": " more ribust handling of labes insafari for state diagrams. resolves #1269 workaround for issue with getbbox in safari have read the contribution guidelines targeted develop branch ", "commit_messages": " #1269 work around for inaccurate bounding box results in safari.  #1269 work around for inaccurate bounding box results in safari. fix for multiple lines ", "linked_issue_titles": " state transition label renders incorrect on safari ", "title": "bug/1269 fix label background on safari"}
{"description": " this is related to bpo-37417: os.sched_setaffinity doesn't properly handle errors that arise during iteration of the mask argument: python 3.9.0a0 (heads/master:d52a83a, jun 26 2019, 15:13:41) type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> import os >>> bad_iter = map(int, \"0x\") >>> os.sched_setaffinity(0, bad_iter) valueerror: invalid literal for int() with base 10: 'x' the above exception was the direct cause of the following exception: traceback (most recent call last): file \"<stdin>\", line 1, in <module> systemerror: <built-in function sched_setaffinity> returned a result with an error set it looks like this bug is also present on all versions of python 3. i've attached a patch with a fix and a regression test. ", "commit_messages": " add a test for error handling in os.sched_setaffinity.  fix error handling in os.sched_setaffinity. ", "linked_issue_titles": "", "title": "os.sched_setaffinity does not handle errors during iteration."}
{"description": " ec2_vpc_nat_gateway ansible version ansible 2.3.0 (devel e35a757ee7) last updated 2017/01/12 16:42:33 (gmt +1000) config file = configured module search path = default w/o overrides check if eip exists before deleting it after deleting the nat gateway, the eip sometimes seems to cease to exist afterwards. check if it exists before deleting it. otherwise you get: failed to release eip eipalloc-abdc1234: an error occurred (invalidallocationid.notfound) \\ when calling the releaseaddress operation: the allocation id 'eipalloc-abcd1234' does not \\ exist\", \"success\": false} also fix some flake8 issues in a separate commit ", "commit_messages": " check if eip exists before deleting it  after deleting the nat gateway, the eip sometimes seems to  cease to exist afterwards. check if it exists before deleting it.  otherwise you get:    failed to release eip eipalloc-abdc1234: an error occurred (invalidallocationid.notfound) \\  when calling the releaseaddress operation: the allocation id 'eipalloc-abcd1234' does not \\  exist\", \"success\": false}    fix flake8 errors with ec2_vpc_nat_gateway ", "linked_issue_titles": "", "title": "fix eip release in ec2_vpc_nat_gateway"}
{"description": " also remove currently unused interruptmsgproc param from sendmessages. i guess some squashing can be done (but i'm worried that interruptmsgproc is planned to be used in sendmessages later). ", "commit_messages": " net: cconnman: make some methods const  net: make cnetmsgmaker more const  net: pass interruptmsgproc as const where possible ", "linked_issue_titles": "", "title": "turn some methods and params/variables const"}
{"description": " this fixes a case where // /* */ became /* /* */ */ but the comment in the test is still duplicated because of babel's ast format (babel/babel#12769). fixes part of #5787 (so at least the produced code is syntactically valid now). ", "commit_messages": " add test  fix the incorrectly nested comment printing ", "linked_issue_titles": "", "title": "fix astring generation of nested comment"}
{"description": " improve heading structure of landing page the full strapline is too long for a heading. it also caused installation and usage to be be on the lowest heading level and didn't translate to the visual representation of the landing page before: after: fixes issues with skipped headings did not check every page under  /components or /api since they're mostly auto-generated. especially for demos i'm not that concerned with skipped headings. the demo should not be concerned with the context it's embedded in. ", "commit_messages": " [docs] improve heading structure  [docs] fix incorrect heading structure for /styles/api  [docs] reduce /customization/breakpoints demos  [docs] improve a11y story of /customization/color#color-tool ", "linked_issue_titles": "", "title": "fix various issues with heading structure"}
{"description": " hi @kazuho !! h2o_mruby supports simple reverse proxy method. please review it :) backends = [ \" \" \" \" ] r = h2o::request.new if r.uri == \"/proxy.html\" r.reprocess_request backends[rand(backends.length)] else # pass to next normal handler h2o.return h2o::declined end ", "commit_messages": " add h2o::request#reverse_proxy  add h2o::request#reverse_proxy test ", "linked_issue_titles": "", "title": "support simple reverse proxy feature in mruby handler"}
{"description": " this patch set enables prefix delegation for a link that shows up later than the ones running the dhcpv6 client. this functionality is useful when the upstream link has been enabled long before local networking is connected or enabled; should any of the later links need prefix delegation, the dhcpv6 clients of the uplinks are restarted to acquire prefixes. fixes #9758 ", "commit_messages": " networkd-dhcp: rename function and reduce its logging  rename dhcp6_verify_link() to dhcp6_get_prefix_delegation() in order  to be clearer in what it does. reduce unnecessary logging.  networkd-dhcp6: request prefix delegation for a new link  request prefix delegation for a new downstream link that is enabled  after any number of upstream dhcpv6 links. submit the request after  the link has been configured with a link-local address.  if the upstream dhcpv6 client has already been configured to request  prefixes, attempt to re-assign any possible prefixes between the  already existing links and the new one. if no prefixes are yet  acquired, nothing will happen right away and any prefixes will be  distributed after a reply from the dhcpv6 server.  if none of the already existing downstream links have requested  dhcpv6 prefixes to be assigned, enable prefix delegation for each  client and restart them one by one if they are already running. this  causes the dhcpv6 clients to re-acquire addresses and prefixes and  to re-distribute them to all links when receiving an updated  response from their respective dhcpv6 servers. if the dhcpv6 client  in question was not already running, it is set to request prefixes  but not restarted.  when an error occurs while setting or restarting the dhcpv6 client,  log the incident and move over to the next link.  fixes #9758. ", "linked_issue_titles": " dhcpv6 pd not requested for later appearing downstream interfaces ", "title": "dhcp6 pd enable later link"}
{"description": " this pr fixes some inconsistencies relating to any and keyof any as the constraint type in a mapped type. specifically, the mapped types { [p in any]: t } and { [p in keyof any]: t } both now yield a type corresponding to { [x: string]: t }. fixes #19152. ", "commit_messages": " properly handle mapped types with 'keyof any'  mapped type { [p in any]: t } should yield { [x: string]: t }  add tests  accept new baselines ", "linked_issue_titles": " mapped generic type with <any> parameter inferred as \"any\" ", "title": "fix 'any' and 'keyof any' in mapped types"}
{"description": " steam games were not showing up while searching using powertoys run. this was happening as they were internet shortcut files with a url file extension. references list of uri schemes -  pr checklist applies to #3425 cla signed. if not, go over here and sign the cla tests added/passed detailed description of the pull request / additional comments changes made in this pr - filter out steam internet shortcut files and obtain their icon. update description to internet shortcut application instead of win32 application. this is the first step towards having separate subtitles so that we can update it for pwas as well. since internet shortcut files don't have run as admin functionality, removed that context menu icon if it is an internet shortcut file. validation steps performed steam games show up - ", "commit_messages": " search shows up steam games  formatting ", "linked_issue_titles": "", "title": "fix for steam games not showing up"}
{"description": " forward port of 5dcce06 wip mostly to see if it passes ci lib/ansible/parsing/vault lib/ansible/cli/ ansible version ansible 2.3.0 (vault_password_bytes_port 91f0e02738) last updated 2017/03/07 14:56:29 (gmt -400) config file = /home/adrian/.ansible.cfg configured module search path = default w/o overrides python version = 2.7.13 (default, jan 12 2017, 17:59:37) [gcc 6.3.1 20161221 (red hat 6.3.1-1)] ", "commit_messages": " retain vault password as bytes in 2.2  prior to 2.2.1, the vault password was read in as byes and then remained  bytes all the way through the code.  a bug existed where bytes and text  were mixed, leading to a traceback with non-ascii passwords.  in devel,  this was fixed by changing the read in password to text type to match  with our overall strategy of converting at the borders.  this was  backported to stable-2.2 for the 2.2.1 release.  on reflection, this should not have been backported as it causes  passwords which were originally non-utf-8 to become utf-8.  people will  then have their working 2.2.x vault files become in-accessible.  this commit pipes bytes all the way through the system for vault  password.  that way if a password is read in as a non-utf-8 character  sequence, it will continue to work in 2.2.2+.  this change is only for  the 2.2 branch, not for 2.3 and beyond.  why not everywhere?  the reason is that non-utf-8 passwords will cause  problems when vault files are shared between systems or users.  if the  password is read from the prompt and one user/machine has a latin1  encoded locale while a second one has utf-8, the non-ascii password  typed in won't match between machines.  deal with this by making sure  that when we encrypt the data, we always use valid utf-8.  fixes #20398  (cherry picked from commit 5dcce0666a81917c68b76286685642fd72d84327)  remove the read_vault_password_file in dataloader.  doesn't look like anything is using it at the moment  and it duplicates cli.cli.read_vault_password_file.  will revist to see if it makes more sense in dataloader  once this works.  merge fixup ", "linked_issue_titles": "", "title": "vault password as bytes forward port"}
{"description": " fixes #17844 please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change this pr copies the mshadow thresholding approach to ensure, that softrelu is numerically stable for large inputs values. ", "commit_messages": " fix numerically unstable fused softrelu op  implement test for softrelu numerical stability ", "linked_issue_titles": " hybridized softrelu on the gpu is not numerically stable ", "title": "fix softrelu fused operator numerical stability"}
{"description": " this is a continuation/split-off from #22986, where i tried to deduplicate the cython code for unique/factorize, and add a return_inverse kwarg to unique at the same time. this didn't fully work because there was a performance impact that was deemed unacceptable. i've opened cython/cython#2660 to figure out why (resp. have a directive to allow force-compilation of different parameter values, which would solve this more elegantly), and @robertwb told me that it's likely the use of kwargs, but also suggested the possibility to use explicit templating on return_inverse. first i tried unification without any kwargs in 858f54e - this still had the same perf impact as in #22986. then i added the explict templating in 4ed354a, which successfully avoids the perf impact, but is a bit uglier in the pxi.in. finally, i've readded the kwargs in 906cd50 to keep the diff here smaller, and this doesn't have an impact. i've had many unsuccessful tries to run the asvs for all those combinations over the weekend, so i'm going back to explicitly testing the unique-code here (code at the end). the overview is as follows (for completeness i've added the #22986 and the commit immediately prior on master; all results in milliseconds): >>> df e5196aaac6 99e640186e caea25a8b9 858f54e5e4 4ed354a954  906cd50e83 0d6dad0ca1 #22986~1     #22986     master  no kwargs  templated tmpl+kwargs  pr+master stringindex        16.220276  16.023982  15.967190  15.706223  15.624902   14.952832  15.480224 categoricalindex    1.274368   1.289882   1.231592   1.400420   1.247882    1.250814   1.327520 intindex            2.743178   2.778960   2.722282   3.115781   2.818848    2.802402   2.877664 uintindex           2.760333   2.773203   2.714546   3.037279   2.786909    2.800675   2.914427 rangeindex          2.765113   2.773916   2.804379   3.071501   2.801661    2.803809   2.816012 floatindex          4.734558   4.576122   4.575152   5.043915   4.518481    4.548134   4.732967 timedeltaindex      4.361350   4.238442   4.187650   4.601932   4.369402    4.409724   4.422439 stringseries       59.779114  58.508761  57.742805  58.343838  58.266719   57.043169  58.619018 categoricalseries   2.708816   2.666240   2.627852   2.895955   2.664937    2.658149   2.715396 intseries           5.078922   4.991856   4.928836   5.480455   5.108894    5.096692   5.434841 uintseries          5.127376   4.984227   5.027707   5.445736   5.155703    5.080125   5.211029 rangeseries         5.218271   5.013379   4.973759   5.531086   5.193241    5.091924   5.197651 floatseries         7.126269   6.959626   6.988052   7.738704   6.977395    6.978753   7.215513 timedeltaseries     5.146969   4.985955   5.024334   5.551364   5.153091    5.108740   5.158593 or, relatively to the commit on master i was basing myself on: >>> df.divide(df.iloc[:, 2], axis=0) e5196aaac6 99e640186e caea25a8b9 858f54e5e4 4ed354a954  906cd50e83 0d6dad0ca1 #22986~1     #22986     master  no kwargs  templated tmpl+kwargs  pr+master stringindex         1.015850   1.003557        1.0   0.983656   0.978563    0.936472   0.969502 categoricalindex    1.034733   1.047329        1.0   1.137081   1.013227    1.015607   1.077889 intindex            1.007676   1.020820        1.0   1.144547   1.035472    1.029431   1.057078 uintindex           1.016868   1.021608        1.0   1.118890   1.026658    1.031729   1.073633 rangeindex          0.985999   0.989138        1.0   1.095252   0.999031    0.999797   1.004148 floatindex          1.034842   1.000212        1.0   1.102458   0.987613    0.994095   1.034494 timedeltaindex      1.041479   1.012129        1.0   1.098930   1.043402    1.053031   1.056067 stringseries        1.035265   1.013265        1.0   1.010409   1.009073    0.987884   1.015174 categoricalseries   1.030810   1.014608        1.0   1.102024   1.014112    1.011529   1.033314 intseries           1.030450   1.012786        1.0   1.111917   1.036531    1.034056   1.102662 uintseries          1.019824   0.991352        1.0   1.083145   1.025458    1.010426   1.036462 rangeseries         1.049160   1.007966        1.0   1.112053   1.044128    1.023758   1.045015 floatseries         1.019779   0.995932        1.0   1.107419   0.998475    0.998669   1.032550 timedeltaseries     1.024408   0.992361        1.0   1.104895   1.025627    1.016799   1.026722 so long story short, this pr prepares the hashtable-backend to support return_inverse=true, which plays into #21357 #21645 #22824, and will also allow to easily solve #21720. code for the above timings: import pandas as pd import numpy as np import pandas.util.testing as tm import timeit hash = pd.__git_version__[:10] k = 10 ** 5 rep = 10 number = 100 tic = timeit.default_timer() tags = ['string', 'categorical', 'int', 'uint', 'range', 'float', 'timedelta'] df = pd.dataframe(index = [x+'index' for x in tags], columns = ['mean', 'std']) np.random.seed(55555) with tm.rngcontext(55555): for tag in tags: idx = getattr(tm, f'make{tag}index')(k=k) t = timeit.repeat('idx.unique()', setup='from __main__ import idx', repeat = rep+1, number = number)[1:] df.loc[tag+'index', 'mean'] = pd.series(t).mean() / number df.loc[tag+'index', 'std'] = pd.series(t).std() / number s = pd.series(idx).sample(frac=2, replace=true) t = timeit.repeat('s.unique()', setup='from __main__ import s', repeat = rep+1, number = number)[1:] df.loc[tag+'series', 'mean'] = pd.series(t).mean() / number df.loc[tag+'series', 'std'] = pd.series(t).std() / number df.to_csv(f'test_{hash}.csv') ", "commit_messages": " unify unique/factorize, remove kwargs (perf); enable inverse for unique  template over {return_inverse, ignore_na} for perf  re-add kwargs to method signature ", "linked_issue_titles": "", "title": "add return_inverse to cython-unique; unify unique/factorize-code"}
{"description": " in the documentation for accounts.loginwith<externalservice>, the forceapprovalprompt option which forces the user consent prompt to appear is missing. the option's implementation can be found here. to add the documentation, i simply copied the description of the option from the same field on accounts.ui.config (seen here) note: i bumped the patch version as the contribution guidelines instructed, though i'm not really sure if i was supposed to (since i didn't really change much code, just added a line to documentation). sorry if i made the wrong call! - i un-bumped the patch version because it looked like that was what was causing build and test to fail, but it ended up still failing anyway. i would be really appreciative if whoever reviews this could let me know whether to bump the patch version or not! ", "commit_messages": " adds documentation for accounts-oath forceapprovalprompt  documentation for the forceapprovalprompt option for loginwith<externalservice> was missing - i copied the documentation for the same option from accounts.ui.config  bump patch version of accounts-oauth ", "linked_issue_titles": "", "title": "add documentation for the forceapprovalprompt option of accounts.loginwith<externalservice>"}
{"description": " fast parsing of ints/doubles as strings as described in #560 note: the null-termination character is never added, always use explicit length ", "commit_messages": " added kparsenumbersasstringsflag  added number() to rapidjson::handler  parsenumber() handles kparsenumbersasstringsflag ", "linked_issue_titles": "", "title": "implemented feature as in #560 (ints/doubles as strings)"}
{"description": " backport of 12524. in running tests on pypy, there were failures due to improper use of the c-api: calling initoperators to initialize the generated ufuncs before calling pytype_ready(pyufunc_type) using the pysequence_fast* functions before calling pysequence_fast which works on cpython but does not always work on pypy we could prevent these mistakes by getting pypy into our ci testing, but there are still test failures due to insufficient ctypes and memoryview support in pypy late writing docstrings into types and objects via _multiarray_umath.add_docstring ", "commit_messages": " maint: call pysequence_fast() before any other pysequence_fast* funcs  bug: call pytype_ready before using type  maint: comment, fix from review  sty: bracket if blocks with braces  doc: rearrange comment sequence from review  sty: add space after \"if\"  maint: unify error messages ", "linked_issue_titles": "", "title": "fix improper use of c-api"}
{"description": " adds special handling for void when checking initializers of binding patterns with zero elements. previously checked only that the initializer type was not null or undefined. fixes #30638 ", "commit_messages": " add failing tests for destructuring void  handle destructuring zero elements from void  add new baselines for destructuring void ", "linked_issue_titles": "", "title": "add type error when destructuring zero elements from void"}
{"description": " this pr implement tasks to set development version and exe icon on windows. the editor window still doesn't have a icon because of atom-shell bug: electron/electron#123. ", "commit_messages": " use node-rcedit to set development version.  add task to set exe icon.  revert \"only run set-development-version on mac\"  this reverts commit 9a4db9d95db8b179397ec3b77ad76b03d1fe1545.  it's supported on windows now. ", "linked_issue_titles": "", "title": "set version strings and icon for the exe on windows"}
{"description": " fixes #3885 ", "commit_messages": " remove legacy session identifier support  remove redundant test  redirect to login to support any invalid session identifiers  be more specific with caught errors  reject empty values in dynamicform ", "linked_issue_titles": " datasource is created with empty ssl mode ", "title": "fix empty values sent in dynamic form"}
{"description": " cherry-picking #25504 to the 5.1 branch. thanks @jirid! fixes rdar://49639321 ", "commit_messages": " [irgen] use singleton metadata strategy in jit mode.  fixedorupdate strategy does not work for non-generic classes in jit mode.  fixes rdar://49639321  split up test/irgen/jit_metadata_strategy.swift and fix the requires: line ", "linked_issue_titles": "", "title": "use singleton metadata strategy in jit mode [5.1]"}
{"description": " the blob class was missing the text() method which turns the blob arraybuffer into a string representation. this pr adds this. implementation code:  mdn reference:  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. ", "commit_messages": " added blob.text() method as it was missing  implementation code:  mdn reference:  added test assertion to text() ", "linked_issue_titles": "", "title": "add text method to blob in node-fetch"}
{"description": " changes the new throughput generators to track messages per window instead of making per-second calculations which can have rounding errors. also, one of these had a calculation error which prompted this change in the first place. fixes a couple typos. fixes an error where certain json fields were not exposed, causing the workloads to not behave as intended. fixes a bug where we use wait not in a loop, which exits too quickly. adds additional constant payload generators. fixes problems with an example spec. fixes several off-by-one comparisons. this was built and tested extensively prior to the moving of trogdor from tools/ to trogdor/. current update builds but fails in unrelated tests. ", "commit_messages": " minor: fix a couple trogdor issues.  fix whitespace issues. ", "linked_issue_titles": "", "title": "improvements and fixes for trogdor payload generators."}
{"description": " vxworks does have the <sys/ioctl.h> header file. in this header file fionbio is also defined but the fionbio request is only supported on socket fd. to set the blocking/non-blocking mode, fcntl is supposed to be used. vxworks' file system can respond to the fcntl request of ioctl. ", "commit_messages": " fix _py_set_blocking() for vxworks rtos  add news ", "linked_issue_titles": "", "title": "add os.set_blocking() support for vxworks rtos"}
{"description": " users can now rotate/pan/zoom based upon the key-bindings available in the settings even if they only have a trackpad. closes #53 ", "commit_messages": " added rotation/panning support for trackpads based upon key-bindings inside of the settings. ", "linked_issue_titles": " moving around in the 3d viewport ", "title": "added rotation/panning support for trackpads in 3d mode #53"}
{"description": " summary inspired by this comment: #1048 (comment) i thought it may be a good idea to omit node_modules by default when running prettier through cli. kinda fixes #1358. notable changes: adds new --with-node-modules cli flag to opt-out from default behavior adds integration tests inside tests_integration directory. adds new npm script command to run integration tests: test-integration test plan added an integration test suite. ", "commit_messages": " ignore node_modules by default  add integration test suite for --with-node-modules cli arg  refactor tests to snapshots ", "linked_issue_titles": " add a glob example for how to ignore node_modules ", "title": "ignore node_modules when running prettier from cli"}
{"description": " tested. note: see  packages/gitlab/gitlab_common.js   -- a new setting needs to be created to configure the gitlab server location. see client/views/login/services.coffee  -- need a gitlab icon or svg glyph ", "commit_messages": " initial commit of oauth2 client support for gitlab #512  fix overwritten code from clean-up ", "linked_issue_titles": "", "title": "initial implementation of oauth2 client support for gitlab server flow  #512"}
{"description": " closes #2874  adds \"users\" to the sort by option in issues stream. issues are sorted by user totals in the current date range, however it may be confusing because the user column shows total lifetime users impacted. this confusion is somewhat addressed via a tooltip in #18832 ", "commit_messages": " add sort issues by user totals  add sort group by users tests ", "linked_issue_titles": " possible to sort by user? ", "title": "add sort by users in issue stream"}
{"description": " i hereby agree to the terms of the cla available at:  category: short description: for tsvwithnames/csvwithnames formats column information (columns order) can now be parsed from format headers. this is controlled with input_format_with_names_use_header parameter. ", "commit_messages": " in [t|c]svwithnames formats start using column information from header  dropped a few debug leftovers  better naming ", "linked_issue_titles": "", "title": "support for header specified order of columns in tsvwithnames/csvwithnames formats"}
{"description": " also update the rmm plugin code to account for the updated signature of the template class rmm::mr::thrust_allocator<t> (rapidsai/rmm#647). ", "commit_messages": " [ci] upgrade cudf and rmm to 0.18 nightlies  modify rmm plugin to be compatible with rmm 0.18 ", "linked_issue_titles": "", "title": "upgrade cudf and rmm to 0.18 nightlies; require rmm 0.18+ for rmm plugin"}
{"description": " fixed db connection leak problem in the crash_gen tool, and ensured that it releases all db connections upon completion, making memory leak detection easier. no user impact, and no documentation changes are needed. ", "commit_messages": " fixed td-2499, ensuring crash_gen tool releases all db connections when completing tests  adjust crash_gen tool to direct logging output to stdout, instead of stderr ", "linked_issue_titles": "", "title": "resolving td-2499, ensuring crash_gen tool releases all resources"}
{"description": " this pr is to fix some incorrect anchor links as below. fix the incorrect anchor name \"preparelinux\", which cause cannot direct to correct section with link:  fix ", "commit_messages": " fix the incorrect link of preparelinux or preparemacos  fix incorrect link of common_installation_problems also ", "linked_issue_titles": "", "title": "fix some minor incorrect anchor links"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. the added types are available in expect, but are missing in these type definitions. see jest docs on expect: ", "commit_messages": " expect: add tobenull(), tobedefined(), tobeundefined()  expect: add expect(...).not  expect: add typings for expect.any()  expect: added tomatchobject()  expect: added tohavebeenlastcalledwith() ", "linked_issue_titles": "", "title": "add missing types to expect"}
{"description": " this pr refactors the integration cli build tests. please note this is only the start of the refactoring and more needs to be done. this pr only gets rid of some boilerplate code which was being repeated in more places. more consolidation has to be done in a future pr. ", "commit_messages": " integcli: add some more docker utils  docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack)  integcli: use dockercmdindir in build tests  docker-dco-1.1-signed-off-by: cristian staretu <cristian.staretu@gmail.com> (github: unclejack) ", "linked_issue_titles": "", "title": "minor refactor of the build tests"}
{"description": " fixes #14337, fixes #19228, fixes #14748, fixes #18956, fixes #14282 apologies for the massive pr. the fix for #14337 required me to modify the chaining wrappers for every single function, so i figured i should clean up some of the messy overloads along the way (which also fixed several other issues). unfortunately, this will be a breaking change in terms of what type arguments are accepted. so if anyone was explicitly passing type arguments (e.g. _.chain([]).find<_.lodashexplicitobjectwrapper<any>>('a')), their code may be broken. but i think in the long run this change should be more helpful than harmful, as it removes the need to explicitly pass type arguments in almost all cases. summary of changes: the chain wrapper interfaces have been greatly simplified. instead of many wrapper types (lodashimplicitarraywrapper, lodashimplicitobjectwrapper, lodashimplicitnumberarraywrapper, etc.), there are now only 2 wrapper types: lodashimplicitwrapper and lodashexplicitwrapper. this allows the return types to be more accurate (especially for functions like head and find). cleaned up messy function overloads (removed unnecessary type arguments) made iteratee arguments more consistent - now they all use one of the new iteratee types, unless they have a good reason not to. replaced object and function types with more appropriate types changed many dictionary<t> inputs to just take plain objects, so an index signature is not required please fill out this template: follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. (not appropriate) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " [lodash] improved iterateee parameters, simplified foreach overloads  changed listiterator to stringiterator, cleaned up more issues with flatmap  even more flatmap cleanup  making wrapper types simpler and more accurate (not done)  fixed type inference for foreach callback arguments  converted explicit wrapper types, implemented differencewith  updated more functions to use new-style wrappers  finished updating the remaining methods  # conflicts:  #\ttypes/lodash/index.d.ts  #\ttypes/lodash/lodash-tests.ts  fixed lint errors  fixed parameter type inference when using any (#19228) ", "linked_issue_titles": " lodash's _.mapkeys(object, ...) fails if object is type object  lodash chain methods uses wrong generic type  lodash missing _.transform as part of the lodashexplicitobjectwrapper  lodash definitions not working on ts 2.5  lodash foreach types broken in v4.14.74 ", "title": "better chaining wrappers, overload clean-up"}
{"description": " enabled code analysis for the editor. this does not fix 2 issues for ##923 for references pr checklist applies to #910 cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments validation steps performed ran application and editor worked as expected ", "commit_messages": " getting analysis up and going  adding in sytlecop and fixing issues  fixing blank lines  fix line issues  fixed a lot of line issues, few auto  moving converters, fixing spacing issues  adjusting event names  fixed a bunch more  fixed a bunch of infos  fixed rest of info items  fix for ca0507  few more fixes  last stylecop issue ", "linked_issue_titles": "", "title": "code analysis / style cop adjustments for .net"}
{"description": " rounds up fee on ram sells in the system contract to ensure a non-zero fee is always paid. ", "commit_messages": " fix fee calculation in sellram and comments  build fail fix  sellram should only succeed if there is a guarantee that the user will at least get some tokens back after the fee is deducted  fix ram fee rounding errors in eosio_system_tests ", "linked_issue_titles": "", "title": "round up fee when selling ram"}
{"description": " this pull includes the rest of the non-result changing float vectorization. min/max is a little ugly as it needs to propagate nan efficiently. are there platforms were fpu flag propagation is supported but no_floating_point_support is set? the base math is lengthy but simple, all the special cases are to archive optimal performance for these very common operations. base math reductions are not vectorized as they change the results slightly (float add and multiply are not associative) ", "commit_messages": " enh: vectorize float min/max operation with sse2  improves performance by ~1.5/3.0 for float/double.  enh: vectorize base math with sse2  improves performance by ~1.5/3.0 for float/double for inplace or cpu  cached operations ", "linked_issue_titles": "", "title": "min/max and base math vectorization"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see code below (not applicable) if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header tabulator-tables@4.9.3's package.json has the following: \"main\": \"dist/js/tabulator.js\", \"module\": \"dist/js/tabulator.es2015.js\", the latter has export default tabulator;, the former has: (function (global, factory) { if ((typeof exports === 'undefined' ? 'undefined' : _typeof(exports)) === 'object' && typeof module !== 'undefined') { module.exports = factory(); } else if (typeof define === 'function' && define.amd) { define(factory); } else { global.tabulator = factory(); }) applied to a function that returns the constructor for tabulator, so having export default tabulator in index.d.ts makes sense in either case. ", "commit_messages": " add default export to type definition and import it in test  disable prefer-const and get rid of octal literals to pass lint ", "linked_issue_titles": "", "title": "add default export for tabulator-tables"}
{"description": " basic version of data transfer object pattern implementation. ", "commit_messages": " #348 - data tranfer object : added module to project.  #348 - data tranfer object : add puml file to etc.  #348 - data tranfer object : implement data transfer object pattern simple version.  #348 - data tranfer object : add puml diagram.  #348 - data tranfer object : customer client request customer details to server at one shot.  #348 - data tranfer object : add readme.md ", "linked_issue_titles": "", "title": "#348 data transfer object design pattern"}
{"description": " what did you implement: in cloudformation, resources are created based on a dag built from the template file. previously, the lambda function iam policy had references to all log groups like this: {\"fn::join\": [\":\", [{\"fn::getatt\": [\"testfunctionloggroup\", \"arn\"]}, \"*\"]]}, for every log group. this made the iam policy depend on all the log groups completing so they could be referenced in the policy. this patch makes use of the aws::region and aws::accountid pseudo-parameters to fill in a full arn for the group. after this change, iam policy lines look like: {\"fn::sub\": \"arn:aws:logs:${aws::region}:${aws::accountid}:log-group:/aws/lambda/myservice-dev-test-function:*\"} the upshot here is that there's no reference to the cfn aws::logs::loggroup resource, so the dependency graph becomes more parallel (allowing cloudformation to do more at once) and makes deploys faster. the one downside to this change is that it could result in lambdas being deployed before their log groups, because currently the lambda depends on the iam role which then depends on the log group. i can add a dependson for each lambda to its respective log group. in practice, i haven't seen this occur because the iam role takes much longer to deploy than the log groups. how did you implement it: how can we verify it: todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " remove implicit dependency between iam policy and log groups  until now, the iam policy had a dependency on log groups completing  before it could finish because of the use of fn::getatt with a log  group, meaning the policy couldn't provision until all log groups were  ready.  this patch changes the log group reference in the cfn template from:    { \"fn::getatt\": [\"myfuncloggroup\", \"arn\"] }    to    {\"fn::sub\": \"arn:aws:logs:${aws::region}:${aws::accountid}:log-group:/aws/lambda/my-service-dev-myfunction:*\"}    meaning the policy can be resolved 100% with pseudoparams for log group arns.  this speeds up the cfn initial deploy significantly, and somewhat  improves deployments that add or rename functions.  having this dependency removed is also the first step in allowing log  groups to be moved to a nested stack.  add tests for new fn::sub template style ", "linked_issue_titles": "", "title": "reduce dependency tree depth between iam & log groups"}
{"description": " while further investigating this as requested, i found some single_file bugs that impacted html output and workers. specifically: single_file with html output would fail to compile, due to embedding the wasm in the js and deleting it, then afterwards trying to embed the deleted wasm in the html. in the case of both html and workers, multiple files would be produced/required (respectively, test.html + test.js and test.js + test.worker.js). most of the lines changed in emcc.py are just indentation, so this will be easier to view with ?w=1. ", "commit_messages": " single_file html output fix  single_file worker js output fix ", "linked_issue_titles": "", "title": "single_file html and worker fixes + tests"}
{"description": " issue: #2636 moved manager to core moved default webpack.config.js to core (didn't touch rn) ", "commit_messages": " move default webpack.config to core  use default webpack.config from core in angular app  move manager to core and use it in angular app  use core in polymer  use core in react  use core in vue ", "linked_issue_titles": "", "title": "move more things to core"}
{"description": " fixes #12673 the error only appears when a property initializer references another property before its definition. references to outer variables, etc are still allowed, and instance property initialisers are still allowed to reference static properties. ", "commit_messages": " error on forward references for property initializers  the error only appears when a property initializer references another  property before its definition. references to outer variables, etc are  still allowed.  test property initialiser forward reference errors ", "linked_issue_titles": "", "title": "error on forward references in property initializers"}
{"description": " these changes roughly follow #52551 (comment) after some course correct. add the apikey.id, apikey.name and authentication.type fields to the access_granted, access_denied, authentication_success and (some) tampered_request audit events (apikey.id and apikey.name are present only when authn with an api key) when authn with an api key, the user.realm field now contains the realm name of the user that created the key, instead of the synthetic value of _es_api_key. note that in this circumstance, the user.name field reflects the name of the user that created the key (they are consistent) user.roles contains the role names (only of found/resolved roles) of the user that created the key. it previously wrongly had the role descriptor names from the api key definition. this is now handled separately in #59041 . relates #52551 ", "commit_messages": " wip  wip mhhhmm  wip mhmm  nothing here  revert to wrong format  wip  wip  tests fix wip  teests compile and authenticationservicetests passes  le tests  limited role changes  authentication type  more tests  filter tests ", "linked_issue_titles": "", "title": "improve auditing of api key authentication"}
{"description": " this pr uses and updated version of biscotto (gjtorikian/biscotto#27) that interprets method references as follows: foo.bar is a class method baz::quux is an instance method this blends in cleanly with the coffeescript literal syntax and brings much joy. the new syntax is used both in the interpretation of {} links in method comments and in the generated docs. ", "commit_messages": " switch all documentation links to match coffeescript literal notation  foo::bar for instance methods  foo.bar for class methods  point at biscotto branch on github until atom/biscotto#27 lands ", "linked_issue_titles": "", "title": "use coffeescript literal syntax to reference methods in docs"}
{"description": " update: refactor check_for_upgrade file - move .zsh-update file migration inside check_for_upgrade - use a trap to remove the lock folder - simplify upgrade script call - rename functions update: remove lock directory if older than one day update: fix trap for sigint and read prompt on non-newline characters fixes #4992 fixes #5286 closes #6646 fixes #7042 fixes #8332 remaining upgrade issues these are not solved by this pr: #2971 #4361 #6732 #6989 #7539 #8003 #8387 #8788 ", "commit_messages": " update: refactor check_for_upgrade file  - move .zsh-update file migration inside check_for_upgrade  - use a trap to remove the lock folder  - simplify upgrade script call  - rename functions  update: remove lock directory if older than one day  update: fix trap for sigint and read prompt on non-newline characters ", "linked_issue_titles": " upgrade does not respect $home - wrong ownership after upgrade  alternative to auto-update prompt  update prompt doesn't appear to work, or does and just repeatidly asks.  old update.lock will block update ", "title": "refactor and fix logic in check_for_upgrade.sh"}
{"description": " issue link: airflow-6521 description above provides context of the change commit message/pr title starts with [airflow-nnnn]. airflow-nnnn = jira id* unit tests coverage for changes (not needed for documentation changes) commits follow \"how to write a good git commit message\" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. * for document-only changes commit message can start with [airflow-xxxx]. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. ", "commit_messages": " add optional 'project' parameter to bq hook method getschema  add some param documentation.  remove extraneous comma ", "linked_issue_titles": "", "title": "add project param to bigquery hook .getschema method"}
{"description": " this pr aims to add proper support of mask in timedistributed wrapper layer. several previous prs have raised questions about this or have attempted to solve it, but i didn't find any perfect solution so far. i may not be able to have a perfect one either but am willing to improve it. the most frequent usage of such layers with masking support might be a hierarchical rnn on a sentence with words with characters, or a paragraph with sentences with words. (e.g., models like this). here are the main ideas/purposes of this pr: for layers like timedistributed(embedding(..., mask_zero=true)) or timedistributed(masking(...)), the layer should call compute_mask() at each time step and stack them. for layers like timedistributed(lstm(...)), the input_mask should be split and fed into the lstm layer at each time step. and if the output_shape changes (e.g., return_sequences=false in lstm), the output_mask of the timedistributed layer should also change correspondingly. the timedistributed layer should support, e.g., input_shape=(none, none). for example, the number of words in a sentence and the number of characters in a word can be different from sample to sample. currently the timedistributed can only support one unspecified input dimension. here are some details of this pr to discuss, which might have better solutions: k.int_shape() may not be available for some mask with theano backend, especially when the inner layer is embedding or masking. this is because _keras_shape is not set in lots of operations in theano_backend if the tensor shape is not changed. i manually create the _keras_shape in compute_mask of these two layers. when input_shape[0] is not none in timedistributed layer, we need to use k.rnn() to dynamically call the inner layer. because k.rnn() can only take 1 tensor input but we need to feed both input and mask, i didn't do anything in this situation. probably we can pass all mask as constants to k.rnn() but i was expecting better solutions. if there's none from the output of k.int_shape, we need to replace it by the output from k.shape, so that reshape can be correctly called. ", "commit_messages": " equip timedistributed with mask and unspecified input length  fix bugs in theano. add test on timedistributed + masking ", "linked_issue_titles": "", "title": "handle mask in timedistributed wrapper."}
{"description": " due to bad formatting the apt-install ... command is not readable on github. also a couple of dependencies for atari-py and box2d-py are missing: cmake zlib1g zlib1g-dev swig. ", "commit_messages": " fix linux dependencies.  add linux dependencies for atari-py and box2d-py ", "linked_issue_titles": "", "title": "fix linux dependencies in readme.rst"}
{"description": " fixes #18831 this pr also includes a package version bump (16.13.1 -> 17.0.0-alpha.0) so that devtools tests will pass ci. pr #19108 broke devtools suspense integration. devtools uses the renderer's version number to figure out what the tag numbers are: react/packages/react-devtools-shared/src/backend/renderer.js lines 156 to 240 45eef8b if (gte(version, '16.6.0-beta.0')) { reacttypeofwork = { block: 22, classcomponent: 1, contextconsumer: 9, contextprovider: 10, coroutinecomponent: -1, // removed coroutinehandlerphase: -1, // removed dehydratedsuspensecomponent: 18, // behind a flag forwardref: 11, fragment: 7, functioncomponent: 0, hostcomponent: 5, hostportal: 4, hostroot: 3, hosttext: 6, incompleteclasscomponent: 17, indeterminatecomponent: 2, lazycomponent: 16, memocomponent: 14, mode: 8, offscreencomponent: 23, // experimental profiler: 12, simplememocomponent: 15, suspensecomponent: 13, suspenselistcomponent: 19, // experimental yieldcomponent: -1, // removed }; } else if (gte(version, '16.4.3-alpha')) { reacttypeofwork = { block: -1, // doesn't exist yet classcomponent: 2, contextconsumer: 11, contextprovider: 12, coroutinecomponent: -1, // removed coroutinehandlerphase: -1, // removed dehydratedsuspensecomponent: -1, // doesn't exist yet forwardref: 13, fragment: 9, functioncomponent: 0, hostcomponent: 7, hostportal: 6, hostroot: 5, hosttext: 8, incompleteclasscomponent: -1, // doesn't exist yet indeterminatecomponent: 4, lazycomponent: -1, // doesn't exist yet memocomponent: -1, // doesn't exist yet mode: 10, offscreencomponent: -1, // experimental profiler: 15, simplememocomponent: -1, // doesn't exist yet suspensecomponent: 16, suspenselistcomponent: -1, // doesn't exist yet yieldcomponent: -1, // removed }; } else { reacttypeofwork = { block: -1, // doesn't exist yet classcomponent: 2, contextconsumer: 12, contextprovider: 13, coroutinecomponent: 7, coroutinehandlerphase: 8, dehydratedsuspensecomponent: -1, // doesn't exist yet forwardref: 14, fragment: 10, functioncomponent: 1, hostcomponent: 5, hostportal: 4, hostroot: 3, hosttext: 6, incompleteclasscomponent: -1, // doesn't exist yet indeterminatecomponent: 0, lazycomponent: -1, // doesn't exist yet memocomponent: -1, // doesn't exist yet mode: 11, offscreencomponent: -1, // experimental profiler: 15, simplememocomponent: -1, // doesn't exist yet suspensecomponent: 16, suspenselistcomponent: -1, // doesn't exist yet yieldcomponent: 9, }; } as of #19108, devtools also decides how to traverse suspense fibers using the tag values as a form of feature detection: react/packages/react-devtools-shared/src/backend/renderer.js lines 1241 to 1247 45eef8b const aresuspensechildrenconditionallywrapped = offscreencomponent === -1; if (aresuspensechildrenconditionallywrapped) { primarychild = fiber.child; } else if (fiber.child !== null) { primarychild = fiber.child.child; } the reason this pr also bumps version numbers is that we previously had multiple suspense implementations published under 16.13.1 (both the npm releases and our ci-built releases that tests run against), so the devtools heuristic failed. to prevent this type of regression from happening again, a larger effort needs to be made in the form of follow up prs to get ci running devtools tests against a range of react releases (not just what's in master). ", "commit_messages": " fixed suspense wrapping heuristic  bump package numbers 16.13.1 -> 17.0.0-alpha.0 to fix devtools suspense heuristic ", "linked_issue_titles": " error: \"commit tree does not contain fiber 256. this is a bug in react devtools.\" ", "title": "fix suspense-wrapping heuristic (and bump version numbers)"}
{"description": " this pr includes fixes for b/30130919 also. ", "commit_messages": " add oss-parent as parent of libphonenumber-parent  roll back libphonenumber parent changes to unblock release  [maven-release-plugin] prepare release libphonenumber-7.4.5  [maven-release-plugin] prepare for next development iteration ", "linked_issue_titles": "", "title": "maven pom.xml updates for release 7.4.5"}
{"description": " related issue = #1905 #1996 in this pr, i try to determine which extension instruction should be used when casting integers. according to my understanding, we should use zext for unsigned int, and sext for signed int. please note that, the original goal of this pr is to determine the instruction for custominttype.  one custominttype should be loaded through globalloadstmt first before casting. after loading, the custominttype would be a \"normal\" integer type (the same type as its computetype). that is to say, we can simply treat the custominttype  and primitive integer type equally here. ", "commit_messages": " mod extensin instructions  add tests  mod tests  fix typo ", "linked_issue_titles": "", "title": "use zext instruction to cast unsigned int"}
{"description": " two fixes here: first, ie11 doesn't do 3d transforms, so we need the fallback. luckily, @supports is dope as hell. second, ie11 has a weird bug with flex: 1 0 auto and min-width on flex items in a variable width parent container. the fix? use width instead. see philipwalton/flexbugs#128 for details. fixes #22882 ", "commit_messages": " use @supports to apply transform3d to those who can do it, then provide a non-3d fallback to ie11  using max-width in flex: 1 0 auto; in ie11 offsets the center-aligned contents ", "linked_issue_titles": "", "title": "fix broken carousel in ie11"}
{"description": " 5.1 cherry-pick of #23944. fixes rdar://49710077 ", "commit_messages": " irgen: assert if its too late to queue up lazy emission  irgen: emit field reflection descriptors for types with custom alignment  the code to decide if field descriptors were going to be emitted was  confusing, so i've refactored it a bit.  irgen: change around how we decide to emit lazy type metadata  the old logic was confusing. the lazytypeglobals map would contain  entries for all referenced types, even those without lazy metadata.  and for a type with lazy metadata, the islazy field would begin  with a value of false -- unless it was imported.  when a non-imported type was finally visited in the ast, we would  try to \"enable\" lazyness for it, which meant queueing up any  metadata that had been requested prior, or immediately emitting  the metadata otherwise.  instead, let's add a separate map that caches whether a type has  lazy metadata or not. the first time we ask for the metadata of a  type, consult this map. if the type has lazy metadata according to  the map, queue up metadata emission for the type. otherwise, emit  metadata eagerly when the type is visited in the ast.  irgen: emit foreign type metadata using the lazy metadata mechanism  instead of a wholly separate lazyness mechanism for foreign metadata where  the first call to getaddrofforeigntypemetadatacandidate() would emit the  metadata, emit it using the lazy metadata mechanism.  this eliminates some code duplication. it also ensures that foreign  metadata is only emitted once per sil module, and not once per llvm  module, avoiding duplicate copies that must be odr'd away in multi-threaded  mode.  this fixes the test case from <rdar://problem/49710077>.  irgen: lazily emit reflection field descriptors  previously even if a type's metadata was optimized away, we would still  emit a field descriptor, which in turn could reference nominal type  descriptors for other types via symbolic references, etc.  irgen: force field descriptors to be emitted when we emit typerefs  emission of typerefs used by the runtime would force type metadata;  do the same for remote reflection-only typerefs.  irgen: stop forcing lazy metadata in a few places  these were all working around other issues that have since been fixed. ", "linked_issue_titles": "", "title": "fix some problems with irgen lazy metadata emission [5.1]"}
{"description": " fixes #11564 remove the iterative use of plt.subplot that will soon be deprecated. not sure there is something to do for plot_discretization_classification.py, no warning were raised when i tried to reproduce. am i missing something ? ", "commit_messages": " change depreciated matplotlib code to new matplotlib api  remove unused params ", "linked_issue_titles": " plot_svm_scale_c.py and plot_discretization_classification.py use deprecated plt api ", "title": "fix plot_svm_scale_c.py and plot_discretization_classification.py use deprecated plt api"}
{"description": " streams like inputmemorystream and deflatedecompressor have slightly different semantics. if you try to read 4096 byte from an inputmemorystream that only has 1024 bytes, then it will fail, but you can still go on because the stream is still in a well defined state. doing the same with deflatedecompressor leaves the stream in a not so well defined state because some of the data could have been consumed already, the stream is left in an undefined state. that's why i am adding has_fatal_error and has_recoverable_error instead of a single has_error. ", "commit_messages": " streams: distinguish recoverable and fatal errors.  ak: remove history from duplexmemorystream.  that feature was really only useful for compress::deflatedecompressor  but that is now using circularduplexbuffer instead.  ak: move memory streams into their own header.  ak: add duplexmemorystream::copy_into_contiguous_buffer.  ak: add outputmemorystream class. ", "linked_issue_titles": "", "title": "better error handling; move memory streams into their own header."}
{"description": " in case of a new cheat sheet, you have used the cheat sheet template. all the markdown files do not raise any validation policy violation, see the policy. all the markdown files follow these format rules. all your assets are stored in the assets folder. all the images used are in the png format. any references to websites have been formatted as text the ci build of your pr pass, see the build status here. this pr covers issue #. ", "commit_messages": " update docker_security_cheat_sheet.md  grammar update in the access_control_cheat_sheet.md cheatsheet. (#422)  syncing with the owasp/cheatsheetseries  updated grammar in web_service_security_cheat_sheet  syncing with master branch of owasp/cheatsheetseries  syncing with owasp/cheatsheetseries  update with opa  update kubernetes_security_cheat_sheet.md  update with service mesh ", "linked_issue_titles": "", "title": "update k8s security cs with service mesh & opa"}
{"description": " what's in this pull request? better abi compatibility checks - more aligned with the sil verifier. the devirtualizer now respects the no-opt markers of callee functions. resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " addresses are always abi compatible.  now it is more inline with the check performed by the verifier.  add a more strict check for conversions between metatypes.  now it is more inline with the check performed by the verifier.  [sil-devirtualizer] do not perform a speculative devirtualization for no-opt callees. ", "linked_issue_titles": "", "title": "small fixes for the sil-devirtualizer"}
{"description": " this pr refactors the rllib train.py script to depend on a new ray.tune module, which implements efficient hyper-parameter search. the overall usage of train.py remains roughly the same, though now it supports two modes: inline args: ./train.py --env=pong-v0 --alg=ppo --num_trials=8 --stop '{\"time_total_s\": 3200}' --resources '{\"cpu\": 8, \"gpu\": 2}' --config '{\"num_workers\": 8, \"sgd_num_iter\": 10}' file-based: ./train.py -f tune-pong.yaml both delegate scheduling of trials to the ray.tune trialrunner class. additionally, the file-based mode supports hyper-parameter tuning (currently just grid and random search). note that though ray.tune should be written to support generic training, right now it has some rl-specific notions like agents and envs, which we should try to remove. ", "commit_messages": " clean up train  update  update train script  add tuned examples  add agent catalog  add tune lib  update  fix  tests  remove  train docs ", "linked_issue_titles": "", "title": "initial work on integrating hyperparameter search tool"}
{"description": " modifies randomversionbetween so that it works with unreleased versions. this should make switching a version from unreleased to released much simpler. ", "commit_messages": " wip  test: randomversionbetween works with unreleased  modifies randomversionbetween so that it works with unreleased  versions. this should make switching a version from unreleased  to released much simpler. ", "linked_issue_titles": "", "title": "make randomversionbetween work with unreleased versions"}
{"description": " i checked most examples and the only problem left is the depthpassplugin. it fixes a lot of problems like visibility and  the __webglinit hack. performance is similar on all examples. so how do we proceed further?? ", "commit_messages": " fix the hack __webglinit for geometry that needs buffer updates.  use recursive projectobject to fix visiblility and make renderdata smaller ", "linked_issue_titles": "", "title": "remove hackery + fix visibility in webglrenderer"}
{"description": " v1.17.0 is released, add api compatibility data for it generated by doing: git checkout v1.17.0 cp -fr staging/src/k8s.io/api/testdata/head staging/src/k8s.io/api/testdata/v1.17.0 git checkout -b 1.17.0-api-fixtures master git add . git commit -m ... does this pr introduce a user-facing change?: / ", "commit_messages": " add v1.17.0 api compatibility data  drop v1.15.0 api test data ", "linked_issue_titles": "", "title": "update api compatibility data for v1.17.0"}
{"description": " backport of #36824 to stable-2.5 fixes documentation and ip configuration where no public ip is defined. azure_rm_networkinterface ansible version 2.5 ", "commit_messages": " azure_rm_networkinterface: fixed issue when public ip address should not be created (#36824)  * fixed issue when public ip address should not be created  * adding test for public ip address  * fixed samples  * another fix to sample formatting  * fixed test  * fix test  * fixed test  * another attempt to fix test  * maybe it works now  * still wrong  * improved check per customer request  * removed stupid semicolon  * updated test to match main scenario  * changed ip configurations to list  * another attempt  (cherry picked from commit 89401f13f761c94552fca8eafbaf5bcf54aff40c)  added changelog fragment ", "linked_issue_titles": "", "title": "backport no public ip fix"}
{"description": " this commit lowers the severity for all settings from critical to warning for all settings that are still present in 8.0.0. releated #79107 === note - i have requested review from @tvernum and @jbaiera since these settings are mostly from areas for which they are familiar. please add others for review if needed. cc: @masseyke @rjernst @pgomulka === note this settings were identified by introducing the following debug code in 8.0.0 and 7.16 and comparing the two lists. if the same setting showed up as deprecated in both 7.16 and 8.0.0 it is included in this pr. if the setting was missing in 8.0.0, no changes since the default is critical. diff --git a/server/src/main/java/org/elasticsearch/common/settings/setting.java b/server/src/main/java/org/elasticsearch/common/settings/setting.java index a56baf6cf3b..8a23f9ce906 100644 --- a/server/src/main/java/org/elasticsearch/common/settings/setting.java +++ b/server/src/main/java/org/elasticsearch/common/settings/setting.java @@ -161,6 +161,12 @@ public class setting<t> implements toxcontentobject { this.defaultvalue = defaultvalue; this.parser = parser; this.validator = validator; +        if(arrays.stream(properties).filter(p -> p.equals(property.deprecated) || p.equals(property.deprecatedwarning)).count() > 0){ +                       system.out.println(\"**deprecated setting: \" + key + +                           (arrays.stream(properties).filter( p -> p.equals(property.deprecatedwarning)).count() > 0 ? \"(warning)\" : \"\")); + + +                    } if (properties == null) { throw new illegalargumentexception(\"properties cannot be null for setting [\" + key + \"]\"); } ", "commit_messages": " initial iter  more iterations ", "linked_issue_titles": "", "title": "reduce deprecation logging severity for settings that are not removed in 8.0"}
{"description": " this pr is a continuation of #76455 changes overflow renamed to posoverflow and underflow renamed to negoverflow after discussion in #76455 changed some of the parsing code to return invaliddigit rather than empty for strings \"+\" and \"-\".  carry the problem char with the invaliddigit variant. necessary changes were made to the compiler as it depends on int_error_matching. redid tests to match on specific errors. r? @kodraus ", "commit_messages": " fill in things needed to stabilize int_error_matching  bring char along with invaliddigit  remove incorrect plural  remove onlysign in favour of invaliddigit  add comment to helper function ", "linked_issue_titles": "", "title": "refactor interrorkind to avoid \"underflow\" terminology"}
{"description": " added izi in transportation section added zippopotam to geocoding section ", "commit_messages": " added cloud vision api  added rekognition api  cloud vision api link fixed  merge  # conflicts:  #\treadme.md  added izi in transportation section  added zippopotam to geocoding section ", "linked_issue_titles": "", "title": "added zippopotam and izi in list"}
{"description": " at the moment you can only get an array of full messages. the link with their attributes are lost. i'd like clients to be able to relate full error messages to their corresponding fields. so i'd like to get e.g. : with this patch it makes the implementation possible with: obj.errors.map { |attr, msg| [attr, obj.errors.full_message(attr, msg)] } ", "commit_messages": " add ability to get an individual full error message + test for full_messages.  added test for obj.errors.as_json ", "linked_issue_titles": "", "title": "ability to get single full error message"}
{"description": " there's one user who has an issue that one of raylets cannot schedule tasks anymore because num_worker_not_started_by_job_config_not_exist  > 0. this pr adds better log messages to figure out if the root cause is the job information is not properly propagated from gcs to raylet through redis pubsub. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " done  lint ", "linked_issue_titles": "", "title": "better logs job message failure"}
{"description": " addresses the handful of remaining feedback from pt. 2, plus adds two new tests: one verifying a multi-topology application with a fkj and its internal topics, another to make sure iq works with named topologies (though note that there is a bit more work left for iq to be fully supported, will be tackled after pt. 3 ", "commit_messages": " followup to feedback from pt. 2, cleanup some tests and peel some pt. 3 refactoring up front, plus test for iq  clarify iq status ", "linked_issue_titles": "", "title": "minor followup from pt. 2 and some new tests"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " update: add get command types  update: add consent types ", "linked_issue_titles": "", "title": "add type of get, consent"}
{"description": " implementation of #6345. the code might be a bit complicated, though i tried to make it as de-coupled from the rest of the codebase as possible. the feature is hidden behind an option, and using the default value means no change in behavior and very little additional code execution. ", "commit_messages": " initial commit w/ working implementation  bug fixes, code cleanup  add execution guard if option is 0 ", "linked_issue_titles": "", "title": "implementation of #6345 - remember tree hierarchy in db navigator"}
{"description": " this speeds up testlogview in test_views.py by moving the app instantiation out of setup and  into setupclass. currently the tests are slow because the app instantiation takes 6 seconds each time, and multiple of the test methods are parameterized, slowing the test down further. www tests now completes in 9:08. previously it was ~12minutes. ", "commit_messages": " blah.  make fail on purpose. ", "linked_issue_titles": "", "title": "speed up tests by moving app instantiation to class method"}
{"description": " with quite some discussions on naming of the apis, finally adds 3 new apis: bool objectempty() sizetype membercount() removeallmembers() apis similar to vector::capacity() and vector::reserve() are not added for member, because some possible implementations of associative array may be considered in the future and these apis may not be suitable for those situations. fixes #116 ", "commit_messages": " add value::membercount(), memberempty(), removeallmembers()  change memberempty() to objectempty() ", "linked_issue_titles": " value::membercount() or value::objectsize() ", "title": "three new apis are added for json object type."}
{"description": " fixes #18837 on sklearn.decomposition set check_finite to false after verifying that the input is checked by one of the internal functions. ", "commit_messages": " duplicate check_finite when calling scipy.linalg functions on covariance._empirical_covariance  check_finite=false on incremental_pca  check_finite=false on fastica  check_finite=false on factor_analysis ", "linked_issue_titles": " duplicate check_finite when calling scipy.linalg functions ", "title": "enh sets check_finite=false in sklearn.decomposition"}
{"description": " this pr adds: adjustments for windows ", "commit_messages": " add command to test wipeallpackages  wipe all packages test  tested on mac  additional checks in tests to ensure that exactly two versions of tool are not removed  fix the test to generate a relative symlink  add fake builds in the test  fix the default release track issue on windows  be able to parse absolute and relative paths in meteor.bat  fix wipe-all-packages test for windows  adapt wipe-all-packages command to windows layout ", "linked_issue_titles": "", "title": "wipe all packages on windows"}
{"description": " related issue = #1905 test case(0.75s -> 0.42s) import taichi as ti ti.init(arch=ti.cpu, kernel_profiler=true, print_ir=true, quant_opt_atomic_demotion=true) quant = true n = 1024 * 1024 * 256 if quant: ci16 = ti.quant.int(16, true) x = ti.field(dtype=ci16) y = ti.field(dtype=ci16) ti.root.dense(ti.i, n).bit_struct(num_bits=32).place(x, y) else: x = ti.field(dtype=ti.i16) y = ti.field(dtype=ti.i16) ti.root.dense(ti.i, n).place(x, y) @ti.kernel def foo(): for i in range(n): x[i] = 1 for i in range(10): foo() ti.kernel_profiler_print() ", "commit_messages": " ir for demoting atomic bit struct stores  codegen ", "linked_issue_titles": "", "title": "atomic demotion for bit struct stores"}
{"description": " this is a basic change.  we have nightwatchtesthooks extending nightwatchglobals, but the globals property is only scoped to nightwatchglobals.  this excludes global before, beforeeach, after, and aftereach functions. it's important to separate before/after and beforeeach/aftereach - they don't get the same arguments. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " fixed page_object_path to page_objects_path  added webdriver options to nightwatchoptions  forgot a semicolon  merge remote-tracking branch 'upstream/master'  changed globals definition to nightwatchtesthooks  separated global hook definitions ", "linked_issue_titles": "", "title": "changed globals from nighwatchglobals to nightwatchtesthooks"}
{"description": " before: ');@output_buffer.append= ( content_icon row[:content] );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('        ');@output_buffer.append= ( spinner_img );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('      </td> <td class=\"content\"> ');@output_buffer.append= ( content_link row[:content] );@output_buffer.safe_concat(' ');@output_buffer.safe_concat('      </td> <td class=\"message\"> '); after: ';@output_buffer.append=( content_icon row[:content] );@output_buffer.safe_append=' ';@output_buffer.append=( spinner_img );@output_buffer.safe_append=' </td> <td class=\"content\"> ';@output_buffer.append=( content_link row[:content] );@output_buffer.safe_append=' </td> <td class=\"message\"> '; ", "commit_messages": " use actionview::outputbuffer#safe_append= from templates  avoid extra method calls for appending newlines  before:  ');@output_buffer.append= ( content_icon row[:content] );@output_buffer.safe_concat('  ');@output_buffer.safe_concat('        ');@output_buffer.append= ( spinner_img );@output_buffer.safe_concat('  ');@output_buffer.safe_concat('      </td>  <td class=\"content\">  ');@output_buffer.append= ( content_link row[:content] );@output_buffer.safe_concat('  ');@output_buffer.safe_concat('      </td>  <td class=\"message\">  ');  after:  ';@output_buffer.append=( content_icon row[:content] );@output_buffer.safe_append='  ';@output_buffer.append=( spinner_img );@output_buffer.safe_append='  </td>  <td class=\"content\">  ';@output_buffer.append=( content_link row[:content] );@output_buffer.safe_append='  </td>  <td class=\"message\">  '; ", "linked_issue_titles": "", "title": "optimize generated erb to reduce method calls"}
{"description": " extending the gpgpu birds demo so that it can load any gltf model/animation and use meshstandardmaterial to shade. gltf vertices are baked onto a texture. one frame per row texture is passed to the vertex shader along with a frame reference. meshstandardmaterial is applied demo here :  on demo, a new geo is loaded randomly, may be confusing... this is my first pr ever. not sure if this is even helpful or correctly done but would like to learn the process to contribute to three in the future. ", "commit_messages": " working and stuff  add models ", "linked_issue_titles": "", "title": "gpgpu birds example with gltf loader and meshstandardmaterial"}
{"description": " first commit fix a delete crash when testing ticket 12729, caused by buffer pointer not set to null after delete. second commit fix ticket 12729 by tell libcurl ignore content-length of shoutcast file.: when the shoutcast file was 302 redirected, libcurl may return the content-length of the 302 page's body, it cause next read return 0. ", "commit_messages": " fix crash in cshoutcastfile::close(), clear buffer pointer after delete.  fix ticket 12729, ignore content-length of shoutcast file.  when the shoutcast file was 302 redirected, libcurl may return the  content-length of the 302 page's body, it cause next read return 0. ", "linked_issue_titles": "", "title": "fix redirected shoutcast ticket 12729"}
{"description": " what do these changes do? log a warning if the default object store size exceeds 50% of available memory (it should only really consume 30% if all memory is available). the value 50% is chosen here to include the 20% of memory allowed to redis. raise an error if the default object store size exceeds 90% of available memory. exclude shared memory from the reported mem stats, since it is quite misleading and already reported as object store memory. also, report up to the 10 memory consumers. the error looks something like this: traceback (most recent call last): file \"./train.py\", line 153, in <module> run(args, parser) file \"./train.py\", line 142, in run num_gpus=args.ray_num_gpus) file \"/home/eric/desktop/ray-private/python/ray/worker.py\", line 1387, in init head=true, shutdown_at_exit=false, ray_params=ray_params) file \"/home/eric/desktop/ray-private/python/ray/node.py\", line 150, in __init__ self.start_ray_processes() file \"/home/eric/desktop/ray-private/python/ray/node.py\", line 514, in start_ray_processes self.start_plasma_store() file \"/home/eric/desktop/ray-private/python/ray/node.py\", line 414, in start_plasma_store plasma_store_socket_name=self._plasma_store_socket_name) file \"/home/eric/desktop/ray-private/python/ray/services.py\", line 1455, in start_plasma_store object_store_memory, plasma_directory, huge_pages) file \"/home/eric/desktop/ray-private/python/ray/services.py\", line 1313, in determine_plasma_store_config round(avail_memory / 1e9, 2))) valueerror: the default object store size of 3.68 gb will use more than 90% of the available memory on this node (1.54 gb). please reduce the object store memory size to avoid memory contention with other applications, or shut down the applications using this memory. #4877 linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " exclude  format ", "linked_issue_titles": "", "title": "add warning/error if object store memory exceeds available memory"}
{"description": " this pr implements features that are sufficient to support wordpress-style url rewrites without stepping into the mod_rewrite-hell. for example, with the pr it becomes possible to map /2015/06/15/blogpost/ internally to /index.php/2015/06/15/blogpost/ in case no file was found. the approach is a combination of: the file handler passes the request through to the next handler if it failed to find the file adds internal attribute to redirect handler, so that it could be used for declaring internal redirections with these features, it is possible to support wordpress-like url rewrites by setting the configuration directive like: file.custom-handler: extension: .php fastcgi.spawn: \"php_fcgi_children=10 exec php-cgi\" hosts: \"hostname\": paths: /: file.dir: /www/root/dir   # serve the files, should they exist redirect:                 # if file was not found, retry with /index.php/<path> url: /index.php/ internal: yes status: 307 ", "commit_messages": " [lib/handler/file.c] in case of 404, delegate the request to next handler  [redirect] support internal redirects with internal attribute  introduce confvar: fastcgi.send-delegated-uri; default is off considering the fact that fastcgi apps tend to expect to receive original uri after the request is being rewritten ", "linked_issue_titles": "", "title": "implement features sufficient to support wordpress url rewrites"}
{"description": " this pr deprecates the init(frominputarray:realparts:imaginaryparts:) for dspsplitcomplex and dspdoublesplitcomplex. i've also updated the fft tests to no longer use these deprecated initializers, and to replace the incorrect use of temporary pointers with withunsafemutablebufferpointer. @stephentyrone ", "commit_messages": " update fft tests  i removed singleprecisioncomplexconversions and doubleprecisioncomplexconversions - they weren't testing any new api.  2dsingleprecision, 2ddoubleprecision, 1dsingleprecision, and 1ddoubleprecision have all been updated to no longer use the deprecated initializer and avoid the temporary pointer warnings.  deprecate split complex inits  deprecate init(frominputarray:realparts:imaginaryparts:) for dspsplitcomplex and dspdoublesplitcomplex ", "linked_issue_titles": "", "title": "accelerate deprecate split complex inits"}
{"description": " adds a new tab for windows containers on the run envoy section to illustrate how to use envoy with a windows container. ", "commit_messages": " add windows container tabs on run-envoy  format python  add new line at the end ", "linked_issue_titles": "", "title": "win32 docs for run-envoy.rst section"}
{"description": " show confirm message when deleting the following items. destination(alert) query snippet the following items are already shown. dashboard widget group ", "commit_messages": " confirm delete a query snippet  confirm delete a destination  confirm delete a data source ", "linked_issue_titles": "", "title": "display confirmation dialog when deleting a item"}
{"description": " all the markdown files do not raise any validation policy violation, see policy here. all the markdown files follow these format rules. any references to website have been formatted as text you verified/tested the effectiveness of your contribution (e.g.: defensive code proposed is really an effective remediation? please verify it works!). the ci build of your pr pass, see the build status here. this pr covers issue #147. ", "commit_messages": " chore: update samesite introduction  chore: update samesite attribute value description  chore: update samesite conclusion ", "linked_issue_titles": "", "title": "css-147 update samesite in csrf cs"}
{"description": " fix 2 corner cases in test setup: unsigned_long not support as index sort,do not overlay a runtime field with index sort fixes #72733 relates #72692 note: this builds on top of #72692, therefore setting backport_pending ", "commit_messages": " fix 2 corner cases in test setup: unsigned_long not support as index sort,  do not overlay a runtime field with index sort  fixes #72733  unmute  add reason ", "linked_issue_titles": " [ci] transformcontinuousit testcontinousevents failing ", "title": "fix 2 issues with index sort in integration test"}
{"description": " i wanted something in the docs that i can link to from each tutorial repo. this was a nightmare to write up and to try and come up with a way for some people to contribute. hey @scissorsneedfoodtoo - you're probably the one who knows the most about working on these. want to give this a look and see if you have any ideas on how to have people contribute to these. i want to be able to accept pr's the main branch so people can fix typos and things. that should be pretty straight forward. changing tests is another story. maybe we should just reserve that for staff for the time being, or permanently. either way, it would be nice to have something in the docs. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. ", "commit_messages": " feat(docs): add how to contribute to coderoad tutorials  update json  finish: some docs anyway  more ", "linked_issue_titles": "", "title": "add how to contribute to rdbms repos"}
{"description": " just a pr to fix some of the troubles that i ran into when going from .pipeline(parallelism=15) -> .window(blocks_per_window=15) follow on to #19050 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " mention the actual args  rename pilelining -> windowing?  clarify the docks that this requires kwargs ", "linked_issue_titles": "", "title": "clean up docs around pipelining -> windowing rename"}
{"description": " updated the test_metadata_upgrade test.  to enable using the 2.1 version i needed to add config change to the streamsupgradetestjobrunnerservice to ensure the ductape passes proper args when starting the streamsupgradetest for testing, i ran the test_metadata_upgrade test and all versions now pass ", "commit_messages": " minor: add 2.1 to the metadata_upgrade test  minor: add latest 2.1 to service start cmd to enable proper start args ", "linked_issue_titles": "", "title": "add 2.1 version metadata upgrade"}
{"description": " hide some implementation details of array types. ", "commit_messages": " stdlib: make _arrayprotocol and _arraybufferprotocol internal  stdlib: mark some array buffers implementation details as internal  stdlib: internalize the _uninitializedcount initializer of array buffer  stdlib: mark _arraybuffer, _contiguousarraybuffer, and _slicebuffer internal  stdlib: mark apis on internal types as internal  stdlib: fix the build with resilience enabled  stdlib: mark _arraybuffer apis as internal ", "linked_issue_titles": "", "title": "make array implementation internal, part 2"}
{"description": " explanation: by manually experimenting with apis, we found a few cases of nested variables in xcode 9 change to global variables in xcode 10. since the pattern migrator used to handle is only the opposite direction, we need to update the swift-api-digester and the migrator to detect and handle this category of changes. scope of issue: swift 4.2 migrator risk: very low reviewed by: nathan hawes testing: unit tests added. radar: rdar://41658300 ", "commit_messages": " swift-api-digester: teach the tool to detect member variables change to global ones. rdar://41658300  migrator: support the migration from member variables to global ones. rdar://41658300  migrator: ensure we update unresolved member access correctly to global names. rdar://41658300 ", "linked_issue_titles": "", "title": "handle member variables change to global ones. rdar://41658300"}
{"description": " importing files from \"the same directory as this file\" was implicitly supported in python2.7 but not python3.  the syntax here works for both. ", "commit_messages": " rework a couple of benchmarks to work with both python2 and python3  adjust relative import statements to use relative syntax  importing files from \"the same directory as this file\" was  implicitly supported in python2.7 but not python3.  the  syntax here works for both. ", "linked_issue_titles": "", "title": "adjust relative import statements to use relative syntax so they work with py2 and py3"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. ", "commit_messages": " i18n italian compliements  first 10 motivational quotes for italian ", "linked_issue_titles": "", "title": "adding first few motivational quotes and compliments in italian"}
{"description": " checks that it can open as read rather than read/write; this will fix the eperm and ebusy errors on read. makes the error better for eperm and ebusy errors when they do happen on save closes #5102 closes #5107 closes #5112 closes #3231 ", "commit_messages": " only check read permission on read  add a better message for eperm errors.  explicitly check if the path to be deserialized is a dir ", "linked_issue_titles": " saving read-only file causes dev tools to open  uncaught error: eperm, operation not permitted when opening a readonly file  atom can no longer open readonly files  uncaught error: ebusy, resource busy or locked 'c:\\code\\ta.mobile\\source\\tamobile6simulator\\bin\\debug\\trackabout.mobile.log' ", "title": "allow opening of readonly files"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixed error when replication connection pool doesn't retry to resolve host, even when dns cache was dropped. ", "commit_messages": " add case for host ip change  fix bug with pooled http sessions and host ip change ", "linked_issue_titles": "", "title": "fix bug in pooled sessions and host ip change"}
{"description": " when performing an in-memory rebase, we should be able to rebase a branch with no common ancestors (that is, the first commit to rebase has no parents). / ", "commit_messages": " rebase: test rebase (merge) w/ no common ancestor  rebase: handle no common ancestor for inmemory ", "linked_issue_titles": "", "title": "rebase a branch with no merge base for in-memory"}
{"description": " this adds: a way to make the compiler ice a way to check for ice in cfail tests with should-ice a regression test for issue #65401 i am not sure the attribute added should-ice is the best for this job ", "commit_messages": " add header to compiletest to check for ice  add rustc_error(delay_span_bug_from_inside_query) attribute  remove another status code check is should-ice  added test for checking that ices are not hidden ", "linked_issue_titles": "", "title": "making ices and test them in incremental"}
{"description": " the initcascades function must be called whenever fov, near, far, or aspect fields are changed on a camera so it can be a hot function especially when resizing a window or animating a transition between camera types. i've modified it here to reuse frustum instances rather than create new ones whenever it's called to save on object allocation. i'll be doing the same thing for .update next. temporary live link:  @vhawk edit: looks like the failure is a diff issue from css3d_youtube: error! diff wrong in 0.079 of pixels in file: css3d_youtube ", "commit_messages": " clone vertices  pre-init vectors  use cached vectors  avoid making new frustums ", "linked_issue_titles": "", "title": "use cache objects in initcascades"}
{"description": " uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design this pr adds annotations to the imagespec object in cri api. the expectation is that for windows in order to use non-default runtime classes pods would specify a kubernetse.io/runtimehandler annotation. this would get passed to the cri and used during various image pull and sandbox creation operations. this behavior would be optional and would need to be implemented for each cri independently. usage and more information can be found here:  does this pr introduce a user-facing change?: add annotations to cri-api imagespec objects. kep: ", "commit_messages": " cri - adding annotations to imagespec and imagespec to image  cri - updating fake_image_server.go to support annotations in imagespec ", "linked_issue_titles": "", "title": "add annotations to cri imagespec objects"}
{"description": " 8ab0d65 ", "commit_messages": " don't retrieve config in running_config when config is provided for diff (#41400)  * don't retrieve config in running_config when config is provided for diff  * fix for eos, nxos  * add integration test  (cherry picked from commit 8ab0d654f3eb44c715af8d8701eb3246d2abf419)  add changelog ", "linked_issue_titles": "", "title": "don't retrieve config in running_config when config is provided for diff stable 2.5"}
{"description": " while awesome, the initial type definition was made based on reverse engineering and improper documentation. this inevitably led to a few mistakes and an incomplete definition. documentation is now available, new package version has been published. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " rox-react-native: minor improvements, update documentation links  rox-react-native: remove internal, undocumented, removed in next release method  rox-react-native: upgrade package version, fix freeze options (they were plain wrong)  rox-react-native: fix return type, add readonly attributes  rox-react-native: adding a few missing items  rox-react-native: default value of a flag is optional  rox-react-native: more extensive tests  rox-react-native: make fetcher result an enum ", "linked_issue_titles": "", "title": "fixes, improvements and update to rox-react-native"}
{"description": " rename container_option to container, make runtime options have the same code style. rename image name from ray-nest-container to ray-worker-container,  because it can be used in other scenarios, not only in nest container. #16671 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " rename container_option to container  rename ray-nest-container to ray-worker-container ", "linked_issue_titles": "", "title": "rename container option and ray-nest-container"}
{"description": " others others task node from python side class use these codes to test mp_dp_sharding: from paddle.distributed.fleet.fleet_executor_utils import tasknode task_node = tasknode( program=main_program.clone(), cur_rank=0, max_run_times=1, max_slot_times=1) main_program._pipeline_opt = {} main_program._pipeline_opt['fleet_opt'] = { 'section_program': main_program, 'tasks': [task_node], 'task_id_to_rank': {task_node.task_id(): fleet.worker_index()} } main_program._pipeline_opt['section_program'] = main_program ", "commit_messages": " python side task node class  reformat  add ut  add annotation  fix typo  rename  remove useless store  bug fix for some assertions  delay the init of task node  bug fix  clone for task node  update task node  create op for set_program  typo fix  use pointer  bug fix and add annotataions  add log ", "linked_issue_titles": "", "title": "python side fleet executor and task node"}
{"description": " what's in this pull request? move the core indexing functionality (the indexswiftastwalker) out of sourcekit and into a new index library in swift.  this makes the sourcekit-specific code lighter, leaving only the serialization issues like constructing uidents behind in swiftindexing.cpp.  mostly this was about pulling the sourcekit::uidents out of the indexdataconsumer interface, and using enums to classify the symbols instead. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " [index] factor out the dependency between the core indexing walker and sourcekit  the goal is to be able to move the core indexswiftastwalker code out of  sourcekit, leaving only the serialization bits behind.  mostly this replaces some direct uses of uident strings with explicit  enums, and then adds the translation code to produce those enums and to  convert them into uidents in sourcekit.  rdar://problem/22348041  [index] move core indexing code out of sourcekit  leaving only the sourcekit-specific code (e.g. uid generation) behind in  sourcekit.  rdar://problem/22348041  [index] move associated type into common macro nfc  now that we have first-class associated types it works the same as the  other simple cases. ", "linked_issue_titles": "", "title": "move indexswiftastwalker out of sourcekit"}
{"description": " if axios is used with multiple domains, the auth_token will be sent to all of them when using the example code: axios.defaults.headers.common['authorization'] = auth_token this pr adds a comment above the example to that effect and points below for an example using custom instance defaults instead. the pr also adds an example setting user-agent, which is another common case for setting axios.defaults.headers.common. this is a continuation of #3471 which was previously closed. ", "commit_messages": " updating the 'global axios defaults' readme to use a safer example  the existing example usage it isn't safe in the general case as it can  lead to auth tokens being leaked to 3rd party endpoints by unexpectedly.  this change instead gives an example using  \"axios.defaults.headers.common\" to set the user-agent, which is an  equally helpful use-case to document.  the 'custom instance defaults' example just below the 'global axios  defaults' example shows a method to set the 'authorization' header  specific to a given api. i've also updated the variable in the 'custom  instance defaults' code to use a semantically more relevant name within  that example.  revert the example instance name in response to pr request  reintroduce the authorization example with a disclaimer about its usage ", "linked_issue_titles": "", "title": "default headers example auth_token comment"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fix bug with incorrect skip indices serialization and aggregation with adaptive granularity. this fixes #6594. ", "commit_messages": " fix bad size of marks  fix comment ", "linked_issue_titles": " bad size of marks file (versions 19.13.1.11 and 19.13.2) ", "title": "fix bad size of marks with skip indices"}
{"description": " this issue wasn't apparent while using the default system theme, but it was while using nord. these changes make the applet manager use the same color role as the one used by taskbar. i also made the clipboardhistory and network applets use the alpha channel as the icons were being filled with an incorrect background color as well. ", "commit_messages": " windowserver: make applet area use the same color role as the taskbar  so far the taskbar has been using the \"button\" as a color role, despite  rest of the applet area using \"window\" color role. although it all  looked alright on most system themes, it broke for the nord theme.  clipboardhistory: make the applet use an alpha channel  network: make the applet use an alpha channel ", "linked_issue_titles": "", "title": "improve the background color consistency of the applets area"}
{"description": " there are certain widget which only need localizations in combination with a certain parameter or as a default value. in this case, there might be valid code that would break if this check were added. while i defaulted to always adding the debug check to the beginning of build - we should probably discuss the best way to do this. fixes #20406 ", "commit_messages": " add assert(debugcheckhasmateriallocalizations(context));  update tests to work with debugcheck ", "linked_issue_titles": " we should assert that localizations are present ", "title": "add debug check for localization parent"}
{"description": " this pr improves the interfaces for the functions encodebase58{check} by using spans, in a similar fashion to e.g. prs #19660, #19687. note that on the master branch there are currently two versions of encodebase58: one that takes two pointers (marking begin and end) and another one that takes a std::vector<unsigned char> const-ref. the pr branch only leaves one generic span-interface, both simplifying the interface and allowing more generic containers to be passed. the same is done for encodebase58check, where only one interface existed but it's more generic now (e.g. a std::array can be directly passed, as done in the benchmarks). ", "commit_messages": " util: make encodebase58 consume spans  util: make encodebase58check consume spans ", "linked_issue_titles": "", "title": "make encodebase58{check} consume spans"}
{"description": " fixes #1236 so that netdata can collect values from snmp string oids fixes #1155, python.d.plugin did not exit when netdata exited. now it does. ", "commit_messages": " collect values from snmp string oids; fixes #1236  python.d.plugin should exit if it cannot send data to netdata; fixes #1155  really exit on fatal situations, even if no output is possible; fixes #1155 ", "linked_issue_titles": " netdata doesn't restart mysql connection when mysql-server is restarted  snmp, wrong values. ", "title": "snmp with string oids; python.d.plugin now exits properly"}
{"description": " for #10970. i do not know if i misunderstood the requirement, but the first five tests required, as stated in the issue 10970, are already in the master branch. hence, i only wrote tests for the last three classes. -authorityrulebuilder -defaultauthorityruleconfigurationbuilder -authorityruleconfigurationyamlswapper ", "commit_messages": " add files via upload  add files via upload  add files via upload  update authorityruleconfigurationyamlswappertest.java  rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/authorityruleconfigurationyamlswappertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/yaml/swapper/authorityruleconfigurationyamlswappertest.java  rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/defaultauthorityruleconfigurationbuildertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/builder/defaultauthorityruleconfigurationbuildertest.java  update and rename shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/authorityrulebuildertest.java to shardingsphere-kernel/shardingsphere-authority/shardingsphere-authority-core/src/test/java/org/apache/shardingsphere/authority/rule/builder/authorityrulebuildertest.java ", "linked_issue_titles": "", "title": "add unit test for shardingsphere-infra-authority (issue #10970)"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  turns out there were more methods and properties needed. ", "commit_messages": " add unload method to webtwainenv  add containers property to webtwainenv  define arguments for registerevent callback function ", "linked_issue_titles": "", "title": "add methods and properties to webtwainenv"}
{"description": " since #2086 was well received, i thought i'd start us out. please review (in case my understanding of any changes was incorrect). and then of course we'll need to add whatever has changed regarding model#change, silent, etc. -- but that i'm less sure about. ", "commit_messages": " updating contributing to reflect keeping index.html up to date with master  removing view#make from docs  updating model#validate docs ", "linked_issue_titles": "", "title": "edge change log in documentation"}
{"description": " problem: u2f-api is being deprecated in chrome for feb 2022, so webauthn is needed for registration and verification of u2f devices. overall changes: refactored u2finterface to support newly created publickeycredentialrequestoptions thats being generated in the backend to support all devices whether it was registered with u2f-api or webauthn. in addition, fixed u2f device page to support new device interface structure and support deleting newly registered u2f devices ", "commit_messages": " authentication with u2f and webauthn devices fully working  device page, remove device and duplicate device detection working  added webauthn_authentication_server to init fn  removed comments  fixed be test  fixed tests once again  removed fe to split pr ", "linked_issue_titles": "", "title": "support authentication with webauthn registered u2f devices - be"}
{"description": " updates to the script that generates tfrecords from the gldv2 dataset for delf training: capability to filter on the clean training dataset. generation of train and validation splits. converting to tfrecord the train clean and test datasets without train and validation splits generation. converting to tfrecord the train clean and test datasets with train and validation splits generation. ", "commit_messages": " first version of working script to download the gldv2 dataset  first version of the defl package installation script  first working version of the delf package installation script  fixed feedback from pr review  push to github of changes to the tfrecord data generation script for delf. ", "linked_issue_titles": " [help wanted] delf (deep local features) ", "title": "push to github of changes to the tfrecord generation of gldv2 dataset"}
{"description": " adds glfw_focus_on_show window hint and attribute for issue #1189. this is a platform independent change which preserves behaviour for all applications written to the glfw api. i believe i have implemented all requirements as per \"contributing a feature\" guidelines. if changes are needed i'm happy to do them. i can also clean the commit timeline if needed. ", "commit_messages": " add glfw_focus_on_show window hint and attribute for issue #1189  fixed tab -> space  fixed tab -> space in windows test.  added glfw_focus_on_show as a supported attributed for glfwsetwindowattrib  updated documentation for glfw_focus_on_show  updated readme and news for glfw_focus_on_show ", "linked_issue_titles": "", "title": "focus on show pr for #1189"}
{"description": " also add tests verifying these methods don't throw errors when called on unmounted components improves coverage by covering some branches that were missing! ", "commit_messages": " ignore defer definition in coverage  warn if forceupdate is called in constructor  add tests verifying setstate and forceupdate don't error when called on an unmounted component  warn if setstate or forceupdate are called on an unmounted component ", "linked_issue_titles": "", "title": "add debug warnings when calling setstate or forceupdate on an unmounted component"}
{"description": " text apis: interface name change passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change interface revision, tests, (and when applicable, api doc) can we move it to mxnet.text asap? ", "commit_messages": " revise text api names  update ", "linked_issue_titles": "", "title": "interface re-design with name changes"}
{"description": " these are only updated for easeljs and tweenjs which is part of the createjs suite. the soundjs and preloadjs definitions have not been updated (primarily because i don't use them). i could hold off on the pull request until they are done, but given my schedule i don't know when that will be, so i thought it would be a good idea to at least push these updates. tests were passing when run locally. ", "commit_messages": " updated easeljs definitions to v0.7 and tweenjs definitions to v0.5  added comment on sprite to avoid intellij thinking it was deprecated  merge remote-tracking branch 'upstream/master'  fixed missing return type ", "linked_issue_titles": "", "title": "upgrade easeljs definitions to 0.7 and tweenjs to 0.5"}
{"description": " systemctl show is built to be easily parsed by machine. systemctl status is built for human consumption only. use the show command from get_status_dict() when systemd is in use. closes #6341. ", "commit_messages": " #6341: check systemd service status with show subcommand  #6341: use shared function for parsing systemd status; check rc code ", "linked_issue_titles": " systemd service backend can fail to detect services not running ", "title": "use ''show'', not ''status'', for systemd service state"}
{"description": " support int64 (large tensor) for remaining random ops below 8 are supported random.exponential random.gamma random.generalized_negative_binomial random.multinomial random.negative_binomial random.normal random.poisson random.randn please feel free to remove inapplicable items for your pr. all changes have test coverage: code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change added 1 test case each currently nosetests tests/nightly/test_large_array.py results in 42 tests pass (4 fail - unrelated test ops- topk,sort,argsort,reduce) ", "commit_messages": " random ops  replace array with uniform  remove dtype ", "linked_issue_titles": "", "title": "large tensor support for random ops"}
{"description": " reducing global usage and refactoring injection in the build system was challenging due to the number of mocks i have created. reduce this by switching to the fakeprocessmanager and reduce the scope of these tests to be unit tests only. also fixes catcherror in frontend_server spawning that caught too much (including a matcher exception) ", "commit_messages": " [flutter_tools] remove mocks from dart_test file  [flutter_tools] removing mocking for dart target integration testing ", "linked_issue_titles": "", "title": "remove mocking and simplify dart target tests"}
{"description": " clean up a couple of members in csapply by passing the selectedoverload instead of individual parameters for things like the function ref kind, choice, and opened type. ", "commit_messages": " [cs] stop passing functionrefkind in a couple of places  we can retrieve it from the passed overloadchoice.  [cs] change openedtype -> openedfulltype in a couple of cases  this helps avoid confusion with selectedoverload's  openedtype member. ", "linked_issue_titles": "", "title": "pass selectedoverload in a couple of places"}
{"description": " in underscore 1.1.4, a test case below will fail: var o = function(str) { return str; }; var fasto = _.memoize(o); equals(o('tostring'), 'tostring', 'checks hasownproperty'); equals(fasto('tostring'), 'tostring', 'checks hasownproperty'); i have fix the bug by changing code \"key in memo\" to \"hasownproperty.call(memo, key)\". hope to merge^o^ ", "commit_messages": " remove unused code and avoid variable redeclaration  bug fix for _.memoize when key is derived from prototype ", "linked_issue_titles": "", "title": "bug fix for _.memoize and other little code change"}
{"description": " currently, the tests for both dropdownbutton and dropdownbuttonformfield are in the same file. this has led to confusing ordering of test cases (ie. dropdownbuttonformfield test sandwiched between two dropdownbutton tests), making it difficult to determine if a test had already been written. this pr separates the tests into two files (dropdown_test.dart and dropdown_form_field_test.dart), renames some of the tests, and formats some of the code. there are no functional changes in this pr. related issues fixes #42483 i added the following tests: n/a before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " separate dropdownbuttonformfield and dropdownbutton test files  dropdownformfield -> dropdownbuttonformfield ", "linked_issue_titles": " separate dropdownbuttonformfield tests from dropdown_test.dart ", "title": "separate dropdownbutton and dropdownbuttonformfield tests"}
{"description": " add missing bits of documentation and reformat to break long lines and use proper sphinx markers. ", "commit_messages": " doc: fixes for doc/source/user/basics.io.genfromtxt.rst.  add missing part of usecols negative index explanation and other  minor redaction fixes.  maint: cleanup doc/source/user/basics.io.genfromtxt.rst.  remove trailing whitespace.  break long lines.  fix some indentation.  use the :: directive to indicate interactive examples. ", "linked_issue_titles": "", "title": "documentation fixes for basics.io.genfromtxt.rst and creation.py"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: < ", "commit_messages": " add type definitions for eins-modal  added possible .modal() method to htmlelement ", "linked_issue_titles": "", "title": "add .modal() function to eins-modal"}
{"description": " pretty self-explanatory. the implementation is straight-forward for regular environments, since it only adds logic that is not used in the built-in environments by default. a slightly tricky thing is in vector environments, where kwargs get passed both into reset_async and reset_wait, because the two different classes process them differently. as with any \"big\" change, this definitely needs some more eyes on it. this closes #2399 (at least to the extent that was agreed in the meantime), and subsumes #2511 for simplicity (easier to just include it here than deal with merge conflicts, or wait for synchronization between merges) ", "commit_messages": " first find/replace, now tests  fixes to the vector env  make seed keyword only in wrappers ", "linked_issue_titles": " [proposal] custom arguments in step and reset methods ", "title": "add options to the signature of env.reset"}
{"description": " uncomment only one  /kind <> line, hit enter to put that in a new line, and remove leading whitespace from that line: /kind design /sig cloud-provider /area provider/azure /priority important-soon continue of kubernetes-sigs/cloud-provider-azure#247. this pr adds a new clientconfig and backoff retry for azure cloud provider: add a new clientconfig so that new azure clients could import it without unnecessary dependencies add backoff retry and implements autorest.senddecorator interface. the new backoff retry would be used in the following azure arm clients switch to new clientconfig in azure cloud provider so that the changes won't break existing codes part of kubernetes-sigs/cloud-provider-azure#247 does this pr introduce a user-facing change?: /assign @andyzhangx ", "commit_messages": " move client config to a separate package  add backoff retry which implements autorest.senddecorator interface ", "linked_issue_titles": "", "title": "add backoff retries and client config for azure cloud provider"}
{"description": " i understand that: i'm submitting this pr for reference only. it shows an example of what i'd like to see changed but i understand that it will not be merged and i will not be listed as a contributor on this project. ", "commit_messages": " replacing text on top banner  changing modal cta to get started  adding start modal as alternative and changing cta  -changed cta to be more about the switch from 4.7 to the latest 5.8.1, rather than selling pro directly  adding back original download modal  updating copy  adding period ", "linked_issue_titles": "", "title": "new banner and home cta"}
{"description": " minor fixes related to my changes to the keyboard handling: capslock had the wrong vkey value (xbmc was seeing it as space) rogue oring with ckey::modifier_ralt meant the right alt wouldn't work as a modifier added a keyboard.xml entry to make backslash work on a french keyboard tidy up keyboard.xml to group the multimedia keys together and add mappings for all multimedia keys, some with null values to act as placeholders. i don't think any of this is controversial, but i thought i'd better give the team a chance to vet them. ", "commit_messages": " vkey for capslock should be 0x14 not 0x20  the keyboard.xml mod attribute doesn't distinguish between left and right alt  on a french keyboard backslash is alt gr 8. xbmc sees this as ctrl-alt-backslash.  tidy up multimedia key mappings. add null mappings for unused multimedia keys as placeholders. ", "linked_issue_titles": "", "title": "minor keyboard related tweaks and fixes"}
{"description": " after recent commits both aclk implementations can be compiled in the agent. adds info into the docs on how to choose which one to use and how to verify which one is used component name docs read the docs and see if the info is understandable for our users. ", "commit_messages": " add info for dual aclk into readme  add info how to check ", "linked_issue_titles": "", "title": "updates the docu with info about dual aclk"}
{"description": " fixes #6827 before fix struct of struct pf d? a (foo)y cannot find format for struct foo cannot find format for struct foo undefned struct 'foo'. a : 0x00000000  = 0 y : array of struct pf d? a (foo)y // was same as struct of struct after fix pf d[2]? x (foo)y x : 0x00000000 = 0 y : struct<foo> a : 0x00000004 = 0 b : 0x00000008 = 0 struct<foo> a : 0x0000000c = 0 b : 0x00000010 = 0 added tests in r2r #1315 too . ", "commit_messages": " refactor and move anal/types.c to util/  make struct of struct work with .ts and fix ts*  array of struct works now with ts ", "linked_issue_titles": " types: array of structs not working ", "title": "refactor types and make array of struct work with ts"}
{"description": " frontenders at airbnb at have been discussing this change for a bit, and we've come to favor one-var-per-variable over one-var-only declarations. two things improve the maintainability of this style over one var for multiple variables: you never have a diff of a line that's removing a ; and inserting a ,. you can't accidentally declare global variables because you have a one-character mistake (semicolon instead of comma): var foo = 1, bar = 2; baz = 3; // added later and (accidentally) declared globally also, make a docstring comment example jsdoc/googleclosurecompiler compatible ", "commit_messages": " switch from single var to one-var-per-variable  frontenders at airbnb at have been discussing this change for a bit, and  we've come to favor one-var-per-variable over one-var-only declarations.  two things improve the maintainability of this style over one var for  multiple variables:  1. you never have a diff of a line that's removing a ; and inserting  a ,.  2. you can't accidentally declare global variables because you have a  one-character mistake (semicolon instead of comma):  javascript  var foo = 1,  bar = 2;  baz = 3; // added later and (accidentally) declared globally    use jsdoc/closure compiler style type annotations ", "linked_issue_titles": "", "title": "switch to one-variable-per-var from many-variables-per-var"}
{"description": " fixes #53974 ", "commit_messages": " move terminalprocess to run in renderer process  part of #53974  don't build terminalprocess module  tidy up terminalprocess  fix most of process proxy ", "linked_issue_titles": " test if we can pull terminalprocess into the renderer process ", "title": "move terminalprocess into the renderer process"}
{"description": " there's a bug in the way we determine the selected package in plugins page. it was just checking if the selected package's name is part of the pathname. so if you select gatsby-source-shopify2 or gatsby-source-shopify-storefront, gatsby-source-shopify will also be highlighted (screenshot below) before this pr fixes this issue. this also works with scoped packages. after closes #10951 ", "commit_messages": " use regexp to determine selected package  update regex ", "linked_issue_titles": " plugin library shows two plugins selected ", "title": "fix plugin search result selected style"}
{"description": " this pr improves our handling of excessively large control flow graphs: if control flow analysis leads to a stack depth of 2500 recursive calls, we now issue an error and disable control flow analysis for the remainder of the containing function or module body. previously we'd simply overflow the call stack. the 2500 recursive call limit was experimentally determined. control flow patterns that cause recursion in the control flow analyzer (such as #11432) overflow the stack somewhere between 2500 and 5000 calls. no rwc tests are affected by this change. fixes #14314 in the sense that it doesn't overflow the stack. however, #14314 still takes >80s to compile. ", "commit_messages": " disable control flow analysis in excessively large statement blocks  add test ", "linked_issue_titles": "", "title": "error on excessively large control flow graphs"}
{"description": " python based scrapers for movies and tv shows (using tmdb as the source). the xml based scrapers are only sort of supported, and there is a desire to move to python scrapers as default for matrix so we can remove the xml scrapers in version 20. the movie scraper has been in use for over a year and tested by members of the team and community. the tv show scraper is newer but based on code from the movie scraper and the tv maze scraper. it has been tested by team members on multiple platforms and community members from the forum. bug fix (non-breaking change which fixes an issue) clean up (non-breaking change which removes non-working, unmaintained functionality) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that will cause existing functionality to change) cosmetic change (non-breaking change that doesn't touch code) none of the above (please explain below) my code follows the code guidelines of this project i have read the contributing document documentation for both scrapers already exists, so i don't think any additional documentation is needed. ", "commit_messages": " add python tmdb movie scraper  add python tmdb tv show scraper  update addon installdata  set python scrapers as default on new install ", "linked_issue_titles": "", "title": "python3 based movie and tv show scrapers"}
{"description": " implements wait and retry logic on ray.connect() this takes care of the case where the server is not yet ready, but does not yet cover the case where the server drops mid-connection (still to come). first half of #13353 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " [ray_client]: wait until connection ready  change-id: ie443be60c33ab7d6da406b3dcaa57fbb7ba57dd6  lint  change-id: i30f8e870bbd5f8859a9f11ae244e210f077cedd0 ", "linked_issue_titles": "", "title": "wait for ready and retry on ray.connect()"}
{"description": " add dilate option for convolution / deconvolution, used for semantic segmentation. detail could be found in the following paper and their code. semantic image segmentation with deep convolutional nets and fully connected crfs. liang-chieh chen, george papandreou, iasonas kokkinos, kevin murphy, and alan l. yuille iclr 2015 ", "commit_messages": " add dilate for convolution  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "add dilate option for convolution for semantic segmentation"}
{"description": " fix #8694 ", "commit_messages": " test cpu float16 data transform  add isnan etc  small fix  fix containsnan test error  add data_type transform gpu test  add float16 gpu example  fix error  fix gpu test error  initial commit  fix error  small fix  add more gemm fp16 tests  fix error ", "linked_issue_titles": " add fp16 gemm support on gpu ", "title": "add float16 gemm math function on gpu"}
{"description": " restorev2() did not work because wildcard match had some issues. enabled rtti for windows as well. ", "commit_messages": " if saver.restore(v2) for windows, directory walk did not work correctly  rtti ifdef did disable rtti for windows  with that we find now the files during restore.  need to check for true (=1) instead of s_ok(=0)   ", "linked_issue_titles": "", "title": "make restorev2() work for windows"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see ", "commit_messages": " add support for checksum  fix merge conflict ", "linked_issue_titles": "", "title": "add encoding support to object key"}
{"description": " pr allows custom securitycontext for stable/redmine. this pr does not change current behavior. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " option to customize securitycontext  new line ", "linked_issue_titles": "", "title": "option to customize security context"}
{"description": " there were still some mentions of ~[t] and ~t, mostly in comments and debugging statements. i tried to do my best to preserve meaning, but i might have gotten some wrong-- i'm happy to fix anything :) ", "commit_messages": " update old uses of ~ in comments and debugging statements  update debuginfo metadata to use box instead of ~  also remove comments that reference the unique_type_id heap_vec_box  metadata, which was removed in 3e62637 and the unique_type_id gc_box  metadata, which was removed in 8a91d33.  update tests to not use old ~ syntax ", "linked_issue_titles": "", "title": "remove mentions of the old tilde owned pointer syntax"}
{"description": " looks something like this: ", "commit_messages": " bring back bg. tighten things up.  clean up group detail alerts  soften hard edges  group sidebar pass  bring back old filter nav  play with level indicator  darken bg  shrink subheader  consistent group headers  fix error labels in release streams  collapse 30px margins  clean up event list container ", "linked_issue_titles": "", "title": "add background color and text-based level labels"}
{"description": " quick example of the issue: interface someinterface { optional?: string; const obj: someinterface = getsomeinterface(); const value = _.get(obj, 'optional', 'defaultvalue'); // ^ value should be of type string since we provided a default value, but it is string | undefined this pr updates lodash.get to exclude undefined when a default value is provided. to use exclude, we had to update typescript version to 2.8.  the file with the relevant change is types/lodash/common/object.d.ts add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update to version 2.8 and fix _.get  fix typescript version header  revert some changes made during find/replace  one more change that wasn't supposed to be added. ", "linked_issue_titles": "", "title": "fix lodash.get to exclude undefined if a default value is provided"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: solid/solid-auth-client@v2.3.1...v2.4.0 (and specifically this pr) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " update api for 2.4 release  specifically, it added the stoptracksession() method.  reflect that tracksession technically is async  it's typically only used for the callback, but it _is_ an async  function:   ", "linked_issue_titles": "", "title": "update solid-auth-client api for 2.4 release"}
{"description": " the default kernel launch method doesn't use the dynamic openmp scheduling primitive, which suffers from workload balance problem when doing sparse matrix multiplication. this pr add launchdynamic method to the original kernel class. @zheng-da please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " dynamic omp for dot  update heuristic  add doc ", "linked_issue_titles": "", "title": "use dynamic omp schedule for sparse dot with large matrix"}
{"description": " adds the option to allow hystrixruntimeexception to be thrown by hystrixcommandaspect. the new property raisehystrixexceptions is supported by both defaultproperties and hystrixcommand. e.g. @defaultproperties( ignoreexceptions = badrequestexception.class, raisehystrixexceptions = {hystrixexception.runtime_exception}) this pattern is extensible should people wish to add support for other hystrix exceptions. pr requested by @dmgcodevil ", "commit_messages": " adding option to raise hystrixruntimeexception instead of cause  adding raisehystrixexceptions to defaultproperties  removing change to basicdefaultignoreexceptionstest ", "linked_issue_titles": "", "title": "add option to raise hystrixruntimeexception"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. @karol-majewski @plantain-00 @rbuckton ", "commit_messages": " update index.d.ts  support es6.  update memoize-one-tests.ts ", "linked_issue_titles": "", "title": "support es6 import for typescript definition"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> changelog:  the ignoreownvisits option was added in a version < 5.0 but was not added to the types. then removed in 5.0.0 but added again in 5.0.1. use-ackee types of use-ackee uses the exported type serverdetails that got changed to string in v5 of ackee-tracker so i changed the types there as v2 now uses ackee-tracker v5 but didn't changed the api. ", "commit_messages": " update ackee-tracker to v5  update tests ", "linked_issue_titles": "", "title": "update ackee-tracker to v5 and use-ackee to v2"}
{"description": " this is a rebase of #6494, with one line (which @sdaftuar commented he forgot to remove) deleted. it also adds a commit to add the change to the bips document and the release notes. ", "commit_messages": " allow block announcements with headers  this replaces using inv messages to announce new blocks, when a peer requests  (via the new \"sendheaders\" message) that blocks be announced with headers  instead of inv's.  since headers-first was introduced, peers send getheaders messages in response  to an inv, which requires generating a block locator that is large compared to  the size of the header being requested, and requires an extra round-trip before  a reorg can be relayed.  save time by tracking headers that a peer is likely to  know about, and send a headers chain that would connect to a peer's known  headers, unless the chain would be too big, in which case we revert to sending  an inv instead.  based off of @sipa's commit to announce all blocks in a reorg via inv,  which has been squashed into this commit.  rebased-by: pieter wuille  documentation updates for bip 130 ", "linked_issue_titles": "", "title": "direct headers announcement (rebase of #6494)"}
{"description": " 1.1-intro-to-programming-languages 1.2-github-basics 1.3-accessibility 2.1-data-types 2.2-functions-methods 2.3-making-decisions 2.4-arrays-loops ", "commit_messages": " migrate 1.1-intro-to-programming-languages id quiz  migrate 1.2-github-basics id quiz  migrate 1.3-accessibility id quiz  migrate 2.1-data-types id quiz to quiz-app  migrate 2.2-functions-methods id quiz to quiz-app ", "linked_issue_titles": "", "title": "migrate existing quizzes indonesian translations to quizz-app"}
{"description": " this pr removes the outdated herramientas de desarrollo section from contributing_es.md along with the following images, which aren't referenced anywhere anymore: docs/docs/images/open-remote-dev-tools.png docs/docs/images/remote-dev-settings.png docs/docs/images/running-redux-devtools.png closes: #7697 ", "commit_messages": " translation: remove section herramientas de desarrollo  refs:  refs:  images: remove open-remote-dev-tools  refs:  images: remove remote-dev-settings.png  refs:  images: remove running-redux-devtools.png  refs: ", "linked_issue_titles": "", "title": "remove outdated section from contributing_es.md"}
{"description": " this is just @gazpachoking's pr #1729 in a mergable state and with the pr feedback that @lukasa left on it. ", "commit_messages": " add a test case for request cookies persisting to session. refs #1728  store the request cookiejar in preparedrequest.cookies fix #1728  conflicts:  requests/sessions.py  address feedback from #1729  - make the preparedrequest's cookie jar an implementation detail ", "linked_issue_titles": "", "title": "fix 1728 (fixed up from #1729)"}
{"description": " this pr has a variety of cleanup changes and fixes to help demonstrate advanced features of ios development like memory mapping and loading retrained models. it also includes some related changes that help shrink the binary footprint of the final executable on ios. ", "commit_messages": " work in progress on memory-mapping example for ios  reduce the size of ios binary, demonstrate mmap support  fixed merge problems, cleaned up ios camera example ", "linked_issue_titles": "", "title": "improved ios camera example and binary footprint optimizations"}
{"description": " this fixes some login and grammatical errors in serbian locales (sr, sr-cyrl) and their tests. two major problems were logic for getting grammatical cases. it was flawed because it didn't consider special cases for multi-digit numbers, just for single digit special cases. along with this, some grammar fixes were made because of different writing of nouns in different tenses (past and future) alongside those without tense (without prefix). here is some info about that on wiki. if that's not enough, i'll try to find something that has specific rules about that but i think it's better that other locale contributors look over this. the tests are adapted to check for new grammar and logic fixes. ", "commit_messages": " fix serbian grammar and grammatical case logic  this fixes the grammatical case logic which overlooked some special  cases in serbain language. also this fixes some grammatical errors  concerning cases in serbian language.  update tests for serbian fix  this updates the tests so they will test the new grammar. ", "linked_issue_titles": "", "title": "fix serbian locale (sr, sr-cyrl)"}
{"description": " this pull-request #539 should be taken into account to  understand the context about the debate of readonly properties in the scikit-learn api. this pull request is also related to issue #470 logisticregression and linearsvc should have read-write coef_ and intercept_ attributes (it does not fix it but makes it a less dangerous behavior). the following is an example session were the unsuspecting user might overlook a bug: >>> from sklearn.svm import svc >>> from sklearn.datasets import load_iris >>> iris = load_iris() >>> clf = svc(kernel='linear').fit(iris.data, iris.target) >>> clf.coef_ array([[-1.0443518 ,  0.01195155, -1.91966087, -0.81040704], >>> clf.coef_[0, 3] = 0 >>> clf.coef_ array([[-1.0443518 ,  0.01195155, -1.91966087, -0.81040704], ", "commit_messages": " enh: mark coef_ as immutable for linear svm models trained in the dual  immutable coef for the sparse svm variant too  mark liblinear coef as immutable too ", "linked_issue_titles": "", "title": "explicitly mark the array returned by the linear svm readonly property coef_ as immutable"}
{"description": " description:  this config seems let coveralls.io reports stable results: above screenshot has 3 build results with exactly same source code, the top and bottom has only one job in each build, but the middle one has multiple jobs, only one job reports code coverage. so you will see coveralls.io still gave us false negative result.   related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " create one tox env for code coverage report  pytest-cov generated report in project root folder, not tox env folder.  add cov tox env to travis  coveralls seems expecting all build jobs upload  only upload coverage after cov env success ", "linked_issue_titles": "", "title": "try to fix coveralls unstable result"}
{"description": " this pr mainly contains two pars: add a common interface pyperfsampleprocessor that can be passed to pyperfutil to handle samples from the profiling. this way, users could use customized logic to log / aggregate / output the result samples. abstract current printing logic to a specific pyperfdefaultprinter that is used by the default cli main, and add parsing for enum values. ", "commit_messages": " add common interface for pyperf sample handling  better printing for enum values ", "linked_issue_titles": "", "title": "improve pyperf sample handling and output"}
{"description": " this pr partially addresses xref #26807 in the case of pandas/tests/test_strings.py. it deletes that file and makes a new subpackage pandas/tests/strings/ with 8 new test modules plus a conftest file. i have only moved tests and flattened the structure by moving the tests from being methods to functions -  i haven't changed them in any other way. there are 1814 tests that were in pandas/tests/test_strings.py and are now in pandas/tests/strings/. i tried to keep each test module logically cohesive and less than 1000 lines long - test_strings.py still contains all the tests that don't really fit anywhere else. tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry ", "commit_messages": " tst gh26807 split out test_api  tst gh26807 split out test_cat  tst gh26807 split out test_find_replace  tst gh26807 split out test_extract  tst gh26807 split out test_split_partition  tst gh26807 split out test_case_justify  tst gh26807 split out test_string_array  tst gh26807 move pytest fixtures to conftest ", "linked_issue_titles": "", "title": "tst gh26807 break up test_strings"}
{"description": " this pull request is identical to #803 except that this time it's on the dev branch. problem 1 : when a timer is resumed manually (from code) after being game resumed (automatically from lost of focus), the way _pausedtotal is computed is no longer accurate since it uses the game pause time. problem 2 : if a timer is paused from code after the game has been game paused, it is not considered to be code paused. these problems have to occur if you want to have a pause screen and display it when the game is out of focus, so that, when the user comes back, he can resume manually. in this sequence, you have to code pause your timer when the game is automatically paused. then, the user has to close the pause screen for the timer to be resumed. ", "commit_messages": " fixed a problem with the timer class wheere the total pause time would be incorrect after unpausing it twice in a row (game pause followed by code pause).  fixed a problem with the timer class where a timer that is _codepaused after a game pause would not be considered to be _codepaused. ", "linked_issue_titles": "", "title": "fixed various problems with timer class"}
{"description": " addresses d9a282f#commitcomment-13296796. @punya, if you could take a look, i'd appreciate it. ", "commit_messages": " module -> namespace in 'leaflet'.  tabs to spaces for consistency with .d.ts.  added test for 'l.control.zoom' in 'leaflet'.  namespaces are one honking great idea -- let's do more of those in 'leaflet'. ", "linked_issue_titles": "", "title": "add missing \"zoom option\" interface in definitions for 'leaflet'"}
{"description": " if requested, automatically download annotations and image files for the coco dataset, including the \"minival\" and \"valminusminival\" annotations provided by ross girshick on dropbox. tested with inspect_model.ipynb and on the command line with python coco.py evaluate --dataset=cocodataset --model=mask_rcnn_coco.h5 --download=true on a machine without the dataset. the latter populates the folder cocodataset with the correct image data and annotation files. ", "commit_messages": " nake it easy to train and eval on ms-coco  tested on win/ubu with notebook/cmd line  pep8 compliant ", "linked_issue_titles": "", "title": "automatically download coco image files and annotations, if requested"}
{"description": " a few examples use normal maps that have not been authored with the opengl normal map handedness convention. in these cases the normal scale y needs to be negated to get the normal maps to display correctly. a mention of normal map handedness is also added to documentation - otherwise it can be hard to find out that the handedness differences exist and how to handle them in three.js. related earlier discussion in issue #11315 ", "commit_messages": " fix normal map handedness in a few examples  a few examples use normal maps that have not been authored with the opengl normal map handedness convention. in these cases the normal scale y needs to be negated to get the normal maps to display correctly.  document handling normal map handedness ", "linked_issue_titles": "", "title": "fix and document normal map handedness"}
{"description": " i did correct some translation, and also i added link to let people visualize the code and test other attributes on it. i will edit this article when i prepare some new things in it, so it become more understandable. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. ", "commit_messages": " total change  i changed the definition and the explanation, and make every possibilies of every logical type, and added some pictures of truth table to make the article and the sentences more understandable.  total change  article edited  i did correct some translation, and also i added link to let people visualize the code and test other attributes on it.  i will edit this article when i prepare some new things in it, so it become more understandable. ", "linked_issue_titles": "", "title": "added arabic translation to html/table article"}
{"description": " refs #15791. this pr fixes some failing protocol module tests when networkservice is enabled. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " fix: always have head.headers available  fix: use stringdatapipeproducer to write string  it can handle large strings correctly.  fix: override registernonnetworksubresourceurlloaderfactories  fix: add dummy uninterceptprotocol implementation  fix: jquery error handler can pass empty string  for some errors jquery would pass empty string in the error handler,  which makes tests pass when they should fail.  chore: fix cpplint warnings  fix: guard registernonnetworksubresourceurlloaderfactories call  it may be called even when networkservice is not enabled.  test: disable protocol.intercepthttpprotocol test ", "linked_issue_titles": "", "title": "migrate protocol module to networkservice (part 5)"}
{"description": " fix confirmation on canceling an object in the menu_cancelobject.cpp so it cancels the right object. (it would be possible to start the menu from 1 instead of 0. but i suggest to keep it starting from 0 and keeping the active object on the status screen corresponding to the nummeration by t486 s[object].) further i suggest with this pull request to relocate the menu for cancel_objects to the main menu while printing directly below tune. fix and better useability of cancel_objects none so far. update: there is an further an unreportet issue with the nummeration of the menu items. objects above 9 dont show up as numbers.. it shows special digits (ascii hex 3a and so on).. ", "commit_messages": " update cancel_object.cpp  update g28.cpp  revert \"update g28.cpp\"  this reverts commit 7e6ed9fb9809326c6ebdc3604808b5fb2124b77c.  revert \"update cancel_object.cpp\"  this reverts commit 292ac9b45ec9b182e43224cb646573b00119d5f8.  fix and move menu_cancelobject ", "linked_issue_titles": "", "title": "fix menu_cancelobject.cpp and move it below tune while busy"}
{"description": " i was able to fix the warnings try transforming the colour argument to an array. it was intially a tuple the error was 'c' argument looks like a single numeric rgb or rgba sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  please use a 2-d array with a single row if you really want to specify the same rgb or rgba value for all points. before the change after the change the plotting still remains the same #widsml @adrinjalali ", "commit_messages": " removing warnings  restructuring comments  removing warnings on plotting by using default colour arguments  removing warnings on examples/neighbors/plot_nca_illustration.py ", "linked_issue_titles": "", "title": "fix warnings in examples/neighbors/plot_nca_illustration.py #14117"}
{"description": " this isn't fully working, though not stopping the os from booting (the aps are in protected mode, but halted for now) for some reason we have what might be a paging issue. accessing the stack or any memory after lgdt/lidt triggers a page fault, which it for some reason can't handle, so it ends up triple-faulting here. interestingly, the cr2 register shows a fault address that is equal to &s_idt + 0x40, which happens to be idt entry #8 (double fault): gdt=     c01c9240 000007ff idt=     c01c9a40 000007ff cr0=e0000011 cr2=c01c9a80 cr3=00109000 cr4=00000060 same gdt/idt and cr3 as the bsp. also, both gdt and idt look fine in both qemu and bochs debugger. qemu's monitor info mem also shows correct mappings (they also look fine in bochs): 0000000000008000-0000000000009000 0000000000001000 -rw 0000000000100000-0000000000200000 0000000000100000 -rw 00000000c0000000-00000000c0118000 0000000000118000 -rw 00000000c0118000-00000000c01c7000 00000000000af000 -r- 00000000c01c7000-00000000c0800000 0000000000639000 -rw 00000000c0801000-00000000c0802000 0000000000001000 -rw 00000000c0803000-00000000c0804000 0000000000001000 -r- 00000000c0805000-00000000c0815000 0000000000010000 -rw 00000000ffe04000-00000000ffe05000 0000000000001000 -rw 00000000ffe08000-00000000ffe09000 0000000000001000 -rw qemu's monitor info tlb also has entries, but they look a little suspicious: 00000000c07fe000: 00000000007fe000 --------w 00000000c07ff000: 00000000007ff000 --------w 00000000c0801000: 80000000fee00000 x--da---w 00000000c0803000: 800000000ffe1000 x---a---- 00000000c0805000: 8000000000802000 x-------w 00000000c0806000: 8000000000803000 x-------w 00000000c0807000: 8000000000804000 x-------w 00000000c0808000: 8000000000805000 x-------w 00000000c0809000: 8000000000806000 x-------w 00000000c080a000: 8000000000807000 x-------w 00000000c080b000: 8000000000808000 x-------w 00000000c080c000: 8000000000809000 x-------w 00000000c080d000: 800000000080a000 x-------w 00000000c080e000: 800000000080b000 x-------w 00000000c080f000: 800000000080c000 x-------w 00000000c0810000: 800000000080d000 x-------w 00000000c0811000: 800000000080e000 x-------w 00000000c0812000: 800000000080f000 x-------w 00000000c0813000: 8000000000810000 x-------w 00000000c0814000: 8000000000811000 x-------w 00000000ffe04000: 000000000010b000 ---da---w 00000000ffe08000: 0000000000801000 ---da---w notice the phyiscal address bit 63 being set. bad tables? 9e5351a#diff-b10e477bf060d4b90924a2559b177384r320-r373 ", "commit_messages": " kernel: add mechanism to identity map the lowest 2mb  ak: add atomic free functions  this allows for using atomic operations on any variables,  not only those wrapped in ak::atomic<t> ", "linked_issue_titles": "", "title": "detect processors and boot them into protected mode"}
{"description": " submit source support sharedb recently added the ability to send an op's source to the server in share/sharedb#426 this change adds the corresponding flag to doc, and updates the structure of the submitrequest. agent.custom agent.custom is normally just an empty anonymous object, which is meant to hold arbitrary information that consumers wish to store. typing this as record<string, unknown> is quite an aggressive typing, and essentially forces consumers to declare their own overriding type definition file, which is quite unusual for a type definition. this change moves us from record<string, unknown> to simply declaring it as any, because the type is completely consumer-defined. if consumers want stricter typing, they're free to: cast agent.custom extend the agent class declare their own type definition (as they are currently forced to do anyway) op and source typing the source may take any truthy value, so boolean is too we also remove internal references that assume ops are json0; documents may use any arbitrary type, including rich-text, for example remove websocket references sharedb can be run in a purely node.js environment, where it doesn't have access to dom types, such as websocket. in these cases, the typescript compilation errors. sharedb doesn't actually rely on a full websocket implementation, its required properties are listed here. internally, sharedb doesn't even use a websocket on server-side connections. it has a streamsocket, which implements the bare minimum. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> ", "commit_messages": " [sharedb] add \"submit source\" support  sharedb recently added the ability to send an op's source to the  server in  this change adds the corresponding flag to doc, and updates the  structure of the submitrequest.  [sharedb] make agent.custom less strict  agent.custom is normally just an [empty anonymous object][1], which is  meant to hold arbitrary information that consumers wish to store.  typing this as record<string, unknown> is quite an aggressive typing,  and essentially _forces_ consumers to declare their own overriding type  definition file, which is quite unusual for a type definition.  this change moves us from record<string, unknown> to simply declaring  it as any, because the type is completely consumer-defined.  if consumers want stricter typing, they're free to:  - cast agent.custom  - extend the agent class  - declare their own type definition (as they are currently forced to do  anyway)  [1]:  [sharedb] less strict op and source typing  - the source may take [any truthy value][1], so boolean is too  strict  - we also remove internal references that assume ops are json0;  documents may use any arbitrary type, including rich-text, for  example  [1]: ", "linked_issue_titles": "", "title": "less strict typings on ops and source"}
{"description": " fixes #7189  (regression introduced with #7102) additionally ensured old function arn format, when no provisioned concurrency setup is involved, this should help partially solve issues for users of plugins which relied on old template format -> davidgf/serverless-plugin-canary-deployments#71 ", "commit_messages": " refactor(aws lambda): ensure natural function reference when no alias  test(aws lambda): improve coverage  expose #7189  refactor(aws lambda): resolve deep value once  refactor(aws lambda): do not deep merge when not necessary ", "linked_issue_titles": " breaking change introduced for custom authorizer lambdas ", "title": "fix lamdba permissions setup when authorizer is involved"}
{"description": " note to reviewers: this pr contains two commits. the first commit ( 4399765) shows what the world will look like once the migration is done. the second commit on top of that (0089896) is a temporary change that allows us to migrate customers over to the new world. once all customers are migrated, the second commit will be reverted. i recommend reviewing the commits separately. this pr reverses the dependency between the services and scheduler layer. prior to this pr, scheduler was depending on services. with this change it is the other way around: this allows the service layers to schedule tasks via the scheduler layer. this work is in preparation of #6827: it will allow us to implement the state restoration manager in the service layer (the restoration manage needs access to the task scheduling api of the scheduling layer). breaking change: this change is expected to only break people that have custom bindings (rare). in those custom bindings, the order of schedulerbinding and servicesbinding will have to be switched around. related issues pre-work for #6827. supersedes #54211, #54202, and  #54151. i added the following tests: modified existing tests to reflect the new dependency chain. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: flutter/website#3918 ", "commit_messages": " wip  wip2 ", "linked_issue_titles": "", "title": "reverse dependency between services and scheduler"}
{"description": " this pr just documents the update process, tries to remove godot-made changes in upstream sources (need testing on msvc!) and gets rid of some unnecessary files. the changes were based on the same 1.0.2h version as before. the last commit then updates to 1.0.2l. ", "commit_messages": " openssl: document update process and delete unused files  openssl: sync with pristine upstream 1.0.2h  our necessary custom changes will be reapplied in later commits for clarity,  and saved as patches for future updates. ", "linked_issue_titles": "", "title": "cleanup and document update process from upstream sources + 1.0.2l"}
{"description": " fix path::split, path::isabsolute, path::getparent, and getcanonicalpath on windows. fixes #13 fixes #14 some edge-case windows pathing may still not work: \"drive relative\" paths: \"c:tmp.txt\" unc paths (network paths): \"\\foo\\bar\" (will be collapsed to \\foo\\bar, which may resolve to a different location than expected) \"absolute paths\": \"\\foo\\bar\" (may or may not resolve to drive root) ", "commit_messages": " fix getcanonicalpath on windows  fix isabsolutepath on windows  add split test  add concatenation tests  handle splits correctly with disk designations ", "linked_issue_titles": " the win32 implementation of getcanonicalpath doesn't work the same as the base implementation  path::isabsolute() doesn't work for win32 paths ", "title": "fix pathing issues on windows"}
{"description": " this pr is intended to allow creation or modification of a metric alert rule - including it's triggers, and their actions - all in one call. it does this by introducing a new serializer, unifiedalertruleserializer that adds the triggers fields. it also adds the actions field to the alertruletriggerserializer.   the id field has also been added to triggers and actions so that the fe can send them back for the put requests. unifiedalertruleserializer implements update, create, and validate functions. we also now serialize the actions externally in the alertruletriggerserializer, so that the fe has this data available to show on the listing index page and it is also returned in the unified create/edit calls. it adds backend constraints on the relationships between triggers and their threshold types and values in the validate function. i believe billy will be implementing these constraints on the fe. tests included that send various valid and invalid payloads to the api. they also include a few tests that update a trigger's type and a trigger's threshold value. ", "commit_messages": " just switching branches  first draft of unified creation api ", "linked_issue_titles": "", "title": "unified metric rule api - post & put"}
{"description": " second attempt of #17132, which was reverted due to failure bundling for mac & windows runs the \"yarn install\" from the root of the packages to de-duplicate node requires via hoisting. reduces the overall bundle size by a considerable margin ~80mb, and the compressed app by ~30mb. main changes: moved install path to path.join(os.tmpdir(), 'cypress-build', platform) with a symlink to build in the root for convenience (per @brian-mann request) loosen semver ranges from pinned to ^ for better deduplication of dependencies copy yarn.lock from the root before yarn --production to ensure we are building with the same dependencies we have in the lockfile for develop/testing (allows us to use the ^ rather than pinned versions with more confidence) removes additional unused directories or files demo / test that are taking up space, primarily in image libraries smaller bundle faster install time before: after: ", "commit_messages": " refactor: loosen semver ranges for deps  refactor: rename binary script files js -> ts  refactor: update binary script files to be more procedural  refactor: additional script cleanups  yarn lock ", "linked_issue_titles": "", "title": "use hoisted yarn install in binary build"}
{"description": " change for request #3384 added support for aarch64 updated to debian stretch (nodejs wasn't in the jessie release on aarch64, and it's been stable for 6+ months now, probably time to update and keep them all in sync anyway) ", "commit_messages": " update to debian stretch for docker containers  add aarch64/arm64 build ", "linked_issue_titles": "", "title": "aarch64/arm64 support for docker builds"}
{"description": " fixes an unintended breaking change introduced by #55792, which introduced an output-dir option. if arb-dir is a custom value, existing users of the gen_l10n tool would realize that their output-dir defaults to lib/l10n instead of the input directory. this behavior is a breaking change and likely undesired by most users. this pr introduced a fix to make sure that the output-dir is always the input-dir by default. i added the following tests: a test to ensure that the gen_l10n tool defaults to using the input directory as the output directory if unspecified. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide ", "commit_messages": " fix breaking change introduced by gen_l10n output-dir option  fix typo ", "linked_issue_titles": "", "title": "fix unintended breaking change introduced by output-dir option"}
{"description": " closes #22875 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry this is a resubmit of a previous pr i submitted that was approved (#22916). i tried to close and reopen to get a rebuild on travis but i couldn't reopen it because i had deleted my old fork (after accidentally pushing to master). ", "commit_messages": " cln gh22785 replace bare excepts by explicit excepts in pandas/io/  cln gh22875 modify previous commit so flake8 passes  cln gh22875 fix pandas/io/packers.py  cln gh22875 fix other except in pandas/io/packers.py  cln gh22875 incorporated feedback from tests  cln gh22875 delete unnecessary comments and incorporate test feedback ", "linked_issue_titles": " replace bare excepts by explicit excepts in pandas/io/ ", "title": "cln gh22875 replace bare excepts by explicit excepts in pandas/io/"}
{"description": " reopening pr with cleaned up style ", "commit_messages": " add a bottom affixed element to affix visual tests.  refactor determining affix state into a separate expanded method  in order to handle multiple edge cases, specifically when the document  height is dynamic.  always reposition an affix that is affixed to the bottom.  fix issue where bottom affixed element floats over the footer when the  document height is smaller than the viewport height.  cleanup style ", "linked_issue_titles": "", "title": "charlesbjohnson affix bottom when dynamic height"}
{"description": " in this pr i extend the operator pad for 16x8 quantization mode. this operator is present in mobilenet v1/v2 from keras.applications. ", "commit_messages": " added missing operators 16x8 pad operators needed for keras mobilenet v1/v2.  excluded new tests for int16 from tests for acceleration. ", "linked_issue_titles": "", "title": "16x8 reference kernel for pad operator"}
{"description": " original pull-request #13341 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix moving sum segfault  fix moving sum segfault ", "linked_issue_titles": "", "title": "cherry pick #13341 to 20.5: fix moving sum segfault"}
{"description": " backbone-relational exports a store class. it also exports a default instance of this class, called store (note the lowercase s), but the latter was missing in the typings. so i added it. the tests that were intended to test for the store export, revealed that store.unregister was typed incorrectly. i fixed that as well. fixing that, i ran into an unwarranted linter error. types/backbone/index.d.ts exports model and collection<tmodel>, where tmodel defaults to model. types/backbone-relational/index.d.ts imports these classes as bmodel and collection, respectively, and defines a model class of its own that extends bmodel. this confused the use-default-type-parameter linter rule when encountering collection<model> on line 166. i disabled the rule on that line. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). this is nowadays automatically included with the tests.  #32883  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. not applicable. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add tests for backbone-relational's exported store instance  add the missing store export to backbone-relational  fix the typing of store.unregister in backbone-relational  disable use-default-type-parameter linter rule in backbone-relational  the linter gives an unwarranted error: it complains that model is the  default type parameter of collection on line 165, column 41 of the  index.d.ts. while it is true that the default parameter is called  model, the type in question has been renamed to bmodel in the current  module.  disable the linter rule in the correct way (see b1deb1c2) ", "linked_issue_titles": "", "title": "add the missing store instance to backbone-relational"}
{"description": " we want to be able to emit witness_method calls on concrete types and class-constrained archetypes. sil part of #15735. ", "commit_messages": " sil: tweak sil verifier condition for witness_method conformance  - existential type cannot appear here at all, don't handle it explicitly  - archetypes can have concrete conformances via their superclass  silgen: use a concrete conformance if we have a witness_method call on a concrete type ", "linked_issue_titles": "", "title": "preliminary \"opaque conformance\" support in sil"}
{"description": " this does a fair amount of fun to create a common keymap that works across a variety of keyboards! since it has some larger-scale changes (i.e. renaming a layout to a better name) submitting a pr now before i work on 40% support. ", "commit_messages": " add userspace to talljoe layout.  move more authority to userspace and create bananasplit layout.  move more things into userspace.  common core example  more work on common layout.  num layer.  talljoe-ansi layout  updates for zeal60  add zeal60 to 60_ansi_split_bs_rshift  swap escape and grave  num-layer tweaks  more tweaks.  add 1up60rgb to world of layouts.  rename ansi_split_bs_rshift layout to hhkb.  control rgb backlight.  change capslock led ", "linked_issue_titles": "", "title": "talljoe's layout with common keymap."}
{"description": " no longer preventing default behaviour due to relation of 'touchstart' and 'click' events alter implementation of stopping bubbling add demo of event bubbling ", "commit_messages": " * [html5] fix bubbling and <a> component  * [html5] add demo for event bubbling ", "linked_issue_titles": "", "title": "html5 bugfix stop events bubbling"}
{"description": " closes #26513, related to #28380 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry this pr basically deals with three issue: implement keyword aggregation for dataframe.agg implement keyword aggregation for series.agg ", "commit_messages": " remove \\n from docstring  fix conflicts  merge remote-tracking branch 'upstream/master'  implement agg for dataframe ", "linked_issue_titles": " allow keyword aggregation in dataframe.agg and series.agg ", "title": "implement keyword aggregation for dataframe.agg and series.agg"}
{"description": " this change brings basic support for timeouts to the futex system call when invoked with the futex_wait option. it's currently implemented by taking advantage of the timer queue to wake the thread on timeout. with that implemented libpthread needed to be fixed to actually pass the option through. a test case was added to very the feature works. ", "commit_messages": " ak: add timeval_to_timespec and timespec_to_timeval conversion methods  add the ability to easily convert between timeval and timespec.  kernel: refactor timequeue::add_timer to use timeval  the current api of add_timer makes it hard to use as  you are forced to do a bunch of time arithmetic at the  caller. ideally we would have overloads for common time  types like timespec or timeval to keep the api as straight  forward as possible. this change moves us in that direction.  while i'm here, we should really also use the machines actual  ticks per second, instead of the optimal_ticks_per_second_rate. ", "linked_issue_titles": "", "title": "plumb futex wait timeout support throughout."}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: 23611 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " d3-geo strictnullchecks mode:  allow geogeometryobjects type to be null  check existence of optional mehtods before calling them  added null to union type or some results of call  missing space ", "linked_issue_titles": "", "title": "d3 geo strict null check"}
{"description": " abstract introduces a new option --fragment-retries for retrying fragments in fragment based downloaders (yet dash segments only) with default value of 10 retry attemps. rationale youtube may often return 404 http error for a fragment in dash segments downloader causing the whole download to fail. however if the same fragment is immediately retried with the same request data this usually succeeds (1-2 attemps is usually enough for success) thus allowing to download the whole file successfully. so, we will retry all fragments that fail with 404 http error for now. example urls example videos i've been able to reproduce failing fragments with: rtwddp2uiu0 imiqwgpbquq. videos uploaded to youtube in a last hour are also very likely to be dash segments with failing fragments. demo here is how it looks in action: > py26yt -v  deleting original file test online game. bigdaimon vs _shepherd-imiqwgpbquq.f160.mp4 (pass -k to keep) deleting original file test online game. bigdaimon vs _shepherd-imiqwgpbquq.f140.m4a (pass -k to keep) further improvements this can be adopted for other fragment based downloaders if necessary. ", "commit_messages": " [options] add --fragment-retries option  [downloader/fragment] add report_retry_fragment  [downloader/dash] add fragment retry capability  youtube may often return 404 http error for a fragment causing the  whole download to fail. however if the same fragment is immediately  retried with the same request data this usually succeeds (1-2 attemps  is usually enough) thus allowing to download the whole file successfully.  so, we will retry all fragments that fail with 404 http error for now.  [downloader/{common,fragment}] fix total retries reporting on python 2.6  [downloader/fragment] document fragment_retries ", "linked_issue_titles": "", "title": "add --fragment-retries option (fixes #8466)"}
{"description": " this ensures spr pages with a . in the name end with .html instead of treating it as a custom extension ", "commit_messages": " make sure to handle paths with dot in name for spr ", "linked_issue_titles": "", "title": "fix spr handling with dot in name"}
{"description": " fixes #19677, which is a regression in how onehotencoder and ordinalencoder handle categories having dtype='s'. changed the dtype.kind checks from 'ou' to 'ous' and updated the test. to facilitate the test, also added a dtype arg to _convert_container. examples: >>> _convert_container([['a'], ['b']], \"list\", dtype='s') >>> _convert_container([[1], [2]], \"list\", dtype=np.float32) ", "commit_messages": " fix 19677: specify categories with dtype='s'  - add dtype='s' cases to test_encoders_string_categories  - add dtype arg to _convert_container to force dtype when applicable  - _convert_container to list now converts container [[1], [2]] to requested dtype (e.g., [[1.], [2.]])  flake8 compat ", "linked_issue_titles": " onehot/ordinalencoder categories broken for dtype='s' ", "title": "fix encoder should accept categories having dtype='s'"}
{"description": " it is a concise course on react native. i was recommended this by the community devs. no sign in required, direct access. it is a course. read our contributing guidelines ", "commit_messages": " add \"data structures and algorithms specialization\" link  update free-courses-en.md  update free-courses-en.md  update free-courses-en.md ", "linked_issue_titles": "", "title": "add- \"introduction to react native\" course"}
{"description": " adds a banner to the top of the page when a user is not on the latest release documentation. partially addresses #58346 docs.ansible.com ", "commit_messages": " add banner to versions that are not latest  move div into script  fix div  move comment ", "linked_issue_titles": "", "title": "add a banner message to warn when not on latest documentation"}
{"description": " this pr fixes #6479 and fix also the ner example that was not working anymore since few weeks. ", "commit_messages": " align tf ner example over the pt one  fix dataset call  fix gradient accumulation training  apply style ", "linked_issue_titles": " [tftrainer] gradient accumulation error ", "title": "fix the tf trainer gradient accumulation and the tf ner example"}
{"description": " a fix for #21103 ", "commit_messages": " homectl: if homed asks for the recovery key to be supplied, query the user for it  fixes: #21103  pam_systemd_home: prompt user for recovery key if homed asks for it  for accoutns that have no passwords but only a recovery key homed might  ask explicitly for that. honour the request and ask the user for it. ", "linked_issue_titles": " `homectl passwd` fails when used on an account with recovery key set ", "title": "handle password changing for accounts that have recovery keys correctly"}
{"description": " throw errors if users don't pass in the correct type of argument to the plugin instead of leaving them in the dark. for occurenceorderplugin, passing in no arguments should still work just in case there are people currently using it without arguments. ", "commit_messages": " add argument error handling in optimization plugins  remove undefined check for minchunksizeplugin ", "linked_issue_titles": "", "title": "add argument error handling for optimization plugins"}
{"description": " the cloudbees build/release config has been upgraded to assuming nebula rxjava plugin 2.x which assumes gradle 2. this is an attempt to upgrade this project. see #117 ", "commit_messages": " upgrade to nebula 2.x and gradle-rxjava-project-plugin 2.x  disable sample-app  it doesn't work with gradle 2 ", "linked_issue_titles": "", "title": "upgrade nebula plugin and gradle"}
{"description": " this pr implements changes proposed in kip-495. this change will introduce an /admin/loggers endpoint to the connect worker that can be used to get/modify the log levels of any named logger in the connect worker. the following new configs are introduced: admin.listeners to control where the admin endpoint will be made available. the default value should bring the /admin endpoint along with the existing endpoints. setting it to empty disables the /admin endpoint altogether. any other host:port string create that listener and only bring the admin endpoints on it. the admin.listeners.https. prefix is used to find ssl props for any https endpoints. multiple tests are added to verify adding admin endpoints with various listeners, and to check if the rest endpoints behave as intended. ", "commit_messages": " kafka-7772: initial commit  kafka-7772: start admin context only if admin endpoints are on different listeners  kafka-7772: implementation of the logging resource  kafka-7772: add /admin prefix to resource  kafka-7772: add integration tests for loggerresource  kafka-7772: rename and clean up adminurl method in restserver ", "linked_issue_titles": "", "title": "dynamically adjust log levels in connect"}
{"description": " we had a few different mechanisms for lazy deserialization in the ast. start folding them together into one mechanism, pack some ast nodes better, and eliminate some dead code. should all be nfc ", "commit_messages": " [ast] optimize lazy-member storage for nominal type and extension declarations.  save two pointers of storage in iterabledeclcontext (a base class of  nominal type and extension declarations) by storing the lazy member  loader + context data in an astcontext side table. it also makes it  easier to add more lazy context information later on.  [ast] remove lazyloaderarray; it's all dead code.  [ast] fold lazy conformance loading into the lazyiterabledeclcontextdata.  this standardizes on just one side-lookup table for storing  information about lazy deserialization of nominal type and extension  declarations. nfc ", "linked_issue_titles": "", "title": "some cleanups in lazy deserialization"}
{"description": " i recently renamed editor::setsoftwrap and ::getsoftwrap to ::setsoftwrapped and ::issoftwrapped. i also renamed the config setting and command to match, but we've decided that wasn't a good idea. this pr renames the config setting back to editor.softwrap and the command back to editor:toggle-soft-wrap. fixes #3531 ", "commit_messages": " rename editor.softwrapped config option back to editor.softwrap  rename editor:toggle-soft-wrapped back to editor:toggle-soft-wrap ", "linked_issue_titles": " soft wrap doesn't work at all ", "title": "rename soft-wrapped back to soft-wrap"}
{"description": " i ran the current the current rails guides site against lighthouse & one of the things it suggested was to add a valid robots.txt file. when i inspected the current robots.txt, it's 404'ing. so i added one copying the html5 boilerplate example. to test this locally i ran rake guides:generate & inspected the output folder. i did look into adding a sitemap also, but i think i'll save that for another pr :) ", "commit_messages": " adding a robots.txt to the guide  just adding an allow all robots.txt file ", "linked_issue_titles": "", "title": "adding robots.txt to guide as lighthouse is warning about it"}
{"description": " adds press prop types creates constants for default delay ms fixes a mouse pointer check for safari (no pointer events) ref #15257 ", "commit_messages": " add pressprops type to event module  move default press event delays to constants  fix right-click press check for safari ", "linked_issue_titles": "", "title": "add press event prop types and fix a check in safari"}
{"description": " fixes #6311. this is an alternative approach to #6328. offline discussions have determined that there was not enough review around the idea of type predicates on accessors and properties. this moves them back to signatures, keeps this-based predicates, and continues to infer from type predicates. @mhegazy ", "commit_messages": " add test  move type predicates back onto signatures, remove narrowing for property/get type guards.  error on nodes which should not have type predicates.  minor rename.  use names of accessors instead of their entire spans.  added tests.  actually, it makes more sense to error on the predicate annotation than anything else.  removed trailing whitespace for linter.  fixed up fourslash tests to only test functions.  accepted baselines. ", "linked_issue_titles": "", "title": "remove notion of predicates as types, move predicates back to signatures"}
{"description": " adds monitor selection, basic properties and a fix to enum_monitors to win-capture plugin ", "commit_messages": " use of text macros instead of direct obs_module_text calls  fix for enum_monitors  function enum_monitors would always stop after first found monitor due to wrong return value.  add monitor selection and basic properties ", "linked_issue_titles": "", "title": "add monitor selection and properties to monitor capture (win)"}
{"description": " closes #17383 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry test case refactoring: moved the existing  index-as-string test cases out of test_groupby.py and into a new test_index_as_string.py file extracted test data generation functions and parameterized existing test cases to clean them up and shorten them. added a new parameterized test case on a series updated test_grouper_column_index_level_precedence to reproduce false warning problem as described in #17383 updated test_grouper_column_index_level_precedence to verify when warnings should not be raised (results in a test failure due to #17383 without this fix) ", "commit_messages": " refactor groupby tests for using strings to reference index levels  - extract to separate file (test_index_as_string.py)  - parameterize over test dataframes  - add series test case  - update test_grouper_column_index_level_precedence to reproduce false warning problem as described in gh17383  - update test_grouper_column_index_level_precedence to verify when warning shouldn't be raised (results in test failure due to gh17383)  fix for gh17383  added whatsnew entry ", "linked_issue_titles": " groupby with matching column and index name emits spurious warning ", "title": "refactor index-as-string groupby tests and fix spurious warning (bug 17383)"}
{"description": " deprecations? spec compliancy? tests added/pass? fixed tickets doc pr breaking changes: this deletes the 'options' export from babel-core. babel options that expect arrays must be arrays, where before strings would be split on commas and single values would be converted to arrays. the cli still supports comma-strings however. hopefully will effect relatively few people. the primary goal of this pr is to get rid of our config.js file that listed options in favor of defaults + validation inside the option manager. the primary user-visible change is the required array inputs. ", "commit_messages": " get rid of circular dependencies in babel cli script.  move babel config descriptions to babel-cli.  move option parsing to babel-cli.  remove config.js file in favor of config code. ", "linked_issue_titles": "", "title": "more strictly parse configs and explicitly handle arguments in babel-cli"}
{"description": " i hereby agree to the terms of the cla available at:  mergetree full support for disks3 detailed description / documentation draft: all i/o operations in mergetree are reworked using idisk. mergetree works with s3 as the main storage. merges and mutations work as well. disks3 can be used in storage policy as cold or primary storage. background processing pool settings are now configurable. ", "commit_messages": " imergedatapart full s3 support.  mergetreedata full s3 support.  compilation fixes.  mutations and merges s3 support.  fixed removing data part.  mergetree for s3 integration tests and fixes.  code style issues.  enable aws logging.  # conflicts:  #\tdbms/src/storages/mergetree/mergetreedata.cpp ", "linked_issue_titles": "", "title": "mergetree full support for s3"}
{"description": " please refer to the individual commit messages for additional details. ", "commit_messages": " replace some instances of implicit function.bind(this) usage, in src/display/api.js, with arrow functions instead  reduce the amount of unnecessary function calls and object allocations, in messagehandler, when using streams  with pr 11069 we're now using streams for operatorlist parsing (in addition to just textcontent parsing), which brings the nice benefit of being able to easily abort parsing on the worker-thread thus saving resources.  however, since we're now creating many more readablestream there appears to be a tiny bit more overhead because of it (giving ~1% slower runtime of browsertest on the bots). in this case we're just going to have to accept such a small regression, since the benefits of using streams clearly outweighs it.  what we *can* do here, is to try and make the streams part of the messagehandler implementation slightly more efficient by e.g. removing unnecessary function calls (which has been helpful in other parts of the code-base). to that end, this patch makes the following changes:  - actually support transfers in messagehandler.sendwithstream, since the parameter was being ignored.  - inline the sendstreamrequest/sendstreamresponse helper functions at their respective call-sites. obviously this causes some amount of code duplication, however i still think this change seems reasonable since for each call-site:  - it avoids making one unnecessary function call.  - it avoids allocating one temporary object.  - it avoids sending, and thus structure clone, various undefined object properties.  - inline objects in the messagehandler.{send, sendwithpromise} methods.  - finally, directly call comobj.postmessage in various methods when transfers are *not* present, rather than calling messagehandler.postmessage, to further reduce the amount of function calls.  change the internal stream property, as sent when streams are used, from a string to a number  given that the stream property is an internal implementation detail, changing its type shouldn't be a problem. by using numbers instead, we can avoid unnecessary string allocations when creating/processing streams. ", "linked_issue_titles": "", "title": "various messagehandler improvements when using streams"}
{"description": " what kind of change does this pr introduce? (check at least one) does this pr introduce a breaking change? (check one) for issue #5324 , i have added some ts declarations generatorapi, promptmoduleapi in @vue/cli pluginapi in @vue/cli-service test utilities function declaration in @vue/cli-test-utils i added test for these declarations. also i linted the code by dtslint with some necessary rules according to the readme of definitelytyped . test by npx tsc -p packages/@vue/cli/types/tsconfig.json known issue it seems there are some problem in webpack's declaration. so \"skiplibcheck\": true should be set in tsconfig.json when use pluginapi in .ts. by the way, i formated and linted the codes whithout adding config file (like tslint.json, .prettierrc) to vue-cli repo. besides, vscode may report error for *.d.ts caused by eslint parser of cli repo.  i believe i should avoid adding extra config files/codes or changing eslintignore.  core maintaner do this will be better, if necessary. add i used yarn link to verify the declarations of @vue/cli, @vue/cli-service, @vue/cli-test-utils in my own plugin repo. vscode can finish code completion even in .js file according declaration of @vue/cli-test-utils pluginapi and generatorapi can be used in .ts file  normally i hope this pr will be helpful. appendix for @vue/cli-test-utils,i  added declaration to cli-test-utils folder directly, like createtestproject.d.ts we can organize the file structure  better, but it may cause break change. or there is good way i overlooked. ", "commit_messages": " feat(cli-service): add declaration for pluginapi  fix #5324  feat(cli): add declaration for generatorapi,promptmoduleapi  fix #5324  feat(cli-test-utils): add declaration for test utilities  fix #5324 ", "linked_issue_titles": "", "title": "feat(cli,cli-service,cli-test-utils): add ts declaration"}
{"description": " / #48187 ", "commit_messages": " updating dockerfile.rocm to use rocm 4.1  updating ci scripts to use rocm 4.1  switching rocm tf to use the new hipfft library (instead of rocfft).  for rocm 4.0 and prior, hipfft was a header-only \"library\" that was shipped along with the rocfft library. rocm tf code uses the hipfft apis defined in the \"hipfft.h\" header file, which was part of the package for rocfft library. rocm tf would dynamically load the \"rocfft\" library at runtime.  from rocm 4.1 onwards, it seems hipfft is a separate library from rocfft, and rocm tf needs to use the \"hipfft\" library insteaf of the \"rocfft\" library. specifcally, rocm tf needs to  * pick up the \"hipfft.h\" header from the hipfft install area (instead of the rocfft install area).  * dynamically load the the \"hipfft\" library instead of the \"rocfft\" library  this commit has the two above changes  this change is required because without this change, the unit-tests that called the hipfft api ( hipfftsetworkarea ) were failing when run with rocm 4.1 (and without the changes in this commit).  rocm tf continues to build (with rocm 4.1) without the changes in this commit, because the old \"hipfft.h\" file in the rocfft install area is still present (do not know whether that is by design or accident)  unit-tests known to call the hipfftsetworkarea api    //tensorflow/python/kernel_tests/linalg:linear_operator_circulant_test_gpu  //tensorflow/python/kernel_tests/signal:dct_ops_test  //tensorflow/python/kernel_tests/signal:mel_ops_test  //tensorflow/python/kernel_tests/signal:mfcc_ops_test  //tensorflow/python/kernel_tests/signal:spectral_ops_test  //tensorflow/python/ops/parallel_for:control_flow_ops_test_gpu    updating the mapping of gcn arch name tokens to feature strings.  prior to this commit, the gcn arch name \"gfx908:+sramecc\", would get mapped to  * { target : \"gfx908\", feature_string : \"+sram-ecc\"}  this commit changes the mapping to the following  * { target : \"gfx908\", feature_string : \"+sramecc\"}  (notice the dash \"-\" is gone from \"+sram-ecc\")  the llvm version being picked up by tf in this branch ( develop-upstream-qa-rocm42 ) seems have changes withing it (as compared to the version being picked up in the develop-upstream-qa-rocm41 branch), which require this change in the mapping.  this mapping is expected to be in a state of flux until all the amdgpu target-id related changes have been pushed out to the upstream llvm repo, and tf llvm pointer is updated to pick those changes.  add clang 13 header for rocm configure  re-enabling subtests that were disabled due to jira ticket - 236756  re-enabling unit-tests that were disabled due to jira ticket - 248713  revert \"adding no_rocm tag to rocm unit-tests that regress with rocm 3.9\"  this reverts commit 7301217ef410b9a0490bff6e717715ad2aeb1428.  re-enabling some unit-tests that regressed starting rocm 3.8  they were disabled in the following commit    adding no_rocm tag to //tensorflow/python/kernel_tests:extract_image_patches_grad_test_gpu  this unit-test starts to fail when we switch from rocm 4.0.1 to rocm 4.1.0  qa did not detect this regression because this test passes in the branch they were using to qualify rocm 4.1.0 ( develop-upstream-qa-rocm41 )  in addition to other changes (between develop-upstream-qa-rocm41 and tip of develop-upstream), the testcase itself seems to have changed. we need to root-cause the regression, fix it and re-enable the test.  copy-pasting the error log here for reference    ======================================================================  fail: test_allnone_gradient (__main__.extractimagepatchesgradtest)  test_allnone_gradient (__main__.extractimagepatchesgradtest)  ----------------------------------------------------------------------  traceback (most recent call last):  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 185, in test_allnone_gradient  self._variableshapegradient([none, none, none, none])  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 173, in _variableshapegradient  self.assertless(err, 1e-4)  assertionerror: nan not less than 0.0001  ======================================================================  fail: test_bxxc_gradient (__main__.extractimagepatchesgradtest)  test_bxxc_gradient (__main__.extractimagepatchesgradtest)  ----------------------------------------------------------------------  traceback (most recent call last):  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 176, in test_bxxc_gradient  self._variableshapegradient([-1, none, none, -1])  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 173, in _variableshapegradient  self.assertless(err, 1e-4)  assertionerror: 0.4175793528556824 not less than 0.0001  ======================================================================  fail: test_xhwx_gradient (__main__.extractimagepatchesgradtest)  test_xhwx_gradient (__main__.extractimagepatchesgradtest)  ----------------------------------------------------------------------  traceback (most recent call last):  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 179, in test_xhwx_gradient  self._variableshapegradient([none, -1, -1, none])  file \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/extract_image_patches_grad_test_gpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/extract_image_patches_grad_test.py\", line 173, in _variableshapegradient  self.assertless(err, 1e-4)  assertionerror: 0.2977283000946045 not less than 0.0001  ----------------------------------------------------------------------  ran 7 tests in 406.984s  failed (failures=3, skipped=1)  ================================================================================    adding no_rocm tag to tests which are failing on mi100 with rocm 4.1  these tests    //tensorflow/compiler/xla/tests:convolution_test_1d_gpu_alternative_layout_gpu failed in 3 out of 3 in 16.0s  //tensorflow/compiler/xla/tests:convolution_test_1d_no_vmodule_gpu       failed in 3 out of 3 in 16.1s    re-enabling all the tests that will potentially be fixed by jira ticket - 263833  the following is list of unit-tests from which we are removing the no_rocm tag in this commit, because we suspect/hope that the issue being fixed by jira ticket 263833, will make these tests pass.  all of these tests are passing locally when tested with rocm 4.1rc1, but given the flaky nature of the failure (these tests would only fail on some ci nodes...sometimes), we need to have them pass consistently on all ci nodes, over some periosd of time (couple of weeks) before we can claim victory    //tensorflow/python/distribute:cross_device_ops_test_gpu  //tensorflow/python/distribute:distribute_utils_test_gpu  //tensorflow/python/distribute:strategy_common_test_gpu  //tensorflow/python/distribute:strategy_gather_test_gpu  //tensorflow/python/distribute:test_util_test_gpu  //tensorflow/python/distribute:values_test_gpu  //tensorflow/python/distribute:vars_test_gpu  //tensorflow/python/keras/distribute:custom_training_loop_metrics_test_gpu  //tensorflow/python/keras/distribute:custom_training_loop_models_test_gpu  //tensorflow/python/keras/distribute:keras_rnn_model_correctness_test_gpu  //tensorflow/python/keras/distribute:keras_utils_test_gpu    the following two tests fell into the same category as above, but their no_rocm tag ios staying put, because flaku failures were observed for them in local testing with rocm 4.1    //tensorflow/python/keras/distribute:distribute_strategy_test_gpu  //tensorflow/python/keras/distribute:keras_dnn_correctness_test_gpu  //tensorflow/python/keras/distribute:keras_embedding_model_correctness_test_gpu  //tensorflow/python/keras/distribute:keras_image_model_correctness_test_gpu  //tensorflow/python/keras/distribute:keras_save_load_test_gpu    also some of the tests take longer than 900s to complete on the rocm platform (no sharding on rocm!)...bumping them up to size large in this commit  adding no_rocm tag to tests that seem to have done flaky with rocm 4.1  these tests    //tensorflow/python/keras/distribute:saved_model_save_load_test_gpu  //tensorflow/python/kernel_tests:tensordot_op_test_gpu    see details here -  syncing the contents of the run_gpu_multi.sh script with the rocm fork  fixing errors in \"buildifier check\"  fixing errors in \"bazel query\"  piperorigin-revid: 367580713  change-id: i5289492260ea8c6fde64848ba895c1ea736019d8 ", "linked_issue_titles": "", "title": "port pr 48187 to r2.5"}
{"description": " this allows people to avoid having audit messages in the journal at all:  some related cleanups, and adding systemd-journal-audit.socket to documentation. ", "commit_messages": " journald: move server_restore_streams out of server_open_stdout_socket  one has little to do with the other, so it's confusing that the second  also calls the first.  journald: make audit socket optional  if we were given some sockets through socket activation, and audit  socket is not among them, do not try to open it. this way, if the  socket unit is disabled, we will not receive audit events.   ", "linked_issue_titles": "", "title": "make journald audit socket maskable"}
{"description": " this pr updates links to external pages. it: changes  changes  updates links to other services, where to skip unnecessary redirects. one thing i didn't fix is the link to  what do you think? i'd be happy to squash the commits, or skip some of them if you think this changes too much. ", "commit_messages": " [docs] fix link to py-amqp issue tracker  use https for github and wikipedia links  [docs] update external links in readme ", "linked_issue_titles": "", "title": "update and fix links to external pages"}
{"description": " this is a follow-up for this abandoned pull request: #32202 hopefully the code is acceptable and can be merged this time? i would like to use this feature in my current projet. edit: documentation reference (unclear)  source code reference ", "commit_messages": " chartjs - missing tooltip axis option  according to  trailing space  updated axis type based on uniqueiniquity's comment. ", "linked_issue_titles": "", "title": "chart.js - missing tooltip axis option"}
{"description": " removed truncating of text in attachment.text. added attachment.text to be parsed to markdown by default. earlier now closes #20560 #20560 (comment) shows the bug which can be reproduced by using the curl command if you already have a bot with the correct credentials. otherwise you can use this way to reproduce the message, (i have used a bot for that): on the terminal, do git clone  add this bot with these username and password to the list of users. (for reference, you can see this -  now in the terminal where you cloned the repo for the bot, do npm start. you will get a message in the general channel of your running instance. ", "commit_messages": " fix: remove truncating of attachment.text  fix: display attachment.text as markdown ", "linked_issue_titles": " jira notifications via webhook - layout broken ", "title": "default attachments - show full attachment.text with markdown"}
{"description": " adding my dz60 keymap, and updating my boardwalk keymap my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " updating boardwalk layout, and adding dz60 layout  dz60 config.h  image added to readme ", "linked_issue_titles": "", "title": "niclake - keymap updates - boardwalk updates & dz60 create"}
{"description": " i'm working on font/language support detection and this pr is actually a first bunch of (mostly) obvious fixes. ", "commit_messages": " guifontttfdx: prevent crash on unallocated texture or unavailable direct3d device  cguifontttfgl::begin: prevent crash on unallocated texture ", "linked_issue_titles": "", "title": "set of fixes for font processing"}
{"description": " change the primary motivation of this change was to add new fields for use in the list and upgrade commands; system reference strings that can be used to associate a winget package with software currently installed on a machine.  this required creation of schema 1.1, as well as some refactoring to make inheritance and behavior changes easier between versions. the two types of strings added are packagefamilyname for msix packages, and productcode for packages that register through arp (add/remove programs).  these are added with the option of having multiple of each in the event that a package's installers have unique values.  the values are stored with their casing folded to allow for ordinal comparisons, a performance requirement due to future work on list and upgrade. additional noteworthy changes: changed from implicit indices to explicit ones in 1.1, and drop more of them during preparation for packaging. this should result in a ~35% reduction in page count in the database, with no impact to performance. added a dev debug tool in sqlitewrapper.cpp; set winget_sqlite_explain_query_plan_enabled to 1 to have the query plan for every sqlite prepared statement output to logging. validation the existing tests have been updated to use generate to run the tests not only against all versions, but also with backcompat scenarios. microsoft reviewers: open in codeflow ", "commit_messages": " add query plan output for debugging  move header output to remove non-read statements  add index version 1.1 (initial) that uses named indeces throughout and removes more of them when packaging  add new 1:n tables for system reference strings, still requires testing of search  add tests for system reference strings ", "linked_issue_titles": "", "title": "create db 1.1 schema for system reference strings"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: docs to path() increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " [ramda] fix path() return type  add tests ", "linked_issue_titles": "", "title": "fix path() return type according to documentation"}
{"description": " test sharding appears to have been broken by commit 87cc788. the result being that many tests are simply not run when sharding is enabled. the issue seems to be that the filtering for sharding is happening twice, once in tensorflow/python/platform/googletest.py and then once again in external/absl_py/absl/testing/absltest.py. this commit fixes the issue by removing the shard filtering code in googletest.py. fixes: #25594 ", "commit_messages": " fix test sharding  test sharding appears to have been broken by commit 87cc788.  the result  being that many tests are simply not run when sharding is enabled.  the issue seems to be that the filtering for sharding is happening  twice, once in tensorflow/python/platform/googletest.py and then once  again in external/absl_py/absl/testing/absltest.py.  this commit fixes  the issue by removing the shard filtering code in googletest.py.  fixes:  remove unused import of itertools ", "linked_issue_titles": " test sharding appears to be broken ", "title": "fix test sharding version 2"}
{"description": " for the snap updates caddy to 0.11.0 and updates node.js to 8.11.2 i've already updated the 0.65.1 snap which is live for everyone.  this is just making these changes upstream :) ", "commit_messages": " update caddy version  update node.js to 8.11.2 ", "linked_issue_titles": "", "title": "snap update caddy and nodejs"}
{"description": " fix #4620 use click event instead of change event. add test case for #4521 ", "commit_messages": " listen to click event for checkbox and radio.  add test cases ", "linked_issue_titles": " checkbox :checked is not fully reactive when checkbox is in focus ", "title": "use 'click' event for checkbox and radio (fix #4620)"}
{"description": " the old socket.io guide didn't actually work that well, for the reasons that i've outline in the new guide i wrote. ", "commit_messages": " adding feathers to the mix.  adding feathers to the mix. ", "linked_issue_titles": "", "title": "adding feathers to the mix and an updated react native socket.io guide"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " added cordova-plugin-native-keyboard  updated to conform linting checks  onsubmit callback is now optional  pull and conflicts resolved  added possibility to use an array for the property country in geocodercomponentrestrictions ", "linked_issue_titles": "", "title": "possibility to use an array for the property country in geocodercomponentrestrictions class"}
{"description": " this is used surprisingly often. for example, it is used by a core youtube library called structured page fragments. it allows you to manually dispatch an event with arbitrary data attached to it. the only thing missing from this implementation is the constructor. this is because wrappergenerator is currently missing dictionary capabilities. ", "commit_messages": " libweb: add [customvisit] idl interface extended attribute  this custom attribute will be used for objects that hold onto arbitrary  js::value's. this is needed as js::handle can only be constructed for  objects that implement js::cell, which js::value doesn't.  this works by overriding the visit_edges function in the wrapper.  this overridden function calls the base visit_edges and then forwards  it to the underlying implementation.  this will be used for customevent, which must hold onto an arbitrary  js::value for it's entire lifespan.  libweb: add support for the any type in returning and parameters  required for customevent. ", "linked_issue_titles": "", "title": "add initial support for customevent"}
{"description": " original pull-request #13752 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " range check for h3kring  update test  range check for h3kring ", "linked_issue_titles": "", "title": "cherry pick #13752 to 20.6: range check for h3kring"}
{"description": " right now formatting of std::byte using compile-time api like so: fmt::format(fmt_compile(\"{}\"), std::byte{42}) ends up with compilation error, proof on compiler explorer. because there are 2 write functions which satisfy for the passed type std::byte: fmt/include/fmt/format.h lines 2114 to 2120 5a37e18 template <typename char, typename outputit, typename t, fmt_enable_if(std::is_enum<t>::value && !std::is_same<t, char>::value)> fmt_constexpr outputit write(outputit out, t value) { return write<char>( out, static_cast<typename std::underlying_type<t>::type>(value)); fmt/include/fmt/format.h lines 2150 to 2162 5a37e18 template <typename char, typename outputit, typename t> auto write(outputit out, const t& value) -> typename std::enable_if< mapped_type_constant<t, basic_format_context<outputit, char>>::value == type::custom_type, outputit>::type { using context_type = basic_format_context<outputit, char>; using formatter_type = conditional_t<has_formatter<t, context_type>::value, typename context_type::template formatter_type<t>, fallback_formatter<t, char>>; context_type ctx(out, {}, {}); return formatter_type().format(value, ctx); also, i found __cpp_lib_byte feature macro, so all new checks are based on this macro instead of __cplusplus >= 201703l and i changed old checks accordingly. ", "commit_messages": " add test for byte formatting with fmt_compile  fix byte formatting with fmt_compile, use __cpp_lib_byte macro ", "linked_issue_titles": "", "title": "fix std::byte formatting with compile-time api"}
{"description": " removed and renamed several files that do not exist or have been renamed, but the project files had never been updated.  this was causing an issue building with visual studio 2015/2017, with a \"project is out of date\" warning every time the program is run from within the ide. ", "commit_messages": " [libcocos2d.vcxproj, libcocos2d.vcxproj.filters] removed entries for non-existent files that were causing \"build is out of date\" issues in visual studio  [project.pbxproj] removed entries for non-existent file  [libcocos2d.vcxproj.filters] renamed ccstencilstatemanager.h extension to .hpp.  [libcocos2d.vcxproj, libcocos2d.vcxproj.filters] removed entry for file ccdownloaderimpl.h which does not exist. ", "linked_issue_titles": "", "title": "vs and xcode project files have non-existent file references"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: luxon#1.20.0 ", "commit_messages": " [luxon] add interval#toisodate and interval#toisotime  [luxon] add duration#mapunits  patch version not allowed ", "linked_issue_titles": "", "title": "add interval#toisodate, interval#toisotime and duration#mapunits"}
{"description": " fixed an index out of bounds error that occurs when you pass 256 into iskeyjustpressed() on lwjgl3 backend ", "commit_messages": " update lwjgl3input  fixed an index out of bounds error that occurs if you pass the value 256 into gdx.input.iskeyjustpressed()  update lwjgl3input  made the iskeyjustpressed method more consistent with lwjgl backend. ", "linked_issue_titles": "", "title": "iskeyjustpressed index out of bounds on lwjgl3"}
{"description": " description: added error handling. the error prompt the user to reboot the sky hub router in case home assistant is not able to fetch data from it. the rebooting has been reported to solve the issue here. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " added error handling in function _get_skyhub_data  error line split for readability ", "linked_issue_titles": "", "title": "improve sky hub error handling"}
{"description": " setting the 2nd tool's z-offset to a positive value, results in the tool not being able to reach bed level. this is because zmin soft endstop is translated and the new endstop value for the tool becomes its z-offset. since tools in a parking_extruder configuration are all carried on the x-axis, their nozzles' height difference must be compensated by moving the lowest tool lower than zmin, and zmin endstop value for all tools should be 0 (untranslated). this is typically not an issue, since tools are parked outside the hotbed area. if tools are parked within the bed area (in which case useful bed space is consumed, so not a typical configuration), they must be perfectly aligned in height in order to avoid the lowest tool from crashing on the bed. this solution allows both tools reach the bed by skipping the change to the z-min soft endstop value (which typically happens on tool change). all other endstop values are translated accordingly. e0 active: ___________x-axis__________ |||             ||| |||             ||| |||              v ------bed------- e1 active, before the fix: ___________x-axis__________ |||                ||| |||                ||| |||                 v ------bed------- e1 active after the fix: ___________x-axis__________ |||                ||| |||                ||| |||                 v v    ------bed------- 2nd tools with a positive z-offset can work properly. enable parking_extruder, create a 2nd extruder with a positive z-offset value. this is complementary to pull request #20473 ", "commit_messages": " fixed broken parking_extruder operation.  fixed configuration files  update solenoid.cpp  update t.cpp  update tool_change.cpp  update tool_change.cpp  update tool_change.cpp  invert  last touch  fix for 2nd tool z-offset operation ", "linked_issue_titles": "", "title": "don't apply hotend_offset.z to z soft endstops"}
{"description": " this is a backport of #54803 for 7.x. this pull request cherry picks the squashed commit from #54803 with the additional commits: 6f50c92 which adjusts master code to 7.x a114549 to mute a failing ilm test (#54818) 48cbca1 and 50186b2 that cleans up and unmutes the previous test aae12bb that adds a missing feature flag (#54861) 6f330e3 that adds missing serialization bits (#54864) bf72c02 that adjust the version in yaml tests a51955f that adds some plumbing for the transport client used in integration tests ", "commit_messages": " merge feature/searchable-snapshots branch into master (#54803)  this commit merges the searchable-snapshots feature branch into master.  see #54803 for the complete list of squashed commits.  fix stuff after cherry-picking  mute testdeleteactiondeletessearchablesnapshot (#54818) ", "linked_issue_titles": "", "title": "merge feature/searchable-snapshots branch into 7.x (#54803)"}
{"description": " when constructing union and intersection types, we eagerly remove duplicate function types that originate in function or method declarations. this eager reduction can be very expensive when resolving the members of unions of a large number of array or tuple types. we used to rely on the eager reduction, but it is no longer necessary because a similar and more efficient reduction happens later (and in a deferred manner) when we compute the signature lists of union and intersection types. with this pr we remove the unnecessary eager reduction. this makes our behavior more consistent since the eager reduction was never done for other types. one example that directly benefits is this code in #26756. when requesting statement completion: function sendcommand<c extends keyof commands>(method: c, ...params: commands[c]['paramstype']) { params.  // statement completion here } we currently spend 5-6 seconds grinding away before bringing up a completion list. with this pr the completion time drops to less than half a second. only one rwc project, fp-ts, is affected by this. upon inspection the new errors in fp-ts look correct, and with the latest code here ", "commit_messages": " defer reduction of identical function types in unions and intersections  accept new baselines ", "linked_issue_titles": "", "title": "defer union and intersection type reduction"}
{"description": " this pr moves .flake8 and .coveragerc into pyproject.toml use pflake8 wrapper use coverage[toml] extra the makefile line \"pip install coverage[toml]\" can be removed once the docker base image has been deployed ", "commit_messages": " migrate .flake8 config to pyproject.toml through pflake8  migrate .coveragerc to pyproject.toml through toml extra ", "linked_issue_titles": "", "title": "consolidate .coveragerc and .flake8 config int pyproject.toml"}
{"description": " when using tooltip with a delay on show, but not on hide the delay timer is not cancelled. this is now fixed and an unit test is added to the test framework. ", "commit_messages": " cancel running timer for tooltips with delayed show, but instant hide. this prevents delayed tooltips from appearing if the mouse leaves the elements before tooltip is showed and the hiding delay is 0.  added unit test to check that tooltips is not showed when leave event is triggered before show delay has expired and the hide delay is set to 0 ", "linked_issue_titles": "", "title": "added fix for bootstrap-tooltip with show-delay but now hide delay."}
{"description": " as in the description, it's now fixed. i've removed the signed word since it's implicit. ", "commit_messages": " added most of the standard ppc instructions, missing some altivec and complex instructions  fixed rot instructions.  minimal support to ppc[64] emulation  fixed for  flavour  fixed inv_mask[32/64]  fixed parsing of some functions  merge with radare/radare2 repo ", "linked_issue_titles": "", "title": "ppc pseudo bad parse due missing uppercase letters & ppc emu (due mistake)"}
{"description": " fixes #70168 introduced in #69604 which was backported to 2.9.10. this would need to be backported to 2.9 and 2.10. this is another take to get these fixes in after they were reverted in #70272 due to issues with testing the fixes in our ci. lib/ansible/plugins/action/__init__.py ", "commit_messages": " fix storing local task_vars facts for the retry (#70171)  * fix storing local task_vars facts for the retry  fixes #70168  (cherry picked from commit eaf6086eeab3ffc0389694a037c776cd3d6ac0b5)  fix storing delegate_to facts (#70231)  * fix storing delegate_to facts  (cherry picked from commit 88bb76f248833ea0761fc474ba77ef697c62baac)  remove non_local ", "linked_issue_titles": " 2.9.10: unboundlocalerror: local variable 'module_style' referenced before assignment ", "title": "fix delegate_facts with interpreter not being set"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: this is used in many strategies -  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added passreqtocallback to passport authenticationoptions  added myself to contributors just in case  fixed tabs  actuall fixed tabs ", "linked_issue_titles": "", "title": "passportjs - add passreqtocallback to authenticateoptions"}
{"description": " hello, i would like to add my project to this amazing library. componofy is a web app that allows users to merge or create their playlists out of many, personal or public, playlists. it also allows users to re-order tracks in playlist with drag and drop and upload custom playlist cover images. please see a 2-minute demo for more details:  it uses material-ui from top to bottom with themes and measurement units applied for each component. for more code details you can see the source code:  i believe this project is great and will be a good asset to your showcase! thanks a lot for this amazing ui library. link: ", "commit_messages": " added showcase to readme - componofy  align text ", "linked_issue_titles": "", "title": "add showcase to readme - componofy"}
{"description": " add tooltips to st.checkbox, st.radio, and st.number_input. pr preview is in e2e/scripts/st_tooltips.py. ", "commit_messages": " add help keyword/field to protobufs and api  add tooltip to textinput  remove unnecessary code  fix pylint  fix pylint stuff  fix tests  remove unnecessary change  add e2e test  remove unnecessary change  add tooltips for st.checkbox, st.radio, st.number_input ", "linked_issue_titles": "", "title": "add tooltips to more widgets"}
{"description": " fix #9942. ", "commit_messages": " fix sankey edge emphasis not work #9942  fix opacity not work in edge emphasis which is override by focusnodeadjacency action  fix adjacency node emphasis color not work with focusnodeadj action ", "linked_issue_titles": " emphasis line style options do not work on sankey charts ", "title": "fix emphasis line style options do not work on sankey charts #9942"}
{"description": " added trace steps to show addition of nodes and how tree is traversed while adding a new node. this will help in resolving issue #213 in my opinion. please review and let me know your feedback. thanks, raj ", "commit_messages": " added trace to construct elements  still work pending in construct and tree code  removed node collection dependecy from consumed app  udpated code to store nodecollection and root with in the construct  tracer  updated layout stratergy to draw nodes ", "linked_issue_titles": "", "title": "tracer to depict addition of nodes in binary search tree"}
{"description": " closes: #7683 if multiple --config options are provided, crash with serverlesserror example node .\\bin\\serverless.js --config hello --config world error serverless error --------------------------------------- got 2 config paths: [hello, world].expected single value get support -------------------------------------------- docs:          docs.serverless.com bugs:          github.com/serverless/serverless/issues issues:        forum.serverless.com ", "commit_messages": " crash on config multiple cli inputs  add tests ", "linked_issue_titles": " serverless cron is not working with type error 'path' ", "title": "display error message on duplictate conf path"}
{"description": " fix sentence case requests by sigmavirus24 here:  added myself to authors. ", "commit_messages": " added space and sentence case  added space and sentence case as requested by sigmavirus24.    adding my name to authors.  adding myself to authors.  adding my name to authors ", "linked_issue_titles": "", "title": "add to authors and fix case"}
{"description": " a fix motivated by #29785. while i have noted in #44696 (comment) that different requests require different required paramters (overall, implementing the documentation change in that comment is probably the 'final' paramter requirements fix), the op in #29785 appears to be saying that name is required to use the module in the first place. linode ansible version ansible 2.7.0.dev0 (mark-name-required-#29785 f112e314b7) last updated 2018/08/27 00:25:34 (gmt +200) config file = none configured module search path = [u'/home/decentral1se/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/decentral1se/hobby/ansible/lib/ansible executable location = /home/decentral1se/hobby/ansible/bin/ansible python version = 2.7.13 (default, nov 24 2017, 17:33:09) [gcc 6.3.0 20170516] in the running of the test, i can't seem to test against the output but have manually verified: lib/ansible/module_utils/basic.py:2367: systemexit -------------------------------------------------------------- captured stdout call --------------------------------------------------------------- {\"msg\": \"missing required arguments: name\", \"failed\": true, \"invocation\": {\"module_args\": {\"payment_term\": 1, \"displaygroup\": \"\", \"state\": \"present\", \"wait_timeout\": 300, \"swap\": 512, \"watchdog\": true, \"wait\": true}}} ", "commit_messages": " mark 'name' parameter as required.  closes  add the linode-python dependency for unit tests. ", "linked_issue_titles": "", "title": "mark 'name' as required. fixes #29785"}
{"description": " if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. ", "commit_messages": " fix avg time of grpc is not right.  merge remote-tracking branch 'origin/master'  fix avg time of grpc is not right.  fix avg time of grpc is not right. ", "linked_issue_titles": " the average response time of grpc is not right ", "title": "fix the response time of grpc is not right."}
{"description": " related to #14813 deprecates none in featureunion. two options to do the same thing is undesirable. ", "commit_messages": " enh deprecates none in feature union  enh deprecates none in feature union  doc adds todo  doc adds todo  sty ", "linked_issue_titles": "", "title": "dep deprecate none in featureunion"}
{"description": " there are several variations of alerts in the app: alertmessage .alert (bootstrap) styledwarning this pr aims to unify these as one alert component, as well as introduce a variation of alert that plays well with panels. todo: introduce alert component update alertmessage to use alert introduce panelalert replace styled warning with alert future pr: update all the various uses of bootstrap's .alert to use this component remove .alert and our overrides from sentry.less and shared-components.less introduce grid helper function fix nan value issue in snapshots by wrapping tests with <themeprovider> ", "commit_messages": " fix remove org positioning  add panelalert component  add box shadow ", "linked_issue_titles": "", "title": "one alert to rule them all"}
{"description": " issue: #11371 render iframes with &refid=$refid. pass refid over the channel when emitting events match events to refs first via refid, falling back to postmessage event origin. @tmeasday i removed a least code as possible. i could delete more of the compatibility code dealing with source. ", "commit_messages": " add refid to channel-postmessage  de-duplicate the code for switching between handling event from refs vs local iframe  add refid to iframe url  fix typings of channel-postmessage  sourcetype is always external when refid is given  change setstoriespayload to single type ", "linked_issue_titles": "", "title": "change event source to ref"}
{"description": " went to go play around in the code and add some of my own things, realized things were a little different here. things i changed: 1. pragma once the files that are missing it edit: zvecr says no 2. turn on bootmagic lite. the volcano 660 has a solid bottom so if a user forgets to put on a reset key in their keymap, it's back to dismantling 3. rgblight is enabled.....even though there is no rgb light on this board 4. backlight is enabled.....even though there is no backlight on this board 5. enabled command_enable for extra debugging prowess 6. audio_enable was included twice, once disabling and once enabling. assuming its enabling as why else would you have a speaker? my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " fix audio enable repetition  remove rgb led support as this board has no rgb lb leds  use pragma once  this board has no backlight support  enable command_enable  comment cleanups  setting bootmagic to lite as the first board thathat has this pcb has a solid bottom. if someone forgets to put in a reset key on their keymap, they are not going to have fun resetting the board ", "linked_issue_titles": "", "title": "clueboard rev4 updates aka volcano 660"}
{"description": " also see #3366, #3373. support .msg as file format option in spacy convert (already supported internally by goldcorpus) so training data can be provided as binary messagepack data. support .jsonl in goldcorpus so training data can be provided as jsonl. update spacy convert documentation. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " populate converter argument info automatically  add conversion option for msgpack  update docs  allow reading training data from jsonl ", "linked_issue_titles": "", "title": "improve converters and training data file formats"}
{"description": " commit ce_aaa_server module new module pull request ce_aaa_server.py ansible version ansible 2.3.0 config file = /etc/ansible/ansible.cfg configured module search path = ['/home/ansible-2.1.1.0/lib/ansible/modules/core/network/cloudengine', '/home/ansible-2.1.1.0/lib/ansible/module_utils', '/home/ansible-2.1.1.0/lib/ansible/modules', '/home/ansible-2.1.1.0', '/home/ansible-2.1.1.0/lib/ansible/utils/'] task [configure accounting scheme] ********************************************* task path: /usr1/code/openness/code/current/kvm/intg/test/testcases/test-ce_aaa_server.yml:58 using module file /usr/local/lib/python2.7/site-packages/ansible-2.3.0-py2.7.egg/ansible/modules/core/network/cloudengine/ce_aaa_server.py <ce_6850> establish local connection for user: root <ce_6850> exec /bin/sh -c '( umask 77 && mkdir -p \" echo $home/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160 \" && echo ansible-tmp-1487042119.19-256857505644160=\" echo $home/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160 \" ) && sleep 0' <ce_6850> put /tmp/tmpcgsfja to /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py <ce_6850> exec /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py && sleep 0' <ce_6850> exec /bin/sh -c '/usr/bin/python /root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/ce_aaa_server.py; rm -rf \"/root/.ansible/tmp/ansible-tmp-1487042119.19-256857505644160/\" > /dev/null 2>&1 && sleep 0' changed: [ce_6850] => { \"changed\": true, \"end_state\": { \"accounting scheme\": [ [ \"none\", \"default\" ], [ \"radius\", \"test1\" ] ], \"local user group\": [ \"manage-ug\", \"system-ug\", \"monitor-ug\", \"visit-ug\", \"wdz_group\" ], \"radius enable\": [ \"true\" ], \"radius template\": [ \"group1\", \"wdz\", \"w\", \"wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww\", \"test2\" ] }, \"existing\": { \"accounting scheme\": [ [ \"none\", \"default\" ] ], \"local user group\": [ \"manage-ug\", \"system-ug\", \"monitor-ug\", \"visit-ug\" ], \"radius enable\": [ \"true\" ], \"radius template\": [ \"group1\", \"wdz\", \"w\", \"wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww\" ] }, \"invocation\": { \"module_args\": { \"accounting_mode\": \"radius\", \"acct_scheme_name\": \"test1\", \"auth_pass\": null, \"authen_scheme_name\": null, \"author_scheme_name\": null, \"authorize\": false, \"domain_name\": null, \"first_authen_mode\": null, \"first_author_mode\": null, \"host\": \"ce_6850\", \"hwtacas_template\": null, \"local_user_group\": \"wdz_group\", \"password\": \"value_specified_in_no_log_parameter\", \"port\": 12345, \"provider\": null, \"radius_server_group\": \"test2\", \"ssh_keyfile\": null, \"state\": \"present\", \"timeout\": 10, \"transport\": null, \"use_ssl\": false, \"username\": \"rootdc\", \"validate_certs\": true }, \"module_name\": \"ce_aaa_server\" }, \"proposed\": { \"accounting_mode\": \"radius\", \"acct_scheme_name\": \"test1\", \"local_user_group\": \"wdz_group\", \"radius_server_group\": \"test2\", \"state\": \"present\" }, \"updates\": [ [ \"accounting-scheme test1\", \"accounting-mode radius\" ], [ \"radius server group test2\" ], [ \"user-group wdz_group\" ] ] } ", "commit_messages": " commit ce_aaa_server module  commit ce_aaa_server module  update ce_aaa_server.py  update ce_aaa_server.py ", "linked_issue_titles": "", "title": "contributing lib/ansible/modules/network/cloudengine/ce_aaa_server.py module to manage huawei data center cloudengine"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " added: initial files, more work needed  fixed: more classes  fixed: some fixes to incorrect types so that gods has no errors  improved: more strick tsconfig  fixed: tslint.json typo in filename  fixed: npm test errors  added: umd global var athenajs ", "linked_issue_titles": "", "title": "added definitions for the athenajs npm package"}
{"description": " plan is to cut another 2.x release, maybe 2.7182818284? also, bumps agp, compilesdk and targetsdk to latest bumps gradle and robolectric to more recent releases (opted not for latest to minimize build fixes) ", "commit_messages": " remove obsolete manifest stuff  gradle 6.1.1  agp 4.0.1  compile/targetsdk 30  robolectric 4.0.1  migrate to androidx  closes #2175 ", "linked_issue_titles": "", "title": "migrate 2.x branch to androidx"}
{"description": " previously this caused a crash in parsing. if/when we want to support this syntax, we will need to fix this crash. for now, it's enough to skip the code path and continue parsing in a non-nested fashion. fixes #24389 ", "commit_messages": " callback tag:disallow nested-object-param syntax  previously this caused a crash in parsing. if/when we want to support  this syntax, we will need to fix this crash.  update baselines ", "linked_issue_titles": " [3.0.0-dev.20180522] tsc crashes on parsing jsdoc with error \"debug failure. false expression\" (in parsetag) ", "title": "disallow nested object param syntax in callback tag"}
{"description": " based on comments from our beta release vote. issue: #1251 #1245 #1246  #1247 i do following adjustments: disclaimer file changed. add release_rc_tag into the release script. also need export this new env. variable. add rc(x) version control mechanism into release process add sha512 contents into vote mail add full urls of skywalking and its submodule projects git commitid fyi @apache/skywalking-committers all committers, to be advised, release doc has just updated. if anyone wants to lead further release vote, please follow this document. ", "commit_messages": " adjust release doc and script based on last release vote.  update ui declaimer file. ", "linked_issue_titles": "", "title": "update release doc and related script"}
{"description": " the current code uses fread (+ byte swapping) / fwrite (without byte swapping) and fread or freadendian/ fwrite for de-serialization and serialization. the resulting file is always written in host endianness, so reading on a host with different endianness requires byte swapping. all functions return the number of elements read or written which must be compared with the intended value. the new code always uses deserialize / serialize methods which return true for success or false for failure, like it is already done with the existing deserialize / serialize methods for a lot of classes. with the new api it will be very easy to switch to a fixed little endian file format as soon as it is used for all serialization code. ", "commit_messages": " add helper functions for serialization of simple data types  use tesseract::serialize, tesseract::deserialize  tfile: add helper functions for serialization of simple data types  use tfile::serialize, tfile::deserialize ", "linked_issue_titles": "", "title": "simplify api for serialization and add first users"}
{"description": " these two patches enable \"--relax\" and \"-fwhole-program\" to the linker and compiler of the marlin firmware.  these optimizations reduce overall code size and should also have an improvement to overall speed. for my printer, the size of the firmware went from 71109 bytes to 69203 bytes after applying these optimizations. ", "commit_messages": " use linker \"--relax\" option.  the \"relax\" option enables the linker to convert certain \"call\"  instructions to the smaller \"rcall\" instruction.  this reduces the  size of the resulting binary.  use gcc \"-fwhole-program\" optimization.  use \"whole program\" and \"link time optimization\" features of gcc.  the  whole-program optimization enables the compiler to evaluate the entire  firmware for optimization instead of just one code file at a time.  this leads to better overall optimizations. ", "linked_issue_titles": "", "title": "add additional optimization flags to makefile"}
{"description": " preparations for #7599 that are useful on their own. ", "commit_messages": " logind: simplify one conditional  don't bother with removing the directory if we didn't create it.  logind: fix misleading message  this message would also be emitted at boot for any user with linger  enabled, so \"logged in\" is the wrong term to use.  core: reuse slice_build_parent_slice  tree-wide: use special_root_slice  logind: use free_and_replace in one spot  no functional change.  mount: add option to specify uid= and gid=  the kernel needs two numbers, but for the user it's most convenient to provide the  user name and have that resolved to uid and gid.  right now the primary group of the specified user is always used. that's the most  common case anyway. in the future we can extend the --owner option to allow a group  after a colon.  [i added this before realizing that this will not be enough to be used for user  runtime directory. but this seems useful on its own, so i'm keeping this commit.]  generator: add helper function for writing unit files  it doesn't save too much, but it's a common pattern so i think it's worth  to factor this out. ", "linked_issue_titles": "", "title": "slice cleanups and systemd-mount --owner"}
{"description": " this pr resolves #1747 . an extra hyphen( - )  was appended to the url of contributors badge due to which the url was not correctly routing to all contributors section . this pr deletes the hyphen and fixes the url for all contributors badge. ", "commit_messages": " correcting the hyperlink to redirect to correct url.  corresponds to bug #1703  deleting the extra hyphen(-) that was incorrectly added. ", "linked_issue_titles": " issue with all contributors badge in readme.md file ", "title": "correcting the url to fix #1747  -  bugfix/1747"}
{"description": " override files. move esp32 env in extra file platformio_tasmota_env32.ini the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core tasmota_core_stage and esp32 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " delete platformio_override_esp32.ini  update platformio.ini  add files via upload  update platformio_override_sample.ini ", "linked_issue_titles": "", "title": "fix esp32 build env in platformio and merge"}
{"description": " incorporates and closes #5309. fixes #5399 adapts work by @omnipotence456 after #5354. adds note to get_schema_view docs. aside: i note, in passing, that include_docs_urls and the helper functions from documentation.py are essentially undocumented. i'll add an issue for that but want to address it separately. ", "commit_messages": " allow custom authentication and permission classes for docs view  document extra parameters to get_schema_view ", "linked_issue_titles": " allow `include_docs_urls` to configure schema view authentication ", "title": "allow setting custom authentication and permissions on docs view."}
{"description": " checklist closing issues: #issue i wrote some lines in the radare2book this patch is supposed to add the functionality given by the unix command find . in the future this functionality might enable fetures like recursive copy and remove ", "commit_messages": " added a recursive find function r_file_find()  changed lsrf to r_file_find ()  don't follow symlinks  changed the name of r_file_find() to r_file_dir_recursive() ", "linked_issue_titles": "", "title": "add recursive list functionality to libr/util/file.c"}
{"description": " fix issue with black failing on master and recent prs. add pre-commit as a required check. requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " fix(build): black failing on master  add pre-commit to required checks ", "linked_issue_titles": "", "title": "black failing on master, add to required checks"}
{"description": " resolving conflicts from #130 @keon changed modules names math ->  maths string -> strings queue -> queues ", "commit_messages": " minor updates in merge_sorted_k_lists.py  q.qsize()>0  ---->   not q.empty()      #  is more verbose and pythonic ;)  refactored module name shadowing builtin modules  minor fix  new changes  new changes  resolving conflicts from patch-1 ", "linked_issue_titles": "", "title": "resolve conflict from refractoring modules."}
{"description": " what did you implement: closes #4440. adds ability to specify regional endpoints for api gateway. : # serverless.yml provider: name: aws endpointtype: regional ... how did you implement it: adds the endpointconfiguration attribute when we compile the restapi resource. by default, it sets to edge, which is the default api gw setting. how can we verify it: i used this example: service: endpoint-test # the provider block defines where your service will be deployed provider: name: aws runtime: nodejs6.10 endpointtype: regional functions: helloworld: handler: handler.helloworld events: - http: path: hello-world method: get cors: true then run sls package and check the .serverless/cloudformation-template-update-stack.json file that the restapi resource has the endpointconfiguration defined as desired. todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " add endpointtype configuration  add docs on endpointtype configuration ", "linked_issue_titles": "", "title": "add api gateway endpoint configuration"}
{"description": " r-api for json dump format that was contributed in #1726 bugfix for #1845 bugfix for #1628 json dump example: data(agaricus.train, package='xgboost') bst <- xgboost(data = agaricus.train$data, label = agaricus.train$label, max_depth = 2, eta = 1, nthread = 2, nrounds = 2, objective = \"binary:logistic\") jdump <- xgb.dump(bst, with_stats = true, dump_format='json') cat(jdump) produces: [ { \"nodeid\": 0, \"depth\": 0, \"split\": 28, \"split_condition\": -9.53674e-007, \"yes\": 1, \"no\": 2, \"missing\": 1, \"gain\": 4000.53, \"cover\": 1628.25, \"children\": [ { \"nodeid\": 1, \"depth\": 1, \"split\": 55, \"split_condition\": -9.53674e-007, \"yes\": 3, \"no\": 4, \"missing\": 3, \"gain\": 1158.21, \"cover\": 924.5, \"children\": [ { \"nodeid\": 3, \"leaf\": 1.71218, \"cover\": 812 }, { \"nodeid\": 4, \"leaf\": -1.70044, \"cover\": 112.5 } ]}, { \"nodeid\": 2, \"depth\": 1, \"split\": 108, \"split_condition\": -9.53674e-007, \"yes\": 5, \"no\": 6, \"missing\": 5, \"gain\": 198.174, \"cover\": 703.75, \"children\": [ { \"nodeid\": 5, \"leaf\": -1.94071, \"cover\": 690.5 }, { \"nodeid\": 6, \"leaf\": 1.85965, \"cover\": 13.25 } ]} ]}, { \"nodeid\": 0, \"depth\": 0, \"split\": 59, \"split_condition\": -9.53674e-007, \"yes\": 1, \"no\": 2, \"missing\": 1, \"gain\": 832.545, \"cover\": 788.852, \"children\": [ { \"nodeid\": 1, \"depth\": 1, \"split\": 28, \"split_condition\": -9.53674e-007, \"yes\": 3, \"no\": 4, \"missing\": 3, \"gain\": 569.725, \"cover\": 768.39, \"children\": [ { \"nodeid\": 3, \"leaf\": 0.784718, \"cover\": 458.937 }, { \"nodeid\": 4, \"leaf\": -0.96853, \"cover\": 309.453 } ]}, { \"nodeid\": 2, \"leaf\": -6.23624, \"cover\": 20.4624 } ]} ] and it could be further fed, e.g., into jsonlite: library(jsonlite) jdump %>% fromjson(simplifydataframe = false) %>% tojson(auto_unbox = true) %>% prettify ", "commit_messages": " [r-package] json tree dump interface  [r-package] precision bugfix in xgb.attributes  [r-package] bugfix for cb.early.stop called from xgb.cv  [r-package] a bit more clarity on labels checking in xgb.cv ", "linked_issue_titles": "", "title": "json dump format and a couple of bugfixes"}
{"description": " checks an items off #40675 the current mechanics are unstructured and the tests is not future proof (if new attributes are added tests will not pick these up and fail). this pr generalises the construction and future proofs the tests. no user facing cahnge. ", "commit_messages": " create a cleaner copy mechanism and future proof tests  add gh number  name chg ", "linked_issue_titles": "", "title": "simplify styler copy mechanics and tests"}
{"description": " fixes #26279. context: the dockcross/manylinux2014-aarch64 image provides a broken version of libstdc++ that (if statically linked), causes #26279 we need to use a version of dockcross/manylinux2014-aarch64 that has gcc newer than 4.8 (because otherwise we won't be able to build grpc c core, since the compiler would be too old). when a version of dockcross/manylinux2014-aarch64 that has gcc 4.9.4, the resulting wheel won't be manylinux2014 compliant since the libstdc++ is too new (but at the same time we can't statically link libstdc++ since we know that's broken for some reason). the only reasonable solution in short term seems to be to compromise on the level of binary compatibility and publish  manylinux_2_24 compliant wheels instead of manylinux2014 (see  (the armv7l wheels were suffering from the same problem as reported in #26279, so i'm removing static linking of libstdc++ for armv7 as well). ", "commit_messages": " workaround #26279 at the expense of binary compatibility  correctly tag aarch64 wheels as manylinux_2_24 ", "linked_issue_titles": " free(): invalid pointer crash on specific import order (on arm64 linux) ", "title": "workaround #26279 by publishing manylinux_2_24 wheels instead of manylinux2014 on aarch64"}
{"description": " summary of changes: made _iterate_slices abstract in base class, moved pre-existing definition from base -> series where it was actually being called (dataframe already overrides) made _wrap_transformed_output abstract in base class, as both series and dataframe override this redefined _wrap_applied_output; this was abstract in base class before but its definition was not in sync with how the subclasses actually defined renamed _wrap_output to _wrap_series_output as it is only valid for seriesgroupby renamed _wrap_generic_output to _wrap_frame_output as it is only valid for dataframegroupby renamed _aggregate_generic to _aggregate_frame as it is only valid for dataframegroupby more to come in separate prs ", "commit_messages": " more abstractmethoderrors in base class  removed _wrap_applied_output with wrong signature  cleaned up naming conventions  aggregate as abstractmethod ", "linked_issue_titles": "", "title": "clean up abstract and naming definitions for groupby"}
{"description": " there are a few things to update in this chart. some of them have open prs, but unfortunately, the authors are not signing. bumping versions, not responding to reviews and so on. so this pr is to open the discussion and make drone chart up to date with fixing issues we already know. bump app version to 1.1.0 (a few of us tested it ok). fix grpc  (not in drone 1)  - this is also in #13866 but its incomplete, we need to remove services-grpc also. fix indentation of extracontainers pr: #14284 add drone_agents_enabled = true when it's not kuberentes enabled (agent). #13866 add tolerations #13866 i think set the drone_rpc_host in the server deployment it's important also, the pr  #12864 seems to be attended. by @morriz  - i ve bumped the chart version to  2.0.1 so we can merge this pr with the rc-15 before. dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " master uptodate  bump versions (chart and app)  bump app version  fix drone_rpc_server with no rpc and  if its not k8s enabled set drone_agents_enabled  fix indentation of extracontainers pr:#14284  no grpc in drone 1.0  bumb chart version to 2.0.0-rc.15  add tolerations #13866  add tolerations documentation #13866  bump chart version to 2.0.1 ", "linked_issue_titles": "", "title": "bump app version - fix grpc - and other unattended pr's."}
{"description": " the general principle here is \"if you're going to show line/column, you want a display filename, not a buffer identifier\". follow-up to #19022; thanks to @davidungar and @codafi for reminding me to go check on other issues. review requests: @anemet for the optimization record change @nkcsgexi for the ide/sourcekit/parse changes @douggregor for the run-time error message change i filed sr-8662 for a case where sourcekit may or may not be doing the wrong thing. there are also still a few suspicious uses of getidentifierforbuffer that i'm not sure about, all of which happen to be in @nkcsgexi's components: swift::writeeditsinjson is using offsets rather than line/column numbers, but i'm not sure what it would want to do for #sourcelocation or the vfs swift::ide::getlocationinfo is also using offsets rather than line/column numbers, but \"location info\" sounds like something that needs to be displayed to the user fixitapplydiagnosticconsumer::handlediagnostic is going to rewrite buffers directly, but it's unclear whether doing that is the right thing for code using #sourcelocation (similar to sr-8662, but for migration). groupnamecollectorfromjson::getgroupnameinternal is only used when building the standard library, but it should probably honor #sourcelocation. i just didn't want to touch it without being sure, and it's not immediately relevant. ", "commit_messages": " [ide] honor #sourcelocation in comment-to-xml conversion  [ide] honor #sourcelocation in swift-ide-test's comment printing  [sourcekit] honor #sourcelocation in reporting diagnostics  [silgen] honor #sourcelocation for run-time error messages  we use this when an optional unwrap fails and when a swift-3-style  @objc entry point is used.  [sil] honor #sourcelocation in optimization record yaml files  previously, we were using the physical buffer name but the virtual  line number, which is bogus.  stop using sourcemanager::getbufferidentifierforloc to find buffer ids  the right way is findbuffercontainingloc. getbufferidentifierforloc is  both slower and wrong in the presence of #sourcelocation.  i couldn't come up with a test for the change in ide/utils.cpp because  refactoring still seems to be broken around #sourcelocation. i'll file  bugs for that.  remove sourcemanager::getbufferidentifierforloc  and tidy up doc comments for other methods that do or don't respect  '#sourcelocation'.  'getbufferidentifierforloc' is no longer useful: it doesn't  consistently return either the name of an actual buffer or the name of  a file suitable for diagnostics. as seen in the previous commit, all  remaining uses of it were wrong anyway. remove it. ", "linked_issue_titles": "", "title": "honor #sourcelocation filenames in several more places"}
{"description": " with these modifications and the partially masked test, the r package xgboost 0.6 has been submitted to cran. ", "commit_messages": " fix cran check  change required r version because of utils::globalvariables  merge back  temporary commit, monotone not working  fix test  fix doc  fix doc  merge back  merge back  fix cran note and warning  improve checks  fix urls  merge back  fix cran check ", "linked_issue_titles": "", "title": "fix for cran submission of xgboost 0.6"}
{"description": " this depends on #6635 #6655 #6637. the macos sdk path and version was made configurable, so one can overwrite the autodetected values in the case of fail detection and none apple toolchains. with the removal of optional force unwrappings we broke building on macos 10.12, this is fixed before the migration to swift 5/4 the swift 5 migration was tested on various platforms and combinations of toolchains. building works with all apple provided toolchains from 10.12.6/xcode 9.1/swift 4 onwards. in some combinations the swift 5 toolchains from swift.org work too. i tired to keep all compatibility stuff in a separate file. that way it's less intrusive and can easily be removed later when unneeded. success: macos 10.12.6\tsdk10.13\t\txcode 9.2\tswift 4.0.3 macos 10.13.6\tsdk10.13\t\txcode 9.4\tswift 4.1.2 macos 10.13.6\tsdk10.14 (manually)\txcode 9.4\tswift 5 (swift.org toolchain) macos 10.13.6\tsdk10.14\t\txcode 10.1\tswift 5 (swift.org toolchain) macos 10.14.4\tsdk10.14\t\txcode 10.2\tswift 5 fail: macos 10.12.6\tsdk10.14 (manually)\txcode 8.3.3\tswift 5 (swift.org toolchain) macos 10.12.6\tsdk10.14 (manually)\txcode 9.1\tswift 5 (swift.org toolchain) macos 10.13.6\tsdk10.13\t\txcode 9.4\tswift 5 (swift.org toolchain) the swift.org toolchain can be used like this. sdk path and version might need to be specified depending on your installed xcode version export toolchains=swift macos_sdk=\"path/to/sdk10.14.4\" macos_sdk_version=\"10.14.4\" ./waf configure no rebase of the existing pr since the changes made afterwards made rebasing a pain, and because a lot of work was put into it to make the build actually work on older setups. the code also got a style improvement. tests are appreciated. ", "commit_messages": " build: don't check for swift when disabled  build: add all configure flags as conditional flags to swift compiler  build: add support for swift toolchains not provided by apple  the xcode-select tool only properly works with apple provided toolchains  but not with third party ones from swift.org. in the latter case the  swift compiler executable is found in the proper path but the swift libs  from the xcode or command line tools will be picked. this leads to a  not wanted discrepancy of the swift compiler and libs and possible  errors.  instead of relying on the xcode-select tool search for the libs relative  to the swift executable. that relative path seems to be the same for all  toolchains. if for any reasons a swift executable is not found in the  relative path, fall back to the old xcode-select method.  furthermore, both static and dynamic libs will be searched for but only  the former will be used for now. this is a preparation for the upcoming  swift 5 migration.  build: make swift lib and compiler paths configurable via env vars  build: add swift dynamic linking support  this is in preparation for the upcoming swift 5 transition, where static  linking was replaced by dynamic linking the swift libraries as the  preferred way, by apple. furthermore apple removed the static swift libs  from their dev tools starting with xcode 10.2/swift 5.  because of abi incompatibility dynamic linking for swift versions prior  to 5 doesn't use the system lib path for the dynamic swift libs.  for now static linking is still the default, but that will be changed  when swift 5 support is added and swift 3 support is dropped.  fixes #6232  osxbundle: print the output of the dylib-unhell call  osxbundle: bundle the dynamic swift std library when needed  build: add check for macos sdk version  this provides an easy way to check for a specific macos sdk version and  with that the availability of features.  cocoa-cb: conditional compilation for dark mode and material features  fixes #6621  build: make macos sdk path and version configurable via env vars ", "linked_issue_titles": "", "title": "migrate to swift 5 with swift 4 fallback"}
{"description": " this change fixes a race condition in shard group failure callbacks and ensures that we set the correct flag on initial stored responses. relates #49931 closes #53360 ", "commit_messages": " fix race condition in shard group failure callback  shard group failure callbacks should be executed before incrementing  the total operations. this is required to ensure that we don't notify  a shard group failure **after** the completion callback.  fix the initial response stored in async search index  this change ensures that we set the isrunning flag to false  when storing the initial response of an async search request.  remove the awaits fix  disable cacheability of blockquerybuilder ", "linked_issue_titles": " [ci] asyncsearchactiontests fails unpredictably ", "title": "fix sporadic failures in asyncsearchasynctests"}
{"description": " in zipimport.c: add a check whether zlib.decompress() returned a bytes object. in test_zipimport.py: add a test to verify that the assertion failure is no more. ", "commit_messages": " init commit  fix news.d item  add @cpython_only  use zip_deflated explicitly in the test ", "linked_issue_titles": "", "title": "fix an assertion failure in zipimporter.get_source() in case of a bad zlib.decompress()"}
{"description": " there are some reports of zonewindowdrawing instances failing to initialize. this refactoring should make debugging that easier. pr checklist applies to #xxx cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request validation steps performed run fz and make sure it works. ", "commit_messages": " separate a big function call to several functions  formatting ", "linked_issue_titles": "", "title": "refactor a function in zonewindowdrawing"}
{"description": " fixes #6575 microsoft reviewers: open in codeflow ", "commit_messages": " use whitespace insensitive compare for indentical override detection  fixes #6575  change files ", "linked_issue_titles": " \"identical override\" detection should be whitespace insensitive instead of line ending insensitive ", "title": "use whitespace insensitive compare for identical override detection"}
{"description": " hi, i am improving the oal based on @arugal 's new pr, . now, i could split the one and only official_analysis.oal into separated files, including core jvm dotnet envoy core is also active due to trace, mesh, or so11y. others are not activated when the receivers are open. ", "commit_messages": " split the official_analysis.oal into different parts  add envoy oal define. ", "linked_issue_titles": "", "title": "make oal controlled by the receivers."}
{"description": " this continues the work on splitting up const_fn into separate feature flags: const_fn_trait_bound for const fn with trait bounds const_fn_unsize for unsizing coercions in const fn (looks like only dyn unsizing is still guarded here) i don't know if there are even any things left that const_fn guards... at least libcore and liballoc do not need it any more. @oli-obk are you currently able to do reviews? ", "commit_messages": " move 'trait bounds on const fn' to separate feature gate  separate feature flag for unsizing casts in const fn ", "linked_issue_titles": "", "title": "further split up const_fn feature flag"}
{"description": " the fieldmapper infrastructure currently has a bunch of shared parameters, many of which are only applicable to a subset of the 41 mapper implementations we ship with.  merging, parsing and serialization of these parameters are spread around the class hierarchy, with much repetitive boilerplate code required.  it would be much easier to reason about these things if we could declare the parameter set of each fieldmapper directly in the implementing class, and share the parsing, merging and serialization logic instead. this commit is a first effort at introducing a declarative parameter style.  it adds a new fieldmapper subclass, parametrizedfieldmapper, and refactors two mappers, boolean and binary, to use it. parameters are declared on builder classes, with the declaration including the parameter name, whether or not it is updateable, a default value, how to parse it from mappings, and how to extract it from another mapper at merge time.  builders have a getparameters method, which returns a list of the declared parameters; this is then used for parsing, merging and serialization. merging is achieved by constructing a new builder from the existing mapper, and merging in values from the merging mapper; conflicts are all caught at this point, and if none exist then a new, merged, mapper can be built from the builder.  this allows all values on the mapper to be final. other mappers can be gradually migrated to this new style, and once they have all been refactored we can merge parametrizedfieldmapper and fieldmapper entirely. ", "commit_messages": " first go: need to fix merging with buildercontext  dedicated tests for parametrized mapper  tests  precommit ", "linked_issue_titles": "", "title": "add declarative parameters to fieldmappers"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " types for css-to-react-native  fix test file  fix prettier  fix defs by ", "linked_issue_titles": "", "title": "css to react native types"}
{"description": " this should be pretty straight forward. my only concern are changes in cguicontrolfactory - is it safe to not set fallback navigation there? we won't do anything if action list is empty. this change is needed to set navigation using replace=false flag (we can't set actions because list isn't empty - fallback navigation is there) ", "commit_messages": " don't assign navigation path to itself if <onx> isn't specified  action list will be empty so we won't execute anything anyway  add cguicontrol::setnavigationaction to allow setting single action, add cguiaction(int controlid) ctor to quickly create navigation action  redo applying navigation to grouplist child controls  fixes conditional navigation in grouplist ", "linked_issue_titles": "", "title": "fix conditional navigation in grouplist"}
{"description": " if keepinview is enabled, a listener for moveend is set to the map: leaflet/src/layer/popup.js line 163 in 3466cbb events.moveend = this._adjustpan; _adjustpan calls panby: leaflet/src/layer/popup.js line 276 in 3466cbb .panby([dx, dy]); and then _resetview is called because the popup latlng/ offset is not in the map size (and animate is not set), in _resetview the moveend event is fired without panning the map and then moveend event ist fired from keepinview and it is starting again. leaflet/src/map/map.js lines 322 to 325 in 3466cbb if (options.animate !== true && !this.getsize().contains(offset)) { this._resetview(this.unproject(this.project(this.getcenter()).add(offset)), this.getzoom()); return this; } to prevent this, we can add to the panby call in _adjustpan the option {animate: true}. this will force that _resetview can't be called and we don't end up in a recursive call. this will only happen if the function _adjustpan is called over the moveend event, so i add animate: true if the event object is set. maybe this is not the best way but would be a solution. fix: #5035 ", "commit_messages": " fix keepinview recursion #5035  fix test ", "linked_issue_titles": " calling fitbounds with a keepinview: true popup present can cause leaflet to lock up ", "title": "fix popup keepinview if the map needs to panned over a long distance"}
{"description": " this pr removes the margin-top from the dropdown toolbar and sets the height of the list items to 32px so that it is properly centered via flexbox. i additionally centered the restart icon as it was off-center before. before after fixes #51569 ", "commit_messages": " vertically center the restart icon  remove top margin and set height for flexbox to vertically align dropdown  clean up svgs ", "linked_issue_titles": " dropdown in debug toolbar is not vertically centered ", "title": "center dropdown in debug toolbar"}
{"description": " note: we're experiencing a high volume of prs to this repo and reviews will be delayed. please host your own chart repository and submit your repository to the helm hub instead of this repo to make them discoverable to the community. here is how to submit new chart repositories to the helm hub. fix the issue of wrong typos in 57858d7 (0a8651f) upgrade mysql image version to 5.7.30 (changes in mysql 5.7.30 (2020-04-27, general availability)) upgrade busybox image version to 1.31.1 (25 october 2019 -- busybox 1.31.1 (stable)) upgrade dduportal/bats image version to 1.1.0 (release notes) (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #22253 dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " fix typos in deployment template  mysql to 1.6.4 version ", "linked_issue_titles": " [stable/mysql] typo in deployment.yaml ", "title": "mysql chart version bump to 1.6.4"}
{"description": " adds rgb functionality to keymap.  can be compiled against both master and develop branch keymap changes - adds rbg control keys in fn layer similar to glorious core default fn keys encoder changes - fn layer - change rgb idle timeout - holding left shift, change layers - holding right shift, navigate page up/down new led/rgb functionality - rgb idle timeout (default 5 minutes) - can be changed in fn layer with < and > or encoder - setting to zero disables timeout - indicators in fn layer using rgb in fn and number rows to show the timeout in minutes - led address location map as enum definition - led group arrays for arrows, numpad, f row, num row, left and right side leds - default startup in single mode with default colour - capslock, scroll lock, and num lock (not set) indicator on left side led - layer indicator on right side led - fn key light up red when fn layer activate - win key light up red when win lock mode enabled - layer 2 activation lights up numpad area my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add rgb functions; compatible with master/develop  readme update ", "linked_issue_titles": "", "title": "jonavin gmmk pro keymap add rgb functionality"}
{"description": " in the other classes (pixmappackerio) there is a useindexes flag, but i can't see anything that this could be added to. in pixmappackerio there is parameters that it can be added to, but i'm not seeing an obvious comparison in pixmappacker. alternative idea would be to overload the method, so that the original signature is still available to people, but now it could include the option to pass through useindexes, rather than having it set to true as default. (personally i think it should be true as default, as this doesn't break anything, unless you intentionally call your image files _01.png, _02.png on purpose and don't do that for animations. ", "commit_messages": " [pixmap packer io] added index based on file name, so can be used for animations  update pixmappackerio.java  default useindexes to false.  merge remote-tracking branch 'upstream/master'  - added indexes for animations to work in updatetextureatlas ", "linked_issue_titles": "", "title": "added index usage in pixmappacker for updatetextureatlas (currently missing so can't create animations)"}
{"description": " that seems to have been an old hack. instead, let sbrk/brk handle it themselves, as they otherwise do all the handling of that value. this is also important for pthreads, since sbrk/brk can do this atomically, while if the logic is split into a called function that's much less clean. ", "commit_messages": " don't update the sbrk location in emscripten_resize_heap() - leave that to sbrk, which does it anyhow  fix ", "linked_issue_titles": "", "title": "don't set *dynamictop_ptr in memory growth code"}
{"description": " win: implement double-clicked event. win: fix regression caused by #2328 that bounds is always empty. win: pass modifers in clicked events. use the dom's way of telling modifiers. ", "commit_messages": " win: implement double-clicked event  docs: don't say things that are expected  win: set guid when getting icon's bounds  win: pass modifers in 'clicked' events ", "linked_issue_titles": "", "title": "fix a few things of tray"}
{"description": " this fixes the same problem as #3310 but in a slightly different way: instead of maintaining the minimum resources needed by tasks in the ready queue and skipping going over the tasks there, it keeps an index on which resource shape a task is from, which makes it fast to determine which tasks are of a given resource shape. this pr implements the simplest version of this idea and there is a number of refinements that could be applied (avoiding the task copies, implementing a more clever strategy to avoid head-of-line blocking). it has the advantage over #3310 int that the datastructure allows o(1) in determining which tasks to dispatch (although it currently is more expensive than that, but cheaper than in the master, and also cheaper than in the other pr; the strategy there would break down if the ready queue contains zero-resource tasks). it can also facilitate smarter head-of-line blocking avoidance in the future. it has the disadvantage that it doesn't preserve approximate fifo order like the other pr does. closes #3194 closes #3188 ", "commit_messages": " put queues outside  working version, still needs to be optimized  implement round robin  proper round robin  fix spillback  update  fix  cleanup  more cleanups  fix  fix  add documentation  explanation for hash combiner ", "linked_issue_titles": " task submission is extremely slow when many tasks are queued.  task dispatch iterates over entire task queue even when no resources are left ", "title": "ready queue refactor to make dispatching tasks more efficient"}
{"description": " this breaks a potential deadlock between worker requests for objects (through ray.get or ray.wait) and arguments of queued tasks, when the amount of memory is limited. see #14886 for more details. the fix is to split the request queue in the pullmanager into two queues, one for requests made by a worker and one for arguments of a queued task. the interface is pretty much the same as before, but the implementation is a bit more complicated because requests can now be served out-of-order (e.g., if a worker request is submitted after a task request). closes #14886. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " split queues  regression test  unit tests ", "linked_issue_titles": " ray.get fetches not prioritized in pullmanager (can lead to deadlock with pull manager memory capping) ", "title": "prioritize worker requests for objects over queued task arguments"}
{"description": " description: as promised, here is a pr to switch homekit controller over to use config entries, which i'm hoping is ready for 0.94. (if this pr is ready before 0.93 leaves beta, please don't cherry pick it into 0.93. we are waiting for 0.94). i am aware of #23802 and that i'll potentially need to rebase if that is merged first. the config flows themselves were already added a few releases ago, this adds the async_setup_entry handlers and enables the flows, and removes the old configurator code. there is currently no configuration.yaml stuff for homekit controller so we don't try to preserve the old setup_platform entry points. we have pretty high test coverage (on the tip of my dev branch which has a few extras its >98% for all modules) for config flow and the entities in general - we just have to update common and all the tests carry on working with the new code. this doesn't add device registry stuff, but i already have a branch lined up with device registry support ready to go after this. also, after this is merged i can also remove homekit_controller from .coveragerc. @martinhjelmare sorry to tag you directly, but you've had some really good feedback for me before and as this is probably the biggest change i've submitted i was hoping i could trouble you for some here as well checklist: local tests pass with tox. your pr cannot be merged unless tests pass new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " fix user initiated pairing + show more user friendly name  add lock around async_refresh_entity_map  migrate homekit_controller to config entries. ", "linked_issue_titles": "", "title": "adopt config entries for pairing with homekit accessories"}
{"description": " tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry in testing.pyx we keep a list of numeric dtypes and use that for type checking. but we have functions that do this in tslibs/util.pxd so it's better to use those instead ", "commit_messages": " implement is_real_number_object  use is_real_number_object in testing.pyx  rename is_comparable_as_number -> is_comparable_as_real_number ", "linked_issue_titles": "", "title": "de-duplicate numeric type check in _libs/testing"}
{"description": " this pr creates a new system of onboarding for the aws lambda node integration that involves installing an integration instead of setting up the sdk. pre-installation view: post-installation view: ", "commit_messages": " adds integration setup  fix ", "linked_issue_titles": "", "title": "adds integration setup to onboarding"}
{"description": " added the sentraq number pad keyboard kit to qmk in the sentraq vendor directory. checklist: my code follows the code style of this project. i have read the contributing document. ( ", "commit_messages": " added qmk config for sentraq number pad keyboard.  sentraq number pad documentation cleanup.  mend  added json for configurator.  small documentation tweaks.  updated the layouts to use the default layouts that match.  uncommended user level functions in keymap, left custom keycode/macro code commented but documented why.  switched to #pragma once from #ifndef structure in header file.  moved sentraq number pad to sentraq creator directory.  renamed sentraq_number_pad to number_pad now that it's nested in the sentraq directory.  updated references inside the files for the keyboard rename and nesting. ", "linked_issue_titles": "", "title": "sentraq number pad rgb diy kit"}
{"description": " load the docs part of rendering + the docs page/container lazily in webpreview. results for react-ts, this reduced: initial development bundle from 12.6mb -> 11.1mb = 14% saving initial production bundle from 5.5mb -> 4.8mb = 13% saving caveats / questions this adds a dependency on @storybook/addon-docs from @storybook/preview-web. we might want to make it an optional peer dep? changing parameters.docs.container/page to be strings (or maybe symbols?) is technically a breaking change. i'm not sure anyone would look at them directly. we might want to feature flag this? changing parameters.docs.container/page to be getcontainer/page is technically a breaking change. i'm not sure anyone would look at them directly. we might want to feature flag this? i guess it shows up on bundle size tracking somewhere? ", "commit_messages": " split docs rendering from previewweb  don't set docs container etc as parameters  so we don't need to import docs in a preview config entry. ", "linked_issue_titles": "", "title": "lazy load docs to reduce bundle size"}
{"description": " this uses the new fuzzaldrin library for core scoring and fuzzy filtering so it can be used in packages freely. refs #950 ", "commit_messages": " replace stringscore/fuzzy-filter with fuzzaldrin  upgrade to settings-view@0.29.0 ", "linked_issue_titles": "", "title": "extract string score and fuzzy filter"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fix segmentation fault when the table has skip indices and vertical merge happens. ", "commit_messages": " trying to fix vertical merge  remove redundant changes  remove redundant changes ", "linked_issue_titles": "", "title": "fix segmentation fault in vertical merge with skip indices"}
{"description": " related issue #4052 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " fix mypy error for frequent_pattern_graph_miner.py  fix mypy error for markov_chain.py ", "linked_issue_titles": "", "title": "fix type annotations for graphs"}
{"description": " add info.json change keymap to layout change #includes to qmk_keyboard_h added note on how to fix the flickering in switch lighting problems ", "commit_messages": " add additional readme notes on how to fix the flickering backlight issue  add qmk configurator support ", "linked_issue_titles": "", "title": "add qmk configurator support for org60"}
{"description": " this should close #10339 also fixes some coverity issues in canvas.c: if the realloc() inside expand_line fails, instead of freeing the entire canvas, just abort the write, or else all future writes will fail (and from what i understand there were many defects just for this problem) before considering merging, i would like to wait to check if #10339 is really fixed (i was only able to reproduce it in a virtual machine) ", "commit_messages": " fix crop utf8 in canvas  fix coverity defects ", "linked_issue_titles": " v! glitches when scroll horizontally ", "title": "fix panels horizontal scroll glitch + fix some coverity defects"}
{"description": " addresses tr-356 feature: updated the design of the modal shown when there is a new version of cypress available. added 'copy to clipboard' buttons for upgrade commands. before (project mode) before (global mode) after (project mode) after (global mode) n/a has the original issue been tagged with a release in zenhub? n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? ", "commit_messages": " start test server automatically  update footer design  remove update banner  remove more references to update banner  add source param to changelog links  remove padding right on footer  blur footer buttons after clicking  redesign update modal, add copy to clipboard  abstract lifecycle hooks usage ", "linked_issue_titles": "", "title": "redesign desktop gui updates modal"}
{"description": " what did you implement: closes #2981 how did you implement it: catch the error, then check for specific error message \"no updates to be performed\".  continue execution if it is this message, otherwise throw the error to be caught by the next error handler how can we verify it: re-deploy an already deployed service without any changes and verify that it does not error out with error code 1 service: service provider: name: aws runtime: nodejs4.3 # remove need for functions so that a re-deploy will bring up the error #functions: #  hello: #    handler: handler.hello resources: resources: s3bucket: type: \"aws::s3::bucket\" todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config/commands/resources change ready for review message below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " do no fail when a stack requires no updates  do no fail when a stack requires no updates  resolve(data)  added period to message  new attempt  added comment  updated comment  handle error  fix lint errors  add tests and small refactor ", "linked_issue_titles": "", "title": "fix \"no updates to be performed.\" throwing error code 1"}
{"description": " update docs branch with #11920 #12890 #12981 #13036 #13050 ", "commit_messages": " researching docker hub account linking and automated builds details  (cherry picked from commit a55f8e1ce734035a77cc13d1e2f42dbef41d418e)  update the docker hub account, org and group documentation and images  (cherry picked from commit 5cec69a7b3ea12f9595e017eb27826ff9ad2962b)  spelling fix from marc merlin  (cherry picked from commit bba5fd8caa35d5edf8b68e593eafb277394a6989)  add a userguide to cover the uses of hub before creating new repositories  (cherry picked from commit 9da3a848abea56dff960baa8428dc073b70ec1de)  conflicts:  docs/sources/docker-hub/index.md  docs/sources/docker-hub/repos.md  dhe documentation update  (cherry picked from commit 59bfee2fa4f178660fa4cb2a9d18c924e86595a7) ", "linked_issue_titles": "", "title": "post 1.6.1 docs refresh of hub and dhe docs (on docs branch)"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). add src parameters:  fix invalid argument definitions:  include tests for your changes ", "commit_messages": " update apidoc-tests.ts  fix apidoc argument typings  update apidoc-tests.ts ", "linked_issue_titles": "", "title": "fix wrong args + add src param"}
{"description": " edited 3 buttons to tertiary styling. includes db migration (follow approval process in sip-59) ", "commit_messages": " changed margin right on warning icon to 8px  fixed to grid units from pixels  changed three buttons styles to tertiary ", "linked_issue_titles": "", "title": "three button styles to tertiary"}
{"description": " this pr makes the tf longformer-like models compliant with amp. all the slow tests are passing as well for these models. these two models cannot be xla compliant for now, as it seems that tf.where cannot be used in xla if the x and y parameters are none. see the _get_global_attn_indices method which has this case. i have opened an issue on the tf repo in order to ask if it is an expected behavior or a bug. ", "commit_messages": " amp  add led  apply style ", "linked_issue_titles": "", "title": "making tf longformer-like models compliant with amp"}
{"description": " partially fixes #14312 fixes the following items: fastica, [whitening_] the matrix projecting data onto the first principal components. fastica, [mean_] the mean over features nmf, [n_components_] this attribute is same to the n_components parameter if it was set. otherwise, it is same with n_features gaussianrandomprojection, [n_components_] just a typo fixed: n_component_ -> n_components_ sparserandomprojection, [n_components_] just a typo fixed: n_component_ -> n_components_ pca, [n_features_] the number of features in the data matrix the pca transformer was fitted on. pca, [n_samples_] the number of samples in the data matrix the pca transformer was fitted on. ", "commit_messages": " update documentation to nmf  describe the n_components_ attribute in addition to n_components parameter.  the will differ it no n_components value given to the constructor.  fix typo in docstring for gaussianrandomprojection  there is an attribute named n_components_, not n_component_  update docstring for sparserandomprojection  the n_components_ attribute was referred to as n_component_  update docstring for fastica  document the fastica.mean_ attribute. ", "linked_issue_titles": " ensure all attributes are documented ", "title": "fix attribute mismatches in documentation strings."}
{"description": " you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like searched for similar pull requests what is the purpose of your pull request? description of your pull request and other information an experimental p/invoke based system proxy implementation. main goal is remove all blob in net-core version. ", "commit_messages": " backport wininet from shadowsocksrr  migrate to wininet  drop sysproxy  platform and required service check for wininet  toggle menu item enable by wininet state ", "linked_issue_titles": "", "title": "drop sysproxy.exe in net-core version"}
{"description": " add native support for cpu 128 float.  cupy doesn't have float128, and cuda treats long double as double in device code. convert boolean and float16 in python. the c api for constructing dmatrix from numpy array added in #6998 is renamed from array to dense for consistency. close #6999 . ", "commit_messages": " error message.  change c api name.  test for all primitive types from array.  * add native support for cpu 128 float.  * convert boolean and float16 in python. ", "linked_issue_titles": " libxgboost.so: undefined symbol: xgboostergetstrfeatureinfo ", "title": "support for all primitive types from array."}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. class socket extends eventemitter  client#conn, socket#conn is an instance of engine.socket, including properties \"request\" and \"upgraded\".    increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"../tslint.json\" }. ", "commit_messages": " class socket extends eventemitter    client#conn, socket#conn is an instance of engine.socket, including properties \"request\" and \"upgraded\".        add a test.  add my credit. ", "linked_issue_titles": "", "title": "[socket.io]more information of class \"socket\""}
{"description": " takes 'churn_rates\" data from rabbitmq api/overview and adds the chart to netdata front end.  the structure of the data parser enables a simple addition of the metrics that are needed to the existing data structures. ", "commit_messages": " added chart for churn rates of connections, channels, and queues  clear comments ", "linked_issue_titles": "", "title": "add chart for churn rates"}
{"description": " set settings.enablebytecodecacheing to true in the reactinit.cpp file to enable this feature. default will be false. helps with reducing boot up time. microsoft reviewers: open in codeflow ", "commit_messages": " added basic script store  add basic prepared script store  added code for script store and trygetpreparedscript  added ability to read and write buffer from/to local file  changed code style to match other files in utils folder  made writing bytecode generate appropriately sized file, removed wrappers from bytecode manager  made reading and writing work, removed unneeded wrapper  set default bytecode caching to false  address comments  merge master  use modified date not created ", "linked_issue_titles": "", "title": "implemented uwp scriptstore and preparedscriptstore to allow caching scripts as bytecdoes"}
{"description": " since the are already in tasmota arduino core 2.7.4.1 the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " delete core_esp8266_waveform.cpp  delete core_esp8266_waveform.h  delete core_esp8266_wiring_digital.cpp  delete core_esp8266_wiring_pwm.cpp ", "linked_issue_titles": "", "title": "remove redundant arduino core files from tasmota..."}
{"description": " renamed outdep to out_dep. added a simple test for .d files generated from -mmd. ", "commit_messages": " fixed dependency files not being saved away if using -mmd or similar.  fixed timestamps on object files extracted from archives during link.  this affects builds that use absolute paths to object files when adding to library archives, causing unnecessary archives.  renamed outdep to out_dep.  added test for change for issue #1732. ", "linked_issue_titles": "", "title": "further changes for issue #1732"}
{"description": " another step towards #3016. fixes #4216. changes in this pr: removes lightgbm-custom pointers to r data (r_real_ptr(), r_int_ptr()) with the standard equivalents from rinternals.h (real(), integer()) converts arguments on the c++ side that are accessed that way from lgbm_se to sexp description r is a dynamically-typed language. you can run code like x <- c(1, 2, 3) without declaring that x is a numeric array, and r will just figure it out. r makes this possible by storing data for an object in a structure called a sexprec. that structure will contain different data based on the r class (integer, character, function, etc.). libraries can reference that data in c code using a type, sexp, provided by rinternals.h. libraries can also get a pointer to a particular type of data within a sexprec using other functions provided by rinternals.h, for example real() to get a pointer to its numeric data. as described in #4216, the internal details of the sexprec struct can change between different versions of r. sexp is the official r api into that struct, and by using it libraries can reliably stay compatible with multiple r versions. this pr's changes fix a bug that currently exists when using {lightgbm} with r 3.6, and protects {lightgbm} from similar bugs in the future. for more details on this, see  notes for reviewers this pr does not depend on #4242 or #4247 ", "commit_messages": " real pointer for matrix  remove r_real_ptr  remove r_int_ptr  add test ", "linked_issue_titles": " (r) functions that replace r headers are not compatible with all r versions ", "title": "use r standard routines to access numeric and integer array data in c++"}
{"description": " first commit is just for debugging. it revealed that something is leaking memory after each compilation and it's unclear what. review with whitespace ignored. this leak leads to #28923 failing size:snapshot. though we can live with the leak for now since azure pipelines have 7gb of ram so we can just increase max-old-space-size to 4gb (up from 2) ", "commit_messages": " limit concurrency  increase memory limit ", "linked_issue_titles": "", "title": "increase memory limit for size:snapshot"}
{"description": " original pull-request #24898 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " allowed s3 key to be empty.  fixed unit tests accoording to the fix.  fix. ", "linked_issue_titles": "", "title": "fixed bug with declaring s3 disk at root of bucket"}
{"description": " this adds a new conf true/false option to allow the user to draw message lines that begin and end at same place as right angles, rather than curved lines. ", "commit_messages": " created option for right angle arrows  make path a bit wider  tweak for lint ", "linked_issue_titles": "", "title": "add option for right angles"}
{"description": " new features apis cherry pick 4 amp related pr into 2.0 branch: 29756 29621 29597 29562 ", "commit_messages": " optimizer trans momentum (#29597)  * merge amp related function in momentum from paddle.fluid.contrib.optimizer into paddle.optimizer.  * add unittest for 2.0  momentum api.  * fix some bugs in weight_decay.  add alias for fluid.contrib.mixed_precision (#29562)  * add alias for fluid.contrib.mixed_precision  add static.amp into setup.pu.in (#29621)  * add static.amp into setup.pu.in  * add unittest for api  fix a bug in multi_precision_fp16 unittest. (#29756) ", "linked_issue_titles": "", "title": "amp related pr cherry pick into release/2.0"}
{"description": " this is just a small change to reduce the time some of the tests take.  it decreases the time around 20-30 seconds depending on run.  small improvement but we have to start somewhere. i'm just going through the tests logs and looking at the longer tests and seeing if they first make sense, if they are duplicated, and what we could change to make them faster without losing functionality. ", "commit_messages": " remove build 60 steps  this test is already covered in the individual graph driver tests and it  adds 15s to the test run without adding value.  the original idea was to  test max number of layers, this is fulfilled by the graph drivers.  make network stats version test concurrent  this change makes the test run go down from 10s to 2s  change number of pings to 1  this cuts the test time down from 6s to 2s  decrease sleep to 2 seconds ", "linked_issue_titles": "", "title": "test improvements to reduce time for long running tests"}
{"description": " this pull request adds support for core.ignorecase to libgit2. when appropriate, we use strcasecmp to compare strings instead of strcmp. when core.ignorecase is on, the index object for the repository stores entries in strcasecmp order. this means that index iterators yield results in strcasecmp order as well. when core.ignorecase is on, the workdir iterator returns strcasecmp-ordered results, too. the tree iterator (representing committed data) always returns data sorted with strcmp. when merge joining results from two iterators that do not sort their output in the same way, the case-sensitive iterator has its results spooled into memory and then sorted before the merge join can occur, using an iterator type called spoolandsort. this is a performance penalty, of course. when we write out the index, and the data stored in the index is in strcasecmp order, we make sure to re-sort it to strcmp order on the way out to disk. do people think this approach is the way to go, or are there other opinions about how to attack the problem? is there anything obvious or non-obvious that i've missed? ", "commit_messages": " support for core.ignorecase  minor fixes for ignorecase support ", "linked_issue_titles": "", "title": "support for the core.ignorecase flag"}
{"description": " i suggest removing \"fmt/\" prefix in *.h, *.cc files inside fmt directory. consider someone using fmt library as a git submodule or third-party library and has format.h helper file with direct referencing: include \"../../modules/fmt/fmt/format.h\" include \"../../modules/fmt/fmt/ostream.h\" nevertheless i put explicit relative path to format.h and ostream.h i need to add include_directories(\"modules/fmt\") anywhere i use my format.h helper, because ostream.h contins the following inside: include \"fmt/format.h\" and i believe it could be easily replaced without any side effects with include \"format.h\" ", "commit_messages": " upstream  remove unnecessary \"fmt/\" prefix which should be maintained with additional include_directories() in each project. ", "linked_issue_titles": "", "title": "remove unnecessary \"fmt/\" prefix inside fmt directory"}
{"description": " specifically, remove the vector2, vector3, rect2 and color return types, i haven't found any valid use case for these. also update authors.md to contain my full name. ", "commit_messages": " remove contrived javascript.eval return types  update my name in authors.md ", "linked_issue_titles": "", "title": "remove contrived javascript.eval() return types"}
{"description": " update libbpf submodule reference to the latest libbpf master commit. get rid of custom null #defines in libbpf-tools. and also adjust libbpf-tools makefile to use linux uapi headers distributed with libbpf itself.they are always the most recent version. ", "commit_messages": " libbpf: update to latest master  update libbpf to the latest upstream commit.  libbpf-tools: remove unecessary custom null definitions  now that libbpf defines null in bpf_helpers.h, there is no need for tools to  re-define null.  libbpf-tools: add libbpf's linux uapi headers to build  do not rely on up-to-date uapi headers on the system. instead use the most  recent ones that are used for libbpf's own build. ", "linked_issue_titles": "", "title": "update libbpf and misc fixes"}
{"description": " i found there is typo in setting environment github_repository variable for two jobs, however jobs work fine anyway. after short investigation i found info here which says that: the \" github_repository\" is a default environment variable set by github. when you try using the \" env\" key or the \" set-env\" command to change the value of a default environment variable, github will prevent the value from being changed on the system, but this environment variable will be added into the  env context with the new value. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " fix ci workflow typo  fixup! fix ci workflow typo ", "linked_issue_titles": "", "title": "remove unnecessary environment variable from ci workflow"}
{"description": " original pull-request #33062 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix issue #80: union index out of boundary  addressing review comments  remove the additional white space as per the pipeline build error.  adapt test  whitespaces  merge #33022 ", "linked_issue_titles": "", "title": "cherry pick #33062 to 21.11: merge #33022"}
{"description": " cherry-pick #20781 #20780 #20912 #20824 ", "commit_messages": " [cherry-pick]fix bug in reshape: (#20781)  consider the situation that shape of input can contain more than one -1.  [cherry-pick]support tensor for split and concat, support -1 in num_or_sections, add check num_or_sections (#20780)  * improve split and concat op:  1. support tensor for argument 'dim' in split op.  2. support tensor for argument 'axis' in concat op.  * redefine function getdatafromtensor and set unknown output shape to - 1.  * add check: attr(sections) match input(x).  * support tensor for attr(sections) and attr(sections) can contain -1.  * modify error message and fix bug for concat and call resize only when necessary.  test=release/1.6 ", "linked_issue_titles": "", "title": "reshape,concat, split and squeeze"}
{"description": " i hereby agree to the terms of the cla available at:  fix duplicates after distinct which were possible because of incorrect optimization. fixes #17294. #17296 (li chengxiang) ", "commit_messages": " fix #17294: distinct on subquery with group by may return duplicate result  properly check distinct columns.  properly check distinct columns.  update test. ", "linked_issue_titles": " distinct on subquery with group by may return duplicate result ", "title": "fix incorrect optimization of distinct"}
{"description": " #27398 introduced some logic to better handle anonymous functions in ios stack traces. however, the logic is only applied if the correct platform is passed into the function. fix ", "commit_messages": " test: trim function name logic not working  fix: call trim_function_name with platform ", "linked_issue_titles": "", "title": "call trim_function_name with appropriate platform"}
{"description": " kube-controller-manager panic when removing a lot of nodes from kubernetes cluster (see #58675). which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #58675 release note: ", "commit_messages": " reduce verbose logs  fix possible panic when getting primary ipconfig ", "linked_issue_titles": " kube-controller-manager panic with azure vmss ", "title": "fix possible panic when getting azure primary ipconfig"}
{"description": " #135 plus style fix and test ", "commit_messages": " implements #134 - add a --confirm flag  syle: rename --confirm to --yes  syle: rename --confirm to --yes  style: fix indentation  test: add coverage for auto confirmation ", "linked_issue_titles": "", "title": "--yes flag for auto confirmation"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " update accordionitem.  update checkbox.  update datatable components.  update datepicker.  update menu.  update multiselect. lower specificity of itemtoelement props to jsx.elementconstructor as it is the minimal type signature.  update search.  update tile.  add filterablemultiselect export. ", "linked_issue_titles": "", "title": "update types to match 7.44.0"}
{"description": " fixes #14811. thanks @khodorammar for the repro case. the bug is that we won't pop the portal if it had no children. so we shouldn't push its container either. ", "commit_messages": " adds failing test for  fix removechild() crash when removing an empty portal ", "linked_issue_titles": "", "title": "fix crash unmounting an empty portal"}
{"description": " i had to add new pull patch because they the yara guys introduced another redeclaration bug. i have already filed a pr for this but until the next release comes out, i will have to leave it there. this pr addresses issue #2546. ", "commit_messages": " deps: upgrade yara from 3.4.0 to 3.5.0  deps: update yara bottle hash ", "linked_issue_titles": "", "title": "update yara to version 3.5.0 (#2546)"}
{"description": " this is more of a collection of loosely related stuff. i added a buffered<t> template that adds buffering to any class that inherits from inputstream or outputstream. i've tried to get the gzip implementation to a state where it can correctly decompress usual files (as opposed to files constructed to test one specific behavior.) i already found and fixed a few bugs but there seems to be a bug buried in deflatedecompressor::decode_distance still. i also accumulated a few unit tests that i wrote to track down errors. it started to become annoying to rebase so i thought i'd merge some of it. ", "commit_messages": " libcompress: replace assert_not_reached with set_fatal_error.  we shouldn't assert that the input file is valid.  ak: add log stream operator overload for span.  ak: add buffered<t> which wraps a stream, adding input buffering.  userland: use buffered<t> in gunzip.  libcore: filestream.h: fix infinite loop when trying to read past end-of-file.  deflate: fix deadly typo.  libcompress: add another unit test.  i suspected an error in circularduplexstream::read(bytes, size_t). this  does not appear to be the case, this test case is useful regardless.  the following script was used to generate the test:  import gzip  uncompressed = []  for _ in range(0x100):  uncompressed.append(1)  for _ in range(0x7e00):  uncompressed.append(0)  for _ in range(0x100):  uncompressed.append(1)  compressed = gzip.compress(bytes(uncompressed))  compressed = \", \".join(f\"0x{byte:02x}\" for byte in compressed)  print(f\"\"\"\\  test_case(gzip_decompress_repeat_around_buffer)  {{  const u8 compressed[] = {{  {compressed}  }};  u8 uncompressed[0x8011];  bytes{{ uncompressed, sizeof(uncompressed) }}.fill(0);  uncompressed[0x8000] = 1;  const auto decompressed = compress::gzipdecompressor::decompress_all({{ compressed, sizeof(compressed) }});  expect(compare({{ uncompressed, sizeof(uncompressed) }}, decompressed.bytes()));  }}  \"\"\", end=\"\")  streams: consistent behaviour when reading from stream with error.  the streaming operator doesn't short-circuit, consider the following  snippet:  void foo(inputstream& stream) {  int a, b;  stream >> a >> b;  }  if the first read fails, the second is called regardless. it should be  well defined what happens in this case: nothing.  libcompress: simplify logic in deflate implementation. ", "linked_issue_titles": "", "title": "add buffered<t> to add buffering to byte streams."}
{"description": " this is a public helper method in an api that plugin authors are encouraged to use, so we need to deprecate the method name in 6.x and only remove it in master. ", "commit_messages": " correct typo in analysisplugin#requriesanalysissettings  because this is a static method on a public api, and one that we encourage  plugin authors to use, the method with the typo is deprecated in 6.x  rather than just renamed.  migration docs ", "linked_issue_titles": "", "title": "correct spelling of analysisplugin#requriesanalysissettings"}
{"description": " fixed  i am not sure in which section of the project i would have to write a test for this patch but if someone guides me then i will definitely write a test for this patch. ", "commit_messages": " remove extra dot in the file name of test db. ", "linked_issue_titles": "", "title": "fixed #32582 -- removed unnecessary dot in names of cloned test databases on sqlite."}
{"description": " add some more unit tests to specify the arguments each lifecycle method expects to be passed. with the addition of getderivedstatefromprops, it is important to pass the proper state values into the right parameters. for example, should the next state argument for shouldcomponentupdate get the new state before or after getderivedstatefromprops was called? these tests specify that behavior (answer: after). while not the most useful at this time, i think these tests will be useful if the relevant internals of preact are refactored. ", "commit_messages": " add gsbu prevstate test  add prevstate, etc. test for componentdidupdate  add nextstate, etc. test for shouldcomponentupdate  add gdsfp params test  separate testing new props and new state  simplify tests by removing log concept  remove todo ", "linked_issue_titles": "", "title": "specify the arguments for lifecycle methods"}
{"description": " jquery is throwing when it encounters \"[data-parent=anything.with.a.dot]\". failing fiddle (look in the console to see the error):  the fix is to quote the value for data-parent when finding the elements to hide. pull request contains both a unit test and the fix. ", "commit_messages": " failing test for dot in data-parent  use quotes to allow dots in data-parent ", "linked_issue_titles": "", "title": "accordion's data-parent can't contain dots"}
{"description": " this pr does 2 different things: i removed my attempt to have the unsafe guaranteed builtin take a guaranteed value. it just makes things more complicated than needed. with that in mind, i used ensureplusone to ensure that all values are passed to builtins at plus 1. rdar://34222540 ", "commit_messages": " revert \"[+0-all-args] accept guaranteed arguments to unsafe guaranteed.\"  this reverts commit 0bc964801bb423e32e6f5236fac82917e4bc19cf.  this turned out to be a bad idea and just add more complication than is  necessary.  [+0-all] use +1 for builtins. ", "linked_issue_titles": "", "title": "pass arguments to builtins at +1"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. official doc increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " fix callback and promise resolve  promise and callback should resolve core.document<model>, not just core.response  update pouchdb-upsert-tests.ts ", "linked_issue_titles": "", "title": "fix callback and promise resolve type"}
{"description": " adds tryfrom<{int}> for nonzero{int}. it uses the existing nonzero{int}::new() and option::ok_or() functions, meaning the checks are not repeated. i also added tests, i tried to follow the convention i saw in the test file. i also used #[stable(feature = \"nzint_try_from_int_conv\", since = \"1.46.0\")], but i have no idea if the feature/version are correctly named or even correct. ", "commit_messages": " added implementations for tryfrom<{int}> for nonzero{int}  added tests for the implementations ", "linked_issue_titles": "", "title": "add tryfrom<{int}> for nonzero{int}"}
{"description": " added \"mouse move\" support. change \"mouse enter/leave/over/out\" to rely mainly on \"mouse move\" events rather than on uielement.pointerenered/exited. the latter are fired when os decides the pointer enter/left what it thinks is the hit target, but that is wrong in some scenarios like \"box-none\" views overlapping non-related views. the new mechanism basically makes all events consistent with the target resolution offered by the touchhandler.getreactviewtarget. ", "commit_messages": " first cut of mouse move/enter/leave fixes  added element bounds checks.  fixed the enter/leave/over/out optimizations  pr feedback ", "linked_issue_titles": "", "title": "added mouse move support and fixes some mouse enter/leave scenarios"}
{"description": " hi, i just developed a quick menu ui component based vue.js2. i want to share this with other developers. ", "commit_messages": " add wheels factory to tutorials  this is a website which is used to share ui components and libraries. it displays many execellent ui componets and this website almost updates every day. it provides searching and find by key words(tag) functionality to help user to find a ui component quickly. for each component, the website shows a concise introduction, such as installation of a component, how to use it and the props table of each component. it also show the demo and github page of each component.  add wheels factory  remove the emply line in tutorials, adding new line in the bottom of apps/websit  add description of wheels factory  adding vue-quick-menu to ui components ", "linked_issue_titles": "", "title": "adding vue-quick-menu to ui components--menu"}
{"description": " this fixes #1121. #2999 should be merged first. ", "commit_messages": " modified server ssl certs to allow multiple pairs and force_client_auth flag  fixed tests ", "linked_issue_titles": " change the node ssl server credentials api so that a server can have multiple key/cert pairs. ", "title": "allow node server credentials to have multiple key/cert pairs"}
{"description": " \"eslint\": \"^6.8.0\", \"git-rev-sync\": \"^2.0.0\", \"rollup\": \"^0.59.4\", \"rollup-plugin-git-version\": \"^0.3.1\", \"ssri\": \"^8.0.0\", \"uglify-js\": \"^3.9.2\" keep rollup < 0.60.0 for compatibility with ie 8 (see #6647) ", "commit_messages": " update rollup-plugin-git-version to ^0.3.1  update uglify-js to ^3.9.2  update git-rev-sync to ^2.0.0  update ssri to ^8.0.0  update rollup to ^0.59.4  (latests version with support of ie 8)  remove object.freeze hack, use rollup's output.freeze option instead ", "linked_issue_titles": "", "title": "update dev dependencies, fix most of vulnerabilities"}
{"description": " description: fixed a bug caused in creating a dictionary of entities to observe. using dict.fromkeys all entities where observed for each observation since the empty list was added by reference. replaced by dict comprehension. also using this to learn how to commit my work preparing for more substantial changes to this component. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist tox basically takes forever, but it finished in the end. it's not very useful for small pull requests such as this one though, it took more than two hours! have also run all tests manually as mentioned in  (removed all non-applicable checklists) ", "commit_messages": " change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list  change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list  use get instead of direct keys for dict  change fromkeys to dict comprehension to prevent append working on a list by reference. now each entity id has its own seperate list  use get instead of direct keys for dict ", "linked_issue_titles": "", "title": "fix all entities triggering all observations in bayesian sensor"}
{"description": " makes windows builds extract things that look like warnings and errors from stdout, where msbuild sends all output, and reports them as errors to the logger (essentially making them behave as if they had gone to stderr). this means that native build failures will no longer be completely invisible in non-verbose mode. also fixes an existing warning so that it won't show up in every build: the custom step in the windows template cmake to do the re-entrant flutter step includes a dummy output file to force the step to run every time. this causes a warning from vs. marking it symbolic to indicate that it's not a real output file causes cmake to generate that vs step with the output validation step disabled so that it won't warn. related issues fixes #33583 i added the following tests: tests the regex extraction against sample normal and error lines, and ensures that it properly finds only the latter. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. ", "commit_messages": " fix build warning due to phony output  the custom step in the windows template cmake to do the re-entrant  flutter step includes a dummy output file to force the step to run every  time. this causes a warning from vs. marking it symbolic to indicate  that it's not a real output file causes cmake to generate that vs step  with the output validation step disabled so that it won't warn.  add surfacing of errors from stdout ", "linked_issue_titles": " improve error surfacing from windows builds ", "title": "surface windows build errors in non-verbose mode"}
{"description": " hi @patrickvonplaten, adding 3 documented notebooks to fine tune transformers to downstream nlp tasks with pytorch: multi-class classification: using distilbert multi-label classification: using bert summarization: using t5 - model tracking with wandb these notebooks are pulled from the git repo: ", "commit_messages": " added links to more community notebooks  added links to 3 more community notebooks from the git repo:  different transformers models are fine tuned on dataset using pytorch  update readme.md ", "linked_issue_titles": "", "title": "adding notebooks for fine tuning [community notebook]"}
{"description": " fixes #2200 this is the data output, going out over stdout. json logging as proposed in #2024 would go out over stderr as usual, so no conflicts there. there is some overlap between info (with --last/--first/--prefix) and list which is more obvious in the json output. the difference is that \"info\" reports more stuff, and takes longer for that, while \"list\" is fast (only looks at the manifest). ", "commit_messages": " info: add --json option  create: add --json option  use custom json encoder for repr'ing borg objects consistently  info: --json for archives  list: --json for archive listing  list: --json for archive contents listing ", "linked_issue_titles": " --json for create, info, list ", "title": "json output for major commands"}
{"description": " intention of #802 was to have on-the-fly compression using brotli only available to the standalone server, considering the following facts: brotli encoder is written in c++, while we want to keep libh2o as a c library we do not want to bundle libbrotli in libh2o, but having an external dependency against libbrotli might be bothersome to the users of libh2o for the purpose, a macro named h2o_use_brotli was introduced to conditionally enable / disable the calls to lib/handler/compress/brotli.cc. the macro has been turned of when building libh2o. however, we did not stop linking against brotli.cc.  as reported in #940 this has become an issue when trying to use the shared library version of libh2o (or libh2o-evloop). this pr address the issue by stopping linking to brotli.cc when building libh2o.  it also fixes build issues related to how we build and use the library. fixes #940 ", "commit_messages": " move lib/handler/compress/brotli.cc to brotli_source_files (since it need not be linked for libh2o)  on osx, libraries being built must link to the dependencies ", "linked_issue_titles": " libh2o-evloop 2.0.0 release builds but with unresolved symbols ", "title": "fix link error when trying to use libh2o"}
{"description": " this pr adds a makefile so as to have an entry point to understand how to locally generate the website. i had a hard time understanding how to generate it and finally ended up looking in the github actions files. a makefile will make it easier for new users to start contributing. add a requirement.txt file. so we know which libs we need to install. use some best practices for your bash script that generates the docs. ", "commit_messages": " chore: add python requirements  feat: better bash scripting  chore: add makefile ", "linked_issue_titles": "", "title": "document build process / add requirements / better bash"}
{"description": " using a more recent snippet (following their current docs), and adding anonymization of the ip (according to their docs, this should only \"slightly reduce the accuracy of geolocation\"). if we do this, should do the same for main website as well. ", "commit_messages": " use snippet from google analytics docs  add anonymizeip ", "linked_issue_titles": "", "title": "add anonymizeip for google analytics in docs"}
{"description": " recommend that the defaults in osx/scripts/postinstall-launchd-jenkins be reviewed by a java/osx dev for sanity. ", "commit_messages": " add minpermgen and minheapsize settings for defaults(1) which will be used preallocate java's heapsize and permsize.  set defaults for java heap and perms on both i386 and x64_64 architectures. the x64_64 settings work for me. recommend that they be reviewed by a java/osx dev. ", "linked_issue_titles": "", "title": "add more control of java heap and perm sizing on osx and set defaults."}
{"description": " use nacosservicemanager  to manage the life cycle of namingservice  and namingmaintainservice when the related configuration is dynamically changed through the configuration center, realize the reconstruction of namingservice  and namingmaintainservice ", "commit_messages": " nacos re-register enhance  nacos discovery enhance  merge remote-tracking branch 'origin/master' ", "linked_issue_titles": "", "title": "nacos namingservice support dynamic switching"}
{"description": " added scipy intersphinx inventory to make references clickable (for example in \"see also\" sections in convolve or polyfit). some scipy.stats references also needed updating (such as those in vonmises or zipf; note that to see the effect one needs to rebuild mtrand.so before building the documentation). ", "commit_messages": " doc: add scipy inventory for intersphinx.  maint, doc: update some scipy.stats references.  closes #5813. ", "linked_issue_titles": "", "title": "turn scipy references into links."}
{"description": " in the dgus_lcd_ui_reloaded code void dgusscreenhandler::setstatusmessage(fstr_p const fmsg, const millis_t duration) but in the function it attempt to use uses the variable msg when it was defined as fmsg updated to use fmsg dgus_lcd_ui_reloaded and all its requirements compiles as expected my test config configuration.zip #23089 ", "commit_messages": " use fmsg not msg  remove xtra f ", "linked_issue_titles": "", "title": "fix typo in dgus_lcd_ui_reloaded, dgusscreenhandler::setstatusmessage"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. (already there?) a quick search for \"fullcalendar\" in the issues ( #16935 #4663 #6893 ) reveals the community needs updated typings for fullcalendar but things are moving slowly. in this pr i'm taking steps towards good typings for fullcalendar@3.5: refactor the definition file such that options consistently map to sections of the doc. add the short description and default values for most options. add missing options and mark where further inspection is necessary to find discrepancies with the doc. i'm not pretending to be able to produce fully compatible typings but this is already far better than what we had before and hopefully someone will be willing to finish the job. i have no idea how the release cycle works in this repo but i was thinking at least publishing those as v3.5.0-preview or something if not just v3.5.0 . lmk what you think. thanks ", "commit_messages": " fullcalendar refactoring  add most of v3's features and mark where further checking  is needed to ensure full v3 compatibility.  fix linting ", "linked_issue_titles": "", "title": "fullcalendar refactoring and partial v3 featureset"}
{"description": " enables the annotationusestyle, avoidnoargumentsuperconstructorcall, and noenumtrailingcomma checkstyle checks and fixes all violations. the motivation is to make the code easier to read by using a consistent style throughout. ", "commit_messages": " enable avoidnoargumentsuperconstructorcall checkstyle check  enable annotationusestyle checkstyle check  enable noenumtrailingcomma checkstyle check ", "linked_issue_titles": "", "title": "enable annotationusestyle, avoidnoargumentsuperconstructorcall, and noenumtrailingcomma checkstyle checks"}
{"description": " reworks challenge to use argument in function call. i've joined two parts of the original challenge - finding 20 numbers of sequence and first number greater than - into finding 10 numbers, starting from one greater than. limiting required numbers to 10 allows to keep test descriptions cleaner, while not affecting difficulty of challenge. adds two tests. removes unnecessary link. changes tested on local fork. related to #40896. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. ", "commit_messages": " fix: rework challenge to use argument in function  fix: remove unnecessary link ", "linked_issue_titles": "", "title": "rework rosetta code harshad or niven series"}
{"description": " bugfix yes if relevant, link to documentation update: summary fixes #3484 no other information ", "commit_messages": " fix(ruleset): allow array of functions returning either string or loader objects  beautify, remove comments, debuggers ", "linked_issue_titles": " crash with rule.use as a function returning array ", "title": "normalize mixed use array and function"}
{"description": " label encoder (e.g., scikit-learn's) is a general mechanism of mapping values to integers or vice versa. today, the label encoder in onnx only supports integer-to-string and it's inverse transform. thus, this pr proposes a new signature to fill the gap. ", "commit_messages": " add new signature to md file for preview  clarify look-up for floats  update operator-ml.md ", "linked_issue_titles": "", "title": "upgrade label encoder to support more input types"}
{"description": " this pr doesn't actually add tpu optimization. it restructures the sampling graph to make it compatible with tf.contrib.tpu.rewrite. ", "commit_messages": " coconet: cleanup lib_tfsampling and add sampling support to export_saved_model.  uses tf.placeholder_with_default for the scalar params so they can be  left out of the savedmodel signature.  fix import order.  add missing \"lib_saved_model.py\". ", "linked_issue_titles": "", "title": "cleanup and refactor to support tpu inference"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " updated with info,header and footer  formatting  linting ", "linked_issue_titles": "", "title": "updated pdfmake type definition with info,header and footer types"}
{"description": " fix merge conflict on master-next due to afc8762. ", "commit_messages": " [immediate] fix static constructor/destructor calls in runimmediately.  removes a redundant call to lljit::runconstructors and adds a call to  lljit::rundestructors.  [immediate] fix static constructor/destructor calls in runimmediately. ", "linked_issue_titles": "", "title": "fix merge conflict in lib/immediate/immediate.cpp"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. when i went through these challenges on the website, the wording was a bit confusing, so i fixed it. ", "commit_messages": " refactor: made instructions incurriculum\\challenges\\english\\01-responsive-web-design\\applied-visual-design\\use-the-strong-tag-to-make-text-bold.md a little more clear to user  refactor: changed phrasing in instructions in curriculum\\challenges\\english\\01-responsive-web-design\\applied-visual-design\\use-the-s-tag-to-strikethrough-text.md to make it slightly easier to read and less verbose  refactor: fix phrasing in curriculum/challenges/english/01-responsive-web-design/applied-visual-design/use-the-s-tag-to-strikethrough-text.md ", "linked_issue_titles": "", "title": "change phrasing in challenges to make it easier to read"}
{"description": " fixes #21715 i have followed (at least) the pr section of the contributing guide. description small fix of ripple color for custom switches. ", "commit_messages": " fixed ripple color for custom switch  prettier import ", "linked_issue_titles": " [switch] wrong custom ripple color ", "title": "fix custom switch ripple color"}
{"description": " achieve the proposal in #421 . dsl ref: w3c spec css device adaptation adding item in config script: <script type=\"config\"> { \"viewport\": { \"width\": \"device-width\", ... }, ... } </script> maybe we will use <meta> tag as dsl in future. supported properties width: number or \"device-width\" or \"device-height\" height: number or \"device-width\" or \"device-height\" js-native api module: meta method: setviewport args: [viewportobject] (just same as viewport object in config script) ", "commit_messages": " * [jsfm] add test case for viewport config  * [jsfm] support vieport configs ", "linked_issue_titles": "", "title": "support to set viewport (achieve #421)"}
{"description": " starts to provide a solution for #18971. thinking i will round this out and also add a prop that allows the user to align the icons as desired. would love feedback from the team if this seems like a good path? @oliviertassinari i have followed (at least) the pr section of the contributing guide. closes #18971. ", "commit_messages": " add support for array of customicons  add test for customicons array  revert errant change ", "linked_issue_titles": " [rating] allow different icons ", "title": "add a demo with different icons"}
{"description": " this pr updates the .pot file as described in  this pr is marked wip as i want to reread all translations once again . would be great, if a german speaker could review, at least if we agree on important, recurring keywords. to suggest translations for the few remaining fuzzy messages has associated issue: fixes #17441 includes db migration (follow approval process in sip-59) ", "commit_messages": " pybabel extract  add and correct de translations ", "linked_issue_titles": " german translations missing or wrong ", "title": "update german translations (based on master) (#17441)"}
{"description": " it turns out i had forgotten to include a bunch of files that vagrant-spk was pulling in automatically. the build should be working now, and i've verified that it produces a working spk. ", "commit_messages": " add missing meteor-spk files to travis sandstorm build  fix travis sandstorm build ", "linked_issue_titles": "", "title": "fix travis sandstorm spk build"}
{"description": " @goodmanship i'm creating this draft pr from your branch so we can discuss the code changes. ", "commit_messages": " use the constants  return response for kinesis put_records  new kinesis test, bug fix  use boto for this, but needs config ", "linked_issue_titles": "", "title": "inject kinesis throttling errors for testing"}
{"description": " route section: fix to add multiple properties first init the node then add to list. ", "commit_messages": " networkd: fix route properties.  we are not able to add multiple properties.  wlp3s0.network:  [match]  name=wlp3s0  [route]  gateway=10.68.5.26  metric=10  sudo ./systemd-networkd  failed to parse file '/usr/lib/systemd/network/wlp3s0.network': file  exists  could not load configuration files: file exists  this patch fixes it.  networkd: address- initialize the node before adding to list.  it make more sense to initalize the node first then  we add to the list. ", "linked_issue_titles": "", "title": "fix address and route conf"}
{"description": " which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # ", "commit_messages": " fixed support for ingress and existingpvc  bumped version  fixed typo  values.nginx.persistence.existingclaim  fixed support for k8s 1.9.6 ", "linked_issue_titles": "", "title": "fixed permission issue for tls secret"}
{"description": " this relates to #24576, where users were trying to use the upsert method while passing an upsertoptions argument without a returning value.  this was causing compilation to fail.  i have added the test case and made the returning: false option act as the default, as it is in sequelize. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #24576, increase the version number in the header if appropriate. ", "commit_messages": " upsert should compile with options that dont include returning  fix parens  bump version for bugfix ", "linked_issue_titles": "", "title": "fix types error with upsertoptions requiring the returning option if they are defined at all"}
{"description": " original pull-request #27329 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix incorrect row-level filtering  add test.  add test.  update 02002_row_level_filter_bug.sh  add test to parallel skip list.  update skip_list.json  fix spelling.  fix #27179 ", "linked_issue_titles": "", "title": "cherry pick #27329 to 21.6: fix #27179"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: included in commit messages include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " feat(chromecast-caf-receiver): add messagetype enum to system ns  there are two messagetype enums. the one in system namespace was  missing.  1.  2.  fix(chromecast-caf-receiver): fix eventhandler for castcontextreceiver  methods in castcontextreceiver accepts eventhandlers with system.event  as arguments and not events.event         ", "linked_issue_titles": "", "title": "add missing system.messagetype enum and fix eventhandler type mismatch"}
{"description": " this is a companion pull request for #6227 updating the changelog for activesupport to document the addition of #beginning_of_hour and #end_of_hour core extensions as merged to the 3-2-stable branch in #6170. this pull request contains 2 commits.  the first is the inclusion as outlined above.  the second brings the 3-2-stable changelog up-to-date by adding missing entries for previous releases. / thanks, mark. ", "commit_messages": " bring activesupport changelog up-to-date/consistent with master.  add changelog section for unreleased rails 3.2.4; document addition of #beginning_of_hour and #end_of_hour to time and datetime core extensions. ", "linked_issue_titles": "", "title": "updated activesupport changelog [for 3-2-stable]"}
{"description": " here is an implementation for the get api for system feature upgrades. it is pretty simple. when called, we iterate over all features, resolve all indices, and fetch the version for each index from cluster state index metadata. we then determine the earliest index creation version for each feature to determine whether the features need to be upgraded or not. i've also added a simple bwc test for rolling upgrades to make sure that we are in fact returning the correct index creation versions. ", "commit_messages": " implement and test get feature upgrade status api  use version object instead of string versions  refactor for streams  add integration test for feature upgrade endpoint ", "linked_issue_titles": "", "title": "implement get api for system feature upgrades"}
{"description": " while looking into #497 i realized that the throttle decorator does not work on a per-instance basis but on a per-class basis. class say: @util.throttle(timedelta(seconds=1)) def hello(self): return \"hi\" say().hello() # => \"hi\" say().hello() # => none this was unexpected behavior and this pr fixes this. it also includes some cleanup for the arest sensor which i did while debugging. fixes #497. ", "commit_messages": " fix throttle to work on instance-level  cleanup arest ", "linked_issue_titles": " arest sensor error ", "title": "throttle per instance (fixes arest)"}
{"description": " what this pr does / why we need it: reverts #4377 to fix the same issue which issue this pr fixes: fixes #4704 special notes for your reviewer: attempted to align with other charts, but behaviour is inconsistent between charts. ", "commit_messages": " always set spec.clusterip  version bump ", "linked_issue_titles": " [stable/external-dns] invalid value for spec.clusterip on 0.5.3 upgrade ", "title": "allow upgrade with empty clusterip"}
{"description": " there is a bug in cycle_unicode_input_mode() that prevents cycling in reverse. the bug is due to unsigned arithmetic. as a consequence, the uc_rmod keycode does not currently work. this pr changes the uint8_t offset parameter to int8_t and fixes the bug. this pr further allows shift to be used for inverting the direction of the uc_mod, uc_rmod keycodes, similar to how rgb_mod, rgb_rmod work. i've tested uc_rmod and cycling with shift after these changes and can confirm that they work as intended. currently, audio feedback for changing input modes currently only plays for specific uc_m_* keycodes. this pr allows it to play when changing input modes with uc_mod, uc_rmod as well. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " invert uc_mod/uc_rmod direction when shift is held  also use mod_mask_shift in process_rgb.c  allow audio to be played for uc_mod, uc_rmod keycodes as well  fix signedness bug in reverse input mode cycling  misc formatting in process_unicode_common.c ", "linked_issue_titles": "", "title": "fix bug in uc_rmod, add shift and audio support for uc_mod/uc_rmod"}
{"description": " there was a dashboard issue where, when a user clicked to view the logs or errors of a given worker, the page would crash. this occurred because the front-end expected a different payload than the backend returned. the pr also adds a test for the new payload. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix bug with worker logs/errors not displaying in the dashboard  add error endpoint test. ", "linked_issue_titles": "", "title": "fix bug in display of worker logs and errors in dashboard"}
{"description": " going forward, fixed/constrained images will take width and height as parameters, rather than the previous option of maxwidth/maxheight for fluid and constrained images. open question: right now fluid can take width and height. at what level do we want to warn the user to use breakpoints instead? or do we want to cover that in the forthcoming breakpoints pr? (note that the failing tests are based on the plugin helpers, i'm missing something there) readmes outside of gatsby-plugin-image are also not updated as versioning those is not clear. should determine that before merging this pr. ", "commit_messages": " in progress  update tests  resolve merge conflict  remove maxheight and maxwidth references ", "linked_issue_titles": "", "title": "update image api to remove maxwidth/maxheight"}
{"description": " the stdlib has a panic_immediate_abort feature that turns panics into immediate aborts, without any formatting/display logic. this feature was introduced primarily for codesize-constrained situations. unfortunately, this win doesn't quite propagate to result::expect() and result::unwrap(), while the formatting machinery is reduced, expect() and unwrap() both call unwrap_failed(\"msg\", &err) which has a signature of fn unwrap_failed(msg: &str, error: &dyn fmt::debug) and is #[inline(never)]. this means that unwrap_failed will unconditionally construct a dyn debug trait object even though the object is never used in the function. constructing a trait object (even if you never call a method on it!) forces rust to include the vtable and any dependencies. this means that in panic_immediate_abort mode, calling expect/unwrap on a result will pull in a whole bunch of formatting code for the error type even if it's completely unused. this pr swaps out the function with one that won't require a trait object such that it won't force the inclusion of vtables in the code. it also gates off #[inline(never)] in a bunch of other places where allowing the inlining of an abort may be useful (this kind of thing is already done elsewhere in the stdlib). i don't know how to write a test for this; we don't really seem to have any tests for panic_immediate_abort anyway so perhaps it's fine as is. ", "commit_messages": " inline slice panics on panic_immediate_abort  inline option panics on panic_immediate_abort  add separate impl of unwrap_failed to avoid constructing trait objects ", "linked_issue_titles": "", "title": "make certain panicky stdlib functions behave better under panic_immediate_abort"}
{"description": " this pr adds the poweredbyheader and webpack fields to the public nextconfig type. related issues linked using fixes #number errors have helpful link attached, see contributing.md related issues linked using fixes #number errors have helpful link attached, see contributing.md ", "commit_messages": " chore: add missing poweredbyheader field to nextconfig type  chore: add missing webpack field to nextconfig type ", "linked_issue_titles": "", "title": "add missing fields to nextconfig type"}
{"description": " currently, deform_conv only works for cuda:0 from ops.dcn.deform_conv import deformconv, deform_conv ## works normally device = \"cuda:0\" out = deform_conv(x, offset, weight, 1, [1, 1], 1, 2, 2) print(out.mean(), out.var()) # tensor(0.1310, device='cuda:0'), tensor(0.1312, device='cuda:0') ## fails to work device = \"cuda:1\" out = deform_conv(x, offset, weight, 1, [1, 1], 1, 2, 2) print(out.mean(), out.var()) # tensor(0., device='cuda:1'), tensor(0., device='cuda:1') the patch aims to fix the issue. ", "commit_messages": " update deform_conv_cuda.cpp  update deform_pool_cuda.cpp ", "linked_issue_titles": "", "title": "fix zero outputs when not running on cuda:0"}
{"description": " commit message: count the number of bytes sent to and received from upstream server per request and store them in stream_info for better observability. additional description:na risk level:na testing:will add testing for the new metric. docs changes:add doc for the new metric. release notes:na ", "commit_messages": " count bytes  add count byte interface to stream class  add h1 bytes accounting  count byte sent in h1  log bytes in stream info  clean up  count h2 sent and received bytes  cleam up  clean up ", "linked_issue_titles": "", "title": "count sent and received bytes for http stream"}
{"description": " chai removing the namespace from their types was a bug, which has been fixed - the correct fix from us would have been pinning our version until a fix was out, but instead we went way overboard and removed the dependency, and i'll be honest, while the assertions are no different when all tests are passing, that's not what there're there for. failure messages like this one: are straight bad compared to what chai gives (a useful comparison of both inputs to equals). object diffs for deep equals are also much worse (or rather, non-extant). we didn't use an assertion library for no reason, we used it to be more productive when debugging. i don't want to need to open a debugger just to see every small discrepancy! and while i could spend hours of effort making our custom assertion library become up-to-par with what i'd expect for a decent debugging experience (and i know @rbuckton already has his own assertion framework, but he's not ready afaik), it's much easy to not have a nih mindset and continue using the tested and featureful assertion library we've been using for years. especially since there's not a single issue with it. ", "commit_messages": " revert \"merge pull request #20429 from microsoft/unchai\"  this reverts commit 66ec938164b61a7a9e14214f36bf58edc11c7609, reversing  changes made to 37a40561ac4c4cb1f970ade5fff2389d954593f6.  update lockfile ", "linked_issue_titles": "", "title": "revert merge pull request #20429 (removing chai)"}
{"description": " this is a continuation of #7479 & #7728, progress towards converging ak::inlinelinkedlist usages with ak::intrusivelist. ", "commit_messages": " ak: add intrusivelist::size_slow() to match inlinelinkedlist  the functionality is needed to replace inlinelinkedlist with  intrusivelist in the kernel process class.  kernel: remove unnecessary cast to int during ensure capacity ", "linked_issue_titles": "", "title": "move process inlinelinkedlist usages to intrusivelist"}
{"description": " bug fixes ops this patch fixes onednn-based matmul kernel for cases when both inputs have different number of dimensions. it fixes the issue #30309 for onednn 1.6 (used in the release/2.0 branch). ", "commit_messages": " a fix for onednn matmul kernel. fixes issue #30309 (#30723)  a fix for #30309 with onednn 1.6 ", "linked_issue_titles": "", "title": "a fix for onednn matmul kernel. fixes issue #30309 for onednn 1.6"}
{"description": " to support multiple uris for a job, we need to make the api able to accept multiple uris. right now, protobuf and c++ level is handling multiple uris, but it's not done in python level. this pr fixed it. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix  up  fix lint  fix comment  fix lint  up  up ", "linked_issue_titles": "", "title": "align the interface to use multiple uris for runtime env"}
{"description": " implements a simple env dynamics learner to be used inside different mbrl algos. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  wip. ", "linked_issue_titles": "", "title": "prototype of a dynatrainer (for env dynamics learning in upcoming mbmpo algo)."}
{"description": " there's a bit of refactoring in here to get this all to work, but mostly it's the last two commits that are the meat of it: factor out all of the code responsible for mutating the output buffer into a discrete set of actions. re-implement those actions with a temporary queue so that queued changes can be reversed without requiring any reads from the output string itself. our old logic constantly referenced the output value, meaning every reference got more expensive as the output for larger, leading to an exponential increase in codegen times. for example, using the example script from istanbuljs/babel-plugin-istanbul#5 (comment) which generates doubling ast array, generation time changes as shown: items: the size of the array being generated time: the time in ms to generate the code length: the number of characters in the output code items: 2 ,  time: 9 ,   length: 239 items: 4 ,  time: 2 ,   length: 465 items: 8 ,  time: 6 ,   length: 917 items: 16 , time: 6 ,   length: 1840 items: 32 , time: 15 ,  length: 3696 items: 64 , time: 25 ,  length: 7408 items: 128 ,    time: 93 ,  length: 14917 items: 256 ,    time: 380 , length: 30149 items: 512 ,    time: 1399 ,    length: 60613 items: 1024 ,   time: 5301 ,    length: 121614 items: 2048 ,   time: 20676 ,   length: 246542 items: 2 ,  time: 7 ,   length: 239 items: 4 ,  time: 5 ,   length: 465 items: 8 ,  time: 5 ,   length: 917 items: 16 , time: 6 ,   length: 1840 items: 32 , time: 11 ,  length: 3696 items: 64 , time: 3 ,   length: 7408 items: 128 ,    time: 13 ,  length: 14917 items: 256 ,    time: 18 ,  length: 30149 items: 512 ,    time: 45 ,  length: 60613 items: 1024 ,   time: 63 ,  length: 121614 items: 2048 ,   time: 117 , length: 246542 items: 4096 ,   time: 266 , length: 496398 items: 8192 ,   time: 460 , length: 996110 items: 16384 ,  time: 980 , length: 2014687 items: 32768 ,  time: 2008 ,    length: 4062687 items: 65536 ,  time: 3819 ,    length: 8158687 items: 131072 , time: 7359 ,    length: 16443904 ", "commit_messages": " use the standard newline function.  remove sideeffectful position mutation.  centralize position tracking into buffer.  make the 'catchup' call implicit to source location updates.  drop one usage of removelast.  remove removelast usage.  remove unnecessary passthrough function.  use 'push' for all cases. ", "linked_issue_titles": "", "title": "make the code generator write-only to avoid exponential time generation"}
{"description": " notes are now fed to stories as parameters. no need to broadcast via channel anymore. run the crna-kitchen-sink app, verify notes are still being displayed. ", "commit_messages": " rm unused import  update rn notes addon description  remove dependency on channel to render notes  update readme  update knobs addon structure for consistency with notes and backgrounds ", "linked_issue_titles": "", "title": "remove channel dependency from rn notes addon"}
{"description": " see for instance #896 -- it's a common problem to need mocked nodes. this solution is probably a bit of a bandaid, as large projects would probably want to set options per-story, this is a lot better than nothing in the meantime. fixes #1085, and to some degree #881 and #876 added a snapshotwithoptions test body, and an example of usage in the test-cra app. run npm test. try removing the test option and it should fail with an undefined access issue. ", "commit_messages": " added a snapshotwithoptions test body and example  see for instance  this solution is probably a bit of a bandaid, as large projects would probably want to set options per-story, this is a lot better than nothing in the meantime.  added some docs ", "linked_issue_titles": "", "title": "added snapshotwithoptions to configure storyshots rendering options"}
{"description": " we retain the worker/object subscribe information and use them to re-subscribe when gcs service restart from failure. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " resubscribe worker/object table info when gcs service restart  remove unnecessary include ", "linked_issue_titles": "", "title": "resubscribe worker table info when gcs service restart"}
{"description": " cherry-pick of pr against master: #5440 initial pr description: two changes, close relatives. first change enables writing #if swift(>=3.0.1) by contextually inhibiting an early diagnostic in the parser that's currently blocking the initial semi-parse that runs before the version parser kicks in. second change weakens our sense of logical order and logical equality on version structures such that 4 == 4.0 == 4.0.0 (that is, versions are considered to have as many trailing zeroes as necessary). the function evaluating versions you are allowed to pass on the command line is tightened opposite this change, so you still can't say -swift-version 4.0 (only -swift-version 4) but it means that if someone writes #if swift(>=4.0) it'll work, rather than the current behaviour, that thinks 4 < 4.0. resolves sr-2908. ", "commit_messages": " support #if swift(subminor-version), rdar://problem/28786959 / sr-2908.  logically compare swift versions as though x == x.0 == x.0.0, etc. ", "linked_issue_titles": "", "title": "rdar 28786959 3.0 branch if swift 3 digit version"}
{"description": " via #15319 (redid #15399, removed the changes that didn't even belong in it.) so tl;dr this pr - uses a renderer specific object as the value of reactcurrentactingrenderersigil.current checks this value on 'updatecontainer checks this value when setting a state hook's value adds a fixture folder for act() (which is run on ci) this solves 2 specific problems - using the wrong act() shouldn't silence the 'missing act' warning using the wrong act() logs a warning tha you're, er, using the wrong act() (please see  #15399 for the long spiel on the mechanics for this.) ", "commit_messages": " warn when using the wrong renderer's act around another renderer's updates  like it says. it uses a real object as the sigil (instead of just a boolean). specifically, it uses a renderer's flushpassiveeffects as the sigil. we also run tests for this separate from our main suite (which doesn't allow loading multiple renderers in a suite), but makes sure to run this in ci as well.  unneeded (and wrong) comment ", "linked_issue_titles": "", "title": "using the wrong renderer's act() should warn"}
{"description": " refs #15791. refs #19602. this pr implements the part that passes information to listener and reads the responses. notes: no-notes ", "commit_messages": " implement onbeforesendheaders  pass the request  handle simple listeners  handle response listeners  read responses from listener ", "linked_issue_titles": "", "title": "migrate webrequest module to networkservice (part 6)"}
{"description": " adds a team selector to the metric alerts page, completing the team alerts frontend work. this pr also includes permission changes similar to #24355 ", "commit_messages": " add team selector to metric alerts with proper permissions  woopsie gotta feature flag this  bad at spelling ", "linked_issue_titles": "", "title": "add team alerts support to metric alerts"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. ", "commit_messages": " chore: add docs comment  fix: remove rule in tslint.json  chore: add some fix  fix: format tuya-panel-kit  add no-unnecessary-class for globaltoast  fix: remove no-unnecessary-class and fix ther warning  feat: uiidnaveventemitter typed  feat: uiidnaveventemitter typed  fork sync  fix: lint formater  fix: lint formater ", "linked_issue_titles": "", "title": "add some miss props and comment"}
{"description": " liba52 and libdts haven't been used by default for some time on any platform. ffmpeg is used instead of them. this patch removes them completely from the xbmc source tree and removes the deprecated --enable-libdts and --enable-liba52 configure options. the vs and xcode project files are also updated. build tested on linux and darwin. please test the win32 build to see if i managed to blindly update the vs project files correctly, and maybe provide a fix if that is not the case. also, if someone disagrees about removal of these libraries, now is the time to speak :) ", "commit_messages": " removed: use of deprecated liba52  liba52 hasn't been used by default for a while. remove the use of it  completely in favor of ffmpeg.  removed: internal copy of liba52  it is no longer used. ac-3 streams are decoded by ffmpeg.  removed: use of deprecated libdts  libdts hasn't been used by default for a while. remove the use of it  completely in favor of ffmpeg.  removed: internal copy of libdts  it is no longer used. dts streams are decoded by ffmpeg.  removed: unused dvdaudiocodecpassthrough.cpp  it has been replaced by dvdaudiocodecpassthroughffmpeg.cpp. ", "linked_issue_titles": "", "title": "remove liba52 and libdts completely"}
{"description": " this merges the logic for nullbooleanfield, which originally started off as a unique field, with the booleanfield. this reduces the repeated logic and removes the need for additional special cases. this also aligns with the recent changes within django to discourage the use of nullbooleanfield. fixes #6115 closes #6116 ", "commit_messages": " make nullbooleanfield subclass booleanfield  this removes a lot of the redundancy that was in place becuase we  were not doing this. this maintains the none initial value that  was previously present, as well as disallowing allow_null to be  passed in.  remove special case for mapping nullbooleanfield  in newer versions of django, the nullbooleanfield is handled the  same way as a booleanfield(null=true). given that we also support  that combination, and that our own nullbooleanfield behaves in the  same manner, it makes sense to remove the special casing that exists  for it.  add test for booleanfield(null=true, choices)  remove special case for nullbooleanfield  adjust mapping tests for nullbooleanfield ", "linked_issue_titles": " nullbooleanfield doesn't accept null when choices are defined ", "title": "merge nullbooleanfield with booleanfield(allow_null=true)"}
{"description": " fix sum op. update backward.py: if there is no input grad var in all outputs of previous ops, do not append this op into graph. only apply this stragety when double backward. make some op more standard ", "commit_messages": " fix compiling error with cudnn 5.1  fix sum_op  update backward appedding to support double grad.  test=develop ", "linked_issue_titles": "", "title": "update backward appending stragety to support double backward and fix some bug."}
{"description": " remove the -enable-experimental-conditional-conformances flag, enabling the feature all the time (and in all language modes). this allows developers to work around any source-compatibility issues due to the rollout of conditional conformances in the standard library (e.g, the collapsed slice types). to make the limitations of this feature more visible, introduce a runtime warning when a \"conforms to protocol\" check fails dynamically because we have not yet implemented that behavior for conditional conformances. ", "commit_messages": " [runtime] warn about dynamically querying conditional conformances.  rather than silently returning \"false\" when we are unable to attempt  to satisfy a conditional conformance at runtime, produce a runtime  warning first, to note to users that this behavior is incorrect and  will change in the future.  revert \"[se-0143] put conditional conformances behind an \"experimental\" flag.\"  this reverts commit b59c30c1afe2ae29ee20f14328b3ecb012fc02d6.  eliminate extraneous uses of -enable-experimental-conditional-conformances ", "linked_issue_titles": "", "title": "enable conditional conformances without a flag"}
{"description": " when we are maximized or fullscreened, check for the presence of the taskbar in auto-hide mode. if the terminal finds the taskbar on any side of the monitor, adjust our window rect by just a little bit, so that the taskbar can still be revealed by the user mousing over that edge. closes #1438 i work here note to future code archeologists: this doesn't seem to work for fullscreen on the primary display. however, testing a bunch of other apps with fullscreen modes and an auto-hiding taskbar has shown that none of them reveal the taskbar from fullscreen mode. this includes edge, firefox, chrome, sublime text, powerpoint - none seemed to support this. this does however work fine for maximized. i'm maximized and fullscreened the terminal a lot in the last two days. ", "commit_messages": " i think this _should_ fix #1438 but it instead gets rid of the left, right, bottom borders???  cleanup for pr  you'd think that the rcwork would just account for an autohide taskbar still...  this actually doesn't work for _any_ fullscreen anymore, weirdly. i could have swore that it did before though....  turns out i'm crazy and this is expected behavior. ", "linked_issue_titles": " cannot access taskbar when terminal is maximized/fullscreen ", "title": "reveal the taskbar when the user has the terminal maximized or fullscreen"}
{"description": " the current config object for aws-sdk is missing the majority of the parameters.  i filled it in. ", "commit_messages": " filled out the 'config' object for 'aws-sdk'.  aws-sdk: added support for apiversion/apiversions config options. ", "linked_issue_titles": "", "title": "fill in config options for aws-sdk"}
{"description": " electron's menuitem class has two different signatures for its click-related functions. the first is the menuitem#click instance method which is called by electron when a menu item is clicked and the second is the event handler which consumers provide which is invoked via the click instance method. the instance method takes an event instance, a browserwindow instance and a webcontents instance while the click callback takes a menuitem instance (the item just clicked), a browserwindow instance and an event instance. this pr updates both signatures such that they conform to the current state of affairs in electron. make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. ~~~run npm run lint package-name if a tslint.json is present.~~~ provide a url to documentation or source code which provides context for the suggested changes:  ~~~increase the version number in the header if appropriate.~~~ ~~~if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"../tslint.json\" }.~~~ ", "commit_messages": " the click callback accepts an event as its third param  see  fix signature for menu item click instance method  see  add tests to verify new signatures  add myself to the definitions list ", "linked_issue_titles": "", "title": "fix electron's menuitem click signatures"}
{"description": " this change updates the aggregation script, map script for aggregations, and field scripts to extend docbasedscript to give them access to the new fields api. ", "commit_messages": " add fields api to scripted metric aggs and aggregation scripts  add fields api to script fields ", "linked_issue_titles": "", "title": "add fields api to aggregation scripts and field scripts"}
{"description": " from auto-1016, we have downstream consumers of our ci systems who may not want to push to dockerhub. this pull request allows these downstream consumers who are running our ci code to push to internal registries exclusively. select one: select any that apply: ", "commit_messages": " disable docker interactions for security-like repos.  update check string to catch other repo. ", "linked_issue_titles": "", "title": "don't always push to dockerhub"}
{"description": " lib/ansible/modules/cloud/amazon/lambda.py ansible version ansible 2.3.0 (lambda-add-dead-letter 84c285fcc1) last updated 2017/02/21 09:49:11 (gmt -400) config file = configured module search path = default w/o overrides allows user to set, modify, and delete lambda's deadletterconfig. to delete set dead_letter_arn to an empty string: \"\". closes #21032. playbook used to test: --- - hosts: localhost tasks: - name: looped creation lambda: name: '{{ name }}' state: present zip_file: '{{ zipfile }}' runtime: 'python2.7' role: '{{ role }}' dead_letter_arn: '{{ sns_arn }}' handler: '{{ handler }}' ", "commit_messages": " add dead_letter_arn option for lambda.py  fix logic so deadletterconfig can be deleted ", "linked_issue_titles": " add support for deadletterconfig ", "title": "add dead letter option for lambda module"}
{"description": " this fixes #1558 and uses ast_compare=1 on travis tests, so we can make sure those don't break going forward. ", "commit_messages": " run yarn to update yarn.lock  upgrade typescript-eslint-parser, use jsxtext instead of literal for strings inside jsxelement    so this fixes  see here for more info about the new tsqualifiedname node type:    run ast comparison tests on travis ", "linked_issue_titles": " (typescript) react literals fail `--debug-check` ", "title": "upgrade typescript parser, fix and run ast tests on travis"}
{"description": " fixes #13016 overall the changes are made to address how dictionaries are not ordered in python <= 3.5. the major changes are as follows: uses ordereddict in test to make sure the values passed pytest.mark.parametrize has a deterministic order. users sorted on sets for a deterministic order. changes made to sklearn/linear_model/coordinate_descent.py were to ensure that staticmethod path has a deterministic order in their respective classes. only the two classes that uses lasso_path as a staticmethod are affected. the makefile has been updated to take advantage of pytest-xdist. when pytest-xdist spawns processes, the processes independently look through all files in sklearn to test. if the order of discovered test functions are not the same for all processes, pytest-xdist will return an error. travis-ci does not look like it gets that much faster. locally, this pr does speed up running our tests suite. ", "commit_messages": " tst: adds pytest-xdist support  tst: add pythonhashseed to command  tst: fix  tst: order pytest parameters  tst: fix for xdist  tst: adjusts dicts for 3.5 ordering  tst: fix  tst: fix  tst: fix  tst: fix  enh: faster  tst: fix  tst: optimize  tst: fix  rfc: minor  rfc: add commands for parallel pytest  rfc ", "linked_issue_titles": " parallelize tests again? ", "title": "ci uses pytest-xdist to parallelize tests"}
{"description": " closes #24076 closes #16785 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry additionally, date strings with utc offsets that are using in indexing are now validated by the following: an error is raised if 2 date strings have different utc offsets an error is raised if the date strings have a utc offset and the index is not timezone aware. ", "commit_messages": " bug: indexing with utc offset string not longer ignored  add whatsnew ", "linked_issue_titles": " err: validate partial string indexing with tz-aware end-points  slicing datetimeindex should be timezone aware ", "title": "indexing with utc offset string no longer ignored"}
{"description": " closes #26366 tests passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry pandas/core/indexes/timedeltas.py taken care of as well since the errors were the same. ", "commit_messages": " fis type annotation  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fix some errors and remove the module from mypy.ini  fix linting errors ", "linked_issue_titles": " fix type annotations for pandas.core.indexes.datetimes ", "title": "fix type annotations in pandas.core.indexes.datetimes"}
{"description": " adds type hints for controller.py and backend_worker.py i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " add some monkeytype type hints  manually clean up autogenerated type hints for api.py  added optional types  merge from master  travis format  merge from master  travis format  removed binary files  fix minor errors  travis format  removed binary files again  removed last binary file  add type hints for controller, backend_worker  fix type errors on running test_api  travis format  remove annotations import ", "linked_issue_titles": "", "title": "add type hints for controller and backend_worker"}
{"description": " hi there! this pr just renames parameters seed and nthread to random_state and n_jobs respectively in scikit-learn wrapper with keeping backward compatibility. the most pieces of code is for keeping backward compatibility. is it necessary to leave old parameters for a while or should i remove all this stuff and just rename parameters? ", "commit_messages": " updated scikit-learn interface  fixed better description  updated set_params() ", "linked_issue_titles": "", "title": "parameters renaming for sklearn naming convention"}
{"description": " in order to spare the limited build credits we have on travis, i was thinking we could reduce the number of cron builds we do there: we should migrated the icc build to azure but this can be done in a dedicated pr (todo) we can only do nightly linux/arm64 wheel build only for the latest python version to spare resources: people who run scikit-learn bleeding edge builds are more likely to also run the latest python version we can remove the linux/arm64 cron test job that is redundant with the nightly linux/arm64 wheel build. note that the linux/arm64 test fail with scipy 1.6.0 which is handled in the dedicated issue: #19111. ", "commit_messages": " maint reduce travis build load  re-add [arm64] for manual arm64 builds in prs ", "linked_issue_titles": "", "title": "ci reduce travis nightly load"}
{"description": " git has updated xdiff to produce conflict markers that match the eol style in the conflicting files.  this means that if you have checked in cr/lf files into your repository, and perform a merge, you will now get a conflict file that also has cr/lf line endings. update our xdiff to match theirs, to give us this same functionality, and add some unit tests to ensure that it works. ", "commit_messages": " xdiff: upgrade to git's included xdiff  upgrade xdiff to git's most recent version, which includes changes to  cr/lf handling.  now cr/lf included in the input files will be detected  and conflict markers will be emitted with cr/lf when appropriate.  merge: test cr/lf conflicts for cr/lf files  ensure that when the files being merged have cr/lf line endings that the  conflict markers produced in the conflict file also have cr/lf line  endings. ", "linked_issue_titles": "", "title": "conflict markers should match eol style in conflicting files"}
{"description": " calls to threadpool.markthreadexecution() and threadpool.markthreadcompletion() got removed in the 1.3 -> 1.4 rewrite.  this adds them back and gets the unit tests contributed by @nurkiewicz working.  thanks for those, @nurkiewicz! ", "commit_messages": " hystrixthreadpoolmetrics.getrollingcountthreadsexecuted() always returns 0 in 1.4.x - failing test case  conflicts:  hystrix-core/src/main/java/com/netflix/hystrix/hystrixthreadpoolmetrics.java  added back calls to threadpool.markthreadexecution() and .markthreadcompletion() in abstractcommand ", "linked_issue_titles": "", "title": "added thread pool metrics back to execution flow"}
{"description": " it turns out that it's necessary to special case exclusivity builtins and add flags to sil instructions because of a couple circumstances: swift 3 mode exclusivity warnings will continue to be warnings. the standard library will continue building in swift 3 mode (for the foreseeable future). ", "commit_messages": " [exclusivity] add a [builtin] flag to begin_[unpaired_]access.  this flag supports promoting keypath access violations to an error in  swift 4+, while building the standard library in swift 3 mode. this is  only necessary as long as the standard library continues to build in  swift 3 mode. once the standard library build migrates, it can all be  ripped out.  <rdar://problem/40115738> [exclusivity] enforce keypath access as an error, not a warning in 4.2.  [exclusivity] make keypath enforcement an error in swift 3 mode.  modify irgen to emit builtin access markers with an error flag in  swift 3 mode.  keypath enforcement is required by user code in swift 4+ mode, but is  implemented within the standard library. a [builtin] flag marks the  special case for access generated by builtins so that they are  always enforced as an error regardless of the language mode.  this is necessary for swift 4.2 because the standard library continues  to build in swift 3 mode. once the standard library build migrates,  this is all irrelevant.  this does not actually affect existing swift 3 code, since the keypath  feature wasn't introduced until swift 4.  <rdar://problem/40115738> [exclusivity] enforce keypath access as an error, not a warning in 4.2.  remove the optimize.sil.preserve_exclusivity attribute.  fix a static exclusivity violation in openclsoverlay.swift.  i noticed this during testing, but it has nothing to do with the other changes  in this pr. this static violation has always been present as a warning and would  continue to be a warning after my changes. ", "linked_issue_titles": "", "title": "enforce keypath exclusivity as error"}
{"description": " this is to resolve a failure that looks related to a bad install of xcode 8.0 on our build bots and should be reinstated when the infra issue is diagnosed and resolved. instruments worked well when this was originally landed, and on the following commit, but started failing two commits after this originally landed. manual invocation of instruments on the build host currently results in: dyld: library not loaded: @rpath/instrumentsanalysiscore.framework/versions/a/instrumentsanalysiscore referenced from: /applications/xcode8.0.app/contents/developer/usr/bin/instruments reason: image not found abort trap: 6 it appears the /applications/xcode8.0.app/contents/applications directory (which contains instruments) is missing on the host. ", "commit_messages": " revert \"make device discovery asynchronous (#10803)\"  this reverts commit 972be9c8b4048e18ecfb8ab582159c8d78abace8.  revert required in order to revert  37bb5f1300e67fe590c44bb9ecda653b2967e347, which is triggering failures  on the chrome buildbots.  revert \"use xcode instruments to list devices (#10801)\"  this reverts commit 37bb5f1300e67fe590c44bb9ecda653b2967e347.  instruments worked well when this was originally landed, and on the  following commit, but started failing two commits after this originall  landed. manual invocation of instruments on the build host currently  results in:  dyld: library not loaded: @rpath/instrumentsanalysiscore.framework/versions/a/instrumentsanalysiscore  referenced from: /applications/xcode8.0.app/contents/developer/usr/bin/instruments  reason: image not found  abort trap: 6  it appears the /applications/xcode8.0.app/contents/applications  directory (which contains instruments) is missing on the host. ", "linked_issue_titles": "", "title": "revert use of xcode instruments for device lookup"}
{"description": " description adds emojis to the categories and adds a horizontal rule between cats. ignore the readme file, couldn't revert it back.. only edited the build.js script. what does your pr belong to? website snippets general / things regarding the repository (like ci integration) types of changes bug fix (non-breaking change which fixes an issue) enhancement (non-breaking improvement of a snippet) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) ", "commit_messages": " test readme gen  add emojis  revert readme back ", "linked_issue_titles": "", "title": "add emojis to readme categories"}
{"description": " when running on a cluster, users need to know which node to use for http requests. this is not a complete solution but at least gives the user some manual control - whichever node they first run serve.init() on will house the http proxy (usually the head node). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " pin http proxy  log ", "linked_issue_titles": "", "title": "pin http proxy to the node that serve.init() is run on"}
{"description": " this allows for a simpler preview loader architecture as node manifests can be requested directly from the deployed frontend of the gatsby site instead of requiring a server to check the filesystem in .cache. ", "commit_messages": " move processnodemanifests for inc builds  remove unused import  move node manifests to public dir ", "linked_issue_titles": "", "title": "write node manifests to public dir instead of .cache"}
{"description": " issue: #7264 #7773 #6803 #7162 rearchitect documentformatting & global css reset port doc blocks to new architecture add syntax highlighting for gfm code blocks now, there are a set of components such as { h1, h2, ... } that are exported from @storybook/components/html. these components are individually styled and can be used to render mdx without any need for global styling. for doc blocks, there is a <resetwrapper> component that can achieve most of what the global reset from theming used to do, but can do it locally within the block. what i need @domyen in addition to major restructuring, the major change here is that the global reset in @storybook/theming also includes styles for some child components, e.g.: '*': { boxsizing: 'border-box', }, 'h1, h2, h3, h4, h5, h6': { fontweight: typography.weight.regular, margin: 0, padding: 0, }, the resetwrapper code does not do any of this: it only does things like setting the font for itself and all descendants. therefore each of the components in documentformatting needs to be updated. since there are styling tweaks that need to be done anyway, i am leaving this to you. both @ndelangen and i are available to help as needed. to properly test this, you need to comment out l36 in examples/official-storybook/config.js: adddecorator(storyfn => ( <themeprovider theme={convert(themes.light)}> {/* <global styles={createreset} /> */} {storyfn()} </themeprovider> )); then: cd examples/official-storybook yarn storybook inspect: doc blocks stories new addons|docs/markdown stories docs for mdx files docspage for stories ", "commit_messages": " official-storybook: move addon-docs stories to subdirectory  addon-docs: rearchitect documentformatting, legacy to documentwrapper  addon-docs: restyle doc blocks with new documentformatting  addon-docs: markdown mdx for testing new documentformatting ", "linked_issue_titles": "", "title": "fix css bleed issue in doc blocks"}
{"description": " context and discussion:  tldr: a few teams have the convention to put hooks under a namespace and the current implementation doesn't catch hooks that are written this way. // is hook usesomething(); // is not hook => doesn't recognize foo.usesomething(); this prevented us from catching the true positives and started to cause issues, like t65929958. we want to extend the definition of ishook so that we can safely catch those that are used: on top level / not in react component or other hooks called in class component being conditionally called we intentionally don't include the namespace that are named in \"camelcase\" because there're a lot of false positive, eg: jest.usefaketimers this change requires us to move a few test cases that are used to be regression tests and were valid to invalid. test plan # under react > yarn test eslintrulesofhooks-test.js ", "commit_messages": " extend namespace to pascalcase  add valid case for jest.usefaketimer ", "linked_issue_titles": "", "title": "extend ishook to recognize those under pascalcase's namespace"}
{"description": " this pr also adds integer as a type of value when extracting values from _source. fixes #42858. ", "commit_messages": " cover the integer values when extracting field values from _source ", "linked_issue_titles": " sql: extracting a single small number from _source fails with error ", "title": "cover the integer type when extracting values from _source"}
{"description": " description: hi there, related to pr #11538, here you find a few more fixes and enhancements. they all work on my installation, will follow up for the automated linting/ci tests. a breaking change is commit 963b34e that changes the entity ids in ha. for this, i appreciate some feedback from @philklei as the original author and @bakedraccoon as the contributor of the above-mentioned pr. related issue (if applicable): pull request in home-assistant.github.io with documentation (if applicable): example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " strip off the rts/io id from the entity id  ignore exception thrown when the device does not provide an active state  send actions with a label for easier identification in the tahoma log ", "linked_issue_titles": "", "title": "fixes and enhancements for the tahoma platform"}
{"description": " we no longer have a separate powerpc64 and powerpc64le target_arch, and instead use target_endian to select between the two. these patches fix a couple of remaining issues. ", "commit_messages": " use target_endian, not target.arch in cabi_powerpc64  now target_arch is powerpc64 on both big and little endian, we need to  use target_endian when there are differences in the two abis.  target_arch is always powerpc64, remove powerpc64le check  we no longer need to check for powerpc64le, so remove it. ", "linked_issue_titles": "", "title": "powerpc64 fixes after removal of powerpc64le target_arch"}
{"description": " i hereby agree to the terms of the cla available at:  fix rare crash caused by using nullable column in prewhere condition. continuation of #11608 ", "commit_messages": " fix header for nullable prewhere column.  update tests. ", "linked_issue_titles": "", "title": "fix nullable prewhere type 2"}
{"description": " closes #20303 tests added / passed: pytest pandas/tests/reshape/test_qcut.py pandas/tests/reshape/test_cut.py -v passes black pandas passes git diff upstream/master --name-only -- \"*.py\" | xargs flake8 whatsnew entry ", "commit_messages": " update whatsnew file  add bool to int coerce  add bool to int coercion tests for cut and qcut  syntax changes  switch np.where condition to check if non nan ", "linked_issue_titles": " qcut raising typeerror for boolean series ", "title": "coercing bool types to int in qcut"}
{"description": " related: #18264 the current airflow version (2.x.x) supports custom xcom backends. and it means that the data from xcom could be larger than we think. (e.g. over 100gb) however, pythonoperator and leveldboperator will try to show all of those data from xcom as a log message. this issue can cause web issues such as breaking the web page (due to browser memory issue or rendering speed issue). and it also will make it difficult to see the other log message from the task. this pr suggests changing the loglevel info to debug, because xcom returned value can be treated debug purpose read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " feat: change the loglevel info to debug in pythonoperator  feat: change the loglevel info to debug in leveldboperator ", "linked_issue_titles": "", "title": "change loglevel as debug for xcom returned value message"}
{"description": " i have followed (at least) the pr section of the contributing guide. migrated the following demos to hooks/typescript: components/links/buttonlink.tsx components/links/links.tsx components/transitions/simplecollapse.tsx components/transitions/simplefade.tsx components/transitions/simplegrow.tsx components/transitions/simpleslide.tsx components/transitions/simplezoom.tsx components/typography/typographytheme.tsx customization/components/classesnesting.tsx customization/components/classesshorthand.tsx customization/components/classesstate.tsx ", "commit_messages": " [docs] migrate components/typography/typographytheme  [docs] migrate components/transitions  [docs] migrate components/links  migrate some demos in customization/components ", "linked_issue_titles": "", "title": "migrate batch of demos to hooks/typescript"}
{"description": " bug fix (user facing) code base improvement (dev facing) some users don't know how to properly tick the check boxes. so i've modified the issue templates to give an example each. agreement i carefully read the contribution guidelines and agree to them. ", "commit_messages": " added checkbox example  added checkbox example ", "linked_issue_titles": "", "title": "added an example of how to use markdown checkbox"}
{"description": " i had to create a new project because spring-all already had a lot of configuration and avoiding conflicts was going to take too much time. besides the reader will have a cleaner and much simpler project to understand. ", "commit_messages": " created spring-mvc-web-vs-initializer project  code style check ", "linked_issue_titles": "", "title": "created project \"spring-mvc-web-vs-initializer\" for the web.xml vs initializer article."}
{"description": " fixed a possible segmentation fault when no argument is provided. additionally, made tiny changes to print statements. ", "commit_messages": " fixed possible segmentation fault  fixed possible segmentation fault when no arg is supplied  update mean.c  various small changes to print statements. ", "linked_issue_titles": "", "title": "possible segmentation faults in numerical_methods/mean.c"}
{"description": " this pr fixes #109680. it consists of following major changes: leverage the list view template to reuse the editors. this way we don't keep creating/removing code/diff editors while scrolling limit the editor contributions used the embedded diff editors. avoid unnecessary overview ruler rendering. the diff editor is slower than the native notebook editor, simply because in the diff editor, the amount of monaco editors doubled. the creation and deletion of monaco editors has some cost, even if it's a few miliseconds, rendering 20 monaco editors in a large viewport can cost ~100ms. so the performance of scrolling in the diff editor is definitely slower than scrolling in a notebook editor with the same resource. ", "commit_messages": " allow init dimension for the diff editor and left/right side editors.  reuse source code editor  no longer render overview ruler.  fix memory leak  limit editor contribs in notebook diff view  delay cell text model disposing.  revert change to grooming notebook ", "linked_issue_titles": " scrolling in a notebook diff editor is sluggish ", "title": "notebook diff editor perf improvement"}
{"description": " addresses #20308 this pr ensures polynomialfeatures is compatible with numpydoc: remove polynomialfeatures from docstring_ignore_list. verify that all tests are passing. change docstrings to maintain consistency. ", "commit_messages": " remove polynomialfeatures from docstring_ignore_list  fix numpydocs from polynomialfeatures  change docstrings to maintain consistency ", "linked_issue_titles": "", "title": "doc ensures that polynomialfeatures passes numpydoc validation"}
{"description": " when an application emits a link: rel=preload header, the h2 implementation refers to a push memo to see if it has already pushed the specified resource over the same connection.  if the answer is true, the implementation ignores the header.  if the answer is false, then it pushed the specified resource (if other conditions are met). the memo is implemented as: uses #887 to implement a lru cache of 1,024 entries at maximum hash codes (x31) of urls being pushed are stored in the lru cache implements #896 ", "commit_messages": " tiny multi-thread cache implementation  add files to h2o.xcodeproj  add files to cmakelists.txt  simplify the api  make the use of mutex an optional feature  clang-format  early update should be an optional feature as well  return if an entry already existed  add failing test  implement push memo using h2o_cache_t ", "linked_issue_titles": "", "title": "don't push the same resource twice over a single h2 connection"}
{"description": " this is a fix to issue #19903 . when handle_unknow=\"use_encoded_value\", use super()._fit(x, handle_unknow=\"ignore\") to avoid raise error during the fit process. ", "commit_messages": " fix ordinalencoder fit with unseen category  add test cases ", "linked_issue_titles": "", "title": "fix ordinalencoder.fit should not raise an error  handle_unknown=\"use_encoded_value\""}
{"description": " the dynamic keymap (didn't know at the time) broke the keymap on my zeal boards and with the arrival of the m60-a i finally sat down to figure out why. this pr turns off dynamic keymap for my boards and brings m60-a into the hhkb layout. also brings back some of the backlight commands the broke during the zeal unforking. ", "commit_messages": " fix firmware to work with latest wilba changes (i.e. dynamic keymap) and m60a.  get back rgb backlight codes. ", "linked_issue_titles": "", "title": "update keymap to match latest changes to wilba's firmware."}
{"description": " while reviewing #17062 the line height of the code blocks seemed a little small. this pr makes it slightly bigger: this pr master ", "commit_messages": " sty better line height  sty changes lineheight  sty go to 1rem ", "linked_issue_titles": "", "title": "sty adjust line height of code blocks"}
{"description": " previously: //src/python/grpcio_tests/tests/unit:_server_test //src/python/grpcio_tests/tests/unit:_server_test.python3 //src/python/grpcio_tests/tests/unit:_server_test.python2 now: //src/python/grpcio_tests/tests/unit:_server_test //src/python/grpcio_tests/tests/unit:_server_test.gevent //src/python/grpcio_tests/tests/unit:_server_test.both_pythons //src/python/grpcio_tests/tests/unit:_server_test.python3 //src/python/grpcio_tests/tests/unit:_server_test.python2 this required an update to the rules_python dependency to support the namespace package structure that gevent and zope use. because of a change in behavior in rules_python between our (very old) version and the most recent version, systems without a python3 binary can no longer complete the analysis phase. this breaks windows rbe. i have introduced a patch to make this a soft failure rather than a hard failure. the newer version of rules_python also requires python 3.6+ to be present on the host during the analysis phase. this is a problem for our linux rbe images, which only have python 3.5. i have also turned this into a soft failure. this pr introduced the py_grpc_test rule. this is intended to encapsulate all of the test configurations supported by grpc python which, at the moment, include python 2, python 3, and gevent (under python 3). soon, python 2 will be removed. several tests do not work under gevent. in order to skip them, i have used unittest.skipif. i think this should be the standard way to do this going forward. as you might have guessed based on history, many of these tests are flaky. i have marked them as such so that they will be retried and will therefore not become a blocker for merging prs. ", "commit_messages": " wip  add gevent test suite run under bazel.  fix things up  yapf  fix up bazel files ", "linked_issue_titles": "", "title": "create bazel gevent test harness"}
{"description": " this pr changes the error message for two static patterns in a row. for example: class foo { class static func baz() { } // old: 'static' specified twice static class func bar() { } // new: 'class' cannot appear after another 'static' or 'class' pattern } resolves sr-11265. not sure if i have permissions for this: @swift-ci please test ", "commit_messages": " fix: error message  fix: error messages ", "linked_issue_titles": "", "title": "fix double static error message"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. this pr would resolve #24346. for information why i think the return type should be bigi see there. hoping i correctly raised this pr. if anything is wrong, please let me know ;) ", "commit_messages": " change return type of valueof to bigi  expand tests to cover the previous change ", "linked_issue_titles": " @types/bigi: wrong return type for `valueof` ", "title": "change return type of valueof to bigi (from number)"}
{"description": " this pr makes minor modifications to the text about versions in the operator specification files, as well as the change logs. the proposed text is a bit more concise than the existing text, without losing any precision in what it communicates. ", "commit_messages": " merge from main onnx repo  changing the string discussing versions in operator specifications.  merge from onnx base repo  merge from master ", "linked_issue_titles": "", "title": "more concise operator versioning text"}
{"description": " tokenizedbuffer (and displaybuffer) now emit a tokenized event once a buffer is fully tokenized. they also emit a tokenized event when the buffer's grammar changes and is re-tokenized. editor uses this event as a trigger to determine if a file should use hard or soft tabs. the tokenization event is needed because comments at the top of a file may contain different tab styles than the code and should not be used to determine the tab state. this information is only available after the buffer is tokenized. closes #2421 ", "commit_messages": " add tokenized event to tokenized buffer  use tokenized buffer created by editor  only emit the tokenized event after the first full tokenization  add spec to re-emit the tokenized event when the grammar is changed  determine softtab state after the buffer is tokenized.  reword specs ", "linked_issue_titles": " tokenizedline::iscomment returns the wrong value for javascript blockquotes ", "title": "use tokenized event to determine tab style"}
{"description": " this removes remained duplicated runs of ci for prs from the original repo and now is in consistency with appveyor and github actions configs. refer to #3096. ", "commit_messages": " update .vsts-ci.yml  update .travis.yml ", "linked_issue_titles": "", "title": "run travis and azure pipelines only for master branch"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ", "commit_messages": " fixing doc errors and spacing  tsdoc changes ", "linked_issue_titles": "", "title": "escaping characters to match tsdoc"}
{"description": " the cmake based packaging system is nice, but not quite production ready. move to the more painful but featureful debuild style. this is one step towards an upstreamable package. also, rename libbpfprog (ugh) to libbcc. split out python-bpf and libbcc-examples into separate packages that depend on libbcc. ", "commit_messages": " add proper debian build support  the cmake based build system is nice, but not quite production ready.  move to the more painful but featureful debuild style. this is one step  towards an upstreamable package.  rename libbpfprog (ugh) to libbcc.  split out python-bpf and libbcc-examples into separate packages that  depend on libbcc.  support versioning out of git tree in debuild  this adds support for properly tagging the build when cmake is run not  in a git tree, which is the case when building from src-deb. ", "linked_issue_titles": "", "title": "add proper debian build support, rename libbcc.so"}
{"description": " cherry-pick of #29258 into swift-5.2-branch explanation: if dictionary literal aren't well formed, implicit-member completion didn't use to work because it doesn't type check. this patch improves context type analysis for failed dictionary literal elements, so it increases the chance to successfully suggest completion inside dictionary literals. e.g. let dict: [someenum: string] = [.foo: bar, <here>] scope: code completion inside dictionary literals risk: low issue: rdar://problem/57096392 testing: added regression test cases reviewer: ben langmuir (@benlangmuir) ", "commit_messages": " [codecompletion] improve context type analysis for dictionary literal  - analyze the type of the literal in the context  - if ':' is missing in the literal, treat the expression as a key  expression  - if the parent expression is tupleexpr, analyze the context type of the  tuple first, then return the element type of the position  rdar://problem/57096392  (cherry picked from commit 95f12afb7c527338d824bf01377624d462659556)  [codecompletion] use codecompletionexpr as a value of dictionary literal  when a completion happens in a key position and the value expression  is missing. this allows type checker to use typevariable so it increases  the chance to type check them successfully.  (cherry picked from commit 9d44c455db90ddcf7557adada372842f03af1860) ", "linked_issue_titles": "", "title": "improve context type analysis for dictionary literals"}
{"description": " bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) all new and existing tests passed. ", "commit_messages": " chore: add missing deps to packages  chore: upgrade to webpack-bundle-analyzer@3 ", "linked_issue_titles": "", "title": "add missing package deps & upgrade to webpack-bundle-analyzer@3"}
{"description": " as discussed last week, one of ugliest runtime imports in tslibs is of tm for tm.set_locale.  this moves set_locale and a couple of other locale-related functions out of tm. as discussed in #25162, #25203, #25613, this moves the affected functions to a new directory pandas/_config, intended to be strictly \"upstream\" from the rest of pandas (potentially even made actually-upstream as suggested here). following this and #25613, a bunch of other cleanup/simplification becomes feasible. ", "commit_messages": " implement _config.localization to avoid runtime import in ccalendar  move a couple more funcs to localization, move test_locale to test_localization ", "linked_issue_titles": "", "title": "move locale code out of tm, into _config"}
{"description": " if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. this pr upgraded the configuration center plugin, etcd, to v3.x. i will upgrade it too for the service discovery plugin. we had a discussion on mail list. ", "commit_messages": " upgrade etcd to v3  update changes.md ", "linked_issue_titles": "", "title": "upgrade etcd cluster coordinator and dynamic configuration to v3.x"}
{"description": " #261 fix for invalid characters in dimensions generated by apps.plugin #268 netdataerrorcallback() enhancements ", "commit_messages": " enhanced error reporting in netdataerrorcallback() #268  users and group names are filtered for invalid characters #261  fixed source files permissions ", "linked_issue_titles": "", "title": "apps.plugin fix for invalid named; netdataerrorcallback enhancements"}
{"description": " adds a check to the prepare-stable script to prevent experimental builds from being published using stable semver versions. also updates the function that downloads the artifacts to pull from the correct ci job. i think instead of two separate ci workflows, a better approach might be to build stable artifacts to the build directory and the experimental artifacts to a build_experimental directory, and generate both within the same workflow. this would take some work since lots of things assume the output directory is build, but something to consider in the future. test plan ./scripts/release/prepare-stable.js --skiptests --version=0.0.0-experimental-d364d8555 and confirm that it exits with an error message. ", "commit_messages": " download correct artifacts for release channel  experimental builds should pull artifacts from the  process_artifacts_experimental job.  i think instead of two separate ci workflows, a better approach might  be to build stable artifacts to the build directory and the  experimental artifacts to a build_experimental directory, and  generate both within the same workflow. this would take some work since  lots of things assume the output directory is build, but something  to consider in the future.  prevent experimental promotion to stable  adds a check to the prepare-stable script to prevent experimental  builds from being published using stable semver versions. ", "linked_issue_titles": "", "title": "update release scripts to support experimental releases"}
{"description": " the next changes were made: the description of short script form was added. the mention of obsolete config parameter script.default_lang config parameter was removed. the link to \"how to use scripts\" was added to \"update by queue\" docs. @nik9000, please have a look on these changes. i've tested them with gradle and build them too. everything seems ok... ", "commit_messages": " adding the description of short script form  a mention of obsolete script.default_lang config param is removed  a link to \"how to use scripts\" is added to \"update by queue\" docs ", "linked_issue_titles": "", "title": "update docs about script parameter"}
{"description": " this pr proposes to migrate the test_compatible_versions unit test from snapshots to a blocks.log based system.  this removes any dependency on the post-conditions of the methods used to construct blockchains in our tester framework. instead of building a \"new\" chain in a way that was intended to be deterministic but rarely was in practice, the new process will load replay a small blocks.log file to reconstruct the head state of the chain with the latest code.   it will then systematically check that this state is also recoverable from v2, v3 and v4 snapshots of that same chain. this pr also restores the full integrity checksum based check. the blocks.log was created using v1.8.14 so as to have minimal requirements on the reading process.  if the minimum compatible blocks.log version exceeds the version produced by v1.8.14 then this blocks.log may need to be migrated to a newer version. the snapshots were created with the following versions based on this blocks.log: v2 : v1.8.14 tag v3 : v2.0.7 tag v4 :  26e4100 commit (aka head before the new snapshot was added) the unit test now takes an additional program option: --generate-snapshot-log which will attempt to deterministically recreate the blocks.log file prior to running the test.  this will not overwrite the repo version automatically.  there is no guarantee that the resulting chain matches the existing log but this may be useful in the future when a snapshot bump cleans out old versions and we want to start fresh the pre-existing --save-snapshot still works and will be useful as a forward compatible way of generating the future snapshots for this test.  when a new version is created, the author would need to add it to the list of tested versions, run the unit-test with --save-snapshot then copy the file(s) from <build>/unitttests/snapshosts/snap_v*.{bin,json}.gz to the working tree. ", "commit_messages": " migrate to log based construction  refactor snapshot test to build state from a blocks.log file instead of a set of tester methods; create v4 snapshots in prep for farming older versions  created a blocks.log compatible with 1.8.x  created v2 snapshots from v1.8.14 tag  created v3 snapshots from v2.0.7 tag  re-created v4 snapshots with the blocks.log that was 1.8.x compatible ", "linked_issue_titles": "", "title": "change to log based snapshot test"}
{"description": " description: found a bug in pythonegardia package, have fixed it. updating the requirements file and egardia.py file to require that new version (.18). ", "commit_messages": " bumping pythonegardia package requirement up to .18  updating requirements_all to reflect updated pythonegardia package .18 ", "linked_issue_titles": "", "title": "pythonegardia package requirement to .18"}
{"description": " directly support multiple axes + keepdims in c++. sum_axis, max_axis and min_axis can be depreciated. refer to #2197 . also, the mx.nd.sum(a) will now return a ndarray with shape (1,). the previous sum operator implemented using python will cast it to a float (see ", "commit_messages": " add full support of sum (multiple axes + keepdims)  fix style ", "linked_issue_titles": "", "title": "sum with axis full support"}
{"description": " cleanup 2/3 of style/test_bar.py. parametrises the tests for vmin/vmax clipping and widening, to test with different combinations of align. also adds fixtures for existing tests in the file. ", "commit_messages": " renamed a file ", "linked_issue_titles": "", "title": "styler bar tests cleanup 2/3"}
{"description": " this change shaved 175 kb off of our minified engine javascript. ", "commit_messages": " embind doesn't always need the full std::type_info record.  if emscripten_has_unbound_type_names=0, then use a lighter type identifier.  this shaves 175 kb off of our engine's minified javascript.  add a way to opt out of compiler-generated type names for smart pointers and wrapper types.  always require an explicit name for shared_ptr and wrapper type bindings  some compile fixes ", "linked_issue_titles": "", "title": "embind code size reduction by using lightweight rtti record for non-polymorphic types"}
{"description": " catch exceptions won't work with nested workflow. this pr fixed this. closes #18144 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " up  up  format ", "linked_issue_titles": " nested workflow with catch exceptions failed ", "title": "fix nested workflow with catch exception bug"}
{"description": " remove performance tests of type once. this is needed to run all performance tests in statistical comparison mode (more reliable). ", "commit_messages": " remove infinite performance tests  renamed a test  removed outdated info  addition to prev. revision  remove unused features from performance test ", "linked_issue_titles": "", "title": "remove performance tests of type \"once\", finally."}
{"description": " support for stubbing datetime.now with travel_to was added in #18758. it was later backported to 4-2-stable as part of d7ac341, but the tests and changelog entry were not included. the documentation update from #19303 is also included here. ", "commit_messages": " change as::testing::timehelpers#travel_to to also stub datetime.now  add datetime.now to list of timehelpers#travel_to stubbing [ci skip] ", "linked_issue_titles": "", "title": "backport tests, changelog and docs for travel_to datetime support to 4-2-stable"}
{"description": " this pr fixes the use case where the link is written like this: <a href=\"helloworld.htm\"><b>hello</b> world</a> with the previous implementation, it returned a link.text set to \"hello\". now, it returns \"hello world\", as expected. ", "commit_messages": " basesgmllinkextractor: fixed unknown_endtag() so that it only set current_link=none when the end tag match the opening tag  basesgmllinkextractor: added unit test of a link with an inner tag  basesgmllinkextractor: fixed the missing space when the link has an inner tag ", "linked_issue_titles": "", "title": "fixed link text when there is an inner tag"}
{"description": " this pr adds features so that namespaces work with the new session builder api. you can now do ray.client().namespace(\"hello world\").connect() note: part of this pr is an incidental bug fix where ray.runtime_context().get() was broken in client mode. the fix was necessary to make this pr work so it's included (along with the modification to the test case). closes #15949 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " add namespace to client  done? ", "linked_issue_titles": " getting namespace from global context doesn't work with ray client ", "title": "client builder api namespace support"}
{"description": " this is related to #27260. the elasticsearch-nio jar is supposed to be a library opposed to a framework. currently it internally logs certain exceptions. this commit modifies it to not rely on logging. instead exception handlers are passed by the applications that use the jar. ", "commit_messages": " work on remove logging from elasticsearch-nio  accept generic exception handlers  add doc ", "linked_issue_titles": "", "title": "remove logging from elasticsearch-nio jar"}
{"description": " i haven't removed ak::out yet, because i am expecting merge conflicts. (i mean pretty much everything wants to write to stdout at some point.) since we build with -werror, marking it with [[deprecated]] will produce a helpful error message and we can do the renaming of ak::new_out to ak::out in a week or so. ", "commit_messages": " ak: introduce sourcegenerator::fork().  previously, i abused the copy constructor, this is a lot better.  ak: eradicate the uses of out().  ak: add [[deprecated]] to out(). ", "linked_issue_titles": "", "title": "eradicate remaining calls to ak::out()."}
{"description": " null grid cells in sql lab's result set were no longer returning their muted styling (italicized and muted gray). this was fixed by applying the null styles through the rendertablecell function instead of rendergridcell. with  less than 50 columns (table) with 50+ columns (grid) go to the sql lab editor make a query that returns a null value observe the corrected styling includes db migration (follow approval process in sip-59) ", "commit_messages": " fix null styling in gridcell  removed unnecessary imports ", "linked_issue_titles": "", "title": "null styling in grid cell"}
{"description": " i hereby agree to the terms of the cla available at:  fix possible crash/wrong number of rows in limit n with ties when there are a lot of rows equal to n'th row. detailed description:  leak: ", "commit_messages": " fix limit with ties  get rid of sharedchunk ", "linked_issue_titles": "", "title": "fix limit with ties wrong result and memory leak in mergingsortedtransform"}
{"description": " plus add a compile option to target different versions of windows. needed because for touch events the lowest release is windows 7, but for 2.1 we are targeting vista. this code is donated to godot by adpodnet. (more on this on an upcoming blog post.) ", "commit_messages": " implement multitouch on x11  improve/fix multitouch on windows  - fix logic error.  - track touches to enable defensive handling and releasing on focus out.  - change comment-out by preprocessor #if.  add build param for targeted windows version  remove dead code from windows build script ", "linked_issue_titles": "", "title": "implement multitouch on x11 and improve it on windows (2.1)"}
{"description": " adds framework support for the floating cursor for text editing on ios. it can be triggered by either a force press on the keyboard or (on ios 12) by long pressing the spacebar. fixes #17030 (#5445). ", "commit_messages": " initial force cursor  adds force cursor  initial cursor implementation  minor fix  working floating cursor  nits  nits  adds test  nit  nit  nit  final nit  final nit ", "linked_issue_titles": " support keyboard cursor move on ios ", "title": "adds support for floating cursor"}
{"description": " added async support: refactored the tasks.py to return the query id and added ability to run the code async. changed the celery_tests to be more end to end (calling run_sql endpoint instead of celery function) added implementation of async run of the hive and presto queries added dependencies required by pyhive implemented progress bar for the async queries added extra fields to the query object to improve traceability: limit_used, select_as_cta_used, executed_sql, select_sql tackles backend of the: #858, #746, #886 implement progress bar for the presto / hive queries implement remote query execution it is a preliminary pr and some more things needed to be done. todo: unit test async queries (presto and hive engines) implement cancel_query endpoint add query_results endpoint ", "commit_messages": " refactor the query runner to enable async mode.  refactore the sql calling functions into the queryrunner class. ", "linked_issue_titles": "", "title": "async support for the queries in the sql lab."}
{"description": " new test: removelistenerwhendispatching customeventtest labelkeyboardeventtest spriteaccelerationeventtest ", "commit_messages": " issue #2087: init event::_userdata.  issue #2087: bug fix in eventdispatcher: _isregister fix.  issue #2087: adding new eventdispatcher test.  1) removelistenerwhendispatching  2) customeventtest  3) labelkeyboardeventtest  4) spriteaccelerationeventtest  issue #2087: enabling acc when testing it.  issue #2087: renaming eventdispatchertest name to eventdispatchertest(new) ", "linked_issue_titles": "", "title": "adding  new event dispatcher test and bug fixes."}
{"description": " this refactors incident details components to use typescript and adds additional + more accurate typings. ", "commit_messages": " rename to tsx  rename organizationincident -> incident  remove old proptypes  change to use await async  rename more files to .tsx  add more types ", "linked_issue_titles": "", "title": "refactor incident details to typescript"}
{"description": " converts sharp usage based on file paths to file streams, e.g. // before const imgstats = await sharp(file.absolutepath).stats() // after const pipeline = sharp() fs.createreadstream(file.absolutepath).pipe(pipeline) const imgstats = await pipeline.stats() for the writing of files we use sharppipeline.tobuffer() + fs.writefile() for now. we probably will change it to filestream in future pr (will just need to revert 31cfaf3). running the image-processing benchmark didn't show any major speed improvement/degradation ", "commit_messages": " copied changes  new changes ", "linked_issue_titles": "", "title": "use file streams instead of file paths"}
{"description": " issue: n/a this applies the eslint-plugin-storybook to the monorepo, as well as fixes for all of its recommended rules. there are quite a few changes. i added some @todo for discussions. ", "commit_messages": " add eslint-plugin-storybook  add temporary lint:storybook command  link eslint-plugin locally  clarify sb extract documentation  upgrade eslint-plugin-storybook to official release  attempt to fix some linting errors  disable default-exports rules for storiesof files  update eslint-plugin-storybook  apply eslint-plugin-storybook to all files  fix/disable eslint rules  apply prefer-camel-case rule to all story files  update eslint plugin and remove unecessary command ", "linked_issue_titles": "", "title": "add eslint-plugin-storybook to the repo"}
{"description": " this fixes a bug where styled components are overriding common container styles for stackedbarchart it also fixes a bug where colors were not working on projectfilterschart ", "commit_messages": " increase scoping to override styled component styles for project-filters-chart class  remove width: 100% and height: 100% from figure component because it is overriding traditional width and height styles ", "linked_issue_titles": "", "title": "svg chart excessive height / missing colors"}
{"description": " add associated slides fix typo ", "commit_messages": " fix typo in intro to scan in theano notebook.  add link to associated slides to intro to theano notebook.  * feature/theano-update:  add link to associated slides to intro to theano notebook.  fix typo in intro to scan in theano notebook. ", "linked_issue_titles": "", "title": "add slides to theano intro notebook."}
{"description": " this fixes #149 and #151 ", "commit_messages": " properly bundle all files in linux install step  run make install on linux build  use correct default magic database  set default magic db permissions correctly  fixed magic file detection issues  don't install default magic file if none was found  try fix windows packing issues ", "linked_issue_titles": " libimhex.so missing from binary download ", "title": "properly pack all dependencies into nightlies on all platforms"}
{"description": " the user can now put {'force_mirroring': 'true'} as attributes to force mirroring of a particular operator. @tqchen i got the following observations, did you observe similar thing when coding up the mirroring feature? some operators (e.g. batchnorm) will crash when mirroring is turned on, with some error like src/symbol/graph_executor.cc:606: check failed: (info.type) != (knotinitialized). the memory consumption is a bit mysterious to measure, for the cifar10 example. although i'm only using pycuda to query the total gpu free memory, which is a very rough estimation, i could see that running the exactly same network training (without touching any mirroring option) could actually lead to quite different reporting of memory consumption. ", "commit_messages": " add batch callback parameter to image training examples  script for testing mirroring memory consumption  a convenient interface for getting attr  use attributes to decide whether mirroring is enabled  use attributes to set force_mirroring  some comments on the cifar10-mirroring test case  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "using attributes to enable mirroring for an operator"}
{"description": " reverts #34097 somehow this was inadvertently merged by ansibot... ", "commit_messages": " revert \"adds restart_if_needed argument to nios_zone (#35191)\"  this reverts commit dd5256f3dfe66f34609c016cdf48906ec2e694cb.  revert \"aci: move to 'host' parameter instead of 'hostname' (#35161)\"  this reverts commit d6004852a2504cf3e5ed996c20b45b52d865a1e2.  revert \"win_setup: add product id and product key in facts (#34097)\"  this reverts commit cf1f7b53dfb88f996593ec37fe455c0a2e272758. ", "linked_issue_titles": "", "title": "add product id and product key in facts\""}
{"description": " i added title case to the article headings on each of the pages for parts 0-5 (though not all parts needed edits). ", "commit_messages": " remove title case from the heading to match the sidebar menu  changed all top-level headings to title case  all top-level headings (the main steps) were converted to title case. the sub-headings were left in sentence case. also changed instance of css in all lowercase to uppercase.  change article heading for part-one to title case  change article heading for part-two to title case  change article heading for part-three to title case  update index.md ", "linked_issue_titles": "", "title": "added title case to tutorial page headings parts 0-5"}
{"description": " as far as netfilter statistics can be obtained with root access rights only, the nfacct plugin was separated from netdata daemon so that it isn't needed anymore to run the daemon as root for collecting netfilter stats. fixes #3749 component name nfacct plugin ", "commit_messages": " prepare build configuration  prepare plugin for separating  add command line options  add debug messages  use text api  minor fixes  update the documentation ", "linked_issue_titles": "", "title": "split nfacct plugin into separate process"}
{"description": " hi. i have a user in canada with a 2019 civic sedan touring that's now working. out of the box, it fingerprinted as 2017 hatchback. only difference i've noticed in this car is a lack of doors_status at 0x405 (still looking for this if it moved). right now, we're using self.standstill and self.door_all_closed like on accord as the only major changes. only remaining complaint is improper reporting of set speed as he uses metric on the eon (to be expected afaik). as both cars will fingerprint as hatchback ex, we could potentially merge these. we have a user with hatchback touring if we want to replace the ex print with that. vehicle weights are obviously slightly different. dbc file is unchanged as it used as-is from the 2017 car. note: early stages of testing on this, but initial impressions are its working fine. ", "commit_messages": " fingerprint and new car  you know the drill  fix  mod civic hatch to work for now  try to merge hatch and other bosch  fix ", "linked_issue_titles": "", "title": "merge new 2019 civic and existing 2017-18 civic hatch"}
{"description": " i have read contributing.md. this pr only changes one algorithm file.  to ease review, please open separate prs for separate algorithms. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " created problem06 in projecteuler  updating directory.md ", "linked_issue_titles": "", "title": "created problem06 in project euler"}
{"description": " in preparation for being able to parse searchresponse from its rest representation for the java rest client, this adds fromxcontent to searchprofileshardresults and its nested classes. ", "commit_messages": " adding parsing to profileresult  adding parsing to aggregationprofileshardresult  add parsing to queryprofileshardresult  add parsing searchprofileshardresults  small test changes concerning parsing time strings in profileresult and collectorresult ", "linked_issue_titles": "", "title": "add parsing from xcontent to searchprofileshardresults and nested classes"}
{"description": " tc (qos) plugin has been optimized a bit. it also now supports reporting packets and dropped packets. there is more information already parsed by the plugin, per class, like lended traffic, borrowed traffic, etc. if anyone is missing this info, i can easily add it too. applied the last installer fix that protects charts.d config files, to node.d too. ", "commit_messages": " prevent overwriting node.d configurations while copying  tc plugin now cleanups properly; added tc packets and dropped packets charts  added tc qos options to control individual charts ", "linked_issue_titles": "", "title": "qos plugin now reports packets and dropped packets; installer now protects node.d config files"}
{"description": " the dim curve was somehow strangely applied to the saturation and value when setting the hsv. now it correctly applies the lightness adjustment to each color after doing the calculation. previously it would loose a lot of the color range, and the fading between colors in the rainbow mood and rainbow swirl effects were not smooth at all due to this. i also changed the dim curve to use the correct cie 1931 formula (i think it looks slightly better than the original one). it's still not perfect, especially at the low brightness levels. you can easily see jumps there. that's caused by the fact that the ws2812 only take 8 bits values, and many of the brightness values that the eye can see are not representable with only 8 bits per channel. this could be fixed if some high frequency dithering was applied. edit i forgot to say that the overall brightness of the leds might change a bit with this, so you might need to re-adjust the brightness level of you keyboard after applying this pull request. ", "commit_messages": " apply the dim curve to the rgb output  just like it's supposed to be used. it now looks much better.  cie 1931 dim curve ", "linked_issue_titles": "", "title": "improve the rgb led effects"}
{"description": " this currently has a few issues: 1.) this value is the number of tags that have been seen across the entire project -- not just the number of tags that have been seen for this issue -- so it's super confusing on the group tag page when all of the other values are scoped to values seen within the group. this reference was removed for the grouptagvalues react view with gh-4589, presumably because it was confusing there as well. 2.) it's not recorded correctly on the backend (see gh-5554) and is not a high priority to fix in the near future. ", "commit_messages": " remove uniquevalues count from tag display ui.  remove unique values from settings/tags/. ", "linked_issue_titles": "", "title": "remove unique tag counts display."}
{"description": " newly added groups were always initialising their z index to zero, instead of their position in the parent child list. ", "commit_messages": " fixed  new groups incorrectly always adding with a z index of 0  removed this.z =0, missed from last push ", "linked_issue_titles": "", "title": "groups always had zero z index"}
{"description": " this pull request will fix the hardcoded paths noted in issue #44, adds a script (not a very good one) that makes the cheatsheets folder and pulls in remote repos to populate it and also updates requirements.txt to add the additional needed requirements. ", "commit_messages": " fix srv.bin to work -- listens on 0.0.0.0  adapter_learnxiny updated to not use hardcoded path  get_answer.py updated to not use hard coded path  replaced hardcoded paths with something kept local to the cheat.sh folder  panela_colors not using hardcoded path  less than ideal script to grab cheatsheets from different repos  added additional requirements ", "linked_issue_titles": "", "title": "remove hardcoded paths, add script to get sheets, fix requirements"}
{"description": " removing the script and image  element from the previewing svg to avoid loading images or run scripts from unknown resources. in case of script or image element is found an information bar will be shown on the top of the preview. references pr checklist validation steps performed tests passed and validated changes locally. ", "commit_messages": " added implementation to remove script and image tag  added unit tests for svgpreviewhandlerhelper  updated unit tests for svgpreviewcontrol ", "linked_issue_titles": "", "title": "remove script and image element from svg"}
{"description": " explanation: adds support for keypaths that reference computed properties requiring the capture of generic context. scope: completes the support for property references in key paths. the previous restriction here is difficult to explain to users otherwise. issue: rdar://problem/31768590 risk: low. additive improvement to key paths, should be almost no impact on the rest of the compiler. testing: swift ci ", "commit_messages": " keypaths: support captured arguments in computed components.  a necessary precursor to supporting subscripts and unspecialized generic accessors in general. give get/set components the ability to have an \"argument\" area that gets instantiated by copying out of the key path pattern arguments at instantiation time, and which holds \"witness\" information for how to copy, destroy, equate, and hash arguments.  irgen: support for computed properties with dependent generic context.  use the keypath implementation's new support for instantiating and dealing with captures to lower the generic context required to dispatch computed accessors with dependent generics.  irgen: builtin.unknownobject should not be hardcoded to use objc refcounting.  it's more appropriate to use unknown refcounting, which we correctly handle in the face of non-objc-interop elsewhere. fixes a problem where the linux standard library would contain an unresolvable reference to objc_release. ", "linked_issue_titles": "", "title": "support keypaths with dependently-generic computed components."}
{"description": " #4368 greylisted accounts are not allowed to access extended cpu/net limit in a subjective way. \"cloes get account\" will return the subjective cpu/net limit. if a transaction violates the cpu/net subject limit, it will be rejected by the node immediately. block replay & apply_block will always use the objective cpu/net limit for validation. command line options for producer (can appear multiple times): --greylist-account \"a11111111111\" new api urls: /v1/producer/add_greylist_accounts /v1/producer/get_greylist /v1/producer/remove_greylist_accounts ", "commit_messages": " 4368 subjective to disallow account to access extended cpu/net limits ", "linked_issue_titles": "", "title": "subjective extended cpu/net resource access"}
{"description": " i simply replaced all instances of \"magisk manager\" with \"magisk app\" ", "commit_messages": " replace \"magisk manager\" with \"magisk app\"  to stay consistent with the new name  replace \"magisk manager  replace \"magisk manager\" with \"magisk app\"  to stay consistent with the new name ", "linked_issue_titles": "", "title": "update docs to use the magisk manager's revised name"}
{"description": " update the ergodox / atreus 42 key layouts with cloud 9 ide shortcuts ", "commit_messages": " add screen_nav layer for copy/pasting within screen  working readreg/paste macros  working read reg / paste macros  write log and tran patterns, and expand  add ls -la shortcut, add tab on combined layer  put delete word on the right pinky key on shell_nav layer  add tab on the right side, add reset key  merge remote-tracking branch 'upstream/master'  added cloud9 macros  add cloud9 shortcuts to atreus layout  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "update dvorak 42 key layouts"}
{"description": " for your consideration, this change adds a couple del statements to the teardown method in asynchttptestcase in order to encourage the gc to free up resources passed through application settings. if you are willing to merge this pr, i'd love to also see it applied to the 5.x and 4.x branches. ", "commit_messages": " updated asynchttptestcase teardown to release app references  releasing the application and http server references in teardown helps  encourage the gc to clean up resources passed through the application  settings.  empty commit to trigger travis build  switched to double quotes to make black happy.  fixed mypy errors by referring to self correctly. oops. ", "linked_issue_titles": "", "title": "release app references in asynchttptestcase teardown method"}
{"description": " closes #16939 ", "commit_messages": " fix ice in overloaded call with incorrect arity  when an overloaded call expression has parameters but the function  object takes none, construct an array of formal argument types with  the arity of the call expression so that we don't fail by indexing out  of bounds later.  closes #16939  add regression test for issue #16939 ", "linked_issue_titles": " ice calling an unboxed closure with the wrong number of parameters inside another closure ", "title": "fix ice when checking overloaded call with wrong arity"}
{"description": " resolve #4918, fix #5235. the important bits that i gathered from the discussion were: drf should internally encode/decode only strict json, since other modules (eg, postgres's jsonfield) may not be compatible with the extended float values (infinity, nan). incompatible values should raise an exception. users may still want to render/parse extended json. this pr does the following: adds an internal rest_framework.utils.json module that defaults to strict json encoding/decoding. all imports have been changed to rest_framework.utils.json, so they obey the stricter behavior. adds flake8-tidy-imports, which allows us direct users to import the json wrapper module. adds settings.strict_json, which controls the strictness of jsonparser & jsonrenderer. this defaults to true, but users can revert to the old extended behavior by setting this to false ", "commit_messages": " add json util wrapper, failing jsonfield test  update json imports  add 'strict_json' api setting.  strict_json controls the renderer & parser behavior on whether or not  to accept non-standard float values (nan, infinity).  add banned imports to prevent standard json import ", "linked_issue_titles": " jsonfield: infinity, -inifinity, nan are not compatible with postgres' json field ", "title": "use strict float handling in json functions"}
{"description": " the crash mentioned in the linked issue was happening because we use a single keyboardmanagerstate variable for both of the windows, so when one of the windows is closed there is most likely something getting set to nullptr while a window is still open. the way the code was written was considering only one window open, so the best way to solve this with minimal changes is to ensure only one window can be opened at a time. the pr changes the behavior of the buttons, such that when clicking either of the buttons - if edit keyboard or edit shortcut either of them are open, it will bring that window in focus. earlier if edit keyboard was open and you clicked the same button again, it would just bring that to focus. by this change we ensure that only one window is open at a time, and by bring that in focus the user should also notice the window lying open. this is a first step for #2466 . the pending work for the modal dialog is to prevent the user from being able to access the settings window while this dialog box is up. this also adds a fix where the remap button would stop working if you closed kbm from the taskbar (the runner would not crash though). pr checklist applies to #2469, #2569 cla signed. if not, go over here and sign the cla validation steps performed tried closing and reopening the windows with both the buttons multiple times. ", "commit_messages": " bypass xamlbridge window focus handling  constrain only one window can be opened at a time  revert changes on files changed in another pr ", "linked_issue_titles": "", "title": "constrain the buttons such that only one of the windows can be opened"}
{"description": " this change makes use of the generated protocols for fetchrequest and fetchresponse. the main challenge here was how to allow the transferrable bytes of the record set to be directly sent to the outgoing response without copying into a buffer. the proposed solution is similar to the existing multi-send object used in fetchresponse. however, a new writer class recordswriter was introduced to allow interleaving of bytebuffersend (for headers and other non-record fields) along with recordssend-s which implement the efficient byte transfer. another change introduced here is that fetchrequest and fetchresponse do not maintain their own copies of the fields from the message. instead, they hold a reference to the generated message class (fetchrequestdata and fetchresponsedata). read-only copies of different forms of the message data are created once open construction to allow for efficient access using the existing class methods. for example, in fetchrequest we hold the fetchrequestdata, but also compute and hold: private final fetchrequestdata fetchrequestdata; // these are immutable read-only structures derived from fetchrequestdata private final map<topicpartition, partitiondata> fetchdata; private final list<topicpartition> toforget; private final fetchmetadata metadata; and in fetchresponse, we similarly hold: private final fetchresponsedata fetchresponsedata; private final linkedhashmap<topicpartition, partitiondata<t>> responsedatamap; if we want, we could deprecate all the accessors on fetchrequest/fetchresponse and force callers to use the #data() method. this would eliminate the need for these additional data structures. finally, most of the other changes are fixing up tests that were actually using invalid default values for protocol messages (which are now enforced, thanks to the generated classes) as well as rectifying the json schema to match what the actual defined schemas were (e.g., fetch_response_v11) ", "commit_messages": " kafka-10265 use the generated messages for fetchrequest and fetchresponse  fix compile errors and checkstyle ", "linked_issue_titles": "", "title": "kafka-9629 use generated protocol for fetch api"}
{"description": " if users feed single persistable variable to pe, this variable will be copied n(the number of place) copies, and feed those variable to different place separately. fix #18809 ", "commit_messages": " update executor  update executor feed  update executor feed  test=develop ", "linked_issue_titles": " cpu_num 10batch_size = 500 ", "title": "support feed single persistable variable to pe"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).   if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " refactor(fluent-ffmpeg): update types to match official api specification  refactor(fluent-ffmpeg-tests): add missing semi-colon  refactor: update metadata in definition file ", "linked_issue_titles": "", "title": "update certain methods in ffmpegcommand interface"}
{"description": " we were allowing the pmrem cubemap size to vary based on the input images, but we had hard coded 256 as the size within the glsl.  this pr makes it clear that we have fixed the size and we also no longer varying the cubemap size based on the input. ", "commit_messages": " pick a good default pmremgenerator cube size, and allow it to be overriden.  fix the resolution to what is hard coded in the shaders. ", "linked_issue_titles": "", "title": "fix pmrem cubemap size at 256 for performance reasons"}
{"description": " the current license file is a source header. i've replaced that with a full apache 2.0 text file, and added a notice file. the notice file will need changing, post migration when the code is fixed to match apache software foundation formats/policies. ", "commit_messages": " creating notice.  when code moves to apache, it will need adjusting to the apache format.  replacing source header with full license text ", "linked_issue_titles": "", "title": "fixing license file and adding notice"}
{"description": " new round of cmake improvements: added lzma, zlib support cmake creates pkg-config file from prepared template files are copied to working copy during build not during configure phase anymore (should be less confusing this way) fixed appending compile definitions this pr bumps the required cmake version to 2.8.9 to support finding lzma library. i think we agreed on sticking to versions < 2.8.12 in earlier iteration, but feel free to correct me. ", "commit_messages": " add lzma and zlib support to cmake build system  cmake 2.8.9 needed for findliblzma  copy files during build phase, custom targets instead of commands  previously some files were copied only during configure phase.  custom targets seem nicer.  create and install pkg-config file with cmake  test new cmake branches with circle ci  change all set_target_properties to set_property  set_property function can append to lists, whereas previously used  set_target_properties cannot. ", "linked_issue_titles": "", "title": "add zlib, lzma, pkg-config support to cmake build system"}
{"description": " this helps in resolving the react identifier correctly. fixes #11654 ", "commit_messages": " add testcase for incorrect emit of jsx  when creating react namespace identifier, set its parent to jsx opening element in the parse tree  this helps in resolving the react identifier correctly and fixes #11654 ", "linked_issue_titles": "", "title": "set parent of reactnamespace identifier to be parse tree node"}
{"description": " though this might seem in opposition to @tenderlove's #35404  it's made with the same goal of improving how we construct templates and keeping them immutable. previously, when a template without a format (ex. index.erb) was rendered, it was assigned the first format from details. though this was a convenient default, i'd prefer we didn't store it on template, and used that fallback explicitly at a higher level. this way template is only based on the file itself, and the set of locals it is passed. ", "commit_messages": " allow format to be nil  create templates with format=nil  remove query_format argument from resolver ", "linked_issue_titles": "", "title": "allow nil format on templates"}
{"description": " added 'setmulticastinterface(netif*)' added a getter for the used 'udp_pcb' -> 'udp_pcb* pcb()' the information about the originating netif is also only available while processing 'onrx'. added the netif to the temp stored data and added a getter for this. ", "commit_messages": " addition to udpcontext needed for leamdns2  addition to udpcontext needed for leamdns2 ", "linked_issue_titles": "", "title": "additions to udpcontext needed for leamdns2"}
{"description": " this pull request switches the guids for default profiles from being randomly generated to being version 5 uuids. more info in #870. closes #870 requires documentation to be updated (#883) this pull request has a number of changes that seem ancillary, but they're general goodness. let me explain: i've added a whole new types test library with only two tests in since uuidv5 generation requires sha1, we needed to take a dependency on bcrypt i honestly don't think we should have to link bcrypt in conhost, but lto should take care of that i considered adding a new terminal-specific utils/types library, but that seemed like a waste the best way to link bcrypt turned out to be in line with a discussion @miniksa and i had, where we decided we both love apisets and think that the console should link against them exclusively... so i've added onecore_apiset.lib to the front of the link line, where it will deflect the linker away from most of the other libs automagically. startgroup: uuidtests::testv5uuidu8string verify: areequal(uuidexpected, uuidactual) endgroup: uuidtests::testv5uuidu8string [passed] startgroup: uuidtests::testv5uuidu16string verify: areequal(uuidexpected, uuidactual) endgroup: uuidtests::testv5uuidu16string [passed] ", "commit_messages": " generate uuidv5s for default profiles  closes #870.  add a comment about using memcpy  clean up  move to types, add tests, finish almost everything ", "linked_issue_titles": " feature request: stable uuids for default profiles ", "title": "switch to v5 uuids as profile guids for the default profiles"}
{"description": " md-toast now uses textcontent instead of content - content is deprecated ", "commit_messages": " update text to textcontent for 1.0.0-rc5  update content to textcontent for 1.0.0-rc5  md-toast now uses textcontent instead of content - content is deprecated ", "linked_issue_titles": "", "title": "update md-toast text to textcontent for 1.0.0-rc5"}
{"description": " the content_type parameter was renamed to response_class in release 0.19.0 tangential question to maintainers: this is the 3rd documentation-related pr i've opened this week. they all fall into different categories, but all have fairly small changes. is this disruptive? would it be better to condense any near-future prs into a single \"documentation\" pr? thanks in advance! ", "commit_messages": " fix renamed parameter typo (content_type)  renamed to response_class in release 0.19.0.  specify response_class is a decorator parameter ", "linked_issue_titles": "", "title": "fix renamed parameter content_type typo"}
{"description": " while i made this pr because we need the constants.getwebviewuseragentasync() in our project; i also noticed that the property installationid was missing. no test were defined so i also added them. see the expo documentation for constants for more info. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added missing properties 'installationid' and 'getwebviewuseragentasync()' to 'constants' declaration  added tests for 'constants' declaration ", "linked_issue_titles": "", "title": "added missing 'installationid' and 'getwebviewuseragentasync()' to 'constants'"}
{"description": " fixes #14792 closes #14814 the project id is currently used by sanity's image builder, which is used in a react component. @maybac it was faster for me to create a new pr but the credit goes to you, thank you!. ", "commit_messages": " use public env for the project id  moved util ", "linked_issue_titles": " [cms-sanity] add `next_public_` to readme env variables ", "title": "expose the project id to the browser"}
{"description": " use npx and yarn create to run create-next-app for each example in examples/. this: requires no additional install from the user as these both come with their respective package managers (npx with node ^8.x.x) skips an additional command, reducing the \"getting-started\" friction keeps global install of create-next-app up to date (not sure if npx actually pulls the latest) installs create-<starter-kit-package> globally, or update the package to the latest version if it already exists - yarn docs for those interested, this was done by: removing the npm i -g ... line with: for d in * ( cd $d && sed -i '/npm i -g create-next-app/d' readme.md ) done prepending npx to the execution command with vscode find: create-next-app --example replace: npx create-next-app --example adding the yarn command with: for d in * ( cd $d && sed -i \"/npx create-next-app --example/a # or\\nyarn create next-app --example $d $d-app\" readme.md ) done this would have been easier had i learned sed properly prior to step 1. or 2. and just written a single command. interesting nonetheless. ", "commit_messages": " remove global npm install of create-next-app  add npx to create-next-app command in examples  add bash to shell snippets  add yarn create to next-app command in examples  fix readmes named with lowercase  change readmes to use uppercase ", "linked_issue_titles": "", "title": "use npx and yarn create to run create-next-app on examples"}
{"description": " closes #1305 fixed an issue where \"possible eventemitter memory leak detected\" warnings could appear when running multiple specs. increased plugin child ipc listener limit to infinity so the unneeded warning ceases fixed an actual event listener leak in electron downloads code updated process.emitwarning patching to still log warnings in development, but in production, only log warnings to debug log has the original issue or this pr been tagged with a release in zenhub? ", "commit_messages": " fix electron eventemitter memory leak in downloads  raise eventemitter limit, suppress warnings in prod ", "linked_issue_titles": " do not display maxlistenersexceededwarning \"warning: possible eventemitter memory leak detected.\" warning message during cypress run ", "title": "suppress eventemitter warnings + other node warnings in prod"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). note: the documentation link below is to the v9 documentation. there is no published documentation for v7; however, the code itself proves this change to be correct. in the v7 definitions, each interface that extends attribute has a getvalue() function. provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added getvalue() and setvalue() to xrm v7 xrm.page.attribute.  xrmpageenumattribute - added getvalue and setvalue  revert \"xrmpageenumattribute - added getvalue and setvalue\"  reverted incorrect changes to xrmpageenumattribute  this reverts commit 9a14d6a289e41dcbd6ed8b0ae91c172c701dd756. ", "linked_issue_titles": "", "title": "xrm v7 index- added attribute.getvalue and setvalue"}
{"description": " this pr makes the following changes: on the edit keyboard screen, key remappings are not applied, so even if the user has orphaned a key, then can still search with it in the drop down menu on the edit shortcuts screen, shortcut remappings are not applied, so even if the user has orphaned a shortcut, then can still use it on that window. this is for consistency with the above behavior. commented out app-specific and togglekeytomodifier handlers in the back-end (even though they wouldn't technically do anything unless they were in the settings). this can be uncommented when we add in the feature to the ui. pr checklist applies to #2551 cla signed. if not, go over here and sign the cla validation steps performed manually verified that even if a key is orphaned you can still use it in edit keyboard you can't use it if you change focus to another app and try typing - to make sure \"apply\" makes sense ", "commit_messages": " commented out toggletomod and appspecific function calls  added logic to make sure key remaps don't occur on edit keyboard window ", "linked_issue_titles": "", "title": "change behavior on edit keyboard screen to be physical keys"}
{"description": " i hereby agree to the terms of the cla available at: ", "commit_messages": " rename block to columnswithtypeandname.  rename block to columnswithtypeandname.  rename block to columns.  rename block to columns.  rename block to columns.  rename block to columns.  rename block to columns.  rename block to columns.  rename block to columns. ", "linked_issue_titles": "", "title": "use columnswithtypeandname instead of block for function calls [part 3]"}
{"description": " added a new site:  fixed few typos and updated few comments to follow pep-8 standards note: few tests failing before the following commits ", "commit_messages": " fixed grammar, typos, comments  added new site: 7cups ", "linked_issue_titles": "", "title": "added 7cups site; fixed typos"}
{"description": " fixes #3272 it seems that only a few backends (including llvm, metal) support struct-for, and i only fix this problem for llvm cuda and cpu backends. not sure whether this works for metal. ", "commit_messages": " fix continue in struct for and add a test ", "linked_issue_titles": " [ir] continue statement behavior is confusing in struct for ", "title": "fix continue statement in struct for and add a related test"}
{"description": " your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description ... test plan ... closing issues ... ", "commit_messages": " improve mips.cs esil  update  update sign  modify old test  fix mips32  modify test file  code style  inline  update mthi  upstream  kill warning ", "linked_issue_titles": "", "title": "fix anal_mips_cs some compile warning"}
{"description": " this is my first rustc code change, inspired by hacking on clippy! the first change is to clear cached typeckresults from latecontext when visiting a nested item. i took a hint from here. clippy has a qpath_res util function to avoid a possible ice in latecontext::qpath_res. but the docs of latecontext::qpath_res promise no ice. so this updates the latecontext method to keep its promises, and removes the util function. related: rust-lang/rust-clippy#4545 ", "commit_messages": " reset latecontext enclosing body in nested items  prevents latecontext::maybe_typeck_results() from returning data in a  nested item without a body. consequently, latecontext::qpath_res is less  likely to ice when called in a nested item. would have prevented  rust-lang/rust-clippy#4545, presumably.  query for typeckresults in latecontext::qpath_res  actually fulfills the documented guarantees.  remove qpath_res util function ", "linked_issue_titles": "", "title": "improve safety of latecontext::qpath_res"}
{"description": " this fixes the nll migration mode (which is the default with edition=2018) to inspect all parents of a closure in addition to the closure itself when looking to see if ast-borrowck issues an error for the given code. this should be a candidate for beta backport. fix #55492 ", "commit_messages": " borrowck=migrate mode needs to check parent(s) when its given a closure.  regression test for issue 55492.  update compare-mode=nll stderr files to reflect the fix to #55492. ", "linked_issue_titles": " nll: migration mistakenly downgrades when ast error is spread across closure and its parent ", "title": "borrowck=migrate must look at parents of closures"}
{"description": " hi all @apache/skywalking-committers according to openjdk website( java 8 (lts). at least may 2026 java 11 (lts). at least oct 2024 we should make the jdk11 compiling passed. that is the primary agenda when i started this work. also, with doing this, i planned to upgrade the grpc too. during the jdk11 compiling fix, the version of powermock was detected as the main block, so, i upgraded it to the 2.x directly. so, you would note, some libraries' versions(such as protobuf, protoc) changed because of grpc or powermock requirements. some tests are deleted because they are not valid in the latest powermock. sorry, i don't have enough time to fix all, because some of them make no sense to me. license updated if you have any concerns, please reply. ", "commit_messages": " upgrade dependencies and make the jdk11 compiling passed.  update license and fix license check file.  add ci for jdk11 compiling.  update doc. ", "linked_issue_titles": "", "title": "support jdk 11 compiling and upgrade dependencies"}
{"description": " add missing 'ended' method to the player declaration. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). -ended(): boolean; < ", "commit_messages": " makes repository up to date  adds player ended method  fixes  some lint errors. ", "linked_issue_titles": "", "title": "adds missing 'ended' method to the player"}
{"description": " i think you'll prefer the second simpler version (which i'll think you'll get if you just squash/merge) - but i kept the first, more complex version in so you could see it. for issue #136 ", "commit_messages": " stop warning on fgets, complex version  stop warning on fgets, simple version ", "linked_issue_titles": "", "title": "stop warning on fgets, jq_test.c:42"}
{"description": " this is related to #36652. in 7.0 we plan to deprecate a number of settings that make reference to the concept of a tcp transport. we mostly just have a single transport type now (based on tcp). settings should only reference tcp if they are referring to socket options. this commit updates the settings in the docs. and removes string usages of the old settings. additionally it adds a missing remote compress setting to the docs. ", "commit_messages": " wip  wip  cleanups ", "linked_issue_titles": "", "title": "update transport docs and settings for changes"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " minio: fixed .listbuckets() method signature  updated minio package version ", "linked_issue_titles": "", "title": "fixed .listbuckets() method signature, bucketitemstate interface"}
{"description": " this pr updates the following tests to cover migration till release-1.11 (including release-1.10 and release-1.11): cepmigrationtest bucketingsinkmigrationtest flinkkafkaconsumerbasemigrationtest continuousfileprocessingmigrationtest windowoperatormigrationtest statefuljobsavepointmigrationitcase.scala statefuljobwbroadcaststatemigrationitcase.scala c768117 fixes for cepmigrationtest aaf5040 fixes for bucketingsinkmigrationtest 7d2b7cf fixes for flinkkafkaconsumerbasemigrationtest a1f07bd fixes for continuousfileprocessingmigrationtest 2be0da4 fixes for windowoperatormigrationtest 96e67ee fixes for statefuljobsavepointmigrationitcase f945735 fixes for statefuljobwbroadcaststatemigrationitcase for each test, we creates the corresponding savepoint/checkpoint files by running the corresponding write*snapshots() methods with the corresponding branch. adds 1.10 and 1.11 versions to the migration test version list. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? not applicable ", "commit_messages": " [flink-18552][tests] update migration tests of cepmigrationtest to cover migration till release-1.11  [flink-18552][tests] update migration tests of bucketingsinkmigrationtest to cover migration till release-1.11  [flink-18552][tests] update migration tests of flinkkafkaconsumerbasemigrationtest to cover migration till release-1.11  [flink-18552][tests] update migration tests of continuousfileprocessingmigrationtest to cover migration till release-1.11  [flink-18552][tests] update migration tests of windowoperatormigrationtest to cover migration till release-1.11  [flink-18552][tests] update migration tests of statefuljobsavepointmigrationitcase to cover migration till release-1.11  [flink-18552][tests] update migration tests of statefuljobwbroadcaststatemigrationitcase to cover migration till release-1.11 ", "linked_issue_titles": "", "title": "update migration tests in master to cover migration till release-1.11"}
{"description": " this pull request adds a missing closing parenthesis in the insert statement generated for postgresql in upsert mode. added missing parenthesis in generated sql statement the effect of this change was verified against a local postgresql database where the sink was erroring out without the fix. dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (no) the serializers: (no) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (no) ", "commit_messages": " added missing closing paren to postgresql on conflict clause  typo ", "linked_issue_titles": "", "title": "correct syntax for postgresql dialect \"upsert\" statement"}
{"description": " i double checked my bidirectional rnn code and looked closely to the theano scan implementation and i found an error where the return sequences flag is active. (it actually return the reversed sequences that may cause failure in particular where stacking bidirectional layers. here is the fix. ", "commit_messages": " up do date 2  fixed an error in backward computation of recurrent layers on return sequences. ", "linked_issue_titles": "", "title": "fixed error go_backward and return sequences."}
{"description": " what kind of change does this pr introduce? (bug fix, feature, docs update, ...) chore. this pr contains changes to the build already on master, and includes fixes and fixes to fixes directly instead of sequentially the commit message follows our guidelines:  tests for the changes have been added (for bug fixes / features) docs have been added / updated (for bug fixes / features) other information: ", "commit_messages": " chore(docs-app): load example files based on active deployment  chore(docs-app): only copy relevant assets  this keeps the size of the docs-app build down.  especially needed to keep the size of the generated build .zip  under 10mb, which is the limit for firebase / gcs https function transfers  chore(travis): skip build on deployment job when from pull request  chore(code.angularjs): enable directory listings  chore(code.angularjs): delete old zip files on snapshot ", "linked_issue_titles": "", "title": "update 1.6 with recent travis, fb, docs app changes"}
{"description": " changes to abi generation to auto populate abi from contract and clause files. please look at issue #2389 comments for more information. ", "commit_messages": " starting to add integration to abigen  added clauses generation in abi_generator  finished abi_generator  changed clause decl  removed whitespace changes ", "linked_issue_titles": "", "title": "ricardian misc pr for eos #2389"}
{"description": " this pulls in #3790, which provides retries in more of the posix emulation functions to be more resilient in the face of files locked by the aggressive locking semantics in win32, and #4073, which allows consumers to configure their own locking strategies so that consumers can \"get out of the way\" of their users a bit more instead of locking files unnecessarily. i refactored these a bit:  this now introduces a do_with_retries macro that will execute the given function up to 10 times, retrying if the error appears to be something like a locked file.  callers can provide a \"cleanup\" function - perhaps to set the file writable - that will be called between invocations of the main function.  this allowed us to clean up some patterns of try / set writable / try again. i introduced the git_retry constant here.  this is internal only and should never be returned to callers. these new retryable functions call the win32 functions directly instead of calling windows' posix emulation functions, which allows us to use the win32 error codes which are more fine-grained.  this allows us to retry only particular failures (ie, error_sharing_violation ) instead of a sharing violation and all the other failures that get mapped to a particular posix errno. this also allows us to bring in the configurable share mode for createfile, in #4073. once p_utimes called a retryable version of p_open, i noticed quickly that it was retrying all the time.  our odb freshening test was freshening an object in a repository that had been copied over from a test harness and - as a result - the objects were all writable.  thus p_utimes would succeed on windows.  but freshening a file that we wrote - and thus marked as read-only - would fail.  oops.  so i made p_utimes deal with read-only files by setting them writable temporarily to update the time. ", "commit_messages": " add retries to win32 p_unlink and p_open.  win32: map windows error codes to errno  introduce mapping from windows error codes to errno values.  this  allows us to replace our calls to the windows posix emulation functions  with calls to the win32 apis for more fine-grained control over the  emulation.  these mappings match the windows crt's mappings for its posix emulation  as they were described to me.  win32: introduce do_with_retries macro  provide a macro that will allow us to run a function with posix-like  return values multiple times in a retry loop, with an optional cleanup  function called between invocations.  win32: make p_rename use do_with_retries  win32: teach p_unlink about do_with_retries  win32: teach p_open about do_with_retries  win32: use createfile in p_open  win32: deduplicate code: use p_open in p_creat  allow to configure default file share mode for opening files  this can prevent file_shared_violations when used in tools such as tortoisegit tgitcache and file_share_delete, because files can be opened w/o being locked any more.  win32: do not inherit file descriptors  win32: make posix emulation retries configurable  posix emulation retries should be configurable so that tests can disable  them.  in particular, maniacally threading tests may end up trying to  open locked files and need retries, which will slow continuous  integration tests significantly.  win32: enable p_utimes for readonly files  instead of failing to set the timestamp of a read-only file (like any  object file), set it writable temporarily to update the timestamp. ", "linked_issue_titles": "", "title": "refactor some of the win32 posix emulation"}
{"description": " xref #24499 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry this is part of #24499, will be moving the pages in different prs, so it's easier to discuss. ", "commit_messages": " doc: moving user guide to its own directory to help navigation  fixing typo in toctree formatting  merging from master  fixing path to static files ", "linked_issue_titles": "", "title": "creating top-level user guide section, and moving pages inside"}
{"description": " backports #18923, #18956, #18971 once we do the split for pr jobs, this will be needed for pr jobs to continue running against v1.20.x ", "commit_messages": " split multilang jobs by language  job split followup: increase timeout for macos and windows c/c++ jobs  create build.cfg for split-up pr jobs  remove no-longer-used pr jobs ", "linked_issue_titles": "", "title": "backport kokoro job split to v1.20.x"}
{"description": " as code.google.com is apparently closing (eventually). gcfg does not yet have a new home, so that godep still exists. ", "commit_messages": " move from code.google.com to google.golang.org for google-api-go-client  update mesos-go godep (to eliminate its use of code.google.com)  this helps us remove one more (dying) godep import.  switch from to code.google.com/p/go-uuid/uuid to github.com/pborman/uuid ", "linked_issue_titles": "", "title": "switch godeps away from code.google.com"}
{"description": " we have a number of tasks that either omit, or incorrectly apply gradle input/output annotations on task properties. in addition to some of these instances resulting in potentially incorrect incremental build behavior, this causes a bunch of noise whenever we build :buildsrc. this pr addresses these reported warnings. ", "commit_messages": " fix gradle task validation warnings for test clusters inputs  fix gradle task validation warnings ", "linked_issue_titles": "", "title": "eliminate gradle task input warnings"}
{"description": " ticks off three checkboxes in #8982. the main thing i'm concerned about is the struct returned by parse_temporal_zoned_date_time_string and how it interacts with to_temporal_zoned_date_time (e.g. moving into result and such) as it's currently untested as parse_iso_date_time is not currently implemented. ", "commit_messages": " libjs: implement totemporalzoneddatetime and the required aos  libjs: implement temporal.zoneddatetime.from  libjs: implement temporal.zoneddatetime.compare  libjs: implement temporal.zoneddatetime.prototype.equals ", "linked_issue_titles": "", "title": "implement totemporalzoneddatetime and three functions that use it"}
{"description": " the boost minimum version was bumped from 1.67 to 1.70 solely for rodeos. with rodeos now disabled we can set the minimum back to 1.67. this is somewhat useful for distros like debian 10 which still uses 1.67 out of the box. or, centos 7 & 8 which have 1.69 available via epel (our build scripts still build from scratch though). i completed a build and a ctest -le _tests ctest -l nonparallelizable_tests with 1.67 on this branch. okay okay, this doesn't technically build with 1.67 due to a defect in 1.67 where spsc_queue is missing an include file. however, just about any packager picked up that patch, including debian 10. debian 10:  arch:  homebrew:  as such, i've elected not to introduce a fix for this bug strictly in 1.67 in eosio code since the only likely user (debian 10) already has the fix integrated. needs eosio/fc#175 select one ", "commit_messages": " sync fc to get make_strand() replacement  set minimum boost version back to 1.67 ", "linked_issue_titles": "", "title": "restore boost 1.67 as the minimum boost version required"}
{"description": " this is a part of nnie plugin for ncnn. npn will a wip. ", "commit_messages": " rename ncnn snapshot png file  add nnie imagewatch plugin and working snapshot  add nnie support to readme.md  fix image path ", "linked_issue_titles": "", "title": "add nnie imagewatch plugin natvis"}
{"description": " only prepend the language code if it's not there already - otherwise calling package with for instance name=\"nl_core_my_pipeline\" would result in an \"nl_nl_core_my_pipeline\" package. nitpicking: add empty newline at the end of the python files that are written. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " add empty lines at the end of python files  only prepend the lang code if it's not there already ", "linked_issue_titles": "", "title": "optionally append lang for packaged model name"}
{"description": " description: this pr implement alexa smart home api native into home-assistant for our cloud support. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " init commit for alexa component  more struct component  add mapping for device/component to alexa action  finish discovery  first version with support on/off/percent  fix spell  first init tests  fix tests & lint  add tests & fix bugs  optimaze tests  more tests  finish tests ", "linked_issue_titles": "", "title": "alexa smart home native support"}
{"description": " #10861 , #10724 , and #11142 . explanation: tbdgen now includes all the exported symbols encountered while building the standard library and test suite. scope: future users of tbd files, as there's no functionality change outside of it. radar: rdar://problem/32252869 and its subtasks. risk: low: the only changes outside of tbdgen are tightening the linkage of some symbols, which people shouldn't be relying on. testing: ci and local testing with tbd validation turned on by default (which this pr doesn't include, as that could break user's build). ", "commit_messages": " [tbdgen] static variables in the main file have accessors.  it is only top-level globals in the main file that do not have  accessors, something like class foo { static var x = 0 } has them no  matter where it is.  fixes rdar://problem/32391290 .  [test] stop a test dumping multiple klocs of sil/ir when it fails.  [tbdgen] include all transparent symbols.  this is a vast overestimate, but is better than missing some.  rdar://problem/32254773 ", "linked_issue_titles": "", "title": "tbd including all files from a full build."}
{"description": " added persistent metadata to the agent so that on restart a full set of metadata is kept about the charts and dimensions stored in the dbengine. implemented collector metadata logging added persistent guids for charts and dimensions added metadata log replay and automatic compaction added detection of charts with no active collector (archived) added new endpoint to report archived charts via /api/v1/archivedcharts added support for collector metadata update component name database ", "commit_messages": " add metadata log files (#9078)  * metadata log initial commit  * add metadata log file write support  * add proof of concept plugins d entrypoints for populating the metadata log files.  global guid lookup (#9092)  implement functions to support a global guid map  generate global random guids (#9120)  generate guids for charts and dimensions for the metadata log and maintain in the global lookup table  initial version of metadata log parsing and replay. (#9195)  * initial version of metadata log parsing and replay.  metadata log compaction (#9252)  * implement metadata log compaction.  * implement metadata log compaction failure recovery logic.  * fix very old bug causing crashes during host shutdown with dbengine memory mode  add support for collectors updating their metadata (#9192)  implemented collector metadata update ", "linked_issue_titles": "", "title": "add support for persistent metadata"}
{"description": " @mjbvz this pr replaces pr #22918 to address issue #2187. i noticed that @tyriar had essentially created a \"simple find widget\" to use in the terminal which was much simpler to reuse than trying to refactor the full \"find widget\". i refactored that out into a reusable widget (simplefindwidget) and updated the terminal to use it (terminalfindwidget). i then created a webviewfindwidget to be used by the webview to interact with the native webview find api. to respect the layering contract, i had to make the existing webvieweditor into an abstract class and extend it in the correct layer so it could have access to the webview. htmlpreviewpart and releasenoteseditor now extend from that new webvieweditor implementation and therefore both have access to the new find widget. extensioneditor also now leverages the simple find widget to enable searching through readmes and release notes within the extension editor view. finally, i improved the styling of the simple find widget by adding \"overflow: hidden\" to the containers that use it so that it can properly be animated in. caveat: i don't know what htmleditorzone is so i didn't test that. here are gifs of it in action: this is the find working in a markdown preview: this is the find working in release notes this is the find working the same as before in the terminal, but now with animation: this is the find working in the webview sections of the extensioneditor ", "commit_messages": " refactored terminalfindwidget into a simplefindwidget and used that to provide find for webviews  refactored webvieweditor into an abstract base and a concrete class to respect 'part' separation  cleaned up css and images that i forgot to delete  reset i18n.js file ", "linked_issue_titles": "", "title": "find in webview based views (html preview, release notes, extension editor)"}
{"description": " for gatsby admin, the design calls for us to render a description for each plugin/theme in the ui. this adds a gatsbyplugin.description field, which returns the \"description\" field from the plugin's package.json (using the package.json resource read function!). while i was at it, i also cleaned up the code a bit: instead of manually resolving the node_modules locations of packages, i tried to use require.resolve to fix the tests within the monorepo (they weren't finding the themes in the node_modules, as they aren't there, so no shadowed/able files were returned!). however, require.resolve also doesn't work as it resolves from the __dirname, which is not what we want (particularly in our monorepo). thankfully, the resolve-cwd module by sindre does the exact some thing require.resolve does but from the current working directory instead! instead of duplicating the \"read plugin\"-logic in the \"all plugins\" and the \"single plugin\" function (which already lead to mismatches where shadowable/ed files weren't defined when fetching a single plugin), i now use the common read function in the all method. more consistent results and no duplicate code, yay! ", "commit_messages": " add description to npm package resource  use require.resolve instead of manually joining node_modules path  use resolve-pkg to safely resolve packages just like require() would do instead of manually joining paths with node_modules  add gatsbyplugin.description to provider ", "linked_issue_titles": "", "title": "add description to gatsby plugin resource"}
{"description": " currently, commandpalette creates and maintains the switchtotab commands used for the ats. when command goes into the terminalsettingsmodel, the palette won't be able to access command's implementation type, making it difficult for commandpalette to tell command to listen to tab for changes. this pr changes the relationship up so tab now manages its switchtotab command, and commandpalette just plops the command from tab into its list. ", "commit_messages": " added command object to tab  working state  more comments ", "linked_issue_titles": "", "title": "give tab ownership of its switchtotab command"}
{"description": " this allows stuff like: int mycompare(int i, int j) { j - i } ... list.sort(this::mycompare) it is like a manual transmission lambda. the main idea here is allowing pointers to functions in our own class (whether user explicitly wrote them or we wrote them on their behalf). so a few cleanups were needed: allow creating functionref to these (lots of refactoring here) allow dynamic code (def) to access these. we need a runtime whitelist, and we'd like to keep all methods private, avoid reflection/security issues/etc. we add a whitelist to the class itself, a pointer to each function like this: private static final methodhandle handle$mycompare$2; these are initialized in <clinit> with ldc (they are simply constants). we can lookup from this by name and arity exactly, and we have what we need. 3. general cleanup of functions in our asm code (thanks @uschindler). ", "commit_messages": " merge master  remove unnecessary semicolon and return  write refs for functions  make this static final  unfuck the methodwriter nesting. all methodwriters should only live separately from each other, no nesting  def case working  fix too long line  more cleanup  test interface default methods  remove some hardcoded strings, fix exception handling (remove rethrow), add some utility methods around the \"handle$\" fields  add comments  need not be public, should not be public ", "linked_issue_titles": "", "title": "method references to user functions"}
{"description": " fix the remaining /status subresources that return 405 on get and patch which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): ref #63619 release note: apiservices/status and certificatesigningrequests/status now support get and patch ", "commit_messages": " add get patch support for two /status:  apiservices/status under apiregistration.k8s.io  certificatesigningrequests/status under certificates.k8s.io  generated ", "linked_issue_titles": "", "title": "apiservices/status and certificatesigningrequests/status support get+update+patch"}
{"description": " since esp32 stage has no core_version.h file we have to disable the include. this is done with setting esp32_stage=true in platformio changed esp32 stage to latest commit f7fb00632e0.... the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.4.5 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " no core_version.h in esp32 stage  build flag for esp32 stage ", "linked_issue_titles": "", "title": "make esp32 stage compile possible"}
{"description": " recent upgrade of rnw to mux2.6 caused a second shift in button styling. a couple of small tweaks were needed here to match the styling of the xaml button. added border color and width to button. removed workaround in place for winui2.5 buttonbackgroundpointerover brush. added button title color change with change in states. backport #8148 to 0.65. microsoft reviewers: open in codeflow ", "commit_messages": " backport winui2.6 button changes  change files  revert comment formatting changes ", "linked_issue_titles": "", "title": "adjust button styling following upgrade to winui2.6"}
{"description": " alternative to #3897 ", "commit_messages": " remove threadsafestate  remove threadsafestate completely  clippy  remove loading workers table  reset ci  remove some mutexes from state  remove more mutexes from state  remove mutex from resource table  wrap state in rc and refcell ", "linked_issue_titles": "", "title": "use refcell for mutable state"}
{"description": " this pr extracts some changes from #23308. the following changes are being made: add classes prop to the sliderunstyled updated buildapi to reflect the definition in the classes for the css section in the api page adds helper tests for the unstyled package removed unnecessary component valuelabelstyled and moved the styles to the valuelabelstyled \"slot\" component. renamed valuelabelunstyled to slidervaluelabelunstyled and reverted back some changes from the original implementation ", "commit_messages": " extracted changes  fix ", "linked_issue_titles": "", "title": "general cleanup and add classes prop for unstyled"}
{"description": " the kernel does the equivalent of the following check before proceeding: if (address + 0x8000000000 < 0x7fffe00000) { return err_invalid_memory_state; } which is essentially what our iskernelvirtualaddress() function does. so we should also be checking for this. the kernel also checks if the given input addresses are 4-byte aligned after the above check, however our mutex::tryacquire() and mutex::release() functions already handle this, so we don't need to add code for this case. ", "commit_messages": " kernel/svc: handle error cases for svcarbitratelock() and svcarbitrateunlock()  the kernel does the equivalent of the following check before proceeding:  if (address + 0x8000000000 < 0x7fffe00000) {  return err_invalid_memory_state;  }  which is essentially what our iskernelvirtualaddress() function does. so  we should also be checking for this.  the kernel also checks if the given input addresses are 4-byte aligned,  however our mutex::tryacquire() and mutex::release() functions already  handle this, so we don't need to add code for this case.  kernel/mutex: replace resultcode construction for invalid addresses with the named variant  we already have a resultcode constant for the case of an invalid  address, so we can just use it instead of re-rolling that resultcode  type. ", "linked_issue_titles": "", "title": "handle invalid address cases within svcarbitratelock() and svcarbitrateunlock()"}
{"description": " currently, asynccheckpointrunnable throws an exception if subtaskcheckpointcoordinatorimpl is closed. however, it should also check its own status as it might be a normal case. the change is covered by existing end-to-end tests which are currently failing. unit testing would involve concurrency which i think would be overkill for essentially a logging problem. dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? no ", "commit_messages": " [hotfix] refactor subtaskcheckpointcoordinatorimpl.registerasynccheckpointrunnable  [flink-19012][task] check state of asynccheckpointrunnable before throwing an exception  currently, subtaskcheckpointcoordinatorimpl closes all runnables on close.  it doesn't stop the actual threads, however. when closed runnable starts,  it sees its parent is closed and throws an exception.  this causes end-to-end tests failures.  this change adds a check of runnable state. ", "linked_issue_titles": "", "title": "check asynccheckpointrunnable status before throwing an exception"}
{"description": " added a new define in user config to set the vloume on a secific value 0..30(max). -- very little speakers in a housing (e.g. sonoff sc) can explode by full volume. -- happens to me now two times with white smoke. added version information to the driver file to have some hints what's done. changed two commands -- mp3play 001 to mp3track 001 -- mp3stop is now a real stop and not the pause command as in the original version added some new commands -- mp3play, a real play command. starts at 001.mp3 file on the selected device -- mp3eq, an eq(0/1/2/3/4/5), 0:normal, 1:pop, 2:rock, 3:jazz, 4:classic, 5:bass -- mp3device, specify playback device, usb=1, sd-card=2, default = 2 also after reset or power down/up all is tested parallel (8 h) and works on a sonoff-sv and a wemos d1 (not the mini) as generic device ", "commit_messages": " update from original  added mp3_volume to init the mp3 player  added version info and new mp3 player commands  - added the version information to have some little hints what is done.  - added new commands and changed two commands from the first version.  -- intention was to get as less of commands as needed.  -- there will be possible a version with much more function and serial->read.  command list:  - mp3track  -- specify playback of a track, e.g. mp3track 003.  - mp3play  -- play, works as a normal play on a real mp3 player, starts at 001.mp3 file on the selected device.  - mp3pause  -- pause, was original designed as stop, see data sheet.  - mp3stop  -- stop, it's a real stop now, in the original version it was a pause command.  - mp3volume  -- specifies the volume and means a console input as 0..100.  - mp3eq  -- specify the eq(0/1/2/3/4/5), 0:normal, 1:pop, 2:rock, 3:jazz, 4:classic, 5:bass.  - mp3device  -- specify playback device, usb=1, sd-card=2, default is 2 also after reset or power down/up. ", "linked_issue_titles": "", "title": "changed/added mp3 player commands and version information"}
{"description": " summary created additional documentation for the \"switching from one backend to another\" section of the documentation, including an example of an edited keras.json configuration file. related issues solves issue #11384 pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) ", "commit_messages": " update backend.md  added documentation for loading an external backend  added documentation for using an external backend  added documentation for loading external backends ", "linked_issue_titles": "", "title": "fix issue #11384 - explaining how to load external backends in the documentation"}
{"description": " fixes #17324. @sandy081, you've worked in this area, let me know if this is the right approach. ", "commit_messages": " microsoft/vscode#17324 - implement f4 to navigate results  move id/label  expose navigator methods so i can avoid calling selectnext multiple times per action- it has side effects ", "linked_issue_titles": " suboptimal hotkey workflow for \"find in files\" ", "title": "add f4 shortcut for navigating search results"}
{"description": " this makes sure we have a valid view staying in the window, so opening devtools won't trigger crashes, and the keyboard events can correctly pass in the window. refs #6704. ", "commit_messages": " pass onpaint callback in constructor  this can catch the paint events happened before onload event.  pass skbitmap directly  show dummy view under offscreen mode  also show the text on windows and linux  fix building on linux ", "linked_issue_titles": "", "title": "show a dummy view in the offscreen window"}
{"description": " kip-680: topologytestdriver should not require a properties argument.  jira for the kip: ", "commit_messages": " added default constructor without properties in topologytestdriver  using constructor of topologytestdriver without properties parameter  using constructor of topologytestdriver without properties parameter  changed constructor reference to the one without properties  keeping default test props final  fixed merge conflicts  made changes as per style guilde  no need of static default properties  provide randomized dummy app-id if it's not provided  added another constructor with initial clock time parameter  fixed merge conflicts ", "linked_issue_titles": "", "title": "kafka 10629 - topologytestdriver should not require a properties argument"}
{"description": " what do these changes do? update arrow to apache/arrow#2522 which has glog in plasma. according to arrow's recent change,  n/a ", "commit_messages": " update arrow to plasma with glog and update the building process  remove parquetexternalproject.cmake ", "linked_issue_titles": "", "title": "update arrow using plasma with glog"}
{"description": " hold space to mirror handedness of the ergodox.  tap to space.   same works for enter key on right hand. i also moved the modifier keys from default to a layout that is closer to a 108-key board. i use one of that shape at work and want the switch to be as painless as possible. tested this layout and the layer shifting works correctly. no need to spend $600 to get one from matias. ", "commit_messages": " started work on halfkeyboard  update to keymap  halfkey layouts complete for dvorak and qwerty ", "linked_issue_titles": "", "title": "halfkeyboard functionality for dvorak and qwerty"}
{"description": " closes #19643 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " fix cdivision error, migrate period_asfreq tests  docstrings, parametrize test  fixup typo ", "linked_issue_titles": " period.asfreq issue caused(?) by c division rules ", "title": "fix period.asfreq conversion near datetime(1, 1, 1)"}
{"description": " this pr also adds parallel to elasticnetcv ", "commit_messages": " enh: add the ability to set rho by cross-val  enh: store the path for rho in enet  bug: fix tests and reorganize code  enh: draft of parallel cv in elastic net  test: setting rho with elasticnetcv  doc: document elasticnetcv ", "linked_issue_titles": "", "title": "add the option to set rho by cv in elasticnetcv"}
{"description": " this change cuts over from translog to lucene changes history in ccr component. the autogeneratedidtimestamp will be handled in a follow-up. ", "commit_messages": " [ccr] use indexsearcher to read operations from lucene index instead  of using the translog  moved ccrindexreader to lucene.java and added a simple test ", "linked_issue_titles": "", "title": "read changes from lucene instead of translog"}
{"description": "", "commit_messages": " opencl: fix wrong implementation of function getnumdevicewithemptyscore  gcc report:  opencl_device_selection.h: in function 'ds_status getnumdevicewithemptyscore(ds_profile*, unsigned int*)':  opencl_device_selection.h:589:13: warning: value computed is not used [-wunused-value]  *num++;  ^  this is caused by a buggy implementation which increases the value of num  instead of *num.  opencl: add missing argument for l_warning  gcc report:  in file included from /usr/include/leptonica/alltypes.h:36:0,  from /usr/include/leptonica/allheaders.h:34,  from openclwrapper.h:2,  from openclwrapper.cpp:11:  openclwrapper.cpp: in static member function 'static pix* opencldevice::pixreadmemtiffcl(const l_uint8*, size_t, l_int32)':  /usr/include/leptonica/environ.h:442:68: warning: format '%d' expects a matching 'int' argument [-wformat=]  (void)fprintf(stderr, \"warning in %s: \" a, __va_args__), \\  ^  /usr/include/leptonica/environ.h:427:61: note: in definition of macro 'if_sev'  ((l) >= minimum_severity && (l) >= leptmsgseverity ? (t) : (f))  ^  opencl/openclwrapper.cpp:1162:3: note: in expansion of macro 'l_warning'  l_warning(\"tiff page %d not found\", procname);  ^ ", "linked_issue_titles": "", "title": "fix two small bugs (both found by gcc)"}
{"description": " this does not do it in the spec like way for bytecode but i'm not sure how things like that are supposed to be done in bytecode. ", "commit_messages": " spreadsheet: fix that non first sheets could not access global functions  because we declare the functions in runtime.js we need the correct  global object to be setup otherwise they cannot be accessed when  switching to the sheetglobalobject.  libjs: fix that in bytecode mode functions where not created anymore  this is not a proper fix as we should follow the spec here but it gets  us back to a slightly more working state. ", "linked_issue_titles": "", "title": "fix some issues caused by the variable refactor"}
{"description": " the current codecov only reports the coverage of cpp code. to better integrate with codecov plugin, we should enable coverage report for java and python as well. ", "commit_messages": " add coverage report for java  add coverage report for python ", "linked_issue_titles": "", "title": "add coverage report for java and python"}
{"description": " migrated and fixed the smoke tests over to playwright and execute them on webkit/firefox/chromium as discussed with @rebornix adjusted the github actions, so they run also on a pull requests ", "commit_messages": " feat: migrate e2e tests to playwright  fix: os dependency  fix: race condition ", "linked_issue_titles": "", "title": "fix and migrate smoke tests to playwright"}
{"description": " this cleans up the behavior tests because they were hastily added for the v2 release. the tests themselves were revised for clarity. more work needs to be done documenting how to use and write them, but this is a start. example new test: test('builds in development', async () => { const { fulfilled } = await testsetup.scripts.start({ smoke: true }); expect(fulfilled).tobe(true); }); test('builds in production', async () => { const { fulfilled } = await testsetup.scripts.build(); expect(fulfilled).tobe(true); }); test('formats babel syntax error', async () => { fs.copysync( path.join(__dirname, 'src', 'appbabel.js'), path.join(testsetup.testdirectory, 'src', 'app.js') ); const { stdout, stderr } = await testsetup.scripts.build(); expect({ stdout, stderr }).tomatchsnapshot(); }); ", "commit_messages": " speed up installs with pnp  move to a better relative path test  continue work on new test organization  move mjs test to new enhanced tests  move over last legacy test  update behavior e2e script  add first iteration of instructions to test readme  add some more bad instructions  split test command into multiple lines ", "linked_issue_titles": "", "title": "clean up the behavior tests"}
{"description": " #2110 and #2116 ", "commit_messages": " english translation update.  some typos are fixed.  mysql.md is not translated yet  some more typos are fixed.  external editions are revised. english translation is actualised from 02.03.2018 version up to 26.03.2018. ", "linked_issue_titles": "", "title": "merged docs from #2110 and #2116"}
{"description": " part of #4401. complements #4431 for assignments instead of declarations. it's another example of a case where better error reporting in isimplicitlyconvertibleto might have been helpful (tracked in #4128). ", "commit_messages": " check for matching number of components in tupletype::isimplicitlyconvertibleto instead of the typechecker.  add changelog entry.  update tests. ", "linked_issue_titles": "", "title": "disallow tuple assignment with mismatching number of components."}
{"description": " closes #34656 closes #34271 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry behavioural changes .apply() calls  to self._set_group_selection have been replaced with with _group_selection_context(self): for _agg_general, _make_wrapper, and nth. previously these calls to self._set_group_selection created a bug in groupby.apply where calling another method before .apply would change the output of .apply. this bug is now fixed. one new test is added to check that the output of .apply is constant whether another method is called on the same grouper first. two existing tests were actually dependent on the old buggy-behaviour (i.e. they called groupby.sum first and then expected that groupby.apply(sum) would exclude the index columns from the results). all of these tests have been amended in a manner that enforces the new consistent output format while preserving the existing test. both of the copy-pastable examples in the linked bug-reports are fixed. ", "commit_messages": " groupby.apply() calls self._reset_group_selection at the start. errant tests updated  gb.apply() now resets group selection so it always returns grouping columns as columns. updated tests that relied on previous behaviour  test uses .drop() instead of selection  wrote new tests  rewrote test  whatsnew  restore if-stat in test_transform  amended test  restored test  restored test  amended test  cleanup ", "linked_issue_titles": " bug: same function calls on the same dataframegroupby object give different results  bug: groupby.min has a side effect on groupby.apply ", "title": "groupby.apply() returns different results if a different groupby method is called first"}
{"description": " i fixed several errors in the manual: bd67bb8 the output of unique_by(length) example was not sorted by length. fix typo: trailing ']'. the output of recurse example were missing . object itself. fdbc91e programs, inputs and outputs were not html-escaped, causing named-capture in regexes to disappear in html. (this also fixes #589) b4a9ea5 fix yaml indentation around the regex section because the generated html were corrupted. a6656ed fix markup, unmatched backquotes. jq output not being represented as a list in yaml were causing \"none\"s in generated html. they were commited separately because the indentation fix would have obscured other changes. please squash them if it is more convenient to merge. ", "commit_messages": " fix examples in manual  html-escape jq programs in manual  fix indents in manual.yml  fix examples in manual ", "linked_issue_titles": " documentation inaccuracy for format strings ", "title": "fix several errors in the manual"}
{"description": " updated definition-tester default to tsc v1.1.0-1 some fixes (also by @vvakame) added a version check to runner.js very simple local definition-tester semver check/prompt catches outdated dependency (using npm test or npm run <...>) for #2932 ", "commit_messages": " enabled tsc 1.1.0-1  updated definition-tester to 0.1.x  updated npm run scripts  added basic definition-tester semver check to runner.js  hardened runner.js  first check if definition tester module exists at all ", "linked_issue_titles": "", "title": "switched tester to tsc 1.1.0-1"}
{"description": " the assertitem failure message pattern in testsubscriber does not match any of the regex patterns defined by intellij to show <click to see difference> link. by changing the \"expected to be\" to \"expected:\", the pattern is recognised by intellij and the helpful link is presented. the original idea from #5249 was to use the \"expected:<> but was:<>\" pattern used in junit, but it is not picked up on its own by intellij. the assertionerror must extend from junit's comparisonfailure, to get it recognised. this however requires dependency on junit. so in the end, the fix is just a very simple change in the message. ", "commit_messages": " test intellij formatting fix  fix test subscriber test case ", "linked_issue_titles": "", "title": "1.x use intellij ide friendly assertion failure message"}
{"description": " a quick solution for allowing those using the master branch to use iob or iob2 formats, and to accept whitespace delimitation on a line other than a pipe. fixes the master branch for #2504 and #2970. fixes for the develop branch are not yet done. i have submitted the spacy contributor agreement. ", "commit_messages": " accept non-pipe whitespace as delimiter; allow iob2 filename  added small documentation note for iob2 allowance ", "linked_issue_titles": "", "title": "accept iob2 and allow generic whitespace"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " remove cast as typing stub should now work  fix typing of datejs ", "linked_issue_titles": "", "title": "fix typing for set() and add()"}
{"description": " my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add via support for bt66tech60  delete bt66tech60  add via support bt66tech60 ", "linked_issue_titles": "", "title": "add via keymap support for bt66tech/bt66tech60"}
{"description": " the following functions/criterions now support double backwards: rrelu, hardshrink, softplus, softshrink, logsigmoid, softmin, glu, mseloss, smoothl1loss, kldivloss, hingeembeddingloss. the following functions are now new-style (once-differentiable): marginrankingloss, cosineembeddingloss also updated the softmin documentation to list the simple formula rather than the stable formula; we did the same for softmax. ", "commit_messages": " implement rrelu double backwards.  implement hardshrink double backwards.  implement softplus double backwards.  implement softshrink double backwards.  implement logsigmoid double backwards.  implement softmin double backwards.  implement glu double backwards.  implement mseloss double backward.  implment smoothl1loss double backwards.  implement kldivloss double backwards.  implement hingeembeddingloss double backwards.  marginrankingloss as new style function.  cosineembeddingloss as a new style function. ", "linked_issue_titles": "", "title": "more nn double backwards support"}
{"description": " description: forks more of the implementations between counters and gauges. counters remain effectively as they were. for gauges, we get to drop the pending_increment_ field which was not used, but to resolve this bug we need to add a mutex, so this saves a little memory. the need for this is mentioned in #7109 but this does not fully resolve that bug. this is wip because i need to verify that it passes 'release' test now, having tweaked the expected memory value, but no way to check it on my system. risk level: medium testing: //test/common/stats/... docs changes: n/a release notes: n/a ", "commit_messages": " add a mutex to gauges to avoid an import-mode race.  use absl::mutex directly as it saves 8 bytes per stat relative to thread::mutexbasiclockable and its vptr. ", "linked_issue_titles": "", "title": "remove field from gaugeimpl that was not used, by moving it to the counter-specific section."}
{"description": " this removes a dependency on dashboard bootstrap data from the e2e test suite, so that we can change the implementation without breaking tests. this is blocking #13306. decided to open up a separate pr instead of addressing the issue there, for easier review. test plan requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " chore(cypress): make the load dashboard test behavior driven  remove bootstrap usage from controls test, + new utils  fix save test to not use bootstrap dat  remove bootstrap usage from the filter test  fix race condition  remove bootstrap from url params test  fix lint ", "linked_issue_titles": "", "title": "make the e2e tests more behavior-driven"}
{"description": " fixes #9078 currently fixed for archs : x86 arm 64/32 mips gb (it was already fully implemented) todo add support for more archs include this for more op type if needed add test for different arch currently the r_anal_op_mask_all used in many place , have to clean that and change to appropriate mask $ git grep \"r_anal_op_mask_all\" | wc -l 88 ", "commit_messages": " intial work on supporting ranalop.dst/src in all archs  fix struct offset for dst operand in ta command ", "linked_issue_titles": " struct offset for dst operand ", "title": "support ranalop.dst/src in all archs"}
{"description": " i have followed (at least) the pr section of the contributing guide. fixed spelling mistake in the footer of premium themes examples' footer ", "commit_messages": " override step props over internal state of stepper  add a unit test  merge upstream with 'master'  fix spelling in premium themes footer  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "fix spelling mistake in premium themes footer"}
{"description": " fix issues with gif frame disposal modes (fixes file download animation reported in #3291). add support for interlaced gifs (fixes google doodle in #3291). gifloader now uses a single frame buffer to cache the last decoded frame. this drastically reduces memory usage at the small expense of re-decoding frames on each loop. ", "commit_messages": " libgfx: correctly handle gif frame disposal modes  restorebackground disposal mode is now a transparent fill to allow  background to show through.  restoreprevious disposal mode now restores the previous frame.  libgfx: add support for interlaced gifs  libgfx: only cache last decoded gif frame  gifloader now uses a single frame buffer to cache the last decoded  frame. this drastically reduces memory usage at the small expense of  re-decoding frames on each loop. ", "linked_issue_titles": "", "title": "gif decoding fixes and improvements"}
{"description": " this is a major refactoring that moves the type checking code out of the ast classes into its own module (typechecker). furthermore, data added to the ast after the parsing stage (where the ast nodes are actually created) is not added to the ast nodes themselves, but to a class in the \"annotation hierarchy\". this fact will ease the later introduction of templates. to be merged together with ethereum/alethzero#70 and ethereum/mix#82 ", "commit_messages": " refactoring: check types outside of ast and recover from some errors.  refactored annotations.  error formatting. ", "linked_issue_titles": "", "title": "support mulitple errors and warnings."}
{"description": " add api get method to list the available es versions to be installed. $ awslocal es list-elasticsearch-versions { \"elasticsearchversions\": [ \"7.7.0\", \"7.4.0\", \"7.1.0\", \"6.7.0\" ] } fixes #3439 ", "commit_messages": " rebase from master (#1)  rebase 2 (#2)  rebase correctly  fix: list elasticsearch versions ", "linked_issue_titles": " how to read data written in elastic search cluster ? ", "title": "add list elasticsearch versions api method"}
{"description": " this patch exposes some of the constants used by probe temperature calibration to the user and solves bugs described in #18227 . in the following code a bug was fixed where 2d point addition was performed to calculate probe_pos_xyz by casting measure_point to an xyz value first. the 0.5f constant is exposed to the user. in addition probe.offset_xy is projected to 2d so that ptc_probe_heating_offset is in reference to the z coordinate frame, not the probe trigger point. probe_pos_xyz = xyz_pos_t(temp_comp.measure_point) + xyz_pos_t({ 0.0f, 0.0f, ptc_probe_heating_offset }), noz_pos_xyz = probe_pos_xyz - xy_pos_t(probe.offset_xy); // nozzle position based on probe position the following fixes a bug where the probe wasn't stowed after each probe, stopping the printer from heating below the trigger point. const float measured_z = probe.probe_at_point(nozpos, probe_pt_stow, 0, false);  // verbose=0, probe_relative=false allows probing on non-genuine pinda v2 probes. #18227 ", "commit_messages": " add changes to probe temperature calibration  add values and comments to configuration file ", "linked_issue_titles": "", "title": "extend ptc options and fix probing bugs"}
{"description": " adds e2e tests for various charsets with and without gzip iso-8859 (latin1) fixes #1543 euc-kr (korean) fixes #3479 shift-jis (japanese) gb2312 (chinese) also adds support for windows-1252 and all other charsets supported by iconv-lite:  auto-detects charset from headers or meta tags ensures that content is injected and sent using the detected content type prevents express from always sending content-type: text/html;charset=utf-8 fixes #3650  if you write a string, it will send it as utf-8 always, had to monkey-patch it out ", "commit_messages": " add e2e test that demonstrates encoding issue  fix all sorts of content-type wackiness, infer content-type from html ", "linked_issue_titles": " character problems with character encoding of iso-8859-1 sites  non english characters (korean) encoding is broken  chrome cypress browser adds \"charset=utf-8\" to the content-type in the response header ", "title": "fix a variety of character encoding issues"}
{"description": " per #2109 , it appears that we were a little deficient when checking out when core.autocrlf=input and the text=auto attribute is specified. this pr ensures that we handle core.autocrlf=input and text=auto when checking out.  this adds tests for the combinations of core.autocrlf of false, true and input along with the text=auto attribute being set and unset, both for writing to the working directory and into the repository. ", "commit_messages": " close files on file diff failure  not closing the files on a diff failure ensures that clar  cleanup will fail on win32 because we still have the file open.  tests for core.autocrlf and .gitattributes  tests for crlf filtering into the repository  core.autocrlf=input w/ text=auto attr to workdir ", "linked_issue_titles": "", "title": "handle core.autocrlf=input when checking out"}
{"description": " description: upgrades existing python-hpilo library to v4.3. existing version does not allow connections to ilo v3 due outdated ssl, upgrade to v4.3 works. checklist: documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " update python-hpilo to 4.3  update of python-hpilo requirement to 4.3 to resolve outstanding ssl connections for older hp servers (ilo 3)  update requirements_all.txt  update hpilo to 4.3 ", "linked_issue_titles": "", "title": "upgrade hpilo requirement to v4.3"}
{"description": " this pull requests changes and adds javadoc in some http-related classes it also does some minor internal refactoring to httpcodecutil to make it easier to get the gist of when looking through some methods for the first time sorry about all of these pull requests - i would do more in this package, but i've got enough of a headache to stop for the night and just mindlessly watch tv :) ", "commit_messages": " made the documentation in httpmessage a bit easier to understand  make httprequest's documentation easier to read  make httpresponse's javadoc a bit easier to read  documentation and slight internal refactoring of httpcodecutil  documentation redone for cookie ", "linked_issue_titles": "", "title": "even more documentation changes (mainly) - http"}
{"description": " tuned_examples/regression_tests removed; all tests will be run for both frameworks (use_pytorch will be removed from the yamls and replaced by command line overrides in bazel py_test). also, the regression tests will be run as single, independent py_tests for each algo+env+framework to better be able to catch run errors (hard to track right now). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " conflicts:  rllib/build  rllib/evaluation/worker_set.py  rllib/examples/cartpole_lstm.py  rllib/examples/custom_eval.py  rllib/examples/env/correlated_actions_env.py  rllib/examples/env/env_with_subprocess.py  rllib/examples/env/random_env.py  rllib/examples/env/repeat_initial_obs_env.py  rllib/examples/env/windy_maze_env.py  rllib/examples/nested_action_spaces.py  rllib/examples/parametric_action_cartpole.py  rllib/examples/parametric_actions_cartpole.py  rllib/examples/tensorflow/parametric_actions.py  rllib/tests/test_env_with_subprocess.py  rllib/tests/test_supported_spaces.py  rllib/tuned_examples/cartpole/cartpole-a2c-microbatch.yaml  rllib/tuned_examples/cartpole/cartpole-a3c-tf.yaml  rllib/tuned_examples/cartpole/cartpole-a3c.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-tf.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-torch.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise.yaml  rllib/tuned_examples/cartpole/pendulum-ppo-tf.yaml  rllib/tuned_examples/cartpole/pendulum-ppo-torch.yaml  rllib/tuned_examples/pendulum/pendulum-ppo.yaml  rllib/tuned_examples/regression_tests/cartpole-a3c.yaml  rllib/tuned_examples/regression_tests/cartpole-dqn-tf-param-noise.yaml  rllib/tuned_examples/regression_tests/pendulum-ddpg-tf.yaml  rllib/tuned_examples/regression_tests/pendulum-ddpg-torch.yaml  rllib/tuned_examples/regression_tests/pendulum-ppo.yaml  rllib/tuned_examples/regression_tests/pendulum-td3.yaml  conflicts:  rllib/build  rllib/evaluation/worker_set.py  rllib/examples/cartpole_lstm.py  rllib/examples/custom_eval.py  rllib/examples/env/correlated_actions_env.py  rllib/examples/env/env_with_subprocess.py  rllib/examples/env/random_env.py  rllib/examples/env/repeat_initial_obs_env.py  rllib/examples/env/windy_maze_env.py  rllib/examples/nested_action_spaces.py  rllib/examples/parametric_action_cartpole.py  rllib/examples/parametric_actions_cartpole.py  rllib/examples/tensorflow/parametric_actions.py  rllib/tests/test_env_with_subprocess.py  rllib/tests/test_supported_spaces.py  rllib/tuned_examples/cartpole/cartpole-a2c-microbatch.yaml  rllib/tuned_examples/cartpole/cartpole-a3c-tf.yaml  rllib/tuned_examples/cartpole/cartpole-a3c.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-tf.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise-torch.yaml  rllib/tuned_examples/cartpole/cartpole-dqn-param-noise.yaml  rllib/tuned_examples/cartpole/pendulum-ppo-tf.yaml  rllib/tuned_examples/cartpole/pendulum-ppo-torch.yaml  rllib/tuned_examples/pendulum/pendulum-ppo.yaml  rllib/tuned_examples/regression_tests/cartpole-a3c.yaml  rllib/tuned_examples/regression_tests/cartpole-dqn-tf-param-noise.yaml  rllib/tuned_examples/regression_tests/pendulum-ddpg-tf.yaml  rllib/tuned_examples/regression_tests/pendulum-ddpg-torch.yaml  rllib/tuned_examples/regression_tests/pendulum-ppo.yaml  rllib/tuned_examples/regression_tests/pendulum-td3.yaml  ddpg stats fix.  \u0001 conflicts:  \u0001\t.travis.yml  \u0001\trllib/tuned_examples/regression_tests/pendulum-td3.yaml  wip. ", "linked_issue_titles": "", "title": "benchmark and regression test yaml cleanup and restructuring."}
{"description": " this is needed to get puyo puyo tetris and cave story booting further. also return the correct error code when opening files that don't exist. this supersedes #227 ", "commit_messages": " fs: make ensuresavedata create the savedata folder when called for the first time.  fs: stubbed createsavedata. it currently does nothing.  fs: use the correct error code when trying to open files that don't exist. ", "linked_issue_titles": "", "title": "make ensuresavedata create the save data if it doesn't already exist."}
{"description": " fixes #3729. i suggest this be reviewed commit by commit. ", "commit_messages": " use a more accurate test name.  verify builders.  refactor completion code for object literals/bindings and import clauses.  remove builder from import clauses.  added original test case. ", "linked_issue_titles": "", "title": "don't show builders in import clauses"}
{"description": " added obs_frontend_event_replay_buffer_saved to the frontend api emitted it from the replay buffer save handler in ui updated docs it extends plugin writing capabilities (no drawbacks). arch linux vm, local build, tested with a proof-of-concept plugin with event callback that listens for the event new feature (non-breaking change which adds functionality) documentation (a change to documentation pages) ", "commit_messages": " obs-frontend-api: add the event of saving replay buffer  add obs_frontend_event_replay_buffer_saved as given by rfc 33  ui: emit the replay buffer saved event to the api  send the obs_frontend_event_replay_buffer_saved to api (as in rfc33)  docs/sphinx: add replay buffer saved event  documentation provided for obs_frontend_event_replay_buffer_saved (rfc33) ", "linked_issue_titles": "", "title": "add the replay buffer saved event to the frontend api"}
{"description": " also added a test to app-document suite to make sure we don't regress on this ", "commit_messages": " add missing keys for array elements  add test for missing key prop in app-document ", "linked_issue_titles": "", "title": "add missing key prop for array elements in _document"}
{"description": " the branch in question was merged in #3472 . also updated the comment, which is no longer true. @qlzh727 - for context, these are the files @vishh was using to generate and register a docker image for this repo. ", "commit_messages": " remove cd and checkout  updating comment ", "linked_issue_titles": "", "title": "update dockerfile for gpu now that the branch has been merged"}
{"description": " warnings to encourage people to test reactos in vms until it becomes more stable. ", "commit_messages": " update readme.md  added \"alpha\" warnning to readme  this is so people know to test this in vms(p.s sorry for duplicatoion i am new to github(also exuse my spelling i have dislexia)) ", "linked_issue_titles": "", "title": "added a alpha note for new users to the readme"}
{"description": " this corrects a minor typo made in d2571e5 (#34917). the docs mentioned rescue_with, but the actual method name is rescue_from (with is one of its parameters), as seen in the examples just below these two sentences. i also noticed that we were linking to the rescue_from api docs in the second mention of rescue_from. i think it's conventional to link to an external reference the first time the subject is mentioned, so i moved this link accordingly. ", "commit_messages": " change rescue_with -> rescue_from in action cable overview guide  this was a minor typo made in d2571e560c62116f60429c933d0c41a0e249b58b.  the actual method name is rescue_from (with is one of its  parameters), as seen in the examples below these two sentences.  [ci skip]  move the rescue_from api docs link to the first mention of it  in the action cable overview guide  if we want to link to the rescue_from api docs, it makes more sense to  do it the first time we mention rescue_from rather than the second  time.  [ci skip] ", "linked_issue_titles": "", "title": "fix rescue_from documentation in action cable overview guide [ci skip]"}
{"description": " #1244 didn't supply a test case, so i wrote one for it as a way to get familiarized with the codebase / test system. ", "commit_messages": " fixed issue #1241: _scanstring not supporting upper case format specifiers a, e, f, g, x.  add test for capitalized sscanf format specifiers.  add jez ng to authors. ", "linked_issue_titles": "", "title": "add test for uppercase format specifiers in sscanf."}
{"description": " this change set updates the github.com/stretchr/testify dependency to stretchr/testify@7e4a149. closes mesosphere/kubernetes-mesos#333. ref: #9265 (comment) ", "commit_messages": " update github.com/stretchr/testify/... rev to 7ea4a14  kubelet: use assert.equalvalues instead of assert.equal  the last update to github.com/stretchr/testify makes assert.equal  consider the type of its arguments. this commit makes this test pass  again by only testing for value equality using assert.equalvalues. ", "linked_issue_titles": "", "title": "update github.com/stretchr/testify rev to 7e4a149"}
{"description": " removing trusted-by section from home page and moving it to a new page. this code has been tested on a test web-server. ", "commit_messages": " add custom jenkinsfile  move users from home page  test users page ", "linked_issue_titles": "", "title": "move trusted-by section from main page to a new page"}
{"description": " most network params in dask module is constructed manually based on ips and ports. we need to drop all aliases from params to not confuse lightgbm cpp code with multiple values for the same param. lightgbm/python-package/lightgbm/dask.py lines 125 to 135 in ac706e1 machine_list = ','.join([ '%s:%d' % (urlparse(worker_address).hostname, port) for worker_address, port in worker_address_to_port.items() ]) network_params = { 'machines': machine_list, 'local_listen_port': worker_address_to_port[local_worker_address], 'time_out': time_out, 'num_machines': len(worker_address_to_port) } ", "commit_messages": " update dask.py  update basic.py ", "linked_issue_titles": "", "title": "drop aliases of core network parameters"}
{"description": " towards slep009. fixing the __init__s in cross_decomposition. ping @jnothman @ogrisel ", "commit_messages": " api make __init__ params in covariance kw-only  api make __init__ params in covariance kw-only  checkout out from master  merge remote-tracking branch 'upstream/master'  api make __init__ params in cross_decomposition kwonly ", "linked_issue_titles": "", "title": "api make __init__ params in cross_decomposition kw-only"}
{"description": " unified canadian aboriginal syllabics 1400-1488  common indic number forms a830-a839  coverage: ", "commit_messages": " base: add common indic number forms to font katica regular 10  a830-a839  base: add unified canadian aboriginal syllabics to katica regular 10  1400-1488 ", "linked_issue_titles": "", "title": "add unified canadian aboriginal syllabics & common indic number forms to font katica regular 10"}
{"description": " contains some cleanup of the projectconfig endpoint and generation, along with a fast path for detecting disabled projects based on their visibility attribute. ideally, i would like to merge most of the endpoint's code with the one in the update_config_cache task, but that refactor makes more sense once we're restructuring rate limits. ", "commit_messages": " ref(relay): clean up project config generation and add fast-path  ref(relay): remove unused metrics in projectconfig endpoint ", "linked_issue_titles": "", "title": "clean up project config generation and add a fast path"}
{"description": " add new free course, and sub-categories added a amazing course of codeigniter, a framework php because frameworks promote code productivity it's just free it's a course not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " update free-courses-pt_br.md  update free-courses-pt_br.md  update free-courses-pt_br.md ", "linked_issue_titles": "", "title": "added free codeigniter course, and organizing list by sub-categories"}
{"description": " includes #2280, so that should be reviewed first. ", "commit_messages": " try harder to return deadline_exceeded when we should  do this by ensuring that the alarm callback has had a chance to run on a  call before returning status to the application.  if we do not do this:  - the server alarm could be scheduled and run  - it will write a rst_stream with a status that loses the deadline  exceededness (because that is unexpressable in http2 error codes)  - it will be received by the client and processed  - the client will return an internal error (the lossy re-encoding of the  server status), and then run its alarm handler to set the status to  something else  delay unregister of fd until freelisted  prevents a race whereby we start deleting the freelist before it's used  don't unregister resolver object until callback complete  prevents tsan races in iomgr shutdown code ", "linked_issue_titles": "", "title": "fix iomgr shutdown tsan races"}
{"description": " closes #5838 in particle#fire(), an error is thrown if the particle has no texture frame. this prevents an uncaught error later when the particle fails to render. in particleemittermanager#setemitterframes(), console warnings are printed if an invalid texture frame is given or if no texture frames were set. ", "commit_messages": " warn for missing texture frames  throw an error for missing particle texture frame ", "linked_issue_titles": " please add useful information when a particles emitter has an invalid/null frame ", "title": "warn, throw for particle texture frame mistakes"}
{"description": " format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " fix service metadata update failed problem.  random connect to server  add some metrics and log for service and client  add some metrics and log for naming task worker ", "linked_issue_titles": "", "title": "add some metrics and logs"}
{"description": " #11035 #10625 ", "commit_messages": " make declaration emit test name consistent  update baselines  add tests  update baselines from cherry-pick changes from master  serialize type alias when type alias symbol is not accessible  address pr ", "linked_issue_titles": "", "title": "serialize type alias when type-alias is not accessible and emit generic"}
{"description": " i updated the german translation to match the english original. as the translated version don't have a subfolder for \"additional material\" i incorporated the subsection into the document. ", "commit_messages": " updated the first part of the translation.  update readme.de.md  fixed small typops  translated and added the parts \"additional material\"  # conflicts:  #\ttranslations/readme.de.md  update readme.de.md  clarification  update readme.de.md  read the tutorial again and fixed typos ", "linked_issue_titles": "", "title": "update german translation addresses #96"}
{"description": " the new release of multi site configurator (msc) will be named multi site orchestrator (mso). since these modules have not been released, we do not offer any backward compatibility. msc ", "commit_messages": " msc_tenant: improve docs  rename msc modules to mso ", "linked_issue_titles": "", "title": "rename msc modules to mso nomenclature"}
{"description": " looks for any /packages/<package>/<path requests and maps those to package:<package>/<path> uris, which are then resolved using normal package uri resolution. related issues dart-lang/webdev#865 i added a unit test to the existing web dev server test. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide ", "commit_messages": " support mapping /packages/<package>/<path> requests to package:<package>/<path> uris in the web device file server  add test ", "linked_issue_titles": "", "title": "serve packages uris in flutter_tools dev web server"}
{"description": " since the days immemorial of the terminal, the termcontrol has auto-focused itself when it finalizes its layout. this has led to the problem that wt ; sp ; sp ; sp... ends up focusing one of these panes at random. this pr fixes this issue by getting rid of the auto-focusing. panes now manually get focused when created. we manually focus the active pane when a commandline is dispatched. since we're internally tracking \"active\" separate from \"focused\", this ends up working as you'd hope. closes #6586 i work here i also had to turn the cursor off by default. most termcontrols would never get the lostfocus event, so their cursors would get left on, and that's not right. i've run the following things a bunch of times to make sure they work: wtd sp ; sp ; sp wtd sp ; sp ; sp ; fp -t 0 newtab splitpane use the command palette to do the above as well where the result used to be random (cases 1 & 2), the result is exactly what you'd expect now. it doesn't work at all for wtd sp ; sp ; sp ; mf left presumably because we can't move-focus directionally during startup. however, that doesn't work today either, so it's not making it worse. just highlights that single scenario doesn't work right. ", "commit_messages": " this sorta works to solve #6586  this works well for    wtd sp ; sp ; sp    and for    wtd sp ; sp ; sp ; fp -t 0    but it doesn't work at all for    wtd sp ; sp ; sp ; mf left    presumably because we can't move-focus directionally during startup.  this fixes some fallout issues  primarily with splitting not on the commandline. also with using the cmdpal to execute commands  comments, i'm not a barbarian ", "linked_issue_titles": " wt split-pane (multiple copies) seems to have occasional focus issues ", "title": "only focus the active pane once initialization is complete"}
{"description": " what do these changes do? ray used to hang in the following scenario: node n1 forwards an actor creation task to node n2. n2 dies. n1 submits an actor task. the location is unknown, so the task gets queued. the actor creation task never gets scheduled, so the task remains queued forever. the job hangs because reconstruction is never triggered for the actor creation task. this pr fixes the issue by notifying the backend that tasks for actors whose locations are unknown depend on the actor creation task. this will trigger reconstruction if the actor creation task failed. this pr does not handle suppression for actor creation, which can happen if task lease or actor table notifications are delayed significantly. ", "commit_messages": " add regression test  request actor creation if no actor location found ", "linked_issue_titles": "", "title": "fault tolerance for actor creation"}
{"description": " fixes  #34500 there are two types of attributes. \"string\" and \"configuration attribute\". we need to get the real \"value\" based on the type. win_iis_website.ps1 ansible version ansible 2.4.2.0 ", "commit_messages": " remidate windows debugging  using $complex_args is not working (anymore?). we need to set $params directly.  fixing issue with win_iis_website parameter types  there are two types of attributes. \"string\" and \"configuration attribute\". we need to get the real \"value\" based on the type.  revert \"remidate windows debugging\"  this reverts commit df75d3bb0d152b10c24187ce4c643b4733bae336. ", "linked_issue_titles": " win_iis_website always changed with parameter logextfileflags ", "title": "fixing issue with win_iis_website parameter types. issue #34500"}
{"description": " see jenkins-36923 follow-up to #2474 @jenkinsci/code-reviewers @reviewbybees also matching pr to be made against bouncycastle-api plugin ", "commit_messages": " [fixed jenkins-36922] upgrade to instance-identity-module 2.0  - we migrate the bcpkix dependency from instance-identity to the war's web-inf/lib so that the net effect is zero and we are still not exposiing the bcpkix as a transitive dependency of jenkins-core  [jenkins-36923] give ownership of bcpkix dependency to bouncycastle-api plugin ", "linked_issue_titles": "", "title": "give ownership of bcpkix dependency to bouncycastle-apl plugin"}
{"description": " when receiving a header name that is an uncompressed literal, the qpack decoder was using the address of the literal, rather than the literal itself, as the header field name. this pr addresses the issue as well as adding a round-trip test that uses an uncompressed literal. ", "commit_messages": " add failing test  deference the buffer, not pointer to the buffer ", "linked_issue_titles": "", "title": "fix error in qpack header decoder"}
{"description": " result_type must be unsigned:  using a signed type causes an infinite loop working with ms visual studio 2017, targetting: v140, windowstargetplatformversion 10.0.15063.0, debug, x64 simply using uint32_t seems sufficient, since the value of max() is small enough. ", "commit_messages": " changes randomnumbergenerator::result_type to be unsigned  changes type of randomnumbergenerator::result_type to be compatible with older compilers as well. ", "linked_issue_titles": "", "title": "randomnumbergenerator::result_type should be unsigned"}
{"description": " currently, the same class fieldcapabilities is used both to represent the capabilities for one index, and also the merged capabilities across indices. to help clarify the logic, this pr proposes to create a separate class indexfieldcapabilities for the capabilities in one index. the refactor will also help when adding source_path information in #49264, since the merged source path field will have a different structure from the field for a single index. individual changes: add a new class indexfieldcapabilities. remove extra constructor from fieldcapabilities. combine the add and merge methods in fieldcapabilities.builder. ", "commit_messages": " add a new class indexfieldcapabilities.  remove extra constructor from fieldcapabilities.  combine the add and merge methods in fieldcapabilities.builder. ", "linked_issue_titles": "", "title": "create a class to hold field capabilities for one index."}
{"description": " my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add support for bm65rgb  move bm65rgb to /kprepublic ", "linked_issue_titles": "", "title": "add support for bm65rgb, a revival of #13361"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: correct import style shown here increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " merged definitions with my own. therefor added some types and made  changed the namespace back to a module.  fixxed lint errors  switched from namespace to module declaration and added type declarations for the string types. ", "linked_issue_titles": "", "title": "improved type definitions for recharts"}
{"description": " reverted recent change on adding --no-includes to darttest.sh and modified the source generator for dart  to exclude emitting those includes at all. they are not used in any of the tests. ran . src/clang-format-git.sh and fixed two other c++ issues that were recently introduced. tested: tests/darttest.sh with dart 2.8.1 ", "commit_messages": " fixed refractoring issue in reflection/generate_code.sh. also, mv deletes the original file, so i don't need to clean it up manually in that case.  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fixed dart tests by removing code-gen for included files. ", "linked_issue_titles": "", "title": "getting tests/darttest.sh to work on master."}
{"description": " this pr adds the same optimization we had in #2044 to messagepack. closes #2196 ", "commit_messages": " :bug: serialize 32-bit floating-point numbers as float 32 in messagepack (0xca) #2196  :white_check_mark: update test suite ", "linked_issue_titles": " msgpack serialisation : float is treated as 64bit float, not 32bit float. ", "title": "serialize floating-point numbers with 32 bit when possible (messagepack)"}
{"description": " fix the section headers in the ansible docs that do not follow the allowed section header notation. fixes #75685 docs/docsite/rst/dev_guide/style_guide ", "commit_messages": " docs: fix section header notation in style_guide/grammar  docs: fix section header notation in style_guide/spelling  docs: fix section header notation in style_guide/tm_resources  docs: fix section header notation in style_guide/voice  docs: fix section header notation in style_guide/why_use ", "linked_issue_titles": " docs: update section header notation in style guide ", "title": "fix section header notation in style guide"}
{"description": " cf issue #5181 (which discusses two bugs, so shouldn't be closed just yet) if a training text was empty, gold.ner was none, throwing an error when training the ner pipeline bug fix i have submitted the spacy contributor agreement. ", "commit_messages": " set gold fields to empty list instead of keeping them as none  add unit test ", "linked_issue_titles": "", "title": "prevent none in gold fields"}
{"description": " this is an enhancement or feature. this pr is about changing the heading tag of related posts section from h4 to h2 for seo enhancement. i have implemented the same on my website in pr and working demo with reference to your comment on my post at #3040 (reply in thread) since you have already provided the relevant font size, so any style change may not be required. minimal-mistakes/_sass/minimal-mistakes/_page.scss line 529 3c075fe .page__related-title { ", "commit_messages": " update heading tag from h4 to h2  update heading tag from h4 to h2 ", "linked_issue_titles": "", "title": "change heading tag of related posts section from h4 to h2 for seo enhancement"}
{"description": " updates the openssl static library to be linked into the react windows desktop dll. see introduced  changes: jurocha-ms/openssl@6539cd3...jurocha-ms:bd711e537cc6afab0c295ad81d9728ec7ee6c51d microsoft reviewers: open in codeflow ", "commit_messages": " upgrade openssl nuget to 1.1.1-d.3  change files ", "linked_issue_titles": "", "title": "upgrade openssl nuget to 1.1.1 d.3"}
{"description": " this is an alternative implementation to #13655. before this patch time travel feature depends on mocha's stub feature. since mocha is not a rails dependency we can't depend on this specific library. we choose to use our own implementation to avoid adding one more dependency to rails. this implementation is using an internal stub implementation instead of minitest to make possible to rspec users use this methods without any problem. fixes #13380. thank you @myronmarston for the help. ", "commit_messages": " implement a simple stub feature to use in the time travel helpers  alias the original method first to avoid warnings  use instance method instead of before hook  change the class and method visibility  store the singleton_class in a local variable  use each_value ", "linked_issue_titles": " [4.1.0.beta1] time travel helpers don't work \"out of the box\" ", "title": "alternative implementation to make time travel not dependent on mocha"}
{"description": " namely, add iris and userspace eeprom settings ", "commit_messages": " fix unicode sample  add irony mark  remove unpretty keymaps  add qmk dfu and conditional music mode  unicode fixes  unicode fixes  make layer indication more modular  finish removing faux click  cleanup of userspace and addition of 'update_tri_layer_state' function  add modifier status indicators to orthodox  remove tri layer function  minor tweaks  remove the orthodox's indicator's reliance on layer_state_set  add custom eeprom settings  make eeprom config more efficient  viterbi config  add iris keyboard layout and userspace cleanup  iris keyboard tweaks  use grave escape on iris ", "linked_issue_titles": "", "title": "update to drashna keymaps and userspace"}
{"description": " article will be ready in max 24 hours from now. ", "commit_messages": " expression-based access control  permitall, hasrole, hasanyrole etc.  i modified classes regards to security  added test cases for spring security expressions  handler interceptor - logging example  test for logger interceptor  removed conflicted part  conflicts:  spring-security-rest-full/src/main/java/org/baeldung/web/interceptor/loggerinterceptor.java  spring-security-rest-full/src/main/resources/websecurityconfig.xml  userinterceptor (adding user information to model)  conflicts:  spring-security-rest-full/src/main/java/org/baeldung/spring/webconfig.java ", "linked_issue_titles": "", "title": "changing spring mvc model parameters"}
{"description": " your checklist for this pull request i've read the guidelines for contributing to this repository i made sure to follow the project's coding style i've added tests that prove my fix is effective or that my feature works (if possible) i've updated the documentation and the radare2 book with the relevant information (if needed) detailed description this pr implements the following two functions. read the documentation below. /** * is_annotation_reference() - checks if the specified annotation is a reference. * @annotation: pointer to an annotation. * this function recognizes the type of the specified annotation and returns true if its * type is any of the following three: r_code_annotation_type_global_variable, * r_code_annotation_type_constant_variable, r_code_annotation_type_function_name * return: returns true if the specified annotation is a reference. */ r_api bool is_annotation_reference(rcodeannotation *annotation); /** * is_annotation_variable() - checks if the specified annotation is a function variable. * @annotation: pointer to an annotation. * this function recognizes the type of the specified annotation and returns true if its * type is any of the following two: r_code_annotation_type_local_variable, * r_code_annotation_type_function_parameter * return: returns true if the specified annotation is a function variable. */ r_api bool is_annotation_variable(rcodeannotation *annotation); ... test plan check code. fetch and compile cutter pr #2352 after compiling this pr. that pr uses this api. so you can check if it's working correctly or not. ... closing issues ... ", "commit_messages": " functions added  formatted  add documentation ", "linked_issue_titles": "", "title": "api for checking if an annotation is a reference or function variable."}
{"description": " displayed in internet explorer 11, text placeholder looks same as input text. please check my fiddle with internet explorer 11. (screen capture from my fiddle) this mistake is caused by typo in selecting pseudo class -ms-input-placeholder, so i fixed it. when fixing, i looked this msdn document. and i used !important in some error case because i had to get higher specificity than other style like below. .ui.form .field.error input[type='text'] ", "commit_messages": " fix placeholder typo in vendor prefix for ie  add !important to enable placeholder styling in ie ", "linked_issue_titles": "", "title": "fix typo in placeholder styling for the internet explorer"}
{"description": " i adjusted the oal tool to regenerate all indicators, also change the manual indicators and test mockers. in the parent class, i added the following methods public abstract indicator tohour(); public abstract indicator today(); public abstract indicator tomonth(); by using this, indicator can be transferred to another new indicator in hour/day/month dimensionalities. the high-level dimensionality timer can aggregate indicators in minutes, and save these. ", "commit_messages": " add transfer time bucket methods.  prepare to merge  merge commit '1936d38d163998762e66bbd3af8114a267bc1964' into timebucket  # conflicts:  #\toap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/generated/all/alldispatcher.java  #\toap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/generated/all/allheatmapindicator.java  support to hour, day, month dimensionalities  support time bucket transfer. ", "linked_issue_titles": "", "title": "support time bucket transfer for all indicators."}
{"description": " this pr cherry-picks the following prs to stable: #56467: bump stack size to 32mb #56486: propagate all closure requirements to the caller #56519: update edition guide the changes will be included in the final 1.31.0 binary (to avoid a point release). to deploy the build to dev-static the old manifest needs to be removed from the bucket after the pr is merged.  r? @alexcrichton ", "commit_messages": " bump stack size to 32mb  propagate all closure requirements to the caller  call methods on the right tcx  there are two tyctxts, one global, one local. methods must be called  on the right one, as they differ by invariant lifetimes. ", "linked_issue_titles": "", "title": "add a few critical fixes to the 1.31.0 release"}
{"description": " we will be user friendly close #837 ", "commit_messages": " cli: if user passed unknown option, show help and exit, close #837  cli: test unknown option output  linting ", "linked_issue_titles": " show cli help when user passed unknown option ", "title": "show help on unknown option 837"}
{"description": " when using kubectl describe <resource> <name> , the events returned for the resource do not use the eventseries.count and eventseries.lastobservedtime this pr adds the logic to compute the age of the event using these fields fixes kubernetes/kubectl#1095 changed kubectl describe to compute age of an event using the count and lastobservedtime fields available in the event series ", "commit_messages": " take into account new fields for event  add event with old event fields for test ", "linked_issue_titles": " \"kubectl describe <resource>\" doesn't take into account the new fields of core.v1/event ", "title": "use fields from event series when computing describe events for a object"}
{"description": " makes the controlled/uncontrolled + derived state pattern more obvious which results in one less create callback (wasteful popper re-creation) and flipplacement call. videos are taken with <popper flip /> and we're about to scroll to a position where the placement needs to be flipped. when this happens we used to get this weird create-update-create-update chain that is now replaced by a continuous update.  pr: and we even got less shipped code. hope that makes the implementation more reasonable. ", "commit_messages": " [popper] fix re-creation when placement flips  apply controlled/uncontrolled/derived state pattern ", "linked_issue_titles": "", "title": "refactor to more commonly known react patterns"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. fixes issue #17836 @scissorsneedfoodtoo , #19720 ", "commit_messages": " update adjust-the-background-color-property-of-text.english.md  update adjust-the-background-color-property-of-text.english.md  update adjust-the-background-color-property-of-text.english.md ", "linked_issue_titles": "", "title": "fixes issue with background-color and background being interpreted differently"}
{"description": " description: clarifies the drain time command line option is also used by drain listeners via lds. risk level: low testing: n/a docs changes: n/a release notes: n/a ", "commit_messages": " clarify draining option docs ", "linked_issue_titles": "", "title": "clarify drain time cli docs"}
{"description": " in cases where there are lots of tables and/or tables with long names, sql lab can become difficult to use. this adds a couple of affordances for that use case: adds tooltips to items in the table select menu, displaying the full table name widen the autocomplete window. unfortunately i couldn't find a way to make the width dynamic or add a tooltip. but it's now twice as wide as before which should be pretty accommodating. test plan requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " widen the autocomplete menu for table names  display the full table name in a tooltip ", "linked_issue_titles": "", "title": "handle long table names in sql lab"}
{"description": " adds an extra note as below to explain that a tuple pattern was probably intended. error[e0026]: variant x::y does not have a field named data --> src/main.rs:18:16 | 18 |         x::y { data } => println!(\"the data is {}\", data) |                ^^^^ variant x::y does not have field data error[e0027]: pattern does not mention field 0 --> src/main.rs:18:9 | 18 |         x::y { data } => println!(\"the data is {}\", data) |         ^^^^^^^^^^^^^ missing field 0 | = note: trying to match a tuple variant with a struct variant pattern fixes #41314. ", "commit_messages": " diagnostic note when matching tuple enum with struct pattern  ui unit test for note when matching tuple enum with struct pattern ", "linked_issue_titles": "", "title": "improve diagnostics when attempting to match tuple enum variant with struct pattern"}
{"description": " this is missing a test of the new cudnn support in convolution2d (here). maybe someone could add that, since i don't have it set up on my machine? ", "commit_messages": " add convolutional layer tests  add upsampling layer tests  add tests for border_mode == same ", "linked_issue_titles": "", "title": "add tests for convolutional layers"}
{"description": " description more updates of #20553 to make the car's indicators more in line with stock, especially on audi.  this also keeps visual indicators online regardless of op enablement state, as we already have the status led for this function. route: 07667b885add75fd|2021-04-13--13-53-11 ", "commit_messages": " improve vw hud with laneless and ldw  no longer depend on laneless param ", "linked_issue_titles": "", "title": "vw lane lines visual indicator changes"}
{"description": " i have added the following new language in the process for starting a new translation section. doc page :-  gujarati french mongolian ", "commit_messages": " add gujarati, french, mongolian langulage to new transalation list ", "linked_issue_titles": "", "title": "add new language in transalation list"}
{"description": " backporting a set of patches from 5.6 that improve allow better parsing of the video= strings from the kernel command line. the base code required the resolution to be specified under all circumstances, whereas with these we can now omit the resolution and only add the overscan margins or rotations. ", "commit_messages": " drm/modes: parse_cmdline: fix possible reference past end of string  commit 8582e244e5fe72d2e9ace186fa8f3ed3bb4122e1 upstream.  before this commit, if the last option of a video=... option is for  example \"rotate\" without a \"=<value>\" after it then delim will point to  the terminating 0 of the string, and value which is sets to <delim + 1>  will point one position past the end of the string.  this commit fixes this by enforcing that the contents of delim equals '='  as it should be for options which take a value, this check is done in a  new drm_mode_parse_cmdline_int helper function which factors out the  common integer parsing code for all the options which take an int.  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: make various char pointers const  commit 83e14ea3a64f00897cc31974d3ae4e27e5a7405b upstream.  we are not supposed to modify the passed in string, make char pointers  used in drm_mode_parse_cmdline_options() const char * where possible.  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: stop parsing extras after bpp / refresh at ', '  commit c2ed3e941901810ad3d55ce1935fa22c5007fee4 upstream.  before this commit it was impossible to add an extra mode argument after  a bpp or refresh specifier, combined with an option, e.g.  video=hdmi-1:720x480-24e,rotate=180 would not work, either the \"e\" to  force enable would need to be dropped or the \",rotate=180\", otherwise  the mode_option would not be accepted.  this commit fixes this by fixing the length calculation if extras_ptr  is set to stop the extra parsing at the start of the options (stop at the  ',' options_ptr points to).  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: accept extras directly after mode combined with options  commit cfb0881b8f621b656a9e23b31944a5db94cf5842 upstream.  before this commit it was impossible to combine an extra mode argument  specified directly after the resolution with an option, e.g.  video=hdmi-1:720x480e,rotate=180 would not work, either the \"e\" to force  enable would need to be dropped or the \",rotate=180\", otherwise the  mode_option would not be accepted.  this commit fixes this by setting parse_extras to true in this case, so  that drm_mode_parse_cmdline_res_mode() parses the extra arguments directly  after the resolution.  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: rework drm_mode_parse_cmdline_options()  commit 739b200c2edcaaa7a86f37b0c11db57956433dfb upstream.  refactor drm_mode_parse_cmdline_options() so that it takes a pointer  to the first option, rather then a pointer to the ',' before the first  option.  this is a preparation patch for allowing parsing of stand-alone options  without a mode before them, e.g.: video=hdmi-1:margin_right=14,...  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: add freestanding argument to drm_mode_parse_cmdline_options()  commit 99e2716e053734b70434502867be24d20a3e2d84 upstream.  add a freestanding function argument to drm_mode_parse_cmdline_options()  similar to how drm_mode_parse_cmdline_extra() already has this.  this is a preparation patch for allowing parsing of stand-alone options  without a mode before them, e.g.: video=hdmi-1:margin_right=14,...  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: set bpp/refresh_specified after successful parsing  commit 6a2d163756545aa3180d7851d5f8322b865e72be upstream.  drm_connector_get_cmdline_mode() calls  drm_mode_parse_command_line_for_connector() with &connector->cmdline_mode  as mode argument, so anything which we store in the mode arguments gets  kept even if we return false.  avoid storing a possibly false-postive bpp/refresh_specified setting  in connector->cmdline_mode by moving the setting of these to after  successful parsing of the bpp/refresh parts of the video= argument.  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: allow specifying stand-alone options  commit 7b1cce760afe38b40f0989cdf10b2190dccf9815 upstream.  some options which can be specified on the commandline, such as  margin_right=..., margin_left=..., etc. are applied not only to the  specified mode, but to all modes. as such it would be nice if the user  can simply say e.g.  video=hdmi-1:margin_right=14,margin_left=24,margin_bottom=36,margin_top=42  this commit refactors drm_mode_parse_command_line_for_connector() to  add support for this, and as a nice side effect also cleans up the  function a bit.  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: add support for specifying panel_orientation (v2)  commit 4e7a4a6fbdc669c44e6079f9d5eb25673749455f upstream.  sometimes we want to override a connector's panel_orientation from the  kernel commandline. either for testing and for special cases, e.g. a kiosk  like setup which uses a tv mounted in portrait mode.  users can already specify a \"rotate\" option through a video= kernel cmdline  option. but that only supports 0/180 degrees (see drm_client_modeset todo)  and only works for in kernel modeset clients, not for userspace kms users.  the \"panel-orientation\" connector property otoh does support 90/270 degrees  as it leaves dealing with the rotation up to userspace and this does work  for userspace kms clients (at least those which support this property).  changes in v2:  -add missing ':' after @panel_orientation (reported by kbuild test robot)  buglink:  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: remove some unnecessary code (v2)  commit 5b926617cdef41ce0696e09834991194b1759e28 upstream.  fb_get_options() will return fb_mode_option if no video=<connector-name>  argument is present on the kernel commandline, so there is no need to also  do this in drm_mode_parse_command_line_for_connector() as our only caller  uses fb_get_options() to get the mode_option argument.  changes in v2:  -split out the changes dealing with the initialization of the mode struct  into a separate patch  acked-by: maxime ripard <mripard@kernel.org>  link:  drm/modes: parse_cmdline: explicitly memset the passed in drm_cmdline_mode struct  commit d1fe276b5115f0d581c3cfe6154633b3547e8aab upstream.  instead of only setting mode->specified on false on an early exit and  leaving e.g. mode->bpp_specified and mode->refresh_specified as is,  lets be consistent and just zero out the entire passed in struct at  the top of drm_mode_parse_command_line_for_connector()  changes in v3:  -drop \"mode->specified = false;\" line instead of the \"return false;\" (oops)  this crasher was reported-by: kernel test robot <lkp@intel.com>  acked-by: maxime ripard <mripard@kernel.org>  link: ", "linked_issue_titles": "", "title": "backport a load of cmdline \"video=\" token parsing changes"}
{"description": " early stop callback function with the same logic as in xgboost: stopping after n steps without improvement. ", "commit_messages": " adding early stop round function  adding early stop round function correction  adding early stop round function correction 3 ", "linked_issue_titles": "", "title": "add early stop callback function"}
{"description": " i think your repo could really benefit from having my fantastic username displayed among the other completers! ", "commit_messages": " added mikesigs to the contributors list  something isn't working  drew a picture ", "linked_issue_titles": "", "title": "add mikesigs to the list of contributors"}
{"description": " this pr adds code and unit tests that fix issue #1835 and issue #1836. apologies for the changes being together but they were made at the same time. 1836 readable validation messages in error.h define an enum validateerrorcode for a set of kvalidateerrorxxx error codes, one per validation failure type in en.h add getvalidateerror_en() to map error code to a human-readable error message with inserts in schema.h: when creating a validation error, use the error code as the primary indicator, in addition to the error keyword add getinvalidschemacode() to validator to return the error code oneof: split into two errors - 'no match' and 'multiple match' - with error code and message for each allof: create in accordance to  dependencies: make property dependency error look like schema dependency error (bug found - see issue #1805) additionalitems: correct error keyword from items to additionalitems refactor adderrorlocation() in schematest.cpp fix the expected test outputs to include error code in schemavalidator.cpp example, add code to walk the errors and output error messages with inserts 1835 multiple validation failures in schema.h: add validateflag enum and member flags_ to the validator (analogous to parserflag for the reader) provide a flag kvalidatecontinueonerrorflag provide getvalidateflags() and setvalidateflags() for access to flags_ member if kvalidatecontinueonerrorflag set, do not set the valid_ member and thus allow the validator to continue do not change macro rapidjson_invalid_keyword_return - it still always returns false (see note) change isvalid() to return false if kvalidatecontinueonerrorflag set and the error_ object is not empty change getinvalidschemakeyword() and getinvalidschemacode() similarly at various places ensure that internal variables are in a correct state, so that continuing after an error is safe allow sub-validators to inherit the setting of kvalidatecontinueonerrorflag force sub-validators for oneof, anyof, allof, not, dependencies to not inherit kvalidatecontinueonerrorflag add reseterror() to allow errors to be reset (useful for incremental parsing) in schematest.h: add tests to exercise the validator when kvalidatecontinueonerrorflag set add tests to specifically exercise that validator internal variables are correctly set after an error change validate and invalidate macros in bin folder add new unittestschema folder containing new schemas for tests notes: to allow continuing after an error, i considered changing macro rapidjson_invalid_keyword_return so that it did not return false if kvalidatecontinueonerrorflag set, but instead continued. i coded a prototype, but it meant that unnecessary and unsafe processing continued (eg, creating sub-validators when type wrong). the change to allof error reporting. this was also made to aid the user in locating the failure, but is a change in behaviour. we could control this via a validation flag if necessary. ", "commit_messages": " pr for commits 2021/01/12  code and tests ", "linked_issue_titles": "", "title": "fixes for issues #1835 & #1836 - multiple validation failures and readable validation messages"}
{"description": " i hereby agree to the terms of the cla available at:  fix crash in generaterandom with nested types. fixes #10583. ", "commit_messages": " try fix header for generaterandom.  added test. ", "linked_issue_titles": " column with array type is not represented by columnarray column: fixedstring(size = 100000). ", "title": "fix generate random with nested"}
{"description": " no need to process transactions from accept_transaction next as the transactions are signaled via transaction_ack and processed there. see net_plugin_impl::transaction_ack. no need to update cached transactions block_num if they are expired as they will be purged from the local cache on next cache purge and we should not get them again from the network. add log of accepted connections. when receiving a go_away message, do not attempt to reconnect immediately. this restores old net_plugin behavior for go_away messages. ", "commit_messages": " do not reconnect immediately if sent a go_away message.  no need to process accept_transaction next as it comes through transaction_ack  remove commented out uneeded code  add back in correct trx_in_progress_size reduction  change accepted log level to info from debug ", "linked_issue_titles": "", "title": "remove redundant work from net plugin"}
{"description": " this pull request fixes the windows 10 uwp build by adding the missing external/clipper files and removing some obsolete files from the solution.. ", "commit_messages": " added missing external/clipper files. removed obsolete files  moved clipper files to external/clipper filter in vs solution ", "linked_issue_titles": "", "title": "fix windows 10 uwp build by adding missing external/clipper files"}
{"description": " make lightstepsink to send gprc requests to lightstep collectors. not for this iteration 2) right now we make grpc call only when buffer is full, for the first iteration i'd like to keep it this way, but we might need flush thread to flush traces for low rps services ", "commit_messages": " replace the json-generated span with a proto  supply the runtime random generator. generate lightste::collector::reportrequest. comments.  fix format for existing code.  make changes.  make existing code to compile with lightstep.  move recorder to header, move ordash to stringutil.  move things around.  temp changes.  add grpc/utility  move to utility class.  conflicts:  source/common/cmakelists.txt  source/common/tracing/http_tracer_impl.cc  async rpc client.  tmp  make envoy built.  few refinements. ", "linked_issue_titles": "", "title": "lightstep gprc generation for tracing"}
{"description": " we always run that pass when optimizing, but normally do not when not optimizing. in standalone mode, though, an unnecessary import may make the wasm not standalone and so not runnable in wasmer/wasmtime/etc. so in that mode, it's best to run it, to avoid a silly import breaking the wasm. a concrete example of when this is needed is that in hello world with iostreams we end up with unnecessary imports of atexit (we will need to fix that eventually, but it's only needed when exit_runtime is flipped by the user, as the default ignores atexits). ", "commit_messages": " st2 ", "linked_issue_titles": "", "title": "always run --remove-unused-module-elements when standalone_wasm"}
{"description": " what do these changes do? currently resource variables go undetected by the tensorflowvariables since they do not use the same ops for reading values. this change should fix this until a more robust solution is implemented. still missing: test to make sure resource variables are found in simple case test to make sure resource variables are found in case with control dependencies to check that the ops names don't differ #4437 ", "commit_messages": " adding support for resource variables  currently resource variable go undetected by the tensorflowvariables since they do not use the same ops for reading values. this change should fix this until a more robust solution is implemented. ", "linked_issue_titles": "", "title": "add support for tensorflow resource variables"}
{"description": " in #10676 we renamed the internal subtopology class that implemented the topologydescription.subtopology interface. by mistake, we also renamed the interface itself, which is a public api. this wasn't really the intended point of that pr, so rather than do a retroactive kip, let's just reverse the renaming. ", "commit_messages": " undo renaming  qualify public interface ", "linked_issue_titles": "", "title": "undo renaming of public part of subtopology api"}
{"description": " issue: #6359 in appcomponent, i used the changed detector ref retrieved from the child component's injector (componentref.injector.get(changedetectorref)), rather than the one available as a property on the component ref object (componentref.changedetectorref), as the latter does not work. after the properties are updated, i mark the child component for checking (childchangedetectorref.markforcheck()), but i call change detection from the appcomponent itself (this.changedetectorref.detectchanges()) to ensure that any properties using @hostbinding are also updated. i don't think so, unless we there is an easy way to produce screenshots after knob interaction. yes, included in this pr. no. ", "commit_messages": " merge latest  fix change detection to support onpush  fix issue reference ", "linked_issue_titles": "", "title": "support onpush change detection for class-specified components (to allow use of knobs)"}
{"description": " dateformatter.parse() timeout because of its o(n^2) time complexity the issue is in  it shows timeout (exceeds 60 secs). this is because dateformatter.parse() is costing o(n^2) time. the original implementation uses \"string.replace\" to generate a new string and to collect specifiers in while(regex_search) loop. however, the new string is completely unnecessary and will never be used after this function call. each iteration in the loop, the regex needs to search for the next matched string from the beginning. this causes it to be o(n^2). my implementation is to loop on suffix. in each iteration, set suffix=matched.suffix() and continue searching from the end of the matched string. so when collecting specifiers, we need to use different indices there to make sure they still point to the same positions in the string after being formatted. after this, the timeout test case passed. the running time of 400 layers cascading which cost 45 seconds in my local machine in the past, now can finish in around 300ms. the failed, timeout(exceeds 61s) test case now can pass in 525ms. besides, i added a new unit test against a long, messy string in utility_test.cc. i also added the timeout test case to the corresponding corpus folder. low passed all the following tests: //test/common/router:header_parser_fuzz_test //test/common/router:header_formatter_test //test/common/common:utility_fuzz_test //test/common/common:utility_test added a new unit test against long, messy string in utility_test.cc. / / ", "commit_messages": " added fuzz-test and the corresponding corpus for function getsha256digest() which is in: /source/extensions/common/crypto/utility_impl.cc  merge remote-tracking branch 'upstream/master'  keep master branch up to date  dateformatter.parse() timeout because of its o(n^2) time complexity  the issue is in    it shows timeout (exceeds 60 secs).  this is because dateformatter.parse() is costing o(n^2) time. the original implementation uses \"string.replace\" to generate a new string and to collect specifiers in while(regex_search) loop.  however, the new string is completely unnecessary and will never not used after this function call. each iteration in the loop, the regex needs to search for the next matched string from the beginning. this causes it to be o(n^2).  my implementation is to loop on suffix. in each iteration, set suffix=matched.suffix() and continue searching from the end of the matched string. so when collecting specifiers, we need to use different indices there to make sure they still point to the same positions in the string after being formatted.  after this,  the timeout test case passed. the running time of 400 layers cascading which cost 45 seconds in my local machine in the past, now can finish in around 300ms. the failed, timeout(exceeds 61s) test case now can pass in 525ms.  besides, i added a new unit test against long, messy string in utility_test.cc.  fixed style issues ", "linked_issue_titles": "", "title": "optimized dateformatter.parse() to o(n)"}
{"description": " @marshallofsound and i are working to wrap up the electron.d.ts effort. the last (known) holdout is the webview-tag doc, which has some unique qualities like its name and the fact that it has attributes. this pr contains fixes to the webview api doc, as well as some fixes for other issues found by the linter along the way. ", "commit_messages": " denote webview process so linter will recognize it as an api  fix indentation of app.setloginitemsettings arguments  document arguments for webview methods ", "linked_issue_titles": "", "title": "fix api docs for webview tag"}
{"description": " two new features for github oauth. based on accounts config pass in allow_signup param on the initial request to prevent sign ups on github side if the user does not have an account already. after data about the user is retrieved get more of it into servicedata so that they are available to the app. we will receive the data anyway, so might as well use it. ", "commit_messages": " github save more data retrieved from github  add allow signup option to github oauth ", "linked_issue_titles": "", "title": "github oauth allow_signup & more data returned"}
{"description": " for #6869. ", "commit_messages": " refactor mergedencryptcolumnsmergedresulttest  use static import with mockito.mock  use static import with mockito.returns_deep_stubs  use static import with mockito.when  remove useless mock on mergedencryptcolumnsmergedresulttest  add mockeddatasource  use mockeddatasource instead of h2 data source in spring namespace test cases  use mockeddatasource instead of h2 data source in spring namespace test cases  move encrypt spring namespace to encrypt module  refactor encryptspringnamespacetest  move master-slave spring namespace test to current module  remove useless abstractspringjunittest  move shadow spring namespace test to correct module  remove useless xml  move spring sharding test into correct module  revise springnamespacetest  update encryptspringnamespacetest  update masterslavespringnamespacetest  update shadowspringnamespacetest ", "linked_issue_titles": "", "title": "move spring namespace' test cases to correct modules"}
{"description": " this is a cleanup of the wrappable class, so: there is no getobjecttemplatebuilder, all classes now use buildprototype; developers no longer need to cache the object template themselves; the creation of js object is now in wrappable's constructor, instead of lazily initialized in getwrapper; ", "commit_messages": " make wrappable a template class  remove the isolate parameter of getwrapper  remove unneeded cleanup code ", "linked_issue_titles": "", "title": "clean up the wrappable class"}
{"description": " this is a backport of #12257 and #12279 to swift-4.0-branch to more-accurately gather stats there (in particular: dodge a data-loss issue when writing stats files to deeply-nested directories). rdar://34818636 ", "commit_messages": " [stats] fix typo.  [stats] only use input filename, not mangled path, in stats file name.  this was causing cases of very long input pathnames to be mangled into  stats filenames greater than 255 characters long, which in turn meant  stats files were not being written in some cases.  [stats] add a test for long input-path bug (0e5b982d) ", "linked_issue_titles": "", "title": "rdar 34818636 backport pr 12257 stats output dir filename issues to swift 4.0 branch"}
{"description": " due to ray limitations, we cannot create references to portions of an existing ray object with zero-copy semantics. hence, in dataset we have to store arrow tables as top-level ray objects. this means we have to add a wrapper class to access different block types in a uniform way. after this pr, calls to ds.to_arrow() and ds.from_arrow() are zero copy. possible design alternatives: rename block to something like blockdata (can still do this in the future, but didn't do this in this pr since it changes a lot of code) require all block accesses to be done via static methods (e.g., block.num_rows(block_data). this is a bit clunky and potentially slower since we have check the python type of the data each time. support zero-copy sub-object references in ray. closes #17186 related issue oap-project/raydp#166 ", "commit_messages": " wip  fix  wip ", "linked_issue_titles": " [data] store pyarrow.table directly as a block instead of wrapping in arrowblock ", "title": "enable zero-copy access to underlying arrow tables"}
{"description": " closes #82956 closes #84659 closes #86530 closes #86535 there is also a random test in here about array repeat expressions that i already had on this branch but it seems to fit the theme of this pr so kept it... r? @lcnr ", "commit_messages": " e-not-needs-test  tidy ", "linked_issue_titles": " ice using `const_generics` feature  trait with a lifetime parameter, associated constant, and an associated type can trigger an ice  const generics panic  no errors encountered even though `delay_span_bug` issued', compiler/rustc_errors/src/lib.rs:1023:13 ", "title": "add tests for some const generics issues"}
{"description": " see the following links in the node api docs showing the missing optional parameters... crypto.pbkdf2 crypto.pbkdf2sync ", "commit_messages": " added optional parameters for the crypto.pbkdf2* functions  fixing typescript optional parameter issue, all tests pass ", "linked_issue_titles": "", "title": "added optional parameters for the node crypto.pbkdf2* functions"}
{"description": " internal fields model snapshot id, established model memory and job version should not be settable via a request to anomaly_detectors/job_id/_update partial backport of #30512 ", "commit_messages": " add jobversion to update  hide internal fields from the rest request parser  change yml tests to not use secret job update settings  use the revert model snapshot api instead ", "linked_issue_titles": "", "title": "hide internal job update options from the rest api"}
{"description": " don't nack empty updates or those where expected resources are not present.  instead, report an error to watchers for missing resources. implement removing deleted resources from the cache. don't cache cds resources that we didn't ask for. properly unsubscribe from rds resources as required by lds update. when unsubscribing from one resource and then subscribing to another, combine the xds requests. fix a potential crash in the xds lb policy when trying to update a locality whose priority is not in the current update. ", "commit_messages": " add test for changing clusters  change logic to send empty response when resources go away  don't nack empty updates. ", "linked_issue_titles": "", "title": "don't nack empty updates, remove deleted resources from cache, and other fixes"}
{"description": " upgrade the yubihsm wallet to use libyubihsm2. this brings about two user facing features: support for newly shipping yubihsm 2.1 firmware support for talking to a yubihsm directly through usb instead of through the connector (use yubihsm-url = yhusb://) libyubihsm2 is open source so now we build and statically link to the library internal to the eosio project. this makes using yubihsm for users much easier as they don't have to chase down yubico's installer and dump the .sos in the correct directory (correct can be tricky here). however, this also makes eosio have three new dependencies: libusb, libcurl, and pkg-config. all three of these are pretty standard fare so i don't feel too guilty adding them as dependencies. ci is currently failing because of the inability to have libusb available in the test instance (i link to it dynamically since i consider it much like other system level packages like openssl) ", "commit_messages": " upgrade to libyubihsm 2 and link directly with it  add build deps and packages deps for libusb/libcurl/pkgconfig  don't build libyubihsm with lto  lto objects confuse some of the older platforms/compilers we target  handle libusb better in macos build script  something really wonky here; it's like the script tries to unlink everything it installs?? get this working for now with just the libusb that i added  add installation of libyubihsm license  block out libyubihsm's add_test()s  exclude_from_all blocks out all non-dependant targets but this doesn't prevent add_test() from being called on the now non-existant targets. i tried several approaches to remove these tests (without changing upstream cmake) and this approach was the best when factoring in that it's documented and simple ", "linked_issue_titles": "", "title": "libyubihsm2 upgrade & yubihsm 2.1 support"}
{"description": " this pr adds the capability for async methods in serve actors as well as preliminary support for multiple methods. class mybackend: async __call__(self, flask_request): def other_method(self, _): pass the other_method currently can only be invoked internally by constructing call_method=\"other_method\" to the query parameter. it is planned for the future to expose this through serve.route decorator. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " allow task runner to run async method  allow multiple methods endpoint  fix a batching bug ", "linked_issue_titles": "", "title": "add async, multi methods support for serve actors"}
{"description": " if a semantic update finishes fast enough, the token snapshot may be identical to the edit snapshot, but because of getbufferforsnapshot consolidating edits into a new buffer, we were not detecting that case properly, and it could cause an assertion failure (or potentially incorrect range shifting in a release build). this would have reproduced very rarely in practice, but i can reproduce it by putting sleep(2) calls right before we read the semantic info in open and edit requests. fix sourcekit-test and unit tests for the (rare) case where an open or edit already has updated semantic info. fix editing test previously disabled so that semantic tokens will be the same regardleess of whether they come from range-shifting or from a full semantic update. ", "commit_messages": " [test] fix annotation test to have same behaviour before and after update  the goal of the test is to test the behaviour when the edit is  range-shifted, but in the (rare) case where the document update happens  before the edit finishes, we need the ranges to be the same. in  particular, using separate statements ensures that the tokens not  touched by the edit are not affected by the edit.  re-enable the test disabled on asan, since this seems to be the  underlying issue.  rdar://65934938  [sourcekitd] fix range shifting \"race\" with a fast semantic update  if a semantic update finishes fast enough, the token snapshot may be  identical to the edit snapshot, but because of getbufferforsnapshot  consolidating edits into a new buffer, we were not detecting that case  properly, and it could cause an assertion failure (or potentially  incorrect range shifting in a release build). this would have reproduced  very rarely in practice, but i can reproduce it by putting sleep(2)  calls right before we read the semantic info in open and edit requests.  incidentally, fix sourcekit-test and unit tests for the (rare) case  where an open or edit already has updated semantic info. ", "linked_issue_titles": "", "title": "fix range shifting vs semantic update timing issues"}
{"description": " @marcoabreu @kellensunderland @chancebair @gautamkmr @bhavinthaker this pr adds new dockerfiles for python that are currently being used to release docker images to dockerhub after each mxnet release. these dockerfiles are built on the mxnet pip binaries instead of 'build from source' as in the existing dockerfiles. this makes the docker files easier to build and keeps the docker & pip binaries consistent. i have also added a script that can be used to build all 10 different images, run 3 sanity tests and upload them to dockerhub (credentials need to be provided) with one command. please refer to the readme added for more details. docker images are uploaded here:  please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change 4 dockerfiles to build mxnet python for the latest released version. script to automate build, test and release of docker images to dockerhub. a test script that makes sure that the installed version of mxnet matches the requested version. ", "commit_messages": " initial commit for docker automation python  fixes  change dir for tests  fix more issues  fix docker tag command  cosmetic changes  update readme  update test to fail on version mismatch  remove debug mode  update readme.md  update readme.md  update readme ", "linked_issue_titles": "", "title": "python dockerfiles built on pip binaries and build/release script"}
{"description": " since most browsers no longer allow making async requests from a page loaded from file://, we now need a proper http server to load the exported html5 game. this should also allow us to get the debugger to work over a websocket connection. includes a small refactor of editorexportplatform/editorrunnative interaction. fix bug where editor theme was not accessible via singleton. closes #16245 . ", "commit_messages": " fix editornode.get_editor_theme  editornode was not correctly setting the class memeber when creating the  theme, using a local variable instead.  theme is now created before registering exporters (as they might need it).  improve editorexportplatform interface.  convert all get_device* methods to get_option* and normalize their usage  as icon, label, tooltip.  implement http server for html5 export  since most browsers no longer allow making async requests from a page  loaded from file://, we now need a proper http server to load the  exported html5 game.  this should also allow us to get the debugger to work over a websocket  connection. ", "linked_issue_titles": " add simple http server for html5 debugging ", "title": "implement http server for html5 \"run\" export"}
{"description": " please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  pkg.go.dev:  goreportcard.com:  coverage service link (codecov, coveralls, gocover etc.)  very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. ", "commit_messages": " initial commit  change remote url ", "linked_issue_titles": "", "title": "add lets-go, a library with various aws and rest utility packages."}
{"description": " this is of course still wrong regarding #5662, but at least brings it in line with the other output formats (and adds a test) import {$679c7b63be557d242f596b1b4cbcc6a9$init} from \"./a.js\"; console.log(\"b\", $679c7b63be557d242f596b1b4cbcc6a9$$interop$default); after: function $parcel$interopdefault(a) { return a && a.__esmodule ? a.default : a; } import {$679c7b63be557d242f596b1b4cbcc6a9$init} from \"./a.js\"; var $679c7b63be557d242f596b1b4cbcc6a9$$interop$default = $parcel$interopdefault($679c7b63be557d242f596b1b4cbcc6a9$init()); console.log(\"b\", $679c7b63be557d242f596b1b4cbcc6a9$$interop$default); ", "commit_messages": " add test  fix ", "linked_issue_titles": "", "title": "add interop declaration for esm cross bundle imports"}
{"description": " only 567 orgs (<.1% of all sentry's orgs) have more than 50 projects which led to the decision to paginate this settings -> projects page ( before after closes sen-1201 ", "commit_messages": " paginated and grid emotion changes  snapshot?  changed to flex  snap ", "linked_issue_titles": "", "title": "change projects settings pagination to 50 items and remove grid emotion"}
{"description": " what do these changes do? rllib.models.lstm is currently using tf.nn.rnn_cell.basiclstmcell. however, as pointed out in the docs, basiclstmcell will be deprecated from tensorflow 1.13 and should be replaced with tf.nn.rnn_cell.lstmcell. no need to change the signature. tested on cartpolestatelessenv and it works: none linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fixed bug in dirichlet (#4440)  update  replaced deprecated rnn_cell.basiclstmcell with rnn_cell.lstmcell ", "linked_issue_titles": "", "title": "replaced discontinued rnn_cell.basiclstmcell with rnn_cell.lstmcell"}
{"description": " i have created some custom keymaps for the iris and planck keyboard for my personal sets. ", "commit_messages": " inital layout  fix the backspace  add a number pad  move the backlight to the adjust layer; move ctrl and delete.  rodhaene/keymap  update from main repo  add initial files for custom keymap  light keymap mod  rodhaene/iris keymap ", "linked_issue_titles": "", "title": "merge in some custom keymaps from forked repository"}
{"description": " hi, minggo and owen. please review these commits for tizen support. thanks a lot. ", "commit_messages": " sync with original branch  support audio interruption and resume callback when change earphone status.  refactor keyevent callback and add makecurrent for compatible with different binary.  enable tizen indicator.  remove the unnecessary evasobject in the window and refactor the function for glview mode.  fix the compatible issue between tizen 2.3 and 2.4.  fix the wrong directory of script resources for helllua template project.  create performance-test project for tizen platform. ", "linked_issue_titles": "", "title": "some bug-fix and quality assurance for tizen support."}
{"description": " built on #6070 ", "commit_messages": " add a failing test due to a head of line blocking bug in the server  initial interface rework to allow knowing whether to pull payload at registration, not at request time  merge github.com:grpc/grpc into head-of-line-blocking  add missing line  fix registration in test  fix head-of-line blocking in server  fix codegen  introduce machinery to allow tests to register plugins  add test to verify bad behavior  add a test demonstrating forced closure of a stream, and make it work ", "linked_issue_titles": "", "title": "add a test for forced stream closure on the server, and make it work"}
{"description": " the encrypted repository is usable to the extent that the feature can greatly benefit from testing as part of snapshot builds on cloud. to get an impression of how to use this feature see the description of the last pr merged in the feature branch  #53352 (comment) . after this pr is merged to the feature branch, my plan is to raise the pr that merges the feature branch to master, without asking for any other reviews. ", "commit_messages": " feature flag to register the new encrypted repository type  reverse condition to have a friendlier diff  spotless and invert condition ", "linked_issue_titles": "", "title": "introduce the encrypted repository behind a feature flag"}
{"description": " sil: make adjustfunction type of closures parameterized on whether we use guaranteed closures this is going to go away once we change the default to guaranteed closures. silcombine: fix @callee_guaranteed combine of try_apply i missed another place where we were releasing the context. sr-5441 rdar://33255593 ", "commit_messages": " sil: make adjustfunction type of closures parameterized on whether we use  guaranteed closures  this is going to go away once we change the default to guaranteed  closures.  sr-5441  rdar://33255593  silcombine: fix @callee_guaranteed combine of try_apply  i missed another place where we were releasing the context.  sr-5441  rdar://33255593 ", "linked_issue_titles": "", "title": "silcombine and sil adjustfunctiontype fix for @callee_guaranteed"}
{"description": " solve dts==0 bug when demux mpegts if (dts == 0) {dts = pts} solve many aac packed in a large mpegts(2930bytes) demux mpegts and recover the dts. ", "commit_messages": " solve dts==0 bugs; solve large aac 2930bytes timestamp bugs  solve dts==0 bugs; solve large aac 2930bytes timestamp bugs ", "linked_issue_titles": "", "title": "solve dts==0 bug and solve many aac packed in a large mpegts(2930bytes)"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. i fixed some english errors and i added more details about video challenges. ", "commit_messages": " upade fork  fix some errors ", "linked_issue_titles": "", "title": "fixed some orthographic errors and improvements"}
{"description": " np.ndarray.dumps and np.ndarray.dump will now let the user specify a pickle protocol. pickling tests now loop over all possible protocols. part of #12011, that implements pickle protocol 5 for numpy arrays (this pr is currently being broken out in multiple shorter prs for simplification and clarity purposes). pinging @ogrisel @mattip ", "commit_messages": " added protocol kw to c implementations of array_dump[s]  updated documentation for array_dump[s]  loop over protocol for pickle tests ", "linked_issue_titles": "", "title": "update pickling tests by making them loop over all protocols"}
{"description": " fixes #12386. often the max_features parameter of a bagging estimator is set as a float, to represent a fraction of the number of features to use. to convert to an integer, this equation is currently used: max_features = int(self.max_features * self.n_features_) however, this often leads to a valueerror if the result is rounded down to zero. this may occur if the number of features is often unknown (for example, due to hyperparameter tuning in an earlier stage). this pr ensures a minimum of one feature is kept in this situation: max_features = max(1, int(self.max_features * self.n_features_) ) would be grateful to check that unit test is implemented in the right place in an appropriate manner. i've tried to be consistent with other tests. i've tried to find the cleanest implementation that still raises a valueerror if max_features is negative, zero, too large, or not an int nor float. ", "commit_messages": " added constraint max_features at least one  added non-regression test ", "linked_issue_titles": " max_features often rounded down to zero, leading to valueerror ", "title": "fix  keep at least one feature when max_features is small fraction"}
{"description": " fixes #1137 this is not location.reload(), but reload the internal next.js state. ", "commit_messages": " add support to reload the page when ask to change the same url.  do not run change() in the initial page load.  add integration tests. ", "linked_issue_titles": "", "title": "reload the page if asked to change the current url"}
{"description": " fixes #15845 alternative to #15885 implements @jnothman's suggestion: #15845 (comment) this pr adds attributes back in as an optional keyword to check_is_fitted. ", "commit_messages": " enh adds attributes back to check_is_fitted  doc updates docstring ", "linked_issue_titles": " check_is_fitted has false positives on custom subclasses with private attributes ", "title": "bug adds attributes back to check_is_fitted"}
{"description": " convolution2d only has border_mode='full' or 'valid' and the image size changes upon convolution. i added a layer that allows to shrink the image after using convolution2d with border_mode='full' back to the original size (before the convolution2d) example, assume images are 28x28 as in the mnist example model.add(convolution2d(32, 1, 3, 3, border_mode='full'))   # images are now 30x30 model.add(activation('relu')) model.add(cropimage(1))                                     # images are now 28x28 thanks for a great package ", "commit_messages": " added cropimage layer. shrinks images in a convolution layer. when  applying a convolution2d with border_mode='full', images will grow in  size, this layer allows to shrink them back to its original size (or any  other size) ", "linked_issue_titles": "", "title": "cropimages to maintain sizes in cnn"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. release url:  beta url: ", "commit_messages": " [office-js-preview] (excel) pulling latest type definitions from cdn  [office-js] (excel) pulling latest type definitions from cdn ", "linked_issue_titles": "", "title": "pulling latest excel type definitions from cdn"}
{"description": " for...of introduces a dependency on symbol and symbol.iterator (and bloated code too, with try / catch in a potentially very hot dev path). we accidentally merged that in #10783. i'm adding this rule so we can be more vigilant. you can ignore it for build and other scripts but please don't ignore it in the source. ", "commit_messages": " add no-for-of lint rule  ignore legit use cases of for..of  rewrite for..of in source code ", "linked_issue_titles": "", "title": "disable for...of by default, rewrite cases where it matters"}
{"description": " libweb: add pc css unit libgfx+fonteditor+fonts: add \"mean line\" value to all fonts the main inspiration behind this was to have a correct ex css unit. the mean line is based off what it shows in the css values and units level 4 specification, section 6.1.1. ", "commit_messages": " libweb: add pc css unit  libgfx+fonteditor+fonts: add \"mean line\" value to all fonts  the main inspiration behind this was to have a correct ex css unit.  the mean line is based off what it shows in the css values and units  level 4 specification, section 6.1.1.   ", "linked_issue_titles": "", "title": "add pc css unit and get a correct ex unit"}
{"description": " this change address two issues: #12372 view columns not visible with 'no schema binding' views on redshift connection #12396 dbeaver 21.0.4: not all columns showing in db navigation pane/generated sql - view it address a few aspects, first it will allow the column to display in the navigator and also allow the columns to show in 'generate sql' functions. ", "commit_messages": " add datatype aliases for time and timestamp  update check for no binding view to be case insensitive ", "linked_issue_titles": "", "title": "redshift missing columns when view is configured as a non-binding."}
{"description": " graylog uses layer 4 loadbalancers for tcp/udp traffic ingress, however there was no way to specify the externaltrafficpolicy in order to preserve the client ip address. my changes allow overrides to local, but default to cluster @kongz  - obligatory mention :) hi! dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " adding the ability to specify externaltrafficpolicy, and thus preserve client ip addresses  updated readme ", "linked_issue_titles": "", "title": "adding the ability to specify externaltrafficpolicy for loadbalancer services"}
{"description": " i added examples that make use of the args form ( i didn't know about this language feature so for me it was quite a search before i found it out. it would be nice to add it to the examples of these modules because you would probably use this language feature faster with these modules than others. ", "commit_messages": " added examples to the shell module  added examples to the command module ", "linked_issue_titles": "", "title": "add examples for shell and command modules."}
{"description": " kevaa/decompress exports a function with 4 overloads: decompress (input, output, opts) decompress (input, output) decompress (input, opts) decompress (input) prior definition did not support third and fourth overload patterns. this pull request corrects that. line 41 provides for undefined options function extractfile is invoked from decompress on line 95  line 81 allows for decompressoptions sent as second argument instead of third ", "commit_messages": " 'output' argument of decompress function is overloaded to support undefined, string, or decompressoptions  updated definitions by tag  added additional tests for output argument overload alternatives  fixed string formatting per lint recommendations ", "linked_issue_titles": "", "title": "decompress function should have four overloads"}
{"description": " this fixes a pathological-sounding-but-it-happened-to-us scenario that caused incorrect template digests for */* requests that render non-html (json, in our case) templates. the scene looks something like this: an appended view path: append_view_path(rails.root.join(\"app/views/api\")) partials in this path with the same logical path as partials in app/views, but for different formats: app/views/api/todos/_todo.json.jbuilder and app/views/todos/_todo.html.erb, both \"logically\" known as todos/todo. both of these partials have cache fragments. a controller action (schedules#show) with a corresponding json template (show.json.jbuilder) that in turn renders a collection of partials: json.todos @todos, partial: 'todos/todo', as: :todo. a client-side fetch requests to this action that doesn't set an accept header so it defaults to */*. the json response is correctly returned, but the template digest it uses for caching is computed using the html templates. altering _todo.json.jbuilder does not invalidate its cache, but altering _todo.html.erb does. we worked around the issue by adding an accept: application/json header. adding a .json format to the url would have worked around it too. here are the new tests failing without the changes to actionview::digestor: $ rake test test=test/template/digestor_test.rb run options: --seed 2948 # running: ........f.............f............... finished in 5.274653s, 7.2043 runs/s, 10.4272 assertions/s. 1) failure: templatedigestortest#test_template_formats_of_nested_deps_with_non_default_rendered_format [/users/javan/projects/rails/actionview/test/template/digestor_test.rb:165]: expected: [:json] actual: [:json, :html] 2) failure: templatedigestortest#test_different_formats_with_same_logical_template_names_results_in_different_digests [/users/javan/projects/rails/actionview/test/template/digestor_test.rb:287]: expected \"18824a8cf013bb976bc39b5809a262c4\" to not be equal to \"18824a8cf013bb976bc39b5809a262c4\". 38 runs, 55 assertions, 2 failures, 0 errors, 0 skips all green with the changes. / ", "commit_messages": " fix digesting templates with identical logical names when requesting a format other than the first default  explicity find with the rendered format to handle searching multiple view paths correctly  fix finding templates for digesting for */* requests that render a non-default (html) template  move and rename test  add test for nested html dependencies with same logical name as templates for other formats ", "linked_issue_titles": "", "title": "fix digesting non-html templates with non-unique logical names"}
{"description": " cherry pick the following fixes to 0.65: i18n.allowrtl should default to true (#7840) better reporting of failures to load the bundle file (#8018) intermittent deadlock when reloading multiple times rapidly (#8026) remove javascriptmainmodulename and debughost (#8027) turbomodules might be kept alive by rnh when instance is shutdown (#8035) fix crash when adding a reactrootview while reloading a reacthost (#8042) microsoft reviewers: open in codeflow ", "commit_messages": " i18n.allowrtl should default to true (#7840)  * allowrtl should default to true  * change files  better reporting of failures to load the bundle file (#8018)  * better reporting of failures to load the bundle file  * change files  * remove extra call to abandonjscallqueue, since onerror will do it.  * format  * codereview feedback  intermittent deadlock when reloading multiple times rapidly (#8026)  * intermittent deadlock when reloading multiple times rapidly  * format  remove javascriptmainmodulename and debughost (#8027)  * remove javascriptmainmodulename and debughost  * change files  * update vnext/microsoft.reactnative/reactinstancesettings.idl  turbomodules might be kept alive by rnh when instance is shutdown (#8035)  * turbomodules might be kept alive by rnh when instance is shutdown  * change files  fix crash when adding a reactrootview while reloading a reacthost (#8042)  * fix crash when adding a reactrootview while reloading a reacthost  * change files  * ensure we always reset unloading flag ", "linked_issue_titles": "", "title": "cherry pick various high impact fixes"}
{"description": " adds generic type for relayprops to type variables. adds relayprops interface that can be used to fully abstract relay prop injection. interface iprops extends relay.relayprops<componentrelayvariables> { // everything but no relay. ", "commit_messages": " (relay-classic) adds relayprops variables typing  (react-relay) add relayprops interface  (react-relay) fix lint  (react-relay) add maintainer ", "linked_issue_titles": "", "title": "react-relay - improve props and relay variables typing"}
{"description": " introduce and use new apis to perform lookups of existing pre-specializations in a more light-weight way. don't serialize and don't even try to read bodies of pre-specialized functions. just check if they exist. ", "commit_messages": " add apis to check if a function with a given name exists and to invalidate a sil linker entry for a function.  these apis are useful e.g. for quickly finding pre-specialisations by their names.  the existence check is very light-weight and does not try to deserialize bodies of sil functions.  serialize only declarations of pre-specializations.  only declarations of whitelisted pre-specializations from with public linkage need  to be serialized as they will be used by useprespecializations pass during -onone  compilations to check for availability of concrete pre-specializations.  the bodies of these functions are not required as they cannot be used anyways,  because they may refer to symbols with non-public linkage.  simplify a search for an existing generic specialization.  use the new hasfunction api to check for existence of a specialization and clean-up the code. ", "linked_issue_titles": "", "title": "implement a more light-weight approach to perform lookups of existing pre-specializations"}
{"description": " current behavior: we have a grace period (1s) for transient object store full errors to wait for operations like gc. however if object spilling takes long, we would run out of grace period time and raise oom immediately after spilling is done without waiting for gc. this pr added a test for this scenario, and changed the code such that the oom grace period timer only starts after spilling is done. this is related to #14788 but does not fully resolve it. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix deserializer in metrics.counter  fix restore_spilled_objects() for external object spilling  wip reset oom timer ", "linked_issue_titles": "", "title": "reset oom timer as objects are being spilled"}
{"description": " checklist closing issues: #issue i wrote some lines in the radare2book the new format is similar to the older one, but all string references are offsets from the start of the string table instead of relative to where the reference lives. this change detects and reacts to this condition. depends on new test bin:  radareorg/radare2-testbins#60 ", "commit_messages": " add support for modern coresymbolication elements ##bin  add tests for new coresymbolication elements ", "linked_issue_titles": "", "title": "add support for new coresymbolication element format ##bin"}
{"description": " this touches some delicate functions to be messing with, so i've split off the underlying logic into a function in common and added an exhaustive test. would welcome review none the less. also, i tried to test for nagative perf. there must something wrong with the test since comparing the commit after just adding a test to the baseline, shows 50% degredation in a bunch of things. as i said, i don't trust this, ideas? timeseries_asof_nan                       23.4131    15.7471 1.4868 datetimeindex_normalize                 1153.1918   774.8010 1.4884 timeseries_asof                           22.3342    14.9964 1.4893 reshape_unstack_simple                     4.8106     3.2289 1.4899 read_table_multiple_date_baseline        980.0920   657.3641 1.4909 timeseries_1min_5min_mean                  0.8087     0.5422 1.4915 timeseries_timestamp_tzinfo_cons           0.0210     0.0141 1.4922 match_strings                              0.5718     0.3817 1.4982 timeseries_large_lookup_value              0.0301     0.0201 1.4998 reindex_fillna_pad                         0.1828     0.1217 1.5018 timeseries_to_datetime_iso8601             5.6048     3.7270 1.5038 read_table_multiple_date                2169.5440  1441.5460 1.5050 reindex_daterange_pad                      0.2608     0.1731 1.5066 timeseries_1min_5min_ohlc                  0.8046     0.5331 1.5092 reindex_daterange_backfill                 0.2466     0.1634 1.5094 period_setitem                          1166.9910   772.4509 1.5108 reindex_fillna_backfill                    0.1790     0.1183 1.5130 timeseries_asof_single                     0.0656     0.0434 1.5136 append_frame_single_mixed                  2.0747     1.3697 1.5147 timeseries_slice_minutely                  0.0762     0.0501 1.5208 columns: test_name | target_duration [ms] | baseline_duration [ms] | ratio (01bc3e0 against 81169f9) - a ratio of 1.30 means the target commit is 30% slower then the baseline. closes #2347 ", "commit_messages": " tst: df.pop() of non-unique column  enh: add com.split_ranges util function  tst: add tests for com.split_ranges()  bug: deletion of non-unique column. closes #2347  tst: split_block_at() after changes  doc: docstring of index.get_loc, clarify return type ", "linked_issue_titles": " del df[k] fails for a non-unique key ", "title": "del df[k] with non-unique key"}
{"description": " i carefully read the contribution guidelines and agree to them. i created the file strings.xml in values-oc folder to be able to translate to occitan from weblate ", "commit_messages": " added initial strings.xml for occitan language  move to values-oc ", "linked_issue_titles": "", "title": "add support for occitan language"}
{"description": " fixes two regressions that were introduced in swift 5.2: default arguments of local functions inside @inlinable functions were not serialized, which would cause a sil verifier failure if the default argument was referenced there was no enforcement that these default arguments did not reference non-public symbols, which again could cause crashes. fixes rdar://problem/62200974 / ", "commit_messages": " ast: diagnose references to non-public declarations from default arguments of inlinable local functions  part of <  sil: serialize default arguments of inlinable local functions  fixes < ", "linked_issue_titles": "", "title": "fix default arguments of inlinable local functions [5.3]"}
{"description": " remove the code that is not useful in the loop ", "commit_messages": " remove spaces before and after the properties  update mixall.java  remove spaces before and after the properties  remove spaces before and after the properties  remove spaces before and after the properties ", "linked_issue_titles": "", "title": "[rocketmq-226]remove the code that is not useful in the loop"}
{"description": " add str->int dict in kvstore backend so that module can use the param name to perform update instead of its index @mli @piiswrong ", "commit_messages": " update kvstore unit test  update model/module.py  fix lint ", "linked_issue_titles": "", "title": "support str key type in kvstore"}
{"description": " change points: undo the pr #1033 set the createdependencyreducedpom to true. the code of seata-* has all be packed into the seata-all.jar, and should not be inclueded in the seata-all.pom. modify the all.xml change  the  configs of maven-javadoc-plugin in seata-all.xml ", "commit_messages": " undo  pr #1033  undo  pr #1033  modify file.conf ", "linked_issue_titles": "", "title": "undo pr 1033 and adjust the maven plugin of seata-all.xml"}
{"description": " i hereby agree to the terms of the cla available at:  fix incorrect behavior when alter table ... drop part 'part_name' query removes all deduplication blocks for the whole partition. fixes #18874. ", "commit_messages": " fix deduplication block names parsing  add test ", "linked_issue_titles": " dropping of a part breaks deduplication of data blocks ", "title": "fix drop part query break deduplication"}
{"description": " hey @felixxm. this is a backport of adam's #12645. beyond being an improvement, i thought it worth doing, since i imagine it makes our lives easier backporting docs changes in the next few months. but, given the docs conf changes, i wanted to run it passed you so... ", "commit_messages": " [3.0.x] prevented (and corrected) single backtick usage in docs.  backport of 1cdfe8d91215eefaa18c398069dd9c6879a9511d from master.  [3.0.x] corrected docs spelling of pgbouncer.  backport of b1f88476dbd738bdcc20466efd5ffcb83ab25093 from master ", "linked_issue_titles": "", "title": "backport of #12645 to stable/3.0.x."}
{"description": " mainly gets rid of sign conversions, but also tidies up the surrounding area a little bit. ", "commit_messages": " gl_state: get rid of mismatched sign conversions  while we're at it, amend the loop variable type to be the same width as  that returned by the .size() call.  gl_state: make references const where applicable in apply() ", "linked_issue_titles": "", "title": "get rid of mismatched sign conversions in apply()"}
{"description": " i made a brief documentation for shaders. you can preview it here (before this pr is merged):  currently contains introductory tutorials, documentation for constants.py and custom_default.yml and something about development. i will fill in the rest of the documentation later (about this summer), but i think this document is enough to be used as an introductory guide. this document is built using sphinx, applies furo theme, and is automatically deployed on github pages through github action. if i made some mistakes, please point them out. if there is a grammatical error, please also bring it up (my english is not very good). @3b1b please take a look at this documentation. i will tell you in private about how to deploy this document. ", "commit_messages": " update  set up docs  set up action workflow to build up docs  update structure  fix path for sphinx-build  fix action workflow (#5)  set up structure  add manimlib to path  change theme  create manim_example_ext  finish development category and improve style  finished quick start  finish config, structure, constants and custom_default  finish example scenes  fix bugs and update readme  add pycairo to env  add icon  update workflow ", "linked_issue_titles": "", "title": "add documentation for shaders version"}
{"description": " corrected the code style to pep8. a correction that does not affect the operation. before $pycodestyle redash/|wc -l                                                                                                                                                     181 after $pycodestyle redash/|wc -l                                                                                                                                                     111 ", "commit_messages": " fix w292 no newline at end of file  fix extra whitespace  fix e305 expected 2 blank lines after class or function definition  fix w391 blank line at end of file  fix e231 missing whitespace after  fix e303 too many blank lines  fix e302 expected 2 blank lines  fix e128 continuation line under-indented for visual indent ", "linked_issue_titles": "", "title": "fix according to pycodestyle format"}
{"description": " addresses #134660 creates a clearer telemetry ui to prevent misconceptions regarding telemetry re-enablement ", "commit_messages": " work on improving telemetry setting description  two options  third option  add old crash reporter to gettelemetrylevel  more verbose wording + comments ", "linked_issue_titles": "", "title": "clearer settings ui for new telemetry setting"}
{"description": " these changes fix/improve: allow to specify expandrowprops.nonexpandable when table key is of type other than number (according to docs, there is no such restriction), better type control for expandrowprops.expanded which previously was of any[] type. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add key type to expandrowprops  add test cases for providing key type ", "linked_issue_titles": "", "title": "add type for table key to use expandrow with correct types"}
{"description": " fixes #78. this is a resurrection of #130 with test and docs; it seems that effort stalled. i've rebased @lachenmayer's branch on top of latest master and dealt with conflicts, this should merge cleanly. most critically, it does not rely on url embedded identities (aka  thanks to @lachenmayer for the initial effort, and @mzabriskie for the lovely axios. ", "commit_messages": " add http basic authentication.  add http basic authentication for node.  documenting the http basic auth request config  abandoning url embedded identities for basic auth  use an authorization header instead, which is a safer choice than url embedded identities (aka  added documentation note about how this will overwrite any existing authorization header that the user may have set.  [chromium128323]:  adding tests for basic auth ", "linked_issue_titles": " support for basic authentication on xmlhttprequest.open() ? ", "title": "add support for http basic auth via authorization header"}
{"description": " the c# interpreter requires the seconds parameter to be included, so if one has a raw duration of 13:45, one must append ':00' for the constructor to recognize the duration (input[type=\"time\"] produces such raw durations). this pr solves that problem. ", "commit_messages": " added tests for 24-hour time support.  added 24-hour time support.  converted to spaces  changed tests to test greater than 24 hour timestamps  * feature/24-hour-time:  changed tests to test greater than 24 hour timestamps  converted to spaces  added 24-hour time support.  added tests for 24-hour time support. ", "linked_issue_titles": "", "title": "support constructing durations from timestamps that do not include seconds"}
{"description": " this pr adds selectedtextstyle and unselectedtextstyle parameters to the bottomnavigationbar class. these parameters provide two main benefits to users of bottomnavigationbar: further customization of the fonts in a bottomnavigationbar. having a generic textstyle allows for more than just fontsize to animate. for example, textstyle.fontweight or textstyle.fontstyle can animate. also, selectedtextstyle and unselectedtextstyle provide a convenient way to customize the fontfamily of the text in a bottom nav. previously, this was only possible by supplying a textstyle directly to all of the individual text widgets passed to bottomnavigationbaritem. selectedtextstyle and unselectedtextstyle parameters will allow for the textstyles to be customized in bottomnavigationbartheme, when it is created. this pr also adds selectedicontheme and unselectedicontheme. these params now make bottom navigation bars much more customizable: related issues n/a i added the following tests: selectedtextstyle and unselectedtextstyle are honored in the bottomnavigationbar. the selectedtextstyle.fontsize and unselectedtextstyle.fontsize take precedence over selectedfontsize and unselectedfontsize. the selectedtextstyle.color and unselectedtextstyle.color take precedence over selecteditemcolor and unselecteditemcolor. the selectedicontheme.color and unselectedicontheme.color take precedence over selecteditemcolor and unselecteditemcolor. the selectedicontheme.size and unselectedicontheme.size take precedence over iconsize. tests for making sure that the padding on the nav bar items is calculated correctly when all labels are shown, just selected labels are shown, and when no labels are shown. alternatives considered since selectedfontsize and unselectedfontsize already exist as parameters, it brings up the question of what to do when both selectedtextstyle.fontsize and selectedfontsize are provided. there are three options i considered: keep both parameters, but prefer selectedtextstyle.fontsize if it is provided, since providing the entire textstyle is more specific. keep both parameters, but throw an assert saying that font size should not be provided on both selectedtextstyle and selectedfontsize. deprecate and remove selectedfontsize, since it is now achievable through selectedfontstyle.fontsize. i opted for option 1, because it is non-breaking and is inline with some existing components. for example, in tabbars, you could provide both indicatorcolor and an indicator with it's own color, and the custom indicators color will be used. if we think that having both will serve as unnecessary complication, or that it will be unclear to users which to use, i can deprecate/remove selectedfontsize and unselectedfontsize in the future. it would require a breaking change, but it may be worth it. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " add tests  add tests  remove extra space ", "linked_issue_titles": "", "title": "selected/unselected label styles + icon themes on bottomnavigationbar"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration this is an odd situation where the npm package and the name of the modules consumers import do not align. these types align with the module names create it with dts-gen --dt, not by basing it on an existing project. does not apply in this case tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. cc: @dwickern @jamescdavis @dfreeman @chriskrycho fixes typed-ember/ember-cli-typescript#264 ", "commit_messages": " [ember] failing test - relax observermethod property name arg  [ember] relax observermethod property name arg  [ember] @ember/component types refactored into their own package ", "linked_issue_titles": "", "title": "refactor @ember/component types into their own package"}
{"description": " fix bug/typo in previous pr #9931 add unit test for new feature dropout with axes (variational dropout) passed code style checking (make lint) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change dropout operator with axes, unit tests ", "commit_messages": " fix bug  add test for dropout with axes ", "linked_issue_titles": "", "title": "fix bug for dropout with axes, also adding unit test"}
{"description": " upgrade actions/cache to the latest upgrade actions/setup-python disable cache for npm and pip since they don't seem to help much enable parallelization for cypress tests (need to configure record key) here is an example of a successful run when the record key is properly configured. n/a test plan make sure ci passes requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " upgrade cache action and disable cache  always upgrade pip itself  re-cache and clean up  fix hash key; enable parallel for cypress  disable npm and pip cache  export cypress env variables  update build id  reformat and update  longer wait  longer sha  move nonce out  disable parallelization for now ", "linked_issue_titles": "", "title": "optimize github actions for building speed and stability"}
{"description": " xgboost is a gradient boosting library. it's one of the most popular gb libraries used among kaggle users because it's yielded some of the highest scores. and its also a favorite with some of the champions. here's an example of its use with an otto dataset:  here is a kaggle first place team winner, showing their love for it:  this library is solely for gradient boosting. this resolves issue #821. anyone who agrees with this pull request could vote for it by adding a  to it, and usually, the maintainer will merge it when votes reach 20. ", "commit_messages": " resolve issue #821  added xgboost library  resolved issue #821  included period at the end ", "linked_issue_titles": "", "title": "xgboost is a kaggle favorite!"}
{"description": " increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add {loadnewmodules, modules} to angular.auto.iinjectorservice  add {loadnewmodules, modules} to angular.auto.iinjectorservice  allow for annotated functions in .loadnewmodules() ", "linked_issue_titles": "", "title": "add types for $injector.{loadnewmodules, modules} to types/angular"}
{"description": " an implementation of 3 variants of search function on trie. a simple search determining if the word exists in the trie. a suggestions search which suggests all possible words in trie which share the longest prefix with the search key. and a frequency based suggestions search, which suggests top3 most frequently searched words in trie which shares the longest prefix with search key. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines notes: 3 variants of search explicitly defined, to be performed on trie. explicitly defined so people can refer/use them directly. ", "commit_messages": " trie with 3 types of search  trie with 3 types of search and all basic operations  updating directory.md  docs: added main function documentation ", "linked_issue_titles": "", "title": "multiple variants of search on trie"}
{"description": " hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! add thai java book for students basic java programming with data structure & algorithm book for students. they include all basic data structure & algorithm written in java it's produced by thai university. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " update free-programming-books-th.md  fixed order & added more info ", "linked_issue_titles": "", "title": "update free-programming-books-th.md with java programming book"}
{"description": " currently when you use the query builder on eloquent models you end up with an instance of the query builder, thus calling find uses the hard-coded id instead of the key defined on the model. see issue #1476. this pr removes the find method from the model itself and instead defines it on the query class. you can now do things like this. $order = order::where('seller_id', '=', $seller_id)->find($order_id); ", "commit_messages": " add the find method to the eloquent query class.  find no longer needs to be defined on the model since the query catches it correctly. ", "linked_issue_titles": "", "title": "allow find to be called anywhere on an eloquent model"}
{"description": " this pr changes the colors of all the elements in the edit keyboard and edit shortcuts windows to default as per the os theme. the theme does not change when the powertoys settings theme is changed. light theme dark theme pr checklist applies to #6 cla signed. if not, go over here and sign the cla detailed description of the pull request / additional comments background and foreground properties removed for all the controls. by removing that, the control using the default winui colors, which follow the selected os theme. requesttheme(light) was removed since that will only give colors for the light theme. the two places where we manually set the color had to be adjusted: for the keys in the type key and type shortcut ui, we were using the border xaml control with gray background. this was changes to the systembaselowcolor theme resource (which matches the same color in light theme and had a corresponding dark theme variant as well). this does not get refreshed when the os theme is changed, however the moment another key is clicked the correct color is loaded. for the hold enter to exit animation, we were changing the ok button to dark gray. this was changed to systembasemediumlowcolor. windows::ui::xaml::application::current().resources().lookup(box_value(l\"systemcontrolbackgroundbaselowbrush\")).as<windows::ui::xaml::media::solidcolorbrush>() is the code equivalent of {themeresource systemcontrolbackgroundbaselowbrush} in xaml. ", "commit_messages": " fixed colors for edit keyboard  fixed colors for edit shortcuts ", "linked_issue_titles": "", "title": "fix colors in kbm ui and add support for light/dark theme"}
{"description": " a function is added in generator_helpers.h for other wrapped languages. the detached leading comments and leading comments are put together separated by blank lines. the method comments are added to both stubinterface methods and service methods. a test is added, which also illustrated not all things are returned by the protobuf library, namely file level comments are all ignored service trailing comments are taken from one non-blank line below service (methoda1 detached comment) ", "commit_messages": " add comments to the generated header file  add a test ", "linked_issue_titles": "", "title": "put proto file comments to generated grpc header file."}
{"description": " added the time_series_metric mapping parameter to the unsigned_long and scaled_float field types added the time_series_dimension mapping parameter to the unsigned_long field type fixes #78100 relates to #76766,  #74450 and #74014 ", "commit_messages": " added time_series mapping params to unsigned_long  added time_series mapping params to scaled_float ", "linked_issue_titles": " can't use `time_series_metric` mapping parameter with `scaled_float` or `unsigned_long` fields ", "title": "add time series params to unsigned_long and scaled_float"}
{"description": " fixes #3726 (\"replaced task in chain causes chain to skip to last link\"). updates the task.replace() method to copy the replaced task's chain in the correct order. (was copying the chain backwards.) updates integration test of complex chaining to reproduce the issue and pass. ", "commit_messages": " add add_replaced test task  make test_complex_chain fail by adding a replaced task  - update expected output  copy replaced task's request chain in reverse  - make t/integration/test_canvas.py::test_chain::test_complex_chain pass ", "linked_issue_titles": "", "title": "fix #3726 - chaining of replaced tasks"}
{"description": " hi, i added the config.ru for development and thought others may like it. i think the background image (from subtlepatterns.com) makes the page a little easier on the eyes. i thought a print button might be nice, and the print.css was already there. added an email link too. ", "commit_messages": " added a config.ru for rack/local dev  added subtle background, added email and print links ", "linked_issue_titles": "", "title": "config.ru for dev, sexy background, print and email links"}
{"description": " noticed some typos in the pt-br (brazilian), along with the facts that the slack badge and the last section (self-promotion) are missing. this pr solves both issues. ", "commit_messages": " adding slack badge, correcting typos and adding \"self-promote\" section  removing unused text ", "linked_issue_titles": "", "title": "fix and adequate pt-br translation"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. ", "commit_messages": " fix:(curriculum): rename rdbms cert project  fix: some more spots to rename  fix: rename i18n's ", "linked_issue_titles": "", "title": "rename rdbms cert project to proper name"}
{"description": " fixes the docstring for encode_plus. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case. documentation guidelines, and here are tips on formatting docstrings. @sgugger or anyone really. ", "commit_messages": " fix docstring for 'special_tokens_mask'  revert auto formatter changes  revert another auto format  revert another auto format ", "linked_issue_titles": "", "title": "fix 'encode_plus' docstring for 'special_tokens_mask' (0s and 1s were reversed)"}
{"description": " fa45c44 original pr #43432 ", "commit_messages": " update openstack inventory script to keep basic functionality (#43432)  re-applies commit 6667ec447466abf1641787afccf9175369319d1f which  fixed the plugin to the script so that it will work with current  ansible-inventory.  also redirect stdout before dumping the ouptput, because not doing  so will cause json parse errors in some cases.  (cherry picked from commit fa45c44026ed471714d0383fd2731911d16a1271)  fixed the plugin to the script so that it will work with current ", "linked_issue_titles": "", "title": "update openstack inventory script to keep basic functionality backport/2.6/43432"}
{"description": " non-unique index support clarified #3092 fix assigning a new index to a duplicate index in a dataframe would fail #3468 fix construction of a dataframe with a duplicate index ref_locs support to allow duplicative indices across dtypes, allows iget support to always find the index (even across dtypes) #2194 applymap on a dataframe with a non-unique index now works (removed warning) #2786, and fix #3230 fix to_csv to handle non-unique columns #3495 modification to cache_readonly to allow you to pass an argument (allow_setting), to 'set' this value (useful in order to avoid a computation you know to be true, e.g. is_unique = true for a default index partially fixes #3468 this would previously raise (same dtype assignment to a non-multi dtype frame with dup indicies) in [6]: df = dataframe([[1,2]], columns=['a','a']) in [7]: df.columns = ['a','a.1'] in [8]: df out[8]: a  a.1 0  1    2 construction of a multi-dtype frame with a dup index (#2194) is fixed in [18]: dataframe([[1,2,1.,2.,3.,'foo','bar']], columns=list('aaaaaaa')) out[18]: a  a  a  a  a    a    a 0  1  2  1  2  3  foo  bar this was also previously would raise in [3]: df_float  = dataframe(np.random.randn(10, 3),dtype='float64') in [4]: df_int    = dataframe(np.random.randn(10, 3),dtype='int64') in [5]: df_bool   = dataframe(true,index=df_float.index,columns=df_float.columns) in [6]: df_object = dataframe('foo',index=df_float.index,columns=df_float.columns) in [7]: df_dt     = dataframe(timestamp('20010101'),index=df_float.index,columns=df_float.columns) in [9]: df        = pan.concat([ df_float, df_int, df_bool, df_object, df_dt ], axis=1) in [14]: cols = [] in [15]: for i in range(5): ....:     cols.extend([0,1,2]) ....: in [16]: df.columns = cols in [17]: df out[17]: 0         1         2  0  1  2     0     1     2    0    1    2                   0                   1                   2 0  0.586610  0.369944  1.341337  1  1  1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 1 -1.944284 -0.813987  0.061306  0  0  1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 2 -1.688694  1.644802  0.659083  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 3  1.422893  0.712382  0.749263 -1  0 -1  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 4 -0.453802  0.228886 -0.339753  2  0 -2  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 5 -0.189643  1.309407 -0.386121  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 6  0.455658  0.822050 -0.741014  0  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 7 -0.484678 -1.089146  0.774849  0  1  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 8  0.720365  1.696400 -0.604040 -1  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 9 -0.344480  0.886489  0.274428  1  0  0  true  true  true  foo  foo  foo 2001-01-01 00:00:00 2001-01-01 00:00:00 2001-01-01 00:00:00 for those of you interested.....here is the new ref_loc indexer for duplicate columns its by necessity a block oriented indexer, returns the column map (by column number) to a tuple of the block and the index in the block, only created when needed (e.g. when trying to get a column via iget and the index is non-unique, and the results are cached), this is #3092 in [1]: df = pd.dataframe(np.random.randn(8,4),columns=['a']*4) in [2]: df._data.blocks out[2]: [floatblock: [a, a, a, a], 4 x 8, dtype float64] in [3]: df._data.blocks[0]._ref_locs in [4]: df._data._set_ref_locs() out[4]: array([(floatblock: [a, a, a, a], 4 x 8, dtype float64, 0), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 1), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 2), (floatblock: [a, a, a, a], 4 x 8, dtype float64, 3)], dtype=object) fixed the #2786, #3230 bug that caused applymap to not work (we temp worked around by raising a valueerror; removed that check) n [3]: in [3]: df = pd.dataframe(np.random.random((3,4))) in [4]: in [4]: cols = pd.index(['a','a','a','a']) in [5]: in [5]: df.columns = cols in [6]: in [6]: df.applymap(str) out[6]: a                a               a               a 0  0.494204195164   0.534601503195  0.471870025143  0.880092879641 1  0.860369768954  0.0472931994392  0.775532754792  0.822046777859 2  0.478775855962   0.623584943227  0.932012693593  0.739502590395 finally, to_csv writing has been fixed to use a single column mapper (which is derived from the ref_locs if the index is non-unique or the column numbering if it is unique) ", "commit_messages": " bug: gh3468 fix assigning a new index to a duplicate index in a dataframe would fail  enh: support for having duplicative indices across blocks (dtypes)  bug: fix construction of a dataframe with duplicative indices  bug: enabled applymap to work (and updated internals/convert to use iget) when  using a non-unique index (gh2786 for the warning and gh3230 for applymap)  tst: test for gh2194 (which is fixed)  bug: gh3495 change core/format/csvformatter.save to allow generic way of dealing  with columns duplicate or not ", "linked_issue_titles": " enable applymap for dataframes with duplicate columns  pandas inconsistenly handles identically named columns in csv export and merging ", "title": "allow the blockmanager to have a non-unique items (axis 0)"}
{"description": " multi-line comments in typescript aren't aligning properly. they should follow the tslint rule jsdoc-format. this pr adds some failing tests for the issue. i can also try to take a crack at fixing it fixes #648. ", "commit_messages": " fix typescript comment snapshot  add failing test for typescript method comments ", "linked_issue_titles": " re-indent comments ", "title": "fix indentation for jsdoc comments"}
{"description": " generating jsb_cocos2dx_extension_auto.hpp/.cpp. it was separated from original cocos2dx.hpp/cpp.  developer could remove redundant jsbinding native codes now. cocos2dx.hpp/cpp ~> jsb_cocos2dx_auto.hpp/cpp adding jsb_cocos2dx_extension_manual.hpp/cpp ", "commit_messages": " fixed #1748: generating jsb_cocos2dx_extension_auto.hpp/.cpp. it was separated from original cocos2dx.hpp/cpp.  developer could remove redundant jsbinding codes now.  updating the submodule of  cocos2d-js-tests.  updating the submodule reference of js tests.  fixed #1748: updating win32 project setting. ", "linked_issue_titles": "", "title": "separating js extension from cocos2dx.hpp/cpp."}
{"description": " add default network timeout values to the networking troubleshooting guide. fixes #41826 docs.ansible.com ", "commit_messages": " add toc and default timeout values  make options more obvious ", "linked_issue_titles": " ansible network automation timeout values for command_timeout, connect_timeout and retry_timeout are not provided in documentation ", "title": "add default network timeout values to network troubleshooting guide"}
{"description": " description: changes for issue #2751 caused that certain code paths were not evaluated during coverage run. this change allows running coverage test with \"trace\" log level and dropping all log messages to avoid cluttering stderr/out. running at \"trace\" level evaluates all code paths. risk level: low. testing: executed several unit tests to check if log level is lowered to trace and logs are dropped. docs changes: no. release notes: no. fixes: #3012 ", "commit_messages": " modified test environment setup. if --log-path command line option is  specified a fake file sink is allocated and all logs are dumpoed there.  removed trailing _ from local variables.  removed inaccurate log-level command line arg description. ", "linked_issue_titles": "", "title": "lower log level to trace and drop all logs"}
{"description": " restoring from a snapshot (which is a particular form of recovery) does not currently take recovery throttling into account (i.e. the indices.recovery.max_bytes_per_sec setting). while restores are subject to their own throttling (repository setting max_restore_bytes_per_sec), this repository setting does not allow for values to be configured differently on a per-node basis. as restores are very similar in nature to peer recoveries (streaming bytes to the node), it makes sense to configure throttling in a single place. the max_restore_bytes_per_sec setting is also changed to default to unlimited now, whereas previously it was set to  40mb, which is the current default of indices.recovery.max_bytes_per_sec). this means that no behavioral change will be observed by clusters where the recovery and restore settings were not adapted. relates #57023 ", "commit_messages": " use recovery settings for restore  add docs  default max_restore_bytes_per_sec to unlimited ", "linked_issue_titles": "", "title": "account for recovery throttling when restoring snapshot"}
{"description": " cherry picked from (25f485f) backport for pr #54419 nios ", "commit_messages": " update nios_member.py (#54419)  * update nios_member.py  * update api.py  * update nios_member.py  * update nios_member.py  * update api.py  (cherry picked from commit 25f485f79db3aaff53bd649790297452739cef30)  nios_member param fix ", "linked_issue_titles": "", "title": "backport to fix nios member module param bug fix"}
{"description": " resolve #7600 resolve #7601 ", "commit_messages": " add python wrapper for matmul_op  add python wrapper for matmul_op and dot_product_attention  add dot_product_attention to nets.__all__ ", "linked_issue_titles": " need python wrapper for matmul_op  need python wrapper for dot-product-attention ", "title": "add python wrapper for dot-product-attention"}
{"description": " capture a weak reference to the instance in the websocket resource's callback lambda and bail if it's not available. microsoft reviewers: open in codeflow ", "commit_messages": " make ws callbacks capture weak instance instead of strong instance pointer  change files ", "linked_issue_titles": "", "title": "prevent reference cycles between websocketmodule and react instance."}
{"description": " followup of #40 and with added localization support the makefile does the .po to .mo part that the shell scripts used to do. ", "commit_messages": " much simpler, pure-python packaging  simple building and packaging of i18n ", "linked_issue_titles": "", "title": "much simpler, pure-python packaging + i18n"}
{"description": " this adds a link to training t5 in tensoflow 2 community notebook under the notebooks/readme.md community notebook section. this notebook demonstrates how to train t5 for any task using tensorflow 2. trains a question & answer task implemented in tensorflow 2 using squad this pr fixes a typo or improves the docs (you can dimiss the other checks if that's the case). yes did you read the contributor guideline, pull request section? yes was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case. forum link documentation guidelines, and here are tips on formatting docstrings. not applicable did you write any new necessary tests?  not applicable @patrickvonplaten @jplu ", "commit_messages": " t5 t5 community notebook added  author link updated  t5 t5 community notebook added  author link updated ", "linked_issue_titles": "", "title": "train t5 in tensoflow 2 community notebook"}
{"description": " hi everyone, this is a significative pull request in skywalking 6. i propose the new header protocol v2, now it is the time to implement it. if you miss the last one, see v2 protocol. several things you need to pay attention base64 for trace id, segment id, host, entry op name, and parent op name entry op name and parent op name are optional in contextcarrier and contextsnapshot @liuhaoyang .net core @ascrutae nodejs need to follow this protocol, after this is merged. also v1 is still supported in receiving sw3 header, but you need to active v1 header manually in order to let the agent send sw3 header. in default, sw3/sw6 headers could be received, sw6 sent only. ", "commit_messages": " add some supports to sw6 header. break many test cases because i turn sw3 default off. for sure, you could open in agent.conf.  fyi @peng-yongsheng @ascrutae  fix ci and make user cases still work under v1 header.  merge commit '513c1b86c6d86b981bf9e5c09c0d041d6c2d624e' into sw6-header  support base64 in v2 header and make entryoperationname and parentoperationname optional in contextcarrier or contextsnapshot ", "linked_issue_titles": "", "title": "new v2 header with header key sw6"}
{"description": " it was becoming quite annoying to have to open the shell each time i wanted to execute a file, so i did this. this can be made to also run shell scripts and the sort (application/x-shellscript is different from text/x-shellscript), but i'm still not sure about it. a more elegant way of doing this would be to just create a separate plugin which would handle running things from within nnn, and then binding that to a key (like how e is bound to open in editor) or possibly have nuke use it as an opener like it does mocq. ", "commit_messages": " added execute fallback to nuke  fixed syntax error  merge local with remote ", "linked_issue_titles": "", "title": "pseudo-ability to run binary files for nuke"}
{"description": " this adds two trends options to the release's transaction list, trending regressions & trending improvements clicking the transaction name will bring you to the transaction's summary view with the trend display mode already selected this also adds that when clicking on releases in trends, the transactions list will already be on the related list ", "commit_messages": " feat(perf): add transactions list to release details  the current release details page does not show any information regarding the  transactions associated with this release. this change adds a transactions list  on to the release details page. this transactions list will show a list of  transactions along with their failure rate, throughput, and p50 duration.  wip: got the table to show trend data  - still have to render percentage correctly  - probably going to refactor the transactions list even more to take  trends more naturally  wip: got it functional with the dropdown  todo still have to get the link working properly  fix: updating link to summary, updating trend queries ", "linked_issue_titles": "", "title": "adding trends to the transaction list"}
{"description": " relative paths in gradle break when the gradle daemon is used unless user.dir can be changed while the process is running. java 11 disallows this, so we use project paths instead. verified that rat and checkstyle work with java 11 after these ", "commit_messages": " rat plugin should not rely on working directory  it breaks when used with the gradle daemon and  java 11.  don't use relative paths in checkstyle config  they break under java 11 ", "linked_issue_titles": "", "title": "fix rat and checkstyle config for java 11 support"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " cytoscape: join layout options declarations  cytoscape: layout events with layouteventobject as parameter  cytoscape: add type to cy property in abstracteventobject  cytoscape: add myself to the 'definitions by' ", "linked_issue_titles": "", "title": "add missing callback parameter and adjust property type"}
{"description": " currently the run-windows command appears to hang for a long period of time while its building, and its not obvious that anything is happening. this change adds some progress ui to the command so that its easier to see whats going on. microsoft reviewers: open in codeflow ", "commit_messages": " improve output of run-windows command  change files ", "linked_issue_titles": "", "title": "improve ui of run-windows command"}
{"description": " shard level request cache is improved to work correctly at all time. also ensure profiling and suggester are properly disabled when not supported. ", "commit_messages": " add tests  attempt to fix  fix implementation  fix suggester and profiling ", "linked_issue_titles": "", "title": "improve shard level request cache efficiency (#69505)"}
{"description": " fix #819  the smoke test should no longer hang after this fix #679 this will users debug why the smoke test process could hang we now kill smoketest after 10s using execa's timeout feature print an error message that the command timed out along with stderr (or stdout) review tasks: remove promise cancellation ", "commit_messages": " temp 04/29/19 [skip ci] cli verify timeout  add smoke test timeout error and tests ", "linked_issue_titles": " add timeout to verify command  cypress hangs on verify step ", "title": "add timeout for cli/verify smoke test"}
{"description": " fix higher-order array functions (sigsegv for arraycompact/illegal_column for arraydifference/arraycumsumnonnegative) with consts detailed description / documentation draft: ci: ", "commit_messages": " fix sigsegv for arraycompact() with consts  arraycompact() implements usedefaultimplementationforconstants() but it  is a no-op for functionarraymapped, fix this.  ci report [1]:  [1]:  fix arraydifference() for consts  fix arraycumsumnonnegative() for consts ", "linked_issue_titles": "", "title": "fix higher-order array functions (arraycompact/arraydifference/arraycumsumnonnegative) with consts"}
{"description": " fixes #12546. pinging @westy92, @yuit, @vvakame, @bonnici, @codeanimal ", "commit_messages": " decomposed 'winston' into a var/namespace/type so it can export a member named 'default'.  fixed 'winston' to expose a member named 'default'.  added a test for the default logger in 'winston'. ", "linked_issue_titles": "", "title": "expose 'default' member on winston"}
{"description": " this rfc is about how to evolve grammars and syntax themes so that their design goals don't get in each others' way. i am utterly certain that a maximum of four people on earth will care about this, but i'd love to find out i'm wrong. hopefully some discussion can help refine exactly what is being proposed here. rendered version. view rendered docs/rfcs/005-scope-naming.md ", "commit_messages": " add rfc about how to evaluate proposed scope additions to grammars.  give the rfc a title.  fix typos. ", "linked_issue_titles": "", "title": "evaluating scope name additions to built-in grammars"}
{"description": " continues the work in #17535 $ git grep --name-only \"swift-version 3\" | grep -ev 'compatibility/' | wc -l > 238 after $ git grep --name-only \"swift-version 3\" | grep -ev 'compatibility/' | wc -l > 158 ", "commit_messages": " migrate some stdlib tests to swift 4  migrate sil parser tests  migrate serialization tests to swift 4  migrate sil serialization tests to swift 4  migrate interpreter tests  migrate parse and namebinding tests  miscellaneous test migrations ", "linked_issue_titles": "", "title": "migrate more tests to swift 4"}
{"description": " the pr is another solution to fix #11974 .  i believe that it is better than #12127 . what changes were proposed in this pull request? make dimension to be compatible with integer, so [1, dimension(2)] will be casted to [1, 2] automatically. how was this patch tested? add a doctest. add an unit test. pass all unit tests. ", "commit_messages": " bug: make dimension compatible with integer  tst: add doctest  bug: resolve circle import ", "linked_issue_titles": " tf.reshape does not accept dimension objects for the shape parameter ", "title": "make dimension be compatible with integer"}
{"description": " this should fix the warning messages that we get around the usage of strtok_r (). how to use it correctly: see  see  thanks ", "commit_messages": " our usage of strtok_r () was not totally correct (but almost)  also double-check input/output of strtok_r () ", "linked_issue_titles": "", "title": "fix our usage of strtok_r (), it was not 100% correct"}
{"description": " cherry-pick of #37380 explanation: with se-0293, closure parameters can use the $ prefix to have a property wrapper type inferred from context. however, when a closure is resolved, the contextual parameter type doesn't always exist. this happens most commonly when the solver is attempting an overload where the contextual type for the closure isn't a function type (e.g. a concrete nominal type, or a type parameter). the implementation was assuming the contextual parameter type always existed, resulting in a crash in the constraint system when attempting to bind to a null type.  the solution is to simply create a type variable for the property wrapper type if the contextual parameter type doesn't exist. scope: this only affects the new $ syntax on closure parameters. risk: very low. testing: added several tests covering a variety of cases where a contextual type for a closure parameter doesn't exist. reviewer: @xedin resolves: rdar://77793820 ", "commit_messages": " [constraintsystem] if the contextual parameter type doesn't exist when  resolving a closure, create a new type variable for inferred property  wrapper types.  [diagnostics] always use the parameter name for closure parameter diagnostics,  because the $ prefix does not indicate that the parameter is anonymous. ", "linked_issue_titles": "", "title": "fix a constraint system crash with property wrapper inference using the $ syntax."}
{"description": " this patch replaces gui::widget::find_descendant_by_name with core::object::find_descendant_of_type_named. elephant in the room, this patch enables rtti for userspace programs. some quick measurements showed that this is a small binary size increase, on the order of 3% for a class-rich library like libgui.so. this pr is an alternative to #4708, which does the ak::traits thing to do the rtti manually. which, is kind of awkward and really annoying to have to copy paste the \"opt-me-in to rtti\" macro into every header under the sun. i'm not sold on the name of the core::object helper, so lemme know if there's a better one. everyone loves a good naming thread. ", "commit_messages": " meta: enable rtti for userspace programs  rtti is still disabled for the kernel, and for the dynamic loader. this  allows for much less awkward navigation of class heirarchies in libcore,  libgui, libweb, and libjs (eventually). measured rootfs size increase  was < 1%, and libgui.so binary size was ~3.3%. the small binary size  increase here seems worth it :^)  libcore: add typed find_child and find_descendant helpers to object  these look a lot like the parallel functionality in gui::widget :).  these use dynamic_cast now, to make use of that rtti we just added.  applications+libgui: convert all gml consumers to use the libcore finder  remove widget::find_child_by_name and widget::find_descendant_by_name,  and convert all users to using the type-safer version in core::object. ", "linked_issue_titles": "", "title": "type safe widget gml usage, with rtti"}
{"description": " also ensures inferred and auto import projects have name per project service so they are same across any type of runs this is the pr i had started as part of #41004 and is partially done but nothing wrong with merging this without converting many more tests to baselines. that can be done as and when needed. ", "commit_messages": " tests to baseline tsserver instead of checking  also ensures inferred and auto import projects have name per project service  log structureisreused value ", "linked_issue_titles": "", "title": "tsserver tests can be baselined"}
{"description": " fixed #253 and a bunch of related issues. here now common modules loads once using the webpack's commonschunkplugin. still, we use next.js module loading system and ssr features. as a result of this, we don't need to worry about loading the next-bundle and even creating it. ", "commit_messages": " add example app which demonstrate the problem.  add the first working version.  fix lint issues.  add readme.md ", "linked_issue_titles": "", "title": "add support for webpack's commonschunkplugin and remove next bundle"}
{"description": " xref #28792 as requested in #32823 creating separate pr. also all descriptions for methods starts with upper case and it looks a little out of place. should it be casted to lowercase perhaps? ", "commit_messages": " doc: partial fix sa04 errors in docstrings #28792  black formatting ", "linked_issue_titles": "", "title": "change doc template to fix sa04 errors in docstrings #28792"}
{"description": " original pull-request #21533 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " podarray left pad not multiple of element crash fix  updated style check  cleanup podarray  remove unused method  fix error (found by @kitaisreal)  fixed podarray  pod array left pad not multiple of element crash fix  cleanup podarray ", "linked_issue_titles": "", "title": "cherry pick #21533 to 20.8: cleanup podarray"}
{"description": " re-apply #29289 with a fix for msvc that makes anyrequestbase subclasses be friends with all specializations of it, and defines getrawstorage in the base class to make it accessible to friend top-level functions. ", "commit_messages": " revert \"revert \"don't heap allocate for active requests\"\"  f8a1ad22e1c5b93d39c6483b0c8ed551a5c7ee17  [ast] fix friendship with anyrequestbase  this was causing issues with msvc. have subclasses  be friends with all specializations of  anyrequestbase, and define getrawstorage in  the base class to make it accessible to friend  top-level functions. ", "linked_issue_titles": "", "title": "re-apply \"don't heap allocate for active requests\""}
{"description": " clojure api docs for the website please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change start of api docs markdown pages for the clojure package minor tweaks to add rm viz example checked in by mistake and other slight wording tweaks the website changes are not linked in so even if the pr is merged it won't be visible yet. ", "commit_messages": " rm visualization example output checked in by mistake  add kovas to special thanks  fix up tutorial example with right namespaces  - get rid of getting started since it shows up in codox docs  start on clojure api docs  tweaks in wording  tie in building of clojure docs ", "linked_issue_titles": "", "title": "clojure package api docs for the website"}
{"description": " the fix for bmfontconfiguration::parseconfigfile reads string file. 'strchr' finds a char until it gets a '\\0' or the char to find, if 'contents' self doesn't end with '\\0', 'strchr' will search '\\n' out of 'contents' 's buffer size, it will trigger potential and random crashes since linelength may bigger than 512 and 'memcpy(line, contents + parsecount, linelength);' will cause stack buffer overflow. const data -> const data& for function argument, performance improvement. removes unused code in material::initwithfile. refactor ccbundle3d, remove wrong use of getdatafromfile. _jsonbuffer is std::string, _binarybuffer is data instance now. spritetest fix image is ref class, please new & release it. don't allocate it on stack. fixes complicated logic of getting string from file. ", "commit_messages": " the fix for bmfontconfiguration::parseconfigfile reads string file.  'strchr' finds a char until it gets a '\\0', if 'contents' self doesn't end with '\\0',  'strchr' will search '\\n' out of 'contents' 's buffer size, it will trigger potential and random crashes since  linelength may bigger than 512 and 'memcpy(line, contents + parsecount, linelength);' will cause stack buffer overflow.  const data -> const data& for function argument, performance improvement.  removes unused code in material::initwithfile.  refactor ccbundle3d, remove wrong use of getdatafromfile. _jsonbuffer is std::string, _binarybuffer is data instance now.  spritetest fix  * image is ref class, please new & release it. don't allocate it on stack.  * fixes complicated logic of getting string from file. ", "linked_issue_titles": "", "title": "some important fixes for file reading, may cause stack overflow"}
{"description": " i did more extensive testing on the export and realised that i could not rely on the format used by the original xml export as much as i had hoped since it did locale dependent formating in order to be more human readable. i've added dbunit-compatible formating and verified the corresponding java classes mapping. ", "commit_messages": " added missing tag ending  use dbunit output formats  use internal output format for different datatypes instead of relying on  format used by dataexporterxml ", "linked_issue_titles": "", "title": "support for export in dbunit dataset format - improved formating"}
{"description": " start integration of the first available nightly build before 0.63. this build has some interesting stuff like c++ version stamping, platformcolor, import fixes. fixes #3990 microsoft reviewers: open in codeflow ", "commit_messages": " allow override tooling to use nightly builds  fixes #4857  teach the tooling about the pattern and make sure we can validate against 0.0.0-56cf99a96 (the earliest nightly build). we cannot do a lazy fetch against a shortned commit hash, so we need to get a bit \"creative\" here.  we make a couple other improvements here:  1. change fetch depth to 1 to pull in less history. this reduces the scratch repo size from 174mb to 34mb when fetching just 0.62.2 (which is already much less than the 500mb for cloning entire remote)  2. don't add remotes to the scratch git repo and instead fetch using the url. we've seen transient errors where simplegit thinks we don't yet have a repo set up and adds a duplicate remote. this should hopefully fix that.  change files  reduce unneeded fetches  begin integration of 3/22 nightly build  change files  new specs  do auto upgrades (limited success here)  begin manual merging + nativeordynamiccolor deletion ", "linked_issue_titles": " remove nativeordynamiccolor related patches when platformcolor is available  platformconstants cannot determine correct patch and prerelease version  react patching due to upstream bypassing metro platform checks  rename rctimage to rctimageview in devmain  forking of scrollview to prevent crash from duplicate rctscrollview registration  upgrade to a facebook master build  image.onload event's source.url is now source.uri ", "title": "integrate of 3/22 nightly build"}
{"description": " it is possible and in some cases likely that we will try to sync reversible blocks that we already know about.  this pr is to handle those cases. select one: select any that apply: ", "commit_messages": " fix uncaught exception  added handling of duplicate reversible blocks ", "linked_issue_titles": "", "title": "added handling of duplicate reversible blocks."}
{"description": " i have followed (at least) the pr section of the contributing guide. closes #14203 before when using the variant prop to change the input of select nothing happens. after now when setting a value for variant like outlined the input will change based on this value, check the code bellow: <select value={values.age} onchange={handlechange} variant=\"outlined\" labelwidth={labelwidth} inputprops={{ name: 'age', id: 'outlined-age-simple' }} > output: ", "commit_messages": " change variant prop to handle defaultinput  add specs ", "linked_issue_titles": " select doesn't support variant=\"outlined\" ", "title": "changes the default input based on variant prop"}
{"description": " commit message: fixes oss crash in router fuzz tests due to unimplemented features being tested filteraction filter_action in the route message is not implemented but was being tested, causing an assert to fail in routeentryimplbase::clusterentry risk level: low testing: passed regression test that originally failed on ossfuzz docs changes: n/a release notes: n/a fixes: ", "commit_messages": " fix oss issue  style fix ", "linked_issue_titles": "", "title": "fix ossfuzz crash in router tests"}
{"description": " it turns out that np.ma.masked is actually pretty bad at preserving identity or value this pr attempts to fix that. fixes #9328 and #4595 ", "commit_messages": " enh: make duplicated masked constants obvious  bug: np.ma.masked does not preserve identity through pickle  it's still possible to create duplicate maskedconstants through .copy()  bug: prevent copies of np.ma.maskedconstant from being created by .view.  this seems to solve the problem everywhere. it's not clear if this works on pypy.  fixes gh-9328 ", "linked_issue_titles": " bug: maskedconstant  is mutated despite copying ", "title": "fix various problems with the np.ma.masked constant"}
{"description": " this should fix #3275. ", "commit_messages": " make scheduling queues removetasks return task states as well.  add test  don't unsubscribe for infeasible tasks when spilling over.  linting ", "linked_issue_titles": " test failure in test_object_transfer_dump in runtest.py. ", "title": "don't unsubscribe dependencies for infeasible tasks."}
{"description": " others docs cherry-pick #pr36554 modify the english document, add warning reminder, only used in cuda11.3 and above ", "commit_messages": " fix cusparse compile bug in cuda11.2, test=develop  modify sparse_attention docs, test=document_fix (#36554)  * modify sparse_attention docs, test=develop  * add warning  * add warning ,test=document_fix ", "linked_issue_titles": "", "title": "[cherry-pick]add sparse attention doc warning"}
{"description": " adds fallback routine for when a font name is missing instead of crashing due to uncaught exception thrown when font cannot be found. closes #550 i'm an employee doesn't need documentation i'm a core contributor for gdi and for directx using the stock layouts and formats, if your chosen font face name isn't found... something else is just picked on your behalf. when i wrote our custom dx code, i instead threw an exception when i couldn't find the chosen font face. that exception was uncaught and led to a crash. i decided to just make the custom code act more like the stock code and attempt to choose a fallback if we cannot find what you've requested. i also improved a bit of the passing around of the chosen font name and added locale name information while i was at it. opened settings set font name to \"arse\" watched as nothing changed from previous consolas selection closed application relaunched didn't crash this time, it just chose consolas instead ", "commit_messages": " stop the crash with fonts by trying a few fallback/backup fonts if we can't find what was selected.  create fallback pattern for finding a font. resolve and pass the locale name. retrieve the font name while retrieving the font object. use retrieved data in the _getproposedfont methods instead of re-resolving it. ", "linked_issue_titles": " specifying a font to be used in profile that does not exist causes the app the crash ", "title": "fixes crash when specifying invalid font"}
{"description": " grid browser session priority, first cut at working logic with unit tests. there's more code than necessary, and an abusive amount of commentary, but this should correctly prioritize where sessions go based on browser \"rarity\". still need a code review and some unit tests, but i wanted to put this up for review and feedback. there's plenty to optimize, but i think this does the job. by placing an x in the preceding checkbox, i verify that i have signed the contributor license agreement ", "commit_messages": " adding distributor test  added first functionality for balancing distributor by browser availability  filling out unit test for \"host priority\", still ignored because the feature isn't implemented  interim commit  adding logs and traces to the distributor code  unit test is passing for distributor optimization by browser  adding comments, slight refactors, and setting up for pr ", "linked_issue_titles": "", "title": "selenium 4.0 grid browser priority, first cut"}
{"description": " fixed number of led rgb on rart4x4 and pin matrix on rart45 my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " update config.h  update config.h ", "linked_issue_titles": "", "title": "fix number rgb rart4x4 dan matrix pin rart45"}
{"description": " setemitzone was rejecting custom objects passed as the source argument because it was checking for the wrong methods. i fixed the checks, but i would actually prefer removing them. ", "commit_messages": " correct source checks in setemitzone  correct source types in *zoneconfig definitions  remove source checks in setemitzone ", "linked_issue_titles": "", "title": "fix source checks in particleemitter#setemitzone"}
{"description": " after #9665, this moves the remaining types in posixmodule to be heap-allocated to make it compatible with pep384 as well as modifying all the type accessors to fully make the type opaque. the original pr that got messed up a rebase: #10854. all the issues in that commit have now been addressed since #11661 got committed. this change also removes any state from the data segment and onto the module state itself.  automerge-triggered-by: @encukou ", "commit_messages": " make posixmodule use pytype_fromspec  added news  updated hash  addressed pr issues  rebased  ran argument clinic  added news  remove incref from genericalloc  make posixmodule use pytype_fromspec  added news  updated hash  addressed pr issues  ran argument clinic  added news  merged to master ", "linked_issue_titles": "", "title": "bpo-35381 remove all static state from posixmodule"}
{"description": " i translated readme.md and contributing.md into japanese. saved as readme_jp.md and contributing_jp.md respectively. i hope japanese users will be able to use this project more conveniently. thank you. ", "commit_messages": " create contributing_jp.md  create readme_jp.md ", "linked_issue_titles": "", "title": "created readme and contributing files in japanese"}
{"description": " enables build_test for macos. currently only flutter_gallery has platform directories for the desktop platforms, so this will run only that build, but this will provide an end-to-end build test for macos. once this lands, other example/test projects can be brought online for macos in the future just by adding the macos/ directory to the project. related issues #54295 i added the following tests: build_test for macos before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. ", "commit_messages": " enable dev/bots/ build_tests for desktop  enables build_test for windows, macos, and linux. currently only  flutter_gallery has platform directories for the desktop platforms, so  this will run only that build, but this will provide an end-to-end build  test for all three desktop platforms.  once this lands, other example/test projects can be brought online for  desktop platforms in the future just by adding the relevant platform  directories to the project.  add missing awaits  add config enabling  remove linux  remove windows ", "linked_issue_titles": "", "title": "enable dev/bots/ build_tests for macos"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes. the list is: ", "commit_messages": " improve typing deprecation for dep0010 and dep0011  improve typing deprecation for dep0012 ", "linked_issue_titles": "", "title": "add deprecation messages for dep0010, dep0011 and dep0012"}
{"description": " in the process of organizing these, some parametrization opportunities become clear.  didnt do them in this pr to keep this just a moving-around diff ", "commit_messages": " more frame method tests  test_count  series cov, count, round methods ", "linked_issue_titles": "", "title": "method-specific tests for cov, corr, corrwith, count, round"}
{"description": " fix an issue where arrowvegalitechart react component wasn't being updated after add rows, which caused an unexpected behavior. fix a couple of \"index out of bounds\" issues in arrowvegalitechart component. additional reportnode unit tests. activate metrics for arrow add rows. (totally unrelated, and should have been sent as a separate pr) ", "commit_messages": " fix index out of bounds issue in arrowvegalite  update react component after addrows ", "linked_issue_titles": "", "title": "fix add rows on arrowvegalitechart"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " hooks api  added region for hook events ", "linked_issue_titles": "", "title": "definitions and documentation for hooks api"}
{"description": " in some build modes (certain asyncify flags) we forgot to remove debug info at the very end, if we only needed it in the middle. note that this only affects the names section - function names. we did not have any issues with dwarf, which has explicit stripping code already, and that is heavily tested (as dwarf can be huge) as correct. the fix here is by tracking the reasons why we need interim debug info, and noting when we no longer need it. we can then strip it out at the end, if so. we also stop emitting it as soon as possible, which makes the build slightly more efficient. also, this can avoid running wasm-opt just to strip the debug info if it's already been removed by a previous command, which is potentially a large speedup in a big project in an unoptimized build (as in an optimized one there will be another command that strips it anyhow). to achieve that, this adds tracking of the last command - is there perhaps a nicer way to do it? fixes #14143 ", "commit_messages": " fix #14143  fix  fix flake8  better  fixes  fix  flake8  format  comment ", "linked_issue_titles": " asyncify, shipping build (o3), code bloat and increased memory usage between emscripten versions ", "title": "do not emit intermediate debug info by mistake in the final output"}
{"description": " heron's formula for area of any (valid) triangle. description adding heronarea.js and adding the corresponding entry in tag_database. more info on heron's formula (and why it works) here:  pr type snippets, tests & tags (new snippets, updated snippets, re-tagging of snippets, added/updated tests) scripts & website & meta (anything related to files in the scripts folder, how the repository's automated procedures work and the website) glossary & secondary features (anything related to the glossary, such as new or updated terms or other secondary features) general, typos, misc. & meta (everything else, typos, general stuff and meta files in the repository - e.g. the issue template) guidelines i have read the guidelines in the contributing document. ", "commit_messages": " adding heron's formula for area of a triangle  tagging heron as math, beginner ", "linked_issue_titles": "", "title": "adding heron's formula for area of any triangle"}
{"description": " this pr completes any previously missing pytorch model counterparts to tfmodels in examples/models. it also makes sure, all example scripts in the rllib/examples folder are tested for both frameworks and learn the given task (this is often currently not checked) using a --as-test flag in connection with a --stop-reward. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  wip.  wip.  wip.  wip.  lint.  fixes and lint.  fixes and lint.  fixes and lint.  fixes and lint.  fixes and lint.  fixes and lint.  fix and lint.  fix and lint.  wip.  wip.  wip.  \u0001 conflicts:  \u0001\trllib/examples/batch_norm_model.py  \u0001\trllib/examples/custom_fast_model.py  \u0001\trllib/examples/hierarchical_training.py  \u0001\trllib/examples/multi_agent_cartpole.py  \u0001\trllib/examples/twostep_game.py ", "linked_issue_titles": "", "title": "examples folder restructuring (model examples; final part)."}
{"description": " the current nightly test for ray wheel urls is flaky because sometimes mac wheels take a long time to build, see #19331. this pr retries the urls every 10 minutes until all the urls are available, for up to 120 minutes.  the 120 minute figure comes from the fact that mac wheels sometimes take close to 2 hours to show up in the aws bucket, see e.g.  #19331 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " retry urls every 10 min for 90 minutes  increase cluster timeout to 100min  up retries from 90m to 2 hours ", "linked_issue_titles": "", "title": "retry wheel urls for up to 2h to give time for mac wheels to build"}
{"description": " split out from #68241. this prints the correct effect diff for each line (the before-effect and the after-effect) and makes marginal improvements to the graphviz output for the new dataflow framework including using monospaced font and better line breaking. this will only be useful when #68241 is merged and the graphviz output changes from this: to this: r? @wesleywiser ", "commit_messages": " print after effect in default graphviz formatter  now the line for each statement will show the diff resulting from the  combination of before_statement_effect and statement_effect. it's  still possible to observe each in isolation via  borrowck_graphviz_format = \"two_phase\".  add option to dot::render for monospace font  remove unnecessary allows  don't break first line  use nicer alignment when printing state vectors ", "linked_issue_titles": "", "title": "small graphviz improvements for the new dataflow framework"}
{"description": " resolves #8858 resolves #8916 ", "commit_messages": " fix cmake param in build eosio for all platforms  add caution message to avoid changing eosio_build_location  fix typo in amazon linux 2 manual build instructions  remove pinned instructions for manual builds  rename unpinned build platform files  update index file for manual build platforms  remove unpinned references in build platform files ", "linked_issue_titles": "", "title": "updates to manual build instructions"}
{"description": " description: follows the general trend of moving things into components with config flow's. related issue (if applicable): fixes # pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> example entry for configuration.yaml (if applicable): weather: - platform: ipma checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " initial version  works  lint  move ", "linked_issue_titles": "", "title": "move weather.ipma into a component"}
{"description": " mostly this was to make sure we're using the final releases of those fbjs versions but looked at other things and cleaned up. ", "commit_messages": " remove jsx task & jsx-internal script  these haven't been used in a long time so it's time to get rid of them.  upgrade fbjs  upgrade browserify ", "linked_issue_titles": "", "title": "upgrade a few package dependencies, remove unused task"}
{"description": " backport of #71580 change: fix up wording and do proper backports for porting guide entries. ", "commit_messages": " [docs] fix up porting guides for cve revert  change:  - fix up wording and do proper backports for porting guide entries.  (cherry picked from commit ed48a2dd624cb7feb874fddcf49ef538857cd3e6)  remove original, non-backported version ", "linked_issue_titles": "", "title": "fix up porting guides for cve revert [2.9]"}
{"description": " only works for unoptimized / uncompressed builds. implements a simplistic lexer that makes some assumptions about the lexed source (as described in comments). this should be much faster than running a full parser. i've separated out the addition of the source-map library as a separate commit, so you can review a cleaner diff by looking at the second commit alone. ", "commit_messages": " commit the source-map library.  implement basic source maps. closes #1252. ", "linked_issue_titles": "", "title": "implement basic source maps. refs #1252."}
{"description": " this pr contains commits that add / update scripts required to setup the rocm community supported build (csb). @gunan , please review the tensorflow/tools/ci_build/linux/rocm/run_csb_tests.sh. it is based on your recommendation of the bazel test command to use, and will be the script we use for our csb. @tatianashp @whchung @parallelo @gunan ", "commit_messages": " adding a script for testing the rocm community supported build  updating that parallel_gpu_execute.sh script such that it works as expected for amd gpus  adding rocm support in the build_pip_package script  adding/updating rocm support in the ci_build scripts ", "linked_issue_titles": "", "title": "script updates for the rocm csb build"}
{"description": " backport of #18618. xref #18601. sub-modules, such as np.linalg, must be explicitly imported in the main namespaces' stub file if one wants to access the sub-module via a getattr operation, i.e. so that one can directly use np.linalg.norm rather than import numpy.linalg; np.linalg.norm. while this was taken care of in the main numpy namespace, the relevant annotations were missing for others such as np.lib.*. this pr fixes aforementioned issue. examples the behavior prior to this pr: >>> import numpy as np >>> x = np.arange(6) >>> out = np.lib.stride_tricks.sliding_window_view(x, 3) mypy output: test.pyi:4:7: error: module has no attribute \"stride_tricks\"  [attr-defined] ", "commit_messages": " api: formally classify np.lib.stride_tricks as part of the public api  with as_strided, and the newly introduced sliding_window_view function, there are currently 2 public objects that can:  a. only be imported from a private module  b. are publicly documented to-be imported from aforementioned module  both observations are problematic and in need of rectification.  this commit therefore moves np.lib.stride_tricks to the public_modules list.  maint: re-export a number of sub-modules  ensures that type checkers will allow the likes of:  >>> import numpy as np  >>> out = np.lib.stride_tricks.sliding_window_view(...)  api: move polynomial.polyutils to the private_but_present_modules list  aforementioned module was accidently marked as public ", "linked_issue_titles": "", "title": "ensure that re-exported sub-modules are properly annotated"}
{"description": " issue: #9507 removed legacy data and apis from story store. updated getstorybook to use _data (hopefully works the same) added migration notes see tests. try some example storybooks. ", "commit_messages": " clean up story store and remove legacy data  fixes #9507  add migration notes about changes ", "linked_issue_titles": "", "title": "remove legacy data from story store"}
{"description": " restricted to only files just needed you can use assetsmanager within javascript. multiple assetsmanagers support. script package / resource package / promotion package / ... ", "commit_messages": " added jsb support for assetsmanager  purgestoragepath added  key with hash to support multiple assetsmanager  delegateprotocol is weak-referenced again  applied cocos2d-x coding style  style edited ", "linked_issue_titles": "", "title": "exposed assetsmanager to javascript and added multiple-assetsmanager support"}
{"description": " this adds a conversion layer from any prior cached results in the database that were created via ptrees to be rapidjson arrays. we do so by setting a database results version flag while processing differentials in query results to ensure we only upgrade result schemas once. this addresses #4206 ", "commit_messages": " bug: updating database ptree entires to rapdijson  unit test for database upgrade  fixing up logic to leverage results version flag ", "linked_issue_titles": "", "title": "convert cached ptree entires to rapidjson results"}
{"description": " addresses #2931, approximately following the suggestions of @gkatsev in the discussion on #3433.  adds named export setformattime  to utils/format-time.js. allows overwriting the standard format-time implementation with a custom function, which will be called with seconds and guide as arguments. also exposes setformattime on videojs. example: videojs.setformattime((seconds, guide) => ${seconds}, ${guide})); change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) ", "commit_messages": " add option to override format-time with custom implementation.  added named export setformattime to time-format.js, which replaces the original function with a custom implementation.  addresses issue #2931  fix lint errors, add jsdoc comments  addresses issue #2931  add test for setformattime  issue #2931 ", "linked_issue_titles": "", "title": "add an option to override format-time (#2931)"}
{"description": " small change regarding the default precision, making it 3 (milliseconds will be returned) from previous value of 0. fixes #39288. ", "commit_messages": " change the current_timestamp precision from 0 to 3. ", "linked_issue_titles": " sql: change the default precision for current_timestamp ", "title": "change the default precision for current_timestamp function"}
{"description": " original pull-request #24898 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " allowed s3 key to be empty.  fixed unit tests accoording to the fix.  fix. ", "linked_issue_titles": "", "title": "fixed bug with declaring s3 disk at root of bucket"}
{"description": " @jasonbahl this caches introspection queries between builds as well as an md5 of the query response. the hash of the last builds query response is checked against the hash from the current build. if they're different, i recursively regenerate gql queries (to be used in requesting data from wpgql), if they're the same i use cached queries that were generated in the last build. i also store wether or not the schema has changed in redux so that if it has changed i can pull all nodes again later in the plugin, since we don't know if the data shape is the same. if needed, this could later be refactored to track the schema of each individual type and only invalidate cached nodes if their part of the schema changes. for now i'm doing it this way for the mvp ", "commit_messages": " add extra safety checks  refactor  update local url  refactor scripts  cache queries and check if the schema has updated ", "linked_issue_titles": "", "title": "cache queries and monitor for schema changes [gatsby-source-wordpress]"}
{"description": " this pr bumps graphql-js major from v14 to v15 and graphql-compose from v6 to v7 closes #25906 ", "commit_messages": " chore: bump graphql major version  fix graphql-compose deprecations  graphql-compose: fix args mapping for directives  graphql-compose: fix incorrect type merging  new version of graphql-compose adds type composers added via createtemp to schemacomposer. so before the upgrade schemacomposer.has(typename) always returned false for temp types, now it returns true (as the temp composer is already added).  graphql-compose: fix merged type assignment  in the new version of graphql-compose the list of actual final types is stored in schemacomposer itself, not typemapper. also the same composer may have multiple keys ", "linked_issue_titles": " support new graphql major (15) ", "title": "bump graphql and graphql-compose major versions"}
{"description": " addresses #591 ", "commit_messages": " upgrade jacoco version to fix the uuid initialization problem #591  load ee module to make ee classes available on classpath #591  turn forking on to prevent datanucleus from missing a jdk 9 module #591  add another jdk 9 module to prevent class not found errors #591 ", "linked_issue_titles": "", "title": "configuration changes needed to run tests on java 9"}
{"description": " these reverts #7766 it fixes #7630 in a different way and also fixes #7951. ", "commit_messages": " add failing spec for window size after restore  revert \"incorrect position when restored from maximize-on-top-drag under windows #7630\"  this reverts commit a2b3abbf47f2adc8f945f3e12ce6f756670d03ca.  fix maximize --> unmaximize positioning issue ", "linked_issue_titles": " incorrect position when restored from maximize-on-top-drag under windows  windows: restore (after minimize) to wrong window size ", "title": "fix incorrect window size after restore on windows"}
{"description": " simplification of the spec handling for asyncmock and correction for how spec_set is handled. ", "commit_messages": " port tests from original pr  port tests from original pr  minor fixes  remove extraneous tests  remove extraneous test ", "linked_issue_titles": "", "title": "minor fixes to asyncmock spec handling"}
{"description": " also logs a message when defaulting, and a warning when using a prerelease build of react-dom (e.g. the react 18 alpha) which are not officially supported. note: i've done this in webpack-config.ts instead of the next.js config, as we don't actually want you to be able to opt-out without downgrading back to react 17, and so it ought to be entirely removed from the config eventually. ", "commit_messages": " use createroot if detected ", "linked_issue_titles": "", "title": "automatically use createroot for react@>=18"}
{"description": " please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo: coverage service link (codecov, coveralls, gocover etc.) very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. ", "commit_messages": " add dasel to data-structures  add dasel to devops tools  remove dasel from data-structures  update dasel description ", "linked_issue_titles": "", "title": "update dasel description and change category"}
{"description": " new features others add gen_bkcl_id_op for multi baidu kunlun cards training support fleet api for multi baidu kunlun cards training ", "commit_messages": " dygraph supports multi xpu card training  add bkcl_context_test and fix error messages (#1)  fix xpu fill_constant place, to_tensor place  mulit xpu dygraph (#2)  add xpudeviceguard  fix multi xpu dygraph (#3)  * fix some uts' interfaces  * add todos and fix err_messages  fix copy  fix getdeviceid  add gen_bkcl_id_op, test=notest  fix,test=notest  fix,test=notest  fix,test=notest  fix,test=notest  fix  fix test_gen_bkcl_id_op.py  merge upstream/develop ", "linked_issue_titles": "", "title": "add gen_bkcl_id_op, support multi xpu cards training using multiprocess"}
{"description": " added logic to net_plugin_impl and connection classes to support security group in privacy features. select one: select any that apply: ", "commit_messages": " epe-721: add connection management  wip  wip  wip  wip  epe-672: add security group to net_plugin  added the security_group_manager class to net_plugin and added logic  to handle connections that are and are not participating in a  security group. ", "linked_issue_titles": "", "title": "add security group participant message handling to net_plugin"}
{"description": " i hereby agree to the terms of the cla available at:  category: doc fixes ('ru'). changes description: adding description of the check table query. ordering miscellaneous queries by alphabet. ", "commit_messages": " translation for check table query to russian  fix link to nowhere ", "linked_issue_titles": "", "title": "adding description of the check table query to the 'ru' doc"}
{"description": " improvement covered both auto bindings and manual bindings all changes follow generational gc style for #12405 ", "commit_messages": " improve js template documentation  remove useless manual bindings for menuitems  solve a possible memory leak in httprequest  remove useless manual bindings for addeventlistener functions in ui  use js::persistentrooted instead of js::heap to prevent delegates and wrappers internal js object from gc  more elegant and secured way, potential crashes exists in previous implementation  clean up manual bindings code, remove js_this_object and js_set_rval ", "linked_issue_titles": "", "title": "improved js bindings with more secured memory management"}
{"description": " this pull request removes the blog feature (and all the other stuff that goes along with it) from the website folder. addresses #5238 ", "commit_messages": " update ma' fork  initial setup of docusaurus (#5227)  remove the blog link from the header  remove blog link from the site footer  remove blog translation, as we no longer have a blog  remove all sample blog-content  remove blog info from the website readme ", "linked_issue_titles": "", "title": "5238 removing blog from docusaurus"}
{"description": " adds generatecontextapispec gradle task that generates whitelist api specs under modules/lang-painless/src/main/generated/whitelist-json. the common classes are in painless-common.json, the specialized classes per context are in painless-$context.json. eg. painless-aggs.json has the specialization for the aggs contexts ", "commit_messages": " scripting whitelist api spec: add generatecontextapispec task  scripting whitelist api spec: find common classes  scripting whitelist api spec: generate common.json  scripting whitelist api spec: handle arrays for parameters and return values  scripting whitelist api spec: handle arrays for static methods  scripting whitelist api spec: handle arrays for constructors  scripting whitelist api spec: handle arrays for fields  scripting whitelist api spec: change $ internal names to display names  scripting whitelist api spec: generate rest of the contexts ", "linked_issue_titles": "", "title": "whitelist api spec gradle task"}
{"description": " i'm working on getting these into master (#22580 and #22579) but i'd really like to have them in tensorflow asap because they make the colab autocomplete very crashy. ", "commit_messages": " repl completer crash while defining struct  invalid unary ops crash repl completer ", "linked_issue_titles": "", "title": "cherry-pick some autocomplete crasher fixes into tensorflow"}
{"description": " bpo-33789: test_asyncio: fix resourcewarning (gh-7460) bpo-33789, test_asyncio: hide pendingdeprecationwarning (gh-7461) bpo-32676, test_asyncio: fix warning in test_error_in_call_soon() (gh-7462) ", "commit_messages": " bpo-33789: test_asyncio: fix resourcewarning (gh-7460)  * close sockets and streams to fix resourcewarning warnings  * catch also oserror to hide a traceback on an expected handshake  error  (cherry picked from commit 0eba7c39132614a5730cda6b340e18dfb2d30d14)  bpo-33789, test_asyncio: hide pendingdeprecationwarning (gh-7461)  hide pendingdeprecationwarning in test__register_task_3().  (cherry picked from commit 7ed61e9431ee2c191aeeeb26f86a71bb90ab99fd)  bpo-32676, test_asyncio: fix warning in test_error_in_call_soon() (gh-7462)  fix \"<corowrapper ...> was never yielded from\" warning in  pytask_pyfuture_tests.test_error_in_call_soon() of  test_asyncio.test_tasks.  close manually the coroutine on error.  (cherry picked from commit 9f04f0df6fdb27190690bda949d213893d14e807) ", "linked_issue_titles": "", "title": "backport test_asyncio fixes from master"}
{"description": " issue raised in dockerode repo: apocas/dockerode#464 when using the run command, to split the stdout and stderr, an array of streams should be passed in as the 3rd parameter of the run command. optionally you can pass in a single stream as well. ", "commit_messages": " add array of streams option to run command.  re-add import back in. ", "linked_issue_titles": "", "title": "dockerode - allow passing in array of streams to run command."}
{"description": " breaking change: after the discovery of some additional commands, client library now has much better tracking of tv power state. as a result of the client library changes, the standby_connection parameter is no longer needed/present (since the relevant behaviour can be steered automatically by the client library now) description: all standby and suspend modes are currently propagated to home assistant as \"off\", and all other states as \"on\" in order to preserve proper ui behaviour. this also fixes #30999 documentation update in home-assistant/home-assistant.io#11838 ", "commit_messages": " upgrade to aiopylgtv 0.3.0 and corresponding simplification and cleanup of webostv state tracking  properly handle case where live tv is not reported in list of apps ", "linked_issue_titles": " webos integration now displaying 'live tv' in source list... ", "title": "improve state tracking for webostv"}
{"description": " fixes #7145. connect internally strips trailing slash. but we need to also do this during hmr. ", "commit_messages": " fix(server): strip trailing slash from middleware  builder: show / for hmr log  chore: remove unreachable condition ", "linked_issue_titles": " hmr for servermiddleware fails if sub-app is registered without prefix ", "title": "hmr for sub-app servermiddleware without path"}
{"description": " cherry pick of #104384 #104382 on release-1.21. #104384: fix: skip case sensitivity when checking azure nsg rules #104382: fix: ensure instanceshutdownbyproviderid return false for for details on the cherry pick process, see the cherry pick requests page. fix: skip case sensitivity when checking azure nsg rules fix: ensure instanceshutdownbyproviderid return false for creating azure vms ", "commit_messages": " fix: skip case sensitivity when checking azure nsg rules  fix: ensure instanceshutdownbyproviderid return false for creating azure vms ", "linked_issue_titles": "", "title": "fix: skip case sensitivity when checking azure nsg rules\r\n#104382: fix: ensure instanceshutdownbyproviderid return false for"}
{"description": " make sure you have checked all steps below. jira my pr addresses the following airflow jira issues and references them in the pr title. for example, \"[airflow-xxx] my airflow pr\"  in case you are fixing a typo in the documentation you can prepend your commit with [airflow-xxx], code changes always need a jira issue. in case you are proposing a fundamental code change, you need to create an airflow improvement proposal (aip). in case you are adding a dependency, check if the license complies with the asf 3rd party license policy. update example dags of emr to context manager and bitshift composition. my pr adds the following unit tests or does not need testing for this extremely good reason: commits my commits all reference jira issues in their subject lines, and i have squashed multiple commits if they address the same issue. in addition, my commits follow the guidelines from \"how to write a good git commit message\": subject is separated from body by a blank line subject is limited to 50 characters (not including jira issue reference) subject does not end with a period subject uses the imperative mood (\"add\", not \"adding\") body wraps at 72 characters body explains \"what\" and \"why\", not \"how\" in case of new functionality, my pr adds documentation that describes how to use it. all the public functions and the classes in the pr contain docstrings that explain what it does if you implement backwards incompatible changes, please leave a note in the updating.md so we can assign it to a appropriate release code quality passes flake8 ", "commit_messages": " [airflow-5398] - update emr example dags to context manager  [airflow - 5398] update emr example dags to context manager ", "linked_issue_titles": "", "title": "update contrib example dags to context manager"}
{"description": " instead of doing it ourselves use the pflags version.  makes our code smaller, cleaner, more readable, less casting etc. ", "commit_messages": " convert for util.ip to just use a net.ip  pflag can handle ip addresses so use the pflag code instead of doing it  ourselves. this means our code just uses net.ip and we don't have all of  the useless casting back and forth!  use pflag ipnet instead of our own helpers  since pflag can handle net.ipnet arguements use that code. this means  that our code no longer has casts back and forth and just natively uses  net.ipnet. ", "linked_issue_titles": "", "title": "use pflags for net.ip and net.ipnet instead of custom flag types"}
{"description": " right now we're exiting on the very first error. this is not in line with other test-like tasks we have (e.g. yarn lint or yarn test:unit). it also hid a more severe issue #23627. docs: src/pages/components/drawers/persistentdrawerleft.tsx(88,19): error ts2554: expected 1 arguments, but got 0. --  @material-ui/core: ../material-ui-utils/src/deepmerge.ts(2,3): error ts2322: type 'unknown' is not assignable to type 'boolean'. --  closes #23627 ", "commit_messages": " [core] don't bail on monorepo typescript task  revert later run with ts 4.1  [utils] fix deepmerge return type for falsy inputs  [styles] fix usestyles requiring props in ts 4.1 ", "linked_issue_titles": " makestyles overload breakage with typescript 4.1 ", "title": "add support for typescript 4.1"}
{"description": " a few changes in src/core/main.c: fix crash when crashchangevt is specified in config. a couple of changes to crash handler behavior. an error message reworded. ", "commit_messages": " core: adjust error message about /etc/mtab  since having /etc/mtab as a regular file is now a fatal error, stop  mentioning irrelevant minor consequences.  core: remove spurious assert in parsing crashchangevt=  \"data\" is always null (and unused) in config_parse_crash_chvt().  core: change how crash_shell and crash_reboot interact  instead of freezing in pid1 and letting the forked child freeze or  reboot when exec(\"/bin/sh\") fails, just wait for the child's  exit and then do the freeze_or_reboot in pid1 as usual.  this means that when both crash_shell and crash_reboot are enabled, the  system will reboot after the shell exits.  core: always let the kernel reap zombies when we're about to freeze  regardless of whether we're going to spawn a crash shell or not, let the  kernel reap zombies. it's more consistent this way. ", "linked_issue_titles": "", "title": "crash handler changes, crashchangevt parsing fix"}
{"description": " github makes own copies of images referenced in readme, and that fails for large image sizes. the gif has 6mb and so is over the threshold. instead of using an off-github image, use the same image uploaded to user-images.githubusercontent.com. this makes github show the image even when it's very large. this reverses #11170 and finalizes #11158. ", "commit_messages": " remove broken image in readme  github makes copies of images referenced in readme, and it fails for large image sizes. the gif has 6mb and so is over the threshold.  this removes the image until i can figure out how to reinsert it so that it shows.  re-add the hot-reload gif animation  instead of using an off-github image, use the same image uploaded to user-images.githubusercontent.com. this makes github show the image even when it's very large (our animation gif is 6mb). ", "linked_issue_titles": "", "title": "fix missing animated gif in readme"}
{"description": " this pr expands the meaning of include_global_state for snapshots to include system indices. if include_global_state is true on creation, system indices will be included in the snapshot regardless of the contents of the indices field. if include_global_state is true on restoration, system indices will be restored (if included in the snapshot), regardless of the contents of the indices field. index renaming is not applied to system indices, as system indices rely on their names matching certain patterns. if restored system indices are already present, they are automatically deleted prior to restoration from the snapshot to avoid conflicts. this behavior can be overridden to an extent by including a new field in the snapshot creation or restoration call, feature_states, which contains an array of strings indicating the \"feature\" for which system indices should be snapshotted or restored. for example, this call will only restore the watcher and security system indices (in addition to index_1): post /_snapshot/my_repository/snapshot_2/_restore { \"indices\": \"index_1\", \"include_global_state\": true, \"feature_states\": [\"watcher\", \"security\"] } if feature_states is present, the system indices associated with those features will be snapshotted or restored regardless of the value of include_global_state. all system indices can be omitted by providing a special value of none (\"feature_states\": [\"none\"]), or included by omitting the field or explicitly providing an empty array (\"feature_states\": []), similar to the indices field. the list of currently available features can be retrieved via a new \"get snapshottable features\" api: get /_snapshottable_features which returns a response of the form: { \"features\": [ { \"name\": \"tasks\", \"description\": \"manages task results\" }, { \"name\": \"kibana\", \"description\": \"manages kibana configuration and reports\" } } features currently map one-to-one with systemindexplugins, but this should be considered an implementation detail. the get snapshottable features api and snapshot creation rely upon all relevant plugins being installed on the master node. further, the list of feature states included in a given snapshot is exposed by the get snapshot api, which now includes a new field, feature_states, which contains a list of the feature states and their associated system indices which are included in the snapshot. all system indices in feature states are also included in the indices array for backwards compatibility, although explicitly requesting system indices included in a feature state is deprecated. for example, an excerpt from the get snapshot api showing feature_states: \"feature_states\": [ { \"feature_name\": \"tasks\", \"indices\": [ \".tasks\" } ], \"indices\": [ \".tasks\", \"test1\", \"test2\" relates #61657 ", "commit_messages": " add plugin name to systemindexplugin  use plugin name for system index descriptor map  add pluginstates to create and restore snapshot requests  plumb system index descriptor map into snapshotsservice  remove unnecessary comment ", "linked_issue_titles": "", "title": "introduce \"feature states\" for managing snapshots of system indices"}
{"description": " test and fix for #2420 ensures that the recursive type-checking of new graphql fields added by plugins does not infinitely recur when types contain circular references. the solution used is to simply track the set of types during a traversal, aborting at the first instance of circularity, yet preserving the functionality of input type inference up until that point. ", "commit_messages": " add failing test for recursive custom fields  track visited types during field recursion to prevent infinite loop ", "linked_issue_titles": "", "title": "prevent infer input fields infinite recursion"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). docs for net.server.address docs for ws.address cleartextstream was removed 10 major versions ago increase the version number in the header if appropriate. n/a if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. n/a two open questions before this gets merged. one, is it ok to make changes to multiple packages in one pr?  the update to ws is what i actually wanted to make but doing so required exposing the interface from node.  changing the function signature in node broke tests on several other packages, so i fixed those at the same time. i can submit separate prs if need be. two, is there a convention about where to put named interfaces for structures that aren't named in the actual library being described?  node does not actually define an addressinfo type anywhere in its codebase or documentation, but it's an object shape that's used in many places so it makes sense to have one in the typings.  i'm just not sure where it belongs.  i moved it into net because that made sense to me. ", "commit_messages": " node: cleartextstream hasn't existed for 3 years  node: move addressinfo to net module; address() can return string  ws: server.address() can return string (same as net.server.address etc) ", "linked_issue_titles": "", "title": "address() method on server and related classes can return a string"}
{"description": " some assorted stuff i noticed while reviewing #6236. ", "commit_messages": " mount: fix potential bad memory access when /proc/self/mountinfo is empty  it's unlikely this can ever be triggered, but let's be safe rather than  sorry, and handle the case where the list of mount points is zero, and  the \"l\" array thus null. let's ensure we allocate at least one entry.  mount: rework find_loop_device() to log about no errors  we should either log about all errors in a function, or about none (and  then leave the logging about it to the caller who we propagate the error  to). given that the callers of find_loop_device() already log about the  returned errors let's hence suppress the log messages in  find_loop_device() itself.  mount: add debug logging for the case when we knowingly ignore an error  mount: change find_loop_device() error code when no loop device is found to enxio  enoent is a bit too likely to be returned for various reasons, for  example if /sys or /proc are not mounted and hence the files we need not  around. hence, let's use enxio instead, which is equally fitting for the  purpose but has the benefit that the underlying calls won't generate  this error on their own, hence any ambiguity is removed.  mount: add missing validation error message  we really should generate exactly one log message for each error, hence  let's do that in this one case too. ", "linked_issue_titles": "", "title": "a bunch of mini fixes for mount-tool.c"}
{"description": " some random cleanups picked out of pr #49. ", "commit_messages": " util: introduce {send,receive}_one_fd()  introduce two new helpers that send/receive a single fd via a unix  transport. also make nspawn use them instead of hard-coding it.  based on a patch by krzesimir nowak.  nspawn: close unneeded sockets in outer child  (david: note, this is just a cleanup and doesn't fix any bugs)  nspawn, machined: fix comments and error messages  a bunch of \"client -> child\" fixes and one barrier-enumerator fix.  (david: rebased on master) ", "linked_issue_titles": "", "title": "util, nspawn, machined: random cleanups"}
{"description": " dawn 4.0 changes the code of the existing exceptions and this causes a mismatch with the error advice given by cleos. this causes confusion when understanding the given error advice. this pr rematch the error code with the error advice. at the same time, this pr also changes the reference from account_history_api_plugin in cleos to history_api_plugin since the former is obsolete. #3067 ", "commit_messages": " update cleos mismatched error advice  update outdated error advice  change account history api plugin reference in cleos httpc to history api plugin ", "linked_issue_titles": "", "title": "fix mismatch error code with cleos error advice on dawn 4.0"}
{"description": " this commit enables the copydockerfile task to render a dockerfile that sources the elasticsearch binary from artifacts.elastic.co. this is needed for reproducibility and transparency for the official docker images in the docker library. relates #38552 (backport) ", "commit_messages": " enable dockerfile from artifacts.elastic.co  this commit enables the copydockerfile task to render a dockerfile that  sources the elasticsearch binary from artifacts.elastic.co. this is  needed for reproducibility and transparency for the official docker  images in the docker library.  add comment ", "linked_issue_titles": "", "title": "enable dockerfile from artifacts.elastic.co 6.7"}
{"description": " original pull-request #27383 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix  fix flacky test ", "linked_issue_titles": "", "title": "cherry pick #27383 to 21.7: fix flacky test"}
{"description": " restore iuo bridging behavior on swift-5.0-branch. ", "commit_messages": " restore implicitlyunwrappedoptional extension conforming to _objectivecbridgeable.  partial revert of 26f6a751c4dc97383f35bc2d913317df15b54c15.  removing this breaks bridging these values to objective c. once iuos  are removed from the type system and implicitlyunwrappedoptional<t> is  removed from the library, we'll be strictly using optional<t> which  has this conformance as well.  fixes: rdar://problem/36477954,  revert \"iuo: update protocol conformance checking to check iuo attr on decl.\"  this reverts commit ec5cebd4d6bcecce2014c88fa4a4afa010a3ddf8.  the way it's implemented is problematic when we still have iuos in the  type system and library.  we end up thinking there are mismatches between requirements and  potential witnesses when there are not.  add runtime tests for bridging optionals and iuos. ", "linked_issue_titles": "", "title": "fix iuo bridging swift 5.0 branch"}
{"description": " ok, looks like no real changes are needed to support retina devices. we can add an option to iosapplicationconfiguration in the future to allow someone to take full advantage of retina. for now, retina devices simply return the same dimensions (called \"points\" not \"pixels\") as the non-retina displays. on retina devices 1 point = 2 pixels (non retina: 1 point = 1 pixel). here are the changes: getdensity() + getppi() implemented (via help from wikipedia) build-natives.sh fixed (no arm6 anymore!) all convert.xml updated (use env.ivkm_home now) all 3 demo projects updated: 2 of them working, for vectorpinpall i get the following error: \"warning: the referenced library 'gdx-backend-ios.dll' is not used from any code, skipping extraction of content resources. (gdx-vectorpinball-ios)\" - i couldn't figure out what's wrong? iosapplicationconfiguration has now config options for landscape/portrait in any case, that completes your requests for ios :)  i'll look over missing stuff in the ios backend. looks like properties is missing for example. otherwise, i think it's pretty much ready to go besides the build scripts. it's going to be a pain to setup. maybe i look into that? anything special planned for the build scripts to make them easy to use (for others)? ", "commit_messages": " shouldautorotatetointerfaceorientation implemented.  removed arm6 (not supported anymore via xcode). path update: \"/developer/usr/bin/xcodebuild\" -> \"xcodebuild\"  iosapplicationconfiguration updated: landscape/portrait update.  convert.xml uses env.ikvm_home now!  all 3 demo projects using ios updated.  note: cannot get vector pinball to work. i get the following error. not sure how to fix!?  \"warning: the referenced library 'gdx-backend-ios.dll' is not used from any code, skipping extraction of content resources. (gdx-vectorpinball-ios)\"  iosgraphics returns density & ppi values now. that \"completes\" the retina update for now. there are actually no changes needed to get apps to work on retina enabled devices.  note: we could add a flag to iosapplicationconfiguration in the future to allow apps to take full advantage of retina. for now all apps will work on both retina and non-retina devices without code changes :) ", "linked_issue_titles": "", "title": "retina support + misc. other changes"}
{"description": " libweb: expose element.{prefix,localname} libweb: make element::tag_name return the html uppercased qualified name i forgot to change tag_name when this was added. also makes html_uppercased_qualified_name return a const reference. ", "commit_messages": " libweb: expose element.{prefix,localname}  libweb: make element::tag_name return the html uppercased qualified name  i forgot to change tag_name when this was added.  also makes html_uppercased_qualified_name return a const reference. ", "linked_issue_titles": "", "title": "expose element.{prefix,localname} and fix element.tagname"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " morgan: correct morgan function signature  morgan: enable strictnullchecks, add linting  morgan: add definitions author ", "linked_issue_titles": "", "title": "fix function signature, enable strictnullchecks, enable linting"}
{"description": " as discussed in #173 summary this pr introduces one command vue build and three options --port --prod/production --local --config outputs to ./dist by default using buble-loader respect user config, you can populate them at ~/.vue/config.js (cli options) and ~/.vue/webpack.config.js (webpack config to merge) check out doc for more. i choose ~/.vue directory instead of file ~/vue.config.js, in a directory you can install loaders and modules there, so that you don't need to install them again in your project what's not ready no auto install, it could be buggy imo still need to add vue build counter.vue magic still need to add some custom css preprocessors for sfc, so that user only need to install relevant loader extract css allow to have project-specific config at project directory, use --config and --webpack to switch, for example --config config.js, and --webpack webpack.config.js tests what do you think? ", "commit_messages": " add vue-build  add production mode and custom config  fix lint ", "linked_issue_titles": "", "title": "add vue build command, closed #173"}
{"description": " this pr fixes #3629 , and fixes the r package ci to be sure that similar issues don't arise in the future. also fixes #3616 for ci, i'm proposing that instead of having a limit on the number of r cmd check notes, we just ignore very specific notes that we know are not problematic for cran. i think that will be less susceptible to issues like #3629 and give us more confidence that ci is catching problems that would be caught by cran. this is blocking release 3.1.1 (#3611) ", "commit_messages": " [ci] [r-package] fix issue with partial argument name matches  fix partial name matches ", "linked_issue_titles": " [ci] [r-package] r ci jobs on mac, linux do not always fail if unit tests fail  [r-package] r cmd check note 'partial argument match' ", "title": "fix partial matching of keyword arguments in lgb.cv() (fixes #3629)"}
{"description": " fix broken link on 3-1 readme files related to #514 issue ", "commit_messages": " fix small typo, links and reference fr assignment  fix small typo, links and reference french assignment  fix: add loc param and reference fr assignment  add localization parameter on quizzes links and reference fr assignment  fix localization param  fix localization param  fix broken link on 3-1 readme files ", "linked_issue_titles": "", "title": "suggest broken link fix on 3-1 readme files"}
{"description": " this pr addresses several issues on windows with paths containing special characters. the source of some of those issues is a slash package which explicitly declares that it only works with ascii paths (see sindresorhus/slash#5). we already have a pr addressing one specific issue in gatsby-source-filesystem (#14372) but many places are affected (including core gatsby package). this pr moves slash util into gatsby-core-utils and replaces slash usages. it also fixes an issue with invalid graphql query names generated from such paths, see #4565 (comment). p.s. not sure what would be the right pr name when it affects multiple packages from monorepo? #4565 #13882 #13865 #14126 #17746 #17746 #19108 ", "commit_messages": " generate spec-compliant graphql query names  move slash util from gatsby-source-filesystem to gatsby-core-utils  replace slash package in plugins with a slash util from gatsby-core-utils  refactor: uppercase windows drive letter ", "linked_issue_titles": "", "title": "handle special characters in windows paths"}
{"description": " back-port of fixes for libavcodec version checks found during #18146 . to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work allow_multiple_commits=1 ", "commit_messages": " fix: libavcodec version check for av_codec_flag_global_header  fix: libavcodec version check for avdiscard_nonintra  - avdiscard_nonintra flag is supported only for ffmpeg libraries pack ", "linked_issue_titles": "", "title": "back-port for ffmpeg versions guard fix for av_codec_flag_global_header and avdiscard_nonintra"}
{"description": " this pr implements directives to tweak the response headers; model after headers directive of apache. it provides following directives: header.add, header.append, header.merge, header.set, header.setifempty, header.unset. see #196 ", "commit_messages": " implement h2o_str_stripws  implement the headers module ", "linked_issue_titles": "", "title": "add directives to tweak the headers"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dslint/dt.json\" }. ", "commit_messages": " new typings  updated types into a namespace to allow the default function to be fired  typo on findone  dt tests passed ", "linked_issue_titles": "", "title": "updated bonjour types (were not working on typescript 2.2)"}
{"description": " cc/ @mit-mit @xster note: this version uses assets that are not in the gallery assets package. once the assets have been added to that package i'll do a conversion to use those. highlights: adds a first time run experience to describe what the gallery is all about adds in the running demo ", "commit_messages": " add welcome stub  transplant assets and welcome screen, refactor  finish refactor, keep hardcoded welcome test  transplant and update customize design, add to studies  rename to customized  type annotations  small updates  check for welcome state  remove welcome bg  refactor - wip  add image  welcome implemented  auto progress welcome if no interaction  add limit to pageview  welcome content changes  tweak welcome images on larger screens  clean up  merge master ", "linked_issue_titles": "", "title": "add a welcome screen and a demo from the posse gallery"}
{"description": " the kernel itself checks whether or not the provided addresses are word aligned before continuing, so we should be doing the same. ", "commit_messages": " common: move is4kbaligned() to alignment.h  aligning on 4kb pages isn't a switch-specific thing, so this can be  moved to common so it can be used with other things as well.  common: add function for checking word alignment to alignment.h  this will be used in a following change to svcarbitratelock() and  svcarbitrateunlock()  svc: check for word alignment of addresses within svcarbitratelock/svcarbitrateunlock  the kernel itself checks whether or not the provided addresses are word  aligned before continuing, so we should be doing the same. ", "linked_issue_titles": "", "title": "add missing error checks in svcarbitratelock/svcarbitrateunlock"}
{"description": " fixed  left/right bracket logic when pressing lalt and lctl small changes here and there my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " add layer switcher functionality  fixes in left/right bracket functions and other small fixes ", "linked_issue_titles": "", "title": "bugfixes on tapdance logic and small changes in layout"}
{"description": " this pr fixes a bug when wav2vec2 is trained with batch_size=1 did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " correct long to bool  up ", "linked_issue_titles": "", "title": "make sure tensors are always bool for mask_indices"}
{"description": " please check #10735 for why we are doing this. to solve the issue above, we have merged a pr #10817 and now there is utility functions here to create lodtensor. so this means that we can simplify the book example code using the new api. this pr tries to modify the rnn encoder decoder book example. ", "commit_messages": " initial commit  modify rnn_encoder_docoder example ", "linked_issue_titles": "", "title": "modify rnn encoder decoder example using new lodtensor api"}
{"description": " description: fix for timeout error caused by big image icon for notification default image changed to smaller size. added timeout option for connection. related issue (if applicable): fixes # pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4196 example entry for configuration.yaml (if applicable): notify: - platform: webostv host: 192.168.0.112 name: livingroom_tv filename: webostv.conf checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " use smaller icon  add timeout option ", "linked_issue_titles": "", "title": "notify webos timeout error fix"}
{"description": " in this pr, i fixed some bugs and add members property to response for the api getroominfo. now an example result of this api is like following: { \"roomid\": \"d2laekjpjwyssxrht\", \"roomname\": \"rocket.chat-experimental-basket-basketball-frvr-xqfx4gsxbn\", \"members\": [ { \"userid\": \"h6vzrjfv2wilf5map\", \"username\": \"kevin\", \"avatarurl\": \" \"status\": \"offline\" }, { \"userid\": \"b8dsjdragwdnj4p9z\", \"username\": \"anakin\", \"avatarurl\": \" \"status\": \"offline\" }, { \"userid\": \"rhwz9jaukm7w6rvnc\", \"username\": \"root\", \"avatarurl\": \" \"status\": \"online\" } ] } ", "commit_messages": " [fix] the invalid room name issue  [fix] limit externalcomponent name length  add members property to response ", "linked_issue_titles": "", "title": "fix some bugs and add members property to response"}
{"description": " this changeset switches the mitigation strategy away from the one taken in pr #1350 (which avoids missing the end-of-input check by restarting the dictionary search with bestlength = 0) to totally avoiding searching the dictionary when we're in that situation, since a precondition to being at risk of running past the end of the input is that we've already found an optimal match. so there's no utility in searching the dictionary. i suspect this will produce a small performance win. notably, this approach to avoiding the issue was already present in the zstd_btopt implementation. not sure how it got missed in zstd_btlazy2 . in making this change, this patch fixes an unfortunate bug. without this change, the zstd_btlazy2 strategy unconditionally selects the best dictionary match (if one is found) over the best input match, even if the dictionary match is worse. furthermore, it then skips trying to match against the input as if it had used the better match into the input that it found and discarded. in the worst case, this can lead to totally failing to compress very repetitive input. this changeset avoids that behavior by returning to only considering matches in the dictionary that are better than the best input match. as a result, this pr fixes issue #1357. ", "commit_messages": " remove unused variable  clean up debug log statements  avoid searching dictionary in zstd_btlazy2 when an optimal match is found  bailing here is important to avoid reading past the end of the input buffer. ", "linked_issue_titles": "", "title": "avoid erroneously trampling on match with worse dictionary match"}
{"description": " @nvbn what do you think? please review. any comment is welcome ", "commit_messages": " test(shells): add fuck alias to collection of aliases  refact(shells): use an env var tf_alias to keep the name of the alias  this environment variable may be used by any rule to decide whether it  matches or not. ", "linked_issue_titles": "", "title": "use an environment variable that keeps the alias name to avoid looping"}
{"description": " exp sigmoid tanh 61: [ run      ] jitkernel.vexp 61: i1116 17:31:25.289243 70727 jit_kernel_test.cc:192] vec size 7: refer takes: 0.1193 us, mkl takes: 0.06805 us, tgt takes: 0.04005 61: i1116 17:31:25.292809 70727 jit_kernel_test.cc:192] vec size 8: refer takes: 0.10145 us, mkl takes: 0.0595 us, tgt takes: 0.0142 61: i1116 17:31:25.298521 70727 jit_kernel_test.cc:192] vec size 12: refer takes: 0.19745 us, mkl takes: 0.05865 us, tgt takes: 0.02685 61: i1116 17:31:25.306084 70727 jit_kernel_test.cc:192] vec size 15: refer takes: 0.25365 us, mkl takes: 0.06725 us, tgt takes: 0.05415 61: i1116 17:31:25.313345 70727 jit_kernel_test.cc:192] vec size 16: refer takes: 0.263 us, mkl takes: 0.0668 us, tgt takes: 0.03025 61: i1116 17:31:25.322093 70727 jit_kernel_test.cc:192] vec size 20: refer takes: 0.33465 us, mkl takes: 0.05935 us, tgt takes: 0.04095 61: i1116 17:31:25.332445 70727 jit_kernel_test.cc:192] vec size 30: refer takes: 0.3682 us, mkl takes: 0.07565 us, tgt takes: 0.0708 61: i1116 17:31:25.425176 70727 jit_kernel_test.cc:192] vec size 128: refer takes: 1.54815 us, mkl takes: 2.86435 us, tgt takes: 0.21885 61: [ run      ] jitkernel.vsigmoid 61: i1116 17:31:25.505259 70727 jit_kernel_test.cc:264] vec size 7: refer takes: 0.1178 us, better(jit exp) takes: 0.08285 us, tgt takes: 0.0532 61: i1116 17:31:25.509996 70727 jit_kernel_test.cc:264] vec size 8: refer takes: 0.13415 us, better(jit exp) takes: 0.08 us, tgt takes: 0.02035 61: i1116 17:31:25.517647 70727 jit_kernel_test.cc:264] vec size 15: refer takes: 0.2031 us, better(jit exp) takes: 0.10545 us, tgt takes: 0.0703 61: i1116 17:31:25.524626 70727 jit_kernel_test.cc:264] vec size 16: refer takes: 0.2162 us, better(jit exp) takes: 0.0947 us, tgt takes: 0.0362 61: i1116 17:31:25.537247 70727 jit_kernel_test.cc:264] vec size 30: refer takes: 0.40715 us, better(jit exp) takes: 0.13325 us, tgt takes: 0.08795 61: i1116 17:31:25.549927 70727 jit_kernel_test.cc:264] vec size 32: refer takes: 0.4349 us, better(jit exp) takes: 0.1228 us, tgt takes: 0.0724 61: i1116 17:31:25.574997 70727 jit_kernel_test.cc:264] vec size 64: refer takes: 0.87295 us, better(jit exp) takes: 0.2315 us, tgt takes: 0.14305 61: i1116 17:31:25.613718 70727 jit_kernel_test.cc:264] vec size 100: refer takes: 1.34945 us, better(jit exp) takes: 0.34655 us, tgt takes: 0.2316 61: i1116 17:31:25.662092 70727 jit_kernel_test.cc:264] vec size 128: refer takes: 1.7127 us, better(jit exp) takes: 0.41525 us, tgt takes: 0.2857 61: i1116 17:31:25.758944 70727 jit_kernel_test.cc:264] vec size 256: refer takes: 3.4511 us, better(jit exp) takes: 0.82345 us, tgt takes: 0.5594 61: [       ok ] jitkernel.vsigmoid (258 ms) 61: [ run      ] jitkernel.vtanh 61: i1116 17:31:25.763900 70727 jit_kernel_test.cc:332] vec size 7: refer takes: 0.1219 us, better(jit exp) takes: 0.06585 us, tgt takes: 0.0525 61: i1116 17:31:25.767813 70727 jit_kernel_test.cc:332] vec size 8: refer takes: 0.1395 us, better(jit exp) takes: 0.0354 us, tgt takes: 0.018 61: i1116 17:31:25.776193 70727 jit_kernel_test.cc:332] vec size 15: refer takes: 0.25945 us, better(jit exp) takes: 0.08585 us, tgt takes: 0.07065 61: i1116 17:31:25.783507 70727 jit_kernel_test.cc:332] vec size 16: refer takes: 0.2763 us, better(jit exp) takes: 0.05105 us, tgt takes: 0.0359 61: i1116 17:31:25.797840 70727 jit_kernel_test.cc:332] vec size 30: refer takes: 0.5218 us, better(jit exp) takes: 0.10425 us, tgt takes: 0.0872 61: i1116 17:31:25.812160 70727 jit_kernel_test.cc:332] vec size 32: refer takes: 0.55535 us, better(jit exp) takes: 0.08625 us, tgt takes: 0.0708 61: i1116 17:31:25.840363 70727 jit_kernel_test.cc:332] vec size 64: refer takes: 1.1042 us, better(jit exp) takes: 0.16155 us, tgt takes: 0.14015 61: i1116 17:31:25.884611 70727 jit_kernel_test.cc:332] vec size 100: refer takes: 1.7222 us, better(jit exp) takes: 0.2579 us, tgt takes: 0.2271 61: i1116 17:31:25.941277 70727 jit_kernel_test.cc:332] vec size 128: refer takes: 2.2213 us, better(jit exp) takes: 0.32435 us, tgt takes: 0.2811 61: i1116 17:31:26.054328 70727 jit_kernel_test.cc:332] vec size 256: refer takes: 4.42075 us, better(jit exp) takes: 0.6569 us, tgt takes: 0.56345 ", "commit_messages": " exp support all size  refine act and vxx with all size  refine relu and fix addrelu test  refine exp jitcode with all size  test=develop ", "linked_issue_titles": "", "title": "jitcode act support all size"}
{"description": " others others parse rank_to_ip map on cpp side and start message bus ", "commit_messages": " add ip parser  adapt singlton  update vlog  modify structure  add isinit interface for message bus  some update  correct typo ", "linked_issue_titles": "", "title": "parse rank_to_ip map on cpp side and start message bus."}
{"description": " ts 3.7 has been released which supports optional chaining and nullish operator. gastby-plugin-typescript uses babel to transform typescript so two plugin must be added accordingly to support these new feature ", "commit_messages": " add plugin  add optional chaining ", "linked_issue_titles": "", "title": "add support for optional chaining and nullish coalescing operator"}
{"description": " should mitigate the issues found during mcp on #73255. once this is done, we should clean up the queries a bit, since i think mir_drops_elaborated_and_const_checked can be merged back into mir_promoted. fixes #90770.  r? @nikomatsakis (since they reviewed #71824) ", "commit_messages": " separate removefalseedges from simplifybranches  otherwise dataflow state will propagate along false edges and cause  things to be marked as maybe init unnecessarily. these should be  separate, since simplifybranches also makes if true {} else {} into  a goto, which means we wouldn't lint anything in the else block.  add \"is\" methods for projections to a given index ", "linked_issue_titles": " post-drop elaboration const-checking fails on zsts ", "title": "move #![feature(const_precise_live_drops)] checks earlier in the pipeline"}
{"description": " see issue #3854. we used the mardown syntax to format the coding style page: styled lists; used syntax highlighting; formatted correct and incorrect code as in the solidity style guide; fixed punctuation as for the english rules for bulleted lists; formatted links. there is still room for improvements and small fixes. we could for example remove some numbers in the section titles and lists, remove some lists ... ", "commit_messages": " update coding_style.md  use markdown formatting  - never use more than 2 line breaks  - cpp syntax highlighting  - use yes / no instead of right / wrong (as seen in the style guide at  stylizing markdown on this coding_style.md, lists, code  merge  remove punctuation in titles  add list style, links style on coding_style.md  syntax highlighting  merged  punctuation consistency  put correct before incorrect code examples ", "linked_issue_titles": "", "title": "correct the style of coding style (#3854)"}
{"description": " this pr fixes the behavior raised in #42420. now, the user can create new host record bypassing dns and will also be able to delete existing host_record made via bypassing dns. also, now user can use the feature of dhcp while creating the new host record. nios ansible version 2.7 i have included dhcp support also in this pr, which will help the user to create host_record under dhcp which earlier was not supported and was by default set to false. if the user chooses to create host_record under dhcp, a user will have have to mention the mac address. ", "commit_messages": " fixes issue 42420  fixes issue 42420 ", "linked_issue_titles": "", "title": "allow dns bypass for add/remove of host records with nios_host_record"}
{"description": " this was the last genericsignature-based operation that relied upon the genericsignaturebuilder. next steps: finish some edge cases with superclass requirements various rewrite system optimizations to recover performance enable the requirement machine by default? start work on using rewrite system to compute minimal and canonical generic signatures nuke the gsb altogether ", "commit_messages": " ast: factor out genericsignature::getlocalrequirements() method  this encapsulates genericenvironment's usage of the gsb.  requirementmachine: implement genericsignature::getlocalrequirements() query  ast: don't force requirementmachine creation in getorcreategenericsignaturebuilder()  this was for test coverage before i had any queries ported over, just to  make sure that the completion procedure worked.  now that all the genericsignature queries have been ported over, we don't  need this since  we're going to create all the requirementmachines anyway.  requirementmachine: drop protocols that the superclass conforms to when building an archetype  requirementmachine: tri-state enable flag, and move queries to genericsignaturequeries.cpp  the -enable-requirement-machine and -disable-requirement-machine flags are now  replaced by a new flag -requirement-machine={on,off,verify}.  ast: asert that we don't create genericsignaturebuilders when requirementmachine is enabled  requirementmachine: re-use a single global rewritecontext ", "linked_issue_titles": "", "title": "use requirementmachine to build archetypes when enabled"}
{"description": " this is in response to #873 essentially, i would like to add a callback function to sla miss handling. in the callback function, i can decide whether to post to slack and to victorops/pagerduty, or some other 3rd party ops solution. email is too limiting. i've added another column to the table to track sla notifications in general. not in this pr is a fix for a general problem which can occur is slas were enabled on a task but no emails or sla alert call back were provided. in this case, the query to return all sla misses would progressively return more and more data, slowing down the scheduler. we need a separate fix to place a window on the max number of sla misses queried. ", "commit_messages": " sla miss alert callbacks : allow dags to specify a callback function that can be executed during sla misses. one use-case for this is to allow 3rd party notification on sla misses such as pagerduty and victorops  sla alert callback : supporting the ability to do optional sla alert call backs and emailing  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "allow dags to specify a callback function for sla miss handling"}
{"description": " description: bump nessclient version to use latest release (0.9.10), with a handful of fixes which should improve the general stability of this component. example entry for configuration.yaml (if applicable): ness_alarm: host: alarm.local port: 2401 zones: - name: garage id: 1 - name: storeroom id: 2 - name: kitchen id: 3 - name: front entrance id: 4 checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. ", "commit_messages": " ness_alarm: bump nessclient version  update requirements_all.txt ", "linked_issue_titles": "", "title": "bump nessclient version to 0.9.10"}
{"description": " fix: #9401 note: i added some extra code that checks the operand values which is not strictly necessary, but now the errors are exactly the same as when using mongo shell. ", "commit_messages": " add support for  aliasses  styling ", "linked_issue_titles": "", "title": "add support for $type aliasses."}
{"description": " closes t-1087 this disables workers of all types from being created with a string literal. it's now required to use new worker(new url('filename.js', import.meta.url), {type: 'module'}). this is because strings passed to the worker constructor are supposed to be resolved relative to the page url, not to the current file. using the url constructor solves this issue so that parcel is more web compatible. this is also how other bundlers like webpack now work. this also makes some formatting improvements to diagnostics, especially when multiple diagnostics are displayed at once. the code frame and hints are now indented underneath each error message so it's clear what it is associated with. in addition, it's now possible to have multiple code frames pointing to different files within the same diagnostic. this way, errors can show context for the error in another file without creating a separate diagnostic which looks like a different error. there's also some other small diagnostic improvements in this pr which you can see in the code. ", "commit_messages": " disable workers with string literals  diagnostic improvements ", "linked_issue_titles": "", "title": "disable workers with string literals and improve diagnostics"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): from now on .sql tests can be run isolated by server, in parallel, with random database. it allows to run them faster, add new tests with custom server configurations, and be sure that different tests doesn't affect each other. ", "commit_messages": " initial implementation of pytest tests for stateless queries.  run .sql tests with standalone server  try \"fix\" tests  revert \"try \"fix\" tests\"  this reverts commit 52d1042310fa8aef45fc42ae795301f38b3b84b8.  check every test cleans up everything and doesn't hardcode db names ", "linked_issue_titles": "", "title": "run query-tests using pytest framework"}
{"description": " release a bunch of summarization and translation pseudolabels with reasonably nice documentation. allow make_student(teacher, 'student_000_baseline', 12, 3, d_layers_to_copy=[0,0,0]) for baseline purposes. ", "commit_messages": " kwarg layers2copy  allow 000  links to precomputed pseudolabels  boom boom ", "linked_issue_titles": "", "title": "release pseudolabel links and instructions"}
{"description": " what do these changes do? clean up the pytorch model api to support rnns, dict / tuple spaces unify qmix rnn model with model catalog i expect we'll have to make more changes (and add more tests) as we implement pytorch support more fully; this is just an initial cleanup to better unify qmix with pytorch a3c. #3365 ", "commit_messages": " wip  clean up  wip  add reg  rnn  mask test ", "linked_issue_titles": "", "title": "refactor pytorch custom model support"}
{"description": " added qwerty and command layers moved modified tap keys to press instead of release added one shot modifiers organizational changes my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " added my own keymap  changed thing  updated keymap samuel  updated laypout for better one handed use  updated stuff i want  happy with my lagout  formatting  added new literate config  merge remote-tracking branch 'upstream/master'  made everything nice  cleaned  fixed spelling and two small bugs in macros  made press and lift function for modifiers  made taps occur on press instead of release  added oneshot keys and chars cant be negative!  removed debug message  added command and qwerty layers  updated  fixed bug with oneshot layer  same bug, different key ", "linked_issue_titles": "", "title": "improvements to samuel's literate keymap"}
{"description": " continues from #4232,  closes #4153. fixes #2703. fixes #2710. @piscisaureus please review. ", "commit_messages": " wip: get better frame info from preparestacktrace  use callsiteeval with fields instead of methods  convert 1-based line/column numbers to 0-based  don't apply source maps twice  fix tests ", "linked_issue_titles": " async stack traces  discrepancy in output between error.stack and thrown error  don't destructure errors using v8::exception::create_message(), just read error.stack ", "title": "get frame data from preparestacktrace()"}
{"description": " this pull request patches fs.access and fs.accesssync to support paths in asar archives. it also does a little  on the file and uses let/const instead of var. it also supports calling fs apis with a buffer path (instead of a string) which was added in node 6.0.0, nodejs/node#5616 closes #6555 ", "commit_messages": " use let/const instead of var  add asar-supported fs.access implementation  add asar-supported fs.accesssync implementation  support paths as buffers ", "linked_issue_titles": "", "title": "add asar implementation of fs.access/accesssync"}
{"description": " backport of #10194 ", "commit_messages": " bug: failure to decref in pyufunc_genericreduction.  would lead to a reference leak for the case that an invalid axis  is passed in.  maint: use single failure path in py_ufunc_genericreduction.  this should help avoid reference leaks in future additions. ", "linked_issue_titles": "", "title": "ufunc reduce reference leak (backport)"}
{"description": " i did not get yaml working on my local machine so i hope it builds from my careful (?) mimicry. it all works now. ready to merge on my end :) ", "commit_messages": " added relation prediction, removed from wishlist  relation prediction skeleton  relation prediction results (wn18rr)  described relation prediction ", "linked_issue_titles": "", "title": "new task - relation prediction on wn18rr"}
{"description": " if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #. update the changes log. fyi @lujiajing1126 ", "commit_messages": " remove page path in the browser log query condition.  remove endpoint name in the backend log query condition.  fix a code style issue.  fix missing changes. ", "linked_issue_titles": "", "title": "remove endpoint name in backend log and browser log query"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. #30792 ", "commit_messages": " fix error in list type  [release] increase prompts version 1.2  [improve] add boolean as initial message  [improve] add falsy type to skip the question  [fix] remove trail space  [improve] improve type of prompts  fix lint error ", "linked_issue_titles": "", "title": "update a error from #30792"}
{"description": " save settings file instead of sending ipc message added file watcher to track changes in the settings.json updated ui unit tests what is include in the pr: linked issue: #11077 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " removed ipc messages  added settings utils  replaced mock msg  added asserts  added new tests  file watcher on settings change  update window via message  reverted setconfig ", "linked_issue_titles": "", "title": "drop support for the module interface api to save settings"}
{"description": " rdar://76568032&76567759&76567375&76566897&76566598&76566242&76566029 ", "commit_messages": " [test] disabled several autodiff tests for back_deployment_runtime.  rdar://76566029  [test] disabled casting/casts.swift for back_deployment_runtime.  rdar://76566242  [test] disabled several concurrency tests for back_deployment_runtime.  rdar://76566598  [test] disabled interpreter/bridged_casts_folding.swift for back_deployment_runtime.  rdar://76566897  [test] disabled two playgroundtransform tests for back_deployment_runtime.  rdar://76567375  [test] disabled several runtime tests for back_deployment_runtime.  rdar://76567759  [test] disabled several stdlib tests for back_deployment_runtime.  rdar://76568032 ", "linked_issue_titles": "", "title": "disabled several tests for back_deployment_runtime."}
{"description": " in #2923 , filespipeline added support for google cloud storage. however, the pr did not implement support for acl. so, this pr add support acl for google cloud storage. (venv) [rhoboro]~/github/scrapy % gcs_project_id=\"xxx\" gcs_test_file_uri=\"gs://xxx\" tox -- tests/test_pipeline_files.py -v ... =================================================================================================== test session starts ==================================================================================================== platform darwin -- python 2.7.10, pytest-2.9.2, py-1.5.3, pluggy-0.3.1 -- /users/suyamar/github/scrapy/.tox/py27/bin/python cachedir: .cache rootdir: /users/suyamar/github/scrapy, inifile: pytest.ini plugins: twisted-1.7.1, cov-2.2.1 collected 18 items tests/test_pipeline_files.py::filespipelinetestcase::test_file_expired <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed tests/test_pipeline_files.py::filespipelinetestcase::test_file_not_expired <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed tests/test_pipeline_files.py::filespipelinetestcase::test_file_path passed tests/test_pipeline_files.py::filespipelinetestcase::test_fs_store passed tests/test_pipeline_files.py::deprecatedfilespipelinetestcase::test_default_file_key_method passed tests/test_pipeline_files.py::deprecatedfilespipelinetestcase::test_overridden_file_key_method passed tests/test_pipeline_files.py::filespipelinetestcasefields::test_item_fields_default passed tests/test_pipeline_files.py::filespipelinetestcasefields::test_item_fields_override_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_cls_attrs_with_default_prefix passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_custom_settings_and_class_attrs_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_custom_settings_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_different_settings_for_different_instances passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_no_custom_settings_for_subclasses passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_subclass_attributes_preserved_if_no_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_subclass_attrs_preserved_custom_settings passed tests/test_pipeline_files.py::filespipelinetestcasecustomsettings::test_user_defined_subclass_default_key_names passed tests/test_pipeline_files.py::tests3filesstore::test_persist <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py skipped tests/test_pipeline_files.py::testgcsfilesstore::test_persist <- .tox/py27/lib/python2.7/site-packages/twisted/internet/defer.py passed =========================================================================================== 17 passed, 1 skipped in 8.53 seconds =========================================================================================== _________________________________________________________________________________________________________ summary __________________________________________________________________________________________________________ py27: commands succeeded congratulations :) ", "commit_messages": " add acl support for gcs  added test for gcs policy  update docs for support gcs acl ", "linked_issue_titles": "", "title": "filespipeline supports acl for google cloud storage"}
{"description": " expand use of xdsresourcetype outside of xdsapi into xdsclient.  this removes a bunch of duplicate data structures and code-paths for different resource types, which makes the xdsclient implementation resource-type-agnostic. the xdsclient api still has a different watcher api for each resource type, which is implemented on top of the new resource-type-agnostic api.  in a subsequent pr, i will remove those resource-type-specific apis and move them to the xdsresourcetype interface. there are two noteworthy structural changes here: i have improved the interface of xdsapi::parseadsresponse().  instead of passing in a bunch of lists of expected resource names for each resource type and then passing out a different map based on the resource type, i have introduced a adsresponseparserinterface api.  the xdsclient provides an implementation of that api, and parseadsresponse() invokes the methods on that object to perform the parsing.  this allows the xdsclient to directly handle each resource as it is parsed, adding it to the cache and notifying watchers as appropriate. i have added a global registry for xds resource types.  the xdsclient code uses this to determine which xdsresourcetype to use for each ads response without hard-coding an \"if/else\" block with options for each resource type. ", "commit_messages": " wip  introduce xdsresourcetype api and change listener parsing to use it  converted routeconfig parsing  convert cluster and endpoint parsing  cleanup  clang-format  attempt to work around compiler problems  move xdsresourcetype to its own file, and move endpoint code out of xdsapi  move cluster parsing to its own file  move route config parsing to its own file  move listener parsing to its own file  clang-format  minor cleanup  plumbed xdsresourcetype throughout xdsclient  a bit of cleanup  more cleanup  construct full resource names before calling xdsapi::createadsrequest() ", "linked_issue_titles": "", "title": "use xdsresourcetype abstraction throughout xdsclient"}
{"description": " addresses #20308 this pr ensures linearsvr is compatible with numpydoc. remove linearsvr from docstring_ignore_list. verify that all tests are passing. #dataumbrella sprint ", "commit_messages": " remove linearsvr from docstring_ignore_list.  fix numpydocs from linearsvr. ", "linked_issue_titles": "", "title": "doc ensures that linearsvr passes numpydoc validation"}
{"description": " bug fixes apis this pr fixes several problems in dy2stat for deoldify model in paddlegan. in model, software engineer wrote if x.shape == y.shape, the tenser shape is a tuple in dygraph so the == returns true/false, but in static graph the == becomes element-wise comparison, which is a different behavior. in this pr we reduce the element-wise comparison result. if software engineer write computations which uses parameters in hooks, the static graph can loss the parameter variable because we put param_guard at forward of a layer. in this pr we made param_guard cover pre-hook and post-hook. in paddlegan, software engineer calculated some parameter values in __init__ by running some dygraph code. those code also run during dy2stat. so some variables may be assign as a varbase (tensor) first and then variable, which raised an error. we fixed the bug in this pr by handling the case. todo: we just added testcase for the 1. shape comparison. should add test case for 2. and 3. but since we are chasing 2.0rc, i will do it in the near future pr ", "commit_messages": " fix paddlegan deoldify model layer problems, test=develop  code for python/paddle list/variable compare diff, test=develop ", "linked_issue_titles": "", "title": "fix paddlegan deoldify model dy2stat problems"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): fixes #5990 detailed description (optional): for csv input format: consider unquoted null literal as \\n (if setting format_csv_unquoted_null_literal_as_null=1) initialize null fields with default values if data type of this field is not nullable (if setting input_format_null_as_default=1) ", "commit_messages": " use default if not nullable  parse unquoted null  add tests ", "linked_issue_titles": " load data with csvwithnames or tabseparatedwithnames got error when two columns  continuous  null ", "title": "csv unquoted nulls and default values"}
{"description": " closes #39677 ml.get_calendars accepts post requests with a body but in the rest spec body was null which makes the language clients think that is not the case. correct the docs for ml.get_calendars using page parameters in the body. closes #39673 by registering the missing url for delete forecast where the forecast id is not specified. closes #39676 with a doc change in eventresource.asciidoc. ", "commit_messages": " forecast id is optional in delete forecast  make get categories with post consistent and update docs  correct docs for scheduled event time format ", "linked_issue_titles": " [ml] delete forecast : rest json inconsistency  [ml] scheduled event resources : inconsistent request parameter types  [ml] calendars api : inconsistencies in documentation / json spec ", "title": "correct small inconsistencies in ml apis spec and docs"}
{"description": " fixes #3493 a copy/paste error meant that the wrong animation was being started for scalex and scaley animations. microsoft reviewers: open in codeflow ", "commit_messages": " call startanimatiom on m_scalecombined for scalex / scaley animations  there was a copy-paste error previously that started m_translationcombined instead.  change files ", "linked_issue_titles": " animated native driver does not animate scalex or scaley ", "title": "call startanimation on m_scalecombined for scalex / scaley animations"}
{"description": " added \"--sign-with \" or \"--sign-with [ <public key 1>, <public key 2>, ... ]\" option to cleos subcommands that result in one signed transaction being sent to nodeos, skipping the step of requesting nodeos for the keys required for signing the transaction. #8199 the following cleos subcommands will now allow signing with one key (\"--sign-with \") or multiple keys ( \"--sign-with [ <public key 1>, <public key 2>, ... ]\"): \"set action permission\" \"system regproducer\" \"system unregproducer\" \"vote producer proxy\" \"vote producer prods\" \"vote producer approve\" \"vote producer unapprove\" \"system delegatebw\" \"system undelegatebw\" \"system bidname\" \"system buyram\" \"system sellram\" \"system claimrewards\" \"system regproxy\" \"system unregproxy\" \"system canceldelay\" \"system rex deposit\" \"system rex withdraw\" \"system rex buyrex\" \"system rex lendrex\" \"system rex unstaketorex\" \"system rex sellrex\" \"system rex cancelrexorder\" \"system rex mvtosavings\" \"system rex mvfromsavings\" \"system rex rentcpu\" \"system rex rentnet\" \"system rex fundcpuloan\" \"system rex fundnetloan\" \"system rex defcpuloan\" \"system rex defnetloan\" \"system rex consolidate\" \"system rex updaterex\" \"system rex rexexec\" \"system rex closerex\" \"system rex \" \"set contract\" \"set code\" \"set abi\" \"transfer\" \"push action\" \"push transaction\" \"multisig propose\" \"multisig propose_trx\" \"multisig approve\" \"multisig unapprove\" \"multisig invalidate\" \"multisig cancel\" \"multisig exec\" \"wrap exec\" ", "commit_messages": " added ability to provide the keys to sign a transfer transaction with rather than asking nodeos.  added class to handle providing keys to sign transactions with.  added option to sign sub-commands that produce one transaction.  added parameter to allow signing directly for methods that result in cleos creating actions.  refactoring changes to provide accounts instead of account names for methods that can sign. ", "linked_issue_titles": "", "title": "add option to provide transaction signature keys to cleos"}
{"description": " ucs dns server management new module pull request ucs_dns_server ansible version ansible 2.7.0.dev0 (ucs_dns_server 92f5bf79fb) last updated 2018/10/10 20:36:19 (gmt -400) config file = /users/jomcdono/.ansible.cfg configured module search path = ['/users/jomcdono/documents/src/ucs/ansible/lib/ansible/modules/remote_management/ucs'] ansible python module location = /users/jomcdono/documents/src/ucs/ansible/lib/ansible executable location = /users/jomcdono/documents/src/ucs/ansible/bin/ansible python version = 3.7.0 (default, jun 29 2018, 20:13:13) [clang 9.1.0 (clang-902.0.39.2)] ", "commit_messages": " add module for ucs dns server  updates from review  recommit for ansible pr ", "linked_issue_titles": "", "title": "add ucs dns server management module"}
{"description": " hi @antirez @madolson , now i open this pr to discuss the codes i mentioned in  #6152 , except the original problem, here are other three changes: propagate exec directly in lua script i think we don't need to use also propagate in lua, cause multi is already propagated. flag module client as client_multi if needed in case of nested multi/exec, lua script has the same problem, see details in #5780 propagte brpoplpush as rpoplpush when unblock after the expire problem is fixed, i think it's ok to do that now btw, if this pr is ok, before merge it we should merge #5780 at first to avoid nested mulit/exec when spop with count is called in lua script. ", "commit_messages": " propagation: wrap commands in also_propagate array with mulit/exec  random command like spop with count is replicated as  some srem operations, and store them in also_propagate  array to propagate after the call, but this would break  atomicity.  to keep the command's atomicity, wrap also_propagate  array with multi/exec.  propagation: propagate exec directly in lua script  propagation: flag module client as client_multi if needed  in case of nested multi/exec  block: propagate brpoplpush as rpoplpush when unblock ", "linked_issue_titles": "", "title": "wrap also propagate as multi"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " add maxfontsize and minfontsize to series that have it.  update version at top of file.  revert the formatting ", "linked_issue_titles": "", "title": "highcharts - add maxfontsize and minfontsize to series that have it."}
{"description": " with this change, github will create and publish a nuget that contains the dll's and headers needed for win32 and uwp. microsoft reviewers: open in codeflow ", "commit_messages": " first stab at moving nuget creation to github  fix typo  update copytostaging  update staging bat  more staging update  remove trailing \\ from srcroot  typo in artifact name  rework where files were put  remove react-native-windows prefix  missed ship arm  replace original publish yaml  remove accidental whitespace ", "linked_issue_titles": "", "title": "modify publish task to publish nuget"}
{"description": " others others add flags_call_stack_level to control call stack of error message if flags_call_stack_level == 0, only the error message summary will be shown.  (todo) if flags_call_stack_level == 1, the python stack and  error message summary will be shown. if flags_call_stack_level == 2, the python stack, c++ stack, and error message summary will be shown. currently, default value is 2 (show all call stack), we need to discuss whether to set default to 1 (hide c++ call stack). so the default behavior remains unchaged after this pr before  (flags_call_stack_level=2) traceback (most recent call last): file \"b.py\", line 12, in <module> result = paddle.stack([x1, x2, x3], axis=2) file \"/usr/local/lib/python3.5/dist-packages/paddle/tensor/manipulation.py\", line 361, in stack attrs={'axis': axis}) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py\", line 2794, in append_op kwargs.get(\"stop_gradient\", false)) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op not stop_gradient) paddle.fluid.core_avx.enforcenotmet: -------------------------------------- c++ traceback (most recent call last): -------------------------------------- 0   paddle::imperative::tracer::traceop(std::string const&, paddle::imperative::namevarbasemap const&, paddle::imperative::namevarbasemap const&, paddle::framework::attributemap, paddle::platform::place const&, bool) 1   paddle::imperative::preparedop::prepare(paddle::imperative::namevarbasemap const&, paddle::imperative::namevarbasemap const&, paddle::framework::operatorwithkernel const&, paddle::platform::place const&, paddle::framework::attributemap const&) 2   paddle::imperative::preparedop paddle::imperative::prepareopimpl<paddle::imperative::varbase>(paddle::imperative::details::namevarmaptrait<paddle::imperative::varbase>::type const&, paddle::imperative::details::namevarmaptrait<paddle::imperative::varbase>::type const&, paddle::framework::operatorwithkernel const&, paddle::platform::place, paddle::framework::attributemap const&) 3   paddle::framework::operatorwithkernel::getexpectedkerneltype(paddle::framework::executioncontext const&) const 4   paddle::framework::operatorwithkernel::indicatedatatype(paddle::framework::executioncontext const&) const 5   paddle::platform::enforcenotmet::enforcenotmet(std::__exception_ptr::exception_ptr, char const*, int) 6   std::string paddle::platform::gettracebackstring<char const*>(char const*&&, char const*, int) 7   paddle::platform::getcurrenttracebackstring[abi:cxx11]() ---------------------- error message summary: ---------------------- invalidargumenterror: the datatype of stack op's duplicable variable x must be consistent. the current variable type is (double), but the previous variable type is (float). at (/paddle/paddle/paddle/fluid/framework/operator.cc:1307) after (flags_call_stack_level=1) traceback (most recent call last): file \"b.py\", line 12, in <module> result = paddle.stack([x1, x2, x3], axis=2) file \"/usr/local/lib/python3.5/dist-packages/paddle/tensor/manipulation.py\", line 361, in stack attrs={'axis': axis}) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/layer_helper.py\", line 43, in append_op return self.main_program.current_block().append_op(*args, **kwargs) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/framework.py\", line 2794, in append_op kwargs.get(\"stop_gradient\", false)) file \"/usr/local/lib/python3.5/dist-packages/paddle/fluid/dygraph/tracer.py\", line 45, in trace_op not stop_gradient) paddle.fluid.core_avx.enforcenotmet: ---------------------- error message summary: ---------------------- invalidargumenterror: the datatype of stack op's duplicable variable x must be consistent. the current variable type is (double), but the previous variable type is (float). at (/paddle/paddle/paddle/fluid/framework/operator.cc:1307) ", "commit_messages": " add flags_call_stack_level  update ", "linked_issue_titles": "", "title": "add flags to control call stack of error message"}
{"description": " this pr cleans up mmdloader and adds document. changes are clean up mmdloader code and apis (more friendly to three.js manner and less polluting three.js objects) separate mmdanimationhelper from mmdloader.js add mmdloader/mmdanimationhelper documents ", "commit_messages": " change outlineeffect parameter format for serialization  separating mmdanimationhelper from mmdloader.js  clean up mmdloader  minor update of mmdphysics  update mmd examples  add mmdloader documentation  add mmdanimationhelper documentation  update docs/list.js ", "linked_issue_titles": "", "title": "mmdloader clean up and document"}
{"description": " bug fixes others 1. support dy2stat error message when call paddle.jit.save before: when call paddle.jit.save(...), if exception is raised in dynamic-to-static, the exception is python native exception and not the optimized dy2stat exception. 2. polish error message 2.1 the original dygraph code is marked with (* user code *) ; 2.2  \"in user code:\" -> \"in transformed code:\" for example: ", "commit_messages": " [dynamic-to-static] support dy2stat error message when call jit.save;  add tests for error flags and for disable flags  polish dy2stat error message: (1)add flag (* user code *) for original dygraph code; (2) \"in user code:\" -> \"in transformed code:\" ", "linked_issue_titles": "", "title": "support dy2stat error message when call jit.save and polish error message"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " chore(snowflake-sdk): re-lint type definitions  feat(snowflake-sdk): add snowflakeerror interface, errorcode enum ", "linked_issue_titles": "", "title": "add error interface, error code enum for snowflake-sdk"}
{"description": " the transform matrices were all wrong previously. so i split the part where the the dictionary and streams are read and the part where the pattern is calculated. basically the pattern is set right before a fill or stroke. ", "commit_messages": " git radial gradients working  changed linear gradients  fixed gradients, need to work on tiling  patterns working  fixed tiling patterns  cleanup, add support for stroking  cleanup ", "linked_issue_titles": "", "title": "fix to gradient and tiling colorspaces"}
{"description": " basic bsdfs meshstandardmaterial -> roughnessnode, metalnessnode,  normalnode simplification of nodebuilder code generator and depedencies (biggest update of this pr) normalmap support 30+ math functions to mathnode colorspacenode all three.js encoding functions (automatic use in texturenode) temporary variable system: tempnode structnode support new lightcontext ( more generic ) expressionnode for inline code webgpu - selective lights  // physicallightingmodel example // reflectedlight use the same standard native of threejs const glslcode = void ( inout reflectedlight reflectedlight, vec3 lightdirection, vec3 lightcolor ) { re_direct_physical( reflectedlight, lightdirection, lightcolor ); } const physicallightingmodel = new functionnode(  glslcode   ).setincludes( [ re_direct_physical ] ); ", "commit_messages": " new nodematerial system updates  update custom lighting model example ", "linked_issue_titles": "", "title": "basic bsdfs of meshstandardmaterial and nodebuilder simplification"}
{"description": " the tests would occasionally fail on slower machines due to the nodes being out of sync. this changes here explicitly validate that the nodes state matches expectation. also refactored the test code into reusable classes. ", "commit_messages": " refactored test methods into helper classes for easier reusability. use transaction id validation to make a lot of the api calls more deterministic.  refactor python test code into reusable classes. add additional options to restart script. user can specify kill signal as well as kill count.  revert comment deletion.  add documentation. update run_tests script to output test config and stderr log in error scenario. ", "linked_issue_titles": "", "title": "improve transaction synchronization in tests stat301"}
{"description": " bug fix (user facing) code base improvement (dev facing) add fast rewind / fast forward in backgroundplayeractivity (activity where you manage videos playing in background) honestly, 9 icons in one row is maybe too much? we could move shuffle and repeat upward. and we could remove (one of) playbackspeedbutton/playbackpitchbutton, since they both do the same. fixes #2722 agreement i carefully read the contribution guidelines and agree to them. ", "commit_messages": " add fast-rewind/forward buttons in layout  add listeners in activity ", "linked_issue_titles": " fast forward/rewind buttons in background mode ", "title": "fast rewind forward in background activity"}
{"description": " fixed a portion of failing tests after introducing numpy compatible shapes. added a thread-safe switch to turn on/off numpy compatibility. by default, it's off and existing tests should not be affected. @junrushao1994 @szha @eric-haibin-lin @zheng-da @yzhliu ", "commit_messages": " fix infer shape rnn  fix boolean mask and custom op unit tests  fix multi proposal  fix diag  add global switch for backward compatibility and fix infer shape bugs  fix slice op infer shape ", "linked_issue_titles": "", "title": "fix unit tests after introducing numpy compatible shapes"}
{"description": " currently, opening large files takes a long time. most of the time is spent tokenizing the lines and computing the screen lines (accounting for soft-wraps, etc). because of a small logic error, this was all happening twice, every time we opened a file. these flame graphs are for opening an example 2.3mb javascript file (jquery 2.0.3, concatenated 10 times). before opening the file took about 8.2 seconds. the span of time between the two red arrows is unnecessary work. after no more duplicated work. opening the file took about 3.2 seconds. ", "commit_messages": " allocate fewer objects for fold attributes in displaybuffer  avoid double computation of screen lines when opening files  previously, instantiating a texteditor would always compute compute  screen lines twice: once when the displaybuffer was instantiated,  and once when the 'invisibles' property was set on the displaybuffer. ", "linked_issue_titles": "", "title": "improve performance of opening files"}
{"description": " if this pull request closes/resolves/fixes an existing issue, replace the issue number. closes #7230 . update the changes log. ", "commit_messages": " add some new thread metric and class metric to jvmmetric(#7230)  update protocol (#7230)  update metrics name (#7230)  add benchmark for classmetrics and threadmetrics (#7230)  update scope-definitions.md (#7230) ", "linked_issue_titles": " add some new thread metric and class metric to jvmmetric ", "title": "add some new thread metric and class metric to jvmmetric (#7230)"}
{"description": " description this pr migrates the doc's breadcrumbs page to hooks. relates to #15032. this is not ready for merge yet, since i have encountered some difficulties with typescript definitions in customizedbreadcrumbs (lines 12 and 44) and routerbreadcrumbs (lines 29 and 82). i didn't get what should be the type of props, when it does not extend withstyles i have followed (at least) the pr section of the contributing guide. ", "commit_messages": " [docs] migrate collapsedbreadcrumbs to hooks  [docs] migrate customseparator to hooks  [docs] migrate customizedbreadcrumbs to hooks  [docs] migrate iconbreadcrumbs to hooks  [docs] migrate routerbreadcrumbs to hooks  [docs] migrate simplebreadcrumbs to hooks ", "linked_issue_titles": "", "title": "migrate docs' breadcrumbs page to hooks"}
{"description": " since c++17 is supported now in envoy, we can concisely replace the uninformative .first/.second variables with better names to improve readability. this belongs to a more expansive effort referenced here #12354. risk level: low, only cosmetic change is introduced testing: all existing tests passed ", "commit_messages": " subject: replacing .first/.second with meaningful names  changed a naming  more name changes ", "linked_issue_titles": "", "title": "replacing .first/.second with meaningful names [envoy/include and miscellanies in envoy/source/common]"}
{"description": " for use in windows shells that are bash-like. closes #4586 ", "commit_messages": " add initial windows atom wrapper script  use $0 instead of %~dp0  add .sh extension  install atom.sh shim ", "linked_issue_titles": " include bash launch scripts in /bin/ with the windows installer ", "title": "add atom.sh and apm.sh windows scripts"}
{"description": " also updates to react-transform-hmr and handles some issues with it's throwing behavior. closes #643 & addresses comments on #690 ", "commit_messages": " update to renamed react-transform-hmr.  switch universal example to webpack-dev-middleware.  better concurrent start script. ", "linked_issue_titles": "", "title": "use webpack-dev-middleware in universal example"}
{"description": " summary this change adds the material 3 text style names to the texttheme api. it includes renames of all 2018 text styles and the introduction of 2 more styles for a total of 15. the 2018 names will be deprecated later on, once material 3 is fully implemented. part of #89853 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making, or this pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " add m3 text style names to text theme  update typography constructors to use new text style names  update typography tests  update text theme tests ", "linked_issue_titles": "", "title": "update texttheme to have m3 names for styles"}
{"description": " first, cleans things up by moving all the seen_datetime and seen_integer variables to the tops of their respective blocks. mainly splits the try: block for string_to_dts up into two pieces based on the two lines in that block that could raise and handles errors more specfically. ", "commit_messages": " set seen_foo at the top of the inning  catch exceptions in better order ", "linked_issue_titles": "", "title": "order of exceptions in array_to_datetime"}
{"description": " this mostly touches the first section of the docs. i also added some stuff to the rllib training docs to extend the table of contents. ", "commit_messages": " fixes  reorder pages  cluster launcher  rename  update  clean up pages  remove outdated internal  some rllib fixes  model  model summary  update  update ", "linked_issue_titles": "", "title": "consolidate and clean up documentation"}
{"description": " this pr changes it so we a) use globalthis to reference the global scope in internal code and b) we define global runtime variables in globals.ts in a more supportable fashion. ", "commit_messages": " use globalthis for global scope access.  cleanup defining globalthis properties ", "linked_issue_titles": "", "title": "use globalthis to reference global scope"}
{"description": " as we're working through more feature detects in #509 we're missing from ringmark, here's another for blobbuilder. this can be updated to use the modernizr.prefixed(\"blobbuilder\",window); syntax once #495 lands. ", "commit_messages": " adding blobbuilder feature detect test  revision to include support for moz ", "linked_issue_titles": "", "title": "adding feature detect test for blobbuilder"}
{"description": " closes #39203 tests added / passed ensure all linting tests pass, see here for how to run them i didn't add a whatsnew entry since it's only style fixes. i'll open a new issue regarding @jreback suggestion to ban this with a precommit style rule. i prefer it to be done in a different pr. ", "commit_messages": " style: remove use in pd.api.dtype in test_ufunc.py (#39203)  style: remove use in pd.api.dtype in test_integer.py (#39203)  style: remove use in pd.api.dtype in doc-string in inference.py (#39203)  style: remove use in pd.api.dtype in json/array.py (#39203)  style: remove use in pd.api.dtype in test_floating.py (#39203)  style: remove use in pd.api.dtype in list/array.py (#39203)  style: remove use in pd.api.dtype in dtype.py (#39203)  style: remove use in pd.api.dtype in test_bool.py (#39203)  style: remove use in pd.api.dtype in reshape.py (#39203)  style: remove use in pd.api.dtype in arrow/arrays.py (#39203)  style: remove use in pd.api.dtype from doc-string and add import in generic.py (#39203)  style: remove use in pd.api.dtype in decimal/array.py (#39203)  style: remove extra line (#39203)  style: run precommit hook to fix import locations (#39203) ", "linked_issue_titles": " style: dont' use pd.api.types anywhere in tests ", "title": "dont use pd api types in tests"}
{"description": " fix pie label layout in multiple cases. here are some of the typical cases: a. plain text cannot control wrapping and may be displayed outside of the canvas (left: before; right: after) b. the distances between labelline and labels are not correct due to the width calculation c. the background area of rich text is not correct d. line width of rich text is not correct e. when the text width is explicitly set, rich text area breaks the width constraint. most of the problems relates to text bounding rect calculation and this pr also fixes related logic with pie charts. a full list of changes are listed in the \"view visual test result\" part of this pr. #16023 this pr depends on zrender changes (ecomfe/zrender#847). test/pie-label-alignto-adjust.html please squash the commits into a single one when merge. run visual test of pie charts. ", "commit_messages": " fix(pie): label position with rich text #16023  test(pie): add test case ", "linked_issue_titles": " pie chart rich labels overflow ", "title": "label layout and text wrapping"}
{"description": " @rocketchat/core closes #4315 removed unnecessary sizes and removed android icons from meta tags (android icons are requested by manifest.json) ", "commit_messages": " normalize favicons, tiles and touchicons  fix browserconfig identation  add favicon svg ", "linked_issue_titles": " wrong favicon are shown in some browsers ", "title": "fix favicons, tiles and touchicons"}
{"description": " @quval requested a cherrypick for 4.2.0 (#13558) to bring in the fixes for the \"test\" exec group inheritance (see #13459 and related commits). commits: 1e258d2 d067669 f1e0d34 8186fbb dcceaa3 68effbe e35aedf b9519f9 52b1b74 627c16e b120d4f 64534e2 9b18d95 762b5d8 a116649 afba8ac 645c42b ", "commit_messages": " allow exec groups to inherit from the rule or other exec groups.  work towards #12006.  add a \"test\" exec group for testrunneractions. this will allow users to set {\"test.key\", \"value\"} inside their exec properties and {\"key\", \"value\"} will propagate as to just testrunneractions.  this addresses user request #10799  this is a rollforward of c1ae939e2e27c928dc87ca64280948d93fdb056a, which  was reverted in c266ac966761c4b3d8a408a03e407505c93effdd.  closes #13119.  piperorigin-revid: 360168649  support execution constraints per exec group  when computing exec properties from the execution platform for an action, take into account only the properties that are relevant to the action's exec groups. in particular, allow setting exec properties for arbitrary exec groups on platforms. previously, any such properties were rejected.  with this change, the following becomes possible:    cc_test(  name = \"my_test\",  ...,  exec_properties = {  \"test.key\": \"value\",  },  )    this will apply {\"key\": \"value\"} for the test-runner action only (i.e., compilation and linkage won't be affected). the following also becomes possible:    platform(  name = \"test_platform\",  constraint_values = [\":test_constraint\"],  exec_properties = {  \"test.key\": \"value\",  },  )  cc_test(  name = \"my_test\",  ...,  exec_compatible_with = [\":test_constraint\"],  )    this achieves the same in a more succinct way.  for related discussion, see pr #12719 by @ulfjack.  closes #13110.  piperorigin-revid: 361167318  clean up rulecontext to use a table instead of a map of maps.  closes #13164.  piperorigin-revid: 361216667  documentation for #13110  closes #13167.  piperorigin-revid: 361885312  split execgroup into a new target.  piperorigin-revid: 372342357  create a new interface to allow starlark objects to get a thread when getindex is called.  piperorigin-revid: 367454604  renamed execgroupcollection to clarify that it is only for starlark usage.  non-starlark usage can go via the toolchaincollection directly.  piperorigin-revid: 367461392  make starlarkexecgroupcontext use autovalue.  this gives reasonable equals and hashcode behavior.  piperorigin-revid: 367493368  use a dummy toolchain context for rules that don't have one.  fixes #12610.  closes #13162.  piperorigin-revid: 361545255  extract a separate starlarktoolchaincontext for starlark-only operations.  also make toolchaincontextapi use starlark threads.  piperorigin-revid: 367515900  fix toolchains to support type lookup.  fixes #13320.  piperorigin-revid: 367624002  move default_exec_group_name from toolchaincollection to execgroup.  piperorigin-revid: 372342837  rename toolchaincollection.getexecgroups to getexecgroupnames.  piperorigin-revid: 372343218  buildviewfortesting should directly call into configuredtargetfunction.  previously it was trying to replicate the code, but wasn't exact.  piperorigin-revid: 372343711  move exec group tests out of platforms_test and into integration.  piperorigin-revid: 372383546  update creating exec groups that explicitly copy from defaults.  also add an execgroupsubject to improve testing.  piperorigin-revid: 372387338  create a new execgroupcollection container to manage exec group inheritance and exec property parsing.  fixes #13459.  piperorigin-revid: 373388266 ", "linked_issue_titles": "", "title": "cherrypick request for 4.2.0: exec group changes"}
{"description": " merging commits that went to rc but skipped rcbugfix. ", "commit_messages": " update readme.md  * description for rc5  * hint for deprecated arduino versions  update readme.md  oops! at least 1.6.0  follow-up to commit 200b248(update readme.md)  follow-up to commit 200b2487c2dfb1a5160c0974d2b7c6f2e54719ee  update release date in another place ", "linked_issue_titles": "", "title": "merge rc => rcbugfix changes since rc5"}
{"description": " this pr improves the registerguest method, allowing to pass the name of a livechat department as parameter, not only the department id. now the department value is checked before saving into guest document, finding for a valid department by both id and name property. ", "commit_messages": " improvements on set livechat department by name, ", "linked_issue_titles": "", "title": "set livechat department before register guest"}
{"description": " #129 this was a refactor to handle adding new 64k pages when existing heaps are used up.  i still have questions for @bytemaster on issue, so to complete this i just added some extra memory to _initial_heap and point to it.  that will be removed when the questions get answered. also, #481 is fixed and at least part of #425 . ", "commit_messages": " fixed to correctly find the end of the memory.  fixes bug #481, and is part of #425.  added new tests to verify the logic for adding memory pages.  improved comments to make it easier to identify where errors occur.  refactored existing handling of malloc and realloc to add new pages of memory.  currently, memory pages are fabricated.  added more test cases, better comments, and cleaned up. ", "linked_issue_titles": "", "title": "wasm memory refactor to add more memory"}
{"description": " i added some code to make the android emulator read glsl files correctly by making the data types constant for uniform variables. if the android emulator cannot read the data types of the variables, it will say opengl error 0x501 or 0x502 gluniform unable to find uniform variable depth. other variables will be affected after depth. with this bugfix, the variables will be read correctly by the android emulator and render your game. i removed too much lines earlier including the original lines for winrt and have placed those back with the bugfix. i needed to remove the earlier pull request to avoid confusion. ", "commit_messages": " android emulator bugfix for 0x501 and 0x502 opengl errors  android emulator bugfix for 0x501 and 0x502 opengl errors changed comment spelling.  android emulator bugfix for 0x501 and 0x502 opengl errors correction.  android emulator bugfix for 0x501 and 0x502 opengl errors correction in code.  android emulator bugfix for 0x501 and 0x502 opengl errors correction in code spacing.  android emulator bugfix for 0x501 and 0x502 opengl errors correction in code spacing. ", "linked_issue_titles": "", "title": "android emulator blank screen 0x501 and 0x502 problem bugfix update"}
{"description": " this is mostly improving the spec test suite support (with this, the only unimplemented assertion types are \"invalid\" and \"malformed\", which can't be implemented until we have a wast parser). this also fixes some other bugs encountered on the way. ", "commit_messages": " tests/libwasm: add support for javascript bigint values  some i64 values will not fit in normal doubles, and these values _are_  tested by the test suite, this makes the test runtime capable of  handling them correctly.  meta: generate bigints for i64 values in libwasm test suite files  libwasm: implement fx.nearest using nearbyint() instead of round()  this instruction wants roundingmode::toeven, so let's use the correct  function.  tests/libwasm: handle all stream errors in parse_webassembly_module  meta: implement support for the \"unlinkable\" wasm spectest assertion  libwasm: make the truncate operator trap on undefined results ", "linked_issue_titles": "", "title": "yet another bag of fixes"}
{"description": " hopefully this the final fix for #848 @skalot i think i found a way to record all inlined classes. i am not sure if the way i have chosen is what you had in mind. therefore consider this pr as a base for discussion. ", "commit_messages": " fix: additionally show smali code of all inlined classes (recursively)  variable name corrected ", "linked_issue_titles": "", "title": "record inlined classes and also generate smali code for them"}
{"description": " some package repositories which require basic http authentication include the user's credentials in urls returned as part of json responses. because poetry's request authentication system checks for a matching netloc, this ends up breaking basic http authentication for such repositories. this pull request compares by hostname instead of netloc. because hostname doesn't include any extra url authentication information, this fixes access to these repositories. this fixes issue #746. ", "commit_messages": " fix authentication failure for some apis  fixes an issue which occurs when apis return authentication information in the urls embedded in json responses.  test authentication on same host with duplicated credentials  add test to ensure that basic authentication credentials in request urls does not break authentication when they credentials match. this test purposefully does not examine program behavior when url credentials and session credentials are different. ", "linked_issue_titles": "", "title": "fix request authentication when credentials are included in urls"}
{"description": " added a via layout for the frosty flake controller for the coolermaster quickfire rapid. not sure if anyone still has this keyboard, but i had one laying around and i wanted to see if i could port it to via. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " updated my personal layouts  added artix to install script  setting up for pr  added artix to install script  created frosty flake via keymap.c  created the default via keymap.c file for the frosty flake controller  created frosty flake via keymap.c  create rules.mk  add #define dynamic_keymap_layer_count 3  update keymap.c  delete keyboards/tada68/keymaps/trashcat directory  create keymap.c  create readme.md  create rules.mk  delete keyboards/whitefox/keymaps/trashcat directory  update qmk_install.sh  rename readme.md to readme.md ", "linked_issue_titles": "", "title": "adding frosty flake via keymap"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. ", "commit_messages": " adding .d.ts for the tress library  removing dev additions from the package.json ", "linked_issue_titles": "", "title": "type definitions for the tress library"}
{"description": " description: add missing documentation for addon_restart and addon_stdin for hassio integration in services.yaml file. i took the opportunity to reformat all the file in full yaml checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist ", "commit_messages": " add services doc  add missing services doc and reformat ", "linked_issue_titles": "", "title": "add missing documentation for some hassio services"}
{"description": " reference: #20687 added a new section \"data considerations\" in sklearn/datasets/descr/twenty_newsgroups.rst. the previous pr failed due to formatting errors. fixing them too. this is my first contribution to a public repo. please bear with me for the errors. ", "commit_messages": " added data considerations for explaining the dataset language  add data considerations section to the descrition of twenty_newsgroups datasets  fix the pull request errors  fix the pull request errors  fix the pull request errors url ", "linked_issue_titles": "", "title": "doc add a note for some data considerations with 20newsgroups dataset"}
{"description": " fixes #3236. if your type argument inference source is a primitive or a type parameter, we don't use the apparent type to get its structure to dive deeper. this change gets the apparent type for better inference. ", "commit_messages": " take the apparent type of the source in type argument inference  add tests ", "linked_issue_titles": "", "title": "take the apparent type of the source during type argument inference"}
{"description": " @carltongibson it looks like an update to the security release archive was missed. i've checked the release process in case it was missing and something needed amending, but i did find it here as point 3. hope these commits do the trick. they will need backporting as appropriate. ", "commit_messages": " added cve-2019-11358 to the security release archive.  added cve-2019-12308 to the security release archive. ", "linked_issue_titles": "", "title": "updated security release archive with missing entries."}
{"description": " see #1330 support metaspacesize and maxmetaspacesize  in java8+ in linux and windows i use shell or batch to get java version by java -fullversion, you can see it in commit. in the commit ,you can find i use java_8_version=\"180\" to compare java vesion. the reasion is that java version naming rule change in java 9. java -fullversion output example in jdk1.7 -> java full version \"1.7.0_79-b15\" in jdk1.7 -> java full version \"1.8.0_152-b16\" in jdk9 -> java full version \"9.0.4+11\" i find many dos symbol in start.sh, if you run start.sh in linux, it may be a problem. i use dos2unix cmd to format the file. test result in windows jdk9 jdk1.8 jdk1.7 ", "commit_messages": " fix [set vm args by different java version] fix #1330  fix [set vm args by different java version] fix #1330  fix [set vm args by different java version] fix #1330  fix [set vm args by different java version] fix #1330  fix [set vm args by different java version] fix #1330 ", "linked_issue_titles": "", "title": "fix support metaspacesize and maxmetaspacesize vm args in java8+"}
{"description": " this pull request adjusts the visual testing with storybook documentation to be more accurate and streamlined. it follows up on #31653 that was recently merged. what was done: the documentation was polished to include more accurate instructions on how to set up storybook with gatsby. the example story was updated to a more accurate example. @meganesu, @lekoarts if you could follow up with me on this i'd appreciate it. thanks in advance! stay safe ", "commit_messages": " update gatsby fork for further fixing errors on the starter submission  april update gatsby fork  april update fork  august update  updates for the storybook documentation ", "linked_issue_titles": "", "title": "update storybook guide with addon"}
{"description": " closes #18601. sub-modules, such as np.linalg, must be explicitly imported in the main namespaces' stub file if one wants to access the sub-module via a getattr operation, i.e. so that one can directly use np.linalg.norm rather than import numpy.linalg; np.linalg.norm. while this was taken care of in the main numpy namespace, the relevant annotations were missing for others such as np.lib.*. this pr fixes aforementioned issue. examples the behavior prior to this pr: >>> import numpy as np >>> x = np.arange(6) >>> out = np.lib.stride_tricks.sliding_window_view(x, 3) mypy output: test.pyi:4:7: error: module has no attribute \"stride_tricks\"  [attr-defined] ", "commit_messages": " api: formally classify np.lib.stride_tricks as part of the public api  with as_strided, and the newly introduced sliding_window_view function, there are currently 2 public objects that can:  a. only be imported from a private module  b. are publicly documented to-be imported from aforementioned module  both observations are problematic and in need of rectification.  this commit therefore moves np.lib.stride_tricks to the public_modules list.  maint: re-export a number of sub-modules  ensures that type checkers will allow the likes of:  >>> import numpy as np  >>> out = np.lib.stride_tricks.sliding_window_view(...) ", "linked_issue_titles": " annotations don't import np.lib.* ", "title": "ensure that re-exported sub-modules are properly annotated"}
{"description": " closes #34297 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff @jbrockmendel i added a lenght check as suggested by you. i could not find another method to check the indices (nlevels for example does not work). i'm open to recommendations about adding additional checks before running into the values call. i have added a test, which measures the execution time of both calls to sub. is there a better way to test, if they are equally fast? ", "commit_messages": " add additional checks if arrays are equal to avoid costly function call  add test to check performance  run black pandas and delete one check  add list comprehension ", "linked_issue_titles": " bug: subsequent calls to df.sub() are much faster than the first call ", "title": "34297 sub slow in first call"}
{"description": " this is the final pr in the stack of #1185, #1169, #1151, and #1117 that modify zstd's compression strategies to allow searching an independent, immutable dictionary context. this pr extends support to the zstd_btopt and zstd_btultra levels. two further work items are planned (in separate prs): improve the heuristic that controls when to attach a dictionary vs when to copy it into the working context. provide a user-accessible override of that heuristic to allow forcing / disallowing attaching the dictionary. ", "commit_messages": " attach dicts when using zstd_btopt and zstd_btultra  convert extdict flag to dictmode enum  add _dictmatchstate functions  implement repcode check  switch != zstd_extdict to == zstd_nodict  fix typo  find mls == 3 matches  misc fixes  find proper matches  misc changes  fix compression ratio regression #1  make sure position 0 gets into the tree ", "linked_issue_titles": "", "title": "support searching the dictionary context in-place"}
{"description": " the preload attribute specifies a script that will be loaded before other scripts run in the guest page, this script always has access to node apis no matter whether node integration is on in guest page. fixes #776. ", "commit_messages": " pass \"preload\" attribute to guestviewmanager  load the \"preload\" script in <webview>  spec: \"preload\" attribute of <webview>  docs: \"preload\" attribute of <webview> ", "linked_issue_titles": " webview ipc unavailable without node integration ", "title": "add \"preload\" attribute for <webview>"}
{"description": " this exposes the torch distributed optimizer settings by adding it as the top level \"ddppo\" trainer. closes #6636 ", "commit_messages": " wip  lint  stats  update  doc it ", "linked_issue_titles": " any plans to support decentralized distributed ppo? ", "title": "add decentralized ddppo trainer and documentation"}
{"description": " i hereby agree to the terms of the cla available at:  fix error output of treeexecutor is not sorted for optimize deduplicate. fixes #11572 ", "commit_messages": " remove sortdescription from iblockinputstream.  added test. ", "linked_issue_titles": " output of treeexecutor is not sorted after optimize final deduplicate ", "title": "remove sort description from streams"}
{"description": " this pr fixes a bug that made the ordering of nodeids values to be lost. the order in which the node filters are specified is important as it dictates which nodes are being kept and which not in the list for which the metrics are retrieved. fixes #41885. ", "commit_messages": " switch to using a list instead of a set for the filters, so that the  order of these filters is kept. ", "linked_issue_titles": " nodes types filters order not kept for _nodes api ", "title": "prevent order being lost for _nodes api filters"}
{"description": " implements the community id hash that will allow correlating network connections detected by osquery with other tools that support the standard (zeek, suricata, etc.). add boost endian library refactor core hashing utility to allow base64 encoding (backwards compatible) implement community id thanks to @security-onion-solutions for supporting development of this feature. ", "commit_messages": " semi-working, needs ordering  add ordering  working with tests  add docs  remove debug print  format  update doc ", "linked_issue_titles": "", "title": "add community_id_v1 hash function to sqlite"}
{"description": " doing so unconditionally breaks standalone + autodebug. this has to move some emcc.py code to decide if we need to legalize to an earlier place, so we know that when we do the autodebug stuff as part of the binaryen passes. also_with_impure_standalone_wasm has to use bigint support while doing the \"impure\" part. in that mode we test standalone but not in a wasm vm, rather in a js vm. so we don't legalize, but we do connect to js. without bigint, we would trap on i64s. ", "commit_messages": " fix legalization of autodebug with standalone mode [ci skip]  fix + test ", "linked_issue_titles": "", "title": "only legalize as part of autodebug if we should do so"}
{"description": " add or edit tests to reflect the change. (run with npm test.) run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " feat: react hooks helper types  fix: react hooks helper test ", "linked_issue_titles": "", "title": "types for npm package: react-hooks-helper"}
{"description": " when searching issues, the snuba backend will use postgres results to filter on message. this pr removes this functionality, and we now use snuba for filtering on messages. ", "commit_messages": " removing postgresql query filter on message  first draft of removing message related queries on postgres ", "linked_issue_titles": "", "title": "make message queries use snuba instead of postgres"}
{"description": " this pull request adds a default onfullfilled/onrejection handler to remote promises so that unhandled rejections of remote promises appear in the renderer process instead of the main process. also adds some var -> const/let formatting to rpc-server.js. closes #6113 ", "commit_messages": " add failing spec for unhandled main process exception  remove unused return  use let/const instead of var  add spec for unhandled rejection in renderer process  prevent unhandled rejection defaul  use once instead of on  add default fulfilled/rejection handler to promise ", "linked_issue_titles": "", "title": "add default error handler to remote promises"}
{"description": " kafka-12541 introduced a regression for listoffsets requests for non maxtimestamp specs. when communicating with old brokers. this pr addresss this case. tested with new unit test for regression case. ", "commit_messages": " kafka-12541 add max_timestamp spec to listoffsets api  kafka-12541 updated replica fetcher to use latest listoffsets request version  kafka-12541 refactor with retry approach in kafkaadminclient  kafka-12541 added logoffsettest tests  kafka-12541 tidy up  kafka-12541 fixes per pr review  kafka-12541 adminclient simplification  kafka-12541 refactor of listoffsets retry per pr review comments  kafka-12541 fixes per pr review  kafka-12541 stopped retries for partitions that cannot use max_timestamp  kafka-12541 roll back changes to requestresponsetest  kafka-12541 fixes per pr review  kafka-12541 fixes per pr review  kafka-12541 fixes per pr review  kafka-13002 fix for immediate downgrade cases for non max timestamp requests ", "linked_issue_titles": "", "title": "listoffsets must downgrade immediately for non max_timestamp specs"}
{"description": " closes #33562 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry the problem with above issue was with the function non_reducing_slice. it didn't correctly re-format slicing tuples on multiindices when rows or cols also contained a slice(none). an additional check is now done. this method is only used for styler currently. tests added / reformmatted. ", "commit_messages": " tst: edited and expanded for latest issue  bug: subset non-reducer  bug: subset non-reducer  bug: subset non-reducer ", "linked_issue_titles": " bug: df.style.apply(subset=...) argument only works for explicit slices but not \":\" ", "title": "subset slicer on styler failed on multiindex with slice(none)"}
{"description": " backport of #14360. addresses part of gh-14359 todo / to decide: there's still two namespaces left that look private: numpy.random.entropy (contains random_entropy and seed_by_array, unclear if those need to be public) numpy.random.bit_generator (contains only bitgenerator as a public object i think) ", "commit_messages": " doc: fix doc linking, was referencing private submodules.  closes gh-14359  doc: address last comment on numpy.random doc page fixes pr ", "linked_issue_titles": "", "title": "random: fix doc linking, was referencing private submodules."}
{"description": " these enhancements were discussed before at ", "commit_messages": " enh: enhance meshgrid to generate 3d grids, sparse grids, matrix indexing.  maint: clean up docstring and some minor items in meshgrid.  remove ndgrid.  bug: meshgrid: raise error on single input.  tst: meshgrid: test expected shapes for cartesian and matrix indexing. ", "linked_issue_titles": "", "title": "meshgrid enhancements (>2-d, sparse grids, matrix indexing)"}
{"description": " i started to use the pubnub type definitions, but i needed to call the set of methods i have added. i've had a forked copy of this file in my codebase for a few months, so i wanted to merge it in here so i can remove the file from my code. i was referencing pubnub@4.25.2, which is the latest version. i don't know if there are other things still missing from the types here, but i only focused on adding the ones i needed. provide a url to documentation or source code which provides context for the suggested changes:  if this pr brings the type definitions up to date with a new version of the js library, update the version number in the header. (i was referencing 4.25.2, but i'm only adding the parts i need and not checking everything.) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add type definitions for channelgroup methods to pubnub type definitions  fix the code formatting after husky configs butchered it  add tests  check in auto-formatted code ", "linked_issue_titles": "", "title": "add channelgroup type definitions to pubnub types"}
{"description": " checklist add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). reason for changes documentation for ontransitionstart available here. i recognise that on this same page the documentation for ontransitionend does not support my change, but please refer to my issue here as i believe that documentation is incorrect. increase the version number in the header if appropriate. i don't believe it is appropriate if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. changes are minor ", "commit_messages": " react-navigation ontransition prop passing  only transition start takes a promise ", "linked_issue_titles": "", "title": "react-navigation ontransition event pass props"}
{"description": " hi, sorry i am not sure if you are expecting from me to write something into the message or just to be sure to fill everything in my pr from this message.  hope the second one. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. ", "commit_messages": " types for osmosis node module  repair linter errors ", "linked_issue_titles": "", "title": "adding new type for osmosis module"}
{"description": " added some new extension points (also see screenshots): query view and source pages: ability to add extra actions in page header dashboard page: ability to add extra actions in page header query and dashboard list pages: ability to add a toolbar with actions that will be rendered above the table. toolbar component should call onstatechange to notify parent that it's available, in that case page will allow to select items in the table and pass selection to the toolbar component. example of the toolbar component: function extraactionscomponent({ selecteditems, onstatechange }) { useeffect(() => { onstatechange({ isavailable: true }); }, [onstatechange]); return <button disabled={selecteditems.length === 0}>very useful button</button>; } ", "commit_messages": " extra actions for query view and query source pages  convert queries list page to functional component  convert dashboards list page to functional component  extra actions for query list page  extra actions for dashboard list page  extra actions for dashboard page ", "linked_issue_titles": "", "title": "extra actions on queries and dashboards pages"}
{"description": " cherrypicked from: ebdf78d backport pr for check point unit tests for the following module from pr #62216: test_cp_mgmt_access_layer.py test_cp_mgmt_access_layer_facts.py test_cp_mgmt_access_role.py test_cp_mgmt_access_role_facts.py test_cp_mgmt_administrator_.py test_cp_mgmt_administrator_facts.py test_cp_mgmt_application_site.py test_cp_mgmt_application_site_facts.py test_cp_mgmt_application_site_catagory.py test_cp_mgmt_application_site_catagory_facts.py test_cp_mgmt_application_group.py test_cp_mgmt_application_group_facts.py test_cp_mgmt_dns_domain.py test_cp_mgmt_dns_domain_facts.py test_cp_mgmt_dynamic_object.py test_cp_mgmt_dynamic_object_facts.py test_cp_mgmt_exception_group.py test_cp_mgmt_exception_group_facts.py unit tests pr check_point ", "commit_messages": " changelog  forth pr 18 tests (#62216)  * update test_cp_mgmt_network.py  * 18 tests  (cherry picked from commit ebdf78d6e43fb20e1f70bd0f59f05922bcc19770) ", "linked_issue_titles": "", "title": "backport pr for check point unit tests for the following module from pr 62216"}
{"description": " currently stat descriptions are single line forcing the scrollbar. so every time we need to read, we need to scroll a lot to get to the full description. this pr adds a css that allows us to split and align lines correctly. risk level: low testing: manual verification of docs docs changes: n/a release notes: n/a ", "commit_messages": " fixed server stats docs  fix comment  fix comment  new css added  css folder  multi line changes  resolved conflicts  stats merged  changed cluster and http con mgr stats ", "linked_issue_titles": "", "title": "css to support multiline descriptions in stats"}
{"description": " i have followed (at least) the pr section of the contributing guide. related to #16947 ", "commit_messages": " docs: migrate variant anchorplayground demo to emotion  docs: migrate variant basicpopover demo to emotion  docs: migrate variant mousepopover demo to emotion ", "linked_issue_titles": "", "title": "migrate popover demos to emotion"}
{"description": " adds: a basic, incomplete implementation of array.from() a basic, incomplete implementation of date.tolocalestring(), date.tolocaledatestring(), date.tolocaletimestring() a mostly-working implementation of node.textcontent also slightly simplifies the clock menuapplet. ", "commit_messages": " libjs: implement basic functionality of array.from()  the optional 2nd and 3rd arguments are not yet implemented.  this assumes that this is the array constructor and doesn't yet  implement the more general behavior in the es6 spec that allows  transferring this method to other constructors.  libjs: add tolocalestring(), tolocaledatestring(), tolocaletimestring() to date  these just return a \"readable\" implementation of the date for now.  clock menuapplet: use core::datetime to simplify the code  libweb: add node.textcontent  this requires moving remove_all_children() from parentnode to  node, which makes parentnode.cpp empty, so remove it.  it also co-opts the existing node::text_content() method and  tweaks it slightly to fit the semantics of node.textcontent. ", "linked_issue_titles": "", "title": "implement various javascript and dom things."}
{"description": " closes #13889 ", "commit_messages": " tst only report coverage on pylatest_conda  tst only one instance  combine with append  rev enable all tests  rev remove ls ", "linked_issue_titles": " coverage on pandas not being reported to codecov ", "title": "fixes coverage reporting on pylatest_conda"}
{"description": " hi, i would like to suggest a \"frequent\" bloggers sections to be added to the list of resources. people interested in staying up-to-date with the latest news and tips&tricks provided by developer blogs can simply add the blogs to their rss readers. a separation could be made between official blogs and community driven blogs (developer blogs). kind regards ruben ", "commit_messages": " added frequent bloggers of react native.  added two official react native blogs ", "linked_issue_titles": "", "title": "add bloggers section to list of react native resources"}
{"description": " this updates the alert details page sidebar for the change alerts. if it's a change alert we show comparison scheme in writing and a more descriptive threshold description for other alerts. also added actions for critical and warning thresholds based on the new design. also removed the threshold lines for change alerts. old (same for change/non-change alerts): new (non-change alert): new (change alert): jira: wor-1450 ", "commit_messages": " new trigger text style  change alert threshold text  remove threshold lines for change alerts ", "linked_issue_titles": "", "title": "show thresholds for change alerts in the alert details sidebar"}
{"description": " as suggested by @drashna, i converted the rules.mk for iris to use split_keyboard. had to modify the quantum/split_common/matrix.c to fix a build error. ", "commit_messages": " convert iris to split-common  fix build error ", "linked_issue_titles": "", "title": "convert iris to use split_keyboard"}
{"description": " hi i'm sean, co-founder of magic! this pull request adds an official example of using magic to implement cookie-based, passwordless authentication with email-based magic links. this work is based on the existing with-passport example (following existing layout and styles), removed dependencies on passport and express, and influenced by @emwsc's pull request: #11678 demo: ", "commit_messages": " add example with magic and passport.js  tweaked wording on readme ", "linked_issue_titles": "", "title": "add example with magic authentication"}
{"description": " i have followed (at least) the pr section of the contributing guide. migrated popover component's mouse over interaction demo from class components to hooks ", "commit_messages": " override step props over internal state of stepper  add a unit test  merge upstream with 'master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  migrate mouseoverpopover demo to use hooks ", "linked_issue_titles": "", "title": "migrate popover demo to hooks"}
{"description": " this pr manages a second \"feedrate\" applied only to g0 moves. it saves/restores the primary feedrate upon evaluation, and likewise restores/saves g0 feedrate. this increases compatiblity with cnc produced gcode, and can speed up cnc gcode execution where faster g0 is implied. and f is not respecified at each command. would answer to feature request #12047 ", "commit_messages": " g0_feedrate  remove default activation  restore unintended suppression of a configuration part ", "linked_issue_titles": "", "title": "option for g0 to have a separate feedrate"}
{"description": " this is a quality of life improvement for typical users. almost all anomaly detection jobs receive their input data through a datafeed. the datafeed config can now be supplied and is available in the datafeed_config field in the job config for creation and getting jobs. backport of: #74265 ", "commit_messages": " [ml] add datafeed field to the job config (#74265)  this is a quality of life improvement for typical users. almost all anomaly jobs will receive their data through a datafeed.  the datafeed config can now be supplied and is available in the datafeed field in the job config for creation and getting jobs.  fixing for backport ", "linked_issue_titles": "", "title": "add datafeed_config field to anomaly detection job configs"}
{"description": " breaking change: n/a description: improve log error and debug messages to help understand unexpected errors. related issue (if applicable): fixes partially #25513 **pull request with documentation for home-assistant.io (if applicable): n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " improve log error messages  remove unique_id not ready yet ", "linked_issue_titles": "", "title": "meteofrance improve log error messages"}
{"description": " bump the android gradle plugins versions to the latest. android studio 4.1+ seems to stop providing editor support for (and recognizing) android libraries when they define an external native build whose root includes the library's directory. as a workaround, i moved the external native build definition into a separate empty android library. this does not affect the project structure since the external native build definition was added in the first place for android studio editor support (the actual native dependencies are handled by scons). ", "commit_messages": " update the gradle plugins  add a separate nativesrcsconfigs module to handle android studio constraints for native code editor support. ", "linked_issue_titles": "", "title": "update android gradle plugins versions"}
{"description": " five new documents: how netdata's metrics collectors work enable or configure a collector collect system metrics with netdata collect container metrics with netdata collect application metrics with netdata see netdata/learn#285 for additional context. this page contains some elements that will only appear on the deployed learn site, so see the deploy preview for this page for the full picture:  some links will not work, as the target docs do not exist yet. for now, these prs will get merged into the docsv2 but not go live on netdata learn. once they're all available, or at least a workable majority, we'll merge them into master and deploy the project as a whole. component name area/docs ", "commit_messages": " init files  finish first two collect docs  finish drafts of collect docs ", "linked_issue_titles": "", "title": "add collect docs to the docsv2 project"}
{"description": " adds unit and integration tests for updating the backend config. this also standardizes the old create_backend codepath and the new deploy codepath on the same underlying call to update a backend config. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " unit tests for backend state  add goals  add explicit goal tests  remove  fix non-detached  small fix  fix version  add cleanup(), include in unit tests  fixes  add exit_actor call  medium for test_handle  refactored unit tests  add tests  add unit tests for updating config ", "linked_issue_titles": "", "title": "add backend_state tests for updating backend config"}
{"description": " closes #18431 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " doc: add whatsnew note  tst: added test for date_range and datetimeindex with mismatching timezones  bug: fixed exception not being raised if end.tzinfo is none but start.tzinfo is not none  tst: fixed new test failure in test_with_tz to pass in a tzaware end date ", "linked_issue_titles": " bug: date_range is inconsistent when given mixed tz aware and tz unaware start/end ", "title": "fix tzaware dates mismatch but no exception raised"}
{"description": " description of change this problem is a part of the original problem subset sum in sense that here it will only count those subsets that are continuous arrays. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines ", "commit_messages": " create subarray_sum.cpp  updating directory.md  clang-format and clang-tidy fixes for 0a293ece ", "linked_issue_titles": "", "title": "add the subarray sum implementation"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. manual notification for @clmcgrath since bot says \"account can't be detected\". ", "commit_messages": " updates flickity definitions for v2 and enables use as a module  adds tslint.json and makes tslint happy ", "linked_issue_titles": "", "title": "updates flickity definitions for version 2 and enables use as a module"}
{"description": " this adds support to the gradle builds for intellij to import the project and have classpaths set correctly. gradle documentation for these changes: ", "commit_messages": " fix javadocs - cleanup some warnings  add intellij idea support to gradle build   ", "linked_issue_titles": "", "title": "support 'provided' dependencies in intellij idea build"}
{"description": " in this pr: bringing the independent subsystems together via the plugin wiring up the http rpc endpoint wiring up the chain_controller signals adding to nodeos linking temporary fix for \"a+\" mode reads not starting at offset 0 on osx ", "commit_messages": " initial http wiring  basic ephemeral store wired into responses  merging http wiring branch  wire in a temporary ephemeral data store implementation to end-to-end test extract and response generation  merge feature/trace-api-plugn @ 3dd66aac1bf103f71587dbc98e84204d6d14c787  merging feature/trace-api-plugin @ 9f196730fb41fdefd0fd9155ae8103e658568ca8  fix merges in the night conflict  merging feature/trace-api-plugin @ 0e8978e4d46ca20728a9dab836996414f053eeb6  integrated with changes to extraction provider constructor  shim to old store api to start working on integration issues  refactored repeated try/catchs  temp fix for osx append read bug  merging feature/trace-api-plugin @ 500ed8e7c4ca41c2299142b47788fd7f7c6974b1  merging feature/trace-api-plugin @ 51e15ef093c314228b810d280daab076e34aba92  merging feature/trace-api-plugin @ 6f0832001eff32a975d78732d15a9abbabe88b0d  remove the shim now that the api matches ", "linked_issue_titles": "", "title": "trace api plugin - initial integration"}
{"description": " this is a significant reorganization of the diff code. i took the old src/diff_output.c that had grown quite large and split it into: src/diff_file.c loads individual files - a patch contains two of these src/diff_patch.c generates patches and can be iterated src/diff_xdiff.c wraps the xdiff dependencies and provides some isolation in the rest of the code src/diff_driver.c is a new file that contains the framework for supporting diff drivers, function context, etc. each of these files is much smaller with a narrower focus. i tried to explain the breakdown of everything in the new docs/diff-internals.md. as part of the new diff drivers work, i added a diff driver cache to the git_repository and removed several unnecessary includes from src/repository.h. after i removed those includes, i had to compensate in a bunch of places around the codebase, but i think it is a good thing because the includes were really overbroad imo. i looked at things in valgrind and there are a bunch of leaks, but most seem related to the new refs stuff and not to this diff code. there is a commit that fixes a few memory leaks that i stuck in just to try to get the valgrind output more readable. reorganize diff into more discrete parts implement diff driver framework implement \"unspecified\" default diff driver that finds last non-blank line (as per core git) implement \"unset\" diff driver that treats file as binary / undiffable implement \"set\" diff driver that forces file to be treated as text [not implemented correctly at the moment] implement \"pattern\" config-based diff drivers with regex matching better isolation for libxdiff code bits add apis to generate git_diff_patch from blobs (or blob and buffer) ", "commit_messages": " basic function context header  this implements a basic callback to extract function context for  a diff.  it always uses the same search heuristic right now with  no regular expressions or language-specific variants.  those will  come next, i think.  move some diff helpers into separate file  reorganize diff and add basic diff driver  this is a significant reorganization of the diff code to break it  into a set of more clearly distinct files and to document the new  organization.  hopefully this will make the diff code easier to  understand and to extend.  this adds a new git_diff_driver object that looks of diff driver  information from the attributes and the config so that things like  function content in diff headers can be provided.  the full driver  spec is not implemented in the commit - this is focused on the  reorganization of the code and putting the driver hooks in place.  this also removes a few #includes from src/repository.h that were  overbroad, but as a result required extra #includes in a variety  of places since including src/repository.h no longer results in  pulling in the whole world. ", "linked_issue_titles": "", "title": "diff code reorg plus function context in diff headers"}
{"description": " fix mono export template build errors. fixes #25903 don't print 'cannot find mono in the registry' if bundled with godot. closes #24753 ", "commit_messages": " mono: fix export template build errors  fixes #25903  don't print 'cannot find mono in the registry' if bundled with godot  closes #24753 ", "linked_issue_titles": "", "title": "get rid of irrelevant error and fix export template build errors"}
{"description": " hide any commandline (cooked read) we have before we begin a resize, and show it again after the resize. i found #5618 while i was working on this. closes #1856 i work here basically, during a resize, we try to restore the viewport position correctly, and part of that checks where the current commandline ends. however, when we do that, the commandline's current state still reflects the old buffer size, so resizing to be smaller can cause us to throw an exception, when we find that the commandline doesn't fit in the new viewport cleanly. by hiding it, then redrawing it, we avoid this problem entirely. we don't need to perform the check on the old commandline contents (since they'll be empty), and we'll redraw it just fine for the new buffer size ran tests checked resizing, snapping in conhost with a cooked read checked resizing, snapping in the terminal with a cooked read ", "commit_messages": " this is the test for #1856  this is the fix for #1856  add a resizing helper that will force you to do the right thing ", "linked_issue_titles": " snapping to smaller screen with a cooked_read crashes conpty ", "title": "hide the commandline on a resize to prevent a crash when snapping the window"}
{"description": " this is another step towards #3016. it proposed using r's standard interface to handle integers passed into the c++ side (for things like array size, buffer size, number of iterations, etc.). changes in this pr: use r builtin sexp type for any arguments passed from r to c++ that should be read-only integers use r builtin rf_asinteger() to convert those sexp objects to ints (replacing lightgbm's r_as_int) fix minor inconsistencies between lightgbm_r.h and lightgbm_r.cpp (e.g. parameter named nrow in the header file and num_row in the implementation) background there is not a scalar integer type in r. when you run some code like x <- 1l, r creates a length-one array (referred to in r as a \"vector\"). to treat such data as an integer, instead of an integer array, in c/c++, it's necessary to extract the first element of that array into a new int. r provides a convenience function, rf_asinteger(), for exactly that purpose. see  notes for reviewers this does not rely on #4242 ", "commit_messages": " [r-package] replace r_as_int with r built-in  merge master  update header  more changes ", "linked_issue_titles": "", "title": "use r standard routine to access read-only ints passed to c++"}
{"description": " this pr does 2 things export all types fix references type. previously it was an object of babel.nodepath. however, the docs say it is an object. i've been unable to lint these packages locally because of the following error any advice on how to fix it is appreciated. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " update babel-plugin-macros types to match docs  babel-plugin-macros update version and ts version ", "linked_issue_titles": "", "title": "export all types and fix references type"}
{"description": " without this pr partial function will fail due to missing fields. closes #17800 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " up  up  up ", "linked_issue_titles": " error for serialize function object with variable passed in ", "title": "allow function without __module__ and __qualname__"}
{"description": " modifies win_hosts module to use the ansible.basic csharp util instead of the legacy powershell module. also includes an improvement to the diff support. instead of generating a prepared diff, it uses the before, after properties. win_hosts i also updated the documents so that it better matches the development guide. before diff change task [win_hosts : remove aliases from the list] *********** -[192.168.168.1 testhost alias1 alias2 alias3 alias4] +[192.168.168.1 testhost alias1 alias2 ] after diff change task [win_hosts : remove aliases from the list] *********** @@ -19,4 +19,4 @@ # localhost name resolution is handled within dns itself. #      127.0.0.1       localhost #      ::1             localhost -192.168.168.1 testhost alias1 alias2 alias3 alias4 +192.168.168.1 testhost alias1 alias2 ", "commit_messages": " switch win_hosts to use csharp util  update win_hosts doc to match doc guide ", "linked_issue_titles": "", "title": "win_hosts to use ansible.basic csharp util and better diff support"}
{"description": " the tests were still passing because of the relaxed tolerance on particular fundamental matrix calculation methods. reverting that catches the bug; the change suggested in ", "commit_messages": " don't relax error level for particular fundamental matrix calculation methods  fix bug #3441, #4072, #4173: 8-point fundamental matrix calculation error ", "linked_issue_titles": "", "title": "8pt fundamental matrix calculation fix - bugs #3441, #4072, #4173, #4186"}
{"description": " fixes #5391. we had a bug in removing just some but not all ctors (and lacked a test...). ", "commit_messages": " support debug info in the ctor-evaller, and save the files before when in emcc_debug mode for debugging purposes  fix ctor evalling in wasm when just some can be removed #5391 ", "linked_issue_titles": "", "title": "fix partial ctor removal in wasm ctor evalling"}
{"description": " added lexrange related methods with limit options redis command zrangebylex key min max [limit offset count] ", "commit_messages": " sentinelconnectionmanager fails to instantiate  when the redis master has no slave connected, sentinelconnectionmanager  fails to instantiate.  conflicts:  src/main/java/org/redisson/connection/sentinelconnectionmanager.java  merge remote-tracking branch 'mrniko/master'  added lexrange methods with limit options ", "linked_issue_titles": "", "title": "lexrange related methods with limit options and zrangebyscore support"}
{"description": " description: this pr addresses a todo left behind earlier in guarddog_impl.cc which was bypassing the time-source and working directly with real time. instead we use timers and a dispatcher to run the guard dog. there was a race previously in guarddog_impl_test.cc which had to be resolved to integrate this (inserting a sleep at the current impl: #6239 (comment)), and another race in the interlock mechanism due to a race between the test sleep()ing (moving time forward) and the impl reading time to compute misses and megamisses. this was resolved by incorporating time into the interlock mechanism. note: simulatedtimesystem had threading issues when mutating alarms on one thread while executing them on another. the thread-annotation needed overrides due to the challenges the compiler faces proving that time_system_->alarm_->time_system == time_system, and we want to use a single mutex for the time-system and its alarms. risk level: medium -- guarddog runs all the time. otoh a lot of test iterations show this appears to be robust both in real-time and system-time. testing: //test/... docs changes: n/a release notes: n/a ", "commit_messages": " rework guarddog_impl.cc using timers rather than condvar timed waits.  working with --runs_per_test=1000 with and without tsan.  cleanup  more cleanup and removal of new simulated-time routines that i didn't wind up using. ", "linked_issue_titles": "", "title": "sim-time thread safety and move guard-dog fully into abstract time."}
{"description": " here's a trick with property that @mblondel suggested earlier to make hasattr(clf, \"predict_proba\") work with svc(probability=false) and sgdclassifier(loss=\"hinge\"): models that define the method, but where it doesn't actually work. this is a bit of a hack, so i don't suggest using it in new code (see comment in svc), but it simplifies other code such as bagging and the smoke tests, i.e. it localizes the problem that these exceptional estimators have instead of spreading it across the codebase. there might be more places where the code can be simplified. the documentation comes out almost right, despite the property: (the \"returns x\" is there in master too, i'll change it in a minute.) ping @jnothman, @gaelvaroquaux, @agramfort, @ogrisel. ", "commit_messages": " fix predict_proba status on sgd and svc when disabled  using a property trick suggested by @mblondel. the following now  works:  >>> clf = svc(probability=false)  >>> hasattr(clf, \"predict_proba\")  false  this simplifies the smoke tests.  added a note to svc stating that this should be done in new code.  enh use hasattr \"predict_proba\" in bagging  more robust than catching exceptions. ", "linked_issue_titles": "", "title": "make hasattr(clf, \"predict_proba\") work with probabilities disabled"}
{"description": " this adds a new mode to process-stats-dir.py that handles evaluating expressions over specific stats-dir values. also includes mention of a lit.py mode i had to employ today, as per @gottesmm's request. ", "commit_messages": " [process-stats-dir] add --evaluate for evaluating specific stat conditions  [process-stats-dir] print diagnostic when --evaluate fails.  [docs] mention lit.py -vv option, helpful for diagnosis. ", "linked_issue_titles": "", "title": "process stats evaluate and lit diagnostics docs"}
{"description": " original pull-request #27329 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix incorrect row-level filtering  add test.  add test.  update 02002_row_level_filter_bug.sh  add test to parallel skip list.  update skip_list.json  fix spelling.  fix #27179 ", "linked_issue_titles": "", "title": "cherry pick #27329 to 21.8: fix #27179"}
{"description": " originally reported by @hartmut-co-uk in discord following config makes maximum call stack error: privateruntimeconfig: { api_secret: '${api_secret}' }, it is also reproducible with dotenv-expand itself when using variable as value. since we are using forked version there is this pr but have to also fix for upstream. ", "commit_messages": " fix(config): avoid recursion when interpolating ", "linked_issue_titles": "", "title": "avoid recursion when interpolating env"}
{"description": " these changes address an issue where screen readers may repeatedly and redundantly read texttrackmenuitem's control text on every texttrackchange event in some browsers. the source of the problem is in the handletrackschange() method of texttrackmenuitem and its subclass offtexttrackmenuitem, in which this.selected(true/false) gets called even if the selected state has not changed since its previous invocation. create private isselected_ property for menu items only call .selected(true) in handletrackschange() if !isselected_ ", "commit_messages": " wip  more experimentation, logging  remove logging, clean upcomments  remove event arg used for testing  add comment  set value of isselected_ in selected() method  better comment ", "linked_issue_titles": "", "title": "only select texttrackmenuitem if unselected"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #40316 i've left a couple of questions in #40316 about what to do with the pre elements, those are in separate commits, so it can be reverted if needed. ", "commit_messages": " added languages to prismjs  added language to code fences for python for everybody ", "linked_issue_titles": " code fences should have languages ", "title": "adding language to code fences and pre to console logs"}
{"description": " resolves #6891 move the conversion from fc::variant to json string reponse into the http thread pool to reduce the amount of work done on the application thread. the http_plugin url_response_callback changed from std::function<void(int,std::string)> to std::function<void(int,fc::variant)> -- code calling the url_response_callback is now expected to provide a fc::variant instead of a string. this means the the type must be setup with fc_reflect so it can be converted to variant. this was already the case for all plugins in eos repo, but if external plugins were doing their own json conversion then that will no longer work. ", "commit_messages": " move json::to_string processing to http thread pool  move json::to_string to http thread pool ", "linked_issue_titles": "", "title": "move json::to_string response processing to http thread pool"}
{"description": " add dynamic sampling configuration to projects. this configuration is exposed into the project configurations received by relay. ", "commit_messages": " added dynamic sampling configuration to projectdetails  put dynamic sampling rules into an object (was a simple array)  added dynamicsampling to relay projectconfigs ", "linked_issue_titles": "", "title": "added dynamic sampling configuration to projects"}
{"description": " backports #21872 npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fix fuzzy font rendering when hot-plugging displays on macos catalina ", "commit_messages": " fix: font rendering with hi-dpi transitions on catalina  backports  chore: update patches ", "linked_issue_titles": "", "title": "font rendering with hi-dpi display transitions on catalina"}
{"description": " the global ordinals terms aggregator has an option to remap global ordinals to dense ordinal that match the request. this mode is automatically picked when the terms aggregator is a child of another bucket aggregator or when it needs to defer buckets to an aggregation that is used in the ordering of the terms. though when building the final buckets, this aggregator loops over all possible global ordinals rather than using the hash map that was built to remap the ordinals. for fields with high cardinality this is highly inefficient and can lead to slow responses even when the number of terms that match the query is low. this change fixes this performance issue by using the hash table of matching ordinals to perform the pruning of the final buckets for the terms and significant_terms aggregation. i ran a simple benchmark with 1m documents containing 0 to 10 keywords randomly selected among 1m unique terms. this field is used to perform a multi-level terms aggregation using rally to collect the response times. the aggregation below is an example of a two-level terms aggregation that was used to perform the benchmark: \"aggregations\":{ \"1\":{ \"terms\":{ \"field\":\"keyword\" }, \"aggregations\":{ \"2\":{ \"terms\":{ \"field\":\"keyword\" } } } } } levels of aggregation 50th percentile ms (master) 50th percentile ms (patch) 2 640.41 577.499 3 2239.66 600.154 4 14141.2 703.512 closes #30117 ", "commit_messages": " build terms bucket from matching ordinals  the global ordinals terms aggregator has an option to remap global ordinals to  dense ordinal that match the request. this mode is automatically picked when the terms  aggregator is a child of another bucket aggregator or when it needs to defer buckets to an  aggregation that is used in the ordering of the terms.  though when building the final buckets, this aggregator loops over all possible global ordinals  rather than using the hash map that was built to remap the ordinals.  for fields with high cardinality this is highly inefficient and can lead to slow responses even  when the number of terms that match the query is low.  this change fixes this performance issue by using the hash table of matching ordinals to perform  the pruning of the final buckets for the terms and significant_terms aggregation.  i ran a simple benchmark with 1m documents containing 0 to 10 keywords randomly selected among 1m unique terms.  this field is used to perform a multi-level terms aggregation using rally to collect the response times.  the aggregation below is an example of a two-level terms aggregation that was used to perform the benchmark:    \"aggregations\":{  \"1\":{  \"terms\":{  \"field\":\"keyword\"  },  \"aggregations\":{  \"2\":{  \"terms\":{  \"field\":\"keyword\"  }  }  }  }  }    | levels of aggregation | 50th percentile ms (master) | 50th percentile ms (patch) |  | --- | --- | --- |  | 2 | 640.41ms | 577.499ms |  | 3 | 2239.66ms | 600.154ms |  | 4 | 14141.2ms | 703.512ms |  closes #30117  unused import ", "linked_issue_titles": " string terms is very slow when there are millions of buckets ", "title": "build global ordinals terms bucket from matching ordinals"}
{"description": " updates xcode_backend.sh to use (mostly) assemble apis. this almost completes the migration, though i still need to move the asset unpack step - this is slightly more complicated due to the module format. should have no new external behavior, but does allow us to more easily wire up new features like font-subset, dart-defines, and obfuscation (which was never implemented for ios?) fyi @dnfield fixes #32925 reland: makes the universal framework depend on kernel. due to the behavior of the codegen integration, running them at the same time causes parts of .dart_tool to be deleted and recreated. ", "commit_messages": " [flutter_tools] move ios to assemble  fix dependencies and paths  update ios.dart  updates and more tests  update dart tests  fix order of operations ", "linked_issue_titles": " re-implement existing ios and android build in terms of --legacy flutter assemble targets ", "title": "reland migrate xcode_backend.sh to flutter assemble"}
{"description": " fix #4856 . set roundcap to be true (default false) for polar bars will have this effect. var option = { angleaxis: { max: 5 }, radiusaxis: { type: 'category', data: ['a', 'b', 'c'], z: 10 }, polar: { }, series: [{ type: 'bar', data: [1, 2, 3], coordinatesystem: 'polar', name: 'a', roundcap: true, color: 'rgba(200, 0, 0, 0.5)', itemstyle: { bordercolor: 'red', borderwidth: 1 } }], legend: { show: true, data: ['a'] }, tooltip: { show: true } }; it may also help to provide an array as polar.radius to make rings more easily. currently, this can be done with empty data in the inner side: this will be improved in future prs. i'll see if i can make it in this milestone. please ignore this feature for now. todo: feat: support polar.radius feat: support bar background ", "commit_messages": " feat: add sausage shape  feat(polar): support radius for polar bars  test(polar): add test for polar bars with roundcap ", "linked_issue_titles": " [feature] support barborderradius on the polar bar chart ", "title": "support round cap for polar bars"}
{"description": " long overdue, this pr adds a section in the user guide dedicated to the new gbdts. ping @adrinjalali \t@glemaitre \t@amueller \t@thomasjpfan ", "commit_messages": " user guide for histogram based gbdts  added backlinks to user guide in classes ", "linked_issue_titles": "", "title": "doc user guide section for histogram-based gbdts"}
{"description": " struct a; impl drop for a { fn drop(&mut self) {} } const foo: option<a> = none; const bar: () = (foo, ()).1; was erroring with error: any use of this value will cause an error --> src/lib.rs:9:1 | 9 | const bar: () = (foo, ()).1; | ^^^^^^^^^^^^^^^^^^^^^^^^^^-^ |                           | |                           calling non-const function std::ptr::real_drop_in_place::<(std::option::option<a>, ())> - shim(some((std::option::option<a>, ()))) | = note: #[deny(const_err)] on by default error: aborting due to previous error before this pr. according to godbolt this last compiled successfully in 1.27 ", "commit_messages": " manually inline a function that was only used once  allow evaluating trivial drop glue in constants ", "linked_issue_titles": "", "title": "fix evaluating trivial drop glue in constants"}
{"description": " added response checks to all curl and git network calls. ", "commit_messages": " ubuntu: added network response checks for curl and git calls, added --connect-timeout 30 to all curl calls  fixed conflicts in amazon build script ", "linked_issue_titles": "", "title": "eosio build ubuntu network response checks"}
{"description": " currently, we have two im2rec tools. one is python, the other one is c++. there are slightly different in terms of functionality. it helps to solve the #11884  as well. change the data format on example add some notes to tell users the difference and add corresponding to each other. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change @aaronmarkham please let me know how can i make it less confused. ", "commit_messages": " update the example data format and link to each others ", "linked_issue_titles": "", "title": "refine the documentation of im2rec"}
{"description": " update grafana version to the latest (6.1.3) update kiwigrid sidecar version to (0.0.16) (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) @maorfr @rtluckie @zanhsieh dco signed ", "commit_messages": " bump grafana version to 6.1.3  update grafana version on readme  bump kiwigrid version to the latest  update chart properties  update kiwigrid version on readme ", "linked_issue_titles": "", "title": "update grafana version to 6.1.3"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: helmetjs/helmet@fd4931e increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update helmet definitions  helmet (  update tests for helmet ", "linked_issue_titles": "", "title": "update helmet definitions for 3.13.0"}
{"description": " add typing for bfs and make the code more brief. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " add typing for bfs  add url for bfs ", "linked_issue_titles": "", "title": "add url and typing hint for bfs"}
{"description": " add some warnings to warn users what they are doing. and use rich to display log, which is more beautiful. n manimlib/logger.py m manimlib/__init__.py: add __version__ m manimlib/__main__.py: print version when start using manim m manimlib/config.py: add cli arg -v and change print to log m ...: change print to log ", "commit_messages": " add warning for empty  add tips for interactive mode  add tips for embed mode  add cli flag -v to show version info  use rich to log  print version when start ", "linked_issue_titles": "", "title": "add warnings and use rich to display log"}
{"description": " rules-tags defaults to [\"recommended\"], not empty list close #12615 ", "commit_messages": " fix(lint): use recommend if config without tags  fix lint ", "linked_issue_titles": " bug(cli/lint): all rules are ignored if the config is changed ", "title": "use recommended tag if there is no tags in config file or flags"}
{"description": " you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information fix #23872 by remove non-existing 'ytdl test pl'  change 'ydl_empty_list'  fix incorrect playlist_count for ", "commit_messages": " remove non-existant playlist and replace empty playlist test  fix playlist test count ", "linked_issue_titles": " testdownload.test_youtubeplaylist broken ", "title": "fix playlist tests (fix #23872)"}
{"description": " *note: moving #2999 over here (based on a lightgbm branch) so we can test readthedocs builds. see #2999 (comment) see comments from @strikerrus #2989 (comment) #2989 (comment) a few of the r examples are broken right now. these weren't caught by tests because one is only a warning, one is a plot that is generated successfully but is incorrect, and one is an issue specific to our readthedocs builds. i think the issue for lgb.cv() is #2715. in that issue we found that data.table 1.11.4 and r 3.6.0 lead to a data.table error ending in column or argument 2 is null. i think this can be fixed by upgrading to the data.table  1.12.1 in conf.py. to fix the lgb.set.categorical() example, i changed file names across several examples to be sure that no two examples write to the same file name. this issue with lgb.plot.interpretation() is because i made a change and forgot to use abs(). new plot: i was not able to reproduce the data.table error in  #2989 (comment). it ", "commit_messages": " [r-package] fix r examples and lgb.plot.interpretation  remove space in gitignore ", "linked_issue_titles": "", "title": "fix r examples and lgb.plot.interpretation()"}
{"description": " this allows both aclk-ng and legacy to coexist together and agent decides at startup which one will be used based on aclk implementation config param of cloud section of netdata.conf this has origin in good idea from @ferroin (asking why can't we have both :d) some of the things can be done nicer... e.g. aclk_stats of ng and legacy could be merged. this is not done as this should be done with minimal amount of effort as legacy will be removed soon (would be lot of wasted effort) + time pressures. component name aclk, aclk-ng ", "commit_messages": " ng by default  protobuf not needed yet  ignore --aclk-ng + remove obsolete comment  configure.ac and netdata-installer for dual aclk  fixup config.ac commit  make them coexist  use the legacy version  fixup config.ac  fix disable cloud  ng only fnc back to aclk_util  fix label list on disable cloud  fix disable cloud  update buildinfo  additional fixes  read aclk implementation to be used from cfg file  fix api/v1/info ", "linked_issue_titles": "", "title": "allows aclk ng and legacy to coexist"}
{"description": " this pr moves the os detection method to common and removes the os-detection dll project. for using the os detection functions in imageresizer, a method was added to powertoysinterop in the commonmanaged class which calls the same method. pr checklist applies to #3579 cla signed. if not, go over here and sign the cla validation steps performed validated with local msi that the correct settings and image resizer settings are loaded in 1909 and 1809. ", "commit_messages": " remove os-detection project  removed os-detection project from sln  added os-detection to powertoysinterop  removed references to os-detection and added powertoysinterop.dll to the imageresizer folder ", "linked_issue_titles": "", "title": "move os detection to common and powertoysinterop"}
{"description": " initial pass at a rocksdb jni cross-platform fat jar. building a cross-platform jar requires: vagrant virtualbox a mac osx machine that can compile rocksdb. once you have these items, run this make command from rocksdb's root source directory: make jclean clean rocksdbjavastaticrelease this command will build rocksdb natively on osx, and will then spin up two vagrant virtualbox ubuntu images to build rocksdb for both 32-bit and 64-bit linux. you can find all native binaries and jars in the java directory upon completion: librocksdbjni-linux32.so librocksdbjni-linux64.so librocksdbjni-osx.jnilib rocksdbjni-all.jar rocksdbjni-linux32.jar rocksdbjni-linux64.jar rocksdbjni-osx.jar ", "commit_messages": " update rocksdb's java bindings to support multiple native rocksdb builds in the same jar file. cross build rocksdb for linux32 and linux64 using vagrant. build a cross-platform fat jar that contains osx, linux32, and linux64 rocksdb static builds.  document release.mdgit status  rsync files to vm rather than sync folders, since sync folders was causing clock skew and confusig make.  since we're not sharing folders with the vm, copy built .so files and jars back to host system. ", "linked_issue_titles": "", "title": "build rocksdb jni cross-platform fat jar"}
{"description": " this adds visit* methods for the astbuilder to convert an antlr tree into a ql tree. i've only scoped this to stateless expressions (no sequence, join, pipes, ancestry). there are a few cases of eql are just shorthand for now, unless we add more optimal/direct support within ql: x in (a, b, c, ...) -> x == a or x == b or x == c or ... x == \"some*wildcard*expr*\" -> wildcard(x, \"some*wildcard*expr*\") functions get turned into unresolvedfunction. i think at some point, we'll need to add ql support for these or have these functions be eql only with a custom registry. i haven't dived much into that yet to see how this works. i'm assuming that this will be done in a separate follow up pr (created issue #51556 for new functions) related issues #49589 #49997 ", "commit_messages": " eql: add astbuilder visitors  eql: add tests for wildcards and sets  eql: fix licensing ", "linked_issue_titles": "", "title": "add astbuilder to convert to ql tree"}
{"description": " fixes microsoft/vscode#51139 further to avoid the unnecessary directory watch triggers in case of amd resolution, say we are trying to resolve module \"fs\" we would go looking for file fs.ts/fs.tsx/etc in each of the ancestor folder. at this point we use to create directory watch in the ancestor folder but to watch it recursively. this lead to the watch being triggered frequently. this fixes that issue since ancestor folders will be watched only for something directly in it. (eg. ancestor/fs.ts) in rest of the scenarios we will watch subdirectory of ancestor folder as shown in #24471 ", "commit_messages": " test for amd resolution setting the recursive directory watcher in the parents of root folder  do not watch the parent folders recursively if not needed.  this avoids watching folders like parent folder of the project root just to watch files created in the folder  fixes microsoft/vscode#51139 ", "linked_issue_titles": " tsserver consume constant cpu load (~10% or even more) also i am not typing or doing anything in vs code ", "title": "do not watch parent folders recursively if not needed"}
{"description": " this pr solved issue #36381, and a related issue in mathjs repo: josdejong/mathjs#1539 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update mathjs to v6  [mathjs] fixed test cases to match v6  [mathjs] added some fixes from eval => evaluate  [mathjs] added test cases for renamed functions  [mathjs] more fixes for renamed functions  added type for factory function  [mathjs] added typing to factory dependencies ", "linked_issue_titles": "", "title": "added typing defs for mathjs-6.0"}
{"description": " this is mostly done using the gulp lint --fix command, and manual changes in a small number of cases where eslint couldn't determine what to use, in an effort to reduce the number of disabled eslint rules in the core folder and to use modern syntax. ", "commit_messages": " enable the no-var linting rule in src/core/metrics.js  enable the no-var linting rule in src/core/unicode.js  enable the no-var linting rule in src/core/ccitt_stream.js  enable the no-var linting rule in src/core/glyphlist.js  enable the no-var linting rule in src/core/primitives.js ", "linked_issue_titles": "", "title": "enable the no-var linting rule in more core files"}
{"description": " fix link error for \"what can i do\" part add \"related reports\" part for english version see what it looks like here: @996icu ", "commit_messages": " fix link error  set up related reports part ", "linked_issue_titles": "", "title": "add related reports part for english version and some set up errors."}
{"description": " this extracts logic from computetransformflagsfornode for switch cases that use properties on node subtypes. this allows nodejs (or other hosts) to make deoptimization decisions for each branch rather than for the entire computetransformflagsfornode function which reduces bind time by 10-14% depending on scenario when compared to the \"transforms\" branch. this also manually inlines the updatetransformflags function as it was too polymorphic to be properly inlined. ", "commit_messages": " isolate polymorfic code to individual functions to speed up inlining decisions in node.  fix aggregation issue for namespaces ", "linked_issue_titles": "", "title": "performance improvements in the binder."}
{"description": " original pull-request #29762 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update minio  update docker_compose_minio.yml  ping tests  may be fix s3 tests ", "linked_issue_titles": "", "title": "cherry pick #29762 to 21.3: may be fix s3 tests"}
{"description": " i made some work on the issue #533. ", "commit_messages": " corrects some words in spanish, and changes others for a better comprehention  corrects some words in spanish, and adds translation  for 2 options not include in es-help.txt but present in help.txt ", "linked_issue_titles": "", "title": "spanish translation corrections and additions"}
{"description": " i added wgsl support and keep glsl until finish nodematerial wgsl code generate. updated the example webgpu_compute and scale parameter behavior.  this contribution is funded by google via igalia. ", "commit_messages": " webgpu: hybrid language  webgpu_compute: update of glsl -> wgsl  highlight point color  update screenshot ", "linked_issue_titles": "", "title": "wgsl support and webgpu_compute example updated"}
{"description": " before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? description of your pull request and other information the rtl.nl extractor does not work with the updated url-scheme anymore. this pull requests fixes the url-pattern. without touching the old regex. a new testcase is added, old ones are still the same. see also #25821 (tried a pull-request before, but #25816 got lost due to a rebase while updating to the most recent code-base). ", "commit_messages": " fixed change in rtl.nl url pattern  with old url pattern intact ", "linked_issue_titles": "", "title": "update regex for new urlscheme"}
{"description": " #7939 added support in eosio-blocklog to trim the front of a blocklog and create the version 3 blocklog format added invariant logic for existing version 3 blocklog logic cleanup ", "commit_messages": " fixed block reporting to work for trimmed block logs.  moved trim_data into block_log. gh #7939  adding missed invarients to existing code. gh #7939  movede trim_blocklog_front logic into block_log and added support for version 3. gh #7939  added integration tests for trimming front of block log. gh #7939 ", "linked_issue_titles": "", "title": "7939 trim block log v3 support"}
{"description": " my system has an umask of 027. this means that every file that's created gets the w bit erased for group members, and all of rwx erased for others. it's likely some security measure. this has the effect that the files in base/ don't have rx set for others, but those bits are needed when serenity runs so that e.g. the window user can read /etc/windowserver/windowserver.ini. instead of just copying the on-disk permissions into the image, explicitly set w for group and others, and set x for group and others for files that are x for user (ie executables and directories -- that's what x does). ", "commit_messages": " build-root-filesystem: move \"cp -r\" block up.  i want to add a \"chmod -r\" right after the cp command.  this needs to happen before all the other chmods, to not  undo their effect.  build-root-filesystem: explicitly add +rx for group and others to copied files.  this lets serenity boot even when the repository is cloned with a  umask of 027. ", "linked_issue_titles": "", "title": "make serenity boot even if the umask at git clone time was 027."}
{"description": " fix double-dash param usage (eg: --help) adds -version parameter sync output of -version and qt aboutdialog merge ui models for aboutdialog and helpmessagedialog ", "commit_messages": " remove double-dash parameters from mapargs  should be merged after pull request #4281  (\"add -version option to get just the version #4281\"),  because is changed \"--help\" to \"-help\".  checked that grep of 'mapargs.count(\"--' returned only  three places that are fixed by pull request #4281.  add -version option to get just the version  adds a -version or --version option to print just the version  of the program for bitcoind, bitcoin-cli and bitcoin-qt.  also make it that -help can be used to display the help (as well as  existing --help). up to now, -help was the only option that didn't  work with either one or two dashes.  util: add function formatparagraph to format paragraph to fixed-width  this is to be used for the -version and -help messages.  add 'about' information to -version output  adds a copyright and attribution message to the -version output  (the same as shown in the about dialog in the gui).  move the message to a function licenseinfo in init.cpp. ", "linked_issue_titles": "", "title": "add -version, fix -help and qt aboutdialog"}
{"description": " fixes #10677. i didn't update the docs as i think this is the intended behaviour, but i can do if you think this change would be unexpected. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to it if that's the case. issue #10677. documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " adding required flags to non-default arguments.  make style fix. ", "linked_issue_titles": " hf_argparser doesn't set the required flag on non-defaulted enums ", "title": "adding required flags to non-default arguments in hf_argparser"}
{"description": " this adds a command line option to ignore kernel threads in process list, which in my opinion clutter the display. this only applies to unix systems. a nice side effect is that the cpu usage of glances goes down a bit (-0.5 et -1% on my machine, as measured by glances of course). we should also maybe consider making this the default, as the kernel task on mac is already ignored. ", "commit_messages": " fix some misspellings  add command line option to ignore kernel threads on unix systems ", "linked_issue_titles": "", "title": "add a command line option to hide kernel threads"}
{"description": " only show explore and edit buttons for a slice if user has explore or edit access. don't show save buttons on dashboard if user doesn't have save access. also, remove a \"<br>\" in the error message of the savemodal. it displays on screen since the message is not html. ", "commit_messages": " hide forbidden ui elements, remove <br> from message  add comma for flake8 ", "linked_issue_titles": "", "title": "hide restricted ui elements, remove <br> from error message"}
{"description": " i've run the latest black with default args on new code. added a check for black formatting to ensure only formatted code is merged to the master branch. ", "commit_messages": " add black format check  this will provide a useful ci check before users can merge.  run black format across all files ", "linked_issue_titles": "", "title": "add black format check to ci"}
{"description": " adds a visible indicator that a terminal window is elevated. this icon can be disabled with \"showadminshield\" false in the global settings. spec'd in #8455 also in  big picture: #5000 closes #1939 i work here requires documentation to be updated - yea probably ", "commit_messages": " add shield to titlebar  move where the shield is hosted, make it actually dependent on elevation state  add a setting too  add a tooltip too ", "linked_issue_titles": " ui styling to clearly indicate elevated (admin) window ", "title": "add shield to tab row when elevated"}
{"description": " git gymnastics after #8626 ", "commit_messages": " revert \"introduce an 'svc' segment for dns search\"  install specific salt version on aws, based on gce  the latest salt version breaks the container_bridge.py _state function  we can lock to the same version as gce.  this is not a full fix,  because we can't update to the latest salt without breaking gce,  but this at least unbreaks and sync aws with gce.  this isn't a straight copy from gce, because we still use  the salt master on aws (for now)  fixes #8114  aws: don't use policy-rc.d to prevent starting daemons until we're ready  it isn't required  kubernetes version v0.17.1  kubernetes version v0.17.1-dev  release 0.17.1 ", "linked_issue_titles": "", "title": "merge release 0.17.1 to master"}
{"description": " description: improve support for 1. gen mill heater checklist: local tests pass with tox. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable ([example][ex-requir]). new dependencies are only imported inside functions that use them ([example][ex-import]). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. ", "commit_messages": " improve support for 1. gen mill heater  style ", "linked_issue_titles": "", "title": "improve support for 1. generation mill heater"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #38753 changed the language of the question which was earlier quite complex to understand. also added a new test for better clarification. ", "commit_messages": " changed language for project euler problem-2  changed language for project euler problem-2 ", "linked_issue_titles": " poorly worded challenge: project euler: problem 2: even fibonacci numbers ", "title": "added a test for project euler problem-2"}
{"description": " just in case someone is too clever with object serialization or tries to be clever by setting private properties. potential bugs are really obscure but better be safe than sorry i.e. only we write the property and no one else. ref: ", "commit_messages": " [styles] add stress test for symbol serialization  [styles] fix potential private classname if deserialization is too good  make it more obvious why symbol.for  is dangerous  fix test failing in ie11 ", "linked_issue_titles": "", "title": "fix global classnames being disabled in deserialized themes"}
{"description": " part of #48366. introduce a new static setting, gateway.auto_import_dangling_indices, which prevents dangling indices from being automatically imported. i've also updated the dangling index docs a little to cover the new setting, and add some scary caveats. ", "commit_messages": " add a setting to control dangling index allocation  fix allocate setting and implement its  the new settings didn't work, but now it does, and i've written a couple  of its that create dangling indices and check what affect the setting  has.  i'm still fixing the unit tests though.  finish fixing unit tests  rename the new setting  wip - trying to make new setting static  new setting gateway.auto_import_dangling_indices doesn't need to be  dynamic. unfortunatlely, this has broken one of the its.  add docs for gateway.auto_import_dangling_indices ", "linked_issue_titles": "", "title": "new setting to prevent automatically importing dangling indices"}
{"description": " adds rbac and pod security policy support for elasticsearch (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr contains starts with chart name e.g. [stable/chart] ", "commit_messages": " adds support for rbac and pod security policies for elasticsearch-curator  updated readme to include new psp/rbac options ", "linked_issue_titles": "", "title": "adds rbac and psp support for elasticsearch-curator"}
{"description": " handle the scenario when heritage clause of interface is not entity name expression fixes #12291 handle when type alias's type parameter extends type that wont get emitted in .d.ts fixes #12326 ", "commit_messages": " handle the scenario when heritage clause of interface is not entity name expression  fixes #12291  handle when type alias's type parameter extends type that wont get emitted in .d.ts  fixes #12326 ", "linked_issue_titles": "", "title": "declaration emit when there are errors in the source file"}
{"description": " improves logging overall. ", "commit_messages": " shader_bytecode: add encoding for vote.vtg  shader_ir: add error message for exit.fcsm_tr  shader_bytecode: add encoding for bar  shader_bytecode: rename mov_sys to s2r  shader/other: add error message for some s2r registers ", "linked_issue_titles": "", "title": "add some instruction and s2r encodings"}
{"description": " adds a base file downloader class to be used by fragmented media file downloaders (e.g. f4m/m3u8 manifests). rewrites f4mfd and nativehlsfd in terms of fragmentfd. adds generic progress output and resume for nativehlsfd. ", "commit_messages": " [fragment] generalize fragmented media file downloader  [f4m] implement f4m fd in terms of fragment fd  [hls] implement hlsnative fd in terms of fragment fd ", "linked_issue_titles": "", "title": "generalized fragmented media file downloader"}
{"description": " supply unittests for parsing of json value as root element(rfc7159). assert on impossible code paths. for switch-case in reader::transit() function, put all impossible code cases and non-enumerated cases under default:(also with assertions). ", "commit_messages": " add unittests for parsing root json value other than array and object.  add unittest for state transition to iterativeparsingmemberkeystate.  use assertion for impossible case(the predict() can ensure the token is colontoken, otherwise it would be marked as error state. so there is no need to check colontoken again).  assert on impossible state transition in transit(); put the last case and all non-enumerated cases(also supply assertion for them) in  for code coverage. ", "linked_issue_titles": "", "title": "improve code coverage for iterative parsing"}
{"description": " using parse/react-native gave error from typescript. quick fix for this. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " add parse/react-native definitions  add description ", "linked_issue_titles": "", "title": "@types/parse add react-native typings to fix warnings."}
{"description": " here's a bugfix for functionality which regressed from 1.6 -> 1.7, calling x.fill() with a tuple. should have filed this pr sooner, sorry! >>> import numpy as np >>> np.__version__ '1.6.2' >>> x = np.zeros(2, dtype=[('a', 'f8'), ('b', 'i4')]) >>> x.fill((3.5, -2)) >>> x array([(3.5, -2), (3.5, -2)], dtype=[('a', '<f8'), ('b', '<i4')]) >>> import numpy as np >>> np.__version__ '1.7.1' >>> x = np.zeros(2, dtype=[('a', 'f8'), ('b', 'i4')]) >>> x.fill((3.5, -2)) traceback (most recent call last): file \"<stdin>\", line 1, in <module> valueerror: input object to fillwithscalar is not a scalar ", "commit_messages": " tst: test for x.fill(tuple) where x is a struct array  bug: fix to allow x.fill(tuple) where x is a struct array ", "linked_issue_titles": "", "title": "regression when filling struct from tuple"}
{"description": " i found that when trying to print to pdf, there was a block of code missing from the html, this block is necessary for the pdf layout to be rendered properly and i didn't see it anywhere in the readme so i added it in. ", "commit_messages": " update readme.md  update readme.md to include block for pdf printing ", "linked_issue_titles": "", "title": "update to readme.md for pdf printing"}
{"description": " also, reword the what's new messages: this doesn't change the limited api, it only brings the py_limited_api macro closer to the ideal of only allowing the limited api.  automerge-triggered-by: gh:encukou ", "commit_messages": " reword note on removing pymarshal_* with py_limited_api  these items were not part of the limited api, which is defined  in the docs (via misc/stable_abi.txt).  the change brings the py_limited_api macro closer to the ideal  of only allowing things in the limited api.  exclude all of \"marshal.h\" when py_limited_api is defined.  nothing in the file is listed as part of the limited api.  the symbols are not exported in the windows stable abi dlls.  the header is not included from <python.h>. ", "linked_issue_titles": "", "title": "exclude all of marshal.h if py_limited_api is defined"}
{"description": " this warmup lr can be combinated with other learning rate strategies. for example: decayed_lr = fluid.layers.linear_lr_warmup( fluid.layers.piecewise_decay(boundaries, lr_steps), warmup_steps, start_lr, end_lr) ", "commit_messages": " reduce lstm_op kernel size  test=develop  add linear learning warmup method  this warmup lr can be combinated with other learning rate strategies.  for example:  decayed_lr = fluid.layers.linear_lr_warmup(  fluid.layers.piecewise_decay(boundaries, lr_steps),  warmup_steps, start_lr, end_lr)  test=develop ", "linked_issue_titles": "", "title": "add linear learning warmup method in learning rate scheduler."}
{"description": " auditd_fim_events table changes added the process uid and gid columns. renamed the path1 column to path. renamed the path2 column to dest_path. socket_events table changes print the saddr event field contents when the parser fails. the original function parsing the field has not been changed (this is straight from master); this may still come in handy when debugging. process_events table changes use decodeauditpathvalues to read path fields from the event records. auditdnetlink changes add support for clearing audit rules when osquery starts ( #3468 ). ", "commit_messages": " socket_events: dump the audit_sockaddr saddr field when it can't be parsed.  process_events: use the decodeauditpathvalues helper when reading paths.  auditd_fim_events: change column names. path1 to path, path2 to dest_path.  auditd_fim_events: add process uid and gid.  auditdnetlink: rules can now be cleared on startup using --audit_force_reconfigure. ", "linked_issue_titles": "", "title": "update column names, add process uid/gid, add switch to clear audit config on startup."}
{"description": " eosio-wat2wasm was really the assemble command from wavm and we used it for the old wasm build environment. it's no longer needed. remove it and other wavm tools from being built as some of these tools don't work as intended due to internal wavm changes we've made. this is being considered for 1.7.x because there are user reported crashes when trying to use these unsupported tools: #6946 ", "commit_messages": " don't build wavm tools any longer  some of these don't work as intended due to changes in wavm to support eosio  rename eosio-wat2wasm back to orginal name; don't install  eosio-wat2wasm was really the assemble command from wavm and we used it for the old wasm build enviroment. it's no longer needed. remove the rename and install changes effectively reverting ae9388d restoring this back to upstream ", "linked_issue_titles": "", "title": "remove eosio-wat2wasm and other wavm tools from being built - 1.7"}
{"description": " related to #31131 per discussion with @mayya-sharipova, this is a breaking change in 6.4 not 6.0 ", "commit_messages": " [docs] adds breaking change info for #28344  [docs] moves breaking change from 6.0 to 6.4 ", "linked_issue_titles": "", "title": "move breaking change info re rejecting regex search if regex string is too long"}
{"description": " this is a rebased branch based on development per boelle's comments in #971 conditional integration is an adaptive limit on the integral term that prevents accumulation when the proportional or other terms would saturate the heater output. this helps avoid overshoot by not winding up the integral when starting pid control far from the setpoint. discussion in #971, misdirected pull into marlin_v1 in #1246, reverted out of marlin_v1 in #1247. ", "commit_messages": " heater.c: limit pid i term with conditional integration.  temperature.cpp:add pid conditional integration on heated bed.  configuration.m: set pid_integral_drive_max from pid_max from bang_max.  current defaults are all 255.  if it makes sense to reduce them, they should come down together, and  be in a  pid_integral_drive_max <= pid_max <- bang_max relationship. ", "linked_issue_titles": "", "title": "add conditional integration to prevent excessive integral windup"}
{"description": " hi team! a would like to add \"logging\" subsection to microservice security cheat sheet with design recommendation on how to implement logging subsystem in microservice-based systems. -- alexander barabanov advanced software technology lab huawei ", "commit_messages": " add \"logging\" section  add logging pattern pic ", "linked_issue_titles": "", "title": "add \"logging\" subsection to the microservice security cheat sheet"}
{"description": " see  the downside is that you can't use sudo in the container, but i was able to remove our sudo usages with little effort. ", "commit_messages": " let's try running our testsuite without sudo  the de_de(iso-8859-1) locale is not available on ubuntu by default, but there is no reason to require that over the utf-8 one  use another character device in this test as /dev/console seems that it is different for lxc containers ", "linked_issue_titles": "", "title": "change our travis config to use the new container infrastructure"}
{"description": " category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation problem statement: currently connections to bigquery databases cannot be configured without adding code to superset or adding configuration to its execution environment in the form of google cloud account credentials. solution proposed: add an encrypted field on the dbs table to hold extended connection information. this field can hold json configuration including secrets and add that information on to the database connection object during instantiation. this allows us to configure a service account in google cloud and connect to a bigquery dataset without any code or configuration changes in superset. test plan create a dataset in bigquery in google cloud create a service account in google cloud with access to the dataset download the service account's identity file in json format open the add database screen in superset fill in the sqlalchemy url with bigquery://project-name where project-name is the name of the google cloud project that your bigquery dataset is associated with. add json to the secure extra field with the following structure: { \"credentials_info\": <content from the identity file from google cloud> } click \"test connection\" - it should say the connection is ok. requires db migration. confirm db migration upgrade and downgrade tested. reviewers @mistercrunch @dpgaspar ", "commit_messages": " add encrypted_extra to dbs  wip - ui-based bigquery connection configuration  fix 500 bubbling to the surface when adding a database connection  add check for valid json ", "linked_issue_titles": "", "title": "add ui-only database configuration method for extended authorization scenarios"}
{"description": " while writing the (future) emacs plugin, i had to ensure version of emacs installed was greater than 23. i remembered this script i had worked with during my studies. i have repacked and it here it is: require_tool.sh $ ./require_tool.sh emacs 23 ; echo $? 0 $ ./require_tool.sh emacs 50 >/dev/null ; echo $? emacs 50 or better is required: this is emacs 23.1.1 1 as this might be very helpful to other plugins, i believe $zsh/tools' directory is appropriate. wdyt? by the way, this zsh repo if a very very good idea. thank you all! cheers tristan ", "commit_messages": " new plugin git-svn installing git project  git-svn-clone-externals  new tool require_tool.sh  fix version parsing. now working with command $ zsh --version  add new plugin emacs, to take benefit of daemon capabilities of emacs >=23  removing master stuff ", "linked_issue_titles": "", "title": "new script $zsh/tools/require_tool.sh to ensure version of tool"}
{"description": " building on top of shantur's pr i changed: tuyamcureceived to tuyareceived to keep with established naming scheme (serialsend/serialreceived; tuyasend/tuyareceived) changed topic of tuyareceived from tele/%topic%/result to stat/%topic%/result the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core pre-2.6 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " tuyamcu: implement support for battery powered protocol  tuyamcu: add tuyasend command to communicate with tuya mcu  tuyamcu: add more details to tuyamcureceived  tuyamcu: disable fast reset in low power devices  battery powered devices don't stay up for long which could lead to reset.  tuyamcu : use setoption66 to enable / disable publishing tuyamcureceived over mqtt  tuyasen  tuya_mcu_received ", "linked_issue_titles": "", "title": "aligning tuyamcu code with tasmota naming conventions"}
{"description": " in kafka streams the source-of-truth of a state store is in its changelog, therefore when committing a state store we only need to make sure its changelog records are all flushed and committed, but we do not actually need to make sure that the materialized state have to be flushed and persisted since they can always be restored from changelog when necessary. on the other hand, flushing a state store too frequently may have side effects, e.g. rocksdb flushing would gets the memtable into an l0 sstable, leaving many small l0 files to be compacted later, which introduces larger overhead. therefore this pr decouples flushing from committing, such that we do not always flush the state store upon committing, but only when sufficient data has been written since last time flushed. the checkpoint file would then also be overwritten only along with flushing the state store indicating its current known snapshot. this is okay since: a) if eos is not enabled, then it is fine if the local persisted state is actually ahead of the checkpoint, b) if eos is enabled, then we would never write a checkpoint file until close. here's a more detailed change list of this pr: do not always flush state stores when calling pre-commit; move statemgr.flush into post-commit to couple together with checkpointing. in post-commit, we checkpoint when: a) the state store's snapshot has progressed much further compared to the previous checkpoint, b) when the task is being closed (but as a minor optimization, we would avoid checkpointing on closing if it is exactly the same as the previous one). there are some tricky obstacles that i'd have to work around in a bit hacky way: for cache / suppression buffer, we still need to flush them in pre-commit to make sure all records sent via producers, while the underlying state store should not be flushed. i've decided to introduce a new api in cachingstatestore to be triggered in pre-commit. ", "commit_messages": " first commit  major fixes  flush cache before commit  suppression buffer needs to be flushed too ", "linked_issue_titles": "", "title": "decouple flushing state from commiting"}
{"description": " features included in this pr: server-side of tls 1.3 key-exchanges: secp256r1 and x25519 resumption zero-rtt sni alpn ocsp stapling todos: correctly handle partial record receives log session ids (no need, since we don't log session tickets for tls 1.2) support for logging secrets (since we cannot do this in openssl 1.0.2) log if the request was early-data it's hard, and we might not need this; let's postpone testing ", "commit_messages": " extract  add picotls to xcodeproj  add picotls to cmakefile  change type of the argument to size_t  add picotls support  implement ocsp stapling ", "linked_issue_titles": "", "title": "tls 1.3 support using picotls"}
{"description": " original pr: #23964 this is a pure tooling update. it doesn't require a release candidate. this pr adds a script to generate language-specific documents and push to github. it relies on docker to consistently produce document pages via various tools. currently supported languages: core/c++/objc/c#/php/python. although this script only generates document, it needs to compile python binaries. it took < 5 minutes to run on my desktop. this script creates a branch with name \"doc-\" followed by current grpc version. it also pushes to github assuming your fork of grpc is named \"/grpc\". take my username as an example: $ tools/distrib/docgen/all_lang_docgen.sh lidizheng ... ================================================================= successfully generated documents for version doc-1.32.0-dev. ================================================================= please check  click  welcome to add generation logic for more languages! ", "commit_messages": " add a script to generate all languages doc and push to github  make shellcheck happy  add a link to automatically create a pr  resolve comments  shallow update not allowed (--depth) ", "linked_issue_titles": "", "title": "add a unified doc generation script to 1.32"}
{"description": " introduce a number of small improvements to our handling of tuple types: when forming a type name from tuple metadata, include the labels (e.g., for dynamic casting failure diagnostics) teach the sil optimizer about casting between tuple types teach the runtime dynamic casting implementation to allow adding/dropping labels there's still a bit more work to do here: we should perform per-element casting in the runtime, and printing of tuples doesn't include the labels. resolves rdar://problem/28121915. ", "commit_messages": " [runtime] include tuple labels when printing the runtime name of a type.  when we started recording labels within the metadata for a tuple type,  we failed to print those labels when rendering the type name from  metadata.  [sil optimizer] determine feasibility of dynamic casts between tuple types.  the sil optimizer logic that determined feasability of dynamic casts  completely ignored tuple types, therefore assuming that they would  always fail. check for structural identity, ignoring adding/removing  labels. fixes rdar://problem/28121915.  [runtime] handle tuple/tuple dynamic casts that add/remove labels.  introduce narrow support for tuple/tuple dynamic casts that merely add  or remove labels, but require the element types to match exactly. this  gets us back to allowing the same correct dynamic casts as in swift  3.0, when labels were completely ignored. ", "linked_issue_titles": "", "title": "improvements to casting/metadata of tuple types"}
{"description": " identical to #71764 except the rsyncs needed the --links flag: runcommand rsync -av --delete \"${ephemeral_dir}/app.framework\" \"${xcode_frameworks_dir}\" runcommand rsync -av --delete --links \"${ephemeral_dir}/app.framework\" \"${xcode_frameworks_dir}\" macos version of #51453.  see details and discussion there. push linker and embedding logic into the tool so future changes (like distributing as an xcframework, renaming fluttermacos.framework, etc) do not require changes in the user's project. at some point fluttermacos.framework will ship with x86 and arm slices.  with this change, we will be able to introduce thinning (as ios does) in the script without requiring a user project migration. this change would also set us up to stop copying fluttermacos.framework to flutter/ephemeral.  on ios, for example, the framework is copied directly from the artifacts directory to the built_products_dir so there's never a mismatch between a release build and a debug version of flutter. remove app.framework and fluttermacos.framework link step in template build phase. remove app.framework and fluttermacos.framework from the framework embedding build phase. add migrator to do this automatically based on the xcode identifiers.  i confirmed these are the original template identifiers introduced in #40851. build the example and integration test macos apps and see them migrate. remove disable_input_output_paths from the generated podfile, and from the example projects.  now that fluttermacos.framework isn't being technically emitted by a build phase, the #33684 workaround is no longer necessary. future documentation add a macos doc like  add a website note like flutter/website#4019 that disable_input_output_paths can be deleted.  we decided not to automatically migrate this for existing ios projects. related issues fixes #56581 part of #70413 will make #60113 easier. macos_project_migration_test ", "commit_messages": " move embedding and linking macos flutter frameworks into the tool (#71764)  --links ", "linked_issue_titles": " macos xcode project should move framework linking to tool ", "title": "reland move embedding and linking macos flutter frameworks into the tool"}
{"description": " this may be a good example as the open source code demonstrates how to customize mui components using styled-components and use a theme with overrides. as a side note, in my opinion, the outcome looks fairly attractive :) ", "commit_messages": " added typekev to showcase  added an image for the typekev showcase submission ", "linked_issue_titles": "", "title": "add typekev.com to showcase page"}
{"description": " this adds the audio frame classification (equivalent of token classification) and x-vector (speaker embedding extraction) heads to wav2vec2 and unispeech-sat models. the target tasks for the heads are superb's speaker diarization and speaker verification respectively. these were mainly motivated by unispeech-sat, since the model performs better on those tasks, rather than on asr. sources for the models and weights from the superb's s3prl framework: modelforaudioframeclassification:  modelforxvector:  the heads for both w2v2 and us-sat were finetuned from scratch, since the official checkpoints use custom (better) heads that are incompatible with superb's evaluation protocol. ", "commit_messages": " models  squashed commit of the following:  commit 72278e1e931a16d0879acc77f65762f3364833d0  author: anton-l <aglozhkov@gmail.com>  date:   fri dec 10 21:45:08 2021 +0300  add unispeech heads ", "linked_issue_titles": "", "title": "add speaker diarization and verification heads"}
{"description": " the version of lobpcg in scipy has recently benefited from some bug fixes. we should update the version that we have in master. ", "commit_messages": " ehn update lobpcg  wait for scipy 1.4 ", "linked_issue_titles": "", "title": "ehn update lobpcg from scipy master"}
{"description": " mojaave.com is mahipat's portfolio, i have developed it using gatsby v2 and bootstrap. ", "commit_messages": " updated netlify demo url and description  new demo url -  dummy test  revert \"dummy test\"  this reverts commit d9aab9fa76fed3a1f66dfd73198f2addfeca01a7, reversing  changes made to da850ad8fe47537b1fc08bf095eb98eb41eac994.  merge with origin master branch  adding bootstrap cv starter in the starter list  adding  added source url and made changes in description  added new line at the end of the file ", "linked_issue_titles": "", "title": "add a site(https://mojaave.com) to showcase list"}
{"description": " keeps the same features but adds flexibility thanks to the new api moves gleed to the core. even though gleed it's windows only, anyone could write a script to convert between formats. i'd be happy to make changes if needed. ", "commit_messages": " !a - adds gleed system using new api  !t - consistency pass on map base classes  !d - deletes gleed extension (moves it to core)  !t - updates map, uses sensible texture size and more than 200 objects  !f - adds touch controls to gleed test  !t - better real screen size handling  !t - changes m_mpp for m_units (metres per pixel)  !t - adds gleed map documentation and license headers ", "linked_issue_titles": "", "title": "adapts gleed system to new maps api"}
{"description": " this replaces the pr #1559 in addition to it: further simplifications and readability improvements. replaced the \"shallow\" directive todo-escape with the native angular ng-keydown. one less reason to complain angular is complex :) ", "commit_messages": " angularjs-perf: remove global var todomvc  angularjs-perf: wrap into anonymous functions  angularjs-perf: change to controller as syntax  angularjs-perf: simplified functions  angularjs-perf: removed todo-escaped directive  using the native ng-keydown instead ", "linked_issue_titles": "", "title": "removed globals, readability, simplified or removed components - replace pr #1559"}
{"description": " fixes #9347 fixes #45693 fixes #57803 ", "commit_messages": " fix a bunch of issues with conpty  add use conpty setting  fix use conpty setting  node-pty@0.7.8-conpty1  node-pty@0.7.8-conpty2  flip default to use conpty based on build number  we can revert this before stable if there are bit issues, but the fact that  #57803 goes away is pretty big.  rename experimentaluseconpty to windowsenableconpty  node-pty@0.8.0 ", "linked_issue_titles": " integrated terminal: ctrl-c doesn't work in powershell and cmd.exe  windows terminal issues caused by winpty  terminal not in a good state initially on windows insider builds ", "title": "add terminal conpty support on windows"}
{"description": " this is a convenience pr fix a littlefs bug: avoid crash at boot when fs size is 0 debug message in fs when implementation cannot start change defaults in arduino ide menus in details, new default options: esp-now is working flash size: 1m for generic board (instead of 512k) fs: maximal not-0 size with maximal size for sketch+ota ", "commit_messages": " enable by default latest 2.2.x firmware, including fixed espnow  littlefs: avoid crash when fs size is 0  serial speed defaults to 921k in menu for all boards (testing, since esptool.py)  flash size defaults: 1m for generic board, not empty fs for all  default fw for platformio too  cosmetics ", "linked_issue_titles": "", "title": "switch default fw to \"2.2.2-dev(38a443e)\" (menu:2.2.1+100)"}
{"description": " this should fix issue #5990 serde's #[serde(with = \"serde_bytes\")] field attribute signals that vec<u8> is meant to be binary data and should map to flexbuffer's blob instead of vectoruint. after this pr, i will publish the crate as version 0.1.1. @rw ", "commit_messages": " serde with_bytes maps to blob  bump rust flexbuffers minor version number ", "linked_issue_titles": "", "title": "serde with bytes maps to blob"}
{"description": " detailed list of changes: in lib\\profilefunctions.js: added profile.profilefromtime changed: getcurrentprofile to use it activeprofiletotime activeprofiletreatmenttotime in static/report/js/report.js: add loadprofilesrange which loads only the profiles for the day range, and the profile(s) before and after based on the startdate of the profile changed loadprofileswitch to use loadprofilesrange note: loadprofilesrange uses a ajax $.when to chain three sync api calls - this doesn't feel right, but unless the profiles are all loaded the subsequent processing will fail. i also wanted to re-use as much existing code to speed up changes, so didn't implement the code server side existing loadprofiles i think now becomes redundant in lib\\report-plugins\\daytoday.js: use profile.loaddata to load daily basal profiles (which now has the correct profile range by using loadprofilesrange) this then means the subsequent call to profile.gettempbasal returns the correct value in lib/report_plugins/profiles.js: added a check to make the routine more robust in error conditions in lib/server/profile.js and lib/api/profile/index.js: added the same query model into profiles as the other apis in profile.test.js: added new tests for multi-profile testing ", "commit_messages": " pulling latest master  test profile settings  npm version change  use console log  use console log for client  use console log for client.sbx  use console log for client.ddata  use console log for client again  revert  used the new nightscout config  upgrade  resolved minor differences  added multi-profile reporting capabilities ", "linked_issue_titles": "", "title": "fixes #4991 - now selects basal profile based day by day"}
{"description": " which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #69590 does this pr introduce a user-facing change?: the cabundle and service fields in admission webhook api objects now correctly indicate they are optional ", "commit_messages": " fix omitempty/optional indicator on cabundle fields  generated files  add system root unit test ", "linked_issue_titles": " cabundle should not be required in webhook clientconfig ", "title": "correct optional/omitempty indicator on webhook cabundle"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < ", "commit_messages": " add missing type  update test  add name to definitions by ", "linked_issue_titles": "", "title": "add types to allow string array argument for hmset"}
{"description": " option -p  to specify persistence path save persistence files on sigterm too (not only sigint) ", "commit_messages": " stack protection  fix warnings  emulation on host: option -p to change fs persistence location  exit on sigterm too, with sigint ", "linked_issue_titles": "", "title": "option for fs persistence location"}
{"description": " was trying to run benchmarks, and bumped into some issue (+ the datamatrix, i just removed that as this is now removed from pandas, so not much sense having benchmarks for that) ", "commit_messages": " cln: fix params list  fix issue in asv.conf.json for win32+other environment  fix mistaken exclusion of virtualenv or existing:same on win32 in the config.  credits: @pv  cln: remove datamatrix ", "linked_issue_titles": "", "title": "fix some issues in asv benchmark suite"}
{"description": " this is #18130 rebased. trimstring is an existing alternative. note trimstring uses \" \\f\\n\\r\\t\\v\" as the pattern, which is consistent with the default behavior of std::isspace. see: ", "commit_messages": " replace use of boost::trim use with locale-independent trimstring  replace use of boost::trim_right with locale-independent trimstring  note the only use of readstdin is fed to decodehextx, which fails in  ishex on non-hex characters as recorded in p_util_hexdigit.  tests: add trimstring(...) tests ", "linked_issue_titles": "", "title": "replace uses of boost::trim* with locale-independent alternatives (#18130 rebased)"}
{"description": " part of #29272 fyi: all changes are generated from a script posted in the issue. tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff fyi: when the remaining prs of this are merged, i'll add another one to add the linting rule - then we can close the issue ", "commit_messages": " fixed test util imports in remaining pandas/tests files  replaced 'from pandas.util import testing as tm' with 'import pandas.util.testing as tm' ", "linked_issue_titles": "", "title": "consistent pandas.util.testing imports in remaining test suite"}
{"description": " switched license in repo from lgplv3 to apache2.0 and added a license comment to the minified build. ", "commit_messages": " switched license over from lgplv3 to apache2  added copyright banner to top of distribution video.js  grunt now adds copyright comment to top of video.js  merge remote-tracking branch 'upstream/master'  added license to readme ", "linked_issue_titles": "", "title": "switched license from lgplv3 to apache2.0"}
{"description": " added mask rcnn 3x multi-scale training config result model box ap mask ap mask_rcnn_r50_fpn_mstrain-poly_3x_coco 40.9 37.1 mask_rcnn_r101_fpn_mstrain-poly_3x_coco 42.7 38.5 mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco 42.9 38.5 mask_rcnn_x101_32x4d_fpn_mstrain-poly_3x_coco 43.6 39.0 mask_rcnn_x101_32x8d_fpn_mstrain-poly_3x_coco 44.3 39.5 mask_rcnn_x101_64x4d_fpn_mstrain-poly_3x_coco 44.5 39.7 mask_rcnn_regnetx-400mf_fpn_mstrain-poly_3x_coco 35.7 37.6 32.8 34.4 mask_rcnn_regnetx-800mf_fpn_mstrain-poly_3x_coco 38.0 39.5 34.7 36.1 mask_rcnn_regnetx-1.6gf_fpn_mstrain-poly_3x_coco 39.5 40.9 36.1 37.5 mask_rcnn_regnetx-4gf_fpn_mstrain-poly_3x_coco 42.2  43.4 38.3 39.2 ", "commit_messages": " add mstrain 3x models  fix  fix backbone  caffe norm ", "linked_issue_titles": "", "title": "add mask r-cnn 3x mstrain config"}
{"description": " #470 added support for using the 5-point facial feature extraction model from the face_landmarks() function. these are minor updates to support that: update doc strings add a test update example so it doesn't break if you use the 5-point model fyi @vermeille ", "commit_messages": " update doc strings and examples to support 5-point face model  add test for small face model ", "linked_issue_titles": "", "title": "small updates to support #470"}
{"description": " moves the non-multistream specific state to its own class. this will be necessary to support the multistream variants of opus decoding, given the overall decoder state parameters differ from the regular non-multistreamed version of the decoder. ", "commit_messages": " service/audio/hwopus: enclose internals in an anonymous namespace  makes it impossible to violate the odr, as well as providing a place for  future changes.  service/audio/hwopus: move opus packet header out of the ihardwareopusdecodermanager  this will be utilized by more than just that class in the future. this  also renames it from opusheader to opuspacketheader to be more specific  about what kind of header it is.  service/audio/hwopus: provide a name for the second word of opuspacketheader  this indicates the entropy coder's final range. ", "linked_issue_titles": "", "title": "move decoder state to its own class"}
{"description": " #14890 ## what this pr does / why we need it: to be able to inject custom nginx directive into kong. this is particularly necessary when using kong enterprise with rbac enabled on the kong manager and prometheus plugins is needed. (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " [stable/kong] added custom nginx template injection capability via config map  [stable/kong] bump version ", "linked_issue_titles": "", "title": "add nginx custom template feature via config map"}
{"description": " add direct call mode for normal tasks in java worker. the usedirectcall is now an option of basetaskoptions. due to #5559, the option is not open to users right now. this pr also removes the direct_call test group, since now almost all test cases should be verified under direct call mode, not just the actor tests. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " enable direct call for normal tasks  fix java tests ", "linked_issue_titles": "", "title": "support direct call for normal tasks"}
{"description": " original pull-request #31528 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " remove partial_merge_join_optimizations  this option is redundant because optimization is controlled by partial_merge_join_left_table_buffer_bytes  disable partial_merge_join_left_table_buffer_bytes due to bug ", "linked_issue_titles": "", "title": "disable partial merge join left table buffer bytes"}
{"description": " it was suggested in sr-14667 to remove the potentially confusing .dynamictype diagnostic suggesting users to use type(of:  instead. this pr removes that diagnostic and leaves the other diagnostic: \"foo has no value .dynamictype\" resolves sr-14667. link: ", "commit_messages": " removes dynamictype diagnostic. fixes sr-14667  fix test cases related to dynamictype ", "linked_issue_titles": "", "title": "remove dynamic type diagnostic suggesting using type(of: instead"}
{"description": " replacing the deprecated method \"random.choose\" to \"random.choice\" was technically not part of the original issue. however, it was discussed in the talk page and involved one of the files being moved. i assumed this was too minor to justify the creation of a separate issue. also, i added my name to the contributors list in misc/acks. this will be my third pr to cpython, forgot to do it in the previous ones. ", "commit_messages": " replace deprecated method  replaced deprecated method \"random.choose\" with \"random.choice\" (  added name to contributors list  this will be my third pr to the cpython repository, forgot to add my name in the previous ones. ", "linked_issue_titles": "", "title": "replace deprecated method in \"test_import_pkg.py\""}
{"description": " the contributor covenant at ", "commit_messages": " added to code_of_conduct.md to include link to faq about the code of conduct  added to code_of_conduct.md to include link to faq about the code of conduct ", "linked_issue_titles": "", "title": "add faq to code of conduct"}
{"description": " two riscv-related improvements: update opcodes from binutils-gdb. update to riscv opcodes from riscv-binutils-gdb git 08219b2. set no_alias=false while disassembling: i'm not sure what the rationale was for setting no_alias to true originally. but setting it to false means that shorter and (usually) better readable aliases for instructions will be shown: before after c.jr ra ret addi a5, zero, 123 li a5, 123 jal zero, 0x101dc j 0x101dc and so on. will submit a test update for this to radare2-regressions: ", "commit_messages": " riscv: update opcodes from binutils-gdb  update to riscv opcodes from  [riscv-binutils-gdb](  git 08219b2.  riscv: set no_alias=false while disassembling  i'm not sure what the rationale was for setting no_alias to true  originally. but setting it to false means that shorter and (usually)  better readable aliases for instructions will be shown:  before               |  after  ---------------------+------------  c.jr ra            | ret  addi a5, zero, 123 | li a5,123  jal zero, 0x101dc  | j 0x101dc  and so on. ", "linked_issue_titles": "", "title": "update riscv opcodes for disassembly"}
{"description": " replaces #881.  fixed memory consumption issue by replacing replaysubject with publishsubject and adding an atomicboolean to collapsedrequestobservablefunction to track if a value has been set on the response yet ", "commit_messages": " allowing collapsers to return multiple values per request argument.  addresses #865  modify observablecollapser jmh test to allow multiple response per argument ", "linked_issue_titles": "", "title": "multiple responses per collapser arg"}
{"description": " some application servers speaking http/1.1 is capable of listening to an unix-domain socket (which is often faster and easier to operate than tcp sockets). this pr add to the proxy implementation of h2o the support to connect to such servers. the url of such a server is expressed by  obsoletes #51 ", "commit_messages": " accept test mode as command line options  simplify  simplify  it works!  support testing http backends using unix-domain sockets by: perl t/50reverse-proxy/test.pl --unix-socket=1 (note: requires an unreleased version of starlet)  test the behavior when using unix-domain-socket based backend ", "linked_issue_titles": "", "title": "connect to application server via unix-domain socket"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: microsoft/typescript#3626 increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " case matters in linux  fix files in tsconfig  fix ol-test ", "linked_issue_titles": "", "title": "change some file names to uppercase because linux is case sensitive."}
{"description": " add basic support of tcplisterner for hermitcore revise tcpstream to support peer_addr ", "commit_messages": " add tcplistener support for hermitcore  add basic support of tcplisterner for hermitcore.  in addition, revise tcpstream to support peer_addr.  remove unused function  use latest interface to hermitcore ", "linked_issue_titles": "", "title": "extend network support for hermitcore"}
{"description": " we still need constvalue::scalarpair for match handling (matching slices and strings), but that will never see anything undef. for non-fat-ptr scalarpair, just point to the allocation like larger data structures do. fixes #54387 r? @eddyb ", "commit_messages": " do not normalize non-scalar constants to a constvalue::scalarpair  move scalarmaybeundef into the miri engine ", "linked_issue_titles": "", "title": "do not normalize all non-scalar constants to a constvalue::scalarpair"}
{"description": " issue #2165 1.when brokerid not found and read from slave, use brokerid + 1 as the key 2.add unit test follow this checklist to help us incorporate your contribution quickly and easily. notice, it would be helpful if you could finish the following 5 checklist(the last one is not necessary)before request the community to review your pr. make sure there is a github issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test(over 80% coverage) to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean apache-rat:check findbugs:findbugs checkstyle:checkstyle to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. if this contribution is large, please file an apache individual contributor license agreement. ", "commit_messages": " [client] fix slavereadenable=true not work sometimes when cluster deployed on dledger mode  [client] add unit test for findbrokeraddressinsubscribe ", "linked_issue_titles": " slavereadenable=true not work when cluster deployed on dledger mode sometimes[followed #2157] ", "title": "slave read enable not work sometimes when cluster deployed on dledger mode"}
{"description": " requirements filling out the template is required. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. all new code requires tests to ensure against regressions description of the change adds a new feature request issue template and uses the current issue template as the bug report issue template to take advantage of the new issue template chooser:  alternate designs could leave things as is but we did find the current issue template is more bug report focused which caused some folks to delete it and leave a 1 or 2 sentence feature request.  also, a separate feature request specific template should hopefully encourage more detailed feature requests. why should this be in core? needs to be so it shows up in the issue template chooser. benefits as mentioned above, a more feature request focused issue template will hopefully encourage people to describe why they want something in addition to encouraging them to look at atom's customizability in case the feature can be satisfied without changes to atom. possible drawbacks it's possible that the extra friction for feature requests might discourage someone from making a feature request, but it's helpful for us to have more information about the what/why/alternatives considered. verification process after merging: create a new issue and make sure the template chooser shows. check that the bug report issue template is the current default issue template. check that the feature request issue template is the one being added here. applicable issues n/a ", "commit_messages": " create bug_report.md  create feature_request.md ", "linked_issue_titles": "", "title": "add feature request issue template"}
{"description": " since wrapping bindings into optional type based on expressiblebynilliteral or adjusting position of any doesn't affect ranking it could be performed by typevarbindingproducer instead. ", "commit_messages": " [csstep] don't retain multiple copies of the same bindings just for printing  [constraintsystem] handle binding nullability in producer instead of collector  wrapping bindings into optional type based on presence of  an expressiblebynilliteral conformance requirement should  be done after type variable has been selected for attempting.  otherwise such upfront work would be wasteful since it doesn't  affect binding ranking in any way.  [constraintsystem] make binding producer responsible for attemping any last  instead of doing that while collecting bindings, let's move any  to the end of the list when type variable has been selected to be  attempted next.  [constraintsystem] nfc: extract requiresoptionaladjustment so it could be used for default bindings ", "linked_issue_titles": "", "title": "make binding producer responsible for adjustments to the binding set"}
{"description": " closes #32806 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry this is my first pr against this project, so apologies if i've missed any steps in the process. i'm assuming that i'm supposed to fill in the checklist above myself. this pull request adds the fullmatch regular expression matching mode to the other modes already present under the series.str namespace. for example: >>> s = pd.series([\"foo\", \"bar\", \"foobar\"]) >>> s.str.fullmatch(\"foo\") 0     true 1    false 2    false dtype: bool the fullmatch matching mode restricts matches to those that only match the entire string. note the differences from match: >>> s = pd.series([\"foo\", \"bar\", \"foobar\"]) >>> s.str.fullmatch(\"foo\") 0     true 1    false 2    false dtype: bool >>> s.str.match(\"foo\") 0     true 1    false 2     true dtype: bool i've also added regression tests and a \"what's new\" entry. i have also opened issue #32806 to cover this new feature. ", "commit_messages": " document new functionality  add fullmatch matching mode to series.str  add tests of series.str.fullmatch  add tests of series.str.fullmatch  fix formatting ", "linked_issue_titles": " enh: allow regex matching in `fullmatch` mode ", "title": "add \"fullmatch\" matching mode to series.str [#32806]"}
{"description": " use shared memory atomics (wherever possible) for building histograms. currently, i tested this on 2m rows of airline dataset, tesla v100, cuda v9.0, depthwise tree grow, max-depth=5, numtrees=100. here are the training numbers with and without shared mem atomics. w/o smem: train_time (s): 44.84 w/ smem: train_time (s): 16.98 current change, at runtime, decides to use shared memory for building histogram, if there's enough shared mem available, else, falls back to global mem atomics. ", "commit_messages": " use shared memory atomics for building histograms, whenever possible  fixed shared mem atomics crash issue.  also fixed stray code from a previous incorrect merge.  reverted my accidental checkin of commented python tests.  fixed code styles ", "linked_issue_titles": "", "title": "shared memory atomics while building histogram"}
{"description": " this is the first in a series of prs that updates the mandatory passes for semantic sil. in this pr, i update capture-promotion and move the ownership model eliminator after it. rdar://29870610 ", "commit_messages": " [capture-promotion] refactor out into methods the handling in project_box, partial_apply to helper functions.  [capture-promotion] extract scanning the box for interesting uses into its own helper function and use a higher order function instead of a loop.  [sil] add a new api valuebase::getsingleuser()  this api returns nullptr if the valuebase has more than one user and an  operand * otherwise.  [gardening] use macros and a detail enum to make some code more compact. ", "linked_issue_titles": "", "title": "update capture promotion for semantic sil and move ownership model eliminator after it"}
{"description": " switch to using register_code16() and rename tapdance keys to match the left and right terminology preferred in qmk. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " use register_code16 and relatives for tapdance code  rename tapdance keys to more closely mirror the kc names in qmk ", "linked_issue_titles": "", "title": "use register_code16() and its variants in lieu of separate mod registration"}
{"description": " @matthiasplappert we (@ndrwmlnk @llach) covered the hand model with 92 touch sensors and extended the handmanipulate{block, egg, pen}-v0 environments to handmanipulate{block, egg, pen}touchsensors-v0. now, an observation additionally contains 92 touch values (0 - no touch, 1 - touch detected). sensory information allows faster and better convergence (preliminary results). test the environments with pre-trained weights (currently in training):  python baselines/her/experiment/play.py handmanipulateblocktouchsensors.pkl python baselines/her/experiment/play.py handmanipulateeggtouchsensors.pkl python baselines/her/experiment/play.py handmanipulatepentouchsensors.pkl touch sensor sites are tailored to physical geoms (robot0:dc_hand), thus may visually overlap with meshes (robot0:d_vizual). active touch sensors are highlighted in red, inactive sensors - in green:  sensors_cube_geoms.mp4 sensors_cube_mesh.mp4 sensors_cube.mp4 sensors.mp4 ", "commit_messages": " extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  add touch sensors layout  add touch sensors layout  extending robotics shadow hand with touch sensors  extending robotics shadow hand with touch sensors  add touch sensors layout ", "linked_issue_titles": "", "title": "envs robotics - touch sensors - shadow hand"}
{"description": " what's in this pull request? explanation: these valuable fixits for adding ( as anyobject) trying to do anyobject calls on an any, and for transforming protocol<...> syntax to use & come from notes and warnings.  as such we need to explicitly enable them in the jsonfixitwriter for migration. scope: aides migration to swift 3.0 risk: low; these are fairly straightforward fixits that should not cause unintentional harm during migration. reviewed by: xi ge testing: regression tests added. resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " [fixcode] add ( as anyobject) fixit to the whitelist  this fixit comes from a note, but is very useful for migration of code  that has changed from anyobject to any but wants to do anyobject  dispatch.  rdar://problem/27793389  [fixcode] enabled protocol<...> fixits  the old syntax is deprecated in swift 3, and these fixits seem quite  safe, so apply them for migration.  rdar://problem/27794981 ", "linked_issue_titles": "", "title": "enable ( as anyobject) and protocol<...> fixits"}
{"description": " fixes #16723 it's essentially the benchmark suite started here. the main goal is to be able to easily ask for a benchmark when a pr might impact performance. the benchmark suite includes only a subset of the sklearn estimators but we can add new ones after. obviously, adding more estimators make the whole run to take longer and having all estimators would take several hours. right now, the run takes an hour and a half on my laptop, with n_jobs=1, with an empty cache, with the default configuration. with the fastest config and some stuff cached it goes down to 20 min. todo: add documentation ping @rth ", "commit_messages": " move asv benchmark suite to scikit-learn  cln  don't track cache  config ", "linked_issue_titles": " add benchmarks ", "title": "mnt add asv benchmark suite"}
{"description": " the previous commit dated from the ts 1.6 era and does not compile on ts 2.7+. the ts default lib now includes most of the extensions and such interfaces that are now built-in have been removed from here. breaking: all interface names now use snake_case names like the built-in ones breaking: now requires ts 2.7 or newer add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). this pr changes an existing definition: provide a url to documentation or source code which provides context for the suggested changes: #29897 increase the version number in the header if appropriate. (not there to begin with) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. (already there) fixes #29897 ", "commit_messages": " add missing optional attributes parameter for getcontext() and missing context attribute defs, thanks to @ander-nz  name update  add pre-defined attrs and link to spec for webglcontextattributes  merge remote-tracking branch 'definitelytyped/master'  merge remote-tracking branch 'upstream/master'  remove types from old location  update webgl-ext types to work with ts3  add ts min version header to webgl-ext ", "linked_issue_titles": "", "title": "update webgl-ext types to work with ts2.7+"}
{"description": " since we are using gcs client as kv backend, we need to make it auto-reconnect in case of a failure. this pr adds this feature. this pr adds auto_reconnect decorator to gcs-utils and in case of a failure it'll try to reconnect to gcs until it succeeds. this feature right now support redis which should be deleted later once we finished bootstrap since kv will always go to gcs. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " up  up  up  up ", "linked_issue_titles": "", "title": "make gcs client in python able to auto reconnect"}
{"description": " in addition, prevent capable from reporting itself in the trace. ", "commit_messages": " add kernel stack trace option to capable  capable: avoid stack trace overwrite  use 0 in get_stack() to avoid overwriting the stack trace in the  kernel for the same stack_id.  capable: print both tid and pid  add user-space stack trace option to capable  capable: avoid catching itself  capable: drop unused member pid_tgid in struct  capable: report a proper error message when stack trace is missing  print [missed user stack] or [missed kernel stack] when get_stackid()  returns an error.  capable: add missing errno import ", "linked_issue_titles": "", "title": "add user and kernel stack trace options"}
{"description": " what is this about? this pr fixes some incorrect results and exceptions being thrown by the calculator plugin which might be slowing down pt run. pr checklist applies to #7437 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? the following changes have been made in this pr - following the refactoring of the calculator plugin, the searched which resulted in 0 as the result were not working as there was no difference between a default result returned when the input was not valid and a valid input resulting in 0 as the answer. the validresult field has been added to distinguish a valid result from a default result. null couldn't be returned because calculateresult is a non-nullable type. eg: 1-1. exceptions were being thrown when the user query is not complete, as the queryhelper thinks that the query is valid but the interpreter doesn't. eg: sin, 1+2+ when a string corresponding to a function is the user query an exception is thrown because it is not a valid interpreter input. eg: say hypothetically we're seraching for some app named logo, then on entering log the calculator plugin would be invoked as there is a match with the regex, however, it is not a valid input to the interpreter. there were some functions such as bin2dec, hex2dec, eigval, etc which are not valid inputs to the mages.interpreter function. hence it has been removed. otherwise, the calculator helper would think that these inputs are valid as they match the regex but the mages.interpreter function would throw an exception as they are not valid mathematical oparations according to it. the ideal way to capture a valid input would be using a bnf for a mathematical operation but that cannot be captured in a regex. validation steps performed how does someone test & validate? added tests. manually validated it ", "commit_messages": " remove functions which mages cannot interpret and add in functions which mages can  set validresult when the result is explicitly created to differentiate it form an empty calculateresult  add condition to check that the input is not ending with a binary operation  add tests for all the cases ", "linked_issue_titles": "", "title": "fix exceptions and incorrect results within the calculator plugin"}
{"description": " cherry-picked re-roll of #4156 this is to support the version 2 of the rigidbot motherboard.  it has the same pin-out but has stepper digipots controlled by an mcp4728 dac.  added new board type and updated the dac coding to the current wire library: wire.receive() -> wire.read  wire.send() -> wire.write() major contributor was jayson kelly, who made the first cut at the coding. ", "commit_messages": " support for rigidbot v2  support dac_or_address in printrboard too ", "linked_issue_titles": "", "title": "rigidbot v2 support - has mcp4728 digipot"}
{"description": " this replaces the hand-rolled node version setup with a new feature that was introduced in babel-preset-env@v0.0.7:  changes between 0.0.6 and 0.0.8 should be backwards compatible. ", "commit_messages": " update babel-preset-env to 0.0.8  changes between 0.0.6 and 0.0.8 should be backwards compatible:    use node: 'current' as target for babel-preset-env  this replaces the hand-rolled node version setup with a new feature that  was introduced in babel-preset-env@v0.0.7   ", "linked_issue_titles": "", "title": "update babel-present-env and use node: 'current' as target"}
{"description": " we are moving test262 and rwc into internal repository.this pr is to update the test262 and rwc path used by the runner ", "commit_messages": " update path to test262 and rwc tests files in the runners ", "linked_issue_titles": "", "title": "update rwc and test262 runner"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: since this pr #19777 got closed i picked it to provide the same fix increase the version number in the header if appropriate. i am not sure this is needed. i can fix it after code review note: i am quite new to typescript ", "commit_messages": " fix onchange and onblur parameters  add semicolon  fix definition ", "linked_issue_titles": "", "title": "redux form onchange onblur fix"}
{"description": " if a function always returns ok(something), we can return something directly and remove the corresponding error handling in the callers. clippy::unnecessary_wraps ", "commit_messages": " remove unneccessary wrapping of return value of allow_unstable(), it would always return some(thing)  rustc_parse: remove unneccessary wrapping of return value in fn mk_range() which would always return ok(..)  remove unneccessary wrapping of return value in mk_await_expr()  parser: remove unneccessary wrapping of return value in parse_extern()  remove redundant return value ok(()) of clear_relocations()  rustc_codegen_ssa: remove unneeded wrapping of return type of execute_copy_from_cache_work_item (always returns ok(..))  rustc_mir: remove redundant wrapping of return type in numeric_intrinsic() ", "linked_issue_titles": "", "title": "remove redundant option/result wrapping of return values"}
{"description": " i'm using locust as a library for my custom tests scenarios, and i need to identify my test users with authentication tokens that are received from another stress test system. i had some trouble accomplishing that with the current structure, since we can't add extra parameter to user's __init__ when they are spawned. this pr addresses this. let me know if there is a better way to do that. ", "commit_messages": " allow extra constructor parameters when building user  adding some documentation ", "linked_issue_titles": "", "title": "return the new users on runner.spawn_users"}
{"description": " backport of #19756. addresses #18419: hard to navigate docs front page i'm working with @rossbar to implement the following changes: remove html templates remove references of html templates add sphinx-panels as a extension replace index.html/documentation front page with index.rst update the overview page, following this mock-up create the getting started page, which includes brief installation instructions and links to various guides, depending on user profile (absolute beginners, f2p, etc) -> this change will be in a future pr instead ", "commit_messages": " delete html templates  delete reference to html files  add sphinx-panels as an extension  add sphinx-panels as requirement  modify template  modify panel styling  add getting started page  add images to index.rst  adjust image size to be consistent  move images to different folder  change file path for images  replace svg with higher resolution  change color of svgs  modify styling of panels  update getting started panel text  change image path for getting started panel ", "linked_issue_titles": "", "title": "update front page of documentation with sphinx-panels"}
{"description": " output of roi_perspective_transform op  add mask and transform matrix, test=develop ", "commit_messages": " track_official_repo  track offical update  track official  track official  track official  track official  modify roi_perspective_transform_op to output mask and transform matrix  modify comment  modify comment  modify api.spec  pull develop before push ", "linked_issue_titles": "", "title": "make roi_perspective_transform op return mask and transform matrix"}
{"description": " abstract support locales and fix few bugs. this changes are based on recent master of faker. support localization by changing faker.locale see the test. support individual localization packages see the test. fix types for faker.helpers.randomize() if its param is omitted, it should return a string. see the test. fix types for faker.random.objectelement() if its param is omitted, it should return a string. see the test. 5.  fix types for faker.random.arrayelement() if its param is omitted, it should return a string. see the test 6. fix types for faker.helpers.createcard it should contains address.streeta. see the test. ", "commit_messages": " check returned values  should support locales  make test pass ", "linked_issue_titles": "", "title": "support locale (and few bug fixes)"}
{"description": " reduces checkstyle errors for patterns: ambassador async-method-invocation balking bridge builder changes involved java docs reordering imports indentations line length issues ", "commit_messages": " decreases checkstyle errors for ambassador pattern  reduces checkstyle errors in async-method-invocation  reduces checkstyle errors in balking  reduces checkstyle errors in bridge  reduces checkstyle errors in builder ", "linked_issue_titles": "", "title": "resolves checkstyle errors for ambassador, async-method-invocation, balking, bridge, builder"}
{"description": " changed the warning message to give information about the request generating it as requested in: #2927 tested with spider: import scrapy class quotesspider(scrapy.spider): name = \"test_spider\" custom_settings = { 'download_warnsize': '123', } def start_requests(self): urls = [ ' ] for url in urls: yield scrapy.request(url=url, callback=self.parse) def parse(self, response): page = response.url.split(\"/\")[-2] filename = 'test_spider-%s.html' % page with open(filename, 'wb') as f: f.write(response.body) self.log('saved file %s' % filename) which gives the requested warning message: 2017-10-05 15:41:01 [scrapy.core.downloader.handlers.http11] warning: expected response size (606) larger than download warn size (123) in request <get ", "commit_messages": " changed the log message to make it more clear. as requested in issue #2927  changed the log message to make it more clear. as requested in issue #2927  changed the log message to make it more clear. as requested in issue #2927 ", "linked_issue_titles": "", "title": "changed unhelpful log message from core.downloader.handlers.http11"}
{"description": " the existing test checks for a single user when trying to fuse a random number generator instruction.   this is because if it is fused but has multiple users, the value may be generated an incorrect number of times.  (multiple users should receive the same random number, not different ones). the test checks for users() length == 1.  this ignores the case there the instruction is the root, where users() length == 0, but there is effectively one user. ", "commit_messages": " a root rng instruction has no users, but is still fusable  add comment to explain why zero is ok ", "linked_issue_titles": "", "title": "rng root instruction can be fused as it effectively has one user"}
{"description": " this pr is doing 3 things. expose metrics_export_port to ray start & ray.init support discovery of metrics export port through ray.nodes() pass metrics_agent_port to core worker instead of getting it from ray_config_def.h. this is important because we don't want to use the same port for all metrics agent in all nodes. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " metrics export port expose done.  support exposing metrics port + metrics agent service discovery through ray.nodes()  formatting. ", "linked_issue_titles": "", "title": "metrics export user interface part 1"}
{"description": " description: fixes glances startup errors for docker containers that are not running. glances: error on device update! traceback (most recent call last): file \"/usr/src/app/homeassistant/helpers/entity_platform.py\", line 261, in _async_add_entity await entity.async_device_update(warning=false) file \"/usr/src/app/homeassistant/helpers/entity.py\", line 377, in async_device_update await self.async_update() file \"/usr/src/app/homeassistant/components/glances/sensor.py\", line 191, in async_update for container in value['docker']['containers']: keyerror: 'containers' checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " fix unavailable container errors  update to dev ", "linked_issue_titles": "", "title": "fix glances docker container errors"}
{"description": " this is #49219 up to the point where the bridge is introduced. aside from moving some code around, the largest change is the rewrite of proc_macro::quote to be simpler and do less introspection. i'd like to also extend quote! with ${stmt;...;expr} instead of just $variable (and maybe even $(... $iter ...)*), which seems pretty straight-forward now, but i don't know if/when i should. r? @alexcrichton or @dtolnay ", "commit_messages": " proc_macro: don't use diagnosticbuilder for building up diagnostics.  proc_macro: don't try to reflect literals in quasi-quoting.  proc_macro: clean up the implementation of quasi-quoting.  proc_macro: don't expose compiler-internal filename in public api. ", "linked_issue_titles": "", "title": "prepare proc_macro for decoupling it from the rest of the compiler."}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. add it to notneededpackages.json. see the readme and bundled typing to verify that this typing should be deprecated. ", "commit_messages": " add type definitions for koa-send.  merge upstream master to reflect the big types-2.0 upstream merge.  deprecate argon2 typings. they're included in the lib now.  remove unneeded file (big upstream merge mistake). ", "linked_issue_titles": "", "title": "deprecate argon2. the lib has its own typings now."}
{"description": " use updated fs api fix bug where file.m_file didn't exist in del() if we used file.close() first fs.removetree now removes tree as well as all tree contents (files). this is for a functionality sync between phantomjs and pyphantomjs all tests will now pass successfully ", "commit_messages": " use updated fs api  fix bug where file.m_file didn't exist in __del__() if we used file.close() first  fs.removetree now removes tree as well as all tree contents (files). this is for a functionality sync between phantomjs and pyphantomjs  all tests will now pass successfully  regenerate resources ", "linked_issue_titles": "", "title": "update and sync fs api"}
{"description": " backports some prs (linked below) needed for numpy 1.13.0 support in master to 0.18.x. xref: #7946 xref: #8040 xref: #8355 xref: #9010 ", "commit_messages": " fix tests on numpy master (#7946)  until now we were in a edge case on assert_array_equal  fix tests on numpy master (#8355)  numpy.apply_along_axis has changed behaviour when the function passed  in returns a 2d array ", "linked_issue_titles": "", "title": "backport numpy 1.13.0 fixes to 0.18.x"}
{"description": " hi! this pr increases the test coverage by building and testing the library in c++ 98, 03, and 0x mode with travis. the older standards are only tested in release mode to reduce the number of builds. ", "commit_messages": " state that sudo is required for ci  this informs travis that the container-based build environment can  not be used.  treat format.cc like a header  given that it is required for header only builds it has to be  installed too.  build and test in c++11 and in c++98 mode  test in c++ 98, 03 and 11 mode  specify c++11 as c++0x for travis  fixed typo in script ", "linked_issue_titles": "", "title": "extend ci tests with older c++ standards"}
{"description": " closes #38753 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry @snowman2 can you check if this branch returns behavior to what you had before 1.2? ", "commit_messages": " wip  bug: precise_xstrtod segfault  fix typo ", "linked_issue_titles": " regr: pd.read_csv segfaults with 1.2 (has worked since before pandas 1.0) ", "title": "fix precise_xstrtod segfault on long exponent"}
{"description": " this pr fixes a severe issue for which changes in the properties modal of a dashboard won't be fully saved when the onlyapply prop was used. this pr #17392 enabled the onlyapply tag. later, manual tests have shown that the tag wasn't ready to be used as both the frontend and the backend were not fully implemented for that to work properly. in addition to that, this pr does the following: refactors the propertiesmodal to use typescript refactors the form component to use the functionalities provided by antdesign fixes an issue in the dashboard detail page for which when applying changes and re-opening the properties modal it did not show the latest changes fixes an issue for which changes in the json_metadata for color_namespace, expanded_slices, timed_refresh_immune_slices were not saved fixes an issue for which the dashboard wasn't redirecting back to the original url when the slug was deleted fixes an issue for which changes to native filters would not update the json_metadata immediately, causing potential overwrites changes the endpoint that was used for updating the dashboard (save_dash) with the standard put endpoint. also, it adds the set_dash_metadata function to the update command in the backend. the set_dash_metadata function was only used by the save_dash endpoint before, causing potential discrepancies in the way the json_metatada was handled by the standard put endpoint. removes unnecessary fetch requests open a dashboard edit the properties, including the json metadata apply the changes reopen the modal and make sure the latest changes are there finally, save the changes reload the dashboard and make sure the properties were fully saved includes db migration (follow approval process in sip-59) ", "commit_messages": " refactor propertiesmodal  update json_metadata fully ", "linked_issue_titles": "", "title": "save properties after applying changes in dashboard"}
{"description": " this allows users to take advantage of  (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " [stable/spinnaker]: allow kubeconfig to be referenced from encrypted s3 bucket  update readme  remove whitespace  update comments  add newline ", "linked_issue_titles": "", "title": "allow kubeconfig to be referenced in encrypted s3 bucket"}
{"description": " issue #8636 bug fenced code block closing tags break colorization if they are prefixed with spaces like so: *a* json {}  *b* according to the commonmark spec, up to three spaces are allowed:  update defintion of fenced code block closing tag to support up to three spaces before and any number of spaces after. closes #8636 ", "commit_messages": " fix markdown colorization for fenced code blocks when end fence is prefixed by spaces  issue #8636  **bug**  fenced code block closing tags break colorization if they are prefixed with spaces. according to the commonmark spec, up to three spaces are allowed.  **fix**  update defintion of fenced code block closing tag to support spaces.  closes #8636  also support any number of spaces after end of closing fenced code block ", "linked_issue_titles": " markdown lists containing fenced code blocks with language hints breaks formatting ", "title": "fix markdown highlighting for fenced code block close with space prefix"}
{"description": " fix httpclient connection: close mode (was disconnecting when the server held back responding like when using event stream). closes #25985 . fix httpclient keep alive with chunked encoding. we need to consume the trailer part and final crlf after last chunk as per rfc 7230 section 4.1: chunked-body   = *chunk last-chunk trailer-part crlf we do not return the trailer part, just consume it allowing following requests to work as expected when using keep alive. ", "commit_messages": " httpclient read until eof fixes  fix httpclient keep alive with chunked encoding.  we need to consume the trailer part and final crlf after last chunk  as per rfc 7230 section 4.1:    chunked-body   = *chunk  last-chunk  trailer-part  crlf    we do not return the trailer part, just consume it allowing following  requests to work as expected when using keep alive. ", "linked_issue_titles": "", "title": "httpclient fixes for eof read, chunked transfer encoding"}
{"description": " i also refactored the leftnav to make it more type-safe. because runner-ct does not launch an electron process, i changed the code to just launch an external browser via child_process. ", "commit_messages": " chore: refactor and improve type safety. support target=blank  chore: refactor navbar  fix: launch docs link in external browser ", "linked_issue_titles": "", "title": "open link in external browser"}
{"description": " let's use the redundant requirement graph to diagnose these, just like we already do for redundant conformance and layout requirements. also, diagnose conflicts: multiple superclass requirements where neither is a superclass of the other a superclass requirement and a concrete type requirement that is not a subclass a layout requirement and a concrete type requirement that does not satisfy the layout requirement the first two were already being diagnosed, the third is new. here is an example: struct g<t : anyobject> {} extension g where t == int {} we now reject this on account of t not satisfying anyobject. and last but not least, another bug fix. a protocol can constrain an associated type to self: protocol p { associatedtype a : q where a.b == self } protocol q { associatedtype b } and a class might conform to this protocol: class c : p { typealias a = d } class d : q { typealias b = c } the generic signature <self where self : p, self : c> is built during conformance checking. since self : c, we must have that self.a == d; since d.b == c, the requirement a.b == self in protocol p implies that self == c. so the correct minimized signature here is <self where self == c>. this wasn't handled properly before, because of assumptions in removeselfderived() and a couple of other places. fixes rdar://71677712, rdar://76155506, ", "commit_messages": " gsb: diagnose redundant superclass requirements using the redundant requirement graph  gsb: diagnose conflicts between concrete-type and anyobject requirements  gsb: factor out updatelayout() from addlayoutrequirementdirect()  gsb: remove unused parameter from lookupconformance()  gsb: remove one of the two overloads of checkconstraintlist() ", "linked_issue_titles": "", "title": "the combination of a superclass and conformance requirement might force a type to be concrete"}
{"description": " per #3598 , this finally renames the \"recipes\" section to \"using redux\", and starts reorganizing the content: renamed the recipes docs folder to usage fixed up all markdown links added sub-categories for \"setup and organization\", \"code quality\", and \"redux logic and patterns\". they're organizational only - no additional sub-folders in the repo, so all with /usage/ prefixes updated the _redirects file to hopefully catch all old urls and point them to the new ones dropped the \"object spread\" and \"migrating\" pages, which are very outdated at this point ", "commit_messages": " rename \"recipes\" folder to \"usage\"  rename \"recipes\" section to \"using redux\"  - renamed the \"recipes\" folder to \"usage\"  - changed the title to \"using redux\"  - updated all links that pointed to \"recipes\"  - updated redirects file to point to new urls  - removed links to pages for \"migrating\" and \"object spread\" . didn't  delete them entirely - some of the material could maybe go  somewhere else ", "linked_issue_titles": "", "title": "rename \"recipes\" category to \"using redux\""}
{"description": " type: refactor description:  reduced the padding and size of the input elements of the data privacy rules form component before: after: the height of the input fields was 40px and it is 34px ", "commit_messages": " ref(ui): decreased fild height and spacing ", "linked_issue_titles": "", "title": "reduced padding and size of the input elements"}
{"description": " resolves #3283. also this pr renames the \"unconfirmed\" directory to \"reversible\" (accompanied by similar appropriate name changes throughout the code). --hard-replay-blockchain will now attempt to recover and replay as many reversible blocks as possible from the \"reversible\" block database even if it is left in a dirty state. --replay-blockchain will not attempt to recover the reversible blocks by default. if the \"reversible\" block database is in a good state, those reversible blocks will be replayed after the irreversible blocks are first replayed, just as before. if the \"reversible\" block database is in a dirty state, then --replay-blockchain by itself will still fail. however, this pr introduces a --fix-reversible-blocks which if passed along with --replay-blockchain will cause nodeos to first try to recover the \"reversible\" block database before replaying the blocks. it is also possible to pass in --fix-reversible-blocks by itself. in that case, nodeos will only try to recover the \"reversible\" blocks database and then immediately exit. this pr also makes nodeos remove \"forkdb.dat\" after reading the file on startup. this is to avoid the possibility of reading an old \"forkdb.dat\" file after restarting from a crash (even though a crash should theoretically cause the state db to be left in a dirty state and thus require replay anyway). note: this pr does not change the rules about when fork database emits a signal to write out an irreversible block to disk. fork db is still keeping the last irreversible block in memory and delaying the process of writing it to disk until there is a new irreversible block. this essentially results in what appears the be an off-by-one error: the block log does not contain all the blocks deemed irreversible by dpos standards, the remaining irreversible block not in the block log is found in the fork database and the \"reversible\" block database. i would like to fix this quirk of fork db so that the \"reversible\" block database only contains reversible blocks and the block log contains all irreversible blocks as soon as they became irreversible. but that is a bigger change to fork db and so will be left to another pr. ", "commit_messages": " add --fix-unconfirmed-blocks #3283  rename \"unconfirmed\" to \"reversible\" #3283  --hard-replay by itself should not fail just because the reversible directory is not present #3283  remove forkdb.dat after reading the file  this is to avoid the possibility of reading an old forkdb.dat file after  restarting from a crash (even though a crash should theoretically cause  the state db to be left in a dirty state and thus require replay  anyway). ", "linked_issue_titles": " add --fix-reversible-blocks option ", "title": "nodeos option to recover reversible blocks from unclean shutdown"}
{"description": " @mihaimaruseac this pr adds tf_read_only_memory_region, newreadonlymemoryregionfromfile and stat ( because we need getfilesize ). thank you for doing an import manually with the previous pr. could you please tell me why the it failed the internal import ? ", "commit_messages": " add tf_read_only_memory_region  add stat  add path exists and get file size  add newreadonlymemoryregionfromfile ", "linked_issue_titles": "", "title": "s3 read only memory region and stat"}
{"description": " this directly addresses issue #42157, adding the rls as a non-default component in the mentioned installers. the windows installers appear to have the right functionality added, but i don't have a machine that runs osx, so it would be great if someone could test whether my .pkg commit adds the rls correctly. the final commit also fixes some formatting issues i'd noticed while working on the installers, but i don't know if that's within the scope of this pr, so input would be appreciated. ", "commit_messages": " add rls to .exe and .msi installers  add rls to .pkg installer  fix formatting issues in distribution.xml ", "linked_issue_titles": "", "title": "add the rls to .exe, .msi, and .pkg installers"}
{"description": " this time, with tests passing on centos 6 and including support for lookup plugins. also squashed it down to two commits for basedir and configuration. ", "commit_messages": " look for plugins in the playbook's basedir  load additional plugins from path specified in configuration ", "linked_issue_titles": "", "title": "load plugins from playbook basedir and configured directories"}
{"description": " move local, cell and free variables, plus the evaluation stack to the thread. cuts down the size of frames to under 100 bytes, and enables further optimizations of python-to-python calls. ", "commit_messages": " remove 'zombie' frames. we won't need them once we are allocating fixed-size frames.  add co_nlocalplus field to code object to avoid recomputing size of locals + frees + cells.  move locals, cells and freevars out of frame object into separate memory buffer.  use per-threadstate allocated memory chunks for local variables. dumb and slow implementation.  make per-thread data-stack a contiguous block of memory.  add comments about data stack sizes.  use chunked stack, allows larger stack when needed with reduced memory use most of the time.  delete obsolete comment and debug print statements  move globals and builtins from frame object to per-thread stack.  move (slow) locals frame object to per-thread stack.  add back comment.  fix limit when popping block from data stack.  tidy up frame creation a bit.  improve function name ", "linked_issue_titles": "", "title": "move data stack to thread from frameobject."}
{"description": " fix apigateway model state fetching add integration tests issue fixed: #3888 apigateway on cloudformation can't find ref on resource ", "commit_messages": " add cfn support: kms::alias  fix issues when deploying cfn template with apigateway resources  * fix apigateway model state fetching  * add integration tests  issue fixed:  apigateway on cloudformation can't find ref on resource #3888 ", "linked_issue_titles": "", "title": "fix cfn apigw model resources issues"}
{"description": " this addresses #14578 i created a tutorial for atlassian's sourcetree on macos. a windows one should be made as well but it is similar enough. plus a windows version might be good for someone else to tackle ", "commit_messages": " added sourcetree tutorial reference to main readme file  adding sourcetree macos tutorial and assets  commented out link to nonexistant windows tutorial ", "linked_issue_titles": "", "title": "add atlassian sourcetree tutorial cleaned"}
{"description": " commenting on the cliconf support call for ios-xr modules for ansible 2.9, as the call for support deprecation was added during the early stage of module development and is not relevant currently. iosxr ", "commit_messages": " iosxr cliconf support call  iosxr cliconf support call  iosxr cliconf support call  iosxr cliconf support call  iosxr cliconf support call ", "linked_issue_titles": "", "title": "commenting cliconf support call for ios-xr modules for ansible 2.9 version"}
{"description": " restore alpha support to color picker as a separate property type. this is one of several fixes for the color overlay feature in the color correction filter, which had some questionable math in it. this is technically a breaking change since i'm tweaking the math, but i don't think many noticed the total regression in the first place, so i doubt this feature is widely used. doing a pass to redo the filters in linear space, and noticed this feature must have regressed when alpha was removed from the main color picker. color overlay works again. verified chroma key did not regress. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " ui: support color picker with alpha  libobs: support color picker with alpha  docs/sphinx: add obs_properties_add_color_alpha ", "linked_issue_titles": "", "title": "fix color overlay in correction filter, add color picker with alpha"}
{"description": " with this pr, pointerdownevent and pointermoveevent will always set the 0x01 bit on buttons, including for stylus and touch screen (stylus might have other buttons that start from 0x02). for reasoning, check #30454. related issues fixes #30454 pointereventconverter will be moved to embedder by #28972 flutter/engine#8064 and flutter/engine#8088 in gesture_binding_test.dart, tests now check if pointermoveevent and pointerdownevent have correct buttons. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " add kprimarybutton to events with down=true  eof line ", "linked_issue_titles": " touching the screen should be represented as 0x01 in buttons ", "title": "touching the screen adds 0x01 to buttons"}
{"description": " and a variety of other patches ", "commit_messages": " update coding_style  basic: move two more terminal-related calls into terminal-util.[ch]  core: add support for setting stdin/stdout/stderr for transient services  when starting a transient service, allow setting stdin/stdout/stderr fds  for it, by passing them in via the bus.  this also simplifies some of the serialization code for units.  machined: when opening a shell via machined, pass tty fds in  with this change we'll open the shell's tty right from machined and then  pass it to the transient unit we create. this way we make sure the pty  is opened exactly as long as the transient service is around, and no  longer, and vice versa. this way pty forwarders do not have to deal with  eio problems due to vhangup, as the pty is open all the time from the  point we set things up to the point where the service goes away.  util: do not reset terminal in acquire_terminal()  before, we'd always reset acquired terminals, which is not really  desired, as we expose a setting ttyreset= which is supposed to control  whether the tty is reset or not. previously that setting would only  enable a second resetting of the tty, which is of course pointless...  hence, move the implicit resetting out of acquire_terminal() and make  the callers do it if they need it.  util: minor modernization of vt_disallocate()  shell-completion: add \"machinectl shell\" to bash completion logic  run: various modernizations and smaller fixes  including a fix for properly freeing a calendarspec object after use.  shell-completion: add pseudo machine \".host\" to shell completion ", "linked_issue_titles": "", "title": "allow passing in fds for stdin/stdout/stderr for transient services"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. related to: #39720 boilerplate pr: freecodecamp/boilerplate-advancednode#15 i tried as much as possible to not change unrelated content, but i also took the opportunity to change the instructions with previously discussed versioning additions, and formatting to use github flavoured md. separate issue: husky needs to be configured to not format (search for) changes within backticks. if tests fail, this will be why. also, might be worthwhile (especially once we migrate to mdx) to change the prettier/lint config to do the same. ", "commit_messages": " feat(learn): clarify instructions for boilerplate  add how-to-put-a-profile-together ", "linked_issue_titles": "", "title": "migrate instructions from adnode boilerplate"}
{"description": " see  also i am not 100% sure if i have not introduced leaking of file descriptors somehow (although did run that specific added unittest 10000s of time and everything was legit)... otherwise -- now it passes all old tests and the new one ", "commit_messages": " bug: do not \"own\" the fid for gzipfile and file if provided to load already opened (ticket #2178)  also made all assignments of own_file go in pair with assignments to fid to make things clearer  enh: unittest for preceeding commit fixing #2178 ", "linked_issue_titles": "", "title": "\"own\" (to close) file handles in load() only if they were not opened before"}
{"description": " pr  #8764 adds the feature to title plugin in order to use scriptable options. this features wasn't reported in the documentation. this pr adds the scriptable column to options table. ", "commit_messages": " fixes typo on padding doc  adds column to the options table for scriptable  fixes table headers ", "linked_issue_titles": "", "title": "adds scriptable column to options table in the title documentation"}
{"description": " this pull request adds the ability to specify a secret which contains the credentials.json used to authenticate against the google cloud dns service for external-dns. ", "commit_messages": " the external-dns chart can use a secret containing a credentials.json for google cloud dns  fixed typo in table markup ", "linked_issue_titles": "", "title": "specify google cloud dns credentials.json via kubernetes secret"}
{"description": " this pull-request slightly adjusts the current error handling code to improve exception safety and enable switching the error handling to user-defined exceptions (by defining rapidjson_parse_error_early_return).  an example of such a user-defined exception can be found in pah/rapidjson-upstream@bc0cca12 (not intended for upstream inclusion). the main changes are: moving parseerrorcode to include/rapidjson/error/error.h clearing document and reader stacks from a destructor adding parseresult class to propagate error code and offset together benchmarking results below, details available at  the third column is just to shows the impact of actually using an exception to propagate an error. linux 64-bit, intel(r) core(tm) i7-3520m cpu @ 2.90ghz compiler baseline exception-support exception-throw gcc 4.4 11826 ms 11896 ms 12029 ms gcc 4.6 12730 ms 13218 ms 12661 ms gcc 4.8 9847 ms 9817 ms 10467 ms gcc 4.9 9833 ms 10067 ms 10285 ms clang 3.5 11172 ms 10867 ms 11165 ms linux 32-bit, intel(r) core(tm) i7-3520m cpu @ 2.90ghz compiler baseline exception-support exception-throw gcc 4.4 14545 ms 14571 ms 14408 ms gcc 4.6 14877 ms 15197 ms 15126 ms gcc 4.8 11341 ms 11378 ms 11971 ms gcc 4.9 11649 ms 11498 ms 12175 ms clang 3.5 12683 ms 13038 ms 12750 ms linux 32-bit, intel(r) core(tm)2 duo cpu e8400 @ 3.00ghz (no sse4.2) compiler baseline exception-support exception-throw gcc 4.4 21160 ms 21199 ms 20627 ms gcc 4.6 20933 ms 21717 ms 22107 ms gcc 4.8 17192 ms 17377 ms 18168 ms gcc 4.9 18510 ms 17703 ms 18364 ms clang 3.5 17565 ms 17575 ms 17477 ms performance details: ", "commit_messages": " move parseerrorcode to error/error.h  in order to enable the customization of the error macros  - rapidjson_parse_error_noreturn  - rapidjson_parse_error_early_return  the user may need to have access to the parseerrorcode enum  already.  this requires a separate header location than the  genericreader.  reader.h: prepare \"early return path\" for exception support  in case of a user-defined rapidjson_parse_error_noreturn that throws  an exception instead of using the rapidjson parseerror api, the early  return paths performing the stack unwinding manually can be omitted as  well.  this patch provides a customizable rapidjson_parse_error_early_return  macro to remove these (then unneeded) control paths from the parsing  implementation (with and without a return value).  secondly, clearing the parse stack is moved to a small helper struct  that calls stack_.clear() from its destructor.  this avoids the need  for the 'goto' in the parsestream function and ensures proper cleanup  even if e.g. a user-defined allocator throws an exception.  genericdocument: simplify error handling in parsestream  * unconditionally store error state of reader after parsing  * clear stack after parsing by using a clearstackonexit scope guard  add parseresult  update documentation of parseresult and related functions ", "linked_issue_titles": "", "title": "improve exception safety and add support for swtiching error handling to exceptions"}
{"description": " fix instructions mentioned in #6181 goes with r2r pr radare/radare2-regressions#627 ", "commit_messages": " enhance sub op support for thumb arch  generate correct instructions up to 0x100  improve support for add instruction for thumb arch ", "linked_issue_titles": "", "title": "fix add and sub for arm thumb fix #6181"}
{"description": " nothing has been turned on yet. an incremental build involving incremental external dependencies behaves as a hybrid between an external dependency and a normal swiftdeps-laden swift file. in the simplest case, we will fall back to the behavior of a plain external dependency today. that is, we will check its timestamp, then schedule all jobs that involve these external dependencies if it is out of date. where things get interesting is when cross-module incremental builds are enabled. in such a case, we know that a previous compiler has already emitted serialized swiftdeps information inside of a swiftmodule file. moreover, we know that that swiftmodule file was loaded by the build of the current swift module. finally, thanks to the previous stack of commits, we now know exactly how to extract this information from the swiftmodule file. to bring this all home, we unpack incremental dependency information from external dependencies, then integrate them into the current dependency graph - as though they were any other swiftdeps file. this neatly extends the single-module incremental logic to the multi-module case. ", "commit_messages": " teach the driver to read fine-grained dependency graphs in swiftdeps files  install incremental external dependency integration code  an incremental build involving incremental external dependencies behaves as a hybrid between an external dependency and a normal swiftdeps-laden swift file.  in the simplest case, we will fall back to the behavior of a plain external dependency today. that is, we will check its timestamp, then schedule all jobs that involve these external dependencies if it is out of date.  where things get interesting is when cross-module incremental builds are enabled. in such a case, we know that a previous compiler has already emitted serialized swiftdeps information inside of a swiftmodule file. moreover, we know that that swiftmodule file was loaded by the build of the current swift module. finally, thanks to the previous stack of commits, we now know exactly how to extract this information from the swiftmodule file. to bring this all home, we unpack incremental dependency information from external dependencies, then integrate them into the current dependency graph - as though they were any other swiftdeps file. this neatly extends the single-module incremental logic to the multi-module case. ", "linked_issue_titles": "", "title": "teach the legacy driver to unpack incremental dependency information from swiftmodule files"}
{"description": " explanation: the actor runtime has some known issues with deadlock when an actor has to give up its thread because it's running lower-priority work. to avoid deadlocks here, disable all of the logic that tries to give up higher-priority threads when only lower-priority work is available, effectively making the actor runtime ignore priorities internally. scope: affects new code using swift's concurrency model. radar/sr issue:  rdar://79378762 risk: low. reviewed by: kavon farvardin, konrad malawski testing: pr testing and ci on main, adding more stress-tests of the actor runtime that previously deadlocked original pr: #38709 ", "commit_messages": " [se-0304] clean up handling of task priorities.  fix bit manipulation in activetaskstatus::withescalatedpriority().  due to a missing ~ when trying to mask in a new priority + the  isescalated flag, we were instead getting an incorrect priority as  well as dropping other useful bits. this led to assertions about the  running state of a task not being set.  ignore task priorities in the actor runtime.  the actor runtime has some known issues with deadlock when an actor has  to give up its thread because it's running lower-priority work. to  avoid deadlocks here, disable all of the logic that tries to give up  higher-priority threads when only lower-priority work is available, or  to escalate work, effectively making the actor runtime ignore  priorities internally.  fixes rdar://79378762.  improve actor-counters test to also test priorities.  re-enable test ", "linked_issue_titles": "", "title": "actor scheduling without priorities 5.5"}
{"description": " cleans up the code in the ft.java to make it more readable and works. added a countchar.java algorithm that counts the characters in a string. ", "commit_messages": " count character algo added  clean up floydtriangle (ft.java) ", "linked_issue_titles": "", "title": "clean up ft.java and create countchar.java."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). isjoi property only exists for validationerror: sideway/joi@cd77ba5  anyschema extends from schemainternals: ", "commit_messages": " chore: changes by linter  feat: joi schema has schemainternals  fix: isjoi is removed from joi object ", "linked_issue_titles": "", "title": "anyschema extends schemainternals and isjoi is dropped"}
{"description": " strip 4k from rom for eeprom emulation to save settings with m500 robin e3d can't save settings at all save settings to flash ", "commit_messages": " update mks_robin_e3.ld  strip 4k from rom for eeprom emulation to save settings with m500  update pins_mks_robin_e3d.h  added eeprom emulation to save settings to flash  use 4k flash with emulation to save settings on robin e3d ", "linked_issue_titles": "", "title": "mks robin e3d - enable m500 with eeprom emulation"}
{"description": " closes #9968 ", "commit_messages": " fix(challenges): completed marked at render  mark challenge completed using derived data in a selector  instead of manipulating the data on user load  fix(challenge): update user challenge map on challenge complete ", "linked_issue_titles": "", "title": "update user data on challenge complete"}
{"description": " on both native android and ios attempting to select a space on an uneditable piece of text, will instead select the previous word. this pr brings this functionality to flutter. related issues closes #68226 i added the following tests: selectabletext test for selecting spaces on mobile test for selecting spaces on non-mobile platforms test for double tapping a space on mobile i had to change the following tests: selectabletext long tap still selects after a double tap select i split this test into a macos and ios version because they now differ in behavior when selecting a space, and this particular test taps a space. long press drag moves the cursor under the drag and shows toolbar on lift this test was also split into macos and ios versions because on ios when selecting a word and attempting to drag over a whitespace, it will skip over the whitespace to the next word. before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: ", "commit_messages": " selecting a space attempts to select the previous word instead on  android if the text is read only/not editable  prefer to use _getpreviousword() over custom solution  use previousword variable  clean up from old solution  update selectable text tests for new space select behavior  * long tap still selects after a double tap select has been split into ios and macos versions as the selecting a space behavior is different on both platforms  * long press drag moves the cursor under the drag and shows toolbar on lift split into ios and macos  selectable text space selection test ", "linked_issue_titles": " selecting a space should select previous word in selectabletext on mobile ", "title": "selecting spaces on selectabletext (mobile)"}
{"description": " docs don't mention anything about xpack.security.audit.index.settings when forwarding events to a remote cluster. this is important because in the case when x-pack security is also installed on the remote cluster, the settings there take precedence. jay, do you think we should only register the audit index template if xpack.security.audit.enabled is true ? in this case, when indexing events to a remote with x-pack security installed (but with auditing turned off, by default) index settings from local will be picked up. closes: #30422 ", "commit_messages": " [docs] audit indices settings for remote cluster  docs in the guide too ", "linked_issue_titles": "", "title": "clarify audit index settings when indexing to remote"}
{"description": " with this pr we strongly type this in methods of object literals and provide a facility for controlling the type of this through contextual typing. the new behavior is only enabled in --noimplicitthis mode. the type of the expression this in a method of an object literal is now determined as follows: if the method has an explicitly declared this parameter, this has the type of that parameter. otherwise, if the method is contextually typed by a signature with a this parameter, this has the type of that parameter. otherwise, if --noimplicitthis is enabled and the containing object literal has a contextual type that includes a thistype<t>, this has type t. otherwise, if --noimplicitthis is enabled and the containing object literal has a contextual type that doesn't include a thistype<t>, this has the contextual type. otherwise, if --noimplicitthis is enabled this has the type of the containing object literal. otherwise, this has type any. some examples: // compile with --noimplicitthis type point = { x: number; y: number; moveby(dx: number, dy: number): void; } let p: point = { x: 10, y: 20, moveby(dx, dy) { this.x += dx;  // this has type point this.y += dy;  // this has type point } } let foo = { x: \"hello\", f(n: number) { this;  // { x: string, f(n: number): void } }, } let bar = { x: \"hello\", f(this: { message: string }) { this;  // { message: string } }, } in a similar manner, when --noimplicitthis is enabled and a function expression is assigned to a target of the form obj.xxx or obj[xxx], the contextual type for this in the function expression is obj: // compile with --noimplicitthis obj.f = function(n) { return this.x - n;  // 'this' has same type as 'obj' } obj['f'] = function(n) { return this.x - n;  // 'this' has same type as 'obj' } in cases where an api produces a this value by transforming its arguments, a new thistype<t> marker interface can be used to contextually indicate the transformed type. specifically, when the contextual type for an object literal is thistype<t> or an intersection including thistype<t>, the type of this within methods of the object literal is t. // compile with --noimplicitthis type objectdescriptor<d, m> = { data?: d; methods?: m & thistype<d & m>;  // type of 'this' in methods is d & m } function makeobject<d, m>(desc: objectdescriptor<d, m>): d & m { let data: object = desc.data || {}; let methods: object = desc.methods || {}; return { ...data, ...methods } as d & m; } let obj = makeobject({ data: { x: 0, y: 0 }, methods: { moveby(dx: number, dy: number) { this.x += dx;  // strongly typed this this.y += dy;  // strongly typed this } } }); obj.x = 10; obj.y = 20; obj.moveby(5, 5); in the example above, the methods object in the argument to makeobject has a contextual type that includes thistype<d & m> and therefore the type of this in methods within the methods object is { x: number, y: number } & { moveby(dx: number, dy: number): number }. notice how the type of the methods property simultaneously is an inference target and a source for the this type in methods. the thistype<t> marker interface is simply an empty interface declared in lib.d.ts. beyond being recognized in the contextual type of an object literal, the interface acts like any empty interface. patterns similar to the above are used in several frameworks, including for example vue and ember. using thistype<t> we can now more accurately describe those frameworks. supercedes #8382. we revoked that pr because it always made the type of this in object literal methods be the type of the object literal. we now make that the default behavior, but allow the default to be overridden using a thistype<t> contextual type. ", "commit_messages": " use '__this__' property in contextual type to indicate type of 'this'  introduce thistype<t> marker interface  default contextual 'this' type is containing object literal  update tests  accept new baselines ", "linked_issue_titles": "", "title": "typed 'this' in object literal methods"}
{"description": " small fix to resolve issues caused by using the init container used to install plugins. (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #13482 dco signed title of the pr contains starts with chart name e.g. [stable/chart] ", "commit_messages": " modify ingress template to be easier to --set  update readme  updated tls to match new ingress format  fix trailing spaces  additional readme info  modified ingress template to allow path configuration.  bumped major version to reflect incompatible api change.  sync fork  increment chart patch version  merge fix  just use /bin/bash instead of /usr/bin/env bash ", "linked_issue_titles": " [stable/sonarqube] `extraenv` not passed to /opt/sonarqube/bin/run.sh when `.values.plugins.install` is truthy ", "title": "use #!/bin/bash in ./templates/copy-plugins.yaml instead of #!/bin/sh"}
{"description": " this is an updated version of #4809. it is rebased to current master and has some new tests added that verify the behavior of the modified securegiturl() function. securegiturl() tries to make sure that we use secure urls. it currently behaves inconsistently, like allowing plain http download without any warnings or raising securityerror if a repository doesn't exist. see #4307 for details. main changes in behavior with this pull request: insecure http: and git: urls are handled consistently: plain http: urls without a commit hash now report a warning. previously they were silently accepted. plain git: urls without a commit hash now no longer raise a securityerror. instead they report a warning. non-existing or otherwise inaccessible repositories now no longer raise securityerror. previously this happend in some cases, leading to very confusing error messages. for more context/rational see #4307 and the test cases in this pull request. ", "commit_messages": " allow insecure urls with warnings (#4307)  added test cases for securegiturl() ", "linked_issue_titles": "", "title": "make securegiturl() warn for insecure urls"}
{"description": " fixes: #19193 ", "commit_messages": " fileio: bump limit for read_full_file() and friends to 64m  apparently people use such large key files. specifically, people used 4m  key files, and we lowered the limit from 4m to 4m-1 back in 248.  this raises the limit to 64m for read_full_file() to avoid these  specific issues and give some non-trivial room beyond the 4m files seen  irl.  note that that a 64m allocation in glibc is always immediately done via  mmap(), and is thus a lot slower than shorter allocations. this means  read_virtual_file() becomes ridiculously slow if we'd use the large  limit, since we use it all the time for reading /proc and /sys metadata,  and read_virtual_file() typically allocates the full size with malloc()  in advance.  in fact it becomes so slow, that test-process-util kept  timing out on me all the time, once i blindly raised the limit.  this patch hence introduces two distinct limits for read_full_file() and  read_virtual_file(): the former is much larger than the latter and the  latter remains where it is. this is safe since the former uses an  exponentially growing realloc() loop while the latter uses the  aforementioend ahead-of-time full limit allocation.  fixes: #19193  cryptsetup: improve error message when key files to load are too large  let's make this easier to grok for users.  prompted-by: #19193 ", "linked_issue_titles": " luks key file stopped working after upgrading to 248 ", "title": "add back support for large key files to systemd-cryptsetup"}
{"description": " add a cache in front of lazy member loading that indicates whether the lookup table has a complete accounting of a given base name with respect to the set of all known extensions of the given nominal type.  as a consequence, this cache must be flushed when a new extension with lazy members is installed after we've run any direct lookups. i anticipate this having a non-trivial impact on the performance of lookup.  this is built on #28914 so we can run a shootout and see if the space tradeoff is worth it. ", "commit_messages": " [nfc] remove memberlookuptable::clear()  the incremental name lookup cache no longer needs to chuck out the old tables.  [nfc] one-shot name lookup  simplify lookupdirect to attempt one-shot name lookup based on some ideas slava had.  this means we'll try to perform a cache fill up front, then access the table rather than assuming the table is always (relatively) up to date and filling when we miss the first cache access.  this avoids a walk over the deserialized members of an extension that fails named lazy member loading.  instead, we eagerly page the members of the extension into the table and remove it from consideration for lazy member loading entirely.  in the future, we can convince the clang importer to avoid falling off the lazy member loading happy path.  [experiment] stick a cache in front of lazy member loading  add a cache of lazily-imported names so we don't run off and deserialize extensions multiple times.  the cache indicates that the lookup table has a complete understanding of any given base name.  as a consequence, it must be flushed when a new extension with lazy members is added to avoid returning inconsistent results.  this should make lazy member cache misses much, much cheaper. in the best case, we'll avoid repeatedly crawling around on disk.  in the average case, we'll have fallen off the lazy member loading path at some point for some extension and the lazily-complete cache will kick in to keep that one extension from pessimizing the rest.  in the worst case - when an enormous amount of lookups for non-existent members occur - we'll probably balloon memory usage somewhat adding bogus members to the set.  [nfc] update some bounds on lazy member loading tests  not sure when these moved, but tighten them up so we don't regress. ", "linked_issue_titles": "", "title": "one-shot name lookup + lazily-complete base name cache"}
{"description": " fixes #5989 read and process /sys/class/net/xxxx/duplex and /sys/class/net/xxxx/operstate create custom variables duplex_state and operstate under the bandwidth chart map states to numeric values duplex state (variable duplex_state) 0 = unknown 1 = half duplex 2 = full duplex operstate status map (variable operstate) 0 = unknown 1 = notpresent 2 = down 3 = lowerlayerdown 4 = testing 5 = dormant 6 = up component name ", "commit_messages": " - read and process /sys/class/net/xxxx/duplex and /sys/class/net/xxxx/operstate  - create custom variables duplex_state and operstate under the bandwidth chart  - map states to numeric values  duplex state (variable duplex_state)  0 = unknown  1 = half duplex  2 = full duplex  operstate status map (variable operstate)  0 = unknown  1 = notpresent  2 = down  3 = lowerlayerdown  4 = testing  5 = dormant  6 = up  - fix array size element count!  - return int value  - fix casting warning ", "linked_issue_titles": " network interface speed, duplex, operstate ", "title": "network interface speed, duplex, operstate #5989"}
{"description": " adding userspace and keymaps of mine. plus prepping for eventual corne and ergotravel. can move to different name for userspace if y'all want. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " add userspace and keymaps  * adding keymaps for zeal60 and iris  * created my own tap dance that toggles rgb mode based on whether i toggled caps lock or not  parent 578ed42a7f8f986147cad040d50d4ae1d24a32e2  author seth barberee <seth.barberee@gmail.com> 1565065903 -0500  committer seth barberee <seth.barberee@gmail.com> 1565065903 -0500  move to userspace  add zeal60 ", "linked_issue_titles": "", "title": "adding my userspace and keymaps"}
{"description": " fixes #1436 with this, we don't need to wait for the js bundle and page can render directly. this will lead to better page load performance. ", "commit_messages": " use a webpack plugin to combine assets.  add comments and make this releseable. ", "linked_issue_titles": "", "title": "load the main js bundle in production with async"}
{"description": " for #3691. standardized routecontext standardized executioncontext move executioncontext to shardingsphere-executor module ", "commit_messages": " rename routeunit to executionunit  move executioncontext to shardingsphere-route module  move routeresult to shardingsphere-route module  add result and context package in shardingsphere-route module  remove setter of routeresult  rename routingunit to routeunit  use sqlstatementcontext instead of shardingrouteresult.getsqlstatementcontext() in shardingpaginationparameterrewriter  rename routeresult to routecontext  rename routingresult to routeresult  split shardingsqllogger  move executioncontext to shardingsphere-executor module  move routecontext from result package to route package ", "linked_issue_titles": "", "title": "standardized route and execution's context object"}
{"description": " if auto fan pins use the pins that regular fans use, init them the same way. always init configured fan pins with set_output (as in marlin 1.0.1) also includes some other fixes and cleanup. reference: #4579 ", "commit_messages": " flags for matching auto-fans  update has_fan flags for 4 auto fans  init next_auto_fan_check_ms to zero  loop fan-pins based on array size  init pwm-able auto fan pins with set_output  use matching auto-fan flags  always init configured fan pins ", "linked_issue_titles": "", "title": "init pwm-able auto_fan pins with set_output"}
{"description": " this function currently always overwrites the underlying error message with a rather useless one. instead let's let the callback set their own error message and only set our own when they fail to do so. this sets a more informative error message for #2797 and fixes #2965 ", "commit_messages": " path: don't let direach overwrite the callback's error message  this function deals with functions doing io which means the amount of  errors that can happen is quit large. it does not help if it always  ovewrites the underlying error message with a less understandable  version of \"something went wrong\".  instead, only use this generic message if there was no error set by the  callback.  fileops: set an error message if we fail to link a file  now that git_path_direach lets us specify an error message to report,  set an appropriate error message while linking. ", "linked_issue_titles": " cryptic error on disk full ", "title": "provide error messages for git_path_direach operations"}
{"description": " this also fixes python/typing#512 this also fixes python/typing#511 as was discussed in both issues, some typing forms deserve to be treated as immutable by copy and pickle modules, so that: copy(x) is x deepcopy(x) is x loads(dumps(x)) is x  # pickled by reference this pr adds such behaviour to type variables special forms like union, any, classvar unsubscripted generic aliases to containers like list, mapping, iterable this not only resolves inconsistencies mentioned in the issues, but also improves backwards compatibility with previous versions of python (including 3.6). note that this requires some dances with __module__ for type variables (similar to namedtuple) because the class typevar itself is define in typing, while type variables should get module where they were defined. ", "commit_messages": " treat type variables and special typing forms as immputable by copy and pickle  add news entry ", "linked_issue_titles": " can't pickle generic types  typevar equality broken? ", "title": "treat type variables and special typing forms as immutable by copy and pickle"}
{"description": " a few pieces of context: when a docker container is started with a mount where the host_path does not currently exist, it will be created with root ownership. when most linux machines are stopped & started the /tmp directory is deleted what is the issue: node reuse is enabled a cluster is started (with file mounts), and eventually shutdown. the ray cluster is restarted and the head node is pulled from the cache. run_init is executed before file mounts are synced a.  this causes /tmp/ray_tmp_mount/, /tmp/ray_tmp_mount/<cluster_name>/ and /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> are all created by docker and with root ownership. b. rsync happens, and tries to copy files to /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> and fails because ubuntu (the default user on the host) cannot edit root-owned files. the solution: flip 4b and 4a to ensure that rsync creates the /tmp/ray_tmp_mount/<cluster_name>/<mount_name_1> path closes #17228 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " first pass  delay start up until after file mounts  add test ", "linked_issue_titles": " [docker] [autoscaler] failure to setup head node on recycled head ", "title": "sync files before starting docker"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  documentation showing that emojiindex.search() returns an array of emoji  source showing that the emojiindex.emojis returns an object of emojidata when multiple skin tones exist. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " fix types for emojiindex  run prettier ", "linked_issue_titles": "", "title": "fix types for emoji-mart emojiindex"}
{"description": " removes several unused templates removes team name from title of anything inheriting from the stream base template (possibly only plugins at this point) removes team name from reprocessing script ", "commit_messages": " ref(templates): remove unused cannot create teams template  ref(templates): remove unused project and team base templates  ref(templates): remove unused teams template partial  ref(teams): remove team name from stream base template title  ref(reprocessing): remove team name from reprocessing script ", "linked_issue_titles": "", "title": "remove unused templates, remove team name in a few places"}
{"description": " this pr runs hack/update-staging-client.sh in kubernetes release-1.5 branch. this helps client-go release-2.0 branch to pick up the bug fixes. i cannot follow the regular cherrypick process because the staging/ folder has been changed too much in the master branch.  fixes kubernetes/client-go#66. ", "commit_messages": " fix copy.sh for osx  update staging client ", "linked_issue_titles": "", "title": "update staging in release 1.5"}
{"description": " while testing #81455 i encountered 2 issues with remote-test-server: it is built with the stage 0 toolchain, which does not support a newly added target. it overwrites ld_library_path instead of appending to it, which prevents the use of a custom sysroot for target libraries. ", "commit_messages": " don't build remote-test-server with the stage0 toolchain  newly added targets aren't available on the stage0 toolchain.  preserve existing ld_library_path in remote-test-server ", "linked_issue_titles": "", "title": "make remote-test-server easier to use with new targets"}
{"description": " sorry for all the commits. still learning git. problem was cr/lf wall-of-pink issues. here is the new router.map in use: resolves issue #454 ", "commit_messages": " update to latest  added comments from durandaljs documentation to module and routeinfo  renamed interface irouteinfo from routeinfo  added interface irouteinfoparameters  bugfixed maproute to have two function signatures.  bugfixed map to take single or array of irouteinfoparameters.  revert \"added comments from durandaljs documentation to module and routeinfo\"  this reverts commit 3ab33b847a8b86cb64f0047a229e3e3778531afc.  bugfixed router.map and router.maproute  bugfixed maproute to have two function signatures.  bugfixed map to take single or array of irouteinfoparameters.  renamed interface irouteinfo from routeinfo  added interface irouteinfoparameters  revert \"bugfixed router.map and router.maproute\"  this reverts commit f6d09ab31b41225bda7ea1d2c0ce5ddcc9a37803.  bugfixed router.map and router.maproute  bugfixed maproute to have two function signatures.  bugfixed map to take single or array of irouteinfoparameters.  renamed interface irouteinfo from routeinfo  added interface irouteinfoparameters  fix for router.map et al.  tried to rebase. first time. too late. i had pushed to github. sorry. ", "linked_issue_titles": "", "title": "fix for router.map et al. in durandal.d.ts"}
{"description": " others others move func from kernel_context.h into kernel_context.cc for compile quickly ", "commit_messages": " add inplace op adaptation  optimize inplace logic and fix bugs when run kernel that has args of vector<densetensor>  move func in kernel_context.h into kernel_context.cc  refactor logic that transform variable to densetensor  fix bugs when compile  update func name  merge develop  merge develop ", "linked_issue_titles": "", "title": "[pten]move func from kernel_context.h into kernel_context.cc"}
{"description": " adds an option to export detection models with input node that accepts encoded image strings. ", "commit_messages": " change define_enum to define_string and delete unused file.  add option to export graph with input node that accepts encoded jpeg or png string ", "linked_issue_titles": "", "title": "add option to export model with input node that accepts jpeg or png strings"}
{"description": " this module adds support for dns record management via the api of netcup (german hosting provider). new module pull request netcup_dns ansible version ansible 2.7.0.dev0 (netcup_dns 520b744f81) last updated 2018/08/13 11:42:45 (gmt +200) config file = /etc/ansible/ansible.cfg configured module search path = [u'/home/nbw/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/nbw/dev/ansible/lib/ansible executable location = /home/nbw/dev/ansible/bin/ansible python version = 2.7.15 (default, may 16 2018, 17:50:09) [gcc 8.1.1 20180502 (red hat 8.1.1-1)] ", "commit_messages": " add support for netcup dns api  documentation on the return values and small fixes ", "linked_issue_titles": "", "title": "add netcup_dns module (manage dns records hosted by netcup)"}
{"description": " your submissions are formatted according to the guidelines. your additions are ordered alphabetically. your additions are free software, or if not they have been added to non-free. your additions are not already listed at awesome-sysadmin (it infrastructure management), staticgen.com or staticsitegenerators.net (static site generators). any licenses you have added are in our list of licenses. you have searched the repository for any relevant issues or prs. ", "commit_messages": " add musikcube and beets under the \"audio\" heading.  this commit also adds the bsd-3-clause license, as that is the license  for musikcube.  revert bsd-2/3-clause/freebsd distinction  all three licenses will be identified as 'bsd' since we have no track record of which entry has which one  user should read the specific license terms of each program for more details  fix link to bsd-2-clause license ", "linked_issue_titles": "", "title": "add musikcube, beets, merge bsd licenses"}
{"description": " updating the chart to latest stable version, 1.0.6. adding the functionality to roll the deployment upon config changes. moving clusterip configuration to outside the kubernetes plugin section, since it may be useful to configure even if running without the kubernetes plugin. ", "commit_messages": " [stable/coredns] update to latest version 1.0.6  [stable/coredns] roll deployment on config change  [stable/coredns] move clusterip outside kubernetes plugin  might be useful to configure even if not running with kubernetes plugin. ", "linked_issue_titles": "", "title": "update to 1.0.6 and small improvements"}
{"description": " for #13582 show single table rule is modified to show single table support show single table rule statement ", "commit_messages": " show single table rule is modified to show single table  move class  support show single table rule statement.  add document.  # conflicts:  #\tshardingsphere-distsql/shardingsphere-distsql-parser/src/main/antlr4/org/apache/shardingsphere/distsql/parser/autogen/commondistsqlstatement.g4  update document. ", "linked_issue_titles": "", "title": "support show single table rule resource statement"}
{"description": " some codegen tests didn't seem relevant (e.g. unsupported annotations). the risc-v abi tests were broken by llvm 10, c872dcf fixes that (cc: @msizanoen1) i'm not sure about skipping catch-unwind.rs and included that change here mostly as a request for comment - i can't tell if that's a bug. ", "commit_messages": " test: codegen: skip tests inappropriate for riscv64  test: codegen: riscv64-abi: print value numbers for unnamed func args  llvm 10 includes a009a60a917bc30940422bcef73f8270566d78db which will  print value numbers for unnamed func args.  update these tests to be in line with the referenced clang tests.  test: codegen: add riscv abi llvm intrinsics test  test: codegen: skip catch-unwind on riscv64  it isn't clear to me if this is a bug or not, hence the fixme ", "linked_issue_titles": "", "title": "fix codegen tests for risc-v"}
{"description": " closes #20012 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry added center functionality for variablewindowindexer. note - i am unsure if the notimplementederror in lines 1966-1969 in rolling.py still correctly raises an error for offset based windows. finalizes previous pr #36097 ", "commit_messages": " update syntax for pandas style  fix syntax error  reintroduce calculate_center_offset as private function ", "linked_issue_titles": " center rolling window with date notimplementederror ", "title": "center rolling window for time offset"}
{"description": " related issue = #1905 #2078 #2085 atomic add may crash when adding negative numbers. it is because we didn't partially set the value to memory using mask after we do the addition. adding negative numbers may cause the change of the higher bits. for example: if we pack a (ci3) and b(ci5) in a bit_struct(num=8), and set them all zero at beginning(a is the lower 3-bits, and b is the higher 5-bits). then we add -1 to a, and we will find that b will be changed too. so, a possible solution might be partially setting value to memory with mask in runtime.cpp just like set_partial_bits_b which only affects the bits of a in the former example . ", "commit_messages": " quick fix  mod test ", "linked_issue_titles": "", "title": "support atomic add negative numbers for custom types"}
{"description": " remove the need for extra interfaces in node_provider to support custom node types each node type now gets a custom node_config section, which is merged with the default node configs require specifying the default head/worker node type in multi node type clusters i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip  wip  fix  fix  refactor ", "linked_issue_titles": "", "title": "refactor multi node type autoscaler config"}
{"description": " follow-ups for #20477. ", "commit_messages": " ethtool: move function  i'd like to locate all conf parsers at end of file.  udev/net: initialize coalesce tristate variables  otherwise, 99-default.link may introduce something like the  following warnings:  ----  aug 26 03:23:59 systemd-udevd[519]: wlan0: could not set coalesce settings, ignoring: operation not supported  aug 26 03:24:00 systemd-udevd[547]: wlp59s0: could not set coalesce settings, ignoring: operation not supported  ----  follow-up for 6c35ea5ef0231d519ff24d43a57a72cebab6a121. ", "linked_issue_titles": "", "title": "follow-ups for coalesce feature support"}
{"description": " this pr fixes #122365 it seemed like everyone enjoyed the way files.associations worked so i copied that flow. this will read in and be able to handle the old and new format, but will only write to the new format. when i try to handle conversion i get an error saying we can't write to the user setting because there are errors. this is shown due to the fact that the types have changed from array to object, if you have any suggestions let me know. secondly, the biggest downside to this is we lose intellisense. the loss of intellisense does clean up a lot of code since it was dynamic, but that is still something to consider. file associations also doesn't have intellisense and the setting is often set through a picker similar to custom editors. ", "commit_messages": " cleanup editor association setting  remove commented out code ", "linked_issue_titles": " editor association should have ui piece in settings editor  editor associations setting is overly verbose ", "title": "reduce editor association setting verbosity."}
{"description": " this pr also fixed two bugs: in getdeviceandallocator() it didn't set cuda_device_id when device is found in cluster; in the same method if cluster is not available but device name is set in engine, it'll use the tf gpu id from the device name, but the tf_gpu_id->cuda_gpu_id mapping could be unset, in which case it'll failed. e.g. #20780 i've run all available tests and verified that the generated graphdefs are the same as before. ", "commit_messages": " fix tf_trt_integration_test.py when running in python3.  use tf_optimizer.optimizegraph() to reimplement create_inference_graph() method, and fix a bug in getdeviceandallocator() where it doesn't set the cuda_device_id even if the device is found. ", "linked_issue_titles": "", "title": "use tf_optimizer.optimizegraph to implement create_inference_graph"}
{"description": " resolves #6551 renamed onerrorresumenext(source) to onerrorresumewith(source) for observable, maybe, single, and flowable renamed some unit tests and their classes to reflect the method name change changed parameter type of single.onerrorresumewith from single to singlesource updated javadocs for all renamed methods removed redundant casts for unit tests deleted duplicate unit test that arose from no longer needing to cast arguments ", "commit_messages": " #6551 renaming observable.onerrorresumenext to observable.onerrorresumewith, removing unnecessary cast from null tests, and updating observable.onerrorresumewith's javadoc to reference correct parameter name, renamed test classes since the distinctions in their names are no longer necessary.  #6551 renaming maybe.onerrorresumenext(maybesource) to maybe.onerrorresumewith(maybesource), renamed some of the affected unit tests, and updated javadoc.  #6551 renaming single.onerrorresumenext(single) to single.onerrorresumewith(single), renamed an affected unit test, updated javadoc, and removed redundant casts.  #6551 changing single.onerrorresumewith parameter from single<? extends t> to singlesource<? extends t>  #6551 renaming flowable.onerrorresumenext(publisher) to flowable.onerrorresumewith(publisher), renaming some affected tests, deleted duplicated unit test that arose from being able to remove redundant casts, updated javadocs. ", "linked_issue_titles": " disambiguous some method call sites when calling from kotlin ", "title": "3.x rename on error resume next methods to disambiguate when calling from kotlin (#6551)"}
{"description": " this implements the following: loosens the requirement on localscalar() that the tensor is a scalar; now it only needs to be one element; scalar(...) still has the old requirement because it makes the code simpler (and people probably don't call that constructor directly anymore because we provide nicer conversion functions). implement tocdouble, tocfloat, etc. so that it calls through localscalar() and gets the 1-element property; this is to match the pytorch scalar conversion api and #3839. add a is_nonzero native function which is functionally equivalent to tocbool, which doesn't exist because we don't have bool tensors (it adds a nicer error message as well). uses the above aten changes to implement variable scalar conversions via aten; there is a bit of complication around conversion from double to (python) int, because we want to avoid the aten code path in that case because pylongs don't overflow.  also added a bunch of tests. ", "commit_messages": " have localscalar work with all 1 element tensors, not just scalars.  also have tocfloat, etc. call localscalar so 1 element tensors work as well.  implement python number conversions.  implement __bool__, __nonzero__ as aten functions.  remove merge artifacts. ", "linked_issue_titles": "", "title": "implement python scalar conversions via aten; allow localscalar if numel == 1"}
{"description": " the original author left his own key in there in order to get users started as easily as possible. not only is this a bad idea, but the server key also gives way too many privileges to the user. in essence, people could run their own complete website with that key. i removed the key and provided a script to let them easily upload the schema, create a role and a client key that uses that role. currently that script just lives in scripts/ and is called as yarn setup (defined in package.json) feel free to come up with an alternative but we do need to fix that users see this obscene content as they create a new sample app at this point. ", "commit_messages": " let users define their own client token.  make sure users know that graphql schema can also be done via the ui ", "linked_issue_titles": "", "title": "let users define their own database as easily as possible."}
{"description": " i implemented the binomial and multinomial sampling. i also renamed the previous multinomial implementation to categorical. ", "commit_messages": " implement binomial sampling  add correct multinomial implementation  small fix in binomial symbol api doc  change npx_categorical to npx_multinomial ", "linked_issue_titles": "", "title": "add binomial sampling and fix multinomial sampling"}
{"description": " now we don't need to restart the program to apply new disassembly settings. and fix #715 (the disassembly interface is too messy) this change is ", "commit_messages": " gui: resolve issue #715  initialize mwidths with zero  gui: restart is nolonger required  gui: restart is nolonger required  gui: restart is nolonger required  gui: restart is nolonger required  gui: restart is nolonger required  gui: restart is nolonger required ", "linked_issue_titles": " the disassembly interface is too messy ", "title": "resolve ui bug (#715) and do not require restart on settings change"}
{"description": " increased the vertical margins between the 3 settings since they are not related to each other. added a release notes link. references #2138 #889 pr checklist applies to #2138 #889 cla signed. if not, go over here and sign the cla ", "commit_messages": " added release notes link  minor styling fixes ", "linked_issue_titles": "", "title": "release notes link + minor styling fixes"}
{"description": " after a post from user \"tann\" on discord #android channel we've realised some inconsistencies on the libgdx default color format (rgb565) and the platform defaults on android (rgb888) and ios (rgba8888). android it is currently set to rgb565 because that was the default of glsurfaceview before but, currently (not sure since when), it's rgb888 ( by default glsurfaceview will create a pixelformat.rgb_888 format surface. i've kept rgb565 as fallback in case the provided color format configuration is not supported by the device. this is the safest approach as, in the rare case a device did not support rgb888 it would fallback to previous default but it's not necessarily the best one. it depends if there are actually devices in the wild (with min sdk 14+) that don't support rgb888, if there aren't, we should default to rgb888. unfortunately i haven't been able to find that information. regarding the changes a couple of comments: the change in the bufferformat on androidgraphics is aesthetic. a new instance with the appropriate configurations is assigned to bufferformat, i'm not sure if instantitating it on declaration is needed at all but i've kept it just in case. something similar happens on glsurfaceview20 init() method changes. even if we set the color format there (either rgb888 or rgba8888) it doesn't matter because we set it manually afterwards in every case later on (check for example androidgraphics.createglsurfaceview()): glsurfaceview20 view = new glsurfaceview20(application.getcontext(), resolutionstrategy, config.usegl30 ? 3 : 2); if (configchooser != null) view.seteglconfigchooser(configchooser); else view.seteglconfigchooser(config.r, config.g, config.b, config.a, config.depth, config.stencil); known issues and tests using rgb565 has some known issues on especific devices such as reported here #5993. i've also personally observed issues when running an opengl gradient on a nexus 7 2013 which displays bad banding and artifacts that get fixed using rgb888. current default rgb565 causes dithering to be applied, especially visible when zooming in on any libgdx game with default settings. @cypherdare says he's been using rgba8888 on his apps for 5 years without any issue. ios on ios the current default is rgba8888 ( ios is weird because the color format seems to be ignored when running on a device (it always looks like rgb888) but it is correctly applied on simulator. i've confirmed this and has been reported on the forums before: ", "commit_messages": " set android glsurfaceview texture format to android default rgb888  set ios default color format to rgba8888 ", "linked_issue_titles": "", "title": "use platform default color bit depth on android and ios"}
{"description": " cherry-picks: dc197e5 5306563 bc2d1d3 df0c097 risk level: low testing: ci part of #10741 ", "commit_messages": " release: kick-off 1.14.2-dev  build: refine docker image ci process (#10729)  ci: remove tools from agent for disk (#10775)  ci: update before purge in cleanup (#10938) ", "linked_issue_titles": "", "title": "various build fixes for 1.14.x"}
{"description": " currently this change reports errors only for heritage clause and constraints of type parameters if the name is not public ", "commit_messages": " make the symbol writing api on the text writer  checker and emitter changes to report errors on inaccessibility of symbols when writing types in declaration file  report error on class/interface heritage clause if it cant be accessed  fixes #78 and #83  report errors if the type parameter uses constraint that is using private type/module  fixes #86 ", "linked_issue_titles": "", "title": "report errors for usage of private types when generating declaration file"}
{"description": " provide two grafana dashboard settings. use skywalking trace-mode dashboard agent. use skywalking mesh-mode dashboard when skywalking is used with service mesh telemetry, including istio, envoy. this is the first version of grafana settings, feel free to improve this. @hanahmily the last step for #2073 fyi @peng-yongsheng ", "commit_messages": " change a label name for  sw instance to avoid confict.  fix a wrong metric name.  fix too many counter instances.  set uptime to second.  fix format.  fix format  remove two unnecessary counter.  provide grafana dashboard settings and remove unnecessary metric.  provide a simple ui brief doc. fix #2137 ", "linked_issue_titles": "", "title": "provide grafana settings for telemetry"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. summary of changes reduce examples to only those relevant to the overload and use shorter template for code-only examples. (57202ba / 5d46054 / 861831c / e349a3b / f02ab1e) previously, all examples for all overloads of a method were shown for every overload of that method. now, only relevant examples for each overload are shown. also, code-only examples now use a much shorter template. this should improve the experience for consumers through less noise. these changes also takes index.d.ts back under 1 mb which re-enables github features for it (e.g. syntax highlighting and linking to specific lines). minor changes (a8b6588 / 371a701 / ea00476) these changes are for consistency and should have no impact on existing code. add interface for jquery.fx. add interface for jquery.callbacks. apply consistent ordering. documentation fixes (8686d9f / 8310859) the documentation for jquery.deferred was incorrectly attached to its property instead of its call signature. this pr fixes it so that the correct documentation is displayed when using the call signature. also fixes documentation for an overload of jquery.proxy that had incorrect @since tags and an errant . add jquery.getscript(options). (78fb12a) see jquery/api.jquery.com#1052. accept document, window, and jquery.plainobject for the element parameter of data apis. (cf0be56) see  add jquery.cleandata. (39bfedc) see jquery/api.jquery.com#996. ", "commit_messages": " [jquery] introduce interface for jquery.fx.  [jquery] attach jquery.deferred documentation to correct symbol.  [jquery] convert jquery.callbacks to an interface.  this change is purely for consistency with similar properties (e.g. jquery.deferred, jquery.event).  [jquery] for jquery, reduce examples to only those relevant to the overload and use shorter template for code-only examples.  [jquery] for jquerystatic, reduce examples to only those relevant to the overload and use shorter template for code-only examples.  [jquery] for jquery.event, reduce examples to only those relevant to the overload and use shorter template for code-only examples.  [jquery] for jquery.callbacks, reduce examples to only those relevant to the overload and use shorter template for code-only examples.  [jquery] for jquery.promisebase/jquery.deferred, reduce examples to only those relevant to the overload and use shorter template for code-only examples.  [jquery] consistent ordering.  [jquery] add jquery.getscript(options).  see  [jquery] fix documentation for this one overload of jquery.proxy.  [jquery] accept document, window, and jquery.plainobject for the element parameter of data apis.  see  [jquery] add jquery.cleandata.  see ", "linked_issue_titles": "", "title": "documentation improvements. add jquery.cleandata and overloads for jquery.getscript and data apis."}
{"description": " maxpooling1d and averagepooling2d now passes tests with theano backend also added test cases with different padding modes for average pooling1d ", "commit_messages": " added padding test case for averagepooling1d  fixed issues with pool2d ", "linked_issue_titles": "", "title": "fixed issues with conv2d in theano backend"}
{"description": " when writing pub fn f( /// comment id: u8, ) {} produce a targeted diagnostic error: documentation comments cannot be applied to method arguments --> $dir/fn-arg-doc-comment.rs:2:5 | ll |     /// comment |     ^^^^^^^^^^^ doc comments are not allowed here fix #54801. ", "commit_messages": " produce targeted diagnostic when using doc comments on fn args  before parsing argument names and types, try to consume an incorrectly  included doc comment or attribute in order to recover and continue  parsing the rest of the fn definition.  point at match when a parse failure ocurrs inside of it ", "linked_issue_titles": "", "title": "custom diagnostic when trying to doc comment argument"}
{"description": " this enables underlying compiler support for the proposed exclusivity language feature for testing and evaluation. static enforcement: -onone: static access markers present through irgen -o: all access markers stripped before optimization -onone -enforce-exclusivity=unchecked: diagnostics active, no sil change. -o -enforce-exclusivity=unchecked: diagnostics active, markers stripped before optimization dynamic enforcement: dynamic markers are only present in silgen and throughout sil passes as long as necessary. i.e. once a marker is determined to be dynamic, it is stripped if it's inactive. -onone -enforce-exclusivity=checked: runtime diagnostics active. no changes to the sil other than the access markers themselves except in extreme unexpected cases. -o -enforce-exclusivity=checked: unsupported. output a warning. dynamic markers will be stripped. runtime diagnostics will not be active. ", "commit_messages": " [exclusivity] allow accessenforcementselection to run before di.  [exclusivity] handle copy_addr+destroy_addr folding with end_access markers.  [exclusivity] enable access markers for the entire -onone pipeline.  dynamic markers are still conditional on the command line option.  [exclusivity] update tests for access markers.  [exclusivity] access enforcement sil tests. ", "linked_issue_titles": "", "title": "-onone support for access markers, fixes to sil passes, options and pipeline config."}
{"description": " description: when user has multiple miflora devices, we can't connect to them during platforms setup, because it takes several seconds to connect to each device and we can't do it concurrently because of locks in btlewrap ( i will remove a code which makes a connection on platform setup. this will lead to 2 problems: first values will appear in 20 minutes (when first update will be called by ha).  we can handle it by triggering async_schedule_update_ha_state() right after ha start. we won't know if everything is ok with device during ha startup. it's impossible to handle this case, we will leave w/o it. related issue (if applicable): fixes #16700 ", "commit_messages": " possible fix for startup delay  fixed reported issues ", "linked_issue_titles": " platform miflora stoped working on 0.78.0 ", "title": "fix miflora connection errors during platform setup"}
{"description": " adds obs_audio_monitoring_supported() adds audio_monitoring source signal for monitoring type changes updates the advanced audio properties dialog when an input's audio monitoring type changes we allow users to change the monitoring type through obs-websocket, and it wasn't updating the ui when someone would perform a request. i also hate incomplete functionality. os: ubuntu 20.04 build: latest git commit as of posting obs_audio_monitoring_supported() related changes were only tested on ubuntu, but should work the same on all platforms. audio_monitoring signal was tested via obs-websocket advanced audio properties update when setinputaudiomonitortype obs-websocket request is performed bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) code cleanup (non-breaking change which makes code smaller or more readable) documentation (a change to documentation pages) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " libobs: add obs_audio_monitoring_supported()  currently, ifdefs are used to determine if monitoring is supported.  this is difficult to maintain and restricts plugins from knowing if  monitoring is supported by obs. this adds a runtime function to fix  that issue.  libobs/ui: stop using preprocessor directives for monitor  **code cleanup**  stop using preprocessor directives to determine if audio monitoring  is supported. use runtime function instead  libobs: add audio_monitoring source signal  adds a source signal for audio monitoring type changes  ui: update adv audio props on monitoring type change  update the audio monitoring combo box when it is changed via libobs.  required to make obs-websocket requests work well ", "linked_issue_titles": "", "title": "signal when monitoring type is changed and update ui accordingly"}
{"description": " @steven-sheehy @unguiculus this skips initialization of the replicaset during bootstraping if set to true. this is helpful during a migration phase. you can now add the created nodes to an already existing mongodb replicaset and still install and mange the cluster with the helm chart. you just end up with the defined number of new empty nodes and can implement your own migration path with it. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " start the server with ssl enabled if the client also uses ssl  in retry_until only read the last mongo client line  add a donotinit value that skips the replicaset creation on first start  added test for donotinit flag  bumped chart version, added documentation to readme.md ", "linked_issue_titles": "", "title": "dont initiate replicaset during bootstrapping"}
{"description": " hi @apache/skywalking-committers and all this pr brings all i talked in #3098, now oal scripts are loaded in bootstrap stage oal is still at compile level. but not by jdk, instead, by oalruntime to generate binary codes. this is the black magic, i have tried my best to keep codes as simple as possible, and keep using freemaker templates for readability. all metrics process flows are the same as before i am going to add metrics name in the remote protocol after this pr merged, to replace the id, because, at bootstrap level, oal scripts may different somehow in different instances. we should use the literal string name in the internal distributed aggregation and print warning log when receiving unexpected metrics name. ", "commit_messages": " change oal generator tool to runtime.  step 1. change project structure. api links and maven pom.  part of metrics class generation  metrcis class generated.  set up the basic structure of new oal engine.  finish metrics generation.  support dispatcher generation.  format codes.  generate dispatcher all methods.  implement disable in hardcode.  clear up  merge commit 'c7916d9f2715ff9d3c415f86418d8f81c97a21e7' into rt-oal  # conflicts:  #\toap-server/pom.xml  fix compile startup.  update license and document of new oal engine. ", "linked_issue_titles": "", "title": "all new oal runtime engine"}
{"description": " android 4.4 added support for basically a slightly more advanced fullscreen feature called 'immersive mode'. this will be beneficial to some games that have support for smaller phones. this fixes #942 ", "commit_messages": " added immersive mode option  added android 4.4 kitkat immersive support  fixed accidental typos, sorry.  added actual immersive mode  updated android library to android 4.4 for immersive mode  immersive mode needs a flag that requires the android 4.4 libraries ", "linked_issue_titles": " android 4.4 kitkat 'immersive mode' missing ", "title": "added immersive mode support for android 4.4 kit-kat devices"}
{"description": " update the tutorial to use the updated version of graphiql with the explorer pane. replace the graphiql-explore.mp4 screen capture with new version. update related screenshots. add new verbiage to introduce the explorer. add new section on field selections with the explorer. none. closes #15806 ", "commit_messages": " replace graphiql explore screengrab with version with explorer  add graphiql explorer examples ", "linked_issue_titles": " update the tutorial to use the explorer ", "title": "update tutorial to use graphiql explorer"}
{"description": " addresses #21350 #dataumbrella this pr ensures metrics.pairwise.euclidean_distances is compatible with numpydoc: remove metrics.pairwise.euclidean_distances from docstring_ignore_list. verify that all tests are passing. partner: @genvalen ", "commit_messages": " remove euclidian_distances from function_docstring_ignore_list  ensure that euclidian_distances method passes numpydoc validation ", "linked_issue_titles": "", "title": "doc ensures that metrics.pairwise.euclidean_distances passes numpydoc validation"}
{"description": " description: this adds support for the homekit battery service - so battery powered homekit accessories can now report their battery percentage, if they are currently charging and if their battery percentage is low. checklist: local tests pass with tox. your pr cannot be merged unless tests pass if the code does not interact with devices: ", "commit_messages": " add simple battery sensor  vary icon based on battery state  add test for battery sensory  add test for battery sensor based on a real device  read other battery related states from accessory  add a device class to the battery sensor  respect the low battery flag from the device ", "linked_issue_titles": "", "title": "add support for homekit accessory battery sensors"}
{"description": " closes #22556 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " fix na_position when sort_values by categorical values  move test to test_sort.py and fix index  using pandas.isna to allow categoricalindex calling nargsort  linter fix in test_sorting.py  add to whatsnew ", "linked_issue_titles": " df.sort_values() not respecting na_position with categoricals ", "title": "df.sort_values() not respecting na_position with categoricals #22556"}
{"description": " fixes #35226 which is part of #35233. is based on #36208 from @yossi-k. r? @jonathandturner ", "commit_messages": " update e0088 to new format, remove e0090  use span of first unexpected lifetime in e0088. ", "linked_issue_titles": "", "title": "update e0088 to new error format"}
{"description": " when i do something like this: var handlescroll = _.debounce((e:jqueryeventobject)=>{ //handle the scroll event here }); $el.on(\"scroll\", handlescroll); typescript compiler throws error citing parameter mismatch. since these functions return the function with same signature as the functions passed in it is easy to support them via generics. ", "commit_messages": " made the functions once, debounce, throttle, after to accept function with generics signature. the function returened from these functions will have signature as the functions passed into them, compiler should be made aware of this.  corrected the auto spacing created by webstorm ide ", "linked_issue_titles": "", "title": "adding generics support for the underscore functions throttle, debounce, once, after"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " move fingerprintjs types to v1 sub-folder  add types for fingerprintjs2 v2, fix config for v1 ", "linked_issue_titles": "", "title": "add types for fingerprintjs2 v2, move v1 types to subdir"}
{"description": " the check_f macros differ slightly (but eventually do the same thing) so the guards allow all the decoder files to be 'amalgamated' into a single file. older gcc needs to fallback on the old-style pragma optimisation flags (the alternative path was verified with gcc4). ", "commit_messages": " v1.4.1: merge pull request #1691 from facebook/dev  v1.4.2: merge pull request #1700 from facebook/dev  fix the build on gcc 4.x after 812e8f2a1  the ancient gcc 4.x doesn't understand the \"optimize\" attribute until 4.4.  fix the build on platforms with gcc 4.x < 4.4 by limiting the dont_vectorize  definition to gcc 5 and greater.  noticed and patch proposed by warner losh <imp@freebsd.org>.  v1.4.3: merge pull request #1730 from facebook/dev  fix the build on gcc 4.x after 812e8f2a1  tweaks to create a single-file decoder  the check_f macros differ slightly (but eventually do the same thing). older gcc needs to fallback on the old-style pragma optimisation flags. ", "linked_issue_titles": "", "title": "tweaks to create a single-file decompressor"}
{"description": " performance optimization ops cherry-pick #29187, #29484, #29553 ", "commit_messages": " improve performance of elementwise_add grad op (#29187)  * pass stop_gradient for cast op  * improve performance of elementwise_add grad  * use tensor copy async  * dygraph branch  * fix dygraph branch  * add ut  make gelu fp16 computing more robust (#29484)  add fast path for dropout when p == 0  (#29553)  * add fast path for p == 0 in dropout  * add ut ", "linked_issue_titles": "", "title": "some optimizations of elementwise_add, gelu and dropout for amp"}
{"description": " this pr adds 2 extra tests for gridlayer zoom-in and zoom-out animation on \"graphical browsers\" (i.e. not phantomjs). they are similar to these already existing 2 tests: gridlayer number of 256px tiles loaded in synchronous animated grid @800x600px loads 32, unloads 16 tiles zooming in 10-11 gridlayer number of 256px tiles loaded in synchronous animated grid @800x600px loads 32, unloads 16 tiles zooming out 11-10 but instead of using clock.tick to accelerate the tests and have to use raf at the appropriate moments, these tests let the animation execute on its own. therefore they should be less prone to breaking when the animation is internally modified. the drawback is that they take slightly longer time to pass (a few hundreds ms). but there are already much longer tests (a few seconds for some of them). hopefully this pr will not conflict once the previous one gets merged (#6199) ", "commit_messages": " test(gridlayer): add zoom-in for graph browser  add a new test for \"graphical browsers\" for zoom-in animation, not relying on sinon.usefaketimers so that it lets the animation executing on its own, and is less prone to breaking when the animation process is changed internally.  test(gridlayer): add zoom-out for graph browsers  add a new test for \"graphical browsers\" for zoom-out animation, not relying on sinon.usefaketimers so that it lets the animation executing on its own, and is less prone to breaking when the animation process is changed internally. ", "linked_issue_titles": "", "title": "add 2 new tests for zoom-in/-out in graphical browsers"}
{"description": " as title. #17702 and #17872 revised same lines in test_gluon_rnn.py. so we need to backport them in one. @ciyongch @taolv @pengzhao-intel also ", "commit_messages": " support projection feature for lstm on cpu (only inference) (#17702)  * support projection feature for lstm on cpu  * test solution for -werror=maybe-uninitialized  * check device type when create state  * document the projection feature of lstm for rnn operator  * minor fix  * re-run ci  fix issue of zeros gradients w.r.t. rnn bias when num_layers > 1 (#17872)  * fix issue of zeros gradients w.r.t. rnn bias when num_layers > 1  * use nd.copy() to initialize parameters of new operator  * add check for output states  * initialize i2h/h2h_weights with zeros for rnn_relu/tanh, and reduce size  * split fused rnn layer test into tests of individual mode  * skip lstm and gru tests on cpu context without dnnl ", "linked_issue_titles": "", "title": "backport #17702 and #17872 to v1.x branch"}
{"description": " what's in this pull request? resolved bug number: (sr-) before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " improve comment and function name. nfc.  add a test case for recent change in functionsignatureopts ", "linked_issue_titles": "", "title": "address gottesmm's and jrose-apple's comments on the partial_apply optimization"}
{"description": " implement dlpack to paddle tensor conversion, add \"tensorfromdlpack\" function to tensor_util.h, support cpu and gpu. the dlpacktensor class adds the conversion function \"todlmanagedtensor\" to dlmanagedtensor (in order to achieve the connection with cudf and cupy, dlmanagedtensor is required) through pybind11, encapsulate the python interface, pass the dlmanagedtensor pointer through the pycapsule object, and open up with cudf and cupy. added tensor.to_dlpack and fluid.core.from_dlpack interfaces. ", "commit_messages": " support convert tensor to cudf depends on dlpack test=release/1.6 ", "linked_issue_titles": "", "title": "support dlpack convert to cudf"}
{"description": " if we want to support this property, the following patches provides a way of doing so. please refer to the individual commit messages for additional details. fixes #8657. ", "commit_messages": " [api-minor] add support for pagemode in the api (issue 8657)  please refer to  refactor reading from the viewhistory in pdfviewerapplication.load ", "linked_issue_titles": "", "title": "add support for pagemode in the api and viewer (issue 8657)"}
{"description": " this pr introduces a rather big change. the highest-level namespace definition is removed: the whole file represents now the ol namespace. it does not change the way to use the module, still use import * as ol from 'openlayers'. the changes have been tested on a test application based on the draw shapes example. reorganizing the namespaces makes the internal olx namespace available from outside as ol.olx. it fixes #19956. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " fix no-declare-current-package lint  fix no-internal-module lint  fix no-single-declare-module lint  update tests file using import ", "linked_issue_titles": " [openlayers] is there any reason for hiding olx? ", "title": "fix the module-related lint issues"}
{"description": " pulled from some kbfirmware json files after a discord user contacted me about this board. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " [keyboard] neo keys palette g67 hotswap  [keyboard] neo keys palette g67 soldered ", "linked_issue_titles": "", "title": "neo keys palette g67 hotswap & soldered"}
{"description": " this breaks up the serverless-loader into typed handlers to allow for easier maintenance and better type-checking/linting. closes: #19071 ", "commit_messages": " migrate api serverless handler to typed handler  migrate api serverless handler to typed handler ", "linked_issue_titles": " strongly type next.js' serverless loader ", "title": "break up the serverless loader into typed handlers"}
{"description": " >>> @dataclass(repr=false, eq=false, init=false) ... class x: ...     a: int ...     b: int ...     c: int ... traceback (most recent call last): file \"<stdin>\", line 2, in <module> file \"/home/bucher/src/cpython/lib/dataclasses.py\", line 1042, in wrap return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen) file \"/home/bucher/src/cpython/lib/dataclasses.py\", line 1020, in _process_class cls.__match_args__ = tuple(f.name for f in flds if f.init) unboundlocalerror: local variable 'flds' referenced before assignment ", "commit_messages": " add a regression test for bad __match_args__ logic  fix broken __match_args__ logic  blurb add ", "linked_issue_titles": "", "title": "fix __match_args__ generation logic for dataclasses"}
{"description": " closes: #7371 closes: #7726 ", "commit_messages": " fix(aws sqs): fix referencing lambdas with provisioned concurrency  fix(aws api gateway): fix referencing provisioned authorizers ", "linked_issue_titles": " aws sqs event source does not work with a lambda with provisionedconcurrency  api gateway custom authorizer not referencing provisioned alias lambda when specifying provisioned concurrency ", "title": "fix setup of lambdas with provisioned concurrency"}
{"description": " this change ensures pseudoterminal-based and local terminals (vscode-file uri as cwd) do not await available profiles as they will not be used: this also ensures we await the createterminal call before returning to the exthost to ensure the terminal id is ready before proceeding. fixes #132519 fixes microsoft/vscode-remote-release#5556 ", "commit_messages": " don't await profiles for custom ptys, ensure createterminal returns  fixes #132519  fixes microsoft/vscode-remote-release#5556  ensure local terminals can launch before available profiles are ready  fixes #132519  fixes microsoft/vscode-remote-release#5556 ", "linked_issue_titles": "", "title": "fix launching pseudoterminal-based and local terminals in remote workspaces before the connection is established"}
{"description": " this is an extended version of #1084, allowing to specify a custom host in the seafdav.conf file, fixing #478. currently, the webdav server binds to localhost if used in fastcgi mode, and to 0.0.0.0 if used in standalone mode. both may be undesired. it is especially annoying if an external web server is used in conjunction with fastcgi. ", "commit_messages": " added option to seafile controller to configure host to bind seafdav service to using seafdav.conf  added default host to seafdav.conf ", "linked_issue_titles": "", "title": "custom webdav binding configuration using seafdav.conf"}
{"description": " this patch simply adds method docs to most of the methods in ml/dmlc/xgboost4j/scala/spark/xgboost.scala and also adds a few style changes to make the code a bit more uniform. i think/hope this will be valuable for developers who need to make changes to the spark package and even for users who wish to understand how xgboost4j-spark parallelizes training within spark. if this is valuable to the community, please let me know if any style changes violate desired conventions, or if any of the docs should be updated/modified. tests no functionality is changed, so existing unit tests should be sufficient. ", "commit_messages": " add scala docs to several methods  indentation  license formatting  clarify distributed boosters ", "linked_issue_titles": "", "title": "add some documentation to xgboost4j-spark plus minor style edits"}
{"description": " changes in this: if the old state was not present or not used, we set flag that says instead of calculating signature for a file (which is dts emit hash) use the version of file as the signature. this makes it so that initial compilation will not calculate the d.ts emit and next file change to the file will be treated as non local change and thats when the signatures for file reference dependency are calculated and it would probably result in emitting more files than necessary but thats the compromise for not having to spend cost for d.ts emit in the initial round. the next change to that file should be able to correctly detect local/non local change as before. 925e70e just updates tests to ensure we are testing the scenarios we intended. dd1cef2 is actual change and may be ideal to look at the changes as part of that commit. 69ebfe3 checks updates to the incremental correctness of the program, essentially signature is same as d.ts emit signature or version of the file. also exported modules map is checked in similar way. 44ba0ec reverts the compileonsave to old behavior of always computing signature this is simplified implementation of work in #42960 by @sokra there are more todos that we can improve on, eg if global file is changed, mark it for lazy signatures etc  but i think that each change should be separate change to be able to evaluate the perf impact and if needed revert it. potential improvements: global file change => resulting in emitting all files so could benefit from using signature as version certain number of new files percentage certain number of changed file percentage ", "commit_messages": " extra tests in preparation for lazy signature making sure the original intent of test is maintained  whenver we cant use state delay signature calculation and use source file version as signature  incremental correctness checks ", "linked_issue_titles": "", "title": "do not calculate signatures if old state is not used"}
{"description": " fixes #757 (v2) replace all wstring from public methods to platform::string also replace std::task by iasyncoperation convert localizationstringutil and appresourceprovider to \"ref classes\" use wstringstream when we concatenate many strings. manually ", "commit_messages": " prefer platform::string to wstring in calcviewmodel  merge with upstream/master  fix \"__va_start intrinsic only allowed in varargs\" with x64/arm compilation  take feedback into account  fix string formatting with narrator and bring back cached values ", "linked_issue_titles": " prefer platform::string over wstring in calcviewmodel ", "title": "replace wstring used in public methods by platform::string in calcviewmodel"}
{"description": " this simplifies and removes a lot of duplicate code from qwiickeyboard, and should also fix the layer cache to properly work with mt and lt keys. ", "commit_messages": " fix missing brackets warning  make the layer cache more efficient  also change the internal representation to a one dimensional array  add a keymatrix_t type  this contains both the matrix number and key position, in preparation  for multi-matrix support  add proper multimatrix support  document some functions ", "linked_issue_titles": "", "title": "add multi-matrix support and make the layer cache more efficient"}
{"description": " description: adds a stat control_plane.connected_state that indicates whether envoy's connected state with management server risk level: low testing: automated tests docs changes: added release notes: added fixes #4449 ", "commit_messages": " added stat for connected state of control plane  update docs ", "linked_issue_titles": "", "title": "add control plane connected state stat"}
{"description": " this pr adds support for the decrqss (request selection or setting) escape sequence, which is a standard vt query for reporting the state of various control functions. this initial implementation only supports queries for the decstbm margins, and the sgr graphic rendition attributes. this can be useful for certain forms of capability detection (#1040). as one example in particular, it can serve as an alternative to the colorterm environment variable for detecting truecolor support (#11057). of the settings that can be queried by decrqss, the only other one that we could be supporting at the moment is decscusr (cursor style). however, that would require passing the query through to the conpty client, which is a lot more complicated, so i thought it best to leave for a future pr. for now this gets the basic framework in place, so we are at least responding to queries, and even just supporting the sgr attributes query is useful in itself. i've added a unit test verifying the reports for the decstbm and sgr settings with a range of different parameters. i've also tested the decstbm and sgr reports manually in vttest, under menu 11.2.5.3.6 (status-string reports). ", "commit_messages": " add the basic framework for decrqss.  add a handler for the decstbm setting.  add a handler for the sgr setting.  add some unit tests.  appease the spelling bot. ", "linked_issue_titles": "", "title": "add basic support for the decrqss settings query"}
{"description": " this is an update to #3751 to provide an error back to the client when database inserts fail. ", "commit_messages": " log error on device status insert & don't crash  add error logging to all mongo inserts  return error when role or subject create fails.  return error if insert fails for activity, devicestatus, or food. ", "linked_issue_titles": "", "title": "fix database insert error handling"}
{"description": " v2 of #2083 ", "commit_messages": " basic/virt: add missing includes to compile on ppc64  tests: turn check if manager cannot be intialized into macro  we need to check the same thing in multiple tests. use a shared  macro to make it easier to update the list of errnos.  change the errno code for \"unitialized cgroup fs\" for enomedium.  exec format error looks like something more serious.  this fixes test-execute invocation in mock.  tests: fix newlines in skip message  lz4: fix size check which had no chance of working on big-endian ", "linked_issue_titles": "", "title": "test fixes to run in ppc64 mock"}
{"description": " ref #98326 /priority important-soon comments for reviewer: might be easier to review commit-by-commit. ", "commit_messages": " split gce/gke upgrade mechanics to a separate file  rename functions to eliminate master word  move non-provider specific upgrade tests logic to upgrades package ", "linked_issue_titles": "", "title": "split upgrade tests logic to generic and provider-specific"}
{"description": " description: refresh closest store when menu requested related issue (if applicable): fixes #10929 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " reload closest store on api request  revert change from debugging ", "linked_issue_titles": " dominos config error ", "title": "reload closest store on api menu request"}
{"description": " to be merged when 1.15 has been released and we've updated our own prettier version. ", "commit_messages": " update rationale about multiline object literals for the 1.15 changes  add rationale about decorators for the 1.15 changes ", "linked_issue_titles": "", "title": "update rationale for the 1.15 changes"}
{"description": " todo: remove print button fix/add print button restyle progress bar re-arrange the zoom options to stephen's specs. add back the browse file button or just remove it? add disabled state for buttons? i think we should change it so the outline button is never disabled, instead it should just say in italic \"no outline available\" or something. clean up the error message dialog a little more out there: scroll the thumbnail view while the user scrolls the main pages. determine the page number based on the center of the screen instead of the top. ", "commit_messages": " first mockup, loads tracemonkey pages ok  sidebar toggle working  fixing sidebarview scroll bar overflow  text selection ok, switch outline ok  bug fix (works with intelisa)  outline view  disable user select in outline  page number works (not editable yet)  user-changes to pagenumber are working  loadingicon ", "linked_issue_titles": "", "title": "new ui - work in progress"}
{"description": " tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry closing a fixme note in the test suite. ", "commit_messages": " bug: raise ambiguoustimeerror for date_range with ambiguous start time.  clarify comment  add nonexistent tests  xfail one case after discovered bug ", "linked_issue_titles": "", "title": "fix handling of ambiguous or nonexistent of start and end times in date_range"}
{"description": " fixes #7179 please also review #7932 first as the cleanup to this script. as per title component name area/system none tested several variations of the repro in #7179 and in all cases whether or not netdata is installed in a symlinked location editing configuration eith edit-config works as expected with: enjoy real-time performance and health monitoring... copying '/opt/netdata/usr/lib/netdata/conf.d/apps_groups.conf' to '/opt/netdata/etc/netdata/apps_groups.conf' ... editing '/opt/netdata/etc/netdata/apps_groups.conf' ... ", "commit_messages": " re-formated ./system/edit-config.in with shfmt -w -i 2 -ci -sr  fixed and cleaned up ./system/edit-config to work correctly with symlinks ", "linked_issue_titles": " edit-config fails due to /opt being a symlink ", "title": "fixes support for editing configuration when netdata is installed to a symlinked /opt"}
{"description": " hacktoberfest notes: due to volume of submissions, we may not be able to review prs that do not pass tests and do not have informative titles. please read our contributing guidelines be sure to check the output of travis-ci for linter errors if this is your first open source contribution, make sure it's not your last! tryna to transfer cheatsheet links from books to cheatsheets page cheatsheets are smaller and can container good amount of infos you can check it by its link cheatsheets not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " docs: add links for cheatsheets  docs: remove links for cheatsheets from books page ", "linked_issue_titles": "", "title": "transfer links for cheatsheets from books page to new cheatsheets page and add css/js cheatsheets"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration ", "commit_messages": " servicenow jakarta api  rename and add add header  fix linting errors ", "linked_issue_titles": "", "title": "new typings for servicenow javascript api reference"}
{"description": " what is this about? this pr removes the requirement that space is needed after the action keyword. pr checklist applies to #3212. cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request what does this include? the following changes have been made in this pr - previously, there was only one query being sent to all the plugins. if the first space separated item was an action keyword, then only a non global query would be executed. however, now we have a query being generated for each plugin. we execute global plugins along with the non global plugins as we have removed the space requirement following the action keyword. a few symbols have been added to the search ignore regex of the indexer plugin. the symbols which have been added are >, < and : because when we search for >cmd, the indexer plugin is also executed now and it compared the filenames and returns those which are greated than cmd. this was leading to a delay. also, filenames do not contain these symbols >, < and :. hence queries containing these symbols can be ignored. previously the cancellation token was based on the query, however since we have a unique query for each plugin, the cancellation token is based on the querytext instead which is same for all plugins. validation steps performed how does someone test & validate? added  tests manually validated it ", "commit_messages": " returning individual queries for each plugin  changed cancellation token from query type to directly using the rawquery  changed the way we get the plugins for which we execute the query  updated updateresultview to take a string instead of query  changed the way we set a query for each plugin  removed todo comment  global plugins are added as a part of the query builder  merging with master  fix for plugin.json of folder plugin being copied into the shell plugin  >,< and : are not allowed in file paths and indexer creates a query which searches compares if a file name is greater than or lesser than the query  reformatted the regex  catching the exception  fixed merge conflicts  fixed existing tests  modified it so that it works with action keyword as well as action keywords  added unit tests for non global plugins  fixed test ", "linked_issue_titles": "", "title": "to remove the condition that space is needed after the action keyword"}
{"description": " this bug only occurs if ray.job.resource-path is set. in multi-threading scenario, different raynativeruntime instances holds different functionmanager instances, which means different classloader instances for the same job. if the user code involves any static variables, it may behave strangely. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " fix multiple functionmanager instances lead to unexpected behavior about classloader  use explicit locks instead of synchronized keyword on methods ", "linked_issue_titles": "", "title": "fix multiple functionmanagers creating multiple classloader s"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " update ws for version 3.0.0 (  update ws for version 3.0.0  update spdy to avoid redeclaring node types.  put back spaces to avoid pull-request problems ", "linked_issue_titles": "", "title": "avoid re-declaring node types, import instead"}
{"description": " fixes #998 the sls variables xxx type commands now support the serverless variable hierarchy (common, stage and region). you can now easily set a variable within the specified scope. ", "commit_messages": " issue #998 - variables list shows stage variables  issue #998 - variables set command supports common, stage and region variables now.  removed support for \"all\" regions as it is not needed anymore due to the added hierarchy support.  issue #998 variables unset supports common, stage and region variables. ", "linked_issue_titles": "", "title": "998 variables support stage vars"}
{"description": " closes #17253 n/a - internal work for multi-domain removes hard-coded domain in multi-domain implementation, so any secondary domain can be visited. n/a has the original issue (or this pr, if no issue exists) been tagged with a release in zenhub? (user-facing changes only) n/a has a pr for user-facing changes been opened in cypress-documentation? n/a have api changes been updated in the type definitions? n/a have new configuration options been added to the cypress.schema.json? ", "commit_messages": " chore: fix rerunning multidomain tests  remove need for anticipatemultidomain  remove anticipatemultidomain from rerun spec  use the domain  use this.debug  create new signal for multidomain that doesn't abuse stability  fix types and tests  fix typo from merge conflict  chore: remove hard-coded domain for multi-domain ", "linked_issue_titles": "", "title": "remove hardcoded domain for multi-domain"}
{"description": " the interface affects dog/cifar competition chapters. the change also affects utils.py, since the new transform function leaves label as an ndarray object, instead of a scalar. please run ci to make sure this is not breaking anything else. ", "commit_messages": " add librsvg2-bin in readme  improve kaggle dog tutorial  fix  merge remote-tracking branch 'upstream/master'  improve  improve  improve  merge remote-tracking branch 'upstream/master'  update data aug  add fix to utils for new transform  fix ", "linked_issue_titles": "", "title": "switch to new transform function"}
{"description": " for #6478 . add test case for sqlserver output clause without output table column. add test case for sqlserver output clause without output table. add test case for sqlserver output clause column shorthand. ", "commit_messages": " fixes collection empty condition.  add test case for sqlserver output clause without output table column.  add test case for sqlserver output clause without output table.  add test case for sqlserver output clause column shorthand. ", "linked_issue_titles": "", "title": "add sqlserver output clause test case."}
{"description": " i am just doing some incremental work towards formalizing store_borrow into an interior pointer and cleaning up a few other things in the process. more specifically: i eliminated some dead code in borrowedvalue's interior pointer finding code. we were always handling open_existential_box, store_borrow earlier since they are interior pointer operands. i changed ome to while lowering rauw store_borrow's result with its dst and added a test. i added interior pointer error tests for store_borrow, open_existential_box, and an interior pointer that is stored into by a store_borrow (we want to in that case treat the store_borrow result's uses as uses of the interior pointer). ", "commit_messages": " [ownership] delete dead code that explicitly handles interior pointers open_existental_box, store_borrow.  these both are already classified as interior pointers. thus, we would have  already handled them at the top of the loop where we handle interior pointer  operands.  [ownership] when lowering store_borrow, rauw its result with its input dest.  a store_borrow is a manner to temporarily \"borrow\" a guaranteed value into  memory for purposes like reabstraction. to make this safer in ossa, we treat a  store_borrow's result as an interior pointer into the stored guaranteed value,  causing all uses of that result to be validated as being within the lifetime of  the guaranteed value.  note: this is not the complete store_borrow verification story. we also will  verify that the memory that is being store_borrowed into is not written to while  the store_borrow's result is live.  [ownership] add an interior_pointer error test for store_borrow.  just didn't see one. now we have added to our proof collection a  test case where the store_borrow's result has a use after the end of the source  object's lifetime.  [ownership] when looking at an interior pointer's uses, look through store_borrow.  the store_borrow's result is a sub-interior pointer that ensures that any uses  of the interior pointer are within the lifetime of the borrowed value that is  being stored. but fundamentally this is just embedding lifetime ownership on  def-use edges and once ossa is lowered the result is just the destination  address. so it makes sense to include the uses of the result of the store_borrow  as the dest's uses.  [ownership] add an interior_pointer error test for open_existential_box.  i didn't find one in the file, so i added it. ", "linked_issue_titles": "", "title": "small code improvements around interior pointers"}
{"description": " apparently that's allowed and the rfc is just unclear about it. some servers seem to zero-pad the chunk size for whatever reason, and previously, we interpreted that as the last chunk. this still does not fix loading github, as the css parser chokes on one of the stylesheets. this sort of infinite loop seems to stem from us handing it something that has invalid data in it, so i am still quite suspicious of transfer-encoding's. ", "commit_messages": " libtls: do not call on_tls_finished until the client has read app data  libhttp: handle chunk sizes that start with zeros correctly  apparently that's allowed and the rfc is just unclear about it.  some servers seem to zero-pad the chunk size for whatever reason, and  previously, we interpreted that as the last chunk. ", "linked_issue_titles": "", "title": "handle silly chunked-encoding chunk sizes"}
{"description": " this pr addresses a few issues with this system test flakiness. this pr is a cherry-picked duplicate of #6041 but for the 2.1 branch, hence i won't repeat the inline comments here. need to grab the monitor before a given operation to observe logs for signal relied too much on a timely rebalance and only sent a handful of messages. i've updated the test and ran it here ", "commit_messages": " minor: fixes for making test more stable  minor: cherry pick commits to 2.1  minor: move restart of kafka node inside grabbing the monitor  minor: more clean up and close up other timing error gaps  minor: clean up messages ", "linked_issue_titles": "", "title": "fixes for broker down test stability 2.1"}
{"description": " a reopening of #16178. quote from there: theme packages should now be publishable (is that even a word) by lerna note that it wipes out changes from this recent commit: 4793654 (not sure if it makes sense now, needs advice). ", "commit_messages": " move theme starters into starters  move themes into packages  remove themes directory  cleaned up the renovate config  cleaned up the lerna config  cleaned up the ci config  exclude theme starters from markdown-magic  cleaned up themes package.json ", "linked_issue_titles": "", "title": "move themes into starters and packages"}
{"description": " added description of the change added file name matches file name guidelines added tests and example, the test must pass added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines notes: i'll try to fix the merge conflicts in this pr. the reason for this is because i previously worked on this, but i didn't submit the pr the same day i started working on it the merge conflicts are resolved now. ", "commit_messages": " [feat/fix/docs]: improvements in the...  ...backtracking folder, and minor fixes in the others/iterative_tree_traversals.cpp and the math/check_prime.cpp files.  clang-format and clang-tidy fixes for 9cc3951d ", "linked_issue_titles": "", "title": "improvements in the backtracking folder"}
{"description": " now builds static instances correctly. closes #369 as far as i can tell, what essentially happened here is that instances in the designspace were not being renamed, even though the sources were being renamed. as a result, the variable fonts would build correctly, but the static instances were not. the font naming approach has now been changed and is producing reliable results. what's particularly vexing is that for the life of me i can't figure out how the code actually worked before, because as far as i can tell, we've never modified the instance code before. checked tables in ot master ", "commit_messages": " update build.py  fixing so static instances build properly.  update build.py  previous commit wasn't quite working. took a different approach. ", "linked_issue_titles": " according to fontconfig, familyname no longer contains style name :( ", "title": "set the names of the static instances properly"}
{"description": " this pr allows disabling individual rgb matrix effects in userspace. an effect can be disabled by defining disable_[effect_name] in config.h: // to disable alphas mods #define disable_rgb_matrix_alphas_mods ", "commit_messages": " allows disabling animations in user space  describe disabling effects in the docs ", "linked_issue_titles": "", "title": "allows disabling rgb effects in userspace"}
{"description": " to constantly respond to container failures, i add a health check to all integrations. thanks to this, docker is able to detect the problem earlier and restart the container if necessary. information about the state of the containers is also available in docker ps command. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " add health check to integrations  fixup! add health check to integrations  fixup! fixup! add health check to integrations ", "linked_issue_titles": "", "title": "add docker health check to integrations"}
{"description": " move user-agent: to the new metadata traits system (and away from the old callouts system). this required dealing with slices as data in the new metadata system, which more importantly meant figuring out how to deal with values with ownership semantics (as opposed to the simple integer like values we've been shuffling so far). this also meant needing to fix up a few more places where older api's were utilized. in order to deal with the ownership semantics, i needed a slice type that could express them, so this change also introduces grpc_core::slice and some other associated types. for now it exports some c++-ish accessors, some named constructors, and some unnamed conversion constructors. there's a nice story with this type around mutability, and a better story than we have currently about accelerating operations on some slice types. strategically for slices the objective will be to plug this type family throughout grpc_core, and concurrently remove the managedmemoryslice, unmanagedmemoryslice and other friends that derive from grpc_slice, as this pattern seems remarkably hard to understand and use safely. @drfloob ", "commit_messages": " new slice api  storage-classes ", "linked_issue_titles": "", "title": "user-agent metadata trait, also: grpc_core::slice is born"}
{"description": " clean up the styles in <indexroute/> component create a separate component for getting started section move the <diagram/> styles to the <diagram/> component replace css to sx setupscrollersobserver & unobservescrollers using useeffect() hook convert indexroute to function component how to test go to the following link mentioned below and scroll down a little bit, the component should work same in both the local and production link, just the implementation of component is now different. local url:  production url: ", "commit_messages": " move <diagram/> styles inside <diagram/> component  convert indexroute to function component  add homepagegetstarted component  moved the wrapper styles to object  semantics :3 ", "linked_issue_titles": "", "title": "refactor, tidy and convert gatsby homepage to function component"}
{"description": " what types of changes does your pr introduce? put an x in all boxes that apply added dropbox to the list because i used it for some years for screenshotting, it worked great and it wasn't already added in here. ", "commit_messages": " update readme.md  i used dropbox for screenshots until 2 years ago and it works very good  update readme.md ", "linked_issue_titles": "", "title": "added dropbox to the list of screenshot softwares"}
{"description": " this pr contains two changes to swiftlang, the swift layer exposing sourcekit in swift: make each variant keep a strong reference to its sourcekitdresponse context. this is needed because sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was retrieved from (wrapped by sourcekitdresponse) is still alive. expose the new data variant sourcekit apis that were added to support returning the syntax tree in a binary format in swiftlang. ", "commit_messages": " [sourcekit] make each variant keep a strong reference to its sourcekitdresponse context  sourcekitd_variant_t is only safe to use while the sourcekitd_response_t it was  retrieved from is still alive, so keep a strong reference to sourcekitdresponse  (the swift wrapper of sourcekitd_response_t) in each variant (the swift wrapper  of sourcekitd_variant_t).  [sourcekit] expose the data variant sourcekitd apis in the swiftlang wrapper  these were recently added to support returning the syntaxtree in the bytetree  from sourcekit but were never added in swiftlang (the swift layer wrapping  sourcekit). ", "linked_issue_titles": "", "title": "keep sourcekitd response alive for variant lifetime"}
{"description": " emit a compile time provided send_string() macro on a new keycode, and assign it to _fl define a new keycode (pstoken) and assign it to a key in the _fl layer. assign reset to _fl at the same time. the associated send_string() macro emits a compile time defined string that we populate in rules.mk. this only works on macos, since it shells out to the macos security utility, which securely fetches a string from the specified service name and account. that avoids storing the string in the source code or in the clear anywhere on the filesystem. it also avoids changing any of qmk's makefiles, keeping the change local to my keymap. since the keymap is macos-specific due to left of spacebar key swaps, i figure the makefile changes being a bit macos specific is ok. i plan to document the change, including how to interact with the security utility on macos, on my blog. i would wrap the rules.mk changes in macos-specific ifdefs, but i don't think the qmk makefile system defines any i can easily check against. i also updated the layout readme with the correct make invocation, and the layout comments in keymap.c while i was at it, to tidy up a bit. none. checklist: my code follows the code style of this project. i have read the contributing document. ( ", "commit_messages": " update make command with correct variant  add a custom keycode for a compile-time defined macro and add to _fl ", "linked_issue_titles": "", "title": "add a compile-time provided macro and assign to _fl"}
{"description": " this contains some small changes that resolve some of the pr06 errors from running ./scripts/validate_docstrings.py --errors=pr06 xref #28724 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " fix pr06 docstring errors in interval.py  fix pr06 docstring errors in spss.py  fix pr06 docstring errors in pytables.py  fix pr06 docstring errors in sql.py  fix pr06 docstring errors in multi.py  fix pr06 docstring errors in groupby.py ", "linked_issue_titles": "", "title": "docstring fixes for pr06 errors"}
{"description": " in those cases when kubernetes and netdata are manually installed on bare metal, thecgroup-name.sh script cannot get the names of the containers due to empty variables: $kubernetes_service_host $kubernetes_port_443_tcp_port also missing file /var/run/secrets/kubernetes.io/serviceaccount/token my edits add an alternative opportunity to get the name of the container if no variables are set and kubelet is running on the system and kubectl binary is available. by default, /etc/kubernetes/admin.conf is used to access kubectl, if an error occurs during execution, an entry will be added to the log with the warning level, but if you specify the path in the variable $kube_config, then it will be used your custom config. for example, you can use systemd daemon: environment=kube_config=/etc/netdata/kubernetes.conf component name collectors/cgroups.plugin/cgroup-name.sh.in ", "commit_messages": " ability to get pod name with kubectl in cgroup  added $kube_config variable ", "linked_issue_titles": "", "title": "added ability to get pod name from cgroup with kubectl in bare metal deployment"}
{"description": " completes @thomaswangio 's set up a netlify cms-managed gatsby site in 5 steps article with the missing netlify auth provider setup. ", "commit_messages": " docs: upload screenshot for oauth installation  docs: add auth provider setup section ", "linked_issue_titles": "", "title": "complete blog tutorial with netlify auth setup"}
{"description": " closes #16979 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " add temp tests to explore different combinations  put tests at the end ", "linked_issue_titles": " bug: dataframe.where with category dtype ", "title": "add test for df.where() with int dtype"}
{"description": " in scenarios where the cluster-store configuration is invalid or the store is down during daemon bootup, the get apis in libnetwork were aggressively failing resulting in failing even the local networks and endpoints. there is no reason to be aggressive when the cluster-store is unreachable especially on the get all apis. hence it also helps in solving a bunch of inconsistency issues for the docker0 bridge as well as tracked in moby/libnetwork#651 also solves a part of #17007 . ", "commit_messages": " vendoring in libnetwork to fix daemon bootup instabilities  integration test for default bridge init with invalid cluster config ", "linked_issue_titles": "", "title": "fixing bootup inconsistencies due to invalid cluster-store config"}
{"description": " created a custom keymap for gmmk pro that includes a working volume knob. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " initial commit  add jackkenney keymap  shift around pgup and del ", "linked_issue_titles": "", "title": "jackkenney's keymap for gmmk pro"}
{"description": " hey there! the contribution guidelines say to ask before submitting a pr, but it doesn't say how to ask. i don't have a lot of experience contributing to oss, so please let me know if i missed something. this pr allows for cra to control tabs on other chromium-based browsers besides google chrome. how the code works: checks if applescript is applicable. logic isn't changed, but i renamed the variable to shouldtryopenchromiumwithapplescript. runs through a list of supported browsers: chrome canary (has to come before chrome because of grep) chrome edge brave vivaldi chromium for each browser, it greps to see if that browser is a process if it finds a match, it passes the browser name to the applescript applescript uses the google chrome dictionary to control the provided browser other than that, the logic is essentially the same. most people shouldn't see a difference in behavior except for those using a browser in the list above that's not chrome; for those people, cra will reuse the existing tab rather than a new tab. i noticed that safari has its own dictionary for applescripts. if it benefits anyone, i could look into implementing similar logic for safari users. unfortunately for firefox users like myself, there seems to be no hope. apologies if i left something out, but i tried my best. let me know what needs to be changed, would be proud to have my code in cra. closes #8264 ", "commit_messages": " expands scope of openbrowser tab control  adjust openchrome.applescript to allow manipulation of  other chromium-based browsers (defaulting to chrome).  requires list of compatible browsers to try in openbrowser.js  fix typo  remove safari ", "linked_issue_titles": " support for vivaldi & brave browsers for \"openchrome.applescript\" ", "title": "wider chromium support for openbrowser"}
{"description": " i'm open to better names for the new module. with these all in the same place, we can separate out helper functions and de-duplicate a whole bunch of verbose code. ", "commit_messages": " ref: collect get_dst_info methods in tslibs.vectorized ", "linked_issue_titles": "", "title": "collect get_dst_info-using functions in tslibs.vectorized"}
{"description": " we'd like to see how many of these flakes are transient and how many involve the device/machine getting temporarily wedged. add a retry with no delay to see if it is possible to add sufficient error handling to startapp/installapp to handle this. ", "commit_messages": " [flutter_tools] try to retry app startup to see if reduces flakes ", "linked_issue_titles": "", "title": "retry the driver launch of the application up to 3 times."}
{"description": " backport of #11431 to 0.19.x that removes the deprecation warning about abc being moved from collections to collections.abc when importing scikit-learn in python 3.7. do not merge while the parent pr is not merged. done as part of #11422 ", "commit_messages": " fix collections.abc deprecations with python 3.7  pep8 ", "linked_issue_titles": "", "title": "fix collections.abc deprecations with python 3.7 (0.19.x backport)"}
{"description": " previously, the platform_info table on windows did not include the releasedate field. this fix fills in the date column with an iso8601 version of the releasedate. closes #4771 ", "commit_messages": " adding getdatetime function to convert a bstr wmi date to filetime  populating date field in platform_info; added function to convert filetime to iso8601 date fmt  formatting changes ", "linked_issue_titles": "", "title": "add releasedate to table for platform_info queries on windows"}
{"description": " this should drastically speed up the test and allow us to collect coverage data. locally this takes about 6 seconds from source. the usage section of the flutter create test takes about 14 seconds at head ", "commit_messages": " move usage tests to memory filesystem  fix cirrus ", "linked_issue_titles": "", "title": "move usage flutter create tests into memory filesystem."}
{"description": " fixes #2592 i choose this solution instead of changing require_admin_or_owner in objectpermissionslistresource since that would effect permissions for multiple operations. ", "commit_messages": " pull upstream to my fork  pulling from upstream to sv fork  add error message when non owner tries to add a user to a dashboard  fixes #2592  redash_feature_show_permissions_control has to equal true for this to be applicable.  operation does throw a 403 forbidden error before this change but it is in the console not shown to the user. ", "linked_issue_titles": " a user that is granted permissions to a dashboard cannot grant permissions to others for the dashboard ", "title": "throw error when non-owner tries to add a user to dashboard permissions"}
{"description": " only complete options-name, other case use default complete. because options-value has different type, don't have a standard to complete. use case: ", "commit_messages": " merge master  support windows unicode file path. #571  polish \"support windows unicode file path\" #574  update doc  add known user (#583)  update contributing.md (#584)  use docker build args  fix typo (#582)  update readme.md  editing pass of document: rewords some sentences for clarity, makes formatting consistent in lists, and corrects some grammar and spelling.  update doc. close #587  support inject into java process of windows service (#581)  * add as-service.bat to support inject into java process of windows service  * as.bat support telnet/http port args  avoid blocking while start arthas service (#591)  add known user.  packaging as-service.bat (#595)  fix typo (#604) (#606)  fix completionadaptor index out of bounds when the token is empty.  merge remote-tracking branch 'upstream/master'  options command support complete ", "linked_issue_titles": "", "title": "options command support complete options-name"}
{"description": " this gets rid of lots of unnecessary unsafety. all the atomicu32s were wrapped in unsafecell or unsafecell, and raw pointers were used to get to the atomicu32 inside. this change cleans that up by using atomicu32 directly. also replaces a unsafecell by a safer cell. @rustbot modify labels: +c-cleanup ", "commit_messages": " use slice_as_mut_ptr instead of first_ptr_mut.  this function was renamed.  get rid of unsafecell<maybeuninit>s in cloudabi mutex.  get rid of unsafecell in cloudabi rwlock.  get rid of raw pointers and unsafecell in cloudabi condvar.  formatting. ", "linked_issue_titles": "", "title": "cleanup cloudabi mutexes and condvars"}
{"description": " added a command to manually add a repository given a path to that repository. addresses the request in #46763 to add the ability to manually add repos. this can be done both through the command palette or a button from the git sidebar, as seen below. ", "commit_messages": " feature: add support to manually add repositories ", "linked_issue_titles": "", "title": "add option to manually add repos #46763"}
{"description": " add the labex digicosme logo to the funders list in about.rst @gaelvaroquaux i miss some informations like the period when tom and mathurin have been funded. other than that, is there something else to add ? ", "commit_messages": " first modif  add digicosme ", "linked_issue_titles": "", "title": "add a digicosme entry in about us"}
{"description": " test infrastructure this pr is only tests if relevant, link to documentation update: n/a summary adding some foundational bincases suite for testing bin commands. they will call child_process.exec(), and handler will verify if successfully ran. i am just laying the foundation for the tests. helps make it possible to better cover changes in #3524. from forked branch pr #3643 no other information from forked branch pr #3643 ", "commit_messages": " feat(test): add very simple bincases test infra to build off of  reworked the bincases infra. now arguments.json can hold commands ", "linked_issue_titles": "", "title": "add very simple bincases test infra to build off of [fork]"}
{"description": " others others cherry-pick #29885   #30259 ", "commit_messages": " reduce the  occupied size  of memory for the fused pattern of elementwise_add op and activation op(relu op for example) (#29885)  register opmaker and infer shape check for fused_elementwise_add (#30259) ", "linked_issue_titles": "", "title": "[cherry-pick]memory optimization for fuse pattern of elemwise_add + act"}
{"description": " this pr addresses #588, allowing you to do make warn to see all the compiler warnings printed during compilation of c files (really anything that your compiler sent to stderr, which with gcc is nothing unless you have compiler warnings or errors).  it's implemented by sending all stderr output to another file ending with warnings.txt (still printing these warnings immediately after compilation even if you never run make warn) and then concatenating all these warning files into a single summary file afterwards.  if your code successfully compiles without any warnings (i.e. the warning summary file is empty) you should see make happily print make: nothing to be done 'warn' when make warn is run again; otherwise the warnings will be printed every time make warn is run (but without recompiling). in the second commit, i made lint behave in a similar way, producing a per-file lint report and then concatenating the outputs into a summary lint report.  this way lint runs very fast if you run \"make lint\", change just one source file, and then run \"make lint\" again -- this is because it's only invoked for the changed file rather than again for the entire codebase. ", "commit_messages": " dump compiler warnings to *.warnings.txt; use \"make warn\" to print them  output a lint report for every source file linted; use to lint  incrementally ", "linked_issue_titles": "", "title": "\"make warn\" to print compilation warnings; \"make lint\" runs incrementally"}
{"description": " this pr provides the marlin support for the (hopefully) upcoming usb composite feature (sd card and cdc usb) in the st stm32 library. the stm32 library changes are in pr 586. the changes needed to support the new feature are: add flags to the platformio.ini environments to enable the usb composite feature add a section to sd2card_sdio_stm32duino.cpp so that when the usb composite feature is enabled that the marlin access of the sd card uses the usb drivers. this has been tested on a steval board and a black stm32f407 board. it has been tested on 16g sd cards. my 4g sd card does not work with the sdio interface.  i need to look into that. ", "commit_messages": " add support for composite usb  if composite usb is enabled  then use the composite usb drivers for the onboard sd card.  this is in preparation for usb composite changes to st's stm32 library.  tested on steval board.  platformio.ini changes to support  black stm32f407 ", "linked_issue_titles": "", "title": "add support for composite usb on stm32 sdio boards (experimental)"}
{"description": " \"bech32\" isn't very user-friendly; used \"native segwit\" as in #11937. you don't spend from addresses. no reason to block off bech32 access with legacy address default. rebased from #12208 ", "commit_messages": " gui: rephrase bech32 checkbox text/tooltip  - \"bech32\" isn't very user-friendly  - you don't spend from addresses  gui: allow generating bech32 addresses with a legacy-address default ", "linked_issue_titles": "", "title": "rephrase bech32 checkbox texts, and enable it with legacy address default"}
{"description": " upon further coding proceeds, found another unsquashed macos unavailable nproc. decreases travis build time too! fix last pr that uses the wrong command of phy cores instead of logical cores. ", "commit_messages": " nproc for ubuntu, hw.logicalcpu for mac  physicalcpu to logicalcpu  non-efficient j1 to hw.logicalcpu ", "linked_issue_titles": "", "title": "changes nproc for mac to hw.logicalcpu where applicable"}
{"description": " description: an exception is thrown to the user if a custom resolver name is specified when using strict or logical dns in the address section of the endpoints. risk level: low testing: //test/... docs changes: this is a behavior change in an error condition. would documenting this change in the proto file be sufficient? release notes: n/a fixes #3553 ", "commit_messages": " merge latest master from envoy  merge envoy master  throw exception if custom resolver is specified with strict_dns or logical_dns ", "linked_issue_titles": " prevent the use of custom resolvers for dns discovery types ", "title": "disallow specifying custom resolver name for strict and logical dns"}
{"description": " also changes the signature of advance_slice to accept a &mut &mut [ioslice], not returning anything. this will better match the ioslice::advance function. updates #62726. ", "commit_messages": " rename ioslice(mut)::advance to advance_slice  to make way for a new ioslice(mut)::advance function that advances a  single slice.  also changes the signature to accept a &mut &mut [ioslice], not  returning anything. this will better match the future ioslice::advance  function.  add ioslice(mut)::advance  advance the internal cursor of a single slice. ", "linked_issue_titles": "", "title": "rename ioslice(mut)::advance to advance_slice and add ioslice(mut)::advance"}
{"description": " previously, only theme colors could be modified using the themeeditor. now, metric and path properties can also be modified, and the preview shows these changes. :^) preview: inactive window gets a background color instead of being hollow windows get a shadow if they have one specified in the theme window button icons also reflect the theme setting now editing: metrics can be adjusted paths can be modified, with a file picker or manual text editing loading a theme file now updates the ui to show the current values immediately, instead of only when the comboboxes are interacted with i'll have to come back to this later to add support for flagroles which i added in #10609. ", "commit_messages": " themeeditor: give both preview windows a background color  the inactive window previously didn't have a background fill, so it  looked odd.  libgfx: make style painters use east const and virtual specifiers  libgfx+windowserver: move shadow-painting code to stylepainter  specifically, this is to make it accessible to themeeditor, but there's  nothing about it that is especially window-specific.  themeeditor: display window shadows in preview :^)  themeeditor: convert layout to gml  libgfx: add to_string() functions for metricrole and pathrole  libgui: add metricrole and pathrole to gui::variant  this is needed for making them editable in the themeeditor, like  colorrole is.  themeeditor: add metricrole editing  the editing ui at the bottom is now split into two groups, one for  colors and one for metrics.  themeeditor: update value edit boxes when loading a theme file  previously, these would continue to show the previously entered values,  until you interacted with the comboboxes.  themeeditor: add pathrole editing  this allows both typing the path, and selecting it with a file-open  dialog.  themeeditor: display the theme's window icons in the preview  if the icons could not be loaded, we fall back to the defaults (which  are the bitmaps that were always used before.) ", "linked_issue_titles": "", "title": "make preview more accurate, and allow editing all properties"}
{"description": " closes #8439 before after ", "commit_messages": " fix setting language previously selected  isolate i18n startup  isolate i18n client startup  wait tapi18n language load when changed in admin settings  fix indentation  change behavior of suggested server language on footer of login page ", "linked_issue_titles": "", "title": "loading and setting fixes for i18n and rtl"}
{"description": " fixes #4401 fixes #4293 now next.js 6 is on babel 7, remove conflicting babel deps update next server/cloud function .babelrc config update other deps: cloud functions to 1.x.x etc rm install-deps script as it is no longer used on deployment (firebase does not upload node_modules) make scripts consistent in their wrapping of dirs with \" (escaped double quotes) improve readme to clarify config customization and _app.js as per #4401 ", "commit_messages": " with-firebase-hosting: update next.js 6, readme about customization  * now next.js 6 is on babel 7, remove conflicting babel deps  * update next server/cloud function .babelrc config  * update other deps: cloud functions to 1.x.x etc  * rm install-deps script as it is no longer used on deployment (firebase does not upload node_modules)  * make scripts consistent in their wrapping of dirs with \\\" (escaped double quotes)  with-firebase-hosting: pin next to \"latest\" version ", "linked_issue_titles": " with-firebase-hosting example is not working with next 6  adding _app.js to 'with-firebase-hosting' causes \"cannot find module '@babel/runtime/regenerator'\" ", "title": "update to work with next v6"}
{"description": " related to (and dependent on) elastic/docs#657 this pr increases the use of attributes for ccr references in the documentation.  it also adds a glossary entry for cross cluster replication, follower indices, and leader indices. ", "commit_messages": " [docs] updates ccr hyphenation  [docs] adds ccr-cap attribute ", "linked_issue_titles": "", "title": "replaces ccr terms with attributes"}
{"description": " also don't attempt to predicate instructions that don't have a predicate field. this is used by smo, splatoon 2, and some other games. ", "commit_messages": " gpu/shaders: implemented ssy and sync as a way to modify control flow during shader execution.  ssy sets the target label to jump to when the sync instruction is executed.  gpu/shader: don't predicate instructions that don't have a predicate field (ssy). ", "linked_issue_titles": "", "title": "implemented ssy and sync as a set_target/jump pair."}
{"description": " changed incorrect home page url for allenai from appenai.org to allenai.org typo fix for website i have submitted the spacy contributor agreement. ", "commit_messages": " typo fix for allenai url  changed incorrect home page url for allenai from appenai.org to allenai.org  sign contributor agreement  change date format ", "linked_issue_titles": "", "title": "correct typo for allenai url on homepage"}
{"description": " this fixes two bugs: the prune setting range was set after loading the current value. if users had a prune of (eg) 200, it would get limited to 99 before the range was raised. this is fixed by setting the range first. the prune setting was limited to <= the chainparams' \"assumed blockchain size\". there's no reason for this limit (the ux is the same either way), and there are use cases it breaks (eg, setting a prune size such that it begins pruning at some future point). therefore, i raised it to the max value. this is a daggy fix, so should cleanly merge to both master and 0.18 branches. ", "commit_messages": " gui: options: set the range of pruning size before loading its value  without this, an out-of-default-range value gets limited to the range  gui: options: remove the upper-bound limit from pruning size setting  hypothetically, someone may wish to begin pruning at a future blockchain size, and there's no reason to limit it lower ", "linked_issue_titles": "", "title": "gui: options: initialise prune setting range before loading current value, and remove upper bound limit"}
{"description": " add scorer option to components add registered scorers for all components add scorers registry move all scoring methods outside of components as independent functions and register use the registered scoring methods as defaults in configs and inits additional: the scoring methods no longer have access to the full component, so use settings from cfg as default scorer options to handle settings such as labels, threshold, and positive_label the attribute_ruler scoring method no longer has access to the patterns, so all scoring methods are called bug fix: spancat scoring method is updated to set allow_overlap to score overlapping spans correctly enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " add scorer option to components  add an optional scorer parameter to all pipeline components. if a  scoring function is provided, it overrides the default scoring method  for that component.  add registered scorers for all components  * add scorers registry  * move all scoring methods outside of components as independent  functions and register  * use the registered scoring methods as defaults in configs and inits  additional:  * the scoring methods no longer have access to the full component, so  use settings from cfg as default scorer options to handle settings  such as labels, threshold, and positive_label  * the attribute_ruler scoring method no longer has access to the  patterns, so all scoring methods are called  * bug fix: spancat scoring method is updated to set allow_overlap to  score overlapping spans correctly ", "linked_issue_titles": "", "title": "refactor scoring methods to use registered functions"}
{"description": " this pr mutes multiple tests on windows. it does this aggressively to be able to have these passing and make sure we don't cause further breakage on windows. these were found on a local ci setup running with ./gradlew.bat --continue ", "commit_messages": " mute failing test  tracked in #44552  mute evilsecuritytests  tracking in #44558  fix line endings in esjsonlayouttests  mute failing forecastit  test on windows  tracking in #44609  mute autofollowit.testconflictingpatterns  tracking in #44610  mute basicrenormalizationit.testdefaultrenormalization  tracked in #44613  revert \"mute autofollowit.testconflictingpatterns\"  this reverts commit 012de08f59a26c2216297ffea1589c55d5b6ddc9.  mute x-pack internal cluster test windows  tracking #44610  mute failure unconfigured node name  fix mute testdefaultrenormalization  increase busywait timeout windows is slow  mute jvmergonomicstests on windows  tracking #44669  mute sharedclustersnapshotrestoreit testparallelrestoreoperationsfromsinglesnapshot  tracking #44671  mute nodetests on windows  tracking #44256 ", "linked_issue_titles": "", "title": "mute multiple tests on windows (master)"}
{"description": " as discussed here. share the \"added\" and \"removed\" events across dispatches in object3d to cut down on allocation when adding and removing objects a lot. the pattern works in this case because no fields are changed on the object between dispatches -- i wonder if there's a way to extend this to cases where event data must change? ", "commit_messages": " share event objects  # conflicts:  #\tsrc/core/object3d.js ", "linked_issue_titles": "", "title": "reuse \"added\" and \"removed\" event"}
{"description": " enable extra keys to support media keys that are placed on default keymaps. mentioned on boardsource discord. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " extra keys for technik ortho  extra keys for technik staggered ", "linked_issue_titles": "", "title": "enable extra keys for technik ortho and stagger"}
{"description": " control module updates in a very high rate. a formula is calculated in every frame, whose variables are never changed. so, use a variable to store the result of this formula. after testing on tx2, this could reduce the cpu usage of control by 3%-5%. ", "commit_messages": " use a varialbe to store the result of formula to avoid calculating repeatedly  fix code style issues ", "linked_issue_titles": "", "title": "use a variable to store result of formula to avoid calculating repeatedly"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration provide a url to documentation or source code which provides context for the suggested changes: < ", "commit_messages": " add fetch to coins in coingecko-api types ", "linked_issue_titles": "", "title": "add coins fetch funcion types"}
{"description": " follow-up to #38697. see available checks at  i also tried: modernize-deprecated-headers but it breaks the codebase, as we use some code like is_inf, and clang on my distro can't even find cstdint by default. modernize-raw-string-literal is nice, but it breaks our logic to extract strings with ttr(), so editor/translations/extract.py would have to be fixed (and the raw string would have to be re-escaped in python before outputting the pot file for gettext). there's a few more that we may want to evaluate: ", "commit_messages": " modernize remaining uses of 0/null instead of nullptr (c++11)  using clang-tidy's modernize-use-nullptr.    enforce use of bool literals instead of integers  using clang-tidy's modernize-use-bool-literals.   ", "linked_issue_titles": "", "title": "apply some modernize-* checks from clang-tidy (nullptr, bool literals, void args)"}
{"description": " python sample for #16662 i agree to contribute to the project under opencv (bsd) license. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work force_builders_only=docs ", "commit_messages": " add text recognition sample  fix pylint warning ", "linked_issue_titles": "", "title": "add text python recognition sample"}
{"description": " reverts #38424, and re-applies the non-double-bracket-changes-etcetera ", "commit_messages": " revert \"bash scripts; use double brackets, fix bare variables, add quotes\"  this reverts commit 297b30df5ff4deaaedb6ceb17d7bd2e306a580ab.  shell scripts: fix bare variables  this makes my ide a bit more silent :-) ", "linked_issue_titles": "", "title": "remove bashisms and fix bare variables"}
{"description": " the pr removes the following languages from the docs - fr, de, ja, es, ru. the community has not been able to translate them enough. they are up to date, but in english, so not really helpful. they are also the ones with the less usage. i recommend review per commit. i've also added redirects for the languages that are removed, let me know if i should revert this change. todo: revert bdad428 ", "commit_messages": " [docs] remove translation files for fr, de, ja, es, ru  [docs] remove languages from constants  [docs] add redirects for the removed languages ", "linked_issue_titles": "", "title": "remove languages: fr, de, ja, es, ru"}
{"description": " follow up to #17538 fixes all lint errors in js/shaders. i'll run --fix on the other files in the next pr. ", "commit_messages": " fxaashader spaces to tabs  indent updates  volumeshader indents  volumeshader single quotes to double quotes  oceanshader single quotes to double quotes  water refraction shader single quotes to double quotes  single quotes to double quotes  eslint --fix  indents fix to halftoneshader  jsm updaets ", "linked_issue_titles": "", "title": "lint example shaders pr 4"}
{"description": " it is used to generate a all-in-one report file after all the visual test run. usage: npm run test:visual:report it will generate a tmp-report.md file in the test/runtest folder. then you can translate this markdown file to any file you want. like pdf. q: why not integrating it in the dashboard? it has a lot of work(mostly ui) to be integrated. but the most wanted feature is to generate a file which can be shared and achieved for the regression testing before releasing. so i think a cli tool is good enough for this feature. maybe later i can add a button on the dashboard to download the generated markdown report file. ", "commit_messages": " test: add report generation script for visual regression testing  test(visual): optimize generated report ", "linked_issue_titles": "", "title": "add a cli script to generate visual test report markdown."}
{"description": " kubectl currently ignores the local port when creating a port-forward to a service. this pr fixes this and adds unit tests for preventing this behaviour in the future. fixes kubernetes/kubectl#836 builds on #88950 with review comment #88950 (comment) addressed does this pr introduce a user-facing change?: fixes v1.18.0-rc.1 regression in kubectl port-forward when specifying a local and remote port /sig cli /milestone v1.18 /priority important-soon / ", "commit_messages": " fix kubectl port-forward for services with explicit local port  simplify dual or single port logic ", "linked_issue_titles": " kubectl port-forward for service with explicit local port broken in v1.18.0-beta.1 ", "title": "fix kubectl explicit local port for service"}
{"description": " reference to stream changes of braintree search api: ", "commit_messages": " [braintree] change search function to use streams  prettier formatting  [braintree] modify tests to reflect the new types  update version in the comments ", "linked_issue_titles": "", "title": "fix search api to be a stream instead of a promise"}
{"description": " i hereby agree to the terms of the cla available at: ", "commit_messages": " update of english version of descriprion of the table function file.  new syntax for replacingmergetree.  some improvements in text.  significantly change article about summingmergetree.  article is restructured, text is changed in many places of the document. new syntax for table creation is described.  descriptions of aggregatefunction and aggregatingmergetree are updated. russian version.  new syntax for new syntax of create table  added english docs on aggregating, replacing and summingmergetree.  collapsingmergetree docs. english version.  1. update of collapsingmergetree. 2. minor changes in markup ", "linked_issue_titles": "", "title": "updates for aggregating-,collapsing-, replacing- and summingmergetree."}
{"description": " related to #39517 this pr enables code snippet testing for the api key examples. it also clarifies that the role_descriptors array is required but can be empty. finally, it wraps some long lines and adds some minor edits. ", "commit_messages": " [docs] adds testing to api key examples  [docs] adds testing for api keys ", "linked_issue_titles": "", "title": "enable testing for api key examples"}
{"description": " no functional changes. ", "commit_messages": " shared/install: use _cleanup_free_  also rewrap some comments so that they don't have a very long line and a very  short line.  tree-wide: use mfree more  tree-wide: introduce free_and_replace helper  it's a common pattern, so add a helper for it. a macro is necessary  because a function that takes a pointer to a pointer would be type specific,  similarly to cleanup functions. seems better to use a macro. ", "linked_issue_titles": "", "title": "use mfree more and add another function to simplify a common set&free pattern"}
{"description": " closes #24014 xref #10633 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry before this change, when the series.interpolate() method was called with invalid arguments,  exceptions with informative messages would be raised internally, but then caught and suppressed.  an exception with a potentially misleading message would be raised instead. for example, when interpolate is called with method='spline', an order argument must also be supplied.  this is checked internally, but when the order argument was missing, a confusing error would be raised: >>> import pandas as pd >>> s = pd.series([0, 1, pd.np.nan, 3, 4]) >>> s.interpolate(method='spline') traceback (most recent call last): ... valueerror: invalid method 'spline' to interpolate. this problem was reported as issues #10633 and #24014. after this change, a specific and correct exception (previously caught and discarded internally) is raised: >>> import pandas as pd >>> s = pd.series([0, 1, pd.np.nan, 3, 4]) >>> s.interpolate(method='spline') ... valueerror: you must specify the order of the spline or polynomial. in addition, light validation is now performed on the order parameter before it is passed to a scipy class.  previously, pandas would check if order was truthy in the python sense.  if order was non-zero and invalid, a scipy error would propagate to the user: >>> s.interpolate(method='spline', order=-1) traceback (most recent call last): ... dfitpack.error: (1<=k && k<=5) failed for 3rd argument k: fpcurf0:k=-1 after this change, a more understandable exception is raised in this case: >>> s.interpolate(method='spline', order=-1) traceback (most recent call last): ... valueerror: order needs to be specified and greater than 0 ", "commit_messages": " bug: raise accurate exception from series.interpolate (#24014)  actually validate order before use in spline ", "linked_issue_titles": " unnecessary bare except at class block, function interpolate hides actual error ", "title": "fix exceptions when series.interpolate's order parameter is missing or invalid"}
{"description": " this is what i managed to get done this morning. there's some very real issues fixed in this branch plus a bit of readability. unfortunately i haven't managed to figure out how to tell it to ignore memory leaks in case of oom so it's not the nicest thing to drudge through the issues to find the real ones. ", "commit_messages": " merge: actually increment the counts, not the pointers  merge_diff_list_count_candidates() takes pointers to the source and  target counts, but when it comes time to increase them, we're increasing  the pointer, rather than the value it's pointing to.  dereference the value to increase.  pack: use git_buf when building the index name  the way we currently do it depends on the subtlety of strlen vs sizeof  and the fact that .pack is one longer than .idx. let's use a git_buf so  we can express the manipulation we want much more clearly.  object: correct the expected id size in prefix lookup  we take in a possibly partial id by taking a length and working off of  that to figure out whether to just look up the object or ask the  backends for a prefix lookup.  unfortunately we've been checking the size against git_oid_hexsz which  is the size of a *string* containing a full id, whereas we need to check  against the size we can have when it's a 20-byte array.  change the checks and comment to use git_oid_rawsz which is the  correct size of a git_oid to have when full.  filter: close the descriptor in case of error  when we hit an error writing to the next stream from a file, we jump to  'done' which currently skips over closing the file descriptor.  make sure to close the descriptor if it has been set to a valid value. ", "linked_issue_titles": "", "title": "a few more fixes from coverity"}
{"description": " this is a hefty patch that takes some first steps towards solidifying our core comms mechanism. highlights include: introduce a @controller.handler decorator that automatically replys() to messages introduce a reply.take() method to take control of a message and prevent automatic reply. this makes the default use case the easy one, and lets us explicitly audit the codebase for places where extra care must be take to ensure that a message is eventually acked. handers are no longer named handle_message. the decorator makes clear what is a handler, so it's just \"message\" now. add an explicit list of permitted messages. this clarifies our mechanisms, and will be the start of better message documentation and more sophisticated handling mechanisms down the track. add a bunch of sanity checks for messages that are acked twice, or never, or are given invalid arguments. use this to catch numerous occurrences throughout the codebase. simplify the class hierarchy in controller by merging master and servermaster. ", "commit_messages": " sketch out a more solid core  - decorator for handler methods  - stricter checking for double-acks and non-acks  mandate that all handlers must be wrapped, make tests pass  mitmproxy, mitmdump and mitmweb masters still to be done  sketch out a more solid core  - decorator for handler methods  - stricter checking for double-acks and non-acks  mandate that all handlers must be wrapped, make tests pass  mitmproxy, mitmdump and mitmweb masters still to be done  make @controller.handler inheritance-friendly  use this to adapt mitmweb and mitproxy console  zap stray debugging call  be stricter about the handler call signature  uses this to catch an error in mitmweb  flatten servermaster into master  explicitly list all events  handle_* -> *  now that we have the controller.handler decorator, the _handler prefix  stutters.  adapt examples ", "linked_issue_titles": "", "title": "first steps to solidifying the core"}
{"description": " it updates vaultingkube version and add labels to metadata following other projects. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # i think test will fail, you can check the initial chart pr for more information. #3902 ", "commit_messages": " add labels to metadata  bump app and chart versions ", "linked_issue_titles": "", "title": "update vaultingkube version and add lables to metadata"}
{"description": " fixes #17535 description of the change prior to this pull request, if a paneitem implemented the ondiddestroy function and the ondidterminatependingstate function, then the pane would make use of both functions. however, if paneitem implemented an ondidterminatependingstate function but did not implement an ondiddestroy function, the pane wrongly ignored the ondidterminatependingstate function. with the changes in this pull request, the ondidterminatependingstate function and ondiddestroy functions are treated independently: if the item only implements ondidterminatependingstate, that's fine: pane will use it if the item only implements ondiddestroy, that's fine, too: pane will use it if the item implements both functions, pane will use both functions if the item implements neither function, that's fine as well verification process verify correct behavior for paneitem that implements ondidterminatependingstate but not ondiddestroy (i.e., perform the \"steps to reproduce\" identified in #17535) implement a new paneitem with an opener. implement ondidterminatependingstate but not ondiddestroy code const {emitter} = require('atom') class somepaneitem { constructor () { this.emitter = new emitter() } getelement () { return document.createelement('div') } terminatependingstate () { this.emitter.emit('did-terminate-pending-state') } ondidterminatependingstate (callback) { return this.emitter.on('did-terminate-pending-state', callback) } gettitle () { return 'some-pane-item' } geturi () { return 'atom://some-pane-item' } } open it as a pending item with a call to atom.workspace.open(item, {pending: true}) double-click on the tab title verify that the item terminates its pending state and becomes a non-pending item verify correct behavior for paneitem that implements ondiddestroy but not ondidterminatependingstate implement a new paneitem with an opener. implement ondiddestroy but not ondidterminatependingstate code const {emitter} = require('atom') class somepaneitem { constructor () { this.emitter = new emitter() } getelement () { return document.createelement('div') } destroy () { this.emitter.emit('did-destroy') } ondiddestroy (callback) { return this.emitter.on('did-destroy', callback) } gettitle () { return 'some-pane-item' } geturi () { return 'atom://some-pane-item' } } call ondiddestroy to register a callback code item.ondiddestroy(() => console.log('destroyed')) open the item with a call to atom.workspace.open(item) destroy the item with a call to item.destroy() verify that the callback is invoked and that the pane item is removed from the workspace ", "commit_messages": " add failing test to demonstrate the bug identified in #17535  fix #17535  treat ondidterminatependingstate and ondiddestroy as independent  optional functions that a paneitem can implement. a paneitem is free to  implement neither, just one of them, or both of them. ", "linked_issue_titles": "", "title": "teach pane to always look for a pane item's ondidterminatependingstate function"}
{"description": " use stringtopdfstring to sanitizing bad \"prefix\" entries in page label dictionaries it seems that certain bad pdf generators can create badly encoded \"prefix\" entries for page labels, one example being  unfortunately i didn't come across such a pdf file while adding the api support for page labels, but with them now being used in the viewer i just found this issue. with this patch, we now display the page labels in the same way as adobe reader. add a bit more validation to catalog_readpagelabels, to ensure that the page labels are well formed ", "commit_messages": " use stringtopdfstring to sanitizing bad \"prefix\" entries in page label dictionaries  it seems that certain bad pdf generators can create badly encoded \"prefix\" entries for page labels, one example being  unfortunately i didn't come across such a pdf file while adding the api support for page labels, but with them now being used in the viewer i just found this issue. with this patch, we now display the page labels in the same way as adobe reader.  add a bit more validation to catalog_readpagelabels, to ensure that the page labels are well formed ", "linked_issue_titles": "", "title": "use stringtopdfstring to sanitizing bad \"prefix\" entries in page label dictionaries, and add more validation"}
{"description": " closes #35719 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " tst: add tests for to_hdf with dropna arg  bug: add missing val handling to hdfstore.put  doc: add whatsnew ", "linked_issue_titles": " regr: pd.to_hdf(dropna=true) not dropping all nan rows ", "title": "pd.to_hdf(..., dropna=true) not dropping missing rows"}
{"description": " travis ci is a free hosted continuous integration platform for open-source projects.  it allows automated testing for github-hosted projects.  i've enabled its use in my (to be obsoleted) fork. after adding the configuration and the additionally required fix, the current master branch build successfully on 64-bit clang and gcc, see ", "commit_messages": " prepare for travis-ci.org continuous integration  travis ci is a free hosted continuous integration platform for  open-source projects.  it allows automated testing for github-hosted  projects.  this commit adds a corresponding .travis.yml configuration file.  document.h: define __stdc_constant_macros  the c++ standard does not include the c99 macros used to set the (u)int64  constants in document.h and reader.h (see adf66292 and ce1fece2).  many implementations include their definition when the  __stdc_constant_macros preprocessor symbol is defined.  see e.g.  needed to successfully build in travis-ci.org's environment. ", "linked_issue_titles": "", "title": "prepare travis-ci.org integration, fix build on ubuntu 12.04 lts"}
{"description": " the current isnumeric() function checks if the value is not nan, infinity nor -infinity. this function is only used in one file it has unclear name (infinity and -infinity are usually considered number) it can be easily replaced with native function number.isfinite() number.isfinite(infinity);  // false number.isfinite(nan);       // false number.isfinite(-infinity); // false number.isfinite(0);         // true number.isfinite(2e64);      // true number.isfinite('0');       // false, would've been true with // global isfinite('0') number.isfinite(null);      // false, would've been true with // global isfinite(null) @graceguo-supercat @williaster @conglei @michellethomas ", "commit_messages": " remove isnumeric util function and use lodash isfinite instead  use native number.isfinite ", "linked_issue_titles": "", "title": "remove isnumeric util function and use number.isfinite instead"}
{"description": " commit log handwired/reddot: refactor (2fd51a1) reddot.h updated to use #pragma once include guard renamed layout macro keymap to layout refactored arguments to more closely resemble physical layout aligned for readability keymaps/default/keymap.c now uses #include qmk_keyboard_h updated include path for keymap_french.h refactored to use short keycodes aligned for readability handwired/reddot: configurator support (c9f8bee) handwired/reddot: readme update (58f9907) update readme to current qmk template add kle permalink to my best guess at the layout notes arranged the layout based on information in this reddit thread. ", "commit_messages": " handwired/reddot: refactor  - reddot.h  - updated to use #pragma once include guard  - renamed layout macro keymap to layout  - refactored arguments to more closely resemble physical layout  - aligned for readability  - keymaps/default/keymap.c  - now uses #include qmk_keyboard_h  - updated include path for keymap_french.h  - refactored to use short keycodes  - aligned for readability  handwired/reddot: configurator support  handwired/reddot: readme update  - update readme to current qmk template  - add kle permalink to my best guess at the layout ", "linked_issue_titles": "", "title": "handwired/reddot refactor, configurator support and readme update"}
{"description": " add the most basic fastapi support, passing the following test. def test_fastapi_function(serve_instance): client = serve_instance app = fastapi() @serve.deployment(app) @app.get(\"/{a}\") def func(a: int): return {\"result\": a} client.deploy(\"f\", func) resp = requests.get(f\" assert resp.json() == {\"result\": 100} resp = requests.get(f\" assert resp.status_code == 422  # unprocessable entity assert resp.json()[\"detail\"][0][\"type\"] == \"type_error.integer\" i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " [wip] fastapi support in ray serve  lint ", "linked_issue_titles": "", "title": "add initial support for fastapi"}
{"description": " fixes #7299 fixes #7300 ", "commit_messages": " fixes #7300, display docsurl as line or content  fixes #7299 display typescript sourcemaps correctly  - adds typescript e2e tests ", "linked_issue_titles": " display typescript sourcemaps when using default browserify plugin  display \"learn more\" docsurl link in interactive mode, otherwise display docsurl as content ", "title": "display typescript sourcemaps, display docsurl conditionally"}
{"description": " what's in this pull request? more colors in -dump-ast and -dump-parse. when using swift -dump-ast, the astdumper currently produces the following: as you can see, the output is nearly 100% white text. these commits add significantly more color, making it easy to see the distinct elements of the ast: these same benefits apply to -dump-parse. here's the before and after: what's not in this pull request? 100% colorization and test coverage. the screenshots above still contain some white text. these represent parts of astdumper that i haven't modified in this pull request. why? well, the pull request is already large, and i figured i should get some feedback before making it larger. in addition, this pull request doesn't contain test coverage. i do intend on adding test coverage for -color-diagnostics, but that'd take some additional work. i'd prefer to get some feedback on the current color scheme, then add regression tests in a subsequent pull request. should this be merged as-is? i think so. this is a big improvement to -dump-parse and -dump-ast. it could be an ever bigger improvement, it could use a more elegant abstraction than printwithcolorraii, it could have regression tests... but i think those can all come in a future pull request. ", "commit_messages": " [astdumper] more colors, compat with print methods  * the clang ast dumper uses a wide variety of colors, including bold  fonts. use a similar scheme in the swift ast dumper, by introducing a  terminalcolor struct that encompasses both a color and whether it  is bold.  * currently the only color swift's astdumper uses is red, for patterns.  add a wider variety of colors, for various purposes. if maintainers  decide to change the color scheme of the output ast, they need only  to modify the color macros.  * many ast methods take an output stream as an argument. when using  printwithcolorraii, these methods could not be used. add a getos()  method to printwithcolorraii, in order to support these methods.  [astdumper] print colors for expr  begin using colors when printing expr. also, move accesssemantics  overload from the output stream << operator to the printwithcolorraii  operator.  [astdumper] use color when printing patterns  print patterns using color, when available.  [astdumper] use color when printing decl  print decl using color, when available.  [astdumper] use color when printing ast nodes  print ast nodes using color, when available.  [astdumper] use color when printing parameters  print parameters using color, when available.  [astdumper] use color when printing stmt  print stmt using color, when available.  [astdumper] use color when printing identifiers  print identifiers using color, when available.  [astdumper] use color when printing typerepr  print typerepr using color, when available.  [astdumper] use color when printing protocols  print protocols using color, when available. also, color many more  parentheses. ", "linked_issue_titles": "", "title": "improve colorization of parse and ast dumps"}
{"description": " move the deferred limit to the producer plugin which now controls it route all new blocks through producer so it can maintain invariant that there is always a pending block (whether for speculative execution or future signing) re-apply unapplied transactions and apply deferred transactions on a new block (note: this needs proper throttling once subjective failures are handled correctly inside controller). remove spurious calls to start_block in other plugins fixed producer plugin and changed some logic to respect the notion that we \"called our shot\" in start_block and should no longer be concerned with other time slots ", "commit_messages": " move the deferred limit to the producer plugin which now controls it; route all new blocks through producer so it can maintain invariant that there is always a pending block (whether for speculative execution or future signing); re-apply unapplied transactions and apply deferred transactions on a new block (note: this needs proper throttling once subjective failures are handled correctly inside controller).  remove spurious calls to start_block in other plugins  fixed producer plugin and changed some logic to respect the notion that we \"called our shot\" in start_block and should no longer be concerned with other time slots ", "linked_issue_titles": "", "title": "route all pushes through producer"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> add it to notneededpackages.json. ", "commit_messages": " added files  daily update  added comments  moved directory  passed the dt linter  more linter updates  reverted files  merge  removed redundant dir  changed const enum to enum to fix linter ", "linked_issue_titles": "", "title": "added dsb banking and common type definitions"}
{"description": " update pwm code to the latest version of esp8266/arduino#7231 main benefits: ram: -148 bytes flash: -188 bytes iram: -120 bytes the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.0 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " change pwm updated to the latest version of arduino pr #7231  change pwm updated to the latest version of arduino pr #7231 ", "linked_issue_titles": "", "title": "update to latest pwm version of arduino #7231"}
{"description": " adds a url-tvg attribute with a guide from iptv-org/epg if available. languages/bul.m3u #extm3u url-tvg=\" ... the attribute can contain multiple guides separated by commas. categories/classic.m3u #extm3u url-tvg=\" ... update: the changelog is empty due to an error that occurred while updating the playlist. the full list of changed files can be found here: ", "commit_messages": " update playlist.js  install axios package  create epg.js  update db.js  update format.js  update channel.js  update db.js  update generate.js ", "linked_issue_titles": "", "title": "add url-tvg attribute to playlists"}
{"description": " the functionality provided by #11011 already exists natively in the surefire/failsafe plugins by setting the -dmaven.surefire.debug flag. remove redundant maven profile. also upgrade the surefire/failsafe versions, so they cope better when tests prints to stdout. less stuff in our pom.xml file, and better console output when our tests are printing stuff. ", "commit_messages": " revert \"add a profile for debugging tests that run from maven (#11011)\"  this reverts commit 83895f0f  the same functionality is already natively available in surefire, by adding the -dmaven.surefire.debug flag to maven.  update surefire/failsafe version  these new versions copes better when our tests prints to stdout, and disturbs the progress processing that these plugins do. ", "linked_issue_titles": "", "title": "revert test debugging flags and update surefire/failsafe"}
{"description": " i removed the macro definitions that are no longer needed as keymap_grid is now in the file keymap_common.h. i also fixed an error in the documentation. i added comments showing a blank layout (with ascii art, similar to those found in the other keyboard projects under tmk_keyboard) for each of the supported formats. ", "commit_messages": " kc_insert should be kc_ins  the short name was incorrectly set as kc_int when we want kc_ins.  merge remote-tracking branch 'upstream/master'  delete .keymap_nathan.c.swp  update keymap_nathan.c  remove macro for keymap_grid that is in keymap_common.h.  add comments with ascii art for the two layouts in keymap_common.h. ", "linked_issue_titles": "", "title": "housekeeping on keymap_nathan.c, updated documentation"}
{"description": " it seems that nintendo finally filled that last empty spot in applicationlanguage for a total of 16 supported languages. should fix pt-br language support in mario party superstars ", "commit_messages": " ns: language: add brazilianportuguese to applicationlanguage  it seems that nintendo finally filled that last empty spot in applicationlanguage for a total of 16 supported languages.  file_sys: control_metadata: add brazilianportuguese ", "linked_issue_titles": "", "title": "add brazilian portuguese to the list of applicationlanguage"}
{"description": " this is the pr we discussed in #413 for colortool. there are two bugfixes in this pr (the final two commits). the first two commits are the refactoring. 7daea0a - first refactoring commit, pulls logic out of program.cs and into other files. 05f518d - second refactoring commit, gets rid of mutable fields and mutable statics. b61cb83 - only run the required parser for the colorscheme file. before, all parsers could be run for a single colorscheme file, so we could get error output even if everything imported correctly. 12fff31 - allow the writing of screen/popup background/foreground indices to the registry. before this only worked for the currently running console, now it will save for all consoles. this pr modifies a lot of files, but i've isolated the bulk of the changes in the first commits, so there are no user-facing changes in those commits. ", "commit_messages": " pull logic out of program.cs  there aren't any user-facing changes in this commit, just pulling logic out of program.cs. all that remains in program.cs is command line parsing.  - the functions that wrote to the registry, the console, and the virtual terminal (--xterm) are now in their own files, implementing the iconsoletarget interface  - move the utility method uinttocolor into colorscheme, where it can be used as an indexer, e.g. mycolorscheme[i] returns a system.drawing.color  - the \"export to ini\" functionality is now in a \"schemewriters\" namespace; parsers are now in a \"schemeparsers\" namespace  - printing the color table is now in the colortable class.  replace mutable public fields with properties  the properties are made readonly where possible, which is possible in almost all cases.  allow scheme parsers to opt out of attempting to parse a file  this fixes the issue where the ini file parser can throw errors because it's attempting to parse an .itermcolors (xml) file.  add support for writing foreground / background indices to registry  this functionality was implemented for the \"current console\" but was never implemented for writing to the registry, which affects all future consoles. ", "linked_issue_titles": "", "title": "fix colortool parser and registry bugs, and refactor"}
{"description": " added support for the hid liberation device, a replacement controller for filco majestouch tlk keyboards. added a default ansi keymap as well as a lightly customized layout. ", "commit_messages": " keyboard: added support for hid liberation device  keymap: custom (bakageta) layout for hid liberation device ", "linked_issue_titles": "", "title": "add support for bpiphany's hid liberation device"}
{"description": " added implementation for existing dcompact layout to levinson keyboard dir fixed readme typos for dcompact layouts my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " fix whitespace and markdown errors  add dcompact layout implementation for levinson keyboard ", "linked_issue_titles": "", "title": "dcompact layout updates pt. 3"}
{"description": " free book about operating systems. i've read some chapters of this book when i was taking an operating systems class at college. it helped me to learn the fundamentals and some advance topics as well. so i think anyone can benefit from it. it's very well written and has nice illustrations as well. it's under creative commons attribution-noncommercial-sharealike 3.0 unported license, as we can see in the author's official page. yes, it's a book. not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " add index entry for agnostic operating systems topic  add maziero's operating systems book  add under construction indicator  this book is an on going work, it's publish under that link, but things  are changed from time to time in it. ", "linked_issue_titles": "", "title": "add maziero's operating systems book in new index entry for agnostics resources"}
{"description": " the matrix noah board definition doesn't support a 6.25u space bottom row with layout_iso. added a layout_iso_uk that supports it and a personal map that uses that layout. added a new layout to support iso builds with a 6.25u bottom row. not sure if layout_iso_uk is the right name for it, let me know if not (probably isn't but i wasn't sure if layout_iso_625u or similar was better either). tested on my personal build. n/a. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " 6.25u bottom row iso layout for matrix noah  personal map for matrix noah using new 6.25u bottom row iso ", "linked_issue_titles": "", "title": "matrix noah 6.25u bottom row plus personal keymap using it"}
{"description": " as already mentioned in the other pr we have some osx users which have studio audio equipment which has more then the currently supported 24 channels. it seems common for those audio devices to present all its output channels in one single stream which means ca pulls frames with all the  < numberofchannels > in the render callback. also as far as i can tell all those devices use interleaved audio. the latter makes it really cumbersome to do the padding on my own and atm i don't have any time to even try it. this change here fixes the problem for now and doesn't harm any other implementation. (it just allows for channelmaps with up to 64 unknown channels - so the engine takes care of crafting those huge frames for us...). this also fixes trac ticket ", "commit_messages": " [ae] - extend the number of unknown channels from 16 to 64  [ae/ca/osx] - fillup the stream with up to 64 unknown channels fixes support for studio audio devices with more then 16 unused/unknown channels in one stream - fixes #15874 ", "linked_issue_titles": "", "title": "support devices with up to 72 channels (64 unknown + 8 mapped)"}
{"description": " check vainitialize return value in interop and fix related memleak return value must be checked or vaapi will segfault in vacreatesurfaces if init failed e.g. due to missing driver bug fix (non-breaking change which fixes an issue) improvement (non-breaking change which improves existing functionality) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document ", "commit_messages": " fix crash when vaapi cannot be initialized  fix memory leak when vaapi cannot be initialized ", "linked_issue_titles": "", "title": "fix crash when vaapi is not available at runtime"}
{"description": " typically, every libgdx html project has to tweak around with index.html to prevent browser's default behaviour on certain key presses (f1, alt, space, arrow keys and stuff). we already have setcatchkey to prevent system or background app behaviour on key presses, but this is only implemented on android so far. this pr adds the ability to use the setcatchkey methods to prevent browser default behaviour on gwt. additionally, this changes keyforcode from private static to protected. since we now can override the input processing class, it makes sense to have this method overridable as well. ", "commit_messages": " gwt input make keyforcode overridable, use setcatchkey to prevent browser's default behaviour  improve setcatchkey javadoc ", "linked_issue_titles": "", "title": "gwt use setcatchkey to prevent browser's default behaviour"}
{"description": " backport for #16989 copied from original pr: we struggled to investigate flink-23611 due to missing flink logs. it appears that something went wrong with the flink cluster. the stop signal wasn't retrieved by the yarn session cluster thread for some reason which made the test wait forever for the thread to finish. the tests are executed on azureci through tools/ci/test_controller.sh which implements a watchdog mechanism that checks the logs (stdout and mvn-*.log) for new content and kills the test if there's no output for a given amount of time (900s). yarn does produce regular logs, though, through the org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice logger. these log messages are generated every 10 minutes: 22:51:31,785 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 22:51:32,398 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0 hence, the test is not killed while waiting for the yarn cluster to finish. the flink logs, as a consequence, are not copied over from the yarn application folder into the build artifact folder as part of the tools/ci/test_controller.sh execution. hotfix: fixes bug in path creation hotfix: improves local log4j configuration for yarn tests disables info logs for org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice in ci log4j configuration dependencies (does it add or upgrade a dependency): no the public api, i.e., is any changed class annotated with @public(evolving): no the serializers: no the runtime per-record code paths (performance sensitive): no anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn, zookeeper: no the s3 file system connector: no does this pull request introduce a new feature? no if yes, how is the feature documented? not applicable ", "commit_messages": " [hotfix][yarn-tests] fixes path definition for local yarn-test working directory artifact collection  [hotfix][yarn-tests] replaces runtime by timestamp  the intend is to improve local debugging matching log events in different log  files (yarn, flink) via the timestamp.  [flink-23611][yarn-tests] disables info log messages coming from yarn's resourcelocalizationservice  we observed regular info log messages being produced by resourcelocalizationservice after the test ran into a timeout:    22:51:31,785 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0  22:51:32,398 [asyncdispatcher event handler] info  org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.resourcelocalizationservice [] - cache size before clean: 0, total deleted: 0, public deleted: 0, private deleted: 0    these log messages appeared every 10 minutes which prevented the ci/tools/test_controller.sh's watchdog mechanism to  kick in. the watchdog mechanism relies on no output being produced for a given amount of time. this way, the  test_controller script was unable to archive the yarn flink log. ", "linked_issue_titles": "", "title": "disables log message to enable watchdog functionality"}
{"description": " the adder node can now add float vectors of different lengths by trimming them to the same dimensionality. we can change this behavior in the future, or introduce different nodes (like a \"mix\" node) that address differing vector lengths in different ways. ", "commit_messages": " introduce dimensions to expression  rename to setexpressionforslot and add redcomponent function  add expression helpers to aid with differing data widths  add float2constantnode  single-line functions when possible ", "linked_issue_titles": "", "title": "introduce handling for varying dimensionality"}
{"description": " following are the changes - python implementation - coin_change.py with proper comments cpp code fix - order of table filling was not correct, fixed it and commented the code. cpp code fix 2 - order of top-down memoization is not correct - removed it for now. ", "commit_messages": " addition of python implementation and cpp code fix. ", "linked_issue_titles": "", "title": "python implementation of coin_change and cpp code fix"}
{"description": " description: as discussed with @martinhjelmare in #30309 the def device_state_attributes(self): can be removed, as brightness is already an attribute of light. related pr: #30309 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io n/a the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. n/a new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. n/a untested files have been added to .coveragerc. n/a if the code does not interact with devices: tests have been added to verify that the new code works. n/a ", "commit_messages": " remove unnecessary property def  remove unnecessary property def ", "linked_issue_titles": "", "title": "remove unnessecary rfxtrx light property def"}
{"description": " description: fixes xiaomi power strip v1 support fixes chuangmi plug v3 support (syssi/xiaomiplug#11) fixes air conditioning partner (syssi/xiaomi_airconditioningcompanion#21) related issue (if applicable): fixes #13749 ", "commit_messages": " bump python-miio version  fix xiaomi power strip v1 support (closes: #13749) ", "linked_issue_titles": " xiaomi qmi.powerstrip.v1 gives error ", "title": "bump python-miio version (closes: #13749)"}
{"description": " closes  we could only use json and javascript to configure cypress after we can use typescript additionally to js and json i also added cypress.config.ts as a detected default config file ", "commit_messages": " feat: allow to use typescritpt in the config file  add end to end test ", "linked_issue_titles": "", "title": "allow to use typescript in the config file"}
{"description": " according to this issue, we should support python 3.6 and python 3.7 in paddle build scripts ", "commit_messages": " add python3.6 and python3.7 support in padde build scripts  test=develop  add support for mac build  test=develop ", "linked_issue_titles": "", "title": "add python 3.6 and python 3.7 support to paddle build"}
{"description": " adds feature flags (set with defaults to match current behavior) that (a) can escape/display html code, or (b) hide the output of html markup. test plan tested (visually, and in chrome inspector) that html is escaped when escape_markdown_html is enabled, and that html is hidden when display_markdown_html is turned off. requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " utilizing feature flag for html escapement  use src alias  feature flag to allow hiding of html tags  strips js attr  better feature flag naming  simplifying ", "linked_issue_titles": "", "title": "adding feature flags to escape/hide html in markdown"}
{"description": " currently the work of dispatching semantic events to recognizer callbacks is done by rawgesturedetector. the biggest drawback of this design, among others, is that the involved recognizers are hard coded, therefore custom recognizers are unable to get themselves notified on semantic events. this pr moves this work to recognizers by adding a new method to gesturerecognzier: abstract class gesturerecognzier { semanticshandlerconfiguration get semanticshandlers; } which returns a class that has one optional callback for each kind of semantic event. gesture detector will collect the configuration from all of its recognizers and summarize them into one callback per kind of event, therefore becoming agnostic of actual recognizer type. this pr also renames all callbacks related to semantics to semantics*callback from the current gesturetapcallback, gesturelongpresscallback, etc. they are the same (therefore is non-breaking), but gesture*callbacks are defined by subclasses of gesturerecognizer, which are inappropriate for gesturerecognizer to know. related issues blocks: #32770 i added the following tests: {tap,longpress,horizontaldrag,verticaldrag,pan}gesturerecognizer: its corresponding semantic gesture correctly triggers handlers rawgesturedetector a semantic gesture triggers all handlers of that kind replacing gesture recognizers should update semantic handlers before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " basic functionality  move logic to class and pass tests  rename and comments ", "linked_issue_titles": "", "title": "move declaration of semantic handlers from detectors to recognizers"}
{"description": " major changes: 1. expose non-self-register extend api for extensions. so extensions like echarts gl which provide multiple charts and components can also have the new minimal import api. an example: // in extension code. class scatter3dchartview extends echarts.chartview { .... } class scatter3dseriesmodel extends echarts.seriesmodel { .... } export function scatter3dchart(registers) { registers.registerchartview(foochartview); } // in users code import {use} from 'echarts/core/'; import {scatter3dchart} from 'echarts-gl/charts'; use([scatter3dchart]); 2. expose several helper methods for extension usage. echarts.helper.createtextstyle echarts.helper.enablehoveremphasis 3. mark as sideeffects in extensions. ", "commit_messages": " refact: remove registerwhenextend, add ability for class extend in extension.  refact: adjust exports.  chore: no sourcemap in lib  fix: fix unexpected sideeffects in extension  expose more helper functions to extension  settextstyle, enablehoveremphasis  feat: add state opt in createtextstyle export ", "linked_issue_titles": "", "title": "provide better apis for extensions like echarts gl, wordcloud, liquidfill"}
{"description": " addresses #20724 #dataumbrella summary of changes to basedecisiontree: add tests to ensure estimator raises proper errors when invalid arguments are passed in. use the helper function check_scalar from sklearn.utils to validate the scalar parameters. test and validation progress: max_depth min_samples_split min_samples_leaf min_weight_fraction_leaf max_features max_leaf_nodes min_impurity_decrease ccp_alpha references check_scalar docs pr #20723 ", "commit_messages": " max_depth: add tests  max_depth: add validation ", "linked_issue_titles": "", "title": "maint use check_scalar in basedecisiontree"}
{"description": " fixes #4667. on master, the tests added in this pr fail and the code below prints info and warning level logs. library(lightgbm) data(\"agaricus.train\") dtrain <- lgb.dataset( data = agaricus.train$data , label = agaricus.train$label ) lgb.cv( params = list() , data = dtrain , verbose = -1l , nrounds = 3l , nfold = 2l , obj = \"binary\" ) as of this pr, the tests pass and no logs are produced. ", "commit_messages": " fixes  revert debugging code  add test  check for lightgbm explicitly ", "linked_issue_titles": " [r-package] `lgb.cv` ignores `verbose` argument ", "title": "respect 'verbose' argument in lgb.cv() (fixes #4667)"}
{"description": " closes #14743 adds proper support for generating commands from select events on multi-selects i had originally overlooked multiple selects in the original implementation - this should add full support. this pr should be merged in after #14788 since it steals some of the test changes that belong to that pr see original issue for a failing example - here's what it looks like now: has the original issue or this pr been tagged with a release in zenhub? has a pr for user-facing changes been opened in cypress-documentation? have api changes been updated in the type definitions? have new configuration options been added to the cypress.schema.json? ", "commit_messages": " fix(studio): generate selectors before mouse events on click  set up basics for isolated runner tests  update a ton of studio tests  i didn't like that spacing  add another test for mouse events  fix(studio): properly generate commands for multi select  update other tests for studio select ", "linked_issue_titles": " clicking on select option in cypress studio, main window empties - cannot continue testing ", "title": "add support for generating multi select commands"}
{"description": " (whoops branch should've been issue-2117-http-url-not-working...) this pr will resolve issue #2117. it will upgrade an http url to https and see if that works then fallback to using http if it fails. it will test an https url too and verify that the git repos exists fix and rewrite the broken tests the cause of the bug was having a project dependency which itself depended on an http repos. { \"name\": \"yarn-test\", \"version\": \"1.0.0\", \"main\": \"index.js\", \"license\": \"mit\", \"dependencies\": { \"pm2\": \"^1.1.3\" } } running a yarn install on the above would trigger this error error refusing to download the git repo  https is not valid for that domain since they have an invalid certificate chain (refer to #2117 for details). ", "commit_messages": " test for https but fallback to http if necessary  add lang key for https  fix broken tests ", "linked_issue_titles": "", "title": "fix bug for #2117 - http url not working"}
{"description": " fixes #3604 where increase/decrease font size bindings were not working. closes #3604 cla signed. if not, go over here and sign the cla increase and decrease font size works once again! ", "commit_messages": " adding fromjson to adjustfontsizeargs  made a legacy function that just allows you to do 1/-1 delta for adjusting font size  adding test case  removing extra quotes  comments lmao ", "linked_issue_titles": " `{increase,decrease}fontsize` don't seem to work ", "title": "fixing increase + decrease font size"}
{"description": " it's my refactoring on top of jean's pr 307 feed back welcome ", "commit_messages": " added normalize parameter to linearmodel  in fit_intercept, there is now a normalize parameter (default=false)  to normalize data.  added parameter normalize to linearregression  lassolars now uses the normalize parameter  completed the integration of the parameter normalize  implementation of the parameter normalize in bayes.py  added parameter normalize to coordinate_descent  added parameter normalize to ridge.py  added parameter normalize to omp.py  some changes in linear_model  added parameter normalize  added parameter overwrite_x  fixed some errors (mainly docstrings)  conflicts:  scikits/learn/linear_model/omp.py  added a function as_float_array in scikits.learn.utils  this function converts a numpy array to dtype np.float (64 or 32, depending of the original type).  it also takes an optional argument overwrite_x.  thus, _center_data no more takes overwrite_x as an argument, and now modify x inplace.  fix : deleted a forgotten line  i had forgotten a none wanted line in the code, i removed it.  fix : corrected a bug in as_float_array and added a test function  the function was copying x even when overwrite_x was true.  pep8 : replaced tabulations by spaces  fix : if x is already of the good type, we musn't modify it  added a verification in the test  fix : if x.dtype is changed, then a copy of x is returned, even if overwrite_x  is true  the test was updated  test : lasso_lars_vs_lasso_*  added a same test as the existing one, with normalization  conflicts:  scikits/learn/linear_model/bayes.py  scikits/learn/linear_model/least_angle.py  fix : ellipsis in least_angle.py doctests ", "linked_issue_titles": "", "title": "normalize data and refactor of coordinate_descent.py"}
{"description": " this merely log stuff on the console for now. on qemu (without kvm): on hyper-v: ... ... ", "commit_messages": " kernel: add support for hypervisor cpuid feature  kernel: detect and display cpuid hypervisor signature  kernel: detect and display cpuid hyper-v data ", "linked_issue_titles": "", "title": "initial hypervisor guest and hyper-v support"}
{"description": " currently, abstract service classes cause an error during image building. this is reasonable since such services cannot be instantiated. however, since jdk9 there is java.util.serviceloader.stream() which does not force instantiation. thus, we must not fail eagerly. also add test for service with no provider constructor [gr-19958] (#2652). ", "commit_messages": " svm: add abstractserviceloadertest [gr-32503]  svm: fail lazily if service loaders cannot be instantiated [gr-32503]  svm: add test for service with no provider constructor [gr-19958]  this adds a test for the work around for  svm: introduce svm_tests_jdk11 ", "linked_issue_titles": "", "title": "native image should fail lazily if service loaders cannot be instantiated."}
{"description": " this ensures we get a nicer error message from psexec. psexec ansible version v2.6 ", "commit_messages": " psexec: handle socket errors (connection timeout)  this ensures we get a nicer error message from psexec.  add changelog fragment ", "linked_issue_titles": "", "title": "handle socket errors (connection timeout) (backport)"}
{"description": " nearly all of the work required to get aabb vs. aabbs to work in ninja was already present. reportcollisionvsworld already worked, and contained all of the logic required to resolve a collision once the appropriate vectors had been established. reportcollisionvsbody was refactored to use that function (now generically named reportcollision), and now aabbs can collide properly, including bouncing and friction. reportcollisionvsworld is now just a wrapper around reportcollision to maintain compatibility. you can grab a testfile based on the phaser tutorial demo here. all the entities are ninja aabbs. ", "commit_messages": " pull from latest dev  dev  implemented ninja aabb vs aabb collisions  removed unused local variables in ninja.aabb.reportcollisionvsbody ", "linked_issue_titles": "", "title": "aabb vs. aabb collision in ninja"}
{"description": " description: move smartthings integraiton library imports to the top of the modules and use library constants in sensor / binary_sensor modules. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist if the code does not interact with devices: ", "commit_messages": " move imports to top  use lib constants ", "linked_issue_titles": "", "title": "move smartthings imports to top"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. this pr relates to this error: ", "commit_messages": " added fn type for order  added tests for order with order  updated tests to use s.  increased the version number in the header ", "linked_issue_titles": "", "title": "updated \"sequelize typings\" to be able to use fn in \"order\" options"}
{"description": " this is based on pr #2605 though it does not need to :) ", "commit_messages": " add missing headers to build.json  clang-format messed up doxyfile.c++, restored  fix doxyfile for real  only copy stuff when status is ok ", "linked_issue_titles": "", "title": "only copy call details when the status is ok."}
{"description": " the fastcgi process spawned by fastcgi.spawn is executed before h2o calls setuid.  so in case the server is spawned with root privileges (is a requirement if it needs to listen to port 80 or 443), the process gets spawned with root privileges. as discussed in  therefore this pr does the following: by default, change the uid (and group privileges) of the spawned process to that specified using the global user directive (in other words, fastcgi processes will be run under the same privileges as the h2o server) optionally accept a mapping as the argument to fastcgi.spawn, and if it contains a user attribute, use spawn the fastcgi process under name of the given user ", "commit_messages": " compile and install setuidgid into share/h2o  [refactor] store running username in h2o_globalconf_t  spawn fastcgi process using the specified user ", "linked_issue_titles": "", "title": "setuid the process spawned by fastcgi.spawn"}
{"description": " remove last places where diagnostics replied on information from constraint system and instead adjust them to use solution associated with a fix where possible. ", "commit_messages": " [diagnostics] fix requirementfailure::getconformanceforconditionalreq to use data from solution  [diagnostics] fix missingconformancefailure::diagnoseaserror to use solution to retrieve fixes  [diagnostics] fix contextualfailure to use solution data for hasappliedself  [diagnostics] nfc: move is{array, collection}type helpers into failurediagnostic  [diagnostics] add getrawtype which allows to retrieve type associated with astnode  this is useful when diagnostic needs to check something about type  variables involved in a particular type e.g. whether type variable  has been defaulted.  [diagnostics] avoid direct use of constraint system by missingargumentsfailure::ismisplacedmissingargument  [diagnostics] use solution for verify presence of fix in diagnoseuseofreferenceequalityoperator  [diagnostics] use data from associated solution while diagnosing missing generic arguments  [diagnostics] nfc: add israwrepresentable/conformstoknownprotocol helpers into failurediagnostic ", "linked_issue_titles": "", "title": "audit use of constraint system in diagnostics"}
{"description": " tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry hi, i wrote this utility which i use in production almost daily at my job, and it's been super helpful for me personally to fill a gap - slow writes from pandas to ms sql. figured i'd suggest it in the pandas ecosystem if it could be useful to others. wasn't sure where to put it, and didn't want to start a new section, so i put it in out-of-core. it appeared to be sorted alphabetically, so i put it in that order. ", "commit_messages": " update from master  added bcpandas to ecosystem ", "linked_issue_titles": "", "title": "add bcpandas to ecosystem in docs"}
{"description": " improve repo (free-programming-books.md) fix incorrect markdown syntax. fix incorrect markdown syntax. none none none not a duplicate included author(s) if appropriate lists are in alphabetical order needed indications added (pdf, access notes, under construction) ", "commit_messages": " add excel-vba ebook repo.  add vba eboob repo. and fix incorrect menu link.  fix wrong format line  fix incorrect markdown syntax.  add excel - vba ebook repo. (#3079) ", "linked_issue_titles": "", "title": "fix incorrect markdown syntax(free-programming-books.md)"}
{"description": " fixes the invariant test for sample weights as mentioned in issue #11316 (refactor tests for sample weights). what is new? this is a generic test for estimators that makes sure the sample weights yield consistent results. the test checks if the output of the estimators are the same for sample_weight = none and sample_weight=np.ones(). pairwise methods are skipped as they require pairwise data. ", "commit_messages": " test for none and ones for sample_weight added  test for none and ones for sample_weight added  skip kmeans based estimators  conflict resolved  cleaning ", "linked_issue_titles": "", "title": "add a test for sample weights for estimators"}
{"description": " this pull request fixes the following issues: added missing 3d files to libcocos2d project files implemented missing inet_pton() functions for windows phone ", "commit_messages": " added missing inet_pton() for windows phone  fixed check for header already included  added missing inet_pton() for windows phone  added missing files  added missing files ", "linked_issue_titles": "", "title": "wp8 and windows 8.1 universal app fixes"}
{"description": " for #11709 ", "commit_messages": " rename clusterpersistrepositoryconfiguration  refactor gov spring namespace  refactor standalone spring name space  refactor cluster spring name space  remove useless codes  move cluster repository.xsd  move standalone repository.xsd  rename test cases ", "linked_issue_titles": "", "title": "refactor gov spring namespace to cluster"}
{"description": " i hereby agree to the terms of the cla available at:  add materializedpostgresql table engine and database engine. database engine allows to replicate a whole database or any subset of database tables. ", "commit_messages": " initial table sync and replication pre-startup  decode replication messages  add stream and buffer classes  initial sync into replacingmergetree table, select via nested table  setup connection in the background, better drop table  replicate insert queries  replicate delete queries  replicate update queries  slightly better  better  read up to max_block_size rows  better slot usage, some fixes  separate replication interface from single storage  add postgresqlreplica database engine  better  fix and test different data types  slightly better  allow to replicate a subset of database tables  better table sync ", "linked_issue_titles": "", "title": "materializepostgresql table engine and database engine"}
{"description": " this is a minor refactor of the system that deals with previous encryption schemes: it renames #previous_types_including_clean_text -> #previous_types. this private api method is used in other places and invokers are always interested in the \"clean text type\" (when support for unencrypted data is enabled). it makes sense to make that the default behavior. the old internal private method #previous_types is now #previous_types_without_clean_text. this also: adds tests to validate that the system launches decryption errors when all the previous encryption schemes fail to decrypt, and to validate that it returns the ciphertext when support for unencrypted text is enabled. extracts method with common logic for tidying up test of previous encryption schemes. ", "commit_messages": " rename previous_types_including_clean_text => previous_types  it's make more sense to revert the naming approach:  - #previous_types, the exposed public method, always include the clean  text type when suport for unencrypted data is enabled  - #previous_types_without_clean_text is a private method used  internally by the type  we want to check previous_types ignoring clean text type here  this wasn't causing any issue because the behavior was virtually the  same (returning the ciphertext), but it was confusing to read.  add missing text for encryption exception raising  extract helper method for common logic across tests ", "linked_issue_titles": "", "title": "internal refactor relative to previous encryption schemes"}
{"description": " original pull-request #18130 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix remove ttl for column  fix test  fix remove ttl for column ", "linked_issue_titles": "", "title": "cherry pick #18130 to 20.12: fix remove ttl for column"}
{"description": " description: now that zigpy gets the node descriptors for devices and persists them w e no longer have to. this pr removes the node descriptor request that we were making in favor of the one that zigpy does. checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " use zigpy node descriptor  cleanup ", "linked_issue_titles": "", "title": "use node descriptor from zigpy for zha"}
{"description": " category choose one bug fix enhancement (new features, refinement) the js code in the deck.gl examples wasn't working correctly. test plan tested locally reviewers @mistercrunch ", "commit_messages": " fix js_data_mutator  remove redundant line change  add missing line changes ", "linked_issue_titles": "", "title": "fix deck.gl sample charts with js"}
{"description": " change interval of update-notifier to 7 days from the current default of 1 day. message updated with yarn instruction: #20061 ", "commit_messages": " react-devtools update-notifier interval change to 7 days & msg updated with yarn command  overly eager react-devtools ", "linked_issue_titles": "", "title": "overly eager update-notifier usage in react-devtools"}
{"description": " when controlling animation progress using animated.value lottie animation was flickering with android. did some investigation and it seems that animationjson was parsed and applied every time any property change would happen. setting animation only once solved that issue. also examples seemed to be broken when imperative api was disabled so fixed progress slider and cleaned up some example code. probably resolves #362 ", "commit_messages": " use animated component to update progress slider in examples  load animation json only once. should resolve flickering issues  simplify example picker  fixed progress slider and cleaned up some code ", "linked_issue_titles": " animations flicker or won't show after update (android only, ios works perfectly) ", "title": "clear animationjson property to resolve android flickering issues"}
{"description": " closes #45032 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry ", "commit_messages": " gh45032 fix iloc._get_setitem_indexer  test for gh45032  update what's new ", "linked_issue_titles": " bug: iloc(axis=1).__setitem__ ignores axis ", "title": "fix gh45032 iloc(axis=1).__setitem__ axis argument"}
{"description": " #2849 the default wrapping used for textblock in rnw is wrapping. when numberoflines is set to 1, we should set wrapping to none, to have proper trimming/ellipsis for single line text. microsoft reviewers: open in codeflow ", "commit_messages": " fix single line text trimming issue  reset wrapping when numberoflines property reset ", "linked_issue_titles": "", "title": "fix text trmming issue for single line text"}
{"description": " to ease cross-development gentoo alows installing only fully qualified toolchains tools: x86_64-pc-linux-gnu-ar and similar. the change allow overriding ranlib variable similar to existing cc, host_cc, ld and friends. ", "commit_messages": " mk: allow ranlib override  to ease cross-development gentoo alows installing only fully  qualified toolchains tools:  x86_64-pc-linux-gnu-ranlib  and similar.  the change allow overriding ranlib variable similar  to existing cc, host_cc, ld and friends.  reported-by: agostino sarubbo  bug:  mk: allow objcopy override  to ease cross-development gentoo alows installing only fully  qualified toolchains tools:  x86_64-pc-linux-gnu-objcopy  and similar.  the change allow overriding ranlib variable similar  to existing cc, host_cc, ld and friends.  reported-by: agostino sarubbo  bug:  mk: allow ar override  to ease cross-development gentoo alows installing only fully  qualified toolchains tools:  x86_64-pc-linux-gnu-ar  and similar.  the change allow overriding ranlib variable similar  to existing cc, host_cc, ld and friends.  reported-by: agostino sarubbo  bug: ", "linked_issue_titles": "", "title": "allow ar, objcopy, ranlib overrides"}
{"description": " fix hashttpcapability issue with bitbucket shortcut resolver and private repo (#4393) bug with a private repo that used like \"module\": \"bitbucket:team/repo\" fix setrefremote issue with exotic shortcut resolvers and branch/tag/commit bug with a repo that used like \"module\": \"bitbucket:team/repo#tag\" if i have a private dependency like \"activities\": \"bitbucket:openagenda/activities\" in my package.json, and i run yarn install --verbose then i have this error: verbose 0.407 performing \"head\" request to \" verbose 0.867 request \" verbose 0.873 performing \"get\" request to \" verbose 0.98 request \" verbose 0.981 error: error connecting to repository. please, check the url. at /home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:33269:15 at generator.next (<anonymous>) at step (/home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:92:30) at /home/bertho/.config/yarn/global/node_modules/yarn/lib/cli.js:103:13 at process._tickcallback (internal/process/next_tick.js:109:7) error an unexpected error occurred: \"error connecting to repository. please, check the url.\". info if you think this is a bug, please open a bug report with the information provided in \"/home/bertho/openagenda/cibul-node/yarn-error.log\". info visit ", "commit_messages": " * fix hashttpcapability issue with bitbucket shortcut resolver and private repo (closes #4393)  * fix setrefremote issue with exotic shortcut resolvers and branch/tag/commit ", "linked_issue_titles": "", "title": "fix bitbucket exotic shortcut resolvers with private repositories"}
{"description": " so this is my attempt of adding replay and export functions. i first thought on only keeping the last played wav, but then i thought would be nice to let the user choose among the last generated ones for like, comparing and choosing the best. i added a new row on the right side for the 3 new widgets. turned out to be the best placement and  i hope this is fine until the interface cleanup. the interface looks like this now: ", "commit_messages": " replay and save last file  store all waves and select on combobox  functional last waves selection combobox  functional last waves selection combobox ", "linked_issue_titles": "", "title": "export and replay generated wav"}
{"description": " this is for #15749 and #23351 @tyriar the idea is that when storing a backup, callers can now associate metadata with the backup that can be returned when restoring the backup. we can use this metadata to: restore the file properties used for conflict detection (for #15749) restore the file properties used for indicating if a file was deleted on disk or not (for #23351) as you know, we use the first line in the backup for the original file resource already. e.g. file:///users/bpasero/desktop/file.txt contents... with my change, the metadata is being added after the url via json.stringify(): file:///users/bpasero/desktop/file.txt {\"etag\":\"someetag\"} contents... the result will be a uri of file:///users/bpasero/desktop/file.txt with metadata {\"etag\":\"someetag\"}. the space is the actual separator from uri to metadata. i chose it because a uri, when stored as string, will always have spaces escaped. there is one downside with this approach: opening code with a previous version after running with this version causes dirty files to appear twice, once with the correct uri, but once with a uri that contains the metadata. the reason is simple: we change the format of backups and an older version will happily treat the metadata as part of the uri. i think we can tolerate this though because: we do not crash, e.g. startup is still good the dirty file is still there, just twice we typically do not guarantee to be fully forwards compatible, e.g. opening code with an older version on the same directory as a newer code version should not crash, but does not guarantee full data recovery visually it would look like this: ", "commit_messages": " hot exit - simplify model creation from backup  hot exit - convert to async/await  hot exit - move tests into node layer  hot exit - implement support for metadata  hot exit - polish  hot exit - use # as separator for better forwards compatibilty  hot exit - back to ' ' as separator ", "linked_issue_titles": "", "title": "hot exit - allow arbitrary metadata with backups"}
{"description": " fix #13247. r? @alexcrichton  (or anyone else, really). ", "commit_messages": " avoid injecting unfulfilled dependence in compiletest on libnative.  two fixes to get make check-stage1 working.  1. fix a long-standing typo in the makefile: the relevant  ctest_name here is rpass-full (with a dash), not  rpass_full.  2. the rpass-full tests depend on the complete set of target  libraries.  therefore, the rpass-full tests need to use  the dependencies held in the csreq-prefixed variable, not  the tlibrustc_default-prefixed variable. ", "linked_issue_titles": " make check-stage1 is broken ", "title": "get make check-stage1 working again"}
{"description": " remove hacks and wrappers, keep code in sync across our libraries and move spacy a few steps closer to only depending on packages with binary wheels see here:  serialization is hard, especially across python versions and multiple platforms. after dealing with many subtle bugs over the years (encodings, locales, large files) our libraries like spacy and prodigy have steadily grown a number of utility functions to wrap the multiple serialization formats we need to support (especially json, msgpack and pickle). these wrapping functions ended up duplicated across our codebases, so we wanted to put them in one place. at the same time, we noticed that having a lot of small dependencies was making maintainence harder, and making installation slower. to solve this, we've made srsly standalone, by including the component packages directly within it. this way we can provide all the serialization utilities we need in a single binary wheel. srsly currently includes forks of the following packages: ujson msgpack msgpack-numpy cloudpickle enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " wip: replace json/ujson with srsly  replace ujson in examples  use regular json instead of srsly to make code easier to read and follow  update requirements  fix imports  fix typos  replace msgpack with srsly  fix warning ", "linked_issue_titles": "", "title": "replace ujson, msgpack and dill/pickle/cloudpickle with srsly"}
{"description": " @tomaugspurger as promised, this implements a handful of tests, and a few more can be ported from #23415, but the ea-specific tests haven't been started. the big missing piece is datetimearray._from_sequence, which i'm getting started on now in a new branch. closes #23586 ", "commit_messages": " implement most of the rest of ea interface  implement some tests for take, concat_same_type ", "linked_issue_titles": "", "title": "implement _most_ of the ea interface for dta/tda"}
{"description": " this is a follow up of #109 triggered by twisted merge of #4330 ", "commit_messages": " use twisted.web.client.agent for download requests (use of http/1.1)  adds http11.httpdownloadhandler in scrapy.core.downloader.handlers  renamed downloader to http11downloadhandler and some refactoring  only for http, not https  test on expected body length instead of request method (head case)  restore handling of https  http11 cleanup  add http connection pool and custom ssl context factory  enable persistent connections  move ssl context factory to its own module and implement a non-ssl version that warns about pyopenssl support  remove duplicate context factory handling for non-ssl support in http1.0  close pool connections before finishing tests  empty bodies does not require a body producer  adapt for singletons removals  cleanup http connection pool on engine stop  agents requires an instance of contextfactory  implement download timeouts based on deferred cancellation  add required files to support twisted 11.1 (precise) ", "linked_issue_titles": "", "title": "add http 1.1 download handler"}
{"description": " the fix for  this pr is a rollback (git revert) of the specific change 8b795ab that caused the problem. i suggest doing this for a perfectly safe 3.9.4 rather than trying to redo the non-critical bugfix under duress as a rush over a significant portion of the worlds holiday.  fixing it properly can wait until a scheduled 3.9.5. ", "commit_messages": " bpo-43710: revert \"bpo-42500: fix recursion in or after except (gh-23568) (#24501)\"  this reverts commit 8b795ab5541d8a4e69be4137dfdc207714270b77.  it changed the pythreadstate structure size, breaking the abi in 3.9.3.  news entry ", "linked_issue_titles": "", "title": "rollback the 3.9 bpo-42500 fix, it broke the abi in 3.9.3"}
{"description": " additions to types: listeners add definitions to listen/remove listeners from a connection. prettier run prettier as per definetelytyped recommendation. to avoid mixing change and layout, it is split in separate commits. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: apache/tinkerpop@ddf7b98#diff-a974eb4fae74b0556e7ba669da6de50b if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " [@types/gremlin] run prettier  [@types/gremlin] add listener functions to driverremoteconnection ", "linked_issue_titles": "", "title": "add missing methods to driverremoteconnection"}
{"description": " this pr converts the following files to ts: packages/gatsby/src/redux/reducers/nodes.js packages/gatsby/src/redux/tests/nodes.js packages/gatsby/src/redux/reducers/last-action.js packages/gatsby/src/redux/tests/snapshots/nodes.js.snap add new interfaces on: packages/gatsby/src/redux/types.ts and update related imports on: packages/gatsby/src/redux/reducers/index.js related to #21995 ", "commit_messages": " change file type from js to ts  change file type from js to ts  update node reducer export method and types  update redux types adding new action interfaces  update redux nodes test adding ts requirements  update nodes snapshot file  update mapobject type  covert last-action reducer to ts and update the related import ", "linked_issue_titles": "", "title": "migrate nodes reducer and last-action reducer to typescript"}
{"description": " delete by query is a shortcut to search + delete. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. update by query is a shortcut to search + index. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. implementing compositeindicesrequest makes little sense as the indices that the request works against depend entirely on the inner search request. ", "commit_messages": " deletebyqueryrequest to implement indicesrequest.replaceable  delete by query is a shortcut to search + delete. deletebyqueryrequest gets serialized on the transport layer only when the transport client is used. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable  updatebyqueryrequest to implement indicesrequest.replaceable rather than compositeindicesrequest  update by query is a shortcut to search + index. updatebyqueryrequest gets serialized on the transport layer only when the transport client is used. given that the request supports wildcards and allows to set its indices, it should implement indicesrequest.repleaceable. implementing compositeindicesrequest makes little sense as the indices that the request works against depend entirely on the inner search request. ", "linked_issue_titles": "", "title": "update and delete by query requests to implement indicesrequest.replaceable"}
{"description": " from epe-486 and auto-311, i was asked to add testing checkboxes to the pull request template for eosio: this benefits blockchain by encouraging developers to consider test cases while writing pull requests and submitting new contributions. this benefits automation by providing a convenient programmatic way to detect, track, notify, or act upon changes to the ci system or test framework(s), like we do with the other check boxes. more broadly, we all stand to benefit from a culture more focused on testing. the new template has been manually pasted into this pull request so you can see what it looks like, but github will not present the new template to users until it is merged to this repository's default branch: you must create templates on the repository's default branch. templates created in other branches are not available for collaborators to use. see the pull request templates heading on the about issue and pull request templates page of github's documentation for more information. see also pull request 9662 -- eos:develop pull request 9663 -- eos:blockvault pull request 9664 -- eos:develop-boxed pull request 9665 -- eos:release/2.0.x pull request 9666 -- eos:release/1.8.x select one: pull request template. select any that apply: none. none. none. none. ", "commit_messages": " add \"testing changes\" section to the pull request template  whitespace  add italic emphasis on selection quantity  colon ", "linked_issue_titles": "", "title": "add \"testing changes\" section to pull request template"}
{"description": " because getblocktxn requests for unknown blocks would trigger a disconnect, while a getblocktxn for known-old blocks would just be ignored, it should be possible to fingerprint a node by seeing which old, non-main-chain blocks trigger disconnect. the first commit removes the misbehaving score to eliminate this distinction. in the handling of cmpctblock messages, the handling for blocks that are announced that have too little work, or where the block was known but pruned, was busted -- for requested blocks, we would generate a getdata for the block, but for unrequested blocks, we'd fall through and try to process.  in particular, this means that announcing old cmpctblocks could cause a pruning node to redownload old blocks (potentially causing a fill-up-disk dos). the second commit fixes this by aborting processing of cmpctblock messages in this situation. please tag this for consideration in 0.13.0. ", "commit_messages": " ignore getblocktxn requests for unknown blocks  don't disconnect peers, or else we leak information that could be  used for fingerprinting.  ignore cmpctblock messages for pruned blocks  also ignores cmpctblock announcements that have too little work.  this is to  prevent disk-exhaustion dos. ", "linked_issue_titles": "", "title": "prevent fingerprinting, disk-dos with compact blocks"}
{"description": " test sources have been exempt from the bundled forbiddenapi signatures jdk-system-out that check among others usages of system.out.println and throwable.printstacktrace. with the removal of benchmarks in #15356, there is no need to relax this check for tests anymore. this pr: enables jdk-system-out checks on all sources removes the few remaining usages of println and printstacktrace removes two benchmark classes (probably missed in #15356) ", "commit_messages": " remove python and javascript benchmark classes  enable jdk-system-out forbidden api checks on test sources  remove system.out.println and throwable.printstacktrace from tests ", "linked_issue_titles": "", "title": "forbid test sources to use system.out.println and throwable.printstacktrace"}
{"description": " changes based on suggestions on this pr  implemented and more test coverage added ", "commit_messages": " repr description added to depends class  repr description added to security subclass  get rid of __repr__ in security since it will inherit from super  make code format consistent with rest  add desc for rest of the classes  update fastapi/params.py  remove trailing whitespace  implement __repr__  fix formatting  formatting again  ran formatting  added basic testing  get remaining code for params.py  basic tests added to rest of the classes ", "linked_issue_titles": "", "title": "implement changes for __repr__ tests"}
{"description": " fixes #7070, #7080, and #7260. ", "commit_messages": " core: remove compile_read_write_paths()  from 6c47cd7d3bf35c8158a0737f34fe2c5dc95e72d6, runtimedirectory= and  their friends also imply bindpaths=. thus, implying readwritepaths=  is meaningless.  core: readwritepaths= and friends assume '+' prefix when bindpaths= or freinds are set  when at least one of bindpaths=, bindreadonlypaths=, rootimage=,  runtimedirectory= or their friends are set, systemd prepares  a namespace under /run/systemd/unit-root. thus, readwritepaths=  or their friends without '+' prefix is completely meaningless.  so, let's assume '+' prefix when one of them are set.  fixes #7070 and #7080.  test: add test for readonlypaths= with runtimedirectory=  core/execute: runtimedirectory= or friends requires mount namespace  since #6940, runtimedirectory= or their friends imply bindpaths=.  so, if at least one of them are set, mount namespace is required.  core/load-fragment: fix alignment  core/execute: do not create runtimedirectory= under private/ sub-directory  runtimedirectory= often used for sharing files or sockets with other  services. so, if creating them under private/ sub-directory, we cannot  set dynamicuser= to service units which want to share something through  runtimedirectory=.  this makes the directories given by runtimedirectory= are created under  /run/ even if dynamicuser= is set.  fixes #7260.  man: update documents for runtimedirectory= and friends ", "linked_issue_titles": "", "title": "fixes related to runtimedirectory=, readwritepaths= and dynamicuser="}
{"description": " when a tabbarview is nested in a page of another tabbarview, there will be particular scenarios that will throw an exception. to reproduce this issue, two conditions must be true: tap on a tab that is adjacent to a tab containing a nested tabbarview the nested tab has to be in between the initial tab and the tab that was tapped on (ie. current index = 0, tap on tab at index 3 when tab at index 2 has nested tabbarview) this happens when the framework tries to build _pageposition, then dispose of it before applyviewportdimension has the chance to be called to set pixels to a non-null value based on the size of the viewport. this fix adds a flag to determine if applyviewportdimension is invoked before dispose. if it hasn't been, then dispose will set pixels to an arbitrary value before attempting to dispose of it. first exception: this is due to the introduction of #29188, which happens because the initial swap that is necessary for warping causes the nested page that is swapped but not shown to be disposed of before applyviewportdimension to be called. second exception: this one is caused by the animation of the page during warp. the last frame does not build before the second setstate is called to swap the children back to their original positions, causing the nested page to be built and disposed of before applyviewportdimension can be called. todo: add an issue to track adding a test to ensure that the warp animation for tabbarview builds its last frame before setstate is called to re-swap the children back to their original locations. #32054 track the potential need for a more robust swapping mechanism that doesn't cause pages that are not shown to be built and immediately disposed of. #32056 related issues fixes #18756 i added the following tests: a regression test to ensure that the exception does throw when a tab adjacent to nested tab is selected. it tests for the first exception case mentioned above. a separate issue will be created to track writing a test for the second exception case. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " (wip) set pixels to 0 at dispose time  add flag to determine if pixels is set by viewport  (wip) attempt at adding nested tabs regression test  added const keywords where needed in test ", "linked_issue_titles": " exception while scrolling through tabbar navigation ", "title": "fix exception on nested tabbarview disposal"}
{"description": " this pr migrate prometheus bucket to metrics stability framework. the metrics stability framework has provided bucket functionality. (refer: #82583) does this pr introduce a user-facing change?: ", "commit_messages": " migrate prometheus bucket functionality to metrics stability framework.  update bazel by hack/update-bazel.sh ", "linked_issue_titles": "", "title": "migrate prometheus bucket functionality to kube-metrics for proxy metrics"}
{"description": " this change addresses performance issues related to the general behavior of visiteachchild. the current visiteachchild function is highly generic, which make it difficult for hosts to optimize. this change adds individual, more optimized visiteachchildof* functions for the most common nodes in our current test suite. also fixes some issues when compiling processdiagnosticmessages following \"jake clean\". ", "commit_messages": " adds streamlined child visitors for frequently visited nodes.  fix compiler issue after merge  fix unresolved merge issue.  remove unused types. ", "linked_issue_titles": "", "title": "optimize frequent paths in visiteachchild."}
{"description": " use 128 instead of 64 bits for defpath hashes, like we do for everything else. collision probability is unnecessarily high with 64 bits. also change the representation of ich::fingerprint from fingerprint([u8; 16]) to fingerprint(u64, u64) which is better for hashers like fxhasher. ", "commit_messages": " use in-memory representation for fingerprint that is more amenable to hashing.  use 128 instead of 64 bits for defpath hashes ", "linked_issue_titles": "", "title": "use more bits for defpath hashes"}
{"description": " related pr = #2657 and #2792 in this pr, sparse matrix-vector multiplication and direct linear solvers (llt, ldlt, lu) are supported. ", "commit_messages": " sparse matrix multiply with vector and linear solver  add sparse matrix linear solver  add spmv test and linear solver test ", "linked_issue_titles": "", "title": "experimental spmv and direct linear solvers"}
{"description": " closes #6280 ", "commit_messages": " rt: move win32_require out of the rust_kernel type  this is only used on rust_rng, which i am trying to extricate from  the kernel.  rt: eliminate the dependency on rust_kernel from rust_rng  core::rt: add a test that rng works with new tasks ", "linked_issue_titles": "", "title": "make core::rand work with newsched"}
{"description": " fixes #13393. see also pr #12316 fixes linalgerror when using spectral clustering with the amg solver this pr is derived from the previous pr #12316 submitted by andrew knyazev (lobpcg). in that pr, andrew fixed issue #13393 and also added a new label assignment option 'clusterqr'. it was requested that the pr be split to separate the fix and the new label assignment functionality. this pr contains andrew's fix for the amg bug. ", "commit_messages": " change amg tolerance default & laplacian shift (fixes #13393)  add spectral clustering test for amg solver  update docs with edits from andrew knyazev (& some fixed) ", "linked_issue_titles": " amg spectral clustering fails just after a few iterations of lobpcg with \" leading minor of the array is not positive definite\" ", "title": "fix for spectral clustering error when using 'amg' solver"}
{"description": " commit message: make server::options available to the ssl handshaker factory this allows the handshaker to detect the run mode (server::options::mode) and use that to bypass checks required for serving but not for validation. risk level: low testing: added and ran unit tests docs changes: n/a release notes: n/a platform specific features: n/a ", "commit_messages": " clean up handshakerfactorytest  use using declarations where appropriate, fix local variable naming,  use a named constant for the shared magic string.  add server::options to handshakerfactorycontext  this allows the handshaker to detect the run mode  (server::options::mode) and use that to bypass checks required for  serving but not for validation.  add test for handshakerfactorycontext passing objs  test that the handshakerfactorycontext created by the tls transport  socket impl passes through options from the parent transport socket  factory context. ", "linked_issue_titles": "", "title": "make server options available to the handshaker factory"}
{"description": " unzip is handled by busybox on android, and it needs the -d param at the end, otherwise it shows the usage options and does not unzip the file. ", "commit_messages": " add missing dalvik opcode  merge remote-tracking branch 'upstream/master'  conflicts:  libr/asm/arch/dalvik/opcode.h  fix unzip param order on android's busybox ", "linked_issue_titles": "", "title": "fix unzip param orders in android's busybox"}
{"description": " closes #10611 closes #10678. the x-axis for scatter plot and hexbin plot disappears when colorbar is included. this seems to be because colorbar axis is looped through in _handle_shared_axes: pandas/pandas/plotting/_core.py line 426 8a58303 _handle_shared_axes(axarr=all_axes, nplots=len(all_axes), after discussing with @tomaugspurger (issue #10611), we decided to try adding the attribute __is_pandas_colorbar to colorbar axis object and skipping it during handling of shared axes. i've done some tests that seem to fix the issue. but we may need more tests: %matplotlib inline import matplotlib.pylab as pl from mypandas import pandas as pd import numpy as np random_array = np.random.random((1000,3)) df = pd.dataframe(random_array,columns=['a label','b label','c label']) df.plot.scatter('a label','b label',c='c label', patch_mode_flag = false);pl.title('pandas current version'); df.plot.scatter('a label','b label',c='c label', patch_mode_flag = true);pl.title('patch fixing x-axis'); df.plot.hexbin('a label','b label', gridsize=25, patch_mode_flag = false);pl.title('pandas current version'); df.plot.hexbin('a label','b label', gridsize=25, patch_mode_flag = true);pl.title('patch fixing x-axis'); ", "commit_messages": " removed colorbars from _handle_shared_axes when called by scatterplot and hexbin  removed colorbars from _handle_shared_axes when called by scatterplot and hexbin  added a debug global variable ", "linked_issue_titles": " xticks missing for scatter plots with colors  hexbin plots does not display x label and xtick labels ", "title": "scatter plot and hexbin plot lose x-axis when colorbar is included."}
{"description": " this pull request enables the build/include_alpha cpplint filter rule for the atom/ directory which checks for alphabetical ordering of #include statements. this was mostly being followed implicitly but now it is explicitly checked for. most files were already  in compliance and a few had minor changes needed. something worth linting for?  / ", "commit_messages": " enable alphabetical include order lint filter  sort includes alphabetically ", "linked_issue_titles": "", "title": "enable alphabetical include order cpplint rule"}
{"description": " if a diagnostic request is actually canceled, we will throw away the type checker as we cannot be certain that it is still in a usable state. i recommend reviewing this with ?w=1 to make the diff easier to understand. ", "commit_messages": " make type-checking cancellable.  conflicts:  src/compiler/checker.ts  src/compiler/program.ts  src/compiler/types.ts  src/services/services.ts ", "linked_issue_titles": "", "title": "make it possible to cancel requests to get diagnostics."}
{"description": " mainly for \"hygiene\"; add comments to remind people to consider keeping these win sync with the vendored package update binary-commit (userland-proxy) for libnetwork:  moby/libnetwork@fcf1c3b...20dd462 update tomlv binary to match vendor, and use mit license: burntsushi/toml@9baf8a8...a368813 ping @vdemeester @akihirosuda ptal ", "commit_messages": " add notes about keeping versions in sync  sync version of userland-proxy with libnetwork vendor  update tomlv for mit license  the burntsushi/toml code is now re-licensed as mit. while  the vendored package was already updated, the tomlv binary  used was still using the old license type. ", "linked_issue_titles": "", "title": "sync binary commits with vndr"}
{"description": " issue: #12531 added functionality to resolved type aliases and extract enum types from the compodoc generated json file added test cases for named enum types yes, there is a new enum example component possibly. i was not able to get the base enum type with auto-incrementing number values to work correctly. it will generate the select input, though switching between the values does not update the component. ", "commit_messages": " add miscellaneous property to compodocjson type  correct spelling  add resolution for type aliases from compodoc gen  add test component for enums  add enums check for compodoc types ", "linked_issue_titles": "", "title": "fix type aliases and enum types from angular compodoc json"}
{"description": " remove a user from a team, or as a regular user, leave the team. the last modal step should be the one in the screenshot. ", "commit_messages": " update leave team modal  stories  remove user modal ", "linked_issue_titles": "", "title": "change modals for remove user from team && leave team"}
{"description": " currently there are two know issues when compiling with intel icc: the operator() in iterator causes warning the use of internal_iterator causes error the first issue can be resolved by replacing the operator() with a converting constructor and assignment. because the existence of the copy constructor may bring ambiguity, i removed it and the copy constructor will be defined implicitly. the second issue is fixed by adding a struct keyword in front of the type name. ", "commit_messages": " add converting constructors for iterator  add struct keyword in front of internal_iterator  remove the iter_impl<const basic_json> copy constructor and copy assignment ", "linked_issue_titles": "", "title": "#550 fix iterator related compiling issues for intel icc"}
{"description": " passing constant values helps opencl to tune instruction paths. for example, unroll loops (#pragma unroll). performance gain is about 2x ~ 3x faster than before (on an amd hd5850m gpu and an a8m apu's gpu). ", "commit_messages": " replace create with ensuresizeisenough thus buffer objects can be reused.  optimize bfmatcher by passing macros.  further optimize bfmatcher by passing macros.  fix build error on linux.  rename test case category and code clean up.  capitalize macro namings. ", "linked_issue_titles": "", "title": "optimize bfmatcher by passing macros into build options"}
{"description": " fix pojoutil realize type convert not support subclasses of 'java.util.date' #2499 the type convert was modified to support the 'java.util.date' subclass org.apache.dubbo.common.utils.compatibletypeutils.java org.apache.dubbo.common.utils.pojoutilstest.java org.apache.dubbo.common.utils.compatibletypeutilstest.java follow this checklist to help us incorporate your contribution quickly and easily: make sure there is a github_issue filed for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. format the pull request title like [dubbo-xxx] fix unknownexception when host config not exist #xxx. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn clean install -dskiptests & mvn clean test-compile failsafe:integration-test to make sure unit-test and integration-test pass. if this contribution is large, please follow the software donation guide. ", "commit_messages": " solve time, timestamp, sql. date type conversion problems  add ut ", "linked_issue_titles": "", "title": "[dubbo-2499]fix pojoutil realize type convert not support subclasses of 'java.util.date' #2499"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dslint/dt.json\" }. this pr includes changes to d3-format and d3-array to bring them up to their latest minor versions (both v1.2). note that the changes to d3-array also include a definitions bug fix: d3.tickstep(...) returns a number value instead of an array of number. closes #15600 . closes #15902 . @gustavderdrache pls review and approve. thx. t ", "commit_messages": " update d3-format to v1.2  * [feature] adds support for optional \"percent\" suffix in locale definition.  * added tslint.json file  [d3-array] update to version 1.2  * [feature]: add tickincrement(...)  * [fix]: fix incorrect  return type of tickstep(...). the correct return type is number instead of number[]  * [chore]: updated related comments  [d3] update minor version to 4.8 ", "linked_issue_titles": " d3-format update definitions to v1.2  d3-array update to version 1.2.0 ", "title": "d3 update to 4.8.0 (d3-array 1.2 [feature/fix] and d3-format 1.2 [feature])"}
{"description": " original pull-request #16865 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " test for issue #16862  blind fix  update 01560_timeseriesgroupsum_segfault.sql  update aggregatefunctiontimeseriesgroupsum.h  fix for issue #16862 ", "linked_issue_titles": "", "title": "cherry pick #16865 to 20.8: fix for issue #16862"}
{"description": " fixes #5598. background for quite a while, it was the case that when seeking the contextual type of a value, we would always get its apparent type afterwards. this was usually the behavior desired - otherwise, you'd typically run into problems with things like object literals and index signatures. during recent work on string literal types, this turned out to be undesirable because the widened type of a string literal type is the global string type. this was effectively useless because we needed to check whether the contextual type was string literal type or a union with a string literal type, so we separated out the concept of grabbing an expression's contextual type (with getcontextualtype) with grabbing the apparent type of that contextual type (getapparenttypeofcontextualtype). one thing missed in that change was that internally, getcontextualtype was calling getapparenttypeofcontextualtype unnecessarily. this means that if you had a parenthesized string literal, it could never be contextually typed by a string literal type - it would instead get contextually typed by the global string type. the reason the apparent type was necessary in some places is that when \"digging in\" to a type, it's necessary to get the apparent type to recognize its available members, the shape of its type constraint, etc.; however, the apparent type is not needed in simple cases where we simply propagate the type back. ", "commit_messages": " added test for parenthesized string literals.  added other tests for string literal types.  accepted baselines.  added tests for string literal types used as generic constraints.  only get the apparent type when necessary.  accepted baselines. ", "linked_issue_titles": "", "title": "only get the apparent type of a contextual type when needed"}
{"description": " this one should fix #805. ", "commit_messages": " refactor condition in printstatementsequence, add new helper function.  add new test cases. ", "linked_issue_titles": " two blank lines are inserted between a `case` statement and a comment, except on windows ", "title": "fix additional empty line switch case comment"}
{"description": " issue reference #3172 . i added .md files to the formatting scripts. i'm open to any changes for formatting you think best, as i just used mainly the default options and tab spacing. there are some cases where mutli-line code blocks were condensed to a single line, which may not be best for readability in documentation. ", "commit_messages": " add prettier overrides for markdown  add prettier markdown formatting to npm scripts  apply prettier formatting on markdown docs ", "linked_issue_titles": "", "title": "use prettier.js for consistent markdown formatting #3172"}
{"description": " to safely compile for the web, we need to ensure that unsupported code is not reachable. separately, we would like to explore publishing a packaged version of foundation for external consumption. this pr packages us as much of the platform-specific code into libraries based on io and web so they can be conditionally exported/imported. based on #32952 i added the following tests: existing tests cover io bits, web bits still wip. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " move io and web foundation types into libraries  remove dead documentation and provide basic example of defaulttargetplatform for web  try hiding voidcallback  fix analyzer errors.  update libraries ", "linked_issue_titles": "", "title": "use conditional imports for flutter foundation libraries"}
{"description": " added some of the missing functions from the api reference documentation and fixed a couple things in the time series guide. ", "commit_messages": " added series functions to api doc.  adding dataframe methods to api reference.  minor fixes to time series doc. ", "linked_issue_titles": "", "title": "update to api reference documentation."}
{"description": " this is a small doc fix that includes bool as part of the types that is supported in mobile, as bool is clearly invoked in the following define (see ln 105 and ln 135) in mobile platform: #define tf_call_bool(m) m(bool) ", "commit_messages": " fix doc in tf_call_ when defined(is_mobile_platform) && !defined(__android_types_full__)  this is a small doc fix that includes bool as part of the types  that is supported in mobile (is_mobile_platform && !__android_types_full__),  as bool is clearly invoked in the following define.  also add bool to android full version. ", "linked_issue_titles": "", "title": "fix doc in tf_call_ when invoked in mobile platform"}
{"description": " description:  checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " upgrade mypy to 0.720  turn on mypy unreachability warnings, address raised issues ", "linked_issue_titles": "", "title": "upgrade mypy to 0.720, turn on unreachability warnings"}
{"description": " clean-up, moving protobuf code to the pb dir moves interop test generated code and supporting library to the pb directory also added proper binaries for the interop client and server; gem install grpc now installs these also removes the minitest dependency (i.e, begins to address the points raised in #2532) adds a test that validates code generation using the health service (does #635 for ruby) ", "commit_messages": " update the generated code for the interop service.  - updates the code generated for the interop service  - moves the generated interop service/client from bin to pb  also  - removes an empty file from the health pb directories  reorganize interop test files.  - moves the client/server behaviour to pb/test  - deprecate current bin/interop/interop_{client,server}.rb  - adds executable endpoints to bin  - grpc_ruby_interop_{client, server}  - these will be added to the ruby bin path when the grpc gem  gem is installed, making them easier to execute  removes the dependency on minitest  - replaces it with a simple assertion function  adds a test for ruby code generation. ", "linked_issue_titles": "", "title": "grpc ruby mv interop test to pb"}
{"description": " these commits should fix all defects detected by coverity. ", "commit_messages": " jsonservicedescription: fix cid 719179 and 719180  jsonrpc: fix cids 1194413, 1194414, 1194415, 1194416, 1213841 and 1213842  jsonrpc: fix cids 1228813, 1228816, 1228817, 1228818, 1228823 and 1228824  jsonrpc: fix cid 1273979 ", "linked_issue_titles": "", "title": "fix defects detected by coverity"}
{"description": " this change will not change the functionality,  it just changes the internal implementation detail. jwkscache holds both config and cache.  currently,  the whole jwkscache object is in the thread local slot, but actually, only the  cache data needs to be in in the thread local. this change will move the thread local data inside jwksdataimpl,  only stores its {jwks, and expire} into thread local. move jwkscache object out of thread local. this change is in preparation to support async fetch of remote_jwks proposed in #14556 (comment). detail changes: created tls for {jwks, expire} inside jwksdataimpl removed tls for jwkscache in filterconfigimpl removed enable_shared_from_this from filterconfigimpl risk level:  low testing:  unit-tested. docs changes: none release notes: none ", "commit_messages": " move thread local inside jwksdata  move thread local down to lower level  use make_unique_ptr ", "linked_issue_titles": "", "title": "move threadlocal from jwkscache into jwksdataimpl"}
{"description": " #2957 ", "commit_messages": " allow mixing of args uid and gid  reversed the order of setting uid and gid. when uid is set first, the process doesn't have permission to set the gid. so they've been swapped.  give the user all of its group's rights  when using the option --uid <uid> the process now runs with all of that user's permissions, including its groups.  allow mixing of args uid and gid ", "linked_issue_titles": "", "title": "given --uid add all its gids automatically"}
{"description": " r? @petrochenkov extracted out of a larger pr. ", "commit_messages": " ast_validation: comments -> doc comments  syntax::parse::parser: convert unnecessary '&mut self's to '&self'.  parse_bottom_expr: extract common 'return' out.  minor cleanup in parse_assoc_expr_with. ", "linked_issue_titles": "", "title": "assorted cleanup in parser & ast validation"}
{"description": " added the wallpaper.png (used as a placeholder background) to installer file and set the min/max width of the fz preview control. added fz preview control disabled state: #15165 linked issue: #15165 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " added disabled state  added wallpaper image to installer file ", "linked_issue_titles": "", "title": "added disabled state to fz preview control"}
{"description": " add missing methods on vectortile class definition add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " + [mapnik] adding methods of the class vectortile as described in  + fix multiple semicolon at definitions ", "linked_issue_titles": "", "title": "+ [mapnik] additional method definitions on the class vectortile"}
{"description": " fixes #19637, #8710. as suggested in #19641, this pr removed validation from the calibratedclassifiercv predict_proba function and replaced x.shape[0] with _num_samples(x). regression testing has also been added. ", "commit_messages": " fix predictions for calibratedclassifiercv with pipeline  fix pep8 warnings ", "linked_issue_titles": " calibratedclassifier on pipelines ", "title": "fix calibrated classifier cv predictions with pipeline"}
{"description": " redoes #8612 to instead just re-up the existing 2.3.2 tag instead of cutting a new release. update jquery dependencies for bower to avoid some bugs bump to recess 1.1.9 update all links to point to @twbs org and new getbootstrap.com point download urls to the release tag instead of a local zip also bumps some copyright across the project to 2013. ", "commit_messages": " component.json -> bower.json; adjust jquery to >=1.8.0 <2.1.0  bump recess to 1.1.9  twitter/bootstrap => twbs/bootstrap in links etc.  update urls to account for v3 rc1 soft launch  version bump  add changelog entry  more date changes  point changelog in docs to releases on github  point docs downloads to tag in twbs org  revert to 2.3.2 tag instead  finish bumping copyright ", "linked_issue_titles": "", "title": "bump 2.3.2 dependencies and docs links for v3 rc1"}
{"description": " although the new lite interface does support float models as well, the current android demo app does only support quantized models. furthermore, it isn't obvious to transfer the code from the quantized version to the floating point model. based on this discussion i integrated the inception-v3 slim model as an alternative to the existing mobilenet. remaining todo: the confidence scores returned by the inception net are not in [0,1] yet. besides that, the inference itself seems to work. so the correct results are listed on top, but the confidence score isn't normalized. maybe the given model doesn't include a softmax layer and ends with the logits? i'm not sure about this. any help is appreciated. ", "commit_messages": " make imageclassifier abstract and introduce new concrete subclasses  refactor labelprobarray, because the tensorflow interface doesn't  support boxed data types  bugfix  add todo  reformat  change the readme to reflect the latest changes ", "linked_issue_titles": "", "title": "add support for floating point models as inception-v3"}
{"description": " this is a follow-up pr to #7612 fixes small part of #7465, so that we won't create file watcher every time on file updating. when running cargo run -- run --watch --unstable foo.js and update the content of foo.js, it seems like i've got results as expected. the integration test run_watch fails locally right now though. i'm looking into it. ", "commit_messages": " create single watcher for whole watch process  move wach_path to the top  try fix  remove unwatch  impl simplistic debouncer for watcher  refactor debounce to be awaited, remove select to fix race condition  cleanup and comments  remove unnecessary mutex  use select! to handle debounce events  rename _self -> self_mut  fix poll_next implementation  use std::mpsc instead of tokio's  call wake_by_ref  fix  add sleep ", "linked_issue_titles": "", "title": "create single watcher for whole process"}
{"description": " completes #12202 fix abandoned by @parul-l. modifications made as per @amueller and @adrinjalali: replaced random data with an image from sklearn image dataset; reformated the output. this completed fix results from reshama shaikh's push to close all prs opened during wimlds's scikit-learn sprint in sep. 2018. yes, reshama is herding cats! cc: @reshamas ", "commit_messages": " finalizes fix for #12202 from abandonned pr by @parul-l  completes 12202 fix abandoned by @parul-l  completes 12202 fix abandoned by @parul-l ", "linked_issue_titles": "", "title": "doc adds an example to patchextractor"}
{"description": " after previous pr #1552, stirngstore not actually does any cleanup. it just erases keys to stale data, not the data itself. now that behavior was fixed and stringstore cleans up correctly. sorry for the inconvenience. it is a bug fix. i have submitted the spacy contributor agreement. ", "commit_messages": " stringstore now actually cleaned  do not lose docs in ref tracking  merge github.com:explosion/spacy  swap keys in proper place  remove unnecessary clear of the hits ", "linked_issue_titles": "", "title": "actually reset caches in pipe [wip]"}
{"description": " some clients are already using protobuf v2 as part of their application and would need a lot of work to move, but tensorflow requires v3. this script patches the protobuf source code after downloading it to put it into a google::protobuf3 namespace, and alters all the necessary tensorflow code to compile with this new namespace. this allows the v3 library to be linked into applications alongside v2 without causing linker errors. ", "commit_messages": " added protobuf renaming script  post-process protobuf generated source files to use new namespace  removed backup files  updated protoc scripts for version renaming ", "linked_issue_titles": "", "title": "support a separate namespace for the protobuf library"}
{"description": " fixes #6209 support geturl support getbigdecimal ", "commit_messages": " refactor change yamlruleschemametadata same with  ruleschemametadata  change for cr  add test of default constructor  support url and bigdecimal data ", "linked_issue_titles": " support more java types for  getobject with type method ", "title": "support more java types for getobject"}
{"description": " dalli 2.2.x was released, so this is safe for merge now / ", "commit_messages": " let's run action pack tests with dalli  there is no memcache gem left in repo.  more fixes for action pack tests with dalli. ", "linked_issue_titles": "", "title": "use dalli for memcache session store"}
{"description": " just like in #9760, we can't actually use the uwp file picker api, because it will absolutely not work at all when the terminal is running elevated. that would prevent the picker from appearing at all. so instead, we'll just use the shell32 one manually. this also gets rid of the confirmation dialog, since the team felt we didn't really need that. we could maybe replace it with a toast (#8592), but meh closes #11356 closes #11358 this is a lot like #9760 introduced in #11062 megathread: #9700 ", "commit_messages": " allows the dialog to be opened when elevated. moves some helpers around  make it act like a .txt export, in downloads  comments ", "linked_issue_titles": " [1.12] exporting text fails when running elevated (presumably we can't open the file picker elevated)  [1.12] we can probably just ditch the confirmation dialog when exporting text ", "title": "replace the uwp file export with the shell32 one"}
{"description": " as per issue #969. preview result at johannesmoene/catch. it appears to me that adding some titles could improve the reading experience. for example: tutorial in the tutorial and reference in the reference. regards, martin (joahannes) moene ", "commit_messages": " add html anchor 'top'  let toplevel links to .md files link to .md#top ", "linked_issue_titles": "", "title": "link to top of content"}
{"description": " all compatible conversions with tests. ", "commit_messages": " add tests  adapter for batchnorm opset 8 to 9  adapter for upsample opset 8 to 9  adapter for scan opset 8 to 9  update convert.h file  fix syntax error  add type annotations  merge remote-tracking branch 'origin/master'  check node type for cast operator  empty commit to rerun checks  add test for min, msx, mean and sum operators  add adapters for min, max and mean operators ", "linked_issue_titles": "", "title": "version conversion of min, max, mean from opset 7 to 8"}
{"description": " currently, the decisions regarding which translog generation files to delete are hard coded in the interaction between the internalengine and the translog classes. this pr extracts it to a dedicated class called translogdeletionpolicy, for two main reasons: simplicity - the code is easier to read and understand (no more two phase commit on the translog, the engine can just commit and the translog will respond) preparing for future plans to extend the logic we need - i.e., retain multiple lucene commit and also introduce a size based retention logic, allowing people to always keep a certain amount of translog files around. the latter is useful to increase the chance of an ops based recovery. ", "commit_messages": " wip  wip  extract interfaces  java doc tweak  wip  translog tests compile  translog tests pass  remove ontranslogrollover as it's not needed for now  simplification and removal of future stuff  update java docs  tell combineddeletionpolicy of open mode so it can be smarter.  introducing indexcommitref  # conflicts:  #\tcore/src/main/java/org/elasticsearch/index/engine/internalengine.java  #\tcore/src/main/java/org/elasticsearch/index/shard/indexshard.java  #\tcore/src/test/java/org/elasticsearch/index/engine/internalenginetests.java  a little test to test translog min reference advance  some java docs ", "linked_issue_titles": "", "title": "introducing a translog deletion policy"}
{"description": " for the autocomplete feature to work properly (while doing power-rename) we need to handle all previous search and replace items and also keep it as most recently used (mru) list. previously those items were kept in registry, and goal of this pr is to move them to persistent json data file. implemented mru list handler with persistent json storage. migration from registry is supported. support  on the run changes in mru list size. always check if json data file has changed since we loaded it last time, and do reload if needed. enabled flag is also migrated from registry. pr checklist applies to #2011 ", "commit_messages": " handle most recently used search/replace strings withing settings.  check for last modified time of json file and reload it if needed.  handle changes in mru search / replace lists size  improve handling of changes in mru list size ", "linked_issue_titles": "", "title": "migrate power rename mru lists from registry to json"}
{"description": " removed dashcamplayer (the feature is replaced by common/image.js\") improving pnc monitor performance by reducing chart update frequency in pncmonitor, categorizing planning/control plots into different tags. ", "commit_messages": " dreamview: using tabs to categorize pnc plots  dreamview: removed dashcamplayer  dreamview: improving pnc monitor performance by reducing chart update frequency  webpack dv ", "linked_issue_titles": "", "title": "add tags to pncmonitor & cleanup"}
{"description": " fixes #90 . updated the combostyle and progmoderadiobuttonstyle to set istextscalefactorenabled to true so that the text size for these controls will scale according to the system settings. manually tested the text size changes under different scaling percentages. ", "commit_messages": " added bug report and feature request issue tempaltes  bug report and feature request templates  copied pull_request_template.md to .github folder  issuetemplates  updated unitconverter comboboxstyle to set istextscalefactorenabled = true  updated the programmer operator button style to set istextscalefactorenabled to true. ", "linked_issue_titles": " list items of the combo box in \"currency converter\" window are not adapting under 200 and 300 percent text scaling. ", "title": "updated unitconvert combobox and programmer mode radio button styles to enable istextscalefactorenabled"}
{"description": " part of #29692. ", "commit_messages": " particles: properly initialize angular velocity parameter  right now it would take garbage values when loading scenes,  which could end up written to the scene file.  cpuparticles: set linear velocity to 0, like gpu particles ", "linked_issue_titles": "", "title": "fix uninitialized angular velocity, fix inconsistency in linear velocity between cpu and gpu particles"}
{"description": " removing the check for user that was added recently (i added it when i added the same check but without a user for the auto resolve message, and now need to remove this) ", "commit_messages": " fixing auto resolve logic  fixing test  reverting this logic back to how it was ", "linked_issue_titles": "", "title": "fix(workflow) reverting statusitem logic"}
{"description": " this allow the filesystem scan thread to get the class_name scripts without loading extra resources. also added a get_dependencies() method to the gdscript resource loader, so now the preloaded resources are also included as dependencies when exporting. also added a function to fileaccess to get the file as a string, since it's not trivial to do. should fix #17513. ", "commit_messages": " add function to get string from fileaccess  add a dependency search mode for gdscript parser  - this mode avoids loading any other resource.  - search for class_name now uses this mode, to avoid loading in the scan  thread.  - implement get_dependencies() for gdscript loader, now exporting  dependencies only should include the preloaded resources. ", "linked_issue_titles": " resource references from gdscript not followed when exporting w/dependencies ", "title": "add a parse mode for gdscript which doesn't load dependencies"}
{"description": " allow void returns in catch/then blocks support union types for catch handlers that really need to return a different type than the original promise allow calling fromnode for a callback that doesn't expect a result parameter ", "commit_messages": " allow calls to fromnode without a result parameter in the callback  added better catch definitions that pass through the original promise type or type union of promise|rejection type  promise.then definitions that allow void in the error handler ", "linked_issue_titles": "", "title": "bluebird catch, then, fromnode improvements"}
{"description": " wrapped sections within <section> tags on the /manage page. refactor the layout of the advanced plugin manager page from a table to use <section> tags. also set a margin between sections to add \"breathability\" through vertical spacing. screenshots manage page before manage page after plugins advanced before plugins advanced after n/a ?? i don't think it's worth a changelog entry changelog entries and upgrade guidelines are appropriate for the audience affected by the change (users or developer, depending on the change). examples fill-in the proposed changelog entries section only if there are breaking changes or other changes which may require extra steps from users during the upgrade @daniel-beck before the changes are marked as ready-for-merge: changelog entries in the pr title and/or proposed changelog entries are correct if the change needs additional upgrade steps from users, upgrade-guide-needed label is set and there is a proposed upgrade guidelines section in the pr title. (example) if it would make sense to backport the change to lts, a jira issue should exist and be labeled as lts-candidate ", "commit_messages": " refactor layout on the plugins/advanced page  - migrate away from a table-based layout, using the <section> html element  - add some space between sections  refactor the sectioning of the /manage page  - use the <section> html elements  - add some spacing between sections to improve readability ", "linked_issue_titles": "", "title": "rework sectioning on /manage and /pluginsmanager/advanced"}
{"description": " small fixes to a few of the three.js example files to make then work with webgl in ie 11. the main problem was that the examples were overwriting the global window.parent. in ie 11 window.parent is read only so the examples were failing. on other platform browsers window.parent was being changed to a three.object3d. parent = new three.object3d(); i added parent to the following declaration of vars var camera, scene, renderer, parent; this fixes the examples for ie 11. ", "commit_messages": " added var parent. parent should not be global. fixes ie 11  added var parent. parent should not be global. fixes ie 11  added var parent. parent should not be global. fixes ie 11  removed return false to fix return error in ie 11 ", "linked_issue_titles": "", "title": "browser interoperability bug fixes for examples in ie 11"}
{"description": " cherry picks of #47235, #47689 for v1.7.1 note: this will only introduce builds and does not solve for the issues identified in #47776 relates to #45731 ", "commit_messages": " .circleci: add python 3.9 to linux binary build matrix (#47235)  summary:  pull request resolved:  depends on  test plan: imported from oss  reviewed by: malfet  differential revision: d24863739  pulled by: seemethere  fbshipit-source-id: ed78087bb7aae118af7a808d7b5620d6c9b8cb26  (cherry picked from commit cc337069e0213b00da505c0a9ddf4a2644a39ae4)  .circleci: add python 3.9 builds for macos (#47689)  summary:  pull request resolved:  test plan: imported from oss  reviewed by: janeyx99  differential revision: d25029226  pulled by: seemethere  fbshipit-source-id: 1db2b021d3adf243453f4405219d5ce03d03a9c1  (cherry picked from commit 05dc9821be4c6338702ed17e6f385647604654e6) ", "linked_issue_titles": "", "title": "add python 3.9 support (linux / macos)"}
{"description": " closes #324. ", "commit_messages": " add spec for checking webgl support.  download dirextx sdk dlls.  update libchromiumcontent for libegl.dll.  ship webgl necessary files in distribution.  rename \"frameworks\" to \"external_binaries\".  check for version when downloading external binaries.  only build debug target in cibuild. ", "linked_issue_titles": " webgl doesn't work on windows ", "title": "fix webgl support on windows"}
{"description": " description: update the androidtv tests to use pytest instead of unittest. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. if the code does not interact with devices: ", "commit_messages": " move the patchers to a separate file  got a pytest test working (mostly) ", "linked_issue_titles": "", "title": "bump androidtv to 0.0.26 and update tests"}
{"description": " fix the error of  #3940 ", "commit_messages": " bugfix  supports elasticsearch backend options settings  update document of elasticsearch backend settings  elasticsearch: fix serializing document id.  elasticsearch: fix serializing document id.  revert code  fix es default value and document error,fix code friendly ", "linked_issue_titles": "", "title": "fix the build error of #3940"}
{"description": " this is related to #31908. in order to use the external version in a reindex from remote request, the search request must be configured to request the version (as it is not returned by default). this commit modifies the search request to request the version. additionally, it modifies our current reindex from remote tests to randomly use the external version_type. ", "commit_messages": " reproduce  changes  changes  changes ", "linked_issue_titles": "", "title": "propogate version in reindex from remote search"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. the methods returned on line 319 of loading-bar.js (here) haven't been defined in the interface. i've added their definitions and updated the tests to check that the types of the properties can still be changed, without necessarily touching the method implementations. ", "commit_messages": " allow @types/angular-loading-bar to export a string name for angular module inclusion  add in the methods for @types/angular-loading-bar and fix the tests ", "linked_issue_titles": "", "title": "define the methods on the loading bar provider in angular-loading-bar"}
{"description": " adds support to load layeredfs patches on dlcs. since dlcs have different title ids from the base game, they follow the exact same patch structure except with their title id. adds support for dumping dlc romfs from the game list. if dlcs are found, they will appear in a list with base game for user selection. remove duplicates from dlc list if a dlc is installed twice. when dumping the base game romfs, avoid dumping the patched version (with updates/mods). log a dlc layered fs patch to log for debugging. ", "commit_messages": " patch_manager: add support for using layeredfs with data  fsp_srv: apply patches to data storage in opendatastoragebydataid  registered_cache: deduplicate results of listentry and listentryfilter  prevents a entry from appearing in the list twice if the user has it installed in two places (e.g. user nand and sdmc) ", "linked_issue_titles": "", "title": "add support for layeredfs on dlc romfs"}
{"description": " this is a backport of mozilla#327 which fixes mozilla#283. ", "commit_messages": " hard overwrite on conflict for query owners (re #283)  use alertdialog instead of custom global function. ", "linked_issue_titles": " owners of queries should be able to hard overwrite ", "title": "allow query owners to hard-overwrite query content in case of overlap with other user"}
{"description": " we should support safe c++ worker api according the doc, this pr supports normal task for ray_emote. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " add some functions to serializer  remove response; simplify error handling  invoke with rayobject  add use_ray_remote branch  throw error message  add objectref<void>  support single process normal task  support void normal task  normal task single process ", "linked_issue_titles": "", "title": "ray normal task for ray_remote"}
{"description": " initial infrastructure code for specializing call_function. also added specialization for calling meth_o  pycfunctions because it's the easiest to implement. along with meth_fastcall. measured up to 20% faster calls for meth_o on microbenchmarks. ", "commit_messages": " wip: specialize call_function for builtins  fix some gcc compilation warnings  hopefully fix the segfaults  rename to call_cfunction and generalize to all c functions  fix formatting, remove redundant check  goto fail rather than return -1  create 2021-06-28-22-23-59.bpo-44525.ssvukg.rst ", "linked_issue_titles": "", "title": "specialize call_function for c function calls"}
{"description": " this also changes the interactive mode of analyze-sample-code.dart to print the correct line numbers of where the error occurs in the source file (instead of the line numbers in the generated file). unfortunately, it makes the interactive mode a somewhat slower. but having the correct line numbers is more important and helpful. related issues #69123 before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: ", "commit_messages": " migrate api doc samples to nnbd  ++  ++  ++ ", "linked_issue_titles": "", "title": "migrate the first batch of api samples to null safety"}
{"description": " stopping pvr manager must follow the strict two-step logic for all (!) of its sub components. stop all sub components (means, stop their worker threads to hold processing) unload all sub components (clearing all data) starting must follow the exact revere logic load all sub components (loading their data from clients and/or database) start all sub components this was not implemented properly for cpvrtimers and cpvrepgcontainer components and should be fixed by this pr. runtime-tested on macos and android, latest kodi master. i had a testcase reproducible on my mac which led to all kind of errors and even crashes. ", "commit_messages": " [pvr] fix timers thread start/stop, load/unload races.  [pvr] fix epg container start/stop, load/unload races. ", "linked_issue_titles": "", "title": "fix pvr manager start/stop races"}
{"description": " a third version of #16306 and #16328 puts the common checks to mark as xfail into the _xfail_test estimator tag. hopefully addresses concerns raised in the two previous implementations. in particular, this would make the workflow identical between scikit-learn and contrib projects. ", "commit_messages": " add known failure flag to common tests  better pytest integration  passing request more systematically  more comments  detect pytest session  remove outdated import  add pytest --runxfail to tips  typo  update sklearn/utils/estimator_checks.py  add thomas' comment  simplify signature check  simplify _raise_xfail  remove nb skip tests since its never run  add _xfail_test estimator tags  minor fixes ", "linked_issue_titles": "", "title": "enh xfail in common tests with estimator tags (v3)"}
{"description": " this is a step toward the long-term goal of making the \"user\" trees nodes immutable. this change isolates the mutable data for expression nodes in the \"user\" tree during the semantic (analysis) phase by moving the mutable data into input and output objects. these objects are created locally during the semantic phase to share information required for semantic checking between parent-child nodes. note that for this change, input and output are still stored in a mutable way on the expression nodes. this will not be the case once the semantic (analysis) phase and ir generation (write) phase are combined in a future change. relates #49869 ", "commit_messages": " remove isnull from aexpression  remove explicit cast optimization  remove modification of semantic tree for casting  remove ecast node  start of input/output in expressions  partial change for input and output in expression nodes  add input/output objects for expressions  fix shift bug in ebinary  response to pr comment ", "linked_issue_titles": "", "title": "move aexpression mutable members into isolated input/output objects"}
{"description": " the following deprecated warnings are removed from contrib/timeseries examples the name tf.app.run is deprecated. please use tf.compat.v1.app.run instead. the name tf.session is deprecated. please use tf.compat.v1.session instead. the name tf.train.adamoptimizer is deprecated. please use tf.compat.v1.train.adamoptimizer instead. ", "commit_messages": " deprecated tf.app.run removed in known_anomaly.py  deprecated tf.app.run/tf.session/tf.train.adamoptimizer removed in lstm.py  deprecated tf.app.run/tf.session removed in multivariate.py  deprecated tf.app.run removed in predict.py ", "linked_issue_titles": "", "title": "deprecated warning removed from contrib timeseries"}
{"description": " running pytest in getsentry triggers a bug in firefox_profile.py from the selenium driver. upgrading to version 4 is quite involved. this is a stop-gap to prevent distracting engineers when it happens. this is the output when we patch it: --> installing sentry (for development) we are patching .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py. you will see this message only once. --- .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py\t2021-11-09 16:40:20.000000000 -0500 +++ .venv/lib/python3.8/site-packages/selenium/webdriver/firefox/firefox_profile.py.bak\t2021-11-09 16:40:03.000000000 -0500 @@ -207,3 +207,3 @@ def _set_manual_proxy_preference(self, key, setting): -        if setting is none or setting == '': +        if setting is none or setting is '': return ", "commit_messages": " wip  patch ", "linked_issue_titles": "", "title": "patch firefox_profile.py from selenium package"}
{"description": " we add ent_iob as a token pattern key, upon request by #3940 . i also added a tiny addition to the documentation for the new key. enhancement ", "commit_messages": " added new field  added exception for iob strings  minor refinement to schema ", "linked_issue_titles": " ent_iob as a token pattern key  suggested documentation improvement: ent_iob in dependencymatcher ", "title": "add ent_iob key to matcher"}
{"description": " fix for #9957 resolves the deprecated function in diagrammer package used in graph.viz. graph nodes are now of fixed size rather than adapting to wrap the whole text, i will check for a solution to this in the next days. ", "commit_messages": " fix viz.graph r  fix viz.graph r ", "linked_issue_titles": "", "title": "fix r build crash in ci"}
{"description": " fixes #4866: minor bug in the dict update when used by minibatchdictionarylearning. i added a test which currently fail on master. _update_dict seems to make smart things to update the residuals incrementally but i found that it's actually much faster (~10x to 20x) to write the function more naively and compute the objective function from scratch at the end. the impact on the time for the whole dict learning is negligible since the bottleneck is the sparse coding but i find version much more readable (and by reading the related issues i'm not the only one). when an atom is not used, the current strategy is to generate a new one from a normal distribution. but it's very likely that it will still not be used. a discussion with @tommoral lead us think that sample a new atom from the data may be a better strategy. below is a plot of the objective function for both strategies. more small adjustments. i explain thoses in dedicated comments ", "commit_messages": " several fixes to dict update in dict learning  fix docstrings  avoid noise with 0 std ", "linked_issue_titles": " block coordinate descent for dictionary update has a non optimal step ", "title": "fix several issues in the dict update"}
{"description": " this is the second step to bring integration between ebpf and cgroups #11558. this pr is creating shared memory with cgroup plugin. component name cgroup ebpf.plugin 1 - enable flag inside your netdata.conf 2 - compile this branch 3 - take a look in the logs to verify whether shared memory was filled this pr is part of a huge branch that has almost all modifications proposed for #11558 , and it was tested on: manjaro 21.1 (cgroup version 2) centos 7.9 debian 10.10 ubuntu 18.04 ", "commit_messages": " cgroup_shm: move preprocessors to header  cgroup_shm: add library to link shared memory  cgroup_shm: add data types  cgroup_shm: initialize shared memory  cgroup_shm: fill header with initial data  cgroup_shm: close shared memory  cgroup_shm: add cgroup to shared memory ", "linked_issue_titles": "", "title": "add shared memory to cgroup"}
{"description": " this pr along with electron-archive/brightray#157, adds a new api to app: app.allowntlmcredentialsforalldomains(true | false); we are discovering that many domains are incorrectly configured, so that ntlm will not be implicitly passed to a web server because windows (via iinternetsecuritymanager::mapurltozone) will decide it isn't inside the local domain. this pr allows app developers to say, \"don't care about urls, always send ntlm if asked\". if this method is not called, the preexisting behavior will be used we actually set up an in-house domain controller to test this, it appears to be ", "commit_messages": " create a new method on app to override url security manager's decisions wrt ntlm  wire it up  linter fixes  rollback submodule change ", "linked_issue_titles": "", "title": "optionally allow ntlm authentication for all domains"}
{"description": " previously the incremental parser worked in a mode where it would reuse nodes prior to the editedrange, then skip over nodes/tokens in the edited range, then reuse nodes after the edit range.  the reused nodes after the edit range would then have to have their positions fixed up.  i.e. they might move forward/backward depending on what sort of edit it was. this approach resulted in extra complexity as the incremental parser had to keep track of where it was, and how the position it was in the tree related to the position it was at in the text.  this involved keeping track of two different positions in two different sources (the old tree and the text) and keep a relative 'delta' between then to tell if they were in sync. thanks to a suggestion from bill, i've moved things to a simpler model that makes things only slightly more expensive.    specifically, we start the incremental parse with a prepass over the tree.  we skip over all nodes quickly that fall totally before the edit range.  then we mark all nodes and tokens in the edit range as being unusable.  then we move all tokens that fall totally after the change range forward. thanks to this, all nodes/tokens from the old tree that we look at are either marked as unusable, or are located at the same position they would be at in the new text.  this means we no longer need to keep track of relative positions between two sources.  instead, we can simply try move to the node that matches the current text position.  if we find one, we can return it.  otherwise, we know we need to keep rescanning tokens from the new text. ", "commit_messages": " simplify incremental parsing by moving old source tree nodes before doing anything.  fix interface.  simplify parser initializer.  simplify incremental code.  always mark nodes and tokens that cross the edited range.  slightly speed up marking by avoiding calling fullstart on so many nodes and tokens.  simplify incremental parser.  speed up incremental parser.  make 'kind' non-enumerable.  remove unused asserts. ", "linked_issue_titles": "", "title": "change how the incremental parser works."}
{"description": " this pr merges together several changes: updates to the validation for facebook to handle oldschool /page/id urls changing to always store only the unique username / page name portion of twitter & facebook urls adding new utilities to construct the full urls from the usernames updating structured data etc to use the new utilities to output urls where needed providing 2 new helpers for the theme api which also use the new utilities to output urls where needed all together, these changes should go green in travis! ", "commit_messages": " add helpers for facebook & twitter urls  refs #6534  - this pr assumes that we are now saving usernames only in the database for twitter & facebook  - adds a new social links utility which can generate twitter & facebook urls from the username  - adds a {{twitter_url}} and {{facebook_url}} helper which uses these  - adds a full suite of tests for the helpers & utils  update structured data for fb & twitter usernames  refs #6534  - twitter & facebook fields are changing to store usernames only  - use the new social url util to generate urls where necessary  - update tests  fixes error in validation  closes #6826  - refactors the validation of facebook and twitter input field in general.js and user.js controller  - example validations for facebook:  - facebook.com/username will be corrected to the full url  - user will show error your page name is not a valid facebook page name' for general.js and your username is not a valid facebook username for user.js as the username in facebook has to be at least 5 characters long  - twitter.com/username will be autocorrected to the valid facebook url incl. the username  - example validations for twitter:  - twitter.com/user_ will be corrected to the full url  - user:99 will show error your username is not a valid twitter username  - facebook.com/username will be autocorrected to the valid twitter url incl. the username  - updates both acceptance tests  - adds further validation for facebook pages in general settings and user. submitting a url which incl. /page/ or /pages/ will now accept any username followed incl. further /.  - adds a custom transform facebook-url-user which will extract the username (if it's a facebook page, incl. pages/) to store only this in the backend  - uses the twitter-url-user transform now also for user ", "linked_issue_titles": "", "title": "improvements to twitter & facebook handling"}
{"description": " original pull-request #22594 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " consistent aws timeouts.  consistent aws timeouts ", "linked_issue_titles": "", "title": "cherry pick #22594 to 21.2: consistent aws timeouts"}
{"description": " hi tf team, would it be possible to fold these tutorial doc updates from master into the r0.10 release branch? thanks, sanders ", "commit_messages": " code and data for tf.contrib.learn monitors tutorial.  change: 128588838  new tutorial on tf.contrib.learn monitors.  change: 128589916 ", "linked_issue_titles": "", "title": "tutorial updates for r0.10 release"}
{"description": " add check to kafkaapis add unit test specific to follower fetch update tool developed with @mimaison ", "commit_messages": " minor: added check on handling fetch request from follower  minor: added check on handling fetch request from follower  added unit test specific to follower fetch  updated tool  developed with @mimaison ", "linked_issue_titles": "", "title": "additional check to follower fetch handling"}
{"description": " this pr cleans the maps in the tokenizer files to make sure each checkpoint has the proper tokenization files. this will allow us to remove custom code that mapped some checkpoints to special files (like bart using roberta vocab files) and take full advantage of the versioning systems for those checkpoints. all checkpoints changed have been properly copied in the corresponding model repos in parallel. for instance, to accomodate the move on the fast bart tokenizers, the following commits have been on the model hub: in facebook/bart-base in facebook/bart-large in facebook/bart-large-mnli in facebook/bart-large-cnn in facebook/bart-large-xsum in yjernite/bart_eli5 in the pr i've also uniformized the way the maps are structured across models, to make it easier to alter (and ultimately remove) them in the future via automatic scripts. ", "commit_messages": " move tokenizer files in each repo  fix mbart50 tests  fix mbart tests  fix marian tests ", "linked_issue_titles": "", "title": "copy tokenizer files in each of their repo"}
{"description": " preview of results: synthetic data | real data ", "commit_messages": " modified tweaked tests to use tensor learning rate  temporarily enable tensor lr globally for testing  temporarily change compute_lr_on_cpu to false  revert \"temporarily change compute_lr_on_cpu to false\"  this reverts commit c726775b0e216ddd6822006a8b74ad1d11b21027.  revert \"temporarily enable tensor lr globally for testing\"  this reverts commit 300bc29f593b0744a8d24126b5abf5e2ed36a11f. ", "linked_issue_titles": "", "title": "use lr schedule ops instead of lr callback for tweaked tests"}
{"description": " following-up on the url work from the previous pr built a new library called native-url to address the concerns with the differences in the api between our solution the node-url the library has an exhaustive list of test-cases to ensure it remains api compatible. size difference: current url package - ~5kb gzipped native-url - ~1.6kb gzipped ", "commit_messages": " adding native-url package  bumping native-url version  upgrading native-url ", "linked_issue_titles": "", "title": "replace url polyfill with self.url"}
{"description": " this includes a number of commits for the first round of upgrading to llvm 6. there are still lingering bugs but i believe all of this will nonetheless be necessary! ", "commit_messages": " llvm6: codemodel::{jit,}default no longer exists  llvm has since removed the codemodel::default enum value in favor of an  optional implementationg throughout llvm. let's mirror the same change in rust  and update the various bindings we call accordingly.  removed in llvm-mirror/llvm@9aafb854c  llvm6: missing include for llvm 6 in passwrapper.cpp  just bog-standard compile error fixed by adding some new header files  llvm6: tweak fast math intrinsics  looks like they did some refactoring of flags in the backend and this should  catch us up! the \"unsafe algebra\" boolean has been split into a number of  boolean flags for various operations, and this updates to use the setfast  function which should hopefully have the same behavior as before.  this was updated in llvm-mirror/llvm@00e900afd  llvm6: remove mips64 archive variant  it looks like llvm also removed it in llvm-mirror/llvm@f45adc29d in favor of the  name \"gnu64\". this was added in the thought that we'd need such a variant when  adding mips64 support but we ended up not needing it! for now let's just  removing the various support on the rust side of things.  llvm6: different return value for writearchive  updated in llvm-mirror/llvm@203c90ba this function now just returns an error,  so this updates the c++ bindings accordingly  llvm6: don't clone llvm modules on wasm  the comment for why cloning exists doesn't actually apply for wasm today and  apparently cloning is causing subtle bugs in llvm, so let's just avoid it  altogether. more specifically after we emit the assembly for the wasm target we  don't actually use the module again, so there's no need to keep both around.  this seemed to be causing some scary verifier assertions in llvm which seemed to  be uncovered by presumably (?) buggy behavior. let's just avoid it for now and  make the wasm target slightly more lean in the process. ", "linked_issue_titles": "", "title": "first round of llvm 6.0.0 compatibility"}
{"description": " this issue if related to #5546, where it is claimed that datafeeders will become deprecated. as such, this branch has following changes added _generatorfeedfn class generator_input_fn in generator_io.py support for generator_input_fn in enqueue_data() added unitest in generator_io_test.py refactored code keeping indent spacing to 2. ", "commit_messages": " branch to test_tensorflow  using types.generatortype for validation  changed to receving generator function  this allows to run multiple epochs of a finite generator  using placeholders as keys to feed dictionary  added correct counter for the index_placeholder  added corrections to tests  removing extra spaces ", "linked_issue_titles": "", "title": "add support for dict generator input_fn in learn_io"}
{"description": " fixes #5638 i have added tests for the newly introduced function to check for file and also the default icon src config (with a snapshot test). i was also thinking about testing the promise.reject behavior of onpostbuild, but i got stuck because i don't know if mocking the fs would be a good idea, or should i just leave the fs as is and let it generate files in public directory (which is ignored by git anyway). please suggest. \\ ", "commit_messages": " throw error if icon does not exist for manifest  gatsby-plugin-manifest will throw an error if the icon defined in  gatsby-config.js does not exist. if it does exist, then console.log  a better message about what is being done.  see gatsbyjs/gatsby#5638  add tests for gatsby-plugin-manifest  the tests ensure the default icon src configs and behavior of the  newly introduced check for detecting the presense of icon src  mentioned in the gatsby-config.js file.  see gatsbyjs/gatsby#5638 ", "linked_issue_titles": "", "title": "fix gatsby-plugin-manifest cryptic error if file is not present"}
{"description": " as a result of changing the base docker to ubuntu in #80820, the default shell i.e. /bin/sh changed to dash, rather than bash, which could impact anyone invoking /bin/sh and expecting it to still propagate environment variables with periods in their names. reconfigure the default shell back to bash so that this type of situation works again. ", "commit_messages": " change default shell to bash in ubuntu-based images  add a test for what is the default shell ", "linked_issue_titles": "", "title": "change default shell to bash in default docker image"}
{"description": " fixes for two property-wrapper crashes: move \"has lazy resolver\" check later to handle merge-modules properly (sr-10844 / rdar://problem/51484958) ensure that we fully check the property type vs. wrapper's value type (sr-10899 / rdar://problem/51588022) ", "commit_messages": " [se-0258] move \"has lazy resolver\" check later to handle merge-modules properly  the merge-modules phase doesn't have an active type checker, so we were bailing  out of property-wrapper queries before we had a chance to check the cache.  move the check later, to the points where we actually need a type checker.  fixes sr-10844 / rdar://problem/51484958.  [se-0258] ensure that we fully check the property type vs. wrapper's value type  various optimizations / shortcuts in type checking property wrappers meant  that we weren't consistently verifying that a wrapped property type is  identical to the type of the 'value' property of the wrapper. do so.  fixes sr-10899 / rdar://problem/51588022. ", "linked_issue_titles": "", "title": "property wrapper misc fixes 5.1"}
{"description": " moved the logic to measure elapsed time and cpu load from fio_compressfilename to fio_compressfilename_internal. fio_compressfilename is only used for single file case. if we want to show elapsed time and cpu load for each file in multiple file scenario, the measurement needs to be done in fio_compressfilename_internal, which is called by both single and multiple file scenarios. i could have added the logic to fio_compressfilename_internal, fio_compressfilename_dstfile, or fio_compressfilename_srcfile. i thought fio_compressfilename_internal is a good fit since it already has logic to print stats about compression (compression ratio). i see elapsed time and cpu load as the extension to the stats. ", "commit_messages": " zstdcli : exposing cpu load indicator for each file on -vv mode  zstdcli : moving start time and cpu initialization after potential prompt  zstdcli : fixing mixed declarations and code error  zstdcli : moving cpu load calculation from fio_compressfilename_dstfile to fio_compressfilename_internal  zstdcli : trying to fix declaration after statement  zstdcli : remove extra semicolon  zstdcli : align output message with previous message ", "linked_issue_titles": "", "title": "expose cpu load indicator for each file on -vv mode"}
{"description": " some of the multioutput docs contained some errors or were still referring to multilabel. some language issues were fixed on the way. ", "commit_messages": " fix a few quirks in the muliclass docs  change references to multioutput ", "linked_issue_titles": "", "title": "doc fix minor quirks in multiclass docs"}
{"description": " the clojure bert example's infer function accepts a cpu/gpu context, which the command line version of this example exposes as a :cpu/:gpu keyword. previously, these options were ignored and the context was always overridden to the default context (cpu). this pr allows users (both repl and shell) to pass in a gpu context. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (this is a tiny-change pr) to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " clojure bert example: minor code cleanup  * remove unused requires  * remove unused vars & function  * use io alias  clojure bert example: whitespace fix  clojure bert example: allow running with gpu  the infer function accepts a cpu/gpu context, which the command line  version of this example exposes as a :cpu/:gpu  keyword. previously, these options were ignored and the context was  overridden to the default context (cpu). this commit allows  users (both repl and shell) to pass in a gpu context. ", "linked_issue_titles": "", "title": "fix clojure bert example's context argument"}
{"description": " one more round of deprecations removal. ", "commit_messages": " removed deprecated #original_exception in actionview::template::error.  removed deprecated #original_exception in activejob::deserializationerror  removed deprecated support to passing the adapter class to .queue_adapter  removed deprecated methods in activemodel::errors  #get, #set, []=, add_on_empty and add_on_blank.  removed deprecated :tokenizer in the length validator ", "linked_issue_titles": "", "title": "remove deprecations in active model, action view and active job"}
{"description": " attempt to fix urgent issue #4072 i'm sorry, no. don't know how to reproduce the test case with unit tests. for the time being you may want to test it against demo project by rguanghui in #4072. previous to the pr it should run into the error described in the related issue. when trying to build it with the fixed version of lib/dependencies/harmonyexportimportedspecifierdependency.js it should print an error message. added unit test which tests on the result of harmonyexportimportedspecifierdependency#gethashcode(importedmodule) when method parameter is null or undefined. don't think so. ", "commit_messages": " attempt to fix #4072  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "data must be a string or a buffer (#4072)"}
{"description": " updates to support qmk-dfu bootloader, and refactor of oled support to utilize built-in i2c and oled drivers. updated existing keymaps to remove extraneous oled code. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " tkc1800: updated to support qmk-dfu bootloader  tkc1800: updated to support qmk-dfu bootloader  tkc1800: updated to utilize common i2c and oled code ", "linked_issue_titles": "", "title": "refactor and updates to tkc1800 code"}
{"description": " in my fork i have/had to fix the three issues mentioned in the subject. please refer to the (rather extensive) commit messages for more details on my work. the patches so far have been written on a works-for-me basis, so no unittests have been attempted; i'm on a rather tight deadline right now (and i had to get proper error logging from my application). in any case: thanks a lot for making my life a lot easier by writing django-sentry. :) ", "commit_messages": " this seems to fix a bug where it was possible for some class, which is not available on the server side (in my particular case a suds soap text object), to be pickled and sent to the server. this caused a bad data response due to an importerror on the server. ", "linked_issue_titles": "", "title": "better error reporting/logging from within sentry, patch for unicode coercion and bug in exception catching"}
{"description": " addresses #21034 turns out that moniker ranges break indentation in sub-bullet content when the bullet item isn't included in the versioned content ... therefore, the versioned content must include the bulleted item ... i.e. .... the bullet item must be repeated for each version. ", "commit_messages": " patch blazor wasm security layouts  update hosted-with-azure-active-directory.md ", "linked_issue_titles": "", "title": "blazor wasm security versioned content"}
{"description": " improve documentation readability, and avoid an incorrect debug message. ", "commit_messages": " man: systemd.exec: cleanup \"only x will be permitted\" ... \"but x=x+1\"  > only system calls of the *specified* architectures will be permitted to  > processes of this unit.  (my emphasis)  > note that setting this option to a non-empty list implies that  > native is included too.  attempting to use \"implies\" in the later sentence, in a way that  contradicts the very clear meaning of the earlier sentence... it's too  much.  seccomp-util: fix alarming debug message (#8002, #8001)  booting with systemd.log_level=debug and looking in dmesg -u showed  messages like this:  systemd[433]: failed to add rule for system call n/a() / 156, ignoring:  numerical argument out of domain  this commit fixes it to:  systemd[449]: failed to add rule for system call _sysctl() / 156,  ignoring: numerical argument out of domain  some of the messages could be even more misleading, e.g. we were reporting  that utimensat() / 320 was skipped as non-existent on x86, when actually  the syscall number 320 is kexec_file_load() on x86 .  the problem was that syscall nrs are looked up (and correctly passed to  libseccomp) as native syscall nrs.  but we forgot that when we tried to  go back from the syscall nr to the name.  i think the natural way to write this would be  seccomp_syscall_resolve_num(nr), however there is no such function.  i couldn't work out a short comment that would make this clearer.  fwiw  i wrote it up as a ticket for libseccomp instead.   ", "linked_issue_titles": "", "title": "cosmetic seccomp fixes (#8002/#8001)"}
{"description": " change all uses of \"master/slave\" terminology to \"parent-child\". component name no functional differences in the code. there are many mentions of master that i have left in place: references to external systems (e.g. the mysql collector and the macos firmware) the use of webmaster anything in urls (e.g. references to git branches) ", "commit_messages": " change affected file-names under build_external  update testing scenarios for new filenames  all the other mentions of master-slave netdata instances. ", "linked_issue_titles": "", "title": "change streaming terminology to parent-child in the code"}
{"description": " merged mkldnn adaptive pooling with traditional pooling implementation, so that the code redundancy is fixed ", "commit_messages": " implemented adaptive pooling operator in pooling operator  fix: fixed issues from the review  fix: changes with_workspace var to const  refactor: changed const use_adaptive to more informative use_adaptive_pooling  refactor: changed getmkldnnpoolalgo to more descriptive getmkldnnpoolingalgorithm ", "linked_issue_titles": "", "title": "merge mkldnn adaptive pooling with traditional pooling implementation"}
{"description": " fix for continued discussion on #1757 btw, i don't expect simd.js to change rapidly, but should we continue manually pull changes into emscripten rather than using git submodules? it'll be helpful in tests/runner.py to print out the js engine that it's running the test with. it'll be helpful in tests/runner.py to print a message telling the user that v8 cannot be used instead of giving a mysterious message saying no available js engines when the user specified v8 in ~/.emscripten. thanks!! ", "commit_messages": " updated simd.js to fix nan canonicalization issue for bitcasts  fix accidental rewrite of original url source of simd.js ", "linked_issue_titles": "", "title": "fix nan canoicalization issue for simd bitcasts"}
{"description": " see related discussion: maxnowack/node-podcast#39 (comment) add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: maxnowack/node-podcast#39 (comment) include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " allow passing a duration in string format  see related discussion:  update version header ", "linked_issue_titles": "", "title": "@types/podcast - allow passing a duration in string format"}
{"description": " description: use collections helpers from #30313 to manage input_text entities. related issue (if applicable): #30494 pull request with documentation for home-assistant.io (if applicable): home-assistant/home-assistant.io#<home-assistant.io pr number goes here> checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " refactor input_text to use config dict.  use collections for input_text. ", "linked_issue_titles": "", "title": "use collection helpers for input_text entities"}
{"description": " what do these changes do? adds multi-gpu support for multi-agent. previously, this required the simple optimizer that did not support minibatching. also closes #3489 ", "commit_messages": " wip  fix ", "linked_issue_titles": " error on es when running `python rollout.py` from checkpoint ", "title": "multi-gpu support for multi-agent ppo"}
{"description": " fixes #3453, towards #4222 this is not the most elegant patch, but i need to force resource_table into deno_core::isolate now, and this is the best i can do at the moment. ", "commit_messages": " add resource table to core::isolate  wip  compiles  use rc<refcell<resourcetable>> ", "linked_issue_titles": " resource table for plugins ", "title": "move resource_table from deno::state to deno_core::isolate"}
{"description": " fixes #10055 closes #10081 changed multinomialdeviance from total logloss to average logloss. i fixed stalled pr #10081. the main modification is from #10081. what i did is to merge recently master branch and fix conflicts and flake8 errors. ", "commit_messages": " [mrg] fix multinomialdeviance not using average logloss (#10055)  use np.average for handling weighted and unweighted cases  add test for multinomial deviance  extend test of multinomial deviance loss  fix issue with numerical precision in multinomial deviance loss test  split multinomialdeviance tests into several  add test case for unweighted multinomialdeviance  add pytest.mark.parametrize to tests  fix import of assert_raises_regex  conflicts:  sklearn/ensemble/_gb.py  sklearn/ensemble/tests/test_gradient_boosting_loss_functions.py  fix conflicts and follow master branch ", "linked_issue_titles": " multinomialdeviance in gradientboostingclassifier should use average logloss instead of total logloss. ", "title": "fix fix multinomial deviance by taking the weighted average instead of the sum"}
{"description": " first patch fixes problems with finding suitable frame format when videodevice::findtype() is called with default parameters during video capture object initialization which causes reporting its state as closed after initialization (function isopened() returns false). cv::videocapture cap(cv_cap_msmf); bool state = cap.isopened();  // always false second patch fixes assertion warnings thrown when frames are being grabbed ('atlmfc\\include\\atlcomcli.h   line:177   expression: p==0'). these warnings occur because smart pointer is not reset at every loop (in imagegrabber::startgrabbing). ", "commit_messages": " fixed msmf video capture initialization  fixed assertion warning in msmf frame grabber ", "linked_issue_titles": "", "title": "fixed msmf video capture (camera) issues"}
{"description": " enforces a minimum width of 460 wide. this allows tabs to always be seen (albeit partially). note: a minimum height was originally added to allow the about menu to be seen. this minimum height was removed from this pr because we don't foresee a circumstance where your terminal is in that state, and you can't just resize it to make the content fit properly. #4990 may be fixed/affected by this? closes #4976 will close issue #5418 upon verification here's some images of what the terminal looks like when it's at its minimum size: 100% scaling 100% scaling: one tab 100% scaling: two tabs 100% scaling: 3 tabs (scrolling enabled) 200% scaling 200% scaling: one tab 200% scaling: two tabs 200% scaling: 3 tabs (scrolling enabled) ", "commit_messages": " add minimum size to terminal  460x380 min size ", "linked_issue_titles": " minimize button disappears at minimum size ", "title": "add and enforce minimum width"}
{"description": " accompanying the release of tailwind css v2, @adamwathan recently added detailed instructions for integrating with next to the official tailwind docs. this pr brings the tailwind example in line with those instructions in a minimal way by: creating a new app with create-next-app adding tailwind per the instructions updating index.js to use tailwind for styling (screenshot below) removing other css cruft note: i realize someone has already updated this example to use tailwind v2, but it still deviates in small ways from what you'd get if you followed the tailwind docs verbatim. not a huge deal, but could be confusing to newcomers. ", "commit_messages": " remove old stuff  fresh start with create-next-app  add tailwind deps  add tailwind config files  all css -> tailwind  update readme ", "linked_issue_titles": "", "title": "bring tailwind css example in line with official tailwind docs"}
{"description": " as per #236, rewriting the security questions cheat sheet. this is just a draft - not ready to merge. any comments are very welcome. ", "commit_messages": " initial start on improvments to the security questions cs  initial layout for new version ", "linked_issue_titles": "", "title": "rewrite of security questions cs"}
{"description": " fixes #16723 this pr fixes 2 problems: fusedop did not support boolean input type as its inputs. during testing the fix for the first problem another problem was spotted (which i believe was previously fixed during the process of working on the fusion pr, but i guess some merge undid it) - the fusedop did not recompile the code when there was a change of inputs/outputs number of dimensions, which is wrong. this pr fixes both of those problems and introduces tests for them. @sxjscience please validate the fix. ", "commit_messages": " support bool in fusion  added tests ", "linked_issue_titles": " [bug] fused_op does not support boolean type ", "title": "add support for boolean inputs to fusedop"}
{"description": " the two commits have the details of the two fixes ", "commit_messages": " rustc: fix cfg(not(a, b)) to be not(a && b)  previously, the cfg attribute cfg(not(a, b)) was translated to (!a && !b),  but this isn't very useful because that can already be expressed as  cfg(not(a), not(b)). this commit changes the translation to !(a && b) which  is more symmetrical of the rest of the cfg attribute.  put another way, i would expect cfg(clause) to be the opposite of  cfg(not(clause)), but this is not currently the case with multiple element  clauses.  std: fix backtraces on arm linux  on android, libgcc is missing the _unwind_getip symbol because it's defined as a  macro. this is the same case for arm linux, so this commit adds the necessary  cfgs in place to use the \"expanded macro\" in rust for arm linux. ", "linked_issue_titles": "", "title": "tweak cfg(not(a, b)) and fix building libstd on arm linux"}
{"description": " this is step 1 as laid out by @nathansobo in #10979. remove texteditors dependency on notificationmanager. ", "commit_messages": " don't require notification manager in texteditor  instead expose getcursorscope and let users outside the text editor  show the notification.  don't need to pass in the notification manager anymore.  implement the show cursor scope functionality in the default commands.  update the spec. ", "linked_issue_titles": "", "title": "remove texteditor's dependency on notificationmanager"}
{"description": " fixes #16356. ", "commit_messages": " network: fix indentation  network: decrease indentation level  network: always update acquired prefix route  otherwise, routes become lifetime 0.  fixes #16356. ", "linked_issue_titles": " systemd-networkd does not appear to reset the valid/preferred lifetime of delegated ipv6 prefixes when doing a dhcpv6 renew, leading to loss of ipv6 connectivity ", "title": "update acquired dhcp6 prefix routes"}
{"description": " this pr adds support for --checkpoint-at-end to rllib train, which currently ignores this flag. fixes #8919 closes #8919 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  fixes and lint. ", "linked_issue_titles": " [rllib] rllib train ... --checkpoint-at-end flag is ignored ", "title": "issue 8919 checkpoint at end ignored"}
{"description": " differences between using vue in web and weex using vuex and vue-router ", "commit_messages": " + [doc] update <differences between using vue in web and weex>  + [doc] translate the 'using vuex and vue-router' into english  * [doc] finish the difference-with-web doc ", "linked_issue_titles": "", "title": "translate some docs into english"}
{"description": " currently when you ask for data source options as an admin, it was sending back the full data source configuration, including passwords. in case you have multiple admins in your system or you're using re:dash without https (not recommended), it might be a security concern. this pull request changes this: it will send a placeholder instead of the password (or any other field defined as \"secret\"). closes #554. ", "commit_messages": " update comment  stop sending passwords to the ui  fix: don't require uploading file again when editing bq/gs data source ", "linked_issue_titles": "", "title": "don't send passwords back to the ui"}
{"description": " extracted these fixes from #2520 ", "commit_messages": " ci: fix a regression in setting up container_name  container_name was just ignored because script(1) does not give env vars to child processes.  in addition, this commit uses '?=' in check.mk to let container_name be overridable by env vars.  ci: fix a regression that step scripts should have -e as the default does ", "linked_issue_titles": "", "title": "fix regressions in gha migration"}
{"description": " currently there is a clear mechanism to stub sending a request through the transport. however, this is limited to testing exceptions on the sender side. this commit reworks our transport related testing infrastructure to allow stubbing request handling on the receiving side. ", "commit_messages": " merge  change ", "linked_issue_titles": "", "title": "introduce mechanism to stub request handling"}
{"description": " this fixes #4235. this is second attempt to support +json content type suffix. the first attempt in #3353 was declined. i applied authors suggestions regarding using should_render method for automatic view selection. ", "commit_messages": " [#4235] automatic view based on should_render method instead of content_types property  [#4235] update chengelog ", "linked_issue_titles": " recognize `+json` content type suffix ", "title": "automatic view mode based on should_render method"}
{"description": " css: use integer values for font-size in css use correct ordering of @import \"invisible\" isn't a tag - presume its a class \"border-color\" defines the complete border python: use \"not\" instead of == \"[]\" for python prefer triple quoted docstrings prefer static functions where possible prefer modern style classes where possible remove semicolons; global: remove duplicated words words ", "commit_messages": " browsers do not consistently handle non-integer values for font-size.  simplify python code  fix order of @import  in css 2.1, any @import rules must precede all other rules (except the  @charset rule, if present).  pep8 prefers triple quoted with double quotes  prefer tuple to array  remove unused code  make functions static where possible  modern style classes  remove useless semicolon from python  duplicate the  add missing semi-colon  border-color > border  invisible isn't a tag  inherit from object  remove duplicate duplicate words ", "linked_issue_titles": "", "title": "fix a variety of minor issues"}
{"description": " this pr fixes a bunch of callback function signatures so that they align with the signatures expected by windows api. most changes are from __cdecl to __stdcall, which matters on x86, but not on x64 or arm64. cla signed. if not, go over here and sign the cla requires documentation to be updated i find it hard to believe that conhost.exe as shipped in windows would use callback functions with incorrect calling convention. perhaps the version that ships with windows is compiled with /gz (__stdcall-by-default)? but openconsole.sln isn't. all of these functions were found manually, so it's likely that there are more issues like this that i didn't find. it would be great if msvc had a warning similar to gcc's -wcast-function-type. the only one signature incompatibility i found that wasn't eliminated was with fontenumproc (i only fixed the calling convention, which is most important anyway), since a slightly different signature is being used that is similar to enumfontfamproc rather than enumfontfamexproc/fontenumproc, and a slightly more invasive change would be needed. ", "commit_messages": " fix signatures of callback functions  fix calling conventions of callback functions  remove now-unnecessary casts of pointers to callback functions ", "linked_issue_titles": "", "title": "fix signatures of some callback functions"}
{"description": " two changes were made: make sure ray cluster is initialized before calling init() if the loop is already running _async_init is scheduled to run in current loop. linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " assert ray is initialized  make sure ray is initialized  make sure ray is initialized before asyncio init  use ensure_future to schedule coroutine if loop is running  format code ", "linked_issue_titles": "", "title": "allow async_api to init when loop is running"}
{"description": " fixes #417. ", "commit_messages": " mac: convert from imageskia to nsimage to reserve dpi info.  recognize the \"@2x\" suffix of icon's filename.  fix converting empty v8 dictionary.  use mate::dictionary instead of base::dictionaryvalue for options.  mate::dictionary can represent arbitray type, which matches our use.  dicard uses of base::value in native_window.  support high dpi icon as window icon.  fix compilation error.  :memo: add docs on image support in atom-shell.  wait for crash reporter spec longer. ", "linked_issue_titles": " [os x] tray icon for retina display ", "title": "add support for high resolution icon"}
{"description": " sorry, @ogrisel, missed a handful of information commits in the what's new section and feature_extraction.image module (from issue #3167) ", "commit_messages": " adding notes section to img_to_graph and grid_to_graph re: np.matrix->np.ndarray  adding what's new item for sklearn.feature_extraction.image np.ndarray changes ", "linked_issue_titles": "", "title": "minor docstring and what's new changes for issue 3167"}
{"description": " allow to generate changelog for tag which doesn't yet exist fixes #4718 component name move changelog generation to be before creating release artifacts fix problem with failing ci system on master branch create only one commit when creating a release exempt issues with stale label from changelog fix rc0 version tag. use next minor release for release candidates ", "commit_messages": " consolidate commiting in release pipeline; generate changelog before tagging  fix how rc0 is created ", "linked_issue_titles": " use `--future-release` in changelog generation ", "title": "better changelog generation when releasing new version"}
{"description": " this adds console to inner hits, explain, field-stats, request body, scroll docs. relates to #18160 @nik9000 care to take a look? ", "commit_messages": " add console to scroll docs  relates to #18160  add console to inner hits examples.  add console to explain  add console to field-stats docs.  add console annotations to request body docs ", "linked_issue_titles": "", "title": "add console to docs for inner hits, explain, and friends"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. the exported default function does not return a color object, it returns the hexadecimal string value of the resolved color name. the type definition assumes it is a color object. i encountered this error when attempting to use the library in an existing typescript project using import. in testing this change to the type definition, i did notice that using require did not cause any typescript errors: const gethex = require(\"colornames\"); but importing the library this way did: import * as gethex from \"colornames\"; the changes to the type definition in this pr work with both of the above examples. ", "commit_messages": " update colornames types  add name  fix linter errors ", "linked_issue_titles": "", "title": "fix colornames default export type definition"}
{"description": " fixes #5070 intersectsegmentcircledisplace has been replaced by an overloaded method of intersectsegmentcircle that now accepts a minimumtranslationvector as optional parameter. some design choices justifications use vector2 instead of vector3. this has required creating some static vector2 instances for temporary use similar to vector3 ones. to keep simple naming prefix v2 + letter seems the more compact/readable. these instances can be used by any other method in the class that needs temporary vector2. use vector2 operations when possible for readability use circle as argument (the old one didn't use it as circle class was created later in time) even if the new intersectsegmentcircle that accepts an mtv parameter could also replace the old one, it has been left for backwards compatibility (up for discussion, in my opinion we should remove it) i will squash all the changes when i get confirmation on what to do with the old method + code review. ", "commit_messages": " fixed and replaced intersector intersectsegmentcircledisplace  formatting ", "linked_issue_titles": " intersectsegmentcircledisplace does not work when the segment is partially inside the circle ", "title": "fixes #5070 - fixed and replaced intersector intersectsegmentcircledisplace"}
{"description": " this updates the libcontainer dependency to 5210a236b92a8022a673108f347. its fixes issues where we changed the libcontainer.container struct's name to config.  it also includes the refactoring in libcontainer's dependency chain. ", "commit_messages": " update libcontainer to 5210a236b92a8022a673108f347  docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael)  update libcontainer references  docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael)  rename libcontainer.container to libcontainer.config  docker-dco-1.1-signed-off-by: michael crosby <michael@docker.com> (github: crosbymichael) ", "linked_issue_titles": "", "title": "update libcontainer dep to 5210a236b92a8022a673108f347"}
{"description": " we've added several targets since the introduction of the target tier policy. based on experiences of those adding such targets, and discussions around such additions, clarify the target tier policy to make it easier to follow and work with. none of these changes substantively change the requirements on targets. (in some cases the changes do direct target submitters to follow specific process requirements for the addition of a target, such as how to respond to requirements, where to put target-specific documentation, or what should appear in that documentation. those changes are procedural in nature and document the procedures we already direct people to follow.) clarify how to quote and respond to the target tier policy requirements. several times, people have seemed unclear on how to respond to some of the policy requirements, particularly those that just state things the target developers must not do (e.g. not posting to prs that break the target). add a note that such requirements just need acknowledgement, nothing more. clarify dependency requirements in the face of cross-compilation. i previously phrased this confusingly in terms of \"host tools\", since that is the case where an exception applies (allowing proprietary target libraries commonly used by binaries for the target). rephrase it to apply equally to cross-compilation. this doesn't change the net effect of the requirements, since other requirements already cover the dependencies of the rust toolchain. clarify documentation about running binaries. the requirement for target documentation talks about \"running tests\", but tier 3 targets often don't support running the full testsuite, and in practice the documentation for how to run an individual binary may be more useful. change \"running tests\" to \"running binaries, or running tests\". explain where to place target-specific documentation (a subdirectory of platform-support, with a link from the platform-support entry for the target). add a template for target-specific documentation. ", "commit_messages": " clarify how to quote and respond to the target tier policy requirements  several times, people have seemed unclear on how to respond to some of  the policy requirements, particularly those that just state things the  target developers must *not* do (e.g. not posting to prs that break the  target). add a note that such requirements just need acknowledgement,  nothing more.  make quoting and responding a \"must\" rather than an \"is encouraged to\",  since it's easier to review the requirements that way.  clarify dependency requirements in the face of cross-compilation  the requirement on dependencies was phrased in terms of \"host tools\",  but it was also intended to apply equally to targets that only support  cross-compilation. only the exception (for libraries commonly needed for  binaries on the target) was intended to apply to host tools. reword the  requirement to talk about the dependencies required for \"compiling,  linking,and emitting functional binaries, libraries, or other code for  the target\", rather than generically in terms of dependencies for  rustc/cargo.  this doesn't change the net effect of the requirements, since other  requirements already stated that the target can't make the rust  toolchain depend on proprietary libraries. however, this should make the  requirements clearer.  clarify documentation about running binaries  the requirement for target documentation talks about \"running tests\",  but tier 3 targets often don't support running the full testsuite, and  in practice the documentation for how to run an individual binary may be  more useful. change \"running tests\" to \"running binaries, or running  tests\".  point to platform-support/ for target-specific documentation  explain that target-specific documentation should appear in a  subdirectory of platform-support, with a link from the target's entry on  the platform-support page.  add a template for target-specific documentation ", "linked_issue_titles": "", "title": "clarifications in the target tier policy"}
{"description": " fixes #127077 fixes #127078 ", "commit_messages": " fix tabs list -> terminal dnd  fix terminal dnd to editor  drag and drop broken from terminal to editor in #125943 because it no longer  accepted the terminal data transfer type and list views changed to drag text instead of  resources.  fixes #127077 ", "linked_issue_titles": " terminal tabs list to editor drag and drop stopped working  terminal drag and hold on a different tab doesn't switch tab anymore ", "title": "terminal drag and drop fixes"}
{"description": " in modules/_datetimemodule.c, the char *timespec and char *specs[] can be made const.  their contents are never modified. in ndarray_get_format in modules/_testbuffer.c, char *fmt can be made const. ", "commit_messages": " make specs and timespec be const  make char *fmt be const ", "linked_issue_titles": "", "title": "const strings in modules/_datetimemodule.c and modules/_testbuffer.c"}
{"description": " currently onnx runtime is doing shape and type inference on both branches of the if operator, regardless of which branch is executing in runtime. this can cause runtime errors in some cases: condition of the if node is based on shape / size of the input then and else branch have different return types this pass is folding an if node and it enables following tests: test_embedding_sequential_1 test_embedding_sequential_2 test_nllloss test_crossentropy test_embedding_bag_1d_per_sample_weights test_embedding_bag_2d_per_sample_weights ", "commit_messages": " add pass  add tests  enable tests  merge  update dtype symbolic  update pass  clang format  update utils file  fix clang_tidy errors  update pass  update pass  clang format  update pass  merge  update pass  update pass  update pass  update pass ", "linked_issue_titles": "", "title": "add a post-pass for if folding"}
{"description": " contribute to lerna by solving an issue where npm is the hard-coded npm client while a user can choose to use yarn issue #1057 ran all the \"yarn test\" options added tests to verify the configuration params i added breaking change (fix or feature that would cause existing functionality to change) - possibly if someone is using yarn as their client but actually they depend on npm running under the hood i have read the contributing document. ", "commit_messages": " support some run commands  publish can now use custom npmclient ", "linked_issue_titles": "", "title": "use npmclient instead of hardcoded npm"}
{"description": " closes #28383 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry the test code is inspired from a similar tests in raiseerror:  valid list_like:  this is my first pull request here and so i have taken all the necessary precautions, also i read the contributing guidelines. not much sure of  black pandas . problem: if columns is not passed a list-like value a substantial decrease in performance was observed. proposed solution: as mentioned in the issue by @willayd that function should raise and hence based on similar situation in the codebase, i have edited the file to raise typeerror. ", "commit_messages": " updated reshape.py to validate columns in get_dummies  added validation for the argument passed to columns  added tests for the column validation  the code is inspired from a similar tests in  raiseerror:  valid list_like:  updated test_reshape.py with pep-8 code rec ", "linked_issue_titles": " pandas get_dummies validate \"columns\" input ", "title": "pandas get_dummies validate columns input"}
{"description": " take care of mocks breaking the recent version of pytest. fixes #52347 tests n/a ", "commit_messages": " fix invalid os.stat mock in tests  fix leaking mock patch in tests  closes #52347 ", "linked_issue_titles": " some unit tests crash on python 2.7 using pytest 4.2.1 ", "title": "bugfix/ fix mocker patch in tests"}
{"description": " #1987 was merged in before i could update the other pytorch examples. this should also close #1960 once it's merged in. ", "commit_messages": " update run_glue to save optimizer and scheduler states, then resume training from a checkpoint  update run_squad to save optimizer and scheduler states, then resume training from a checkpoint  update run_ner to save optimizer and scheduler states, then resume training from a checkpoint  update run_xnli to save optimizer and scheduler states, then resume training from a checkpoint ", "linked_issue_titles": " improving model saving and resuming ", "title": "closes #1960 add saving and resuming functionality for remaining examples"}
{"description": " add norman layout under the minidox keyboard add keymap_extra def for norman layout re-org'ed the modifiers as explained in the readme corrected colour legend for kle that the readme links to my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " norman layout with lower and raise layers working  * add keymap_extra def for norman layout  * re-org'ed the modifiers as explained in the readme  * corrected colour legend for kle that the readme links to  use #pragma once in header file ", "linked_issue_titles": "", "title": "norman layout for the minidox keyboard"}
{"description": " this redirects stderr to /dev/null when the --help or --version arguments are used. it also shortens the help text so it fits within 80 chars. ", "commit_messages": " shorten the spec-directory description  redirect help and version stderr to /dev/null  closes #1580 based on @zcbenz's suggestion. ", "linked_issue_titles": "", "title": "don't show error messages for version and help cli options"}
{"description": " defers some eager ctypes imports to allow most other functionality to work when ctypes is missing. closes #16331. ", "commit_messages": " defer ctypes imports in _dtypes_ctypes module  defer ctypes import in generated _distributor_init.py ", "linked_issue_titles": " make ctypes completely optional on windows ", "title": "make ctypes optional on windows"}
{"description": " as part of #76147, we're no longer going to skip injecting a migrateactions based on properties an associated allocateaction in the same phase. there are still other circumstances when we would not inject a migrateaction (e.g. when the user has already defined one), though. commit by commit is best, imho, but there's not a ton of diff here. ", "commit_messages": " remove this extraneous migrateaction  combine these tests  imho the details don't matter much, and randomness captures the  \"doesn't matter / either way\" components just fine.  reorganize these just a little bit  it reads more clearly to me this way  ignore the allocate action when injecting migrate  get these tests passing  one last round of test cleanup ", "linked_issue_titles": "", "title": "inject migrate action regardless of allocate action"}
{"description": " (my) tests are flaky--this pull request adds a missing dependency. the cli throws an error if /src/images/ doesn't exist (i.e., after running this recipe in an empty hello-world project.) is this okay? ", "commit_messages": " feat(gatsby-recipes): add mdx images recipe  recipes(fix): add gatsby-transformer-remark package to mdx-images recipe ", "linked_issue_titles": "", "title": "remove gatsby-transformer-remark package from mdx-images recipe"}
{"description": " description: this uses a centralized method to update the plex media_player and sensor platforms, reducing calls to the server and refreshing both platforms in sync. done to prepare for a future improvement to the update mechanism. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist ", "commit_messages": " update plex platforms together  remove unnecessary methods ", "linked_issue_titles": "", "title": "central update for plex platforms"}
{"description": " currently, not even the docs home page will load in ie9/10. some have had luck with polyfills, but accessing props in state initialization is an anti-pattern anyways, it should be set in componentwillmount which is a cleaner solution than polyfills or constructors. this issue is also affecting some other components as mentioned by @hhaidar in #4593. i haven't done a full scan yet to take a look. @hhaidar want to follow my lead here and get the rest shored up? pr has tests / docs demo, and is linted. commit and pr titles begin with [componentname], and are in imperative form: \"[component] fix leaky abstraction\". description explains the issue / use-case resolved, and auto-closes the related issue(s) ( ", "commit_messages": " [listitem] move props access for state initialization into componentwillmount, fixes #4042  [radiobuttongroup] move props access to componentwillmount for setting state, fixes #4223 ", "linked_issue_titles": "", "title": "fix error with props access in state assignment for ie9/10"}
{"description": " this renames the n* and n*_ref tuple getters to val* and ref* respectively, and adds mut* getters. it also removes the cloneabletuple and immutabletuple traits. ", "commit_messages": " implement show for 1-12 element tuples  delegate tostr implementation to show for tuples ", "linked_issue_titles": "", "title": "implement show for 1-12 element tuples and improve the std::tuple api"}
{"description": " i hereby agree to the terms of the cla available at:  other add clickhouse-keeper-converter tool which allows converting zookeeper logs and snapshots into clickhouse-keeper snapshot format. ", "commit_messages": " some code for snapshot deserialization  add some functions for data conversion  better  remove unused flag ", "linked_issue_titles": "", "title": "tool for conversion of zookeeper data into clickhouse-keeper snapshot"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. named export  function signature of seq/sequence ", "commit_messages": " the factory variable can be imported as named import.    add override definitions for seq and sequence.   ", "linked_issue_titles": "", "title": "make factory can be used named import / add override definitions for seq and sequence"}
{"description": " no functional change. ", "commit_messages": " clarify event_free() documentation regarding pending/active events  currently it's not clear as to whether \"first make it non-pending and  non-active\" sentence requires user to take some action (e.g. call event_del(),  which event_free() already does internally) or just describes what this  function does from the developer point of view.  fix a few trivial documentation typos ", "linked_issue_titles": "", "title": "clarify event_free() documentation + fix a few typos"}
{"description": " get things in a state where the stdlib build passes as well as tests, but do not actually enable constraint propagation yet. ", "commit_messages": " [constraint solver] disabling the shrink() pass results in new ambiguities.  one expression in this test becomes ambiguous when the shrink() pass is  disabled. enabling the constraint propagation pass disables the shrink  pass.  for now we'll run this with -propagate-constraints explicitly enabled  and with the expected output changed. this is a regression that will  need to be investigated and fixed in the solver.  [constraint solver] tweak test based on using a bit more memory for -propagate-constraints.  this test is trying to confirm that memory usage is independent and that  follow-on expressions do not fail just because of the first failure, and  now we naturally fail on another expression because of the additional  memory used for -propagate-constraints.  tweak the test to bump up the threshold and swap the order of  expressions so that the now-failing expression is first.  [constraint solver] fix memory corruption issue.  we use simplifyconstraint() to activate other constraints, and then  examine those constraints to find related disjunctions. in examining  those active constraints, we were simplifying them in case they  failed (which would allow us to bail out earlier). in doing so, we could  potentially generate new disjunctions when we simplify an unresolved  value member constraint. if we do that, we end up collecting these new  disjunctions as part of the set of related disjunctions, but that's  problematic because as part of exiting the solver scope to roll back  changes we delete these disjunctions from the system.  instead of actually simplifying the active constraints, just collect the  disjunctions and move the active constraints back to the inactive list.  with this change we can build the stdlib. ", "linked_issue_titles": "", "title": "fixup some issues with constraint propagation"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " add portconfig type for detect port first argument  update detect-port version ", "linked_issue_titles": "", "title": "add portconfig type for first argument from default function"}
{"description": " this pr is bringing instruction per cycle for netdata using perf.plugin. component name perf.plugin 1 - set your /etc/netdata/netdata.conf as : perf = yes update every = 1 command options = cycles instructions emulation l1i 2 - compile this branch and take a look at  perf counters section. 3 - access  { \"plugin\": \"perf.plugin\", \"module\": \"hardware\" }, { \"plugin\": \"perf.plugin\", \"module\": \"cache\" }, { \"plugin\": \"perf.plugin\", \"module\": \"software\" }, ", "commit_messages": " ipc_through_perf: add counter for perf.plugin  ipc_through_perf: add new variable used to create charts  ipc_through_perf: add new chart  ipc_through_perf: fix chart name  ipc_through_perf: update title ", "linked_issue_titles": "", "title": "update perf.events and add new charts"}
{"description": " add open_wesocket_close_frame option to swlistenport websocket close frame code in $frame->code websocket close frame reason in $frame->reason use $server->set(array(\"open_websocket_close_frame\"=>true)) to enable the receiving of close frame in websocket server onmessage callback add test for flag open_websocket_close_frame ", "commit_messages": " sync upstream  add \"open_websocket_close_frame\" option for server  add check for \"open_websocket_close_frame\"  set initial value of zreason  sync with unit-test  add test for flag open_websocket_close_frame  change test with new flag and new frame  fix test  unit test ", "linked_issue_titles": "", "title": "add open_websocket_close_frame flag, fix code and reason in websocket frame"}
{"description": " nano v3, gtr or skr pro boards this pr add support for native usb flash drive, using otg and usb host. stm32duino didn't merge my usb host pr yet, so i created new envs pointing to my stm32duino pr. native usb flash drive for marlin. #define usb_flash_drive_support #define use_otg_usb_host #20299 ", "commit_messages": " add usb flash drive support for native usb host otg  add support for gtr and skr pro  not yet ", "linked_issue_titles": "", "title": "usb flash drive support using native usb host + msc"}
{"description": " the following has always been an error because we require a common supertype to exist among the candidate inferences for a particular type parameter: declare function choose<t>(x: t, y: t): t; let a = choose(10, \"abc\");  // error, type '\"abc\"' not assignable to type '10' however, because we currently infer union types when instantiating a generic function type in the context of a non-generic function type, we don't report an error on the following: declare function foo<t>(cb: (x: number, y: string) => t, x: t, y: t): t; let b = foo(choose, \"abc\", 10);  // not an error, but should be with this pr we stop inferring union types in cases such as the above. this is a breaking change. all errors uncovered in the test baselines seem reasonable, but we'll have to see what results from the rwc tests. worst case we can tighten the rules only in --strictfunctiontypes mode. fixes #16107. ", "commit_messages": " stop inferring unions for disjoint callback parameter inferences  update tests  accept new baselines ", "linked_issue_titles": "", "title": "don't infer unions for disjoint callback parameter candidates"}
{"description": " this pr is the first in a series designed to remove painless type completely in favor of java class.  since we aren't supporting generic types, painless type is completely extraneous.  the goal here is to simply the painless code long term and remove anything unnecessary. the def 'marker' class has been added.  any def type in painless will use this marker class instead of object to denote the type is dynamic.  the marker class will be converted to object when byte code is written.  this does not add more code as the painless type currently must be checked to see if it's dynamic anyway.  by using java class consistent comparisons can be made during casting instead of checking for dynamic then checking against class.  this is simpler. this first step replaces painless type with java class for any casting done during compilation.  there should be no behavioural change. ", "commit_messages": " painless: only allow painless type names to be the same as the  equivalent java class or the imported version of the java class.  fix doc error.  add static methods to make creating painless casts obvious as to what is  being boxed/unboxed.  add a marker class for the def type to be used during type analysis.  replace painless type with java class for casting.  remove use of painless type in favor of java class in casting. ", "linked_issue_titles": "", "title": "replace painless type with java class during casts"}
{"description": " trans: when coercing to box<trait> or box<[t]>, leave datum in it's original l-/r-value state. this fixes a subtle issue where temporaries were being allocated (but not necessarily initialized) to the (parent) terminating scope of a match expression; in particular, the code to zero out the temporary emitted by datum.store_to is only attached to the particular match-arm for that temporary, but when going down other arms of the match expression, the temporary may falsely appear to have been initialized, depending on what the stack held at that location, and thus may have its destructor erroneously run at the end of the terminating scope. fix #20055. (there may be a latent bug still remaining in fn into_fat_ptr, but i am so annoyed by the test/run-pass/coerce_match.rs failures that i want to land this now.) ", "commit_messages": " trans: when coercing to box<trait> or box<[t]>, leave datum in its original l-/r-value state.  this fixes a subtle issue where temporaries were being allocated (but  not necessarily initialized) to the (parent) terminating scope of a  match expression; in particular, the code to zero out the temporary  emitted by datum.store_to is only attached to the particular  match-arm for that temporary, but when going down other arms of the  match expression, the temporary may falsely appear to have been  initialized, depending on what the stack held at that location, and  thus may have its destructor erroneously run at the end of the  terminating scope.  test cases to appear in a follow-up commit.  fix #20055  test cases for issue #20055.  note that i have not yet managed to expose any bug in  trans::expr::into_fat_ptr; it would be good to try to do so (or show  that the use of .to_lvalue_datum there is sound). ", "linked_issue_titles": " panic during unit tests (coerce_match) ", "title": "fix trans coercions of box<[t]> and box<trait> in match arms"}
{"description": " fixes errors in typescript 3.9-beta reported in test_types_next we were previously relying on implicit children types (from functioncomponent and forwardrefcomponent) and the false assumption that every transition component implements the same children type. now that our ts types follow closely our (runtime) proptypes the issue was more obvious but typescript < 3.9 did not catch these. ", "commit_messages": " [core] fix incorrect typings regarding transition components and children  revert: use stable ts ", "linked_issue_titles": "", "title": "fix incorrect typings regarding transition components and chilren"}
{"description": " adding nuspec for the package updating update-binver.ps1 to allow passing in the major/minor version instead of getting from release tag creating new build pipeline which takes a major/minor version as a parameter, updates the version in source and builds and signs, generates a nuget package and signs that, then publishes it i haven't tested the actual push command yet, as i'd like to get pr approval before doing so microsoft reviewers: open in codeflow ", "commit_messages": " testing nuget build pipeline  deleting  set up ci with azure pipelines  [skip ci]  signing  build.sourcesdirectory  changing pattern  exact path  sign nuget  x86  minimatch  230012  ready for nuget push  adding push step  updating package name ", "linked_issue_titles": "", "title": "azure pipeline to generate and publish microsoft.windowspackagemanager.utils nuget package"}
{"description": " added five new sites built by bejamas: mambu avenues multicoin capital argent meet flo changed bejamas creator cover. ", "commit_messages": " chore(sites): add new sites built by bejamas  chore(creators): update bejamas cover ", "linked_issue_titles": "", "title": "add new sites built by bejamas to showcase; change bejamas creator cover"}
{"description": " types of changes bug fix fix language.from_disk overwrites the meta.json file. bug fix fix trailing whitespace on morphology features. ", "commit_messages": " fix language.from_disk overwrites the meta.json file.  fix trailing whitespace on morphology features ", "linked_issue_titles": "", "title": "fix trailing whitespace and language.from_disk overwrites"}
{"description": " adds the aws_profile environment variable to the command prompt for the agnoster theme. setting the aws_profile to anything containing production or ending in -prod will set the colour to yellow on red, otherwise it will be black on green ", "commit_messages": " add aws_profile to prompt  remove errant newline  add aws: prefix to segment ", "linked_issue_titles": "", "title": "add aws_profile env var to prompt for agnoster theme"}
{"description": " this pr is mainly to fix the conhost.exe not using the application manifest correctly and the operating system version cannot be detected correctly. related documents can be viewed #2053. this update also brings support for longpath to conhost.exe. closes #2053 cla signed. if not, go over here and sign the cla requires documentation to be updated when directwrite rendering is turned on with usedx, this application cannot display emoji on windows 10 before applying this pr. after applying this pr, it can be displayed normally. ", "commit_messages": " fix conhost detect os version  fix conhost.exe.manifest ", "linked_issue_titles": " usedx option no longer works in conhost ", "title": "fix conhost.exe detect os version"}
{"description": " laser_feature add two menu items under the laser control submenu when laser_feature is defined to fire a laser test pulse. item 1 sets the adjustable fire time from 1 to 999 milli-seconds and the second menu item fires the trigger. a beep will occur if use_buzzer is defined. if pwm is supported it will fire at the power pwm setting that was previously set, if not set it defaults to 80%. no pwm results in full power with the set time duration. supports alignment, testing and calibration of more powerful laser rigs. #define laser_feature #define reprap_discount_smart_controller none ", "commit_messages": " laser percent power  \"adding laser test fire function\" ", "linked_issue_titles": "", "title": "\"add laser test fire function\""}
{"description": " continuation #8807 closes #8807 ", "commit_messages": " improved docstring for the solver parameter of logisticregression  further improve docstring on n_jobs and solver  added warning when self.solver == 'liblinear' & self.n_jobs != -1  in logisticregression  corrected typo: warning => warnings  tst/doc reverse doc and add test ", "linked_issue_titles": "", "title": "improved docstring for the n_jobs parameter of logisticregression"}
{"description": " as people are asking (#3142) how to use the new rnn symbol in mxnet, we provide this simple example as a demo. more importantly, this allow us to identify the use cases and issues we need to address. currently we only have a wrapper to cudnn rnn cell, so it is not available for cpu mode. also we are working to stabilize the interfaces, as you can see from the comments of the demo, there are still many workarounds need to be applied to be able to work nicely with the rest of the mxnet high level apis. @sbodenstein @antinucleon one important issue i need to mention is that currently the lstm cell takes all the parameters as a concatenated big vector. this is not compatible with our initializer architecture. i only verified it is able to run and the perplexity is decreasing. but i did not compare with our old lstm implementation results. ", "commit_messages": " rnn-cell demo (push to server for testing)  a running example with cudnn rnn cell ", "linked_issue_titles": "", "title": "rnn cell demo with ptb lstm language model"}
{"description": " fixes: #21441 ", "commit_messages": " homectl: also acquire \"cheap\" passwords for homectl update/passwd  in 57bb9bcba5563c040ee0c41f58e3730a006a8de2 support was added to read  \"cheap\" passwords from env vars and stuff before issuing the first  operation, instead of waiting for it until the first operation failed.  this was added for most verbs of \"homectl\", but two were left out:  update + passwd. add it there too.  homework: fix message typo  homework: don't try to shift uidmap for already activated home areas  when we want to operate on an already activated home area we so far  tried to reapply the uidmapping logic. we shouldn't do that, it's  already applied after all.  we only want to apply this for newly activated home areas. hence check  for the right homesetupflags flag for it home_setup_already_activated.  the patch is actually in theory a two-liner. except that so far we don#t  pass the homesetupflags flags down all necessary functions where the  uidmap stuff will eventually run. hence this larger than intended  commit.  homework: also apply uid shifting when changing passwords/resizing/updating home areas  this adds uidmap shifting also when resizing/updating/changing  passwords. prviously i thought we didn't have to, because the user is  not going to access the uidmap if we only quickly activate the home  area. but this thinking is wrong, because the three operations will  result in an update ~/.identity fie to be written, and we should do that  with uidmap applied, so that its ownership maps down to nobody below as  intended.  fixes: #21441  homework: fix a bad error propagation  homework: add debug log message whenever we applied a uidmap to a mount ", "linked_issue_titles": " spurious fails in test-46-homed ", "title": "homed uidmap (and other) fixes"}
{"description": " combine prs #10200 #10206 #10209 #10212 #10215 #10217 to 2.1 minor edits to the reference of various cleos commands select one: select any that apply: ", "commit_messages": " applied new command reference template  applied revised reference template  applied command ref template  applied new reference template  applied reference template  applied reference template  fix broken link and other edits on cleos create account ref :doc  minor edits on cleos create key ref :doc  minor edits on cleos create account ref :doc  minor edits on cleos get transaction ref :doc  minor edits on cleos wallet import ref :doc  minor edits on cleos wallet keys ref :doc  minor edits on cleos net connect ref :doc  minor edits on cleos net disconnect ref :doc  minor edits on cleos net peers ref :doc  minor edits on cleos net status ref :doc ", "linked_issue_titles": "", "title": "update reference for various cleos commands - 2.1"}
{"description": " current way of running testlightgbm.exe on windows doesn't return actual status code. take a look at the logs in master: ...  proposed call in this pr makes master windows job red. looks like appleclang doesn't have leak sanitizer. so set sanitizers to only \"address;undefined\" for macos. -- the c compiler identification is appleclang 12.0.0.12000032 -- the cxx compiler identification is appleclang 12.0.0.12000032 ... clang: error: unsupported option '-fsanitize=leak' for target 'x86_64-apple-darwin19.6.0' it seems that the clang/llvm shipped by apple does not have -fsanitize=leak support.   msvc is just about getting support of asan    current support is limited to x86 and x64 on windows 10. send us feedback on what you'd like to see in future releases. your feedback helps us prioritize other sanitizers for the future, such as /fsanitize=thread, /fsanitize=leak, /fsanitize=memory, /fsanitize=undefined, or /fsanitize=hwaddress. you can report bugs here if you run into issues.  ... cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\_deps\\googletest-build\\googletest\\gtest.vcxproj] gtest-all.cc cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\_deps\\googletest-build\\googletest\\gtest.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\_deps\\googletest-build\\googletest\\gtest.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\_deps\\googletest-build\\googletest\\gtest.vcxproj] gtest.vcxproj -> d:\\a\\1\\s\\build\\lib\\debug\\gtestd.lib building custom rule d:/a/1/s/cmakelists.txt cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] test_chunked_array.cpp cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] test_common.cpp cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=address' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=leak' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] cl : command line warning d9002: ignoring unknown option '-fsanitize=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] test_main.cpp cl : command line warning d9002: ignoring unknown option '-fno-sanitize-recover=undefined' [d:\\a\\1\\s\\build\\testlightgbm.vcxproj] ... i had to remove the following test because it fails with many setups os + compiler 2^971 * (2^53 - 1 + 1/2) : the smallest number resolving to inf @cyfdecyf could you please take a look at this? for example, it fails on windows + msvc 19.16.27045.0; ubuntu focal + clang 10.0.0. tested with swapped compilers: everything is ok. tested thread sanitizer: linux is ok, macos fails - issue created #4331. ", "commit_messages": " run cpp tests with sanitizers  re-trigger ci  continue ", "linked_issue_titles": "", "title": "run cpp tests with sanitizers on linux and macos"}
{"description": " #1913 into 1.1 branch ", "commit_messages": " fix link extractor tests for non-ascii characters from latin1 document  url path component should use utf-8 before percent-encoding (that's what  browsers do when you open scrapy/tests/sample_data/link_extractor/linkextractor_latin1.html  and follow the links)  this matches current w3lib v1.14.1  add link extractor test for non-ascii characters in query part of url ", "linked_issue_titles": "", "title": "fix link extractor tests for non-ascii characters from latin1 document (pr #1913)"}
{"description": " this is a 10x improvement for searching for characters. this also contains the patches from #46713 . feel free to land both separately or together.  r? @bluss fixes #46693 ", "commit_messages": " move rust memchr impl to libcore  use memchr in [u8]::contains  support 16 bit platforms  remove the unused ascii_only field in chareqsearcher  split out char searcher from multicharsearcher  move charsearcher to its own section in the file  fill in forward searcher impl for char ", "linked_issue_titles": " str::find(char) is slower than it ought ot be ", "title": "use memchr for str::find(char)"}
{"description": " /area kubeadm /sig cluster-lifecycle milestone 1.23 kubernetes/kubeadm#2537 follow up of #103063 part of kubernetes/kubeadm#2046 action required: kubeadm: remove the deprecated flag --experimental-patches for the init|join|upgrade commands. the flag --patches is no longer allowed in a mixture with the flag --config. please use the kubeadm configuration for setting patches for a node using {init|join}configuration.patches. ", "commit_messages": " kubeadm: remove deprecated --experimental-patches  kubeadm: disallow the mixture of --config and --patches ", "linked_issue_titles": "", "title": "disallow the mixture of --config and --patches & remove deprecated --experimental-patches"}
{"description": " continues and closes #14337. addresses comments in #14337: add parameter to affinitypropagation class, add test, add what's new entry. this is the last open pr from the 2019 scipy sprint. ", "commit_messages": " added value checks and random state parameter to method  changed default parameter to none instead of 0  added numpy randomstate to the check  replaced inline validation with check_random_state from utils and pointed at glossery  needed a different default parameter to pass the default way this has been working in the past  updated to conform with flake8 stds  sync with upstream.  add random_state to affinitypropagation class.  add test.  add what's new entry and versionadded directive. ", "linked_issue_titles": "", "title": "add random_state parameter to affinitypropagation"}
{"description": " also upgraded to the latest version of the pivot table library. closes #772 and #334. ", "commit_messages": " close #772: upgrade to latest pivottable.js lib  feature: pivots are now regular visualizations that can be *saved*. ", "linked_issue_titles": "", "title": "pivot tables are now regular visualizations that can be saved"}
{"description": " not much to say that's not already contained in the title. pr checklist applies to #1972 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx info on pull request added members and methods to support this operation. the shortcut keys, variable and method names and code readability may require some feedback. validation steps performed tested with a large grid layout. unit tests passed. ", "commit_messages": " added an alt key hook  refactor a block of code into a method  again refactored existing code  apparently win+alt does not reach fancyzones  using ctrl+alt instead of win+alt for now  it works  fixed vd change  remove unused member  fix compilation error  enable shrinking ", "linked_issue_titles": "", "title": "use ctrl+win+alt+arrows to expand/shrink windows to adjacent zones"}
{"description": " please point out the problem, i'll fix it as soon as possible ", "commit_messages": " fix bug stop stopspan when not createspan  fix bug stop stopspan when not createspan  change the agent log level to millisecond  add the function of the specified-agent-config  merge skywalking master to mine ", "linked_issue_titles": "", "title": "add the function of the specified agent config"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. add it to notneededpackages.json. ", "commit_messages": " feat(theme-ui): remove theme-ui package  theme-ui provides its own types as of v0.6.0  (  feat(theme-ui__components): remove theme-ui__components package  @theme-ui/components provides its own types as of v0.6.0  ( ", "linked_issue_titles": "", "title": "remove theme-ui and theme-ui__components typings (no longer needed)"}
{"description": " just some improvements i made in the course of my retroplayer work. the bug fixes here don't affect krypton, so they don't need to be backported. for when master is branched for v18 development. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) ", "commit_messages": " caddonsdirectory: improve code clarity in getscriptsandplugins()  caddondirectory: don't clear existing items from item list parameter  binaryaddoncache: add function to get add-on by id and type  binaryaddoncache: optimize update() function  dvdcodecutils: fix conversion to av_malloc missed by 09acfb8  dvdcodecutils: fix buffer overflow if height is odd  stringutils: template-ize join() to support more container types  playmedia() builtin: don't clear video playlist if item is not video ", "linked_issue_titles": "", "title": "fixes and code improvements from game branch"}
{"description": " previously, invalid attributes were silently accepted and ignored. ", "commit_messages": " [parse/sema] diagnose invalid attributes for paramdecl  previously, invalid attributes were silently accepted and ignored.    [parse/sema] diagnose invalid attributes for generictypeparamdecl  previously, invalid attributes were silently accepted and ignored.   ", "linked_issue_titles": "", "title": "diagnose invalid attributes for paramdecl and generictypeparamdecl"}
{"description": " fixes #17618 padding is only added to the \"left\" and \"bottom\" sides to bring total area to 48 by 48.  this is done prior to the rotation so it works for both rtl and ltr. ", "commit_messages": " increase total area of text selection handle to 48 by 48  remove extra param ", "linked_issue_titles": " selection handle touch target is too small in textfields. ", "title": "increase text handle size to 48 by 48"}
{"description": " solves #2544. unfortunately, coretemp sysctls are quite heavy calls. ", "commit_messages": " add intel cpu temperature chart to freebsd plugin  correct cycle for rrddim in cpu temperature chart  fix data type and mib for coretemp sysctl in freebsd plugin  limit sprintf usage in coretemp module in freebsd plugin ", "linked_issue_titles": "", "title": "add cpu temperature chart to freebsd plugin"}
{"description": " added a new job in the alignments tool which tells you which faces are in the faces folder, but aren't found in the alignments file. this is useful for me because my alignments file is saved every 10 frames it goes through. and if it gets stopped, i want to delete the pngs it made that aren't saved in the alignments file. ", "commit_messages": " add cli option  add logic ", "linked_issue_titles": "", "title": "remove leftover faces alignments job"}
{"description": " update prometheus to 2.13.1 update prometheus operator to 0.34.0 remove prometheusoperator.crdapigroup. this experimental arg was briefly available and has not been working since 0.26.0. it is no longer available on the prometheus-operator container. dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " update core components  remove unsupported crdapigroup param  this parameter already does not work and has not for many versions of  the operator, thus removing it is not a breaking change ", "linked_issue_titles": "", "title": "up versions of operator, prometheus"}
{"description": " replaced assert_raises and assert_raises_regex with pytest.raises context manager. related to #14216 ", "commit_messages": " fix assert_raises and assert_raises_regex in test_locally_linear.py  fix assert_raises and assert_raises_regex in test_spectral_embedding.py  fix assert_raises and assert_raises_regex in test_mds.py  fix assert_raises and assert_raises_regex in test_t_sne.py ", "linked_issue_titles": "", "title": "maint:fix assert raises in sklearn/manifold/tests/"}
{"description": " when possible i simply cherry-picked fixes from the master branch, but sometimes i had to redo them manually. here i started with activesupport, i'm not sure i eliminated them all yet because the test suite is segfaulting on my machine. this is still a work in progress, but opening a pr give me a ci run which is helpful. ", "commit_messages": " :warning: calling uri.open via kernel#open is deprecated, call uri.open directly  introduce keyword arguments for some as::cache methods  since rediscachestore#write_entry takes kwargs, we needed to kwargsify all these methods  in order to eliminate ruby 2.7 warnings.  it's a little bit bigger patch than i expected, but it doesn't warn on ruby 3,  and it doesn't introduce any incompatibility on loder rubies, so it may not be a bad thing anyway.  :number is not a keyword argument  i18n.translate takes kwargs options ", "linked_issue_titles": "", "title": "fix many ruby 2.7 warnings for the 6.0 stable branch"}
{"description": " parse ': class' in a protocol inheritance clause identically to ': anyobject'. this allows us to simplify some code. it also results in cleaner printing of generated interfaces. fixes ", "commit_messages": " parse: simpler handling of 'class' in protocol inheritance list  instead of treating this as its own thing, just parse it as if  the user wrote 'anyobject'.  astprinter: don't print redundant 'where self : anyobject' ", "linked_issue_titles": "", "title": "fix printing of class-constrained protocols"}
{"description": " a board can now define the following linker symbols to configure its flash storage layout: _micropy_hw_internal_flash_storage_start _micropy_hw_internal_flash_storage_end _micropy_hw_internal_flash_storage_ram_cache_start _micropy_hw_internal_flash_storage_ram_cache_end and optionally have a second flash segment by configuring micropy_hw_enable_internal_flash_storage_segment2 to 1 and defining: _micropy_hw_internal_flash_storage2_start _micropy_hw_internal_flash_storage2_end f413, f439, h743, l4xx and wb55 have been converted to this new scheme. ", "commit_messages": " stm32/flashbdev: support generic flash storage config via link symbols.  a board can now define the following linker symbols to configure its flash  storage layout:  _micropy_hw_internal_flash_storage_start  _micropy_hw_internal_flash_storage_end  _micropy_hw_internal_flash_storage_ram_cache_start  _micropy_hw_internal_flash_storage_ram_cache_end  and optionally have a second flash segment by configuring  micropy_hw_enable_internal_flash_storage_segment2 to 1 and defining:  _micropy_hw_internal_flash_storage2_start  _micropy_hw_internal_flash_storage2_end  stm32/boards: convert f413,f439,h743,l4xx,wb55 to new flash fs config. ", "linked_issue_titles": "", "title": "support generic flash storage config via linker symbols"}
{"description": " the core issue seems to be with skip_child. the skip_child function makes some assumption regarding the state you are in. in particular, it seems that you cannot be right before a key so that the first step of skip_child is to bring you to a key. that's never a problem when the key you are searching for is found. when the key you are searching found is not found, then it is possible that you may end up just before a key. by convention, keys are at the level of the object, so the code in the main branch and in the 0.9.x is wrong in such cases because skip_child will encounter a key, it will decrement the depth and conclude that it is back in the parent. this is bad. this is not the nicest fix in the world and it may have small negative impact on performance but i am preoccupied by patching 0.9.x as soon as possible. a better solution might be to ensure that when a key is not found, we are never right before a key. i had implemented that (it is not hard), but it is more invasive. this patch here is very small. fixes  #1521 ", "commit_messages": " reduction of the missing-key bug.  adding the other test cases.  really simple fix for 1529  nicer code. ", "linked_issue_titles": " simdjson 0.9.x ondemand parser fails on dynamic document (possible regression) [fixed in 0.9.3, unfixed in main branch] ", "title": "my third attempt at fixing issue 1521 (not being merged due to performance concerns)"}
{"description": " a previous commit fixed the runtime code, this pr fixes the compatibility issues for the unit tests. ", "commit_messages": " make tests compatible with python 3  * change dictionnaries iteritems() to items()  remove six dependency for dictionnaries iterators ", "linked_issue_titles": "", "title": "make object_detection dictionaries compatible with python3"}
{"description": " set a weekly ci running every sunday night to all models from onnx model zoo with latest onnx.checker and onnx.shape_inference motiviation to enhance the robustness of onnx, add more tests. ", "commit_messages": " add test_model_zoo and weekly ci  change to use windows  fix syntax error ", "linked_issue_titles": "", "title": "test all models from onnx model zoo with latest onnx.checker"}
{"description": " @mourner @danzel simplified version of my previous guide update. publishing plugins on npm now has its own section and the amd/commonjs section is trimmed down quite heavily and focuses around a single piece of sample code. ", "commit_messages": " seperate npm and module loader info. condense module loader section  fix merge conflict  fix spelling ", "linked_issue_titles": "", "title": "module loaders + publishing on npm"}
{"description": " as per request in #4934, new option addition in settings under texturepacker to specify the array of interpolation modes per scale factor. no breaking changes in the api, and fully backwards-compatible assuming bicubic (which was the default) in case nothing is being specified. contributor agreement has been signed and emailed. ", "commit_messages": " fix #4934: add texturepacker interpolation option to settings  document texturepacker settings change in changes ", "linked_issue_titles": "", "title": "option in texturepacker.settings to specify the interpolationmode when scaling"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: see  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. the full diff is messy as i reorganized the types to match the order of ", "commit_messages": " updated react-slider types to 1.1  reorganized types to match react-slider doc ", "linked_issue_titles": "", "title": "update react-slider types to 1.1"}
{"description": " unit tests are always killed because out of memory. this pr reduces memory footprint and skips some heavy tests. also support pytorch1.9 and python3.9 in this pr. skip tests of building all configs. reduce base_channels of resnet in most of the tests. reduce the input size. delete some redundant tests. ", "commit_messages": " fix ci  fix ci  fix ci  fix ci  fix ci  fix ci  fix ci  fix ci  fix ci  fix ci ", "linked_issue_titles": "", "title": "fix ci out of memory & add pytorch1.9 python3.9 unit tests"}
{"description": " i tried to use prophetnet with seq2seqtrainer, but it failed. the error message told me: this is because the collator uses prepare_seq2seq_batch() in _encode(), but prepare_seq2seq_batch() is not implemented in prophetnet tokenizer. i've gotten kind advices in the huggingface forum, and implemented the function.  the modifications are as below: add prepare_seq2seq_batch() in /src/transformers/tokenization_prophetnet.py. to use .view in loss computation in seq2seqtrainer, i add a part where it is confirmed that logits is contiguous in /src/transformers/modeling_prophetnet.py. i've checked it works on cpu and gpu as below: !python finetune_trainer.py \\ --learning_rate=3e-5 \\ --do_train --do_eval --evaluate_during_training \\ --max_source_length 511 \\ --per_device_train_batch_size 2 \\ --predict_with_generate \\ --n_train 300 \\ --n_val 100 \\ --model_name_or_path microsoft/prophetnet-large-uncased \\ --data_dir $xsum_dir \\ --output_dir tmp_gpu \\ --overwrite_output_dir although the pretrained_positional_embeddings_sizes is 512,  if --max_source_lenght is set to 512, cuda error occurs. i'm sorry, but i have not been able to identify the cause of this. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link to the it if that's the case.  documentation guidelines, and here are tips on formatting docstrings.  i'm sorry, i misunderstood what is being asked here.  now i understood that the ./tests/  code is needed. i'm working on this, but i'm getting errors in formatting etc. and using black won't fix it. i added related content to the test_tokenization_prophetnet.py. i changed the environment and made it work again according to the instructions, and it seems that formatting with black works appropriately. @sshleifer thank you for kindly answering my questions in the forum! ", "commit_messages": " simply insert t5tokenizer's prepare_seq2seq_batch  update/add some 'import'  fix runtimeerror caused by '.view'  moves .view related error avoidance from seq2seq_trainer to inside prophetnet ", "linked_issue_titles": "", "title": "adding the prepare_seq2seq_batch function to prophetnet"}
{"description": " this pr adds alerts permission group with alerts:read and alerts:write. these scopes are added to all roles within the app except owners and also added to the relevant issue alert and metric alert endpoints. eventually we will have a setting to turn on alerts:write for owners there are also some frontend changes to enable buttons which were previously behind projects:write ", "commit_messages": " members can now edit alerts  members can now edit alerts  small change to project scopes ", "linked_issue_titles": "", "title": "add new scopes for editing/viewing alert rules"}
{"description": " what did you implement: closes #3142 the aws::lambda::eventsourcemapping resource was being created with wrong the dependson attribute if custom roles were defined using a string to reference a logical role name elsewhere defined in the serverless.yml.  the eventsourcemapping resource was previously only checking for roles defined via a direct arn or the fn::getatt syntax.  it did not support referencing a role's name directly (i.e.. role: mydefaultrole as documented here) the result of this is that the eventsourcemapping resource would set the dependson to the default iamrolelambdaexecution role.  if custom roles were used for all functions then the iamrolelambdaexecution role would not exist in the compiled cloud formation and the deploy would fail with template format error: unresolved resource dependencies [iampolicylambdaexecution] in the resources block of the template how did you implement it: this builds upon #3083 as it enables the custom role to be referenced directly without using the fn::getatt syntax. how can we verify it: deploy any serverless.yml with an event stream using only functions with custom roles (e.g. the sample in #3142 ) todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " add failing test  fix failing test  add additional test for custom role at provider  add type check for a string  fix lint issues ", "linked_issue_titles": " serverless fails to deploy service with a kinesis stream event: unresolved resource dependencies [iampolicylambdaexecution] in the resources block of the template ", "title": "fix event streams when functions have direct reference to custom roles"}
{"description": " two patches that improve the c code quality. the first is important, as it fixes a few calls through function pointers of the wrong type (which cause undefined behavior). the second just shuts up the build by introducing a few casts and removing some unused variables. ", "commit_messages": " fix: wrong function types in ufunc_object.c  assign_reduce_identity_{zero,one} were treated as  pyarray_assignreduceidentityfunc, but that type has  an extra void* argument. added the argument.  fix: remove unused variables and add casts  makes the build complete with fewer warnings. ", "linked_issue_titles": "", "title": "call through wrong function pointer type + minor stuff"}
{"description": " fixes #91290 ", "commit_messages": " scaffold out link provider proposed api  part of #91290  get link providers passing all the way through to the renderer  register via link manager  handle link on exthost  update ", "linked_issue_titles": " allow extensions to contribute links to the terminal (aka link providers) ", "title": "proposed terminal link provider api"}
{"description": " lots of changes here but i wanted to get gles closer to gl. i hope we can all test this and shove it in asap :) i've tested on gbm be aware that to use clinuxrenderergles you need to use sw decoding/rendering or use vaapi this brings all the goodies present with #13428 #13481 #13507 #13968 #13973 #14295 android amlogic ios vaapi ", "commit_messages": " [gles] videoplayer: rewrite yuv - rgb conversion  linuxrenderergles: cleanup confusing log messages ", "linked_issue_titles": "", "title": "yuv2rgb rework, tonemapping, and other cleanup"}
{"description": " relands #47616, but as an opt-in change to allow developers to migrate to the fixed version. the original pr caused golden tests to fail since the snackbar's offset was updated. before fix after fix set all instances of scaffold.shouldsnackbarignorefabrect to true after this pr is merged. fix all failing tests. there are likely two main types: a) fix all golden tests to expect the new change. b) fix any widget tests that expect the snackbar to appear higher than it should. the difference should simply be the size of the floating action button's rect. once scaffold.shouldsnackbarignorefabrect is set to true by default (in a subsequent pr), remove the parameter from all instances of scaffold. related issues addresses #47202 addresses #43716 i added the following tests: same tests as original pr, but with the shouldsnackbarignorefabrect flag turned on. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc and migration guide: ", "commit_messages": " renamed some tests in snack_bar_test.dart  improved one test from snack_bar_test.dart  now the test checks certain position y of fab  fixed issue where snack bar was higher then should be  added tests for testing height of snackbar.  moved test 'floating snackbar is positioned above floatingactionbutton' to group 'snackbar position'  improved test by removing padding details, and renaming.  moved test \"snackbar bottom padding is not consumed by viewinsets\" to group \"snackbar position\"  and improved test for testing with universal behavior  add soft breaking change flag ", "linked_issue_titles": "", "title": "snackbarbehavior.floating offset fix - soft breaking change"}
{"description": " this is an alternative fix for #12180. ", "commit_messages": " tty-ask-password: copy argv[] before forking child  another fix in style of bd169c2be0fbdaf6eb2ea7951e650d5e5983fbf6.  let's also avoid strjoina() in a loop (i.e. stack allocation). while in  this specific caseone could get away with it (since we'd immediately  afterwards leave the loop) it's still ugly, and every static checker  would be totally within its rights to complain.  also, let's simplify things by not relying on argc, since it's redundant  anyway, and it's nicer to just treat things as null terminated strv  array.  fixes: #12180  tty-ask-password: drop redundant local variable  tty-ask-password: no need to initialize something already nul initialized to nul  tty-ask-password: simplify signal handler installation  tty-ask-password: re-break comment ", "linked_issue_titles": "", "title": "let's copy argv[] before forking"}
{"description": " fixes  #66304 r? @gilescope shows both the actual as well as the expected panic value when a test with should_panic(expected=...) fails. this makes should_panic more consistent with assert_eq. i am not sure whether printing the any::type_id() is useful, is there something better that we could print for non-string panic values? ", "commit_messages": " print a more useful error message on should_panic mismatch  replace some asserts with assert_eq for better error readability ", "linked_issue_titles": " better error messages for #[should_panic] tests with expected strings ", "title": "more useful test error messages on should_panic(expected=...) mismatch"}
{"description": " ondidchangeselectionrange and ondidchangecursorposition passed different data to their call backs. this makes them consistent. ", "commit_messages": " add cursor to ondidchangecursorposition event object  only pass event to the editor  add cursor to the docs  ondidchangeselectionrange emits object with ranges + selection  update ondidchangeselectionrange doc string  update doc string in selection::ondidchangerange  update cursor::ondidchangeposition doc string ", "linked_issue_titles": "", "title": "make cursor / selection events consistent"}
{"description": " here are the changes again with the revisions added in. ", "commit_messages": " playing catchup  adding sections, and fixing grammar:  added bodhi linux, as well as a how does a person contribute section.  also ran through and fixed grammar.  fixing ordering.  didn't fix ordering the first time. also forgot to mention in previous commit that i added a few github links to previously listed software, since they weren't listed.  i also previously fixed the wording on some of the softwares from \"best\" to an actual description of what they do.  capitalization and official client utilities section  added pea utilities and pea extractor and pihole  also added more open source repositories for programs.  fixing personal language,  and adding more in-depth descriptions.  grammar is hard  grammar  added how to contribute to toc  added to table of contents  grammar and toc change  fixing linking  table of contents links didn't function, now they do.  added nomacs image viewer  adding suggested changes:  cleaned up from before.  aligning to master: ", "linked_issue_titles": "", "title": "more grammar, more programs 2:"}
{"description": " caches vectors in the class and uses a new helper to opportunistically shrink/grow as viewport sizes change in order to save performance on alloc/free of commonly used vectors. scratches a perf itch. i work here. wil tests added no add'l doc. am core contributor. two fixes: for outputting lots of text, the base renderer class spent a lot of time allocating and freeing and reallocating the cluster vector that adapts the text buffer information into render clusters. i've now cached this vector in the base render class itself and i shrink/grow it based on the viewport update that happens at the top of every frame. to prevent too much thrashing in the downward/shrink direction, i wrote the til::manage_vector helper that contains a threshold to only shrink if it asks for small enough of a size relative to the existing one. i used 80% of the existing size as the threshold for this one. for outputting lots of changing colors, the vt graphics output engine spent a bunch of time allocating and reallocating the vector for graphicsoptions. this one doesn't really have a predictable size, but i never expect it to get extremely big. so i just held it in the base class. ran the til unit test checked render cluster vector time before/after against big.txt from #1064 checked vt graphics output vector time before/after against cacafire case before after big.txt cacafire ", "commit_messages": " cache the vector for clusters and manage its size based on the viewport to save a ton of alloc/dealloc work.  hold vt graphics options vector in class to save alloc/realloc/free time. ", "linked_issue_titles": "", "title": "improve perf by avoiding vector reallocation in renderer clusters and vt output graphics options"}
{"description": " most pager, by default, does not support control characters. so, the idea is to add a test after the set of pager to change it to less -r so control chars can be interpreted first, test for pager, than bat, than change. ", "commit_messages": " added support of most  only test if bat exists  faster this way ", "linked_issue_titles": "", "title": "adding support for most pager"}
{"description": " this adds getclassloader permission for ingest-attachment and mapper-attachments plugins. i will backport the mapper attachment fix to 2.3. closes #16864 ", "commit_messages": " can not extract text from office documents (.docx extension)  add rest test for:  * .doc  * .docx  the later fails with:    ==> test info: seed=db93397128b876d4; jvm=1; suite=1  suite: org.elasticsearch.ingest.attachment.ingestattachmentrestit  2> reproduce with: gradle :plugins:ingest-attachment:integtest -dtests.seed=db93397128b876d4 -dtests.class=org.elasticsearch.ingest.attachment.ingestattachmentrestit -dtests.method=\"test {yaml=ingest_attachment/30_files_supported/test ingest attachment processor with .docx file}\" -des.logger.level=warn -dtests.security.manager=true -dtests.locale=bg -dtests.timezone=europe/athens  failure 4.53s | ingestattachmentrestit.test {yaml=ingest_attachment/30_files_supported/test ingest attachment processor with .docx file} <<< failures!  > throwable #1: java.lang.assertionerror: expected [2xx] status code but api [index] returned [400 bad request] [{\"error\":{\"root_cause\":[{\"type\":\"parse_exception\",\"reason\":\"error parsing document in field [field1]\"}],\"type\":\"parse_exception\",\"reason\":\"error parsing document in field [field1]\",\"caused_by\":{\"type\":\"tika_exception\",\"reason\":\"unexpected runtimeexception from org.apache.tika.parser.microsoft.ooxml.ooxmlparser@7f85baa5\",\"caused_by\":{\"type\":\"illegal_state_exception\",\"reason\":\"access denied (\\\"java.lang.runtimepermission\\\" \\\"getclassloader\\\")\",\"caused_by\":{\"type\":\"access_control_exception\",\"reason\":\"access denied (\\\"java.lang.runtimepermission\\\" \\\"getclassloader\\\")\"}}}},\"status\":400}]  >    at __randomizedtesting.seedinfo.seed([db93397128b876d4:53c706ab86441b2c]:0)  >    at org.elasticsearch.test.rest.section.dosection.execute(dosection.java:107)  >    at org.elasticsearch.test.rest.esresttestcase.test(esresttestcase.java:395)  >    at java.lang.thread.run(thread.java:745)    related to #16864  add getclassloader perm for tika in ingest  add doc and docx rest test to mapper attachment along with  getclassloader permission ", "linked_issue_titles": " can not extract text from office documents (`.docx` extension) ", "title": "fix attachments plugins with docx"}
{"description": " currently, when an agent takes a new omnichannel request(manual selection routing method), the agent is redirected from the room preview to home template, which makes a bad user experience. to fix this wrong behavior, an agent will be redirected to the home template just in case they are no longer allowed to access the room, for instance, when another agent takes the chat. ", "commit_messages": " fix the ux when an agent takes a new chat.  remove unnecessary parentheses. ", "linked_issue_titles": "", "title": "keeps the agent in the room after accepting a new omnichannel request"}
{"description": " fix the bug of simple_test with proposals remove the redundant codes in fast_rcnn ", "commit_messages": " fix wrong keyword argument 'nms_cfg' in htc  fix wrong keyword argument 'nms_cfg' in htc  fix the bug of simple_test with proposals  remove the redundant codes in fast_rcnn ", "linked_issue_titles": "", "title": "fix bug of simple_test with proposals"}
{"description": " part 8. we have an in-house rule to compare explicitly against false instead of using the logical not operator (!). however, this hasn't historically been enforced, meaning that there are many violations in the source at present. we now have a checkstyle rule that can detect these cases, but before we can turn it on, we need to fix the existing violations. this is being done over a series of prs, since there are a lot to fix. ", "commit_messages": " more fixes in libs/  fixes in x-pack/plugin/sql  fixes in server action/admin/indices  fixes in client and server  fixes in server  fixes in server  fixes in server  fixes in server  fixes in server  fixes in server  more fixes ", "linked_issue_titles": "", "title": "replace not operator with explicit false check - part 8"}
{"description": " cherry pick #36587, #36662, #36908, and #36917 into stable-2.5 tower_credential.py ansible version 2.5 ", "commit_messages": " fix credentials for tower api v2  (cherry picked from commit 640749d54f727c1408512f064564056735484b6b)  tower cred: implement credential /api/v1/ kind compatability  (cherry picked from commit 9cb4b70e279e25231a8770b817112b744893b125)  tower cred: filter user name lookup by the proper key  (cherry picked from commit cd6855275e42a564201d93810b89ba7e885d1e06)  tower cred: update kind options in documentation  (cherry picked from commit 8a41233202e01700459735a8dd67502e512261d5)  tower cred: support credential kind/type for /api/v1/ and /api/v2/ (#36662)  older versions of tower (3.1) don't have a concept of credentialtypes  (this was introduced in tower 3.2).  this change detects older versions  of pre-3.2 tower-cli that *only* support the deprecated kind  attribute.  (cherry picked from commit 641f8b4ef6a706f8e45a317445b30eadf3e3f5ba)  add changelog fragment ", "linked_issue_titles": "", "title": "cherry pick tower credential fixes to stable-2.5"}
{"description": " pyenv related docs - macos big sur pyenv issue can be fixed by adding commands into ~/.zshrc file having airflow_home and source code in ${home} can lead to disastrous effect of deleting all the file in the airflow folder. added a warning message to prevent deletion read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " breeze setup-autocomplete zshrc reload  pyenv issue fix -macos big sur  warning message about airflow_home and source code in same path -- initialize-local-virtualenv command  pyenv issue fix -macos big sur  warning message about airflow_home and source code in same path -- initialize-local-virtualenv command ", "linked_issue_titles": "", "title": "pyenv related docs added, warning message in breeze initialize-local-virtualenv command"}
{"description": " also, deprecate getoccurrences and replace it with an appropriate getdocumenthighlights api that matches the roslyn api and properly handles highlights across multiple files. ", "commit_messages": " extract code for getting syntactic document highlights into its own function.  get semantic document highlights as well through the new api.  no need to tweak spans in syntactic highlights.  use the filename that is in scope. ", "linked_issue_titles": "", "title": "ensure that getoccurrences not return items not in the file asked for."}
{"description": " fixes #12181 mimics native behaviour. android unaffected. ", "commit_messages": " add a minimum distance that needs breaking on ios each time scrolls stopped.  testing and tests  tweak docs ", "linked_issue_titles": " after drag and stop, finger lift can still cause a small position shift ", "title": "let ios have a minimum scroll movement threshold to break before motion starts"}
{"description": "", "commit_messages": " meta: add lagom_unsupported helper function to serenity.sh  meta: don't depend on toolchain for lagom target in serenity.sh  - only call ensure_toolchain for non-lagom targets  - use host addr2line, we can't expect the i686 toolchain's addr2line to  support the host's binary executable format  - don't export serenity_arch and toolchain_dir, don't need them anymore  meta: make 'serenity.sh run lagom' run lagom executables  running the tests will be moved to a separate test command which can  then leverage the availability of different targets and run either unit  tests on the host or the image in qemu in self-test mode. :^) ", "linked_issue_titles": "", "title": "serenity.sh tweaks and better lagom support"}
{"description": " docstring lint errors fixed. ", "commit_messages": " update model.py  fixed lint error: one-line docstring summary should be followed by a blank line  fixed lint errors  one-line docstring summary should be followed by a blank line  and 2 spaces for inline comments  update model.py  fixed further lint errors  update utils.py  fixed further lint errors  update utils.py  update model.py ", "linked_issue_titles": "", "title": "fixed lint errors for docstring affecting sketch_rnn"}
{"description": " issue: #10167 exposed sketchpickerprops.presetcolors for the color control component. stop click event propagation at the popup level, to give user the chance to click on the hex input box and edit the color value this way. one side-effect of this change is that now the user will have to click on the color control button to close the color picker, instead of closing it automatically per mouse click. is this testable with jest or chromatic screenshots? no. does this need a new example in the kitchen sink apps? no. does this need an update to the documentation? yes, included in this pr. ", "commit_messages": " expose sketchpickerprops.presetcolors for the color control component  of addon:controls.  add onkeydown and onblur handler for the color picker.  add documentation for  option of color control. ", "linked_issue_titles": "", "title": "expose presetcolors for the color control"}
{"description": " i've hit cases where pbuf_alloc() returns a nullptr.  in the original code, it would happily try to dereference this, and i'd get \"exception 28\".  i've updated udpcontext to check for this condition, and pass along that something has gone wrong.  in the case of send(), that means returning false, and for append(), return that 0 bytes were actually appended. ", "commit_messages": " check that pbuf_alloc doesn't return nullptr ", "linked_issue_titles": "", "title": "udpcontext - check after pbuf_alloc for errors"}
{"description": " implemented playback controls for offline usage updated sources of getting modules/hardware status based on the new changes in hmi ", "commit_messages": " dreamview: implemented playback controls for offline usage  dreamview: reflected hmi proto changes ", "linked_issue_titles": "", "title": "implemented replay controls for offline usage & reflected hmi proto changes"}
{"description": " fixes #12067 in cases where the same (embedded) texture is being loaded into multiple map slots, a separate videonode is created for each slot but only one has a .content entry containing the actual image data, presumably to save space. there appears to be no data in the fbxtree.connections about these duplicate images though, so i track them via absolute paths (all embedded images still keep a track of the original absolute path to the image on the computer the file was made on), and then loop over possible duplicates after all the images are parsed, and for duplicate pairs where only one has an entry in the image map, create a corresponding entry for the other. also fixed a bug  in ascii format where the videonode.content is an empty string so an entry consisting of just data:jpeg;base64, was being created in the imagemap. this was making it seem like this error was only coming up for binary format files while in fact ascii format was just creating blank textures for these duplicates. ", "commit_messages": " fbxloader correctly parse duplicate maps  typo ", "linked_issue_titles": " fbxloader: some textures on mixamo model fail to load ", "title": "fbxloader correctly parse duplicate embedded textures"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: see latest flow config here and new api documentation for connectroutes here increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update redux-first-router typings with api changes as of v1.9.8  scrub trailing commas  fix style of author declarations ", "linked_issue_titles": "", "title": "update type definitions to v1.9"}
{"description": " use configuration::getinstance()->supportsshareablevao() in place of cc_texture_atlas_use_vao. and fix gl_ext_discard_framebuffer always disable in eaglview.mm. ", "commit_messages": " use configuration::getinstance()->supportsshareablevao() in place of cc_texture_atlas_use_vao;  fix gl_ext_discard_framebuffer always disable in eaglview.mm;  fix gl_ext_discard_framebuffer always disable in eaglview.mm (fix compile fail on early ios sdk 4.0); ", "linked_issue_titles": "", "title": "configuration of vao in runtime"}
{"description": " while looking into #38307, i noticed some confusing wording in the asset pipeline guide: rails/guides/source/asset_pipeline.md lines 36 to 45 aeac447 rails automatically adds the sass-rails gem to your gemfile, which is used by sprockets for asset compression: ruby gem 'sass-rails'  using the --skip-sprockets option will prevent rails from adding them to your gemfile, so if you later want to enable the asset pipeline you will have to add those gems to your gemfile. also, specifically adding them to your gemfile add those gems is confusing because the preceding paragraph only mentions one gem (sass-rails). i discovered that this is a result of removing mentions of uglifier and coffee-rails from that paragraph in #35994. so i've opened this pr as a follow-up to #35994 to clean up the confusing wording that was left in the guide. while i was in there, i also clarified the purpose of the sass-rails gem and added links to ", "commit_messages": " clean up leftover plural references in asset pipeline guide  prior to ab123a33d2460dcdc5c36001cef5316eadc75fb3, this guide mentioned  that three gems (sass-rails, uglifier, and coffee-rails) would be added  to the gemfile by default, unless the --skip-sprockets option was  used when generating the application.  however, ab123a33d2460dcdc5c36001cef5316eadc75fb3 removed uglifier and  coffee-rails from the guide (to reflect the switch to webpacker for  managing javascript in rails 6). now that only sass-rails is left, the  guide should say \"adding this to your gemfile\" instead of \"adding them  to your gemfile\" and \"add that gem\" instead of \"add those gems\".  [ci skip]  clarify what sass-rails is used for in asset pipeline guide  the original text \"used by sprockets for asset compression\" was written  when this sentence was summarizing the purpose of three gems:  sass-rails, uglifier, and coffee-rails.  however, ab123a33d2460dcdc5c36001cef5316eadc75fb3 removed uglifier and  coffee-rails from this sentence. now that only sass-rails is left, we  can be more specific about what it is used for: compiling sass  stylesheets.  [ci skip]  link to the sass-rails repo and sass-lang.com in asset pipeline guide  we link to the sprockets-rails repository in the preceding paragraph,  so it seems appropriate to also link to the sass-rails repository in  this paragraph. and since readers of this guide may not know what sass  is, it also seems appropriate to link to the sass-lang.com website.  [ci skip] ", "linked_issue_titles": "", "title": "fix confusing wording in asset pipeline guide [ci skip]"}
{"description": " remove support file update from create-cypress-tests wizard and update vue instructions. test it right now by typing in terminal (inside npm project) yarn create cypress-tests-beta ", "commit_messages": " v0.0.590  v0.0.591  update vue plugins  remove support file injection from wizard  v0.0.592  revert package.json ", "linked_issue_titles": "", "title": "update plugins and remove support"}
{"description": " this pull request is to provide a kafka source/sink pair to simulate a kafkashuffle that can: read topics that are already partitioned by key and process them without partitioning them again (avoid shuffles); and use this to decompose the job into smaller jobs and independent pipelined regions that failover independently. extend datastream api to allow user-defined sinkfunction to manipulate watermark kafka shuffle producer change write timestamp and watermark information together with a record in kafka use keygrouprangeassignment to assign records to different kafka partitions kafka shuffle consumer change, kafka fechter change each consumer read partitions equal to the key group indices that it got assigned. for now, the number of partitions is enforced to equal to the number of consumer parallelism. kafkashufflefechter encapsulates the logic of record emitting and watermark emitting. this change added tests: end-2-end tests partition assignment tests some other tests are missing: specific watermark tests failover tests dependencies (does it add or upgrade a dependency): (no) the public api, i.e., is any changed class annotated with @public(evolving): (yes) the serializers: (don't know) the runtime per-record code paths (performance sensitive): (no) anything that affects deployment or recovery: jobmanager (and its components), checkpointing, kubernetes/yarn/mesos, zookeeper: (no) the s3 file system connector: (no) does this pull request introduce a new feature? (yes) if yes, how is the feature documented? (javadocs) ", "commit_messages": " [flink-15670][core] provide a utility function to flatten a recursive properties to a first level property hashtable  in some cases, kafkaproducer#propstomap for example, properties is used purely as a hashtable without considering its default properties.  [flink-15670][connector] adds the producer for kafkashuffle.  kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.  [flink-15670][connector] adds the consumer for kafkashuffle.  kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.  [flink-15670][connector] kafka shuffle api part  kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected.  [flink-15670] kafka shuffle test case + add log4j2 file  kafkashuffle provides a transparent kafka source and sink pair, through which the network traffic of a shuffle step is persisted and redirected. ", "linked_issue_titles": "", "title": "provide a kafka source/sink pair as kafkashuffle"}
{"description": " @ahtn, just wanna make sure it's cool for me to merge this into qmk - it looks like you did most of the hard stuff with this :) if you want any attribution, let me know, or open a pr to the lets-split-support branch here, and we'll merge that in before this goes to master. @climbalima, if you want your keymap added to this as well, feel free to open a pr as well! (now or at any point in the future) todo make an actual default keymap write up more about the tech/keyboard in the readme work pm_reset into native reset with pro_micro flag ", "commit_messages": " one half working  i2c working  images, docks, clean-up [skip ci]  add options to config.h  remove uno_slave for now, even though it's freakin cool ", "linked_issue_titles": "", "title": "add let's split support"}
{"description": " removes a bit of unnecessary headers and gets rid of some direct dependencies on other headers. reduces the amount of rebuilding necessary if certain headers change in the future. ", "commit_messages": " yuzu/configuration/configure_system: remove unused header inclusions  yuzu/configuration/configure_debug: remove unused header inclusions  yuzu/configuration/configure_per_general: remove unused header inclusions  yuzu/configuration/configure_touchscreen_advanced: remove unnecessary header inclusions  yuzu/configuration/configure_input_player: forward declare types where applicable  allows removing the inclusion of the main input common header from the  ui config header. ", "linked_issue_titles": "", "title": "remove unnecessary inclusions where applicable"}
{"description": " fix cmake generate ios project, default arch config run fail on ios11 device cmake cmd: cmake .. -gxcode -dcmake_toolchain_file=../cmake/ios.toolchain.cmake ", "commit_messages": " arch_dir only useful for search linux prebuilt libs  add ios app target only_active_arch property  set xcode property for application, include all depend target ", "linked_issue_titles": "", "title": "correct ios project config when using cmake -gxcode generate (3.17 round 2 test)"}
{"description": " fixes #4358 ignores some as they seem out of scope for the repository. (more like a challenge or \"codethrough\" than an educational resource or tutorial.) build a discord clone with react js for beginners build a youtube clone with react js for beginners the 5-day react javascript challenge membuat clone aplikasi terkenal dengan react js efek animasi dengan javascript as this is not really a collection of videos for a course or series. it's an accumulation for random videos. ignores challenge 5 hari ngoding react js as this link appears twice in this pr. moves django untuk pemula from id.md to en.md since the tutorial is in english and renamed it to python django tutorial 2018 for beginners to match the source title. everything i ignored was reviewed subjective, could be nice to give them a peek and comment if anyone disagrees with an ignored resource. read our contributing guidelines put lists  in alphabetical order, correct spacing. followup check the output of travis-ci for linter errors! ", "commit_messages": " fixes #4358  update title to match source ", "linked_issue_titles": "", "title": "adds \"python django tutorial 2018 for beginners\" and \"belajar es6 - javacsript gaya baru\""}
{"description": " this pr adds the implementation of nep-35's like= argument, allowing dispatch of array creation functions with __array_function__ based on a reference array. there are two ways to dispatch, details below. the first is via python api (as demonstrated by np.ones and np.full), where array_function_dispatch is used, but differently than the existing dispatch for compute functions, where it's dispatched usually on the first argument, this is dispatched on the like= keyword argument, returning (like,). we also check if like is not none as a performance optimization, see #16935 (comment) . the second dispatch occurs via c through splitting array_implement_array_function in two functions. the first function remains very similar to how it was originally implemented (array_implement_array_function) but adds a step to remove like= argument before calling downstream libraries -- downstream libraries shall not add like= to their signatures. the second function (array_implement_c_array_function) will also remove the like= argument, but it will also extract the reference array from it and will gather the public_api python function by doing an import on np.function_name, where function_name shall be passed by the calling function. the usage of the c dispatch is very straightforward and optimized for the case where like=none, adding minimal overhead to such functions. the necessary work will thus be only done when a reference array is passed, such as importing the numpy python function -- this can still be improved by using a lookup mechanism to avoid reimporting for each subsequent call but it was decided not to do that in this pr. the caller function will still need to add a like argument to its keyword list and parse that, but it will not be used anywhere other than the dispatcher function, it will also need to call the c dispatcher and check for its return value, if it returns py_notimplemented it will continue with numpy's implementation, otherwise return that value (from downstream library) immediately. ", "commit_messages": " enh: add like= kwarg via __array_function__ dispatcher to asarray  enh: add new function for __array_function__ dispatching from c  this new function allows dispatching from c directly, while also  implementing the new like= argument, requiring only minimal  changes to existing array creation functions that need to add  support for that argument.  enh: add like= support to numpy.array  the implementation uses array_implement_c_array_function, thus  introducing minimal complexity to the original _array_fromobject  code.  bug: fix like= dispatcher for np.full  enh: remove np.asarray like= dispatcher via python  np.asarray can rely on np.array's c dispatcher instead.  tst: add some tests for like= argument  tests comprise some of the functions that have been implemented already:  * np.array (c dispatcher)  * np.asarray (indirect c dispatcher via np.array)  * np.full (python dispatcher)  * np.ones (python dispatcher)  enh: remove like= argument during array_implement_array_function  enh: add like= kwarg to ones and full  bug: prevent duplicate removal of like= argument ", "linked_issue_titles": "", "title": "implement nep-35's like= argument"}
{"description": " these test were very slow on pypy and flaky on windows because they relied on refcount semantics to close the underlying mmap object when calling __del__. this pr refactors them to use flush instead, which is sufficient to prove the point of the tests. also update documentation to prefer flush to __del__, and point out the shortfalls of __del__ use a pytest fixture to get a temporary directory rather than a local solution. ", "commit_messages": " tst: avoid refcount semantics, speed up tests  doc: update documentation of numpy.memmap ", "linked_issue_titles": "", "title": "avoid refcount semantics in using numpy.memmap"}
{"description": " this adds a phantom template that can be used to add additional type information to other types, which allows for stronger typing between types represented by the same type. applies this to priorityload and priorityavailability, both of which are represented by a std::vector<uint32_t>. risk level: low testing: uts for phantom, everything else is compile time docs changes: n/a release notes: n/a fixes #5570 ", "commit_messages": " upstream: use phantom types for load/availability  uses a phantom type that allows embedding additional type information  into a simple type to add type safety to usages of priorityload and  priorityavailability.  this ensures compile time safety when passing around these types,  ensuring that they are not used interchangeably.  expose default ctor  always include default ctor  add types file  format  document weird case ", "linked_issue_titles": "", "title": "add phantom types to load/availability"}
{"description": " fixes #15473 minor text+sample change: in 3.x, the microsoft.aspnetcore.diagnostics.healthchecks package is implicit from the shared framework. the 2.x text is fine as it is. the microsoft.extensions.diagnostics.healthchecks package comes in transitively via the microsoft.aspnetcore.diagnostics.healthchecks package, so there's no need for the app to reference it. thanks @lol768! ", "commit_messages": " health checks topic package reference update  package is transitively referenced  package is transitively referenced ", "linked_issue_titles": " is this up to date with asp.net core 3.0? ", "title": "health checks package reference updates"}
{"description": " this migrates all of our unit tests that were previously suffixed with .unit.test.js to a single test/unit folder removing the redundant suffix. a root tsconfig.json has also been added to enable type checking the newly converted tests to help prevent test errors from incorrect usage. ", "commit_messages": " move unit tests to one folder  migrate unit tests to typescript ", "linked_issue_titles": "", "title": "move unit tests to one folder and migrate them to typescript"}
{"description": " original pull-request #21533 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " podarray left pad not multiple of element crash fix  updated style check  cleanup podarray  remove unused method  fix error (found by @kitaisreal)  fixed podarray  pod array left pad not multiple of element crash fix  cleanup podarray ", "linked_issue_titles": "", "title": "cherry pick #21533 to 21.1: cleanup podarray"}
{"description": " trigger the change event on the next tick. this means that multiple changes to a track's mode will only result in a single change event on its associated texttracklist rather than 3 events as it may be currently. fixes #5159. ", "commit_messages": " add helper to event target to queue events  queuetrigger change events  lint error ", "linked_issue_titles": "", "title": "async change events in texttracklist with eventtarget#queuetrigger"}
{"description": " this allows user a way to specify directories and/or files to ignore: 869abb1 adds parsing of new watchoptions: excludefiles and excludedirectories in tsconfig as well as command line 9cd3e93 adds a way to create noopwatcher for files and directories that are being watched. dddd906 adds a way to exclude invoking callback for excluded things from sys itself. this means no invoke for excluded path if its invoked from recursive directory watching or not watching directories that are excluded on os that don't support recursive watching (like linux) 0a8d84f handles the server host configuration and external/inferred projects watch options with ignore. 496939d reloading projects, reloads project from scratch cd18da8 file updates when reloading are reflected this provides a way on systems where watching can be expensive and letting user refresh things if something changes rather than us having to poll or rely on events fixes #33335, #36035, #36243, #36394 ", "commit_messages": " parse excludedirectories and excludefiles  use watch factory in typings installer  some refactoring for watchfactory  create noop watcher if file or directory being watched is excluded  baselines without using exclude watch options  baselines including exclude option  handle exclude options in the system watches  add test without exclude option for recursive directory watching  test baselines with exclude option  always set syslog ", "linked_issue_titles": " initializing js/ts features is extremely slow with wsl and node_modules  add a way to exclude file or directory watching  typescript server won't start on wsl  tsserver.js/typingsinstaller.js is watching ignored directories (causing cpu load) ", "title": "add way to exclude files and directories to watch"}
{"description": " after upgrading to latest, i have begun to have issues with url-loader being able to resolve file-loader, and .cache/app.js being able to resolve socket.io-client.  this is likely because i am using pnpm in my particular repository. url-loader uses a fallback of file-loader, but it only provides a simple string.  url-loader also doesn't provide file-loader as a production dependency, nor does it list it as a peer dependency, so it would need to get it from somewhere else. i'm not sure why this only started breaking now, but this is the error i get: error #98123  webpack generating javascript bundles failed cannot find module 'file-loader' require stack: - <require stack leading to url-loader> file: /path/to/node_modules/typeface-poppins/files/poppins-latin-600.woff what i've done here is simply resolved that to a fully qualified path, relative to gatsby. additionally, i have added an alias for socket.io-client, because .cache/app.js now imports it, but webpack cannot find it because the project i am working on doesn't have it installed in its dependencies.  that's to fix this error: error #98124  webpack generating development javascript bundle failed can't resolve 'socket.io-client' in '/path/to/project/.cache' if you're trying to use a package make sure that 'socket.io-client' is installed. if you're trying to use a local file make sure that the path is correct. file: .cache/app.js both of these fixes work great in my testing.  the only thing i can't be sure of is if the fallback for url-loader will have unintended side effects. additionally, because socket.io-client is used directly by gatsby, it should be installed as a production dependency.  if not, then yarn 2 will break, because it won't be able to retrieve it from socket.io. ", "commit_messages": " provide fully qualified path for url-loader's fallback  create resolution for socket.io-client, for import in .cache/app.js  include socket.io-client as dependency ", "linked_issue_titles": "", "title": "add explicit dependency on socket.io-client and explicitly set url-loader fallback"}
{"description": " on formidablelabs/victory-chart#527 a new prop was added to victoryaxisprops - invertaxis. updating the definition of victoryaxisprops with the new prop ", "commit_messages": " update victoryaxisprops with invertaxis prop  update victoryaxisprops with invertaxis prop ", "linked_issue_titles": "", "title": "adding \"invertaxis\" to \"victoryaxisprops\" definition"}
{"description": " fixes #10051 added an optional argument for_partial_fit=false to _validate_params which bypasses warnings about max_iter and tol added for_partial_fit=true to _validate_params calls in partial_fit methods for both sgdclassifer and sgdregressor i appreciate that this could have been done through the use of set_max_iter=false but it seemed clearer to me to have a dedicated flag. first contribution to this project, so i apologize if i've done something horrifically wrong ", "commit_messages": " partial fit warnings disabled  partial fit warnings disabled for regressor  style improved  tests added  pycodestyle passing  rejiggered format ", "linked_issue_titles": "", "title": "fix for erroneous max_iter and tol warnings for sgdclassifier when using partial_fit"}
{"description": " add 'not null' option to alert if... input when selected, disable value input fix validator_config field to send operator when selected and not null only when corresponding option is selected update usesingleviewresource hook to add error handling on updateresource/createresource methods update error handling on edit/create so modal does not close test plan requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " add not null condition option + related logic  fix error handling  add error handling on create ", "linked_issue_titles": "", "title": "add 'not null' condition option to modal"}
{"description": " also change a bug! to delay_span_bug closes #74018 ", "commit_messages": " delay bug for non-universal regions in member constraints  call type_of for opaque types later in compilation  this ensures that various wf checks have already been done before we  typeck item bodies. ", "linked_issue_titles": " ice when playing around with existential types, impl trait ", "title": "compute underlying type of impl trait types later in compilation"}
{"description": " commits compilations of : toggle menu for psu from lcd pannel from the prepare menu, accessible when is not printing, you have the possibility to turn off the psu when is on et vice versa. from the host, you can turn off or turn on the psu then the menu is updated accordingly. from the lcd message, the printer status is reported ready or off respectively when the psu is on or off. turn off power supply off-load disable the high current outputs and wait a little before to turn off the psu, because the interrupting capacity of the psu is unknown. could be a function if needed by other. no bed config for ramps the motherboard 35 is a config without bed with this pins setting : d8 extruder d9 fan d10 controller fan nicolas. ", "commit_messages": " toggle menu for psu from lcd pannel  from the prepare menu, accessible when is not printing, you have the  possibility to turn off the psu when is on et vice versa.  from the host, you can turn off or turn on the psu then the menu is  updated accordingly.  from the lcd message, the printer status is reported ready or off  respectively when the psu is on or off.  turn off power supply off-load  disable the high current output and wait a little before to turn off,  because the interrupting capacity of the psu is unknown.  could be a function if needed by other.  no bed config for ramps  the motherboard 35 is a config without bed with this pins setting :  d8 extruder  d9 fan  d10 controller fan ", "linked_issue_titles": "", "title": "lcd toggle for psu, current tripping and no bed config"}
{"description": " i messed up the rebase to next, so this pr is this one, but based into next branch, sorry :-/ #14523 i have followed (at least) the pr section of the contributing guide. today i found an issue with the slider inside an scrollable area (a dialog) the more to the right the thum was, the more scroll area that would be shown in the dialog, such as here: apparently the issue is that the thumb uses a width/height of 100% + a transform, which would transform it to be outside of the track area. the fix i applied was setting the width and height to 0, while using the top and left properties to position the thumb wrapper, therefore it never exceeds the track area. i tried the dev docs example page and it seems to work ok. ps: i tried playing with overflow hidden, but it did not help. fixes #13455 ", "commit_messages": " [labs][slider] fix for slider thumb wrapper size  [slider] alternate fix  move padding and margin fix to container instead of root  vertical slider example fix  update slider.js ", "linked_issue_titles": " slider overflows element width ", "title": "fix thumb creating scroll overflow"}
{"description": " db2foreignkeyconfigurator db2indexconfigurator db2schemaconfigurator db2sequenceconfigurator db2uniquekeyconfigurator in org.jkiss.dbeaver.ext.db2.ui based on org.jkiss.dbeaver.ext.db2 managers of the same name created ", "commit_messages": " #8562 part (configurators) of ui-part from plugins/org.jkiss.dbeaver.ext.db2 moved in org.jkiss.dbeaver.ext.db2.ui  #8562 wrong path in plugin.xml fixed ", "linked_issue_titles": "", "title": "#8562 configurators from ext.db2 moved in ext.db2.ui"}
{"description": " following the release of mistral-v1, we are pushing a draft pr with the stability fixes we made for training gpt-2 models directly to the base gpt-2 class definition (ensuring backwards compatibility). this is in line with the following issues: stanford-crfm/mistral#86: enabling sharing mistral checkpoints via hf hub (@osanseviero) #13463: upcasting scaled dot-product attention + layerwise scaling for stability (@lvwerra) concretely we implement: weight initialization from the original gpt-2 paper (by default, shouldn't affect folks unless they are training gpt-2 models from scratch) layer-wise scaling in scaled dot-product attention (optional flag; necessary for running/loading mistral gpt-2 models) scaled dot-product attention reordering (scale before dot-product) & fp32 upcasting when training in mixed precision (optional flag; only necessary for training new mistral/other gpt-2 models). this is a draft pr to aid in @lvwerra and @thomwolf's work training gpt-2 models stably; we plan on implementing tests (please let us know potential pain points), adding documentation, and will act on any other feedback you have . cc mistral team: @lorr1, @j38, @santhnm2 cc others at hf + gpt-2 model reviewers: @stas00, @patrickvonplaten, @lysandrejik resolves #13463 ", "commit_messages": " add layer-wise scaling  add reorder & upcasting argument  add layer scaling & upcast/reordering flags + functionality  add openai gpt-2 weight initialization scheme  openai gpt-2 initialization ", "linked_issue_titles": " upcasting of attention computation for reliable pretraining of gpt-2 models ", "title": "add mistral gpt-2 stability tweaks"}
{"description": " i changed the problematic regex pattern that i critized earlier in #4072 ", "commit_messages": " update app.py  fixed the dns rebind protection for secure handling of ipv6 addresses  update changelog  fixed the dns rebind protection for secure support of ipv6 addresses (@tunnelpr0) ", "linked_issue_titles": "", "title": "secure fix for the dns rebind protection issue from #4072"}
{"description": " fixes #6568 fixes #6587 review url ", "commit_messages": " pull from main  merge from docs  merge from docs  merge  merge  merge  merge  merge  merge  added first draft of asp.net core 2.1 release notes  wip: what's new in 2.1 ", "linked_issue_titles": "", "title": "what's new in asp.net core 2.1"}
{"description": " estuary includes support for several addons, a number of them have not been updated to python 3: script.maps.browser plugin.program.autocompletion script.extendedinfo i couldn't find any sign someone is working on it to get them ported to py3, so we'll drop support for those. support can be re-added in case py3 compatible versions of those addons are submitted to our addon repo. ", "commit_messages": " [estuary] remove support for script.maps.browser  [estuary] remove support for plugin.program.autocompletion  [estuary] remove support for script.extendedinfo ", "linked_issue_titles": "", "title": "remove support for addons that have not been updated to py3"}
{"description": " category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation piking up from @mistercrunch work on #7716 this feature implements async computation of dashboards and charts, includes: rest api endpoint to fetch cached thumbnails or trigger async computation cli utilities to compute thumbnails using a config user (defaults to admin). able to override method to authenticate users on sellenium thumbnails are stored on a extra caching backend get list endpoints for charts and dashboards have a new field with the api endpoint to fetch to corresponding item thumbnail. the retrieved endpoint includes a digest used to avoid browser caching when the chart changed. async jobs are triggered by sqlalchemy events on insert and update of charts and dashboards, to keep cached thumbnails up to date. note: this feature is behind 2 feature flags, one for the api other for sqla event listeners (it's done this way because of tests) tests are running with the feature flag off. there is a specific tox env var to run thumbnails tests similar to cypress-sqllab-backend-persist imho celery tests should be refactored, one possible path would be to introduce superset docker build (nice one to test also) and then run the worker, making it available for tests. short description of the 2 main flows: flow 1 (thumbnail exists on cache): 1 - frontend requests a thumbnail from the api 2 - backend requests the thumbnail from cache 3 - thumbnail exists on cache 4 - thumbnail is retrieved to the client flow 2 (thumbnail does not exist on cache) 1 - frontend requests a thumbnail from the api 2 - backend requests the thumbnail from cache 3 - thumbnails does not exist on cache 4 - async task to celery to compute the thumbnail 5 - http 202 is sent to client (client can render a default thumb) 6,7 - sellenium requests to the frontend a dashboard/chart visualization page, takes a screenshot, resizes and caches the result requires db migration. confirm db migration upgrade and downgrade tested. reviewers ", "commit_messages": " [thumbnails] new, thumbnail computation for charts and dashboards  [thumbnails] initial working api with cache ", "linked_issue_titles": "", "title": "thumbnails for dashboards and charts"}
{"description": " this adds a test to aggregatortestcase that allows us to programmatically verify that an aggregator supports or does not support all available field types.  it fetches the list of registered field type parsers, creates a mappedfieldtype from the parser and then attempts to run  a basic agg against the field. a supplied list of supported vstypes are then compared against the output (success or exception) and suceeds or fails the test accordingly. still a wip, need to tidy up, add javadocs, add another \"main\" agg or two (histo, etc).  putting it up in case folks want to have a look before i spend more time on it. note: to make this work, the pr cherry-picks over the getvaluessourcetype() component of #51503.  this will be added in eventually from the vs refactor branch, but is technically \"unused\" code outside of the tests until then. note 2: does not support field types added from a module at the moment. ", "commit_messages": " put values source types on fields (#51503)  comprehensively test supported/unsupported field type:aggs combinations  this adds a test to aggregatortestcase that allows us to programmatically  verify that an aggregator supports or does not support a particular  field type.  it fetches the list of registered field type parsers,  creates a mappedfieldtype from the parser and then attempts to run  a basic agg against the field.  a supplied list of supported vstypes are then compared against the  output (success or exception) and suceeds or fails the test accordingly. ", "linked_issue_titles": "", "title": "comprehensively test supported/unsupported field type:agg combinations"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. ", "commit_messages": " fix syntax and lexical errors  fix syntax and lexical errors  fix syntax errors  in create an export fallback  fix syntax errors  in create an export fallback  fix syntax and lexical errors in template literals  fix syntax and lexical errors in template literals  fix syntax and lexical errors in es6 const declare  fix syntax and lexical errors in es6 const declare ", "linked_issue_titles": "", "title": "fix syntax and lexical errors in es6 1-4 les"}
{"description": " first gen creality boards didnt have an sd detect pin, so allow setting to -1 in config file to prevent issues. ", "commit_messages": " suggested message change  allow override for old creality boards ", "linked_issue_titles": "", "title": "allow override for creality old boards"}
{"description": " fixes #12800 does not convert pandas dataframe into a dense array if all its columns are sparse arrays. since we have pandas sparse support on our minds: ", "commit_messages": " enh adds pandas sparse support for check_array  enh adds pandas sparse support for check_array  rev remove comments  tst improves test  tst improves test ", "linked_issue_titles": " roadmap: pandas sparsedataframe may be deprecated ", "title": "enh adds support for pandas dataframe with only sparse arrays"}
{"description": " this includes various test fixes, and switches wasm from using js versions of compiler-rt routines to just compiling them with the rest of compiler-rt. ", "commit_messages": " check the complete output of this test.  fix double-to-int conversion overflow.  fix missing #include.  for wasm, compile compiler_rt i64 routines rather than providing them via js.  update to the latest upstream compiler-rt files.  this includes an aapcs attribute fix which is not relevant to  emscripten (upstream r266891), and a fix to avoid undefined behavior  in udivmoddi4.c (upstream r204193). ", "linked_issue_titles": "", "title": "compiler-rt, sqlite, and tests fixes"}
{"description": " closes #20664 i might be unavailable for the next few hours, so i'm just putting this up here, even though it includes changes from #20814 in the first commit. once that is merged, this can be merged on top of master and it'll just have the categorical changes. ", "commit_messages": " squashed commit of the following:  commit ec0cecd292947aa4d8416991e9f8920a4cd9a831  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   fri apr 27 06:02:48 2018 -0500  updates  commit 6858409f3394035483e327c6e0fca05c1a6285ff  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   fri apr 27 05:48:59 2018 -0500  added note  commit eb43fa4159c2affaf57ad686c260b2d1899eeacd  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 20:47:35 2018 -0500  really truly fix it hopefully.  commit 7c4f625fdab30865e23570bf9e0a5450cf3e648e  merge: 9a6c7d44c 6cacdde56  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 20:40:15 2018 -0500  commit 9a6c7d44ce9f474acb68d7b62efc138aedc3a100  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 20:04:17 2018 -0500  doc updates  commit eecd632b16d475a5bbdca2013839298904056997  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 15:00:00 2018 -0500  skip categorical take tests  commit f3b91ca70ce9caacae29f3ecd80cd121f5ee1a33  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 13:43:26 2018 -0500  doc fixup  commit fbc4425a09bb973fefae90b3da2e1a205129658e  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 13:37:45 2018 -0500  updates  * indexer -> indices  * doc user-facing vs physical  * assert na_cmps  * test reindex w/ non-na fill_value  commit 741f284f1c320ef6bbbf8ddadc871322cf703909  merge: 5db66248f 630ef1649  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 07:18:32 2018 -0500  commit 5db66248f2c40d5de6ffe9a2c308830c4128079a  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   thu apr 26 07:17:30 2018 -0500  doc and move tests  commit 74b2c09bfc410be7190bbf6c69cb2c19fee6fbdd  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 21:40:18 2018 -0500  added verisonadded  commit fc729d6dea77dee0d89148cdda738c0e9d8ab7c5  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 15:51:27 2018 -0500  fixed editor  commit 1a4d9873629bb28e19a124e40b063879fc5e3ad0  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 15:50:48 2018 -0500  pass an array  commit bbcbf19a560efed894670b0bc495a80283e003fc  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 15:07:28 2018 -0500  cleanup  commit d5470a0f9f4d2f3937f0e63256f0750a50276586  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 15:02:26 2018 -0500  fixed reorder  commit 82cad8b1f369db80851c13fe856a30bdb8bd154c  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 15:00:43 2018 -0500  stale comment  commit c449afd2208451d67ce9c71c4b9d94448665c534  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 14:48:33 2018 -0500  bounds checking  commit 449983b3686710886da78e2c2b77ce59be9a93d3  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 12:55:31 2018 -0500  linting  commit 69e7fe76b540807bb973496ee5a2e3e636b90287  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 12:40:20 2018 -0500  updates  1. reversed order of take keywords  2. added to extensions api  3. removed default implementation  commit 05d884498a1b15f876e5166bc5208afd804b63c7  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 09:59:33 2018 -0500  updated docs  commit 31cd304e2f61fad841f6d56135fd6bbb202c606f  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 09:43:45 2018 -0500  pep8  commit 338566faf627e1fabd638a65055f1804948dd021  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 09:42:28 2018 -0500  upcasting  commit b7ae0bc2cadd821d97f21fc2eac99b321d9473e5  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 09:06:59 2018 -0500  revert combine change  commit 125ca0b7cf5796b806e76c2c38d780e55ea12176  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 08:37:07 2018 -0500  simplify  upcasting is still broken  commit c721915114c5dd39cd7aec6c9dec762ca28abcac  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 07:50:54 2018 -0500  removed default_fill_value  commit 37915e9f31652904a3a3c9d91e2d4e394aecc14f  merge: 67ba9ddb0 60fe82c8a  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 07:44:15 2018 -0500  commit 67ba9ddb0c8dec7f88a7ce14387898b552afe355  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 07:42:54 2018 -0500  more with default fill value  commit eba137f8c7ae45288200566aebbf32229c69720c  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 05:59:58 2018 -0500  more internals hacking  commit 08f24790daa8bbade46dca86dd2fb9ff0353118c  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   wed apr 25 05:59:17 2018 -0500  fixup json take  commit 0be9ec6593f38b698af6475c668ecf4c709bbe20  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   tue apr 24 18:02:13 2018 -0500  non-internals changes  commit dacd98e5f8ed0947bb2646499ac2e3cfd94e6177  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   tue apr 24 14:45:36 2018 -0500  moves  commit fb3c2343c88be05ff1db5ca0ddef274eb0fda6b3  author: tom augspurger <tom.w.augspurger@gmail.com>  date:   tue apr 24 13:59:51 2018 -0500  [wip]: extensionarray.take default implementation  implements a take interface that's compatible with numpy and optionally pandas'  na semantics.  python  in [1]: import pandas as pd  in [2]: from pandas.tests.extension.decimal.array import *  in [3]: arr = decimalarray(['1.1', '1.2', '1.3'])  in [4]: arr.take([0, 1, -1])  out[4]: decimalarray(array(['1.1', '1.2', '1.3'], dtype=object))  in [5]: arr.take([0, 1, -1], fill_value=float('nan'))  out[5]: decimalarray(array(['1.1', '1.2', decimal('nan')], dtype=object))    closes  bug/api: futurewarning from categorical.take indices  we're changing how categorical.take handles negative indices to be in  line with series and other eas. ", "linked_issue_titles": " bug: categorical.take and series([categorical]).take is inconsistent with other dtypes ", "title": "deprecate categorical take default behaviour + fix series[categorical].take"}
{"description": " this affects gatsbyplugin atm as it requires a npmpackage to be installed. ", "commit_messages": " validate plans that any inter-resource dependencies are satisfied in the plan  pause execution of resource with dependencies while installing until its dependency is ready  fix lint problem ", "linked_issue_titles": "", "title": "let resources declare dependencies & validate recipes & ensure dependencies installed first"}
{"description": " fixes and improvements for the following: because of some changes, we were unable to send utf-8 characters with sendinputevent the cursor-changed event was missing some data needed for custom cursors (hotspot + size of cursor) to be able to draw the cursor easily, i introduced a tobuffer to nativeimage that retrieves the image in a raw representation into a nodebuffer ", "commit_messages": " update as upstream  fixes not being able to send utf8 characters anymore  adds option to get raw data from nativeimage  send some more data with the cursor-changed event ", "linked_issue_titles": "", "title": "a minor fix for sendinputevent and improvements related to cursor-changed event"}
{"description": " i've run the latest black with default args on new code. i have added test_box.py with additional box.py tests and i have added a basic test for console.input() in test_console.py for issue #37. unfortunately, the total coverage didn't change from 94% but hope it helps in the long run. let me know if i should change anything. thanks! ", "commit_messages": " add basic console.input() test  add box tests ", "linked_issue_titles": "", "title": "add input and box tests"}
{"description": " this pull request contains 4 patches. increasingly, data is colliding between jquery internal data and user data. this patch cleanly separates the two. it also changes the way the data functions work on plain js objects as a result. users can still access internal data if they need to, but uses jquery.expando as a key, so it is nearly impossible for collision to occur with any key that a user would reasonably use. this patch includes changes to the unit testing framework that check and report any time a unit test leaks data in any of the jquery globals. it also cleans up all of the tests that had been leaking. dommanip was leaking an element when appending to a list of multiple elements by never using the first element and always cloning. this patch fixes this issue. jquery.dequeue was not properly cleaning up and removing empty queues. this patch fixes this issue. ", "commit_messages": " change the way jquery.data works so that there is no longer a chance of collision between user data and internal data. fixes #6968.  fix dommanip leaks the first element when appending elements to multiple other elements.  fix jquery.queue leaks empty queues.  update unit tests with a leak detection mechanism for the various jquery globals and fix all leaks in the tests. ", "linked_issue_titles": "", "title": "data collision mitigation & unit test leaks patch (bug #6968)"}
{"description": " this pr ensures that the results are displayed along with the warning when enhanced mode is disabled. references pr checklist applies to #2041 cla signed. if not, go over here and sign the cla tests added/passed requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #xxx detailed description of the pull request / additional comments the following changes have been made in this pr - these lines ( modified the tests to reflect the change in code accordingly. the ui behaves as follows - if the enhanced mode is disabled then the first indexer result is this warning, followed by the other results if the enhanced mode is enabled or if the warning is disabled from the settings then the warning is not shown. validation steps performed manually validated it all tests pass (had to modify the test to reflect the change in logic) ", "commit_messages": " show results always and conditionally show warning  changed test logic to show warning when expected ", "linked_issue_titles": "", "title": "drive detection indexer warning refinement"}
{"description": " #3549 #3488 #3661 rnw implementation of viewpanel sometimes create outer border instead of using the inner border, for example when round corner border is requested. this is causing noticeable layout issue especially when border size is large. rn's yoga layout sets the top/left for each children, but yoga has no notion of outer border(in its view, border is always part of the view instead of parent of view), and its placement logic includes the border size. so we need to compensate the outer border size when viewpanel is arranging its children, by deducting the border size from the top and left. when testing, i also found children clipping issue when outer border is present, so fix that too. microsoft reviewers: open in codeflow ", "commit_messages": " format  change files ", "linked_issue_titles": "", "title": "fix viewpanel layout issue when outer border exists"}
{"description": " enables apps to run tasks without the need for manually scheduling them. by passing a config object with the job processor definition (startupsetting), the job will be scheduled to run right after being registered. this is what makes it possible for apps to schedule jobs within the \"initialization\" phase, without the need for user input. it wasn't previously possible due to the fact that a modifier was required to schedule jobs, but no modifiers are allowed in the \"initialization\" phase (it can be potentially problematic in ha setups). how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog ", "commit_messages": " make the apps scheduler run jobs after defining them  ensure onetime jobs won't have duplicates at startup ", "linked_issue_titles": "", "title": "allow apps to schedule jobs along with processor register"}
{"description": " adds more debug info. adds information about why object chunks failed to be received. also adds plasma store debug dumps once capacity is reached. plasma store will periodically dump information if asio stats are turned on (should probably rename this config parameter at some point). i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " debug  todo  periodic dump ", "linked_issue_titles": "", "title": "add object store debug information"}
{"description": " added trimesh fixed convexpolyhedron constructor - faces is a number[][] added trimesh to shape.types added geometryid to shape added axisa, axisb to hingeconstraint added setmotorspeed to hingeconstraint added target to icollisionevent this type def is used to validate the typescript on these pages ", "commit_messages": " added trimesh  fixed convexpolyhedron constructor - faces is a number[][]  added trimesh to shape.types  added geometryid to shape  added axisa, axisb to hingeconstraint  added setmotorspeed to hingeconstraint  added target to icollisionevent  this type def was used to validate the typescript that generated these examples              added author to comment ", "linked_issue_titles": "", "title": "updates for cannonjs types. added trimesh, added hingeconstraint properties, added shape properties, fixed convexpolyhedron constructor"}
{"description": " resolves: #2744 added tests for changed code. updated documentation for changed code. ", "commit_messages": " fix #2744  add test for #2744 ", "linked_issue_titles": " 1.1.0b2 causes envcommanderror (non-posix paths with file:// protocol on windows)  poetry 1.1.0b2 fails to install zipp when trying to install poetry-core ", "title": "fix non-posix paths with file:// protocol on windows"}
{"description": " the pi's gpu only used to support advanced deinterlace for sd video. we've improved the firmware to allow advanced deinterlace at 1080i so we can remove this limit. also allow deinterlace with software decode. pi 2 can handle software decode + deinterlace for dvds. ", "commit_messages": " [rbp] enable qpu based deinterlace and remove resolution limit  [mmalrenderer] allow deinterlace with software decode ", "linked_issue_titles": "", "title": "support advanced deinterlace for 1080i"}
{"description": " bump go.d.plugin version to v0.22.0 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.21.0 ", "commit_messages": " packaging: bump go.d.plugin version to v0.22.0  packaging: update go.d.plugin checksums ", "linked_issue_titles": "", "title": "update go.d.plugin version to v0.22.0"}
{"description": " http client move buffer (1460 byte) from stack to heap. only malloc needed ram if we know the response size and its less then 1460 ", "commit_messages": " http client move buffer (1460 byte) from stack to heap.  only malloc needed ram if we know the response size and its less then 1460 ", "linked_issue_titles": "", "title": "http client move stream buffer the heap"}
{"description": " what did you implement added a link to the aws documentation that describes the differences between rest apis and http apis. closes #xxxxx how can we verify it todos useful scripts npm run test:ci --> run all validation checks on proposed changes npm run lint:updated --> lint all the updated files npm run lint:fix --> automatically fix lint problems (if possible) npm run prettier-check:updated --> check if updated files adhere to prettier config npm run prettify:updated --> prettify all the updated files write and run all tests write documentation enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " rest apis vs. http apis  link clean up ", "linked_issue_titles": "", "title": "rest api vs. http api"}
{"description": " ubl and eeprom with host program such as octoprint in settings.cpp some debugging statements where not correctly disabled. this is causing issues with host programs such as octoprint. in particular ubl.echo_name() was being called and printing out a string without a newline. ok was then appended to that line and octoprint then never sees the ok its waiting for and times out. debugging is correctly disabled and octoprint no longer gives misleading serial errors. configuration.zip #20417 ", "commit_messages": " fix debug messages  correct missing character ", "linked_issue_titles": "", "title": "fix debug messages, causing octoprint serial issues."}
{"description": " emit information to ipc processes about routes, redirects, rewrites, and headers ", "commit_messages": " ipc emit all pages as ssr  ipc emit all pages as ssr  ipc emit all pages as ssr  ipc emit all pages as ssr  more logging  make log action  change string value for pages  edit routes in canary  new canary  change route emission  page data  add tests for sending log_routes  merge master  merge master  adjust tests  commit for canary change  comments  ipc emit redirects and rewrites  add tests for ipc emits ", "linked_issue_titles": "", "title": "ipc events for routes, redirects, rewrites, and headers"}
{"description": " fixes #3914. mysqlvisitor lacks of visitor for ddlstatement.g4. it is necessary to add ddlstatement.g4 antlr visitor. mysqlvisitor adds ddlstatement.g4 antlr visitor. ", "commit_messages": " mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor  mysql ddlstatement visitor ", "linked_issue_titles": " optimization for sharing parser with antlr visitor for mysql ", "title": "add mysql ddlstatement antlr visitor"}
{"description": " in several places in main.cpp, synchronized data structures are accessed without cs_main being held. ", "commit_messages": " lock cs_main for state/misbehaving  processmessage calls state(...) and misbehaving(...) without holding the  required lock; add lock(cs_main) blocks.  lock cs_main for chainactive  activatebestchain uses chainactive after releasing the lock; reorder operations  to move all access to synchronized object into existing lock(cs_main) block. ", "linked_issue_titles": "", "title": "locking for misbehave() and other cs_main locking fixes"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " add @dhis2/ui-constants package  fix lint warnings ", "linked_issue_titles": "", "title": "add types for the @dhis2/ui-constants package"}
{"description": " fixes #642 . focused the textblock element when the event source is the textblock itself. this fixes the resultant number not gaining focus when a right-click is performed. tested manually ", "commit_messages": " fixed issue with focus when right-clicking result ", "linked_issue_titles": " right-click on numbers fails to highlight after 'selecting all' from context menu ", "title": "fix the focus when right-clicking calculationresult's textblock"}
{"description": " what's this pr do? this pr fixes the use of cursorpoller in stream so that it's updated with the current active filters. previously, the poller locked in whatever filters were present on page load. this fixes \"switching the active filter does not prevent old results from loading\" on issue #1585. change summary: streammanager: don't add items unless they have an id stream: sync state with url on mount cursorpoller: add setendpoint method to update internal url unmount react components after each test where should the reviewer start? src/sentry/static/sentry/app/views/stream.jsx src/sentry/static/sentry/app/utils/cursorpoller.jsx how should this be manually tested? run make test-js you can also start the sentry server, navigate to the stream page, and select one of the filters (i.e., \"bookmarks\", \"assigned\") before the poller has a chance to complete its first poll. if the filtered data remains the same after the first poll has completed then the changes have fixed the issue. any background context you want to provide? this pr builds upon #1602. what gif best describes this pr or how it makes you feel? ", "commit_messages": " fix polling with filters  previously, the stream poller would not respect filters selected after page  load. this caused subsequent polls to request data using the old filters. a  change was made to update the poll url upon changing filters.  update react component tests  tests were not unmounting react components after running, which could cause  memory leaks or unexpected behavior from \"watched\" stores or actions. tests now  unmount the tested component. ", "linked_issue_titles": "", "title": "poll with current active filters"}
{"description": " this pr makes classic ui (upscaled dogm) to work with the native display resolution for touch. before that, the code had a lot of fixed magic numbers and weird calculations to translate the touch from the native resolution to an independent resolution of 320x240. the reason for this pr is simple: it allow classic ui use the same xpt calibration values of the color ui and lvgl ui, allowing us to create a generic touch calibration screen. one unique xpt calibration values for all ui. less complex code. it will allow us to create a generic touch calibration screen. it better integrate touchbuttons with the classicui. any board with tft_classic_ui. ", "commit_messages": " make dogm use the real screen resolution for touch and drawing, instead of fixed 320x240 coordinate space. buttons positions now are calculated  we dont need any more xpt values specific for classic ui on 480x320 screens! ", "linked_issue_titles": "", "title": "make classic ui use the screen resolution for touch (not fixed 320x240)"}
{"description": " from #5704. ", "commit_messages": " cgtop: check cgroups after parsing options  we would try to determine controllers even if not necessary:  <mock-chroot><mock-chroot> sh-4.4# ./systemd-cgtop --help  failed to determine supported controllers: no medium found  <mock-chroot><mock-chroot> sh-4.4# ./systemd-cgtop --version  failed to determine supported controllers: no medium found  this broke check-help-systemd-cgtop under mock, but even apart  from that, the program should be able to print --version in any  circumstances.  nspawn: check cgroups after parsing options  same justification as in previous commit. ", "linked_issue_titles": "", "title": "make sure --version, --help always work"}
{"description": " closes #299. in tree view, the recurse_nodes function travels down every possible path, leading to exploding complexity with certain recombining graphs. we can implement a very fast dfs traversal, but then we lose the nice expand/collapse functionality. unfortunately i don't know an easy way to compute the number of paths in a graph (i think there's a big prize for that), so i'm solving this the old fashioned way: try the complicated method, and if it takes too long, fall back on the quick one. here's what happens: the default timeout is 1 second (i thought that was a reasonable wait for most graphs) we try to run the full recursion. if it finishes in less than 1 second, the resulting tree view has full expand/collapse functionality but if the full recursion times out, then it falls back on a quick dfs recursion that will display a full tree, but can't be dynamically expanded if a url parameter force_expand is passed, then the timeout is removed and the system will compute the full recursion no matter how long it takes. ", "commit_messages": " add timeout/fallback to tree traversal  expand_all -> force_expand for clarity ", "linked_issue_titles": "", "title": "add timeout/fallback algorithm for building tree view"}
{"description": " the pr moves the cmsis framework and other lpc176x specific code into an external repository, implementing a custom platformio platform and arduino framework aiming to be be mostly arduino api compatible (only the public api tricks used by libraries will still cause many problems as it does with due etc). this is still a work in progress but there are so many bugfixes and improvements at this point that i can't really wait any longer to merge, (too many issues coming up that are fixed). clean up the platforms directory to include only hal related items clean up the build system, enforcing order of inclusion updates to the usb system (mostly @gloomyandy's work) addresses various timeout issues usb will now always reconnect on board reset fixes cdc serial transmission errors can use onboard sd card for gcode while sharing it with host as usb drive, needs unmounted on marlin to access with host, marlin takes priority default to using flash eeprom emulation as it is more reliable pwm is now compatible with all 6 hardware channels on any compatible pin with transparent fallback onto the 20 interrupt driven channels, if hardware channel is busy or not available. all the things i've forgotten about this is a major overhaul of the platform and how it builds, it more than likely fixed things i don't know about and broke other things that i will soon know about. i've added a near duplication of the lpc1768 pio build environment for the lpc1769, though i may rethink it if people deem it unnecessary, marlin code assume f_cpu is a constant and that any calculation it is used in (there are lots) with be optimised away, if f_cpu has to assigned at run-time these calculations (maybe in isrs) are not optimised. ", "commit_messages": " [hal][lpc176x] pull out framework into separate repository  framework and build platform now located at  fix mkssbase leds  move hardware serial  remove hardware/software serial  hardware serial extraction  hardwareserial isrs  fix disabled serial2 causing serial object to link  move usb devices out to framework  separate out adc/pwm peripheral function from hal.cpp  fix includes  remove unused pwm init  move adc  hal header update  templated filtered adc  lpc1769 platform  usb and sdcard sharing improvements  * add traceback after watchdog timeout  add the cpability to perform a traceback following a watchdog timeout.  * enhanced hardware spi  allow use of either ssp0 or ssp1.  ensure that no data is left in i/o buffers after calls to enable sharing of ssp hardware.  * make flash emulation of eeprom the default  make use of flash for eeprom storage the default. this means that usage of eeprom will not cause usb drive mount/unmount operations.  * allow sharing of sd card  sd card i/o operations from the usb stack take place in idle loop, rather than at interrupt time. allowing sharing of the spi bus.  new configuration options to allow usage of the sd card to be specified.  * fix problem with hardware spi pins  servo update  update lpc builds to use platformios ldf limited to strict mode  need to identify why incompatible libraries are still included without specifically disallowing them  update the sdcard usb sharing config and apply to re-arm  remove debug output from flash persistent store implementation ", "linked_issue_titles": "", "title": "pull out framework, improve build, fix things"}
{"description": " inside pro.h, the keys that are normally \"ralt\" and \"fn\" were swapped, causing confusion in making keymaps, since fn needed to be left of ralt in the keymap when the physical key is to the right. my personal keymap is also included, which i adjusted alongside my fix for these two keys being swapped. default keymap is already correct and does not need to be changed for this (although rgui is used instead of fn. maybe good use of fn couldn't be made here?) added via support. json made by me is being submitted to via repo. config.h has been changed to have bootmagic row/column defined for this board to use esc instead of lshift for bootmagic. firmwares in question have been compiled and flashed to my board with my keymap & tested. first pr, always open to feedback on how to do things better. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " added wholesomeducky keymap for gmmk pro  finalized keymap & added 1000hz polling for gmmk pro  corrected for ralt and fn being swapped  fixed ralt and fn being swapped in the layout definition. updated personal keymap to reflect fixed layout.  removed an old comment from personal keymap for gmmk pro ", "linked_issue_titles": "", "title": "fixed bootmagic lite support; added personal keymap and via support"}
{"description": " this pr fixes the issue that crashed and abnormal sessions are also counted as errored in release health as an example, even though we only have crashed sessions in this example and the total adoption is an accurate measure of how many sessions have been captured which are 7 sessions, the graph shows double that amount as errored sessions. changes: subtract crashed and abnormal from errored session count added test ", "commit_messages": " added node14js support for lambda integration  subtracted crashed from errored to avoid duplication of data  added extra checks to ensure that errored now excludes abnormal and crashed ", "linked_issue_titles": "", "title": "discount crashed and abnormal sessions from errored sessions"}
{"description": " fixes #11441, continues and closes #14463 add comments to clarify spectral clustering algorithm as asked by @gaelvaroquaux. @glemaitre not sure your comments have been addressed. ", "commit_messages": " update comments in spectral.py  clarified what variable maps corresponds to.  update comments in spectral_embedding_.py  update comments in spectral_embedding_.py to clarify laplacian normalization and use of initial approximation of eigenvectors for lobpcg.  update comments in spectral.py  added comment to clarify exact eigenproblem that is solved.  fix formatting spectral.py  deleted line break.  update spectral.py  remove trailing whitespace  update spectral_embedding_.py  removed trailing whitespaces  remove comment describing csgraph_laplacian  remove comment describing csgraph_laplacian return variables when norm_laplacian=true  merge with upstream ", "linked_issue_titles": " spectral clustering algorithm documentation clarification ", "title": "add comments to clarify spectral clustering and spectral_embedding"}
{"description": " hi there this pr adds the ability to add annotations to traefik dashboard's service. this is useful when using tools like external-dns. thank you! jh ", "commit_messages": " update readme.md  add service annotation to configuration table  add annotations to traefik dashboard's service  this commit allows for annotations to be added to traefik dashboard's service. this is useful when using tools like [external-dns]( ", "linked_issue_titles": "", "title": "add annotations to the traefik dashboard service"}
{"description": " related to #2182 this force the user to have an unlocked wallet before he is able to send a transaction. since every transaction is required to have at least one authorizer now, i feel that this behaviour makes sense. ", "commit_messages": " add locked wallet assertion  separate wallet not available and not existent exception ", "linked_issue_titles": "", "title": "make cleos complains about locked wallet"}
{"description": " an initial implementation of gatsby functions. learn more at the rfc at #27667 post feedback at #30735 test this by installing gatsby@functions-next & adding functions: true to your flags in your gatsby-config.js. ", "commit_messages": " add new plugin  add functions plugin by default  add stub  bump up package.json  wip  compile all functions found in build  add plugin by default only if gatsby_experiment_functions is set  move to public for now  move to functions dir  run a dev server for functions  wip  move to onprebootstrap  add target node  bump up package.json  bump up package.json  add support for env vars  publish 0.1.0-4  bump up peerdependencies ", "linked_issue_titles": "", "title": "add the ability to run functions locally and on gatsby cloud"}
{"description": " the e0397 explanation, as i've written it, isn't really an explanation, but i'm not sure what to put here. i will happily take suggestions. partially addresses #25851 ", "commit_messages": " update e0015 explanation, fix e0053.  add error explanations for e0040, e0087, e0378, e0379, e0394.  convert mutable statics error to have error code and add explanation.  also changes 'owned pointers' => 'boxes' in the error message. ", "linked_issue_titles": "", "title": "add 5 more error explanations. update e0015's explanation. add an error code."}
{"description": " this is a naive implementation of what has been working for us internally. ", "commit_messages": " bpo-35022: add support for __fspath__ to magicmock  the magicmock class supports many magic methods, but not __fspath__. to ease  testing with modules such as os.path, this function is now supported by default.  add test  documentation ", "linked_issue_titles": "", "title": "add __fspath__ support to unittest.mock.magicmock"}
{"description": " match header to inbox header, fix mobile styles. fix margin from footer on bottom of page  before mobile new mobile ", "commit_messages": " fix(ui): remove margin from footer on alerts  fix(ui): match alerts to inbox headers ", "linked_issue_titles": "", "title": "adjust alerts header to match inbox, mobile fixes"}
{"description": " breaking change: this change breaks existing service call references to the media_player.epson_select_cmode services by changing the service calls to be epson.select_cmode. my understanding is that because this is not a service provided by the base media_player component, it should live in the domain of the epson component instead. if that's the case, then it also makes sense to update the service name. description: update the domain and service name for epson.select_cmode. see this comment for context: #28890 (comment) related issue (if applicable): related to #27289 pull request with documentation for home-assistant.io (if applicable): n/a checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. ", "commit_messages": " update .coveragerc, move epson constants to const.py, move epson cutsom service to epson domain  newline in services.yaml ", "linked_issue_titles": "", "title": "update service domain for epson from 'media_player' to 'epson'"}
{"description": " libdebug now supports walking the chain of dw_tag_inlined_subroutine entries in dwarf to get the list of source positions in the inline chain for a given address in the program. this pr also contains various requirements for implementing this, a bugfix (5ef0fb4) and some refactoring in libdebug. example backtrace of crash -r: backtraces should now be easier to understand, for example here we can see the location in the code of crash (crash.cpp:282) that caused the refptr assertion failure. thanks @gunnarbeutner for suggesting to implement this ", "commit_messages": " libdebug: fix typo in debuginfo::get_source_position  libdebug: remove unused debuginfo::for_each_source_position  libdebug: move get_die_at_offset to dwarf::compilationunit  libdebug: move dwarf::attributevalue to a separate file  libdebug: store libdebug objects on the heap & make them non-copyable  this fixes an issue were some libdebug objects (for example,  dwarf::compilationunit) held a reference to their parent  dwarf::dwarfinfo object, which was constructed on the stack and later  moved to the heap.  libdebug: move dwarf::lineprogram into dwarf::compilationunit  previously, the lineprogram objects were short-lived, and only created  inside debuginfo::prepare_lines() to create a vector of sorted lineinfo  data.  however, dwarf::lineprogram also contains other useful data, such as  index-to-string mapping of source directories and filenames.  this commit makes each dwarf::compilationunit own its  dwarf::lineprogram.  debuginfo::prepare_lines() then iterates over the compilation units to  prepare its sorted vector of lines.  libdebug: add lineprogram::get_directory_and_file(size_t)  this function returns the directory path & filename for a given file  index.  ak: add redblacktree::find_largest_not_above_iterator  it's a version of find_largest_not_above that returns an iterator. ", "linked_issue_titles": "", "title": "show inlined functions in backtraces"}
{"description": " the internal nfacct plugin: is now synced with the current development of netdata can collect connection tracker metrics too; fixes #161 the plugin still requires netdata to be running as root. the next step is to move it away from the netdata daemon to an external plugin, that will be setuid to root. but in order to do this, it has to be merged with the internal netfilter plugin, so that only one method of netfilter data collection will be used at any time. so, if netlink is available it should be used, otherwise the proc filesystem should be used, but if even this is not available the plugin should stop and exit. ", "commit_messages": " update nfacct plugin to match current netdata development  nfacct plugin with static dimension pointers  properly initialize global structures  properly initialize the just allocated global structures  convert nfacct to linked-list instead of array  added connection tracking information via netlink  netfilter plugin - final touch before moving it outside netdata ", "linked_issue_titles": " netdata uses obsolete procfs for conntrack data - netfilter.plugin ", "title": "data collection of netfilter connection tracker metrics using netlink (libmnl)"}
{"description": " changed makefile and forced mac os x using either gcc-5 or clang-omp, since the -lopenmp flag fails the default xcode compiler and causes confusions when linking. added pippack subroutine in makefile for packaging for pip installation changed manifest.in, the most important part, by adding refactored code plus exclusion to .a files which can fail linux build-on-the-fly changed setup.py and setup_pip.py, added prep_pip.sh for supporting updated pip install and, submitted 0.6a2 tag to pypi, tested with mac os x 10.10, ubuntu 14/16 and centos 7 with no problem ", "commit_messages": " force gcc-5 or clang-omp for mac os, prepare for pip pack  add sklearn dep, make -j4  finalize pypi submission ", "linked_issue_titles": "", "title": "pypi (pip installation) setup for 0.6 code"}
{"description": " context we need to support multiple pages and layouts in the app. this pr enables us to have routing, pages, and layouts. it adds a basic sidebar navigation component. closes unify-308 naive navbar ui note currently, the schema stitching @tgriesser added is preventing the component tests from compiling. features and bonuses we have a router, with url-based navigation + back/forward support we have layouts and pages. pages can have metadata (like a human-readable name) declared in <route> blocks we have a 404 page :-) new ui sidebarnavigation sidebarnavigationrow how to test yarn dev --project packages/launchpad from the workspace root launch a browser navigate to the /vite/ app path see the router, layouts, etc and click through them to see the pages change ", "commit_messages": " feat: adding navigation to the frontend app  cleaning up markup  adding layout and navigation and pages  setimmediate fix ", "linked_issue_titles": "", "title": "adding navigation, pages, router, and layout"}
{"description": " this pr moves the data-oriented parts of feature gating into its own crate, rustc_feature. the parts consist of some data types as well as accepted, active, removed, and builtin_attrs. feature gate checking itself remains in syntax::feature_gate::check. the parts which define how to emit feature gate errors could probably be moved to rustc_errors or to the new rustc_session crate introduced in #66878. the visitor itself could probably be moved as a pass in rustc_passes depending on how the dependency edges work out. the pr also contains some drive-by cleanup of feature gate checking. as such, the pr probably best read commit-by-commit. r? @oli-obk ", "commit_messages": " introduce crate rustc_feature and move active, accepted, and removed to it  move stability to rustc_feature  move attributetemplate to builtin_attrs  simplify gated cfgs logic  builtin_attrs: inline some strings  move is_builtin_attr to syntax::attr  builtin_attrs.rs -> rustc_feature  inline two explanation constants  move unstablefeatures -> rustc_feature  check.rs: inline a constant  tidy: adjust feature gating path  update rustc_feature crate docs  move gateissue to rustc_feature & simplify emit_feature_err  derive(default) for features ", "linked_issue_titles": "", "title": "feature gating declarations => new crate rustc_feature"}
{"description": " this contains @ethomson's failing test that checkout was incorrectly recreating a deleted file even in safe checkout mode, plus it has the fix for the problem and some extra new checkout test helpers that make it easier to look at exactly what checkout is doing. ", "commit_messages": " test asserting checkout should not recreate deleted files  fix checkout of modified file when missing from wd  this fixes the checkout case when a file is modified between the  baseline and the target and yet missing in the working directory.  the logic for that case appears to have been wrong.  this also adds a useful checkout notify callback to the checkout  test helpers that will count notifications and also has a debug  mode to visualize what checkout thinks that it's doing. ", "linked_issue_titles": "", "title": "checkout should not recreate deleted files - with fix"}
{"description": " fixes #12336 part 3. add datasourcepreparer and environmentchecker for opengauss implement opengaussdatasourcepreparer close un-used data sources part of unit test ", "commit_messages": " add datasourcepreparer abd environmentchecker for opengauss  get first actual data node and related data source of all logic tables  close un-used data sources  impl opengaussdatasourcepreparer  refactor, prepare for index name rewrite  get create logic table sqls  unit test ", "linked_issue_titles": " create sharding tables automatically in target data sources before scaling task starting ", "title": "scaling prepare tables part 3 : implement opengauss dialect"}
{"description": " with this pr, when comparing two object types we first check that the source type contains all properties required by the target type. only when that is the case do we then proceed to compare the types of the properties. previously we'd do both of these things in the same pass which could cause us to needlessly drill into the (possibly deep) types of matching properties only to later discover that other properties are missing (meaning that the types are not related). as can be seen from the baseline differences, we now bail out quicker when types are not related. this reduces noise in error messages and should also help performance. ", "commit_messages": " check all properties are present before checking types in relationships  accept new baselines ", "linked_issue_titles": "", "title": "compare shapes of objects before comparing contained types"}
{"description": " related issue (if applicable): fixes # the code change is tested and works with tasmota core esp32 v.1.0.7 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " update xdrv_54_lvgl.ino  fix compile error with lvgl define and without use_berry defined  update xdrv_54_lvgl.ino  fix compile error without berry define. ", "linked_issue_titles": "", "title": "fix compile error with berry defined."}
{"description": " fixes #16691 the reason for the bug is typeof document.all that it returns undefined. indeed this behavior is called \"willful violation\" based on this site \" warning i can't write tests because jsdom hasn't implemented document.all yet. jsdom/jsdom#3028 but if you have any suggestions for writing them down. i'd be happy to write them down. test plan correct typeof document.all error ", "commit_messages": " add html_all_collection type to correct typeof document.all ", "linked_issue_titles": " devtools: failed to execute 'postmessage' on 'window': #<htmlallcollection> could not be cloned. ", "title": "fix devtools crash when inspecting document.all"}
{"description": " adds contributing to flutter: getting started to the contributing.md related issues none no code changes. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. ", "commit_messages": " adds contributing to flutter artcile link  updates article title ", "linked_issue_titles": "", "title": "adds contributing to flutter article link"}
{"description": " adds another field (\"request.method\") to the structured logfile audit. this field is present for all events associated with a rest request (not a transport request) and the value is one of get, post, put, delete, options, head, patch, trace and connect. closes #29765 ", "commit_messages": " walk in the park  tabs are evil ", "linked_issue_titles": "", "title": "security audit includes http method for requests"}
{"description": " this is a continuation of pr #13362 started by @ptrendx titled \"add nhwc layout support to pooling (cudnn only)\".  we're in agreement that i'm the best one to push this work forward to a point of final acceptance. based on reviewer comments, i've expanded the support of the newly introduced 'layout' parameter to include cpu and cuda implementations, not just cudnn.  also 3d support in cudnn and graceful fallback for mkldnn.  i've re-enabled and expanded the testing of test_operator_gpu.py:test_pooling_versions.  i understand and avoid the earlier flakiness of that test, which was due to inclusion of the pooling_v1 operator in some problem domains where its definition differs.  the initial commit here is identical to the last one made by @ptrendx for pr #13362.  follow-up commits will add this new functionality and additional description. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " adds layout support: mx.sym.pooling(..., layout='nhwc',...) with tests.  docs changes  trigger  skip nhwc pooling tests on non-cudnn platforms  fix pylint nhwc pooling  fixes from review ", "linked_issue_titles": "", "title": "add nhwc layout support to pooling (cpu, gpu cuda, gpu cudnn)"}
{"description": " hi @potiuk, this pr fix gcs copy operation without wildcard and rename destination object according to source file name. related: #9803 ", "commit_messages": " fix bug in gcs copy operation  change test copy operation with different_delimiter_and_destination_object ", "linked_issue_titles": "", "title": "#9803 fix bug in copy operation without wildcard"}
{"description": " addresses issue #1174 ", "commit_messages": " new method getsupportedcallingcodes() (java)  cpp code: not yet tested because of santa :/  fixing cpp build issues  - adding pending_code_changes.txt  - removed the \"using std::\" statements in the .h file and fixing the c++  and test code accordingly  removed redundant code, ported to js, compiled.  modified jars. ", "linked_issue_titles": "", "title": "added new api for getsupportedcallingcodes"}
{"description": " commit message: this proposes an email template for announcing the security fix of the main branch. risk level: n/a testing: n/a docs changes: this provides supporting information release notes: n/a ", "commit_messages": " templates: add an emlai template for announcing security fix of main branch  restructure ", "linked_issue_titles": "", "title": "add an email template for announcing security fix of main branch"}
{"description": " fixes eos_logging idempotency issue when trying to set both logging destination and facility. (#31862) added fix for the idempotency issue added new integration tests added fix in changelog.md eos_logging.py ansible version stable-2.4 ", "commit_messages": " fixes eos_logging idempotence issue #31862 (#40604)  * eos_logging idempotence fix  * fixed eos_logging idempotence issue  * fixed pylint and pep8 errors  * added tests for eos_logging & minor fix  * removed q statements  (cherry picked from commit b9ea6468398d23c4b9c39f0c91cd79bf0b61af5d)  added eos_logging fix in changelog ", "linked_issue_titles": "", "title": "fix eos_logging idempotency issue cp into 2.4"}
{"description": " cleanups made while working on other prs. addresses some glitches in the matrix. ", "commit_messages": " whitespace clean  fix m503 s parameter  move temperature reporting to temperature class  general ubl/g26 code cleanup  standardize lcd interface code for ubl a little  allow buffer clean without release command  changes for parity with 2.0.x ", "linked_issue_titles": "", "title": "cleanup, bugfixes, parity with 2.0.x"}
{"description": " continuation of #9304 ", "commit_messages": " more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  more strict aliasing  strict aliasing in c++20  build fix  update types.h ", "linked_issue_titles": "", "title": "strict aliasing via c++20's char8_t (merged with master)"}
{"description": " closes #57554, closes #43459 this is my first contribution to the open source world! write tests for setting make tests use different settings ", "commit_messages": " add tabclosingorder, set default mru and use setting to focus next tab  change domaction name ", "linked_issue_titles": " make closing tab to open next/previous tab instead of mru  allow to close tabs from left to right rather than in order of most recently focused ", "title": "add setting for tab closing order"}
{"description": " we mention in the contributing docs that we expect the airbnb style guide for javascript, but this wasn't actually enforced in our eslintrc. this pr adds the base airbnb style rules, with some exceptions for the ones that we're currently violating and might require some discussion. also note that this doesn't yet include the airbnb react style rules ", "commit_messages": " require airbnb style guide (without react)  automatic style fixes (from eslint --fix)  manual style fixes, and disable often-violated rules  enable no-underscore-dangle rule  enable class-methods-use-this (mark methods as static) ", "linked_issue_titles": "", "title": "enforce airbnb style guide rules"}
{"description": " add t5 model convert to transformers-cli did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. @patrickvonplaten @sgugger @lysandrejik members/contributors which may be interested in your pr. ", "commit_messages": " update run_mlm.py  add t5 model to transformers-cli convert  update rum_mlm.py same as master  update converting model docs  update converting model docs ", "linked_issue_titles": "", "title": "add t5 convert to transformers-cli"}
{"description": " this pr does the following changes: the default model class to benchmark is the one that can be found under config.architectures improve plotting file ", "commit_messages": " add benchmark for all kinds of models  improved import ", "linked_issue_titles": "", "title": "extend benchmark to all model type extensions"}
{"description": " summary we can now test the sequence api on python3. this pr aims at enabling those tests on travis. related issues pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) ", "commit_messages": " split sequence test from generator tests  use_spawn check for windows  do not copy use_spawn ", "linked_issue_titles": "", "title": "split generators tests from sequence tests"}
{"description": " this pr adds two new optional arguments to draggablescrollablesheet called snap and snapsizes. if snap is false (default value), the widget's behavior remains unchanged. if snap is true, the widget will snap to snapsizes when the user's finger leaves the screen during a drag. see for details: #34111 (comment). this is achieved by replacing (if a snap should occur) the sheet's ballistic simulation in _draggablescrollablesheetextent.goballistic with one that snaps to targets instead of moving forward until velocity is dissipated. fixes: #34111 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " hijack helloworld  added snap points and snaping behavior  working in basic scenario ", "linked_issue_titles": " add drag length parameter to draggablescrollablesheet ", "title": "add snapping behavior to draggablescrollablesheet"}
{"description": " description: we need a way to run the deprecated field check on the routeconfiguration. today the schema check tool validates the bootstrap config. this change will help achieve similar functionality on routes served from rds. risk level: low testing: manual testing docs changes: included release notes: included ", "commit_messages": " deprecated check  docs  docs ", "linked_issue_titles": "", "title": "deprecated field check in route checker tool"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " directly give the bbox property to all objects  add unions along side existing types  add iteration example ", "linked_issue_titles": "", "title": "add discriminated unions for geojson types"}
{"description": " every use of apply_mark in a built-in or procedural macro is supposed to look like this location.with_ctxt(syntaxcontext::root().apply_mark(ecx.current_expansion.id)) where syntaxcontext::root() means that the built-in/procedural macro is defined directly, rather than expanded from some other macro. however, few people understood what apply_mark does, so we had a lot of copy-pasted uses of it looking e.g. like span = span.apply_mark(ecx.current_expansion.id); , which doesn't really make sense for procedural macros, but at the same time is not too harmful, if the macros use the traditional macro_rules hygiene. so, to fight this, we stop using apply_mark directly in built-in macro implementations, and follow the example of regular proc macros instead and use analogues of span::def_site() and span::call_site(), which are much more intuitive and less error-prone. ecx.with_def_site_ctxt(span) takes the span's location and combines it with a def-site context. ecx.with_call_site_ctxt(span) takes the span's location and combines it with a call-site context. even if called multiple times (which sometimes happens due to some historical messiness of the built-in macro code) these functions will produce the same result, unlike apply_mark which will grow  the mark chain further in this case. after apply_marks in built-in macros are eliminated, the remaining apply_marks are very few in number, so we can start passing the previously implicit transparency argument to them explicitly, thus eliminating the need in default_transparency fields in hygiene structures and #[rustc_macro_transparency] annotations on built-in macros. so, the task of making built-in macros opaque can now be formulated as \"eliminate with_legacy_ctxt in favor of with_def_site_ctxt\" rather than \"replace #[rustc_macro_transparency = \"semitransparent\"] with #[rustc_macro_transparency = \"opaque\"]\". r? @matthewjasper ", "commit_messages": " audit uses of apply_mark in built-in macros  replace them with equivalents of span::{def_site,call_site} from proc macro api.  the new api is much less error prone and doesn't rely on macros having default transparency.  resolve: do not rely on default transparency when detecting proc macro derives  incremental: do not rely on default transparency when decoding syntax contexts  using expnids default transparency here instead of the mark's real transparency was actually incorrect.  hygiene: require passing transparency explicitly to apply_mark  remove default macro transparencies  all transparancies are passed explicitly now.  also remove #[rustc_macro_transparency] annotations from built-in macros, they are no longer used.  #[rustc_macro_transparency] only makes sense for declarative macros now. ", "linked_issue_titles": "", "title": "audit uses of apply_mark in built-in macros + remove default macro transparencies"}
{"description": " update vulkan loader and headers to sdk-1.2.131.2 (headers are actually sdk-1.2.131.1, they did not get a re-release.) also synced vma 2.3.0 again, fixing unwanted clang-formatting of thirdparty code. glslang: sync with upstream 4fc7a33 for vulkan sdk 1.2.131 1231c2e fixes #36888. @bruvzg could you check if the glslang patch is still needed for macports mingw builds? (for the reference, previous discussion about it: #29993 (comment)) @faless fyi, this glslang version adds some emscripten components that we might want to integrate in our buildsystem eventually: $ ls thirdparty/glslang/glslang/osdependent/web/ glslang.after.js  glslang.js.cpp  glslang.pre.js ", "commit_messages": " update vulkan loader and headers to sdk-1.2.131.2  (headers are actually sdk-1.2.131.1, they did not get a re-release.)  also synced vma 2.3.0 again, fixing unwanted clang-formatting of  thirdparty code.  glslang: sync with upstream 4fc7a33 for vulkan sdk 1.2.131  fixes #36888. ", "linked_issue_titles": " clang 10 failure with glslang ", "title": "update vulkan sdk to 1.2.131.2 and matching glslang version"}
{"description": " this pr stringify the secretsmanager response to mirror ssm behaviour when getting a parameter that references a secret. 3496 ", "commit_messages": " stringfy secret reference value  adds test checking for sourceresult data type  fixes indentation  fixes indentation  fixes indentation  stringify secretsresponse ", "linked_issue_titles": "", "title": "ssm wrong output when referencing secretsmanager"}
{"description": " this pr adds another github action that runs type checks (using the mypy toxenv) and reports the current status to  example: in the above example, the selenium.common package is fully typed (green color & 100% coverage), while selenium.webdriver.chrome.options module is not - more details can be found in tox_mypy job log, where mypy will report an error for the line. in this example: selenium/webdriver/chrome/options.py:25: error: implicit generic \"any\". use \"typing.dict\" and specify generic parameters selenium/webdriver/chrome/options.py:28: error: function is missing a type annotation (relevant spot in the job log for reference) this way, one should be able to easily track the typing errors. this is a proposal to address the discussion in #9482. it is added for @automatedtester for an evaluation! also, once merged into master, codecov should start tracking the changes in upcoming prs, comparing typing coverage against the current master (an example on how it will look like, although this comment actually reports code coverage difference). once all typing errors are resolved (thus a 100% typing coverage achieved for the complete python codebase), we can stop reporting the typing coverage and just run tox -c py/tox.ini in tox_mypy job. it will then simply fail on new typing errors. i have read the contributing document. ", "commit_messages": " [py] add github action for type checking  temporarily enable running ci from ci/branchname  ignore mypy exit code  allow passing arguments in mypy toxenv, add lxml dependency for cobertura reports  record and upload cobertura report in mypy gh action  don't write inline comments for dependencies  use correct coverage report path to upload to codecov  revert running actions on ci/branchname ", "linked_issue_titles": "", "title": "run type checks in ci and report typing coverage to codecov"}
{"description": " related ticket: #1208 this pull request adds support for max_retries as an argument to requests.request. i think that since we already support timeout as a top-level argument then it makes sense to support max_retries too. i've added a unit test, but this is a very difficult thing to test for. i can't see any easy way to simulate an unreliable connection. please let me know what you think. ", "commit_messages": " [kennethreitz/requests#1208] adding a max_retries argument  [kennethreitz/requests#1208] adding unit test for max_retries ", "linked_issue_titles": "", "title": "adding max_retries as an argument"}
{"description": " i noticed the current types for react-redux-toastr were for version 3.6 and mostly outdated. i ended up essentially rewriting the types from ground up. at least one place where i'm not sure if the types are correct: i've written types for the redux action creators explicitly instead of using actioncreator<actions>. follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " react-redux-toastr: unify code style  react-redux-toastr: change react.component types to use state and props  react-redux-toastr: change to named imports  react-redux-toastr: remove module declaration  react-redux-toastr: add union types for known strings  react-redux-toastr: rename toastrconfirmoptions to confirmtoastroptions for unified style, refine properties  react-redux-toastr: add interfaces for all of the toastr option objects  react-redux-toastr: refactor some variables to alphabetical order  react-redux-toastr: add interfaces to toastrs in reducer state, add toastr action payload, toastr reducer state  react-redux-toastr: rename toastoptions to toastroptions to unify style  react-redux-toastr: rename toastroptions to reduxtoastrprops and rewrite properties  react-redux-toastr: slight refactor of reduxtoastrprops  react-redux-toastr: remove confirmoptions interface  react-redux-toastr: remove duplicate confirmtoastroptions interface  react-redux-toastr: rewrite toastremitter, modify tests to comply with version 7.0.0  react-redux-toastr: rewrite action creators, start using toastrstate  react-redux-toastr: slight refactor, alphabetize stuff  react-redux-toastr: remove unused component state and props ", "linked_issue_titles": "", "title": "rewrite types for package v7.0.0 and typescript 2.4"}
{"description": " there is lots of code in core.internals inside try/except blocks, in particular calls to _try_coerce_args.  it is tough to reason about these because it is often unclear what the raising cases are.  this simplifies that problem by separating values, args = self._try_coerce_args(values, args) into values = self._coerce_values(values) and args = self._try_coerce_args(args)  (note the former doesnt have a \"try\" in the name because it never raises). also: removed a never-used ndim kwarg from block.make_block and removed a now-redundant datetimetzblock.copy method. ", "commit_messages": " separate coerce_values from coerce_args  remove redundant method, move non-raising outside try  remove ndim kwarg from make_block  small cleanup ", "linked_issue_titles": "", "title": "separate raising from non-raising parts of method"}
{"description": " in pull_requests.md description: config dump risk level: small? testing: unit test docs changes: n/a(is config_dump auto gen doc enough?) release notes: config_dump handler prints out secret discovery service information ", "commit_messages": " sds config dump single cmt due to dco...  spelling check. ", "linked_issue_titles": "", "title": "config dump for secret discovery service."}
{"description": " not sure if we want to fix it like this, but i think this is a problem that we are going to keep having. related #6621 fixes: #5937 issue originally found and explained by @meikidd, see: #5937 (comment) this pr fixes a regression introduced in 7.7.0 by this pr: #6155 this pr is based on the fix by @dispatchcommit in #6621 but with a bit more \"magic\" closes: #6621 ", "commit_messages": " feat: add a named request animation frame function  implement ", "linked_issue_titles": " high cpu usage after the player stays in background for a while ", "title": "add named requestanimationframe to prevent performance issues"}
{"description": " hi andreas, here a few small improvements i found during implementing the json schema validator. i know the double printing could be improved a lot with the \"%x.yf\" notion, but today i have only a limited version that has %.6f implemented ;-) ", "commit_messages": " ak: print double numbers with printf  this patchset allows double numbers to be printed with the printf function.  the fraction will always be printed as 6 digit number. this can be improved :^)  ak: a few json improvements  * add double number to object serializer  * handle negative double numbers correctly  * handle \\r and \\n in quoted strings independently  this improves the situation when keys contain \\r or \\n that currently  has the effect that \"a\\rkey\" and \"a\\nkey\" in an json object are the  same key value. ", "linked_issue_titles": "", "title": "print double numbers with printf & a few json improvements"}
{"description": " small refactorring of serbian language abbreviation. changed from \"rs\" -> \"sr\" i have submitted the spacy contributor agreement. ", "commit_messages": " serbian stopwords added. (cyrillic alphabet)  spacy contribution agreement included.  test initialize updated  merge remote-tracking branch 'upstream/master'  serbian language code update. --bugfix ", "linked_issue_titles": "", "title": "serbian language code update \"rs\" -> \"sr\""}
{"description": " add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr is a continuation of the work @gitkrystan did in #46278, now that @jamescdavis's refactorings to have qunit expose es module declarations on its own have landed. big thanks to both of them for making this easy to pull over the finish line! note: dt recently had a prettierrc added, and my editor was pretty insistent about applying formatting updates, so the first commit here is just me pre-applying that before actually changing anything. the latter two contain the actual content of this change. ", "commit_messages": " apply dt's prettier formatting before i actually touch anything  annotate this for nested hooks with ember-qunit  add test coverage for this in nested hooks ", "linked_issue_titles": "", "title": "provide this type for module nestedhooks"}
{"description": " this pr addresses a long-standing issue where h2o uses the certificate on the disk when fetching ocsp response for stapling. the problem has been that if the certificate on the disk gets changed (e.g., by an acme client) but h2o is not restarted, the certificate being used and the ocsp response being stapled become inconsistent. this inconsistency leads to tls handshake failures. this pr addresses the issue by using the certificate chain being loaded at boot time for stapling. builds on top of #2879. to be merged after #2879. ", "commit_messages": " [xcode] set file format  [fetch-ocsp-response] load file from stdin, if not specified  [h2o] retain certificate chain in pem format, supply that to fetch-ocsp-response ", "linked_issue_titles": "", "title": "use loaded cert rather than what's on the disk"}
{"description": " issues solved: when metrics is not valid in query(), the error message gives 'nonetype' has no attribute sqla_col, which is not very descriptive count_distinct was transfered to count_distinct(col) expression in sqllab_viz todo: refactor all metrics_creation pr to a consistent place needs-review @mistercrunch @bkyryliuk ", "commit_messages": " return error message when metrics are not valid  fix bug with count distinct expression ", "linked_issue_titles": "", "title": "fix sql expression bug with count distinct metrics"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: <> ", "commit_messages": " heading/text align props update,  flex prop overflow removed  button color, header accblty level, tab props tab  video couple onhandlers ", "linked_issue_titles": "", "title": "updated header/text, video element,  removed flexprop overflow and minor changes"}
{"description": " last of #3625 on top of implementing the new parameterized way of using addons for info, i also added made changes regarding how the options and parameters were processed with respect to each other, #3625 (comment). before, the addon parameters would be the ones that were the latest set (global -> local -> story), replacing the previous ones entirely. now, it only replaces the addon properties per key, #3625 (comment). i don't think my solution in lib/core/src/client/preview/client_api.js is the cleanest one, so if anyone else has a better idea, happy to hear! i tried some stuff with reduce but that only made more of a mess. i applied similar logic to the handling of options and parameters. core tests 2 snapshot tests failed in 1 test suite, both output: - snapshot + received ... - <component> + <deprecated> this seems unrelated to my changes, or am i mistaken? ", "commit_messages": " implement params for info + merge the options and params  add examples of the param implementation  update the documentation with the new possibilities ", "linked_issue_titles": "", "title": "use parameters for info addon"}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. run tsc without errors. include the required files and header. base these on the readme, not on an existing project. ", "commit_messages": " adding type definition for  adding lint and fixing issues reported by it  fixig issues ", "linked_issue_titles": "", "title": "adds type definition for koa-jwt (https://github.com/koajs/jwt)"}
{"description": " i successfully installed pipenv with pip and tried to run for the first time only to encounter this error: traceback (most recent call last): file \"/library/frameworks/python.framework/versions/3.4/bin/pipenv\", line 11, in <module> load_entry_point('pipenv==3.2.4', 'console_scripts', 'pipenv')() file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py\", line 560, in load_entry_point return get_distribution(dist).load_entry_point(group, name) file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py\", line 2642, in load_entry_point return ep.load() file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py\", line 2296, in load return self.resolve() file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pkg_resources/__init__.py\", line 2302, in resolve module = __import__(self.module_name, fromlist=['__name__'], level=0) file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pipenv/__init__.py\", line 1, in <module> from .cli import cli file \"/library/frameworks/python.framework/versions/3.4/lib/python3.4/site-packages/pipenv/cli.py\", line 17, in <module> from requests.packages.urllib3.exceptions import insecurerequestwarning importerror: cannot import name 'insecurerequestwarning' this was due to my installed version of requests being 2.3.0.  upon upgrading requests to 2.4.0 and above, pipenv runs fine. as such, i've qualified the version requirement in setup.py ", "commit_messages": " qualified version of requests to >2.3.0  updated requests version required to >=2.4.0  updated requests version required to >=2.4.0 ", "linked_issue_titles": "", "title": "qualfied version of requests required to >2.3.0"}
{"description": " adds a \"sync\" label to translation sync prs checks if any existing prs have that label before creating a new one. motivation this lets us run the sync script in bulk and not have to worry whether duplicates will be created. ", "commit_messages": " do not create a new pull request if a label exists  add the labels to the created prs ", "linked_issue_titles": "", "title": "(scripts/i18n) check if an existing sync pr exists before creating a new one."}
{"description": " the step pulse widths are longer than expected for the lpc1768, due & teensy35_36.  this is because the stepper_timer_prescale macro was wrong. here are the before and after numbers for lpc1768 & due all numbers are in microseconds minimum_stepper_pulse is the setting in configuration_adv.h minimum_stepper_pulse  0    1    2    3    4    8 lpc1768 previous               0.6  6.1  9.5  13.0 18.5 corrected              0.6  1.1  2.1  3.1  4.0  8.2 due     previous               1.1  6.0  6.0  8.6  11.3 18.6 corrected              1.1  1.4  2.0  3.1  4.0  7.8 we may want to drop the teeny35_36 change because i don't have one to verify against. if i read the code correctly the teeny35_36 step pulse is infinite.  i have a hard time believing that so i expect someone will step up with a different explanation. the current macros end up with pulse_timer_prescale being zero because of the following defines: #define stepper_timer_prescale   0 // not defined anywhere else! #define pulse_timer_prescale    stepper_timer_prescale the following defines the width of the x, y & z step pulses.  since pulse_timer_prescale is zero the while loop will never terminate. while (extra_cycles_xyze > (uint32_t)(hal_timer_get_count(pulse_timer_num) - pulse_start) * (pulse_timer_prescale)) { /* nada */ } ", "commit_messages": " correct pulse_timer_prescale macro  switch to stepper_timer_prescale ", "linked_issue_titles": "", "title": "correct step pulse width on lpc1768, due & teensy35_36"}
{"description": " @rocketchat/core closes #9873 this pr allows to customize the message that will be displayed at the end of the conversation in livechat widget. ", "commit_messages": " message of the conversation finished has been added.  new setting added to display a message when the livechat conversation has ended. ", "linked_issue_titles": "", "title": "livechat setting to customize ended conversation message"}
{"description": " the updated scripts need new binding generators. on windows use .bat linux and mac use .sh ", "commit_messages": " issue #3781, update genbinding script to fit new bindings-generator.  issue #3781: fix the variable name.  issue #3781, add windows bat script.  issue #3781, js not generate cocos2dx physics now.  issue #3781, undefine the __mingw32__ macro to fix the script error on windows ", "linked_issue_titles": "", "title": "issue#3781 update script for each platform bindings generating."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " :bust_in_silhouette: adjust username  :label: add definition for constructor and method 'endpdf' with buffer  :white_check_mark: add test for constructor and method 'endpdf' with buffer  :rotating_light: remove linter error 'prefer-const' ", "linked_issue_titles": "", "title": "adjust username; add definition and test for for constructor and method 'endpdf' with buffer"}
{"description": " our telemetry-sourced bugs have a ton of call stacks like this, where it isn't obvious which refactor triggered it (tons of them have a dochange function) and it isn't obvious which assert failed without checking out very specific versions of tsserver.js and digging into the line numbers: error: debug failure. false expression. at dochange (tsserver.js:116689:22) at unknown (tsserver.js:116680:96) at function.changetracker.with (tsserver.js:111861:17) at object.getcodeactions (tsserver.js:116680:64) at unknown (tsserver.js:112847:121) at object.flatmap (tsserver.js:573:25) at object.getfixes (tsserver.js:112847:23) at unknown (tsserver.js:122423:35) at object.flatmap (tsserver.js:573:25) at object.getcodefixesatposition (tsserver.js:122421:23) at suppressed_frame() at suppressed_frame() at iosession.session.getcodefixes (tsserver.js:131477:64) this pr adds messages to all the assert* family calls in these two folders. as a follow-up we could also do the same for cast as that has a few ambiguous stacks as well. in most cases i tried to make the assert messages globally unique rather than making them consistent, since this will make looking them up later easier. ", "commit_messages": " add comments to assert calls  add comments to assert calls in codefixes ", "linked_issue_titles": "", "title": "add assert comments in codefixes and refactors"}
{"description": " as an alternative to #1287 this implements the core git rules for config section and key validation with new code that is based on what already existed in libgit2. the rules, for reference, that are implemented are: the top-level section name (i.e. before the first period) and the trailing key name (i.e. after the last period) must consist entirely of alphanumeric characters and dashes, the first character cannot be a dash, and all the letters will be mapped to lower case. also, these parts cannot be missing. any middle section name, if it exists, must not contain newlines. these rules are enforced both when you go to set a value in a config file and when you attempt to rename a section of config file. this pr includes a new test that @nulltoken wrote which i copy-pasted from the above mentioned pr. ", "commit_messages": " test buf join with null behavior explicitly  implement config key validation rules  this is a new implementation of core git's config key checking  rules that prevents non-alphanumeric characters (and '-') for  the top-level section and key names inside of config files.  this also validates the target section name when renaming  sections.  test config name validation  this is @nulltoken's work to test various invalid config section  and key names and make sure we are validating properly. ", "linked_issue_titles": "", "title": "stricter config entry name validation"}
{"description": " this pr contains sources for a new 'devexpress-web' types version: add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). asp.net controls and mvc extensions -> client api reference asp.net bootstrap controls -> client api reference dashboard -> asp.net client api reference reporting -> client api reference (webforms & mvc) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " added new major version 191.5  recovered old tslint config  upgraded to 19.1.6  added new major version 192.3 ", "linked_issue_titles": "", "title": "added new devexpress-web major version 192.3"}
{"description": " this cleans up the code and avoids potentially significant js overhead in the common case. ", "commit_messages": " demangle fserror stacks only in assertions, and not all the time; and only do the workaround for node.js 4 in legacy_vm_support, to avoid stack trace overhead  fix  better ", "linked_issue_titles": "", "title": "improve fserror stacks only in assertions, and not all the time"}
{"description": " what's this pr do? this pr mitigates memory leaks on the stream. there are still many more to be fixed, but it's a start. this intended to address \"streammanager does not remove items from groupstore (memory leak)\" in #1585, but none of the leaks we saw were actually related to groupstore. where should the reviewer start? src/sentry/static/sentry/app/components/dropdownlink.jsx how should this be manually tested? using the chrome debugging tools, you can profile the memory use of the stream before and after the changes in this branch. what gif best describes this pr or how it makes you feel? ", "commit_messages": " refactors and bootstrap tooltip delegation  bootstrap tooltips were being added to every column of the barchart. now a  single tooltip is delegated to the barchart component. also, the chart columns  are no longer rendered asynchronously.  there was also some general method extraction refactoring.  fix memory leaks on stream  fixed some memory leaks on the stream caused by several factors including bound  dom events that were never released. there are still leaks, but many fewer.  some components of streamactions were refactored into components for  clarity.  the datepicker was a large source of memory leaks and was non-functional, so we  commented it out.  * redesign/react: (29 commits)  minor fixes to standardize embed  lint  fill userreport.group_id on save  index userreport(project_id, event_id)  format issuetrackingplugin labels with format_html  fix default project query  correct checking of request.sentry  various additions to error embed  support name/email initial data params  ignore embed js  remove some unused bits  basic functional submission and error handling  various responsive fixes  add close action  various responsive features for modal  various stylistic tweaks to modal  add embeddable error feedback  fix tag handling from url params  use entirety of parsed query in stream search  changes for 7.6.2  ... ", "linked_issue_titles": "", "title": "fix memory leaks in stream"}
{"description": " improve code coverage about 1 percent. fix #6193 fix #6192 perfect test cases in dubbo-common perfect test cases in dubbo-remote add runnablewrapper to manage exception in threadlessexecutor fix empty check in statustelnethandler ", "commit_messages": " feat(test): perfect test cases in urlstrparser  feat(test): perfect test cases in baseservicemetadata  feat(test): perfect test cases in hashedwheeltimertest  feat(test): perfect test cases in executorrepository  feat(threadpool): use runnablewrapper to manage exception  feat(test): perfect test cases in threadlessexecutor  feat(test): perfect test cases in common.utils  feat(test): perfect test cases in transporters  feat(test): perfect test cases in remoting.utils  feat(test): perfect test cases in exchangers  feat+fix(telnet, test): perfect test cases in telnet, fix miss check health when get status without parameter  fix(test):fix executor url  fix(test):fix executor url  fix(test):fix executor pool size in jdk 11  fix(format):fix file format in statustelnethandler ", "linked_issue_titles": " [bugfix] telnet unable get proper health when execute 'status' without parameter  [enhancement] threadlessexecutor unable to handle all exceptions ", "title": "improve code coverage and fix some code"}
{"description": " i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. none of my changes are plagiarized from another source without proper attribution. my article does not contain shortened urls or affiliate links. if your pull request closes a github issue, replace the xxxxx below with the issue number. ", "commit_messages": " expand infosec & qa article  expand the information security & quality assurance root article.  fixing capitalization in infosec title. ", "linked_issue_titles": "", "title": "expand certifications/information security and quality assurance article stub"}
{"description": " i have an ergodox ez with the left led hack in place ( would like to add back in support in erogodox_ez.c for this hack. currently it's implemented using #define left_leds (as it was done previously), but i'm totally flexible. the current implementation just cycles the lights on boot; keymap specific code is required to do anything useful on layer switch, etc. (you can see a trivial example here: ", "commit_messages": " add initial support for left leds on an ergodox ez  update left led support  implement ergodox_left_leds_update in ergodox_ez  previously, this code was implemented in keymap.c, but i'm unaware of  someone with a different implementation of this particular hack. [if  someone has it, we can add another #ifdef in the future.]  document how to define left_leds and how that hack is done ", "linked_issue_titles": "", "title": "ergodox ez left leds support"}
{"description": " this pull request adds support for named amd modules and addresses the pain point of using typescript-generated amd modules when anonymous modules and out-of-the-box bundlers (like r.js) are not an option. this feature was previously discussed at ", "commit_messages": " initial support for named amd modules.  added a compiler test for named amd modules. ", "linked_issue_titles": "", "title": "adding support for named amd modules."}
{"description": " closes #12800 changing to streams will make it lighter on both client and server. the first batch of online/away users will come from a rest request (thus will not flood websocket) and only further changes on status will come though ddp. update presence package to include a change on clients to not call connect anymore presence package process instance removals on each instance, which generates lots of duplicate status changes if an instance goes down/updates test without upm ", "commit_messages": " change users publications for rest calls  get active users on startup and listen for changes  better handling reconnections  support streamcast  change full user subscription to no use users collection ", "linked_issue_titles": "", "title": "change user presence events to meteor streams"}
{"description": " per issue #1124 ", "commit_messages": " initial commit for adding support for amazon linux 2015.03  merge remote-tracking branch 'upstream/master'  base rhel/amazon/centos detection on system-release and ubuntu on lsb-release  remove unnecessary conditionals from amazon.sh ", "linked_issue_titles": "", "title": "add support for amazon linux 2015.03"}
{"description": " fixes #11387 ", "commit_messages": " :lipstick:  renames  :lipstick: let -> const  small refactorings  pass in actual editors  be aware of line mapping when rendering diff view zones and diff overview decorations  push view zones to accomodate equal but differently wrapped lines  add iviewmodel.createlinebreakscomputer()  do not store the original content in the diff information for inline diff margin actions  render inline diff view zones in batch  improve rendering of view zones with changed or deleted text (inline diff editor) ", "linked_issue_titles": " support word wrap in the diff editor ", "title": "add support for word wrap in diff editor"}
{"description": " add api on adding recent documents add api for user tasks of jumplist set application dock menu add a guide on desktop environment integration fixes #746. ", "commit_messages": " override => override in browser.h  cocoa: enable modifying initialized menu  cocoa: enable creating empty menu  fix displaying context menu for devtools  override => override in atom_api_app.h  add app.dock.setmenu api ", "linked_issue_titles": " add support for taskbar extensions ", "title": "add api for windows jump list and mac application dock menu"}
{"description": " centralize all options at the root for easier discovery. renaming all_the_debug_macros  ->  enable_all_the_debug_macros for consistency with the rest of the options. making this enable_all_the_debug_macros an option makes it visible to users and tooling and formalize the type of the argument. making this build_lagoms an option makes it visible to users and tooling and formalize the type of the argument. ", "commit_messages": " cmake: consolidate all options to the root of the project  cmake: remove some trailing whitespace from a few cmakelists.txt files ", "linked_issue_titles": "", "title": "consolidate and document all options to the root of the project"}
{"description": " this change makes rodeos be able to get the rabbits stream addresses for queues or exchanges from environment variables. --stream-rabbits arg                  addresses of rabbitmq queues to stream to. format: amqp://user:password@addres s:port/queue[/streaming_route, ...]. multiple queue addresses can be specified with ::: as the delimiter, such as \"amqp://u1:p1@amqp1:5672/queue1 :::amqp://u2:p2@amqp2:5672/queue2\".if this option is not specified, the value from the environment variable eosio_stream_rabbits will be used. --stream-rabbits-exchange arg         addresses of rabbitmq exchanges to stream to. amqp://user:password@address :port/exchange[::exchange_type][/stream ing_route, ...]. multiple queue addresses can be specified with ::: as the delimiter, such as \"amqp://u1:p1@amqp1:5672/exchange1:::am qp://u2:p2@amqp2:5672/exchange2\".if this option is not specified, the value from the environment variable eosio_stream_rabbits_exchange will be used. this pr is done for rodeos following the changes for amqp_trx_plugin in nodeos and for cleos - #10829 . select one: select any that apply: ", "commit_messages": " epe-1577 rodeos accept rabbits queue or exchange from environment variables  epe-1577 improved help message ", "linked_issue_titles": "", "title": "epe-1577 rodeos getting stream addresses for queues or exchanges from environment variables"}
{"description": " fixes #4643 formula for decayed adagrad operator: moment_out = decay * moment + (1 - decay) * grad * grad param_out = param - learning_rate * grad / (sqrt(moment_out) + epsilon) ", "commit_messages": " implementing the decayedadagrad optimizer step operator  implementing decayedadagrad operator  remove file ", "linked_issue_titles": "", "title": "implementing the decayed adagrad optimizer operator"}
{"description": " the new registry asset spacy.emptykb.v1 creates an empty kb with a configurable entity length. this is used with a default length in case the user doesn't specify anything in their config for the entity_linking component. the kb constructor does not take a vocab argument anymore - this can be set (kb.initialize) when the el pipe is created. this now generates a new el component with custom length - without going through the hassle of calling the knowledgebase constructor etc: nlp.add_pipe(\"entity_linker\", config={\"kb\": {\"entity_vector_length\": 35}}) if ok, i'll document this separately on the nightly docs branch. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " el field documentation  documentation consistent with docs  default empty kb, initialize vocab separately  formatting ", "linked_issue_titles": "", "title": "default empty kb in el component"}
{"description": " absence of this tag was causing morphology.pyx to fail when assigning tag ids. types of changes bug fix (non-breaking change fixing an issue) new feature (non-breaking change adding functionality to spacy) breaking change (fix or feature causing change to spacy's existing functionality) documentation (addition to documentation of spacy) checklist: my change requires a change to spacy's documentation. i have updated the documentation accordingly. i have added tests to cover my changes. ", "commit_messages": " fix(model): fix tag map for fixing issues with tag space  merge remote-tracking branch 'upstream/master'  fix(model): add space to es tag_map. fixing error in morphology.pyx when sp tag is missing ", "linked_issue_titles": "", "title": "add space to es tag map"}
{"description": " adds a golden test for a few material icons (first, last, and variants). this will help validate upcoming icon font updates will look something like: ", "commit_messages": " create icons golden test  update icons_test.dart ", "linked_issue_titles": "", "title": "add material icons golden test"}
{"description": " this pr is exactly the same as #7688 with updates to the build file to make tests pass so that we can merge the changes in. closes #7134 and #7688 @eronwright : not sure if you saw updates to #7688 asking for tweaks to the pr to make the tests pass. if you want to update that pr instead, i'm happy to abandon this one. otherwise, will merge this one in and abandon the other. ", "commit_messages": " [java] [feature] load from savedmodel  - add savedmodelbundle class  [java] [feature] load from savedmodel  - incorporate feedback  [java] [feature] load from savedmodel  - incorporate feedback (2)  [java] [feature] load from savedmodel  - update build file to new location for junit  [java] [feature] load savedmodel  - format files using google-java-format  (see ", "linked_issue_titles": "", "title": "ability to load from savedmodel"}
{"description": " tldr: reduces the time it takes to get from flutter run to an interactive debugging session. locally this reduces the startup time for a dirty application from ~40 seconds in the flutter gallery to about ~12 seconds. the default behavior of flutter run is to build the platform binary (apk, ipa) as necessary and update it on the device before starting a debug session. this artifact is almost always invalidated whenever the user restarts a debugging session, because it depends on all dart sources, assets, and native dependencies. depending on the speed of the user's workstation, this can take anywhere from several seconds to several minutes to rebuild. both dart code and flutter assets can be loaded at runtime from the devfs instead of from the apk - this is how hot restart works. if the dart source code and assets are removed as inputs from the apk, then invalidations will only occur on flutter version updates or plugin changes, which will be significantly less frequent than source code changes. instead of building the user's application in the initial apk, we build the empty \"splash\" application which looks like so: after syncing files, the tool performs a silent hot restart to begin the debugging session. known issues: ides are not supported because we cannot hot restart into a paused state #45424 ", "commit_messages": " example of fast start functionality  add splash application ", "linked_issue_titles": "", "title": "support --fast-start for android applications (as an opt-in)"}
{"description": " this pr will add flexibility and allow more configuration for nextcloud deployments: allow to put extra php configs put all default configuration if custom configurations are set for this particular case, if one extra config is set, the rsync exclude will prevent the first copy of all default configurations files. allow to have annotations on pvc cronjob follow redirect for cases like having https but not managed by the ingress controller (aws elb for example) image, affinity, tolerations and resources can be changed just for cronjob instead of using nextcloud deployment one change mount path to allow the creation of a tmp directory in volume instead of using the /tmp which is on kubernetes nodes (large files upload can be in trouble when using the /tmp) use the fs group of www-data (33) for mounted files (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " [stable/nextcloud] allow to inject custom php configuration files  [stable/nextcloud] add annotations and labels on pvc  [stable/nextcloud] add fs group of www-data for mounted files  [stable/nextcloud] change mount path of pvc  [stable/nextcloud] add tmp directory in volume  this directory can be used for uploads as temporary directory  [stable/nextcloud] fix cronjob job template labels for new helm spec  [stable/nextcloud] allow change of cronjob image and add pull secrets  [stable/nextcloud] allow change cronjob resources,tolerations,affinity  [stable/nextcloud] cronjob (curl) follow redirect  [stable/nextcloud] add default values for persistence annotations  [stable/nextcloud] add all default nextcloud configurations  [stable/nextcloud] update documentation with new values and indent  [stable/nextcloud] upgrade chart version ", "linked_issue_titles": "", "title": "add flexibility and more configurations"}
{"description": " since #5702 coldwhite and warmwhite channels were inverted. now channels are back to rbbcw (and not rgbwc) **related issue (if applicable): #5761 the pull request is done against the latest dev branch only relevant files were touched (also remember to update changelog.ino file) only one feature/fix was added per pr. the code change is tested and works. the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " fixed: wc/ww were inverted, back to rgbcw  fixed: wc/ww were inverted, back to rgbcw ", "linked_issue_titles": "", "title": "coldwhite/warmwhite channels were inverted, back to rgbcw"}
{"description": " modify travis-ci: use python 3.6.5 instead of the latest python 3.8. it seems that travis-ci is failing (mac with python3) in recent prs. originally brew upgrade python used python 3.7. it changes to use 3.8 recently and mypy type check fails in python 3.8. error log is here: clang -wno-unused-result -wsign-compare -wunreachable-code -fno-common -dynamic -dndebug -g -fwrapv -o3 -wall -iast27/include -i/usr/local/cellar/python@3.8/3.8.3_2/frameworks/python.framework/versions/3.8/include/python3.8 -c ast27/parser/acceler.c -o build/temp.macosx-10.13-x86_64-3.8/ast27/parser/acceler.o ast27/parser/acceler.c:13:10: fatal error: 'pgenheaders.h' file not found #include \"pgenheaders.h\" ^~~~~~~~~~~~~~~ 1 error generated. error: command 'clang' failed with exit status 1 ---------------------------------------- error: failed building wheel for typed-ast running setup.py clean for typed-ast failed to build typed-ast installing collected packages: typed-ast, mypy, onnx running setup.py install for typed-ast ... error error: command errored out with exit status 1: ", "commit_messages": " merged  update from upstream  merged  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "fix travis-ci on mac with python3 and circleci with stable vision"}
{"description": " fixes color range when dxva processor is used for rendering. fixes a possible segfault in video drivers when driver supports only fl9.1/9.2 re-factoring: see commit details. ", "commit_messages": " [dxva] fix dxva renderer color range.  [winvideofilter] lower feature level for test shader. this fixes segfault in video drivers which support only fl9.1/9.2. ", "linked_issue_titles": "", "title": "a set of fixes for directx."}
{"description": " the cmakelists that i tested worked on linux but not on win32. i made small fixes to get it to work on win32 platform. this probably needs more thorough testing, to make sure nothing is broken on other platforms where it is supposed to work but that i couldnt test on. ", "commit_messages": " adding headers in src files so they appear in ide  basic fixes for win32 builds  fixed network link library curl in win32 case : libcurl_imp ", "linked_issue_titles": "", "title": "fixing cmake project for win32"}
{"description": " this is a bug introduced in #26694 . the issue comes from the attempt to share code that commits the new history uuid and/or a new translog uuid. this goes wrong an existing 5.6 index that is recovered from store: a new history uuid is generated as it doesn't exist in the index the translog is opened and it's uuid doesn't change. the committing the new history uuid used the standard commitindexwriter method. the latter asks the translog for the oldest file generation that is required to recover from the local checkpoint + 1 the local checkpoint on old indices is -1 (until something is indexed) and the translog is asked to recover from position 0. that excludes any operations the translog that do not have a seq no assigned, causing the fullclusterrestart bwc tests to fail. to bypass this pr moves away from the attempt to share the committing code between a new translog uuid and a new history uuid. instead we do what we did before and open the translog with a potential commit. afterwards we commit the history uuid if needed. this comes with the expense of opening up the method to commit an index writer in the engine. this pr is opened against 6.x . we have the option to leave the code on master as is. let me know which you prefer for the long term. i can go either way. ", "commit_messages": " roll back combined history/translog commit  move back to a follow history uuid commit, so not to confuse people that expect a commit to have translog info  relax assertions  name ", "linked_issue_titles": "", "title": "generating and committing a history_uuid on existing old indices destroys translog recovery info"}
{"description": " close #3488 depend on  deno.cachedir() deno.configdir() deno.datadir() deno.datalocaldir() deno.audiodir() deno.desktopdir() deno.documentdir() deno.downloaddir() deno.fontdir() deno.picturedir() deno.publicdir() deno.templatedir() deno.videodir() if the directory does not exist, an exception is thrown e.g. deno.downloaddir() not every linux has a download directory todo: test case ", "commit_messages": " merger upstream ", "linked_issue_titles": " want: more dir api for system ", "title": "add more dir api for deno"}
{"description": " i've fixed a few minor errors in the windows and wsl building documentation; specifically an incorrect link title (windows.md), an unclear article title (windowssubsystemforlinux.md) and an outdated link to msdn (windowssubsystemforlinux.md). ", "commit_messages": " update windowssubsystemforlinux.md  clarified article title, updated msdn link  clarify wsl article link ", "linked_issue_titles": "", "title": "clarified and corrected wsl/windows documentation"}
{"description": " this is a followup to #31886. after that commit the transportconnectionlistener had to be propogated to both the transport and the connectionmanager. this commit moves that listener to completely live in the connectionmanager. the request and response related methods are moved to a transportmessagelistener. that listener continues to live in the transport class. ", "commit_messages": " wip  remove connection listener from transport  add methods  fix checkstyle ", "linked_issue_titles": "", "title": "move connection listener to connectionmanager"}
{"description": " fixes: #4117 i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " f-string update rsa_cipher.py  f-string update rsa_key_generator.py  f-string update burrows_wheeler.py  f-string update non_recursive_segment_tree.py  f-string update red_black_tree.py  f-string update deque_doubly.py  f-string update climbing_stairs.py  f-string update iterating_through_submasks.py  f-string update knn_sklearn.py  f-string update 3n_plus_1.py  f-string update quadratic_equations_complex_numbers.py  f-string update nth_fibonacci_using_matrix_exponentiation.py  f-string update sherman_morrison.py  f-string update levenshtein_distance.py  fix lines that were too long ", "linked_issue_titles": " refactor: use f-strings instead of str format ", "title": "changes occurences of str.format to f-strings"}
{"description": " original pull-request #33065 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " out of bounds column index  add a test  merge #33050 ", "linked_issue_titles": "", "title": "cherry pick #33065 to 21.12: merge #33050"}
{"description": " fixes #8978 during testing of docker with device mapper backend, i often noticed bunch of warnings on console and often thought that if something is wrong with my docker setup. it turned out that docker does not keep track of already used device ids.  this patch series should make docker little bit smarter about it. more details are in issue and patches. please review and pull. thanks vivek ", "commit_messages": " devmapper: move file write and rename functionality in a separate function  currently we save device metadata and have a helper function savemetadata()  which converts data in json format as well as saves it to file. for  converting data in json format, one needs to know what is being saved.  break this function down in two functions. one function only has file  write capability and takes in argument about byte array of json data.  now this function does not have to know what data is being saved. it  only knows about a stream of json data is being saved to a file.  this allows me to reuse this function to save a different type of  metadata. in this case i am planning to save nextdeviceid so that  docker can use this device id upon next restart. otherwise docker  starts from 0 which is suboptimal.  devmapper: export nextdeviceid so that json.marshal() can operate on it  i was trying to save nextdeviceid to a file but it would not work and  json.marshal() will do nothing. then some search showed that i need to  make first letter of struct field capital, exporting this field and  now json.marshal() works.  this is a preparatory patch for the next one.  devmapper: save and restore nextdeviceid in a file  the way thin-pool right now is designed, user space is supposed to keep  track of what device ids have already been used. if user space tries to  create a new thin/snap device and device id has already been used, thin  pool retuns -eexist.  upon receiving -eexist, current docker implementation simply tries the  nextdeviceid++ and keeps on doing this till it finds a free device id.  this approach has two issues.  - it is little suboptimal.  - if device id already exists, current kenrel implementation spits out  a messsage on console.  [17991.140135] device-mapper: thin: creation of new snapshot 33 of device 3 failed.  here kenrel is trying to tell user that device id 33 has already been used.  and this shows up for every device id docker tries till it reaches a point  where device ids are not used. so if there are thousands of container and  one is trying to create a new container after fresh docker start, expect  thousands of such warnings to flood console.  this patch saves the nextdeviceid in a file in  /var/lib/docker/devmapper/metadata/deviceset-metadata and reads it back  when docker starts. this way we don't retry lots of device ids which  have already been used.  there might be some device ids which are free but we will get back to them  once device numbers wrap around (24bit limit on device ids).  this patch should cut down on number of kernel warnings.  notice that i am creating a deviceset metadata file which is a global file  for this pool. so down the line if we need to save more data we should be  able to do that. ", "linked_issue_titles": " snapshot creation failure warnings on console ", "title": "save restore device id: issue #8978"}
{"description": " renamed the folders and projects as per powerrename. there are 3 folders under imageresizer: dll : contains the imageresizerext project (previously shellextensions) ui : contains the imageresizerui project (previously imageresizer) tests : contains the imageresizeruitest project (previously imageresizer.test) all files and references of shellextensions has been replaced by imageresizerext. added an empty readme.md file for imageresizer. pr checklist applies to #53 cla signed. if not, go over here and sign the cla tests passed validation steps performed build/install/run debug/release x64 all test cases pass ", "commit_messages": " created empty readme file  renamed dll project  removed shellextensions references in src  fixed imageresizerui assembly name and added changes to msi ", "linked_issue_titles": "", "title": "refactor imageresizer code base naming to match powerrename"}
{"description": " related issue = #3775 #2489 problem: with the introduction of pretty exception mechanism, the \"excepthook\" and \"_taichi_skip_traceback\" are no longer needed. therefore i removed all occurrences and  make respective changes to documents. briefing of changes: remove all occurrences of \"excepthook\" and \"_taichi_skip_traceback\" change descriptions of pretty traceback messages rename \"misc/demo_excepthook.py\" to \"misc/demo_traceback.py\" ", "commit_messages": " deprecate excepthook and cleanup all _taichi_skip_traceback. ", "linked_issue_titles": "", "title": "deprecate excepthook and completely remove _taichi_skip_traceback"}
{"description": " this pr takes care of correcting a series of crashes and incorrections on async gpu & vulkan. resume of changes: remove cpu query cache invalidation on async gpu, as async gpu always flushes and invalidates them. on async gpu, shader & pipeline invalidations from the cpu will no longer be instant and instead use the sync interface. corrected an issue in vulkan's pipeline cache where if a shader had an invalid address, it wouldn't use a null shader instead of trying to decompile it. ", "commit_messages": " videocore: use syncguestmemory mechanism for shader/pipeline cache invalidation.  vkpipelinecache: use a null shader on invalid address. ", "linked_issue_titles": "", "title": "correct a series of crashes and intructions on async gpu and vulkan pipeline"}
{"description": " currently when a user with talkback active begins to type in a text field, the hint is immediately hidden triggering a secondary read of the nodes semantic info.  to avoid this, we always include the hint semantics in the semantics tree, regardless of whether it is hidden by text. additionally, we remove the label from the semantics tree when focused, as it moves up and away and is de-emphasized. fixes #16673 work towards #15187 ", "commit_messages": " correct order of text field semantics  undo extra change to text field  merge  change semantic visitor order for text field  update test to reflect current order ", "linked_issue_titles": " android a11y: hint is not read out when textfield is toggled to edit mode ", "title": "toggle whether label or hint contribute to text field semantics when unfocused/focused"}
{"description": " improvements to the g-code parser. add parser shorthand functions to get a parameter (or default value). use parser.seenval for cases where a value is required. patch some spacing, comments ", "commit_messages": " apply const, spacing, etc.  cleanups to gcode.h, use seenval() ", "linked_issue_titles": "", "title": "use parser.seenval, add shorthand functions"}
{"description": " note: before submitting this pull request, please review our contributing guidelines. sometimes when publishing a chord with a large header a race condition occurs when the group result isn't saved before one of the tasks of the header completes. this regression was introduced in #4443 when the saving of the group result was moved after publishing the chord's header. even after rearranging the code so that header_result.save() would come first there was a problem since the code that freezes the group didn't use the same task_id as the one that the group was published with. this is now also fixed. ", "commit_messages": " added a test case which artificially introduces a delay to group.save().  fix race condition by delaying the task only after saving the group. ", "linked_issue_titles": "", "title": "fix a race condition when publishing a very large chord header"}
{"description": " hi there, this is my first pull request to rust :-) i started implementing some specializations for doubleendediterator::nth_back() and these are the first two. the problem has been discussed in #54054 and nth_back() is tracked in #56995. i'm stuck with the next implementation so i though i do a pr for the ones i'm confident with to get some feedback. ", "commit_messages": " implement nth_back for box  implement nth_back for windows ", "linked_issue_titles": "", "title": "implement specialized nth_back() for box and windows."}
{"description": " what's in this pull request? dynamic casts to anyobject should succeed for an arbitrary source type because we can always make a swiftvalue. resolved bug number: (sr-2420) resolved bug number: radar #26268575 before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " perform collection force-casts by force-casting the elements  instead of forcing conditional casts of the elements.  this should produce better and more compact code, allow more  efficient runtime behavior, and generate much better runtime  diagnostics if the cast fails.  dynamic casts to anyobject should succeed for an arbitrary source  type because we can always make a swiftvalue.  rdar://26268575 ", "linked_issue_titles": "", "title": "dynamic casts to anyobject should succeed for all types via swiftvalue"}
{"description": " overview this change includes the basics of the sqlite index; namely the metadata table and schema versioning.  it also adds the overarching class that will be used to contain the sqlite index for the consumers above.  finally, the versioning scheme for creating new schemas is begun and detailed below. design the object stack is as such: sqliteindex :: houses the database connection and the proper interface with which to interact with it isqliteindex :: interface that creates a uniform model to use against all schemas schema::v*::interface :: actual implementation of isqliteindex for specific schema version the code that needs to interact with an index will create a sqliteindex object.  that in turn will open the database, determine the schema version, then create the appropriate isqliteindex providing object.  all queries and changes to the index will go through the sqliteindex object. when a change to the schema is needed, a new schema directory should be created.  this can pull code from the schemas before it, only updating the specific table(s) that are needed.  then version code should be updated to create the new interface as appropriate.  any new methods needed on isqliteindex should be added, and sqliteindexbase to implement them in terms of the older functions.  only the new schema should need to implement the new functions.   once shipped, one should never need to update code within an existing schema, save for bug fixes. testing tests are added for creating a new sqlindex, and reopening it with the various dispositions. tests were also added for the new savepoint sqlite wrapper class. ", "commit_messages": " begin index code  checkpoint  forgotten project files  checkpoint  checkpoint  checkpoint  finished baseline code for index with metadata.  needs more complete testing. ", "linked_issue_titles": "", "title": "add the basis for the sqlite index"}
{"description": " some changes needed to install libraries and headers and small addition in testing lib to read wasm and abi files directly. ", "commit_messages": " install libs and headers  updated tester to read wasm and abi files, and updated submodules ", "linked_issue_titles": "", "title": "install libs and support for eosio.system repo"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. ", "commit_messages": " add chayns typings version 0.14.0  fixes for tslint ", "linked_issue_titles": "", "title": "add typings for chayns version 0.14.0"}
{"description": " this adds the feature #8852 requested ", "commit_messages": " add overwrite directory feature to savedmodelbuilder  make indenting consistent to the rest of the code  change assertion error's message to reflect new parameter ", "linked_issue_titles": "", "title": "allow savedmodelbuilder to overwrite existing folders"}
{"description": " this pr adds unit tests for the top-level develop state machine. the child machines will follow. ", "commit_messages": " feat(gatsby): add top-level error handling to state machine  add initial tests  add tests for top-level machine  test error handling ", "linked_issue_titles": "", "title": "add unit tests for develop state machine"}
{"description": " a small cleanup / code consistency pr. no change in functionality. the wart that prompted this pr is the prior code called ::getenv() to sniff the electron_trash environment variable, then immediately used base::environment to sniff the desktop environment. this pr constructs the base::environment first so that it can be used in both places. also removes an unnecessary function wrapper and makes the trash argv builder easier to read. npm test passes pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " chore: use base::environment in moveitemtotrash() linux impl  chore: remove unnecessary local function xdgutil()  chore: tweak code comment ", "linked_issue_titles": "", "title": "use base::environment in linux moveitemtotrash()"}
{"description": " and then add a warning for using -print-stats in such a build, to make it easier to triage these issues in the future. rdar://problem/30386242 ", "commit_messages": " [test] disable -print-stats tests for no-asserts builds.  rdar://problem/30386242  warn when using -print-stats on a release build.  this should make it easier to catch issues like the previous commit  in the future. ", "linked_issue_titles": "", "title": "disable -print-stats serialization tests for no-asserts builds"}
{"description": " fix multiple values for keyword argument error in modelaverageoptimizer and elasticaverageoptimz. for detailed error, please look at here ", "commit_messages": " fix multiple values for keyword argument error  fix multiple values for keyword argument for easgd  place easgd in ea_coustom_getter scope  place ma_opt in ma_coustom_getter scope ", "linked_issue_titles": "", "title": "fix multiple values for keyword argument error in modelaverageoptimizer and elasticaverageoptimizer"}
{"description": " the changes made possible to make custom handler on mouse wheel events in qt and gtk for linux opencv build. reopened pr #6725 due merge checking problem ", "commit_messages": " highgui module: implemented qt and gtk mouse wheel callback support in linux  pull highgui mouse wheel changes linux into master  highgui module: removed unused type_mouse_event mouse_wheel  compilate switch-case with gtk_scroll_smooth since gtk>=3.4  highgui: window_gtk.cpp directive boolean operations or/and replaced by ||/&& to keep compatible with older systems  highgui module: a bit readable onmouse flags mapping  highgui module: using event->scroll.delta_{x,y} instead parsing direction and added widget event mask gdk_smooth_scroll_mask for gtk>=3.4  highgui module: mouse wheel - modification keys fixed, wheel event value is cv_event_mousewheel or cv_event_mousehwheel  highgui module: window_qt mouse wheel reuse variable delta instead call evnt->delta() ", "linked_issue_titles": "", "title": "implemented mouse wheel callback support for linux"}
{"description": " pr to fix #1776 added test_start and test_stop events to the base runner class' start() and stop() method, respectively added/updated relevant tests and documentation. ", "commit_messages": " toggled test condition and fixed broken event handler  added event to base runner.start() method  added dedicated tests for worker event changes  updated test_stop event  updated documentation ", "linked_issue_titles": " restore locust_start_hatching functionality ", "title": "fire test_start and test_stop events on worker nodes"}
{"description": " helps with #75080. @rustbot modify labels: t-doc, a-intra-doc-links, t-rustdoc known issues: the following f32 and f64 primitive methods cannot be resolved: f32/f64::powi f32/f64::sqrt f32/f64::sin f32/f64::cos f32/f64::powf f32/f64::exp f32/f64::exp2 f32/f64::ln f32/f64::log2 f32/f64::log10 f32/f64::mul_add f32/f64::abs f32/f64::copysign f32/f64::floor f32/f64::ceil f32/f64::trunc f32/f64::round links from core to std: links with anchors? i provided a separate commit that replaced links with anchors by intra-doc links. here the anchor location information gets lost, so its questionable whether to actually replace those links. ", "commit_messages": " use intra-doc links for ordering::*  use intra-doc links for atomicbool::*  use intra-doc links for atomicisize::*  use intra-doc links for atomici32::*  use intra-doc links for atomicu32::*  use intra-doc links for u32::*  use intra-doc links for f32::* and f64::*  use intra-doc links for sync::*  use intra-doc links for mem::*  use intra-doc links for ptr::*  use intra-doc linkks  use intra-doc links for compare_exchange and compare_exchange_weak  use intra-doc links for links with anchors ", "linked_issue_titles": "", "title": "move to intra-doc links for /library/core/src/intrinsics.rs"}
{"description": " some minor followups for that pr: add module integration code in shell.js, to avoid writing the js in emcc.py (which is at its maximum size this early in the compilation process, possibly hundreds of mb) just to add it, which is a little slower (a few %). do not force -o2 in test_modularize_closure_pre: while we won't have closure if -o0 or -o1, it's useful to see that the situation in that test passes in those modes as well fix an existing regression bug with debugging stuff like this, improper use of 'final' in emcc, which led to incorrect logging of temp files (if a method calls save_intermediate(), it must modify the global 'final' var, as that method reads it). in particular we logged the modularize temp file incorrectly. ", "commit_messages": " add module integration code in shell.js, to avoid writing the js in emcc.py (which is at its maximum size this early in the compilation process, possibly hundreds of mb) just to add it, which is a little slower (a few %)  do not force -o2 in test_modularize_closure_pre: while we won't have closure if -o0 or -o1, it's useful to see that the situation in that test passes in those modes as well  fix improper use of 'final' in emcc, which led to incorrect logging of temp files (if a method calls save_intermediate(), it must modify the global 'final' var, as that method reads it) ", "linked_issue_titles": "", "title": "followups for eval-removal 1 (#5751)"}
{"description": " fix #2923 for the npe add replaymethodsinvocation  for encryptpreparedstatement: replay  the cache properties such ad querytimeout ", "commit_messages": " sync from apache  fix for #2923  add the protected  querytimeout properties  fix for #2923  if null == preparedstatement, return the empty statement list  fix #2923  re add the querytimeout,set it zero when clear paramaters  add @sneakythrows  sync from apache  fix #2923 ", "linked_issue_titles": " when using encryptpreparedstatement to savebatch occours error ", "title": "fix #2923 add replaymethodsinvocation  for encryptpreparedstatement"}
{"description": " remove useless initilization for tw and th code ", "commit_messages": " emitter.start should setting quantity not adding  i think emitter.start should setting quantity not adding, maybe \"+=\" is a mistake?  remove useless initilization for tw and th code  tw and th have been initialized twice, the first time is useless. ", "linked_issue_titles": "", "title": "remove tw and th init"}
{"description": " closes #31507 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " remove \\n from docstring  fix conflicts  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fix issue 17038  revert change  revert change  fix uo ", "linked_issue_titles": " json_normalize in 1.0.0 with meta path specified - expects iterable ", "title": "non-iterable value in meta raise error in json_normalize"}
{"description": " fix #1149 ", "commit_messages": " fix room model's removebytypecontainingusername.  usernames field missing trailing 's'  deletes direct message subscription for users conversing with user being deleted.  fixes #1149 where \"other\" user's subscription for non-deleted, direct message, was not deleted.  this led to duplicate key error if a new user, with the same username as the deleted user, is created and tries to direct message the \"other\" user. ", "linked_issue_titles": "", "title": "remove direct message subscription for both users when one is deleted"}
{"description": " these commits partially revert my recent pr #10545, in favor of an implementation that uses the importscanner to compile any js modules that were not already compiled by compiler plugins, including modules found in .npm/package/node_modules directories. revert using _findsources to scan .npm/package/node_modules after much thought, i believe this implementation (#10545) would have caused severe compatibility problems when using packages published with earlier versions of meteor in a meteor 1.8.2 app, or when publishing packages with meteor 1.8.2 for use with earlier meteor versions. specifically, this implementation relied on writing the additional .npm/package/node_modules resources found by _findsources into the unibuild json file(s), and there just wasn't any good way to make sure the new json format could be safely consumed by previous meteor versions. even if we found a way to hide the new resources from older versions of meteor, perhaps by putting them in a new/different property of the unibuild json file, packages published with older meteor versions might try to load an npm package with a \"module\" field without realizing the code must be compiled, which would likely cause a syntax error in meteor 1.8.2, since the \"module\" field always gets preference over the \"main\" field of package.json (in meteor 1.8.2). backstop esm module compilation with reify in the importscanner instead of compiling esm syntax in node_modules using compiler plugins, the importscanner can provide \"native\" support for esm syntax by using reify to quickly compile just the import/export syntax in any imported modules that were not already handled by compiler plugins. since this code runs every time the app is built, it should not matter which version of meteor was used to publish a package. compared to the previous implementation (#10545), this implementation should have far fewer compatibility concerns, as well as being faster thanks to not processing or compiling modules until the importscanner determines that they are actually imported. the number of files that get compiled by this system should be relatively small for now, but to maintain good performance, the results of the compilation are cached on disk and in memory. ", "commit_messages": " revert using _findsources to scan .npm/package/node_modules.  after much thought, i believe this implementation (#10545) would have  caused severe compatibility problems when using packages published with  earlier versions of meteor in a meteor 1.8.2 app, or when publishing  packages with meteor 1.8.2 for use with earlier meteor versions.  specifically, this implementation relied on writing the additional  .npm/package/node_modules resources found by _findsources into the  unibuild json file(s), and there just wasn't any good way to make sure the  new json format could be safely consumed by previous meteor versions.  even if we found a way to hide the new resources from older versions of  meteor, perhaps by putting them in a new/different property of the  unibuild json file, packages published with older meteor versions might  try to load an npm package with a \"module\" field without realizing the  code must be compiled, which would likely cause a syntax error in meteor  1.8.2, since the \"module\" field always gets preference over the \"main\"  field of package.json (in meteor 1.8.2).  backstop esm module compilation with reify in the importscanner.  instead of compiling esm syntax in node_modules using compiler plugins,  the importscanner can provide \"native\" support for esm syntax by using  reify to quickly compile just the import/export syntax in any imported  modules that were not already handled by compiler plugins.  since this code runs every time the app is built, it should not matter  which version of meteor was used to publish a package. compared to the  previous implementation based on packagesource#_findsources and unibuild  json files (#10545), this implementation should have far fewer  compatibility concerns, as well as being faster thanks to not processing  or compiling modules until the importscanner determines that they are  actually imported.  though the number of files that get compiled by this system should be  relatively small for now, to maintain good performance, the results of the  compilation are cached on disk and in memory. ", "linked_issue_titles": "", "title": "support module syntax in importscanner, rather than using packagesource#_findsources."}
{"description": " fix \"too many connections of zookeeper datasource\" related to #612 save zkclient in a global map and reuse it 5 rules enabled echo cons | nc zookeeper.host 2181 check if there only exists one connection to zkserver ", "commit_messages": " com.alibaba.csp.sentinel.node.statisticnode#curthreadnum  using the longadder rather than atomicinteger to provides better performance  reformat the code according to alibaba java coding guideline  reformat the code according to alibaba java coding guideline  fix issue#612: too many connection of zookeeper datasource  reformat code ", "linked_issue_titles": "", "title": "fix too many connection of zookeeper datasource"}
{"description": " add some update statements ansible/modules/network/cloudengine/ce_bgp_neighbor_af.py ", "commit_messages": " update ce_bgp_neighbor_af modified information  update ce_bgp_neighbor_af to fix bugs (#60937)  * update ce_bgp_neighbor_af to fix bugs  * update ce_bgp_neighbor_af to fix bugs  * update ce_bgp_neighbor_af to fix bugs  (cherry picked from commit a2602090981a65652199423a185e3c2bd8b2c356) ", "linked_issue_titles": "", "title": "[backport/2.8/60937]update ce_bgp_neighbor_af to fix bugs"}
{"description": "", "commit_messages": " make sure the global asyncio event loop policy isn't changed.  by default there is no default event loop policy, so typically this is simply making sure it isn't set.  update tests to not leave an event loop policy behind  add a news entry ", "linked_issue_titles": "", "title": "check the global asyncio event loop policy isn't set after any tests"}
{"description": " try to implement keyboard shortcuts in the browse folder dialog by importing wine code jira issue: core-14332 import the wine commit which implement the shortcuts - import shellfolder.h to have isfhelper definition (that maybe let us get rid of some #ifdef reactos) now at least renaming via f2 key works, but not delete via del key get del also working (help or tips appreciated) ", "commit_messages": " [shell32] add shortcut to rename folders with the f2 key.  sync wine commit 2e25a43f3fb6230460447bae6fb5db2edbd4a42f by fabian maurer  [shell32] add shortcut to delete folders with the delete key.  sync wine commit 43f44ffb3779ff23c863d9b3297f92720e7e3733 by fabian maurer ", "linked_issue_titles": "", "title": "sync brsfolder.c with keyboard shortcut code from wine"}
{"description": " currently, kafkalog4jappender does not support linger.ms or batch.size. in some situations, those two parameters are good to tune the performance. ", "commit_messages": " kafka-10407: have kafkalog4jappender batch.size and linger.ms    currently, kafkalog4jappender does not support batch.size or linger.ms which would otherwise be beneficial in some situations.  removed import * ", "linked_issue_titles": "", "title": "have kafkalog4jappender support linger.ms and batch.size"}
{"description": " unify the terms and interface used for logging in to 1password  between the facts module and lookup plugins. onepassword.py onepassword_raw.py onepassword_facts.py ansible version 2.7 ", "commit_messages": " unify login behavior between 1password lookup plugins and module  - use the same names for all credential aspects  - only require the minimal amount of information for each  - add more examples  change parameter terms  - use terms in line with 1password documentation.  - update examples  - update tests ", "linked_issue_titles": "", "title": "unify terms and ui between 1password lookups and facts module"}
{"description": " another pr for #4475. refactor tracers config: move interface to include/ introduce factorybase to reduce boiler plate use config::utility to convert opaque config risk level: low testing: ci docs changes: n/a release notes: n/a ", "commit_messages": " move tracer config to its own file  introduce factory base  change interface to use opaque config only ", "linked_issue_titles": "", "title": "refactor tracers to use config::utility"}
{"description": " fixes #5668 for the entity linker training example, according to the first comment by @adrianeboyd . i have submitted the spacy contributor agreement. i ran the tests, and all new and existing tests passed. --> i tested the modified example code. ", "commit_messages": " entity linker training example: model loading changed according to issue 5668 (  contributor agreement ", "linked_issue_titles": "", "title": "fixed vocabulary in the entity linker training example"}
{"description": " fixes #2112 updated to vs2017 project format added description of how types are disposed i didn't update the actual code samples to include cover disposability; i just added an inline code section. perhaps @davidfowl could review. ", "commit_messages": " upgrade to vs2017 project format.  updated to describe how services container handles disposing of idisposable instances ", "linked_issue_titles": "", "title": "di disposing and project format upgrade"}
{"description": " apply #pragma once instead of using bracketing defines. clean up some formatting. remove some extraneous header includes. ", "commit_messages": " adjust some thermistors formatting  apply #pragma once in headers  misc cleanup and formatting ", "linked_issue_titles": "", "title": "apply #pragma once, misc cleanup"}
{"description": " before this pr, files are delivered by cloud pickle which can't deliver the independent modules. in this pr, a new api is introduced job_config = ray.job_config.jobconfig( runtime_env = { 'working_dir': '/mnt/data/test' } ) ray.init(address='auto', _redis_password='5241590000000000', job_config=job_config, logging_level=logging.debug) for the driver: it'll create a package and push it, if it doesn't exist for worker: it'll fetch the package if it doesn't exist. some implementation details here: filelock is used to avoid concurrent downloading package is uploaded to redis when the driver starts package is downloaded when the worker starts file size limit is added to avoid uploading too big files. some work to be done: adding gc to remove non-using pkg better delivering and caching logic ray client support closes #14527 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " prototype support  move downloading to other place  make it work  format ", "linked_issue_titles": " basic support for shipping code with working_dir and py_modules ", "title": "minimal support for runtime env"}
{"description": " attempt to detect and repair situations where optional unwrap is missing from operator/call arguments. don't suggest default value fix-it if effected argument belongs to inout operator parameter or enclosed in explicit address-of. resolves: rdar://problem/47776586 ", "commit_messages": " [cssimplify] detect missing optional unwraps in operator/call arguments  [diagnostics] refactor missing optional unwrap diagnostic  instead of passing all of the information available in the diagnostic  to static functions, let's bring \"default value\" and \"force unwrap\"  fix-it logic under \"missing optional unwrap diagnostic\" umbrella.  [diagnostics] don't suggest unwrap with default value if type is not materializable  [typechecker] nfc: add a test-case for rdar://problem/47776586 ", "linked_issue_titles": "", "title": "detect and diagnose missing optional unwrap in arguments"}
{"description": " this is better for editing the colors (you only need to change the style.css file) ", "commit_messages": " readme update for bin files  note for the esptool (nodmcu-flasher alternative)  all css in 1 file ", "linked_issue_titles": "", "title": "all css in one file"}
{"description": " r? @guillaumegomez ", "commit_messages": " remove unnecessary crate_name parameter to after_krate  it's always tcx.crate_name(local_crate), it doesn't need to be passed  in separately.  remove unnecessary diag parameter to after_krate  remove unnecessary edition parameter to renderer  remove unnecessary edition field on sharedcontext ", "linked_issue_titles": "", "title": "remove unnecessary fields and parameters in rustdoc"}
{"description": " deleted typography.js which unnecessarily complicates the example for styled-components moved createglobalstyle to a separate file with good practise ", "commit_messages": " delete typography.js which shouldn't be in the styled-components example  moved globalstyle to external file with good practise ", "linked_issue_titles": "", "title": "delete typography.js and move createglobalstyle to separate file for styled-components example"}
{"description": " general idea is to show using easily understood tools and metrics how to compare your site's performance, and to use these ideas to show rather than tell that gatsby v2 improves performance over gatsby v1. ", "commit_messages": " blog: start working on gatsby-perf blog post  blog: keep writing post  chore: keep working  blog: some more tweaks  chore: add source ", "linked_issue_titles": "", "title": "add web perf 102 blog post relating to gatsby v2"}
{"description": " fix rss icon too large in rss settings dialog remove trailing spaces fix download & upload icon too large on statusbar in webui ", "commit_messages": " fix rss icon too large in rss settings dialog  give a name to the rss icon (in .ui file)  add helper function: utils::misc::largeiconsize()  group functions under the same #ifdef  remove trailing spaces  fix download & upload icon too large on statusbar in webui ", "linked_issue_titles": "", "title": "fix new icons too large"}
{"description": " flags certain test cases in scheduler using package:test tags in order to facilitate landing support for running all framework tests in a browser. requires: #33349 ", "commit_messages": " changes to scheduler to faciliate web testing  remove extra skips ", "linked_issue_titles": "", "title": "compatibility pass on flutter/scheduler tests for javascript compilation. (2)"}
{"description": " i hereby agree to the terms of the cla available at:  detailed description / documentation draft: converted raw github issues / pulls url links to #ddddd format fixed typos added more detailed descriptions (copy-pasting from other versions of the same pr/issus) wrapped some queries and setting parts as code blocks typo: materialize *d* mysql -> materializemysql (although materialize d sounds natural...) ", "commit_messages": " docs: fix broken changelog link  docs: fix raw link to #ddddd  fix: typo and code blocks, missing explanations ", "linked_issue_titles": "", "title": "changelog issue/pr raw urls to #ddddd links, with some typo fixes"}
{"description": " back when for-loop iteration variables were just de-sugared into let bindings, debuginfo for them was created like for any other let binding. when the implementation approach for for-loops changed, we ceased having debuginfo for the iteration variable. this pr fixes this omission and adds a more prominent test case for it. also contains some minor, general cleanup of the debuginfo module. fixes #19732 ", "commit_messages": " debuginfo: create debuginfo for for-loop variables again.  debuginfo: clean the debuginfo module up a bit.  debuginfo: add test case for destructured for-loop variable. ", "linked_issue_titles": " debuginfo: \"lexical-scope-in-for-loop\" auto-test fails ", "title": "fix regression in for-loop variable debuginfo"}
{"description": " fixes r2d2 (torch) multi-gpu issues with lstm and attention nets. the following yaml file would cause an error for r2d2: stateless-cartpole-r2d2: env: ray.rllib.examples.env.stateless_cartpole.statelesscartpole run: r2d2 stop: episode_reward_mean: 150 timesteps_total: 1000000 config: # works for both torch and tf. framework: tf num_workers: 0 # r2d2 settings. burn_in: 20 zero_init_states: true #dueling: false lr: 0.0005 # give some more time to explore. exploration_config: epsilon_timesteps: 50000 # wrap with an lstm and use a very simple base-model. model: fcnet_hiddens: [64] fcnet_activation: linear #use_lstm: true use_lstm: true lstm_cell_size: 64 max_seq_len: 20 # fake 2 gpus. num_gpus: 2 _fake_gpus: true same for using an attention net instead of the lstm. this pr fixes both issues. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " wip.  wip ", "linked_issue_titles": "", "title": "fix r2d2 (torch) multi-gpu issue."}
{"description": " i hereby agree to the terms of the cla available at:  added postgresql table engine (both select/insert, with support for multidimensional arrays), also as table function. added postgresql dictionary source. added postgresql database engine. ", "commit_messages": " add libpq and libpqxx  add storage postgresql with read support  better  support insert into table  add table function  better  add tests for storage  add postgres dictionary source  better  update libraries  add postgresql database engine  update libpq  add table cache, better drop table ", "linked_issue_titles": "", "title": "add postgresql table function, dictionary source, database engine"}
{"description": " adds a field to docs frontmatter to link to an issue on github if this field is present it will generate a link to the issue on github updates documentation on removing the link to issue when a stub is converted to a doc closes #11342 not sure the style of the link is the best way to display this. happy to have someone provide contribution to this. ", "commit_messages": " added issue frontmatter to docs field  added conditional for render of github link  typo  updated contribution docs re removing issue  update gatsby node to fetch frontmatter for issue ", "linked_issue_titles": "", "title": "link stub to github issue"}
{"description": " also, added exposing webpack to the next.config.js webpack function fixes: #6353 ", "commit_messages": " add using circleci env var for max workers  and expose webpack to config  expose experimental cpu config ", "linked_issue_titles": " build failing with `spawn enomem` / `spawn e2big` ", "title": "add experimental cpus config and use circleci env var"}
{"description": " adding in triage needed by default what is include in the pr: the templates with the tag we merge in and check.  does not touch any source linked issue: #9136 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " update translation_issue.md  update bug_report.md  update feature_request.md  update documentation-issue.md ", "linked_issue_titles": "", "title": "default add triage to issues"}
{"description": " commit 1 fixes \"error c2678: binary '!=': no operator found which takes a left-hand operand of type 'serialized' (or there is no acceptable conversion)\" there is an acceptable conversion, msvc!  #include <iostream> class decl { }; // has to be a subclass - using decl works. class valuedecl : public decl { }; class serialized { public: /*implicit*/ operator decl *() const { return nullptr; } }; // has to be const. void execute(const valuedecl *parent) { serialized serialized; if (serialized != parent) { std::cout << \"hello, world\"; } // replacing the if block with the following is the workaround. /* decl *converted = serialized; if (converted != parent) { std::cout << \"hello, world\"; }*/ } int main() { execute(nullptr); } commit 2 fixes warnings \"not all control paths return a value\" all control paths are covered, msvc! ", "commit_messages": " work around msvc bug for equality check of implicit operator conversion of class to base-class pointer with const subclass pointer  add some llvm_unreachable annotations for recently introduced msvc control path warnings ", "linked_issue_titles": "", "title": "get swift compiling with msvc again"}
{"description": " category documentation added wp-semantix to list of companies using apache superset in readme.md file before: list of companies using apache superset from the readme.md file: after: list of companies using apache superset from the readme.md file: test plan none needed requires db migration. confirm db migration upgrade and downgrade tested. reviewers ", "commit_messages": " latest apache superset (rc 0.33)  latest changes from apache-superset  added wpsemantix to list of companies using apache superset in readme.md file ", "linked_issue_titles": "", "title": "added wpsemantix to list of companies using apache superset in readme file"}
{"description": " this pr upgrades elastalert to 0.1.30, which includes the changes described in the master yelp/elastalert repository: yelp/elastalert@87119b8 which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # no kubernetes related fixes. ", "commit_messages": " upgrade to new docker image 0.1.30  upgrade to new docker image 0.1.30 ", "linked_issue_titles": "", "title": "upgrade to 0.1.30 of elastalert docker image"}
{"description": " i hereby agree to the terms of the cla available at:  add parallel quorum inserts. this closes #15601. detailed description / documentation draft: to use parallel quorum insert set the value insert_quorum >= 2 and insert_quorum_parallel = 1 these inserts can be non-linearizable and can't run in parallel with non-parallel inserts. they also can't be used with sequential_consistency ", "commit_messages": " first part  working copy (with some debug info)  remove debug things  add question in comments  quorum inserts 2  quorum inserts 2 ", "linked_issue_titles": "", "title": "improvement of quorum inserts in clickhouse"}
{"description": " this pr adds a new provider to airflow for executing sql queries against an apache drill instance.  this is useful because, while its primary use case is interactive analysis that often avoids the need for etl, drill's ctas statements and support for querying a large variety of data sources also make it a very capable etl tool.  what is lacking to use drill this way is worklow management, and that gap is one that airflow fills perfectly. ", "commit_messages": " add apache drill provider.  add docs skeletons. ", "linked_issue_titles": "", "title": "airflow-5529 add apache drill provider."}
{"description": " issue: #15172 this adds a new shortcuts query param for the manager. when set to false it will set ui.enableshortcuts: false, so that keyboard shortcuts will be disabled. this is particularly useful when embedding stories on a page, where keyboard shortcuts might conflict. additionally, i've taken the opportunity to support true and false as alternative to 0 or 1, add a table of supported params to the docs, and properly deprecate some legacy params. is this testable with jest or chromatic screenshots? no does this need a new example in the kitchen sink apps? no does this need an update to the documentation? yes, added ", "commit_messages": " implement shortcuts=0 url param to disable keyboard shortcuts  support true/false as url param value, document and properly deprecate layout url params ", "linked_issue_titles": "", "title": "add shortcuts url param to disable keyboard shortcuts"}
{"description": " this pr fixes three small issues: iprofilingblockinputstream checked limits after reading a block (which would be committed, but not used) limits were applied on the unionblockinputstream instead of kafka streams, which could cause an extra block to be read storagekafka: make commit message only if messages are consumed (this is not an issue, but optimization) refs #1690 ", "commit_messages": " iprofilingblockinputstream: check limits before reading block  this makes one pointless check before the first block is read, but  is necessary to prevent reading blocks from storages like kafka where  messages are read only once.  storagekafka: make commit message only if messages are consumed  storagekafka: move limits to individual kafka streams instead of unionblockinputstream  the unionblockinputstream might read an extra block from the asynchronous child streams otherwise,  which will never be used, but offsets for this block would be committed, which would result in  lost messages. ", "linked_issue_titles": "", "title": "fix missing messages in kafka materialized views"}
{"description": " per @oliviertassinari's suggestion at codesandbox/codesandbox-client#2284 (comment), i've added post-updates to each of the container sandbox example package.json files so they run on codesandbox without issue. i have followed (at least) the pr section of the contributing guide. ", "commit_messages": " add post-update for yarn  importing this example to codesandbox doesn't work, but it does with this.  add post-update for yarn  importing this example to codesandbox doesn't work, but it does with this.  adding post-update for codesandbox  adding post-update for codesandbox  adding post-update for codesandbox  editing post-update for codesandbox  adding post-update for codesandbox  editing post-update for codesandbox  adding post-update for codesandbox  adding post-update for codesandbox  adding link to sandbox  removing post-update  added in error - not required as it's a client sandbox, not container.  removing post-update  added in error - not required as it's a client sandbox, not container. ", "linked_issue_titles": "", "title": "add post-update to examples so they run on codesandbox"}
{"description": " part of work for #2958 builds cypress binary for mac platform on circleci (instead of buildkite), all jobs can now run on both linux and mac via executor parameter, both binaries are built. blocked from completing this because cannot sign the mac app using fastlane (does not support mac apps). see issue itself for links about the blocking issue. would like to land the work so far, even with mac workflow disabled for now, since it makes the jobs more robust ", "commit_messages": " use arch when caching dependencies on circle  add mac job  hmm, mac name  executor name  use circle v2.1  circle 2.1 cannot have job names start with a digit  hmm, separate mac workflow  shared build job via executor  allow node version mismatch on circleci mac build  correct workflow names per os  do not check term on darwin platform ", "linked_issue_titles": "", "title": "build osx on circle 2958"}
{"description": " chromium introduced metrics to measure unload performance in:  which would cause some dchecks to assert in electron in some cases: #27717. and it would result in failing tests, because it caused the main process to crash: crashreporter module should send minidump when sandboxed renderer crashes api-crash-reporter-spec.ts 643 ms error message: ptype: expected 'browser' to equal 'renderer' error stack trace: assertionerror: ptype: expected 'browser' to equal 'renderer' at checkcrash (electron\\spec-main\\api-crash-reporter-spec.ts:39:35) at context.<anonymous> (electron\\spec-main\\api-crash-reporter-spec.ts:154:7) at runmicrotasks (<anonymous>) at processticksandrejections (internal/process/task_queues.js:93:5) this patch temporarily disables the metrics so we can have green ci, before finding out a real fix. note that this pr also replaced uses of deprecated crashed events to avoid running into the crash in #27730. npm test passes tests are changed or added pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: none ", "commit_messages": " patch  use render-process-gone instead of crashed  update patches ", "linked_issue_titles": "", "title": "disable unload metrics to fix ci failure"}
{"description": " after talking with @jdipierro i'm taking over this initiative. however i can't actually interact with the old pr so this is being created. his original work has been rebased onto latest master. referencing #849 adds a basic dockerfile with a base of python:3.7-alpine putting final image size at 291mb. i believe most if not all of the changes requested by @mbeacom have been addressed in this as well. ", "commit_messages": " dockerfile and startup script  docker compose example  first pass at docker docs  attempt to add docker build to travis matrix  remove docker compose docs  i've found it easier to run locust locally in standalone mode while developing the locustfile.  the example docker-compose file still exists though.  update dockerfile to slim down created image and tweak behaviors.  change base image from py3.6 to py3.7-alpine. this shrinks the image size by about 600mb so that's nice.  addition of the apk call is required for pip to actually build and of the dependencies for locust.  removal of docker_start portion is based on comments by mbeacom. technically this makes the base image unusable without a consumer  adding their own dockerfile with a copy/add call or another entrypoint.  add py37 environment to tox and travis.yml ", "linked_issue_titles": "", "title": "official docker image and documentation v2"}
{"description": " only position is not enough to decide where to show custom view, fixes #1500. ", "commit_messages": " docs: pass bounds in clicked event of tray  win: mouse position is not notify icon's position  pass bounds in clicked event of tray ", "linked_issue_titles": " get tray icon position ", "title": "pass bounds instead of position in \"clicked\" event of \"tray\""}
{"description": " previously rustdoc would render this struct declaration: pub struct foo<const n: usize = 10>; as: pub struct foo<const n: usize>; this pr changes it to render correctly ", "commit_messages": " rustdoc- show defaults on const generics  add test ", "linked_issue_titles": "", "title": "display defaults on const params- rustdoc"}
{"description": " i hereby agree to the terms of the cla available at:  detailed description / documentation draft: #12508 (comment) ", "commit_messages": " issues-4006 fix race condition in integeration test  issues-4006 try fix bad integration test ", "linked_issue_titles": "", "title": "issues-4006 try fix materialize mysql database integration test"}
{"description": " this pr tweaks our inference logic to only check type parameter constraints in the final phase of type argument inference (and specifically not in the phase where contextually sensitive arguments are excluded). checks prior to the final phase otherwise can cause inferences to become fixed when constraints are self-referential. fixes #29520. ", "commit_messages": " only check constraints after type argument inference is complete  accept new baselines  add regression test  accept new baselines ", "linked_issue_titles": " arrow functions treated differently than functions and methods ", "title": "only check constraints in final phase of type inference"}
{"description": " namedtemporaryfile files can't be reopened on windows. but as nobody knows how windows filesystems work also just skip the test. we are using the 64 byte api so it should work. cleaned up version of gh-4927 ", "commit_messages": " bug: avoid namedtemporaryfile for large file test  namedtemporaryfile files can't be reopened on windows.  tst: skip large file test on windows  nobody knows if it supports sparse filesystems, so just skip it. ", "linked_issue_titles": "", "title": "use tempdir for large file"}
{"description": " moving the new connection pool to its final destination. no code changes. this is a copied file with include fix-ups, and two changed comments (removing the \"move this code\" todo and adding the \"fix void*\" todo promised in #11689) risk level: low (code move) testing: n/a docs changes: n/a release notes: n/a ", "commit_messages": " move  fixing move todo ", "linked_issue_titles": "", "title": "cleaning up a file move todo"}
{"description": " introduces a new superset update_api_docs cli command to regenerate docs/src/resources/openapi.json based on the current openapi spec for the /api/v1 namespace. test plan ensure the superset update_api_docs command runs successfully validate the docs render the /docs/rest-api page correctly requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " update_api_docs cli command for regenerating openapi.json  fix /api/v1/async_events spec  regenerate openapi.json (docs) ", "linked_issue_titles": "", "title": "script to generate api docs (openapi.json)"}
{"description": " i'd like to expose ports commonly used by etcd in the etcd docker image. it does not affect kubernetes in any way but it would make it more convenient to use the image for other purposes, outside of kubernetes. i also merged the two copy lines to reduce the number of layers. ", "commit_messages": " expose old and new etcd client and server ports  merge copy lines in etcd dockerfile ", "linked_issue_titles": "", "title": "expose commonly used ports in the etcd image"}
{"description": " add a new locator path element \"condition\" to represent condition expression of if expression and ternary operator. while generating constraints switch to use if as a anchor for conditional expression conversion to bool. use contextual mismatch diagnostics we already have for while, guard etc. to diagnose if/ternary conditional mismatches. resolves: rdar://problem/56559847 ", "commit_messages": " [constraintsystem] add a new \"condition\" locator path element  \"condition\" path element is used to represent a condition expression  associated with if expression or ternary operator ? :.  locator has been changed in the way that it's now anchored from if  itself which simplifies down to condition expression it needed.  [constraintsystem] use new condition element in constraint generation/diagnostics  [diagnostics] nfc: adjust all of the improved if/ternary test-cases ", "linked_issue_titles": "", "title": "improve if/ternary condition expression diagnostics"}
{"description": " fixes #5644 add postgres to optional reqs add postgres fields mapping tests add importable hstorefield ensure hstorefield accepts null values by default ", "commit_messages": " test postgres field mapping  add hstorefield  ensure 'hstorefield' child is a 'charfield'  add hstorefield docs ", "linked_issue_titles": "", "title": "add hstorefield, postgres fields tests"}
{"description": " removing stl headers from the filamesh reader. not sure that the jsbindings were amended correctly. also still has <functional> from the cstring header using it for std::hash specialisation, maybe that could be moved to another header to be included only by internal source files, as std::hash should only be used by stl headers anyway? (i think). ", "commit_messages": " removed stl headers from filameshio/meshreader.h modified the samples to work the same, and made an effort to remedy the jsbindings although i'm not experienced with them.  fixed assignment operators for materialregistry ", "linked_issue_titles": "", "title": "removing stl headers from filameshio"}
{"description": " now it looks something like this: in redmond 2000: i thin'k now it looks pretty neat :) closes #1987 ", "commit_messages": " libgui: paint texteditor background same as widget's if it's not enabled  now texteditor draws it's background as a colour that does not make the  user think it can be writed into. this also affects textbox.  filemanager: disable propertiesdialog custom rename disabling logic  textbox already handles well its disabled state so it's no use to have a  way to prevent it from propertiesdialog, too. ", "linked_issue_titles": " libgui: texteditor+textbox don't respect is_enabled(). ", "title": "improve painting and managing of disabled widgets: checkbox & textbox"}
{"description": " cherry-pick of xds interop tests: make header/path matching fail properly failover test based on lrs regex path matching test more header matcher tests present/range/regex increase path and header matching timeout case insensitive path matching ", "commit_messages": " xds testing: make header matching and path matching fail properly  xds testing: add failover test based on load  xds testing: add regex path matching test ", "linked_issue_titles": "", "title": "cherry-pick of xds interop tests to v1.35.x"}
{"description": " fixes #17239 code is well-documented: to the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change modified:   cmake/modules/findnccl.cmake tested with following command cmake -gninja -duse_cuda=on -dcmake_cuda_compiler_launcher=ccache -dcmake_c_compiler_launcher=ccache -dcmake_cxx_compiler_launcher=ccache -dcmake_build_type=release -duse_cudnn=on -duse_nccl=on .. without this branch, it failed with nccl not found could not find nccl (missing: nccl_include_dirs nccl_libraries) cmake warning at cmakelists.txt:636 (message): could not find nccl libraries with this pr, it passes. ", "commit_messages": " update findnccl.cmake  if cuda root dir is not specified, search for the symlinked unix default  update findnccl.cmake  fix the cmake variable name  findcudatoolkit exposes result variables (cmake variables). use those.    search for library in /usr/local/cuda  comment if ", "linked_issue_titles": " cmake with nccl flag does not work. ", "title": "fix nccl cmake autodetect issue"}
{"description": " fixing some issues found by using @mui/styled-engine-sc directly in the @mui/system. inspired by #29036. the changes from #29036 are also included here. the purpose is to battle test how well the integration with styled-components is really working. fixes #28905 fixes #27167 list of problems found: ts is broken - all styled-component's utils should be compatible with mui's styled() if @mui/styled-engine-sc is used issues found:  unstyled demos are broken - fixed by b7807f3 created #29048 cssbaseline is broken tests failing. false alarm, it was because the styles were tested with jsdom. everything is fine when using browser, so i just disabled jsdom for them: 75e92d7 styled() tests are broken -  the issues (not blocking) that i could not resolve are:  rtl fixtures are broken - fixed by 22afcab one is still broke - it is related to styled-components/stylis-plugin-rtl#22. it was fixed by styled-components/stylis-plugin-rtl#21, but styled-components v5 is not compatible with the v2 of the plugin, so nothing we can do about it at this point. ", "commit_messages": " [styled-engine] extract types for styled()  [styled-engine-sc] fix mixins, styled options, normalize style args  [mui-material] export css & keyframes  small fix  revert me: test ci using @mui/styled-engine-sc ", "linked_issue_titles": " `css` helper from `styled-engine-sc` produces incompatible type.  [v5] no documented way of importing css or keyframes for styled-components ", "title": "fix various issues reported by using @mui/styled-engine-sc"}
{"description": " this is a big refactor of win_find that does; moves towards the ansible.basic wrapper for better option validation and module invocation reporting streamlined the file information collection to only get the metadata of each file once and not multiple times try to optimise the checks that occur against each file to improve performance the return values are more closely aligned to win_stat with the ultimate goal to share that information in 1 location. in terms of performance here is the difference when running the following task - win_find: paths: c:\\windows\\system32 recurse: yes patterns: '*.exe' get_checksum: no # devel play [2019] ********************************************************************************************* task [win_find] ***************************************************************************************** ok: [2019] play recap ********************************************************************************************** 2019                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 real    1m3.178s user    0m3.918s sys     0m0.272s # win_find-perf play [2019] ******************************************************************************************************************************************************************************************************* task [win_find] *************************************************************************************************************************************************************************************************** ok: [2019] play recap ******************************************************************************************************************************************************************************************************** 2019                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0 real    0m9.127s user    0m1.565s sys     0m0.126s that's a saving of around 1 minute for scanning *.exe in the system32 directory. nothing will ever match the raw performance you can get with get-childitem or some other binary due to the overhead added by powershell itself and the extra information that we collect then serialize. fixes #42696 - win_find vs find behaviour fixes #50569 - performance, path types and win_find vs find behaviour fixes #56712 - performance (somewhat) fixes #63018 - performance supersedes #53148 win_find ", "commit_messages": " win_find - refactor to make more performance and use newer style  win_find - refactor for performance improvements and alignment to find  more path alignment to find ", "linked_issue_titles": " module win_find fails tasks and stops play on non-existing directories  win_find: exits if it can't access a file and will crash if the path it hits has ps centric wildcard characters  win_find partially unknown folder performance (2.4.2->2.8.0 regression)  improve win_find performance ", "title": "win_find - refactor for better performance and alignment to find"}
{"description": " summary see #11665 in this pr, batch_dot uses tf.matmul to avoid memory allocation that happens when doing an elem-wise multiplication, if enough shape information is available. if required shape information is not available, we fall back to old elem-wise mul+tf.reduce_sum based implementation. pr overview ", "commit_messages": " add matmul impl for batch_dot  no shape info tests  pep8 ", "linked_issue_titles": "", "title": "fix memory issue in tensorflow backend's batch_dot"}
{"description": " cherry pick of #78958 #79966 #81390 #81489 on release-1.14. #78958: update to go 1.12.6 #79966: update to go 1.12.7 #81390: update to go 1.12.8 #81489: update go to 1.12.9 update to use go 1.12.9 ", "commit_messages": " update to go 1.12.6  update to go 1.12.7  update to go 1.12.8  fix up failing boilerplate test  fix malformed port in vsphere cloud provider test  the port name previously didn't matter on these tests, but is now  actively being checked in go1.12.8 and higher.    update go to 1.12.9 ", "linked_issue_titles": "", "title": "update release-1.14 to go 1.12.9"}
{"description": " adds the feature requested in #10440 ability to fetch a menu items by passing in menuitems and an id. called like: const fsc = menu.getmenuitembyid('fullscreen'); ", "commit_messages": " add first pass at getmenuitembyid  conform to linter standard ", "linked_issue_titles": "", "title": "add getmenuitembyid to menu api"}
{"description": " if deleteonexithook is in the open state and the program runs for a long time, the deleteonexithook file keeps increasing. this results in a cause memory leak see #10351 i re-customized a deleteonexithook hook. if deleteonexithook is turned on, this hook will be added when creating a temporary file. after the request ends and the corresponding resources are released, the current file will be removed from this hook, so that it will not increase all the time. fixes #10351. ", "commit_messages": " fix  fix  fix ", "linked_issue_titles": "", "title": "fix deleteonexithook cause memory leak"}
{"description": " added programs for displaying adjacency matrix and adjacency list for a graph whose inputs we get from user in python ", "commit_messages": " add files via upload  update adj list.py  update adj mat.py ", "linked_issue_titles": "", "title": "added programs for displaying adjacency matrix and adjacency list in python"}
{"description": " this removes the auto redirect on the report user page for people that aren't signed in. before: after: there was also a tiny bit of margin on this page causing the horizontal scroll bar to show up that i removed... i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the master branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. ", "commit_messages": " fix: dont auto redirect after reporting a user  fix(client): remove annoying redirect on report user page  fix: remove unused code ", "linked_issue_titles": "", "title": "remove auto redirect on report user page"}
{"description": " i implemented m300 before i realized it was already done, oops! but of course i didn't use interrupts so ddrboxman's is better. but s0 should be silent, so i fixed that. define custom_mendel_name makes it easier to change the printer name as it appears in the lcd \"mendel ready.\" message. added code to support up to 10 levels of depth in the sd folder hierarchy. english spelling and grammar corrections here and there. ", "commit_messages": " added custom_mendel_name option to configuration.h and language.h  also cosmetic comment changes and spelling corrections in printed  messages  make m303 silent when \"s0\" is sent  if s is left out perhaps it should be silent, but check the spec for  this m code. ", "linked_issue_titles": "", "title": "m300 bug, custom_mendel_name, sd dir depth, grammar"}
{"description": " this closes probtorch#87. math checked and approved by @fritzo cc: @apaszke ", "commit_messages": " init f distribution  rename f to fishersnedecor, add tests and docs  remove other samplers, fix shape error and add new kl for dirichlet  update entropy function in fisher-snedecor  add comment regarding f-distribution entropy test  remove entropy and revert changes in kl.py ", "linked_issue_titles": " implement f-distribution ", "title": "implementation of the fisher-snedecor distribution"}
{"description": " #19800 (comment) - i investigated the performance issues with test_basic_3.py::test_worker_startup_count. i traced the slow code and figured out that this block is the most consuming one in each worker. for example, if one worker consumes ~4s then this block contributes the maximum towards these ~4s. rest, i will confirm the specific slow line right after the meeting. so, it seems like the issue is with the usage of sleep_for. the documentation says, it blocks the execution for at least the time duration specified. so, we are passing 10 microseconds, that means it would be at least 10 microseconds and it can be more than that too. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " initial support for absl::bitgen  unskipped tests  applied linting ", "linked_issue_titles": "", "title": "replace time based seed generation with absl::bitgen and absl::uniform"}
{"description": " #1966, #1939 add a timeout-handle to stop the auto restart. ", "commit_messages": " add a new props :\"proc.pm2_env.restart_task\" to solve the problem : \"process still restart after it be stop or delete.\"  fix the \"restart_task\" enumerable problem. ", "linked_issue_titles": "", "title": "\"process still restart after it has be stop or delete\""}
{"description": " we produced a new split keyboard. and these are keymap and config about this keyboard. we want to add it to qmk configurator. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " add files via upload ", "linked_issue_titles": "", "title": "[keyboard]add new split keyboard: momoka ergo"}
{"description": " smart open is stateless, so we should pass the session directly. otherwise, it will create a new connection with s3 whenever it spills/restores objects (which caused 100% cpu issue). this indicates the smart open impl is just for s3 now. #13757 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " in progress.  formatting.  formatting. ", "linked_issue_titles": "", "title": "share the same s3 session for smart_open spilling."}
{"description": " fatal notifications created during package load/activation/etc. now contain additional package name metadata for use in the notifications package. required for atom/notifications#100. / ", "commit_messages": " include package name metadata when creating errors  add specs ", "linked_issue_titles": "", "title": "add package name metadata for load errors"}
{"description": " this removes a bunch of dead code from sentry.utils.javascript that i encountered when i was researching where we are going to need to support environment parameters for tsdb, and the code that was only used by code that was deleted (and so on.) ", "commit_messages": " delete groups/public_details.html template.  this was (presumably) replaced by the sharedgroupdetailsendpoint et al.  the last reference to this file was removed with  559fc2c9c834a69cf675cfd1cb60e834c8c60b85.  remove users/details.html template.  the last reference to this file was with  3d815aed3a0ea259e82f317a4fc7582ee426f4b8.  remove handle_before_events template tag.  remove unused transformer abstraction and related code.  remove {event,group}.has_two_part_message.  this isn't used in our supported plugins at all, which is the only  reason i could think that it'd be around other than referenced in a file  deleted in this patch.  remove unused events_per_page constant.  remove sentry_activity template tag library. ", "linked_issue_titles": "", "title": "delete assorted dead and orphaned code"}
{"description": " change all #include s60*** to #include qmk_keyboard_h add info.json for both default and rgb edit layout to remove that extra key on zxcv row propogate above changes to keymap.c files ", "commit_messages": " change to qmk_keyboard_h  add info.json for qmk configurator support ", "linked_issue_titles": "", "title": "qmk configurator support for sentraq s60-x"}
{"description": " just cooked this up on the flight san diego - toronto ;-) extracts scripts logic into a script helper scripts now accept variables to be passed in when turned on via service. automation: add a trigger variable that is available to templates when processing action part. automation: allow using script sequence syntax for action alexa: allow script syntax for action and expose intent slots as variables script - breaking: no longer allow config delay workaround by @jaharkes because it confused the code. (now using config validation to convert all to timedeltas) automation: trigger: platform: mqtt topic: some/notify/topic action: service: notify.notify data_template: message: {{ trigger.payload }} automation 2: trigger: platform: state entity_id: light.hue action: service: notify.notify data_template: message: {{ trigger.to_state.name }} is now {{ trigger.to_state.state }} available trigger data per platform: 'trigger': { 'platform': 'event', 'event': event, } 'trigger': { 'platform': 'mqtt', 'topic': msg_topic, 'payload': msg_payload, 'qos': qos, } 'trigger': { 'platform': 'numeric_state', 'entity_id': entity_id, 'below': below, 'above': above, 'from_state': from_state, 'from_value': from_value, 'to_state': to_state, 'to_value': to_value, } 'trigger': { 'platform': 'state', 'entity_id': entity, 'from_state': from_s, 'to_state': to_s, 'for': time_delta, } 'trigger': { 'platform': 'sun', 'event': event, 'offset': offset, } 'trigger': { 'platform': 'template', 'entity_id': entity_id, 'from_state': from_s, 'to_state': to_s, } 'trigger': { 'platform': 'time', 'now': now, } 'trigger': { 'platform': 'zone', 'entity_id': entity, 'from_state': from_s, 'to_state': to_s, 'zone': zone_state, } ", "commit_messages": " allow variables in service.call_from_config  alexa: expose intent variables to service calls  automation: add trigger context and expose to action ", "linked_issue_titles": "", "title": "trigger variables in automation actions"}
{"description": " you can already implement this today with a stateful callable class, but it can be more intuitive to write a function instead. @michaelzhiluo you might want to try this out for your maml implementation. ", "commit_messages": " wip  wip  wip  update  debug  doc ", "linked_issue_titles": "", "title": "add .transform() function for arbitrary generator transforms"}
{"description": " i am changing how escape keys works in listwidget. currently, the focus gets trapped inside the component when an escape key is pressed. my proposed change unselects all the items on first escape (current logic) and then it lets the default behavior take over. ", "commit_messages": " updating forked vscode 11/16/20  fixing how escape key works in listwidget ", "linked_issue_titles": "", "title": "fixing listwidget escape button behavior"}
{"description": " description: some fixes to huawei lte device tracker. related issue (if applicable): fixes #29354 checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " include mac address in device state attributes for absent devices too  use mac address as default name whether device is connected or not  fix initialization of known entities  closes ", "linked_issue_titles": " huawei_lte device_tracker unavailable after reboot ", "title": "huawei lte device tracker fixes"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add types for package 'fluxible'  add fluxible router types  fix tests  fixed annotation  add missing types  # conflicts:  #\ttypes/fluxible-router/index.d.ts  #\ttypes/fluxible/index.d.ts ", "linked_issue_titles": "", "title": "add missing types and functions to fluxible"}
{"description": " this pr closes #528 and we can improve ui/ux should the need arise. ", "commit_messages": " added tabbar button for listing files uploaded to room.  using (other) local collection for sync  adding limit to publication. ", "linked_issue_titles": "", "title": "including tab for listing room uploaded files"}
{"description": " fixes #19103. this is similar to #19105 and what was discussed in the comments, except that it covers another case (anonymous volumes with permissions) which wasn't covered in the original discussion. this seems to work fine, and doesn't seem to restart existing containers - except if the user specified volumes: strict (or implicitly via wildcard) in comparisons. therefore, i think this pr should not be backported to stable-2.9. docker_container ", "commit_messages": " simplify code.  only pass anonymous volumes. ", "linked_issue_titles": " docker_container sends volume to docker api erroneously ", "title": "pass volumes only for anonymous volumes"}
{"description": " related #7159 ", "commit_messages": " add videocapture / videowriter avfoundation implementation for mac  add support for cap_prop_mode  support setting cap_prop_mode to capture grayscale or yuv frames much  faster from cv_cap_avfoundation_mac.  fix buffer release issue  cvvideowriter_avfoundation_mac had a serious buffer release bug.  also made writeframe() block until isreadyformoremediadata rather than  return an error.  videoio: refactor avfoundation code integration ", "linked_issue_titles": "", "title": "updated pr #7159 (osx avfoundation support)"}
{"description": " remove simplejson. remove utf encoding guessing, which the built-in module handles now. simplify htmlsafe_dumps to use str.translate instead of multiple str.replace. issue deprecation warning if encoding is passed to dumps, dump, loads, or load. this was deprecated in the built-in module back in 3.1. the only valid encodings for json are utf-8 (with/without bom), utf-16 (be/le), and utf-32 (be/le). json.loads accepts bytes and json.loads accepts binary files in these encodings without any special handling on our part. dumps can be encoded after calling, and dump can be passed a binary file wrapped with io.textiowrapper. rewrite docs for consistency. fix imports and references of markup to be from markupsafe instead of flask or jinja. see the individual commits for easier diffs. closes #3555 ", "commit_messages": " remove simplejson  - remove encoding detection backport, json.loads supports it directly  - use str.translate instead of multiple str.replace  deprecate json encoding options  make consistent with built-in json module ", "linked_issue_titles": " remove simplejson ", "title": "remove simplejson and deprecate encoding options"}
{"description": " lldb builds a python module in the form of a c shared library.  this is used in some swift tests. since python module format changed between python 2 and python 3, these tests must be run with the same python version that was used when lldb built it. of course, in a system with multiple python versions installed, this may or may not be the same version used by the rest of the swift build. this adds some logic to lit.cfg to figure out the version of python used by lldb and expose that as %{lldb-python} for use in tests that need to access the lldb module. ", "commit_messages": " use the correct python executable to match lldb  the linux-fatal-backtrace script needs to run with an lldb  module loaded into python.  this in turn requires that the  test be run with the exact same python version as was used  by lldb (not just the same python module directory).  this  can get confused on systems with multiple versions of python  installed.  this replaces lldb-python-path (the python module directory path)  with lldb-python (which is the correct python version run with  the lldb path).  this should ensure that this test is always  run with the same python version and module that lldb used.  use consistent braces for the lldb-python substitution ", "linked_issue_titles": "", "title": "use correct python version for lldb-related tests"}
{"description": " closes #6231 we're collecting more environment variables when running cypress with gitlab ci. one of my projects required this to correctly create a commit url. i'm not able to debug this on the cypress dashboard, however, i suspect that the commit link for gitlab may be incorrect. ", "commit_messages": " #6231 use more ci information from gitlab  issue-6231 fix spec provider tests ", "linked_issue_titles": " missing ci information from gitlab ", "title": "issue 6231 use more information from gitlab"}
{"description": " this pr introduces a script that automates creating a release source archive and handles some licensing issues by removing some files that were identified to be non-compliant, and introducing a apache rat license check in the source generation process to ensure all apache mxnet code is compliant. ", "commit_messages": " fix command for running rat check in v1.x branch.  add script for creating source archives. ", "linked_issue_titles": "", "title": "create tool for building source archives"}
{"description": " before this change, pressing enter in firefox 55 would insert a line break into the description field and then save it. this change prevents the line break from being inserted before saving. there's no change to chrome's behaviour from this change. ", "commit_messages": " update redirected link in readme  remove magic numbers from editinplace()  this makes it a lot easier to read and figure out what's going on.  use event.preventdefault() on editinplace textarea  before this change, pressing enter in firefox 55 would insert a line  break into the description field and then save it.  this change prevents the line break from being inserted before saving.  there's no change to chrome's behaviour from this change. ", "linked_issue_titles": "", "title": "prevent line breaks in editinplace description when using firefox"}
{"description": " i hereby agree to the terms of the cla available at:  fix wrong thread estimation for right subquery join in some cases. close #24075 ", "commit_messages": " fix max parallel stream for joined pipeline  add tests/performance/join_max_streams.xml ", "linked_issue_titles": " version 21.6 is much slower than 21.4 ", "title": "fix max parallel streams for joined pipelines"}
{"description": "", "commit_messages": " bpo-30455: generate tokens related c code and docs from token.py.  generate regexpes from exact_token_types.  fix generating the documentation.  add shebangs and executable bits.  add generated file parser/token_names.h.  misc other fixes and enhancements.  move symbol.py generating code into a separate file.  fix dependencies for pgen.  add a hack for '<>'.  make _pyparser_tokennames a const array.  fix tests.  remove async and await.  generate all token related files from grammar/tokens. ", "linked_issue_titles": "", "title": "generate all token related code and docs from grammar/tokens."}
{"description": " currently only support one overall gauge and i still need to test it, but it should be good for initial review. ", "commit_messages": " add c# stress test client  add metrics.proto generated files to c# project  add generated proto files ", "linked_issue_titles": "", "title": "initial draft of c# stress test client"}
{"description": " addresses this issue #3575 run logs from this branch -> ", "commit_messages": " supress wandb images size mismatch warning  supress wandb images size mismatch warning ", "linked_issue_titles": " warning: \"images sizes do not match\" when w&b logging enabled ", "title": "suppress wandb images size mismatch warning"}
{"description": " this is a preliminary patch to add chamber heat pid control. it introduces a new m309 command for adjusting the pid of the chamber (e.g. \"m309 p37.04 i1.04 d655.17\") and also expands m303 to support auto-tuning pid for an index of -2 to accommodate the chamber heater_id (e.g. \"m303 e-2 c5 s42\") this does not yet add an entry to the onboard printer menu to adjust the pid, as i was in a hurry to get my print running again (now that my temps are stable!), but i will continue adding that support after my current run when i have somewhere to test on again. mostly, i wanted to get this merge request started, in case there are any objections to my just inventing an m309 command for this, and if you guys had a better approach you'd prefer to see here. also, currently using pidtempchamber will preclude the use of chamber_fan and chamber_vent as the previous implementation of those features relies on a check every x ms loop that interferes with pid operation. again, this will also be resolved shortly, but with only one printer it's hard to use and develop on it at the same time. required heated chamber wired in a manner that is safe/sane to use with pwm. my build is a lasko \"myheat\" 100, with a fotek ssr-10da wired between the voltage source and the heating element. the heater fan is wired to run constantly when the printer is powered to avoid heat-soaking the ceramic element under partial current conditions. chamber heat pid control. this is currently operating as expected on a skr 1.4 turbo using my config as archived in my primary git fork here:  resolves: #16316 ", "commit_messages": " chamber pid control, basic support. ", "linked_issue_titles": "", "title": "pid for chamber (resolves feature request #16316)"}
{"description": " quick fix to change this nightly test to install pip packages using pre-release. a different task should add coverage for other packages later. ", "commit_messages": " enable test for pip-mkl  add --pre flag to test pre-releases  merge  fix conflicts ", "linked_issue_titles": "", "title": "test installation of pip --pre"}
{"description": " this pr is based on #4445 please do not review it before #4445 is merged. this pr is part of #4076 ", "commit_messages": " split registry to separate classes  fixes for windows build  reorganized includes to improve compile time (pr#4076 for reference)  # conflicts:  #\tinclude/osquery/registry_interface.h  #\tosquery/registry/registry_interface.cpp  fixed code generation  reorganized includes to improve compile time (pr#4076 for reference)  fixed tests  fixed tests + removed some includes ", "linked_issue_titles": "", "title": "reorganized includes to improve compile time 2"}
{"description": " description: this implements the transparency feature for google calendars. if for example an all-day event is present but it is set to 'free' ha now skips those events and shows the next. this can be turned on/off per calendar. ignore_availablilty is optional and defaults to false. it enables/disables whether to respect/ignore the transparency tag which can be opaque (busy) or transparent (free). related issue (if applicable): fixes #6076 (only partial) pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#5101 example entry for configuration.yaml (if applicable): - cal_id: calendar@googlemail.com entities: - device_id: calendar name: calendar track: true ignore_availablilty: true checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " remove len call.  add transparency feature for google calendars.  remove double default value assignment.  change keyword to be more explicit. ", "linked_issue_titles": " google calendar - all-day events block scheduled events that day from being displayed ", "title": "add option to ignore availability in google calendar events"}
{"description": " in urllib3/urllib3#186 i proposed to add a .stream() generator to the urllib3 response object. this avoids some of the nasty problems with the .read() method on that object (apparent zero-sized reads when there's still data, all sorts of stuff). it's also a much more natural way to stream data. this pr would update urllib3 to include that pr, and updates our streaming methods to use it where possible. @michaelhelmick: do you want to try this branch with your twitter issue? use one-byte chunk sizes. ", "commit_messages": " update urllib3 to cffbd6b317  use the new urllib3 stream generator. ", "linked_issue_titles": "", "title": "use new urllib3 'stream' parameter."}
{"description": " before a maximum 25 of channels was able to be displayed in the teams' channels list. 2021-04-21.15-37-22.mp4 fixes #21707 related to this bug already merged #21518 ", "commit_messages": " updating the code  updating the code  updating the fork  update main branch  updating the branch  update fork  upating the fork  updating fork  updating fork  updating fork  correcting the channel list for teams ", "linked_issue_titles": " maximum 25 channels can be displayed in the teams' channels list ", "title": "maximum 25 channels can be loaded in the teams' channels list"}
{"description": " the short version: this pr implements the currentcolor identifier, which acts somewhat like a pointer to the color property. it's useful for say, setting an underline to always match the text color, and it's the initial-value for several properties. making it actually work exposed a few bugs in other things, so this also fixes: \"0\" failing to parse as a css number several incorrect initial values in properties.json and i made a few places use the generated property_initial_value() function instead of hard-coding things. it's not perfect. for example, border: 2px solid; correctly uses the default of currentcolor, but border-width: 2px; border-style: solid; doesn't. but i couldn't figure out why, and that's an edge case, and i've been on enough tangents with this, so i'm leaving it for now. :^) ", "commit_messages": " libweb: make stylevalue::to_color() take a node instead of the document  this is in preparation for the currentcolor value, which needs to know  what node it's on so it can check the color.  libweb: implement currentcolor special value  the currentcolor identifier represents the current value of the  color property. this is the default value for border-color and  text-decoration-color, and is generally useful to have. :^)  libweb: persuade css parser that idents like currentcolor are colors  shorthand properties were only checking for colorstylevalues, which  excludes identifier colors. now they accept them too, including the  various -libweb-foo colors. :^)  libweb: make \"currentcolor\" lowercase in properties.json  it's technically case-insensitive, but the spec always defines it as  \"currentcolor\" so it feels wrong to capitalise it differently there.  libweb: stop treating eof as a valid part of an identifier  this was specifically causing the string \"0\" to be parsed as an invalid  dimension token with no units, instead of as a number. that then caused  out generated property_initial_value() function to fail for those  values.  libweb: generate shorthand initial values after their longhands  when parsing shorthand values, we'd like to use  property_initial_value() to get their longhand property values,  instead of hard-coding them as we currently do. that involves  recursively calling that function while the initial_values map is  being initialized, which causes problems because the shorthands appear  alphabetically before their longhand components, so the longhands aren't  initialized yet!  the solution here is to perform 2 passes when generating the code,  outputting properties without \"longhands\" first, and the rest after.  this could potentially cause issues when shorthands have multiple  levels, in particular border -> border-color -> border-left-color.  but, we do not currently define a default value for border, and  border-color takes only a single value, so it's fine for now. :^)  libweb: add some more css identifiers  these are used by the \"initial\" values in properties.json  libweb: correct some initial values and add missing ones  - the text-decoration-foo values now match the spec.  - added values for border-foo since those are needed soon.  - make color's initial value be -libweb-palette-base-text.  libweb: use initial values from properties.json inside css parser  this replaces several hard-coded initial values, with use of  property_initial_value().  libweb: replace hard-coded defaults in node::apply_style()  this now uses the values in initialvalues, which is not ideal, but  it's better to have our defaults defined in two places, than in 3.  the default for border-colors is currentcolor, so we shortcut that  here and just grab the value of the color property. as noted, this is  not perfect, but it's somewhat better. ", "linked_issue_titles": "", "title": "implement the currentcolor css special value, with bonus yaks"}
{"description": " closes #19653 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff ", "commit_messages": " clarified fill_value parameter in arithmetic ops  add fill_value change to df  add fill_value example to df ", "linked_issue_titles": " doc: clarifiy fill_value behavior in arithmetic ops ", "title": "clarify and add fill_value example in arithmetic ops"}
{"description": " ipv4interface and ipv6interface did not has netmask and hostmask attributes when its argument is bytes or int. this commit extracts method for constructors of network and interface, and ensure interface class always provides them. ", "commit_messages": " bpo-36392: ipaddress: add test for missing attributes  network class did not have .netmask and .hostmask  attributes on some cases.  bpo-36392: add missing attributes to network ", "linked_issue_titles": "", "title": "ipaddress: fix interface missed some attributes"}
{"description": " wip if there are other parts of the api that break please respond to this issue with the package and the api it relies on. editorview scrollview outlet is missing. geteditor getfirstvisiblescreenrow getfontfamily getfontsize getlastvisiblescreenrow getpagerows ignoring this method, i couldn't find it used anywhere getpane highlightfoldscontainingbufferrange (could probably be removed from the api but it needs to be replaced in selectionview) isscreenrowvisible  (could probably be removed from the api) pagedown pageup pixelpositionforbufferposition pixelpositionforscreenposition redraw scrolltobottom scrolltobufferposition scrolltocursorposition scrolltopixelposition scrolltoscreenposition setfontfamily setfontsize setinvisibles (i think we could ignore this one, its not used and can be set via config) setlineheight setplaceholdertext (this is only used by mini-editors and we are going to wait on implementing it) setshowindentguide setshowinvisibles setsoftwrap splitdown splitleft splitright splitup togglesofttabs togglesoftwrap based on feedback from @abe33 and @smashwilson and anything i've run into personally. closes #2428 ", "commit_messages": " add append shim  add overlayer shim ", "linked_issue_titles": " missing api on reacteditorview ", "title": "add shims to the react view editor"}
{"description": " ci: lgplv2+ify dependapot config and codeql action ci: tighten codeql and labeler even more by moving the read permissions to the top level and granting additional permissions to the specific jobs. it should help to prevent new jobs that could be added there eventually from having write access to resources they most likely would never need. @mrc0mmand could you take a look? ", "commit_messages": " ci: lgplv2+ify dependapot config and codeql action  ci: tighten codeql and labeler even more  by moving the read permissions to the top level and  granting additional permissions to the specific jobs.  it should help to prevent new jobs that could be added  there eventually from having write access to resources they  most likely would never need. ", "linked_issue_titles": "", "title": "lgplv2+ify dependapot config and codeql action and tighten codeql and labeler even more"}
{"description": " cherry pick of #65882 #65986 #65985 #66076 on release-1.11. #65882: add script to verify generated files #65986: verify-generated-files: ensure git tree is clean #65985: re-add pkg/generated/bindata.go #66076: don't delete pkg/generated/bindata.go in make clean re-adds pkg/generated/bindata.go to the repository to allow some parts of k8s.io/kubernetes to be go-vendorable. fixes #65968. ", "commit_messages": " add script to verify generated files  verify-generated-files: ensure git tree is clean  don't gitignore pkg/generated/bindata.go  generate pkg/generated/bindata.go for release-1.11 ", "linked_issue_titles": "", "title": "add script to verify generated files #65986: verify-generated-files: ensure git tree is clean #65985: don't gitignore pkg/generated/bindata.go"}
{"description": " http3-idle-timeout works exactly like http2-idle-timeout, with the exception that it applies to http/3. note that the default is 30 seconds, as we do not expect nat entries to survive longer than that. ", "commit_messages": " add knob for tuning idle timeout  test h3 server idle timeout and client reconnecting ", "linked_issue_titles": "", "title": "add knob to configure h3-idle-timeout"}
{"description": " this fixes 2 crashes on windows. originally part of  #5279 ", "commit_messages": " use port::aligned_free() to free allocations from port::aligned_alloc().  this was resulting in memory corruptions on windows.  windows doesn't use ld_library_path so don't print it.  it was actually crashing instead of printing the error message since getenv() returns null. ", "linked_issue_titles": "", "title": "fixes a memory corruption on windows/gpu"}
{"description": " we've been slowly improving batch support in clusterservice so service won't need to implement this tricky logic themselves. these good changes are blessed but our logging infra didn't catch up and we now log things like: depending on the source string this can get quite ugly (mostly in the zendiscovery area). this pr adds some infra to improve logging, keeping the non-batched task the same. as result the above line looks like: zendiscovery waiting on join moved from: as a bonus, i removed all zen-disco prefixes to sources from that area. ", "commit_messages": " wip  improve and apply to all batchers  line length ", "linked_issue_titles": "", "title": "improve logging for batched cluster state updates"}
{"description": " fix a bunch of things on et_rel elf: when a section symbol is found, get the name of the section, instead of just print empty stuff like readelf does do not print warning messages (e.g. no program headers, no dyn segment, etc.) when the type is et_rel, because it's a regular thing for that kind of files to not have those things fix relocation patching for type r_x86_64_plt32 (there are still some weird stuff there, wrt to that fake .got.r2 section) ", "commit_messages": " get the section name for section/local elf symbols  do not print warning messages if elf is et_rel  in that case, it's a normal thing that dynamic sections and program  headers are not present.  fix the address of the fake plt table ", "linked_issue_titles": "", "title": "fix relocations in et_rel elf"}
{"description": " string normalizer is found in the following frameworks: stopwordsremovertransform in ml.net countervectorizer/tfidfvectorizer in scikit-learn stringnormalization performs string operations for basic cleaning. this operator has only one input (denoted by x) and only one output (denoted by y). this operator first examines the elements in the x, and remove elements specified in \"stopwords\" attribute. note that an implementation should sequentially remove \"stopwords[0],\" then \"stopwords[1],\" and so on. after removing stop words, the intermediate result can be further lowercased, uppercased, or just returned depending the \"casechangeaction\" attribute. ", "commit_messages": " add stringnormalizer  update typeandshapeinference function.  add test output, coverage and docs.  add two dim test, add data. adjust numpy_helper for multi-dim  string array.  update docs ", "linked_issue_titles": "", "title": "add stringnormalizer operator to onnx"}
{"description": " fixes #1093 allow function wrapping methods like ensureasync, that internally use initialparams, to have a context bound to the function they have wrapped. this allows something like this to work: var async = require('async'); var foo = function(one) { console.log(this); }; foo = async.ensureasync(foo); foo = foo.bind({bar: true}); foo(); // prints {bar: true} ", "commit_messages": " explicitly bind 'this', curried by lodash's rest method, to the wrapped method before invoking  add unit test for context curring when using initialparams  update initialparams import to match project style ", "linked_issue_titles": "", "title": "bind context to functions wrapped by initialparams"}
{"description": " with extremely long queries, share query link would break as it exceeds maximal number of characters permitted in a url solution: adding a new key-value store model for us to store text associated with ids store query string in key-value store, use id in search params in url make asynchronous call to get query string after tabbedsqleditors is mounted added tests needs-review @ascott @mistercrunch @bkyryliuk ", "commit_messages": " add keyvalue model for storing id-value pairs  use it for storing shared queries  change string to text and added test  put getquerylink in one place ", "linked_issue_titles": "", "title": "use a key-value store model for sharing long queries"}
{"description": " updates to dart sdk 1.22.0-dev.5.0 migrates flutter analysis code to new analyzer apis works around analyzer futureor type resolution problem (dart-lang/sdk#28285) note that we'll want to time landing this w/ @cbracken's updates to the coverage package.  fyi: @cbracken ", "commit_messages": " bump dart sdk to 1.22.0-dev.5.0.  suppress spurious futureor type warning.  # conflicts:  #\tpackages/flutter_tools/pubspec.yaml  fixed linter dep post merge. ", "linked_issue_titles": "", "title": "bump to dart sdk 1.22.0-dev.5.0"}
{"description": " add marks property to text per documentation at  add return type to editor.withoutsaving and editor.withoutmerging per  add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).   if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add marks property missing from text  add return type to editor.withoutsaving and editor.withoutmerging per    lint fixes  tests  formatting ", "linked_issue_titles": "", "title": "update definitions for slate - text and editor"}
{"description": " we took care of an unnecessary loop that was occurring when an overlay was present in #15894. however, resizes of the overlay were still taking longer than needed because they were invoking .updatesync on the text editor component. in this pr, we take the approach of only updating the dimensions of the overlay element and invoking a render on just the overlay component when a resize occurs. the amount of time spent in the overlay observer callback is greatly reduced which means less time spent scripting on keystrokes. this is important because any scripting that occurs as a result of a new keystroke needs to finish well ahead of the next keystroke to avoid holding up its handling. in the above image, the time spent in the resize observer callback is reduced from 2.36ms to 0.32ms, and the time to handle this frame goes from 11.75ms down to 9.10ms. / ", "commit_messages": " update overlay itself instead of text editor when resize occurs  fix failing test ", "linked_issue_titles": "", "title": "only update overlay instead of text editor when resize occurs"}
{"description": " #18077 - reuse c-api int8 unit test application #18111 - unify fp32 vs. int8 comparison tests output ", "commit_messages": " unify fp32 vs. int8 comparison tests output (#18111)  test=release/1.5  reuse c-api int8 unit test application (#18077)  test=release/1.5 ", "linked_issue_titles": "", "title": "cherry pick or  #18077 and  #18111"}
{"description": " resolves #45210 in this pull request we introduce the ensure query/function. ensure has the semantics and type of the function q1 below: fn q1::ensure(k){ q(k); } further, ensure avoids the need to load the result from disk (or execute the provider, if we are not storing the results of q to disk). @nikomatsakis ", "commit_messages": " implement query ensure  $query::ensure() guarantees that one of two things is true after it returns:  - the query has all green inputs.  - the query has been executed.  and counts as a read from the source query  ensure typeck_tables_of from typck_item_bodies  this should make typecktables lazier. ", "linked_issue_titles": "", "title": "introduce ensure and ensure typeck_tables_of"}
{"description": " fixes \"should call the provided event handlers when respective events are fired:\" in react 18 (  the problem was that updates are only flushed when exiting the outermost act call. so in concurrent react act(() => { updatea(); act(() => { updateb(); }); // updateb assertions }) the updateb assertions would not match all updates. so we should either avoid the nested act() or move the assertions outside of any act call (generally good advise unless you know what you're doing and then you should explain the intention in code comments). i also noticed that the test was basically repeating the same mistakes as our enzyme tests: dispatching mocked events. the problem is that they not only not really test anything meaningful but also are brittle because you need to know what fields react needs. we can just dispatch synthetic dom events which decouples the event dispatching from react entirely (e.g. no need to know that nativeevent is a thing in react's synthetic events) and properly ensures integration of the component under test. general advise: don't try to write as little as possible in tests. optimize for readability (in tests even more than you should already be doing) and isolation (i.e. how well can i reason about this test while ignoring all the other code in the test file?). the rest of the changes are type related changes that avoid type casting (apart from the non-null assertion which is dangerous because it's not true in nested act calls). ", "commit_messages": " revert later run with react 18  [test] use dom events instead of synthetic, partial events ", "linked_issue_titles": "", "title": "use dom events instead of mocked, partial events"}
{"description": " this pr modifies essinglenodetestcase and esintegtestcase and several concrete test classes to use node names when bootstrapping the cluster. today clusterbootstrapservice.initial_master_node_count_setting setting is used to bootstrap clusters in tests. instead, we want to use clusterbootrstapservice.initial_master_nodes_setting and get rid of the former setting eventually. there were two main problems when refactoring internaltestcluster: nodes are created one-by-one in buildnode method. and node.name is created in this method as well. it's not suitable for bootstrapping, because we need to have the names of all master eligible nodes in advance, before creating the node with bootstrapping configuration set. we address this issue by separating buildnode into two methods: getnodesettings and buildnode. we first iterate over all nodes to get nodes settings, then change the setting for the bootstrapping node and then proceed with building the node. if automanageminmasternodes = false, there is no way for the test to set the list of bootstrapping nodes because node names are not known in advance. this problem is solved by adding updatenodessettings method to nodeconfigurationsource and esintegtestcase (which could be overridden by concrete integration test class) . once we have the list of settings for all nodes, the integration test class is allowed to update it. in our case, we update the clusterbootrstapservice.initial_master_nodes_setting setting. ", "commit_messages": " essinglenodetestcase fix  esintegtestcase fix  fix tests that use autominmasternodes = false ", "linked_issue_titles": "", "title": "change unsafe bootstrap nodes count to nodes list in tests"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " types for the datatables.net scroller extension  reformatted for dtslint  neu erstellt mit dts-gen  another dtslint fix. ", "linked_issue_titles": "", "title": "types for datatables.net scroller extension"}
{"description": " this change enables portions of the ingest consumer to be run concurrently. in particular, this allows saving the event to the processing store to be performed concurrently, while other operations remain on the main thread, avoiding thread safety concerns or introducing new connections to shared resources (i.e. postgres.) the motivation for this change is due to the move to bigtable, as set operations against the bigtable storage are marginally slower than the redis storage by roughly 25%. since this is such a frequently hit path, those serially executed blocking operations back up, limiting overall throughput without increasing the consumer count. testing shadow operations with a small thread pool (4 threads per consumer) enabled the bigtable storage to maintain similar quality of service to the existing redis backend. other details of note: individual messages are no longer guaranteed to be processed in fifo order. batches as a whole are still guaranteed to be processed in fifo order, and the committed offset still moves monotonically. the threadpoolexecutor is not backed by a bounded queue, but the queue is implicitly bounded by the batch size and/or time by virtue of being used with the batching consumer. even though the queue has some upper bound, it is still possible that this could lead to the memory required to hold all of the in-flight messages leading to an oom condition (these objects were previously eligible for garbage collection much more frequently since only one message was processed at a time), particularly since the callback itself contains references to large objects. (this backlog should not accumulate to the extent of what we were previously seeing with consumer ooms due to the secondary backend backing up prior to getsentry/getsentry#5545.) ", "commit_messages": " support returning future from processing functions  add return value annotation to processing functions  annotate \"other messages\"  add optional executor for event processing  changes to control flow to enable concurrent event storage  support asynchronous work in consumer  add async process path  callback return value is ignored so don't overspecify  enable in tests  add back to cli  handle early return  misc cleanup ", "linked_issue_titles": "", "title": "enable concurrent execution of event processing store insertion"}
{"description": " same as pull request #1050. this facilitates playbook decision-making that are package manager based.  it also allows simple package installation across distributions in a single statement: -name: install wget action: $ansible_pkg_mgr name=wget state=present now implemented with a list of dicts to identify the package manager in use. ", "commit_messages": " add pkg_mgr fact to setup  this should help facilitate playbook decision making that are not  strictly distribution specific, but more package manager.  update package manager fact innards to a list of dicts ", "linked_issue_titles": "", "title": "add pkg_mgr fact to setup (take 2)"}
{"description": " i encounter the same problem as #1800 when using infinite loop with slidespergroup, some slides will repeat if the number of slides doesn't fit the group. for example, if there are 10 slides with following settings: slidesperview: 4, slidespergroup: 4, loop: true, it becomes: page 1: 1, 2, 3, 4 page 2: 5, 6, 7, 8 page 3: 9, 10, 1, 2 page 1: 1, 2, 3, 4 1 and 2 are repeated in page 3. thus, this pr adds the feature to fit the last page with blank slide(s) when the new parameter fitslidegroupwithblank is set to true. then page 3 will become: 9, 10, (empty), (empty) ", "commit_messages": " add blank slides  add demo .html ", "linked_issue_titles": "", "title": "add blank slides to fit slides per group"}
{"description": " trt 5.1.2 added new functions to itensor. we have to define them for simpleitensor to prevent compiler errors. according to trt team, users are not meant to inherit from itensor, so we should modify our code at some point to avoid having these issues every time the definition changes. ", "commit_messages": " fix itensor virtual functions for 5.1.2+  remove unnecesarry checks ", "linked_issue_titles": "", "title": "override new 5.1.2 itensor pure virtual functions"}
{"description": " category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation the toast presenter is missing from the welcome app, so toasts are never displayed. i noticed this while investigating another problem. i also improved the error message when the dashboard endpoint returns a 401. now: test plan tested locally. requires db migration. confirm db migration upgrade and downgrade tested. reviewers @khtruong @nytai ", "commit_messages": " add toast presenter  improve message when unauthenticated  lint ", "linked_issue_titles": "", "title": "add toast presenter to welcome app"}
{"description": " this pr improves type inference for multiple object literals occurring in the same context. when multiple object literal types contribute to a union type, we now normalize the object literal types such that all properties are present in each constituent of the union type. for example: const obj = test ? { text: \"hello\" } : {};  // { text: string } | { text?: undefined } const s = obj.text;  // string | undefined previously we inferred type {} for obj and the second line subsequently caused an error because obj would appear to have no properties. that obviously wasn't ideal. the key insight behind this pr is that for object literal types we know that unspecified properties always have the value undefined. this is unlike regular object types where unspecified properties might have any value. based on this fact we implement the following new rules: when checking a type relationship between a source type s and a target type t, if t is an object literal type, any excess properties in s are required to have type undefined (normally such excess properties are permitted to have any type). when widening a union type, we normalize all constituent types originating in object literals by adding optional properties of type undefined to each constituent as appropriate such that all constituents have the same set of property names. when inferring multiple object literal types for a type parameter, the object literal types are normalized into a single inferred union type. an example of object literal normalization: // let obj: { a: number, b: number } | //     { a: string, b?: undefined } | //     { a?: undefined, b?: undefined } let obj = [{ a: 1, b: 2 }, { a: \"abc\" }, {}][0]; obj.a;  // string | number | undefined obj.b;  // number | undefined nested object literals are likewise normalized: // let obj: { kind: string, pos: { x: number, y: number, a?: undefined, b?: undefined } } | //     { kind: string, pos: { a: string, x?: undefined, y?: undefined, b?: undefined } | { b: number, x?: undefined, y?: undefined, a?: undefined } } let obj = [{ kind: 'a', pos: { x: 0, y: 0 } }, { kind: 'b', pos: test ? { a: \"x\" } : { b: 0 } }][0]; obj.kind;   // string obj.pos;    // { x: number, y: number, a?: undefined, b?: undefined } | { a: string, x?: undefined, y?: undefined, b?: undefined } | { b: number, x?: undefined, y?: undefined, a?: undefined } obj.pos.x;  // number | undefined obj.pos.y;  // number | undefined obj.pos.a;  // string | undefined obj.pos.b;  // number | undefined multiple object literal type inferences for the same type parameter are collapsed into a single normalized union type: declare function f<t>(...items: t[]): t; // let obj: { a: number, b: number } | //     { a: string, b?: undefined } | //     { a?: undefined, b?: undefined } let obj = f({ a: 1, b: 2 }, { a: \"abc\" }, {}); obj.a;  // string | number | undefined obj.b;  // number | undefined fixes #19236. ", "commit_messages": " missing properties in fresh object literals are known to be undefined  normalize object literals in widened union types  normalize nested object literals  use a single union type for all inferred object literal types  accept api changes  accept new baselines  ensure void return in foreachtype  add tests  accept new baselines  add missing semicolon ", "linked_issue_titles": "", "title": "improved type inference for object literals"}
{"description": " the ruby dsl for defining a protobuf schema has always been implemented in c. originally this was necessary, because upb could not consume descriptors directly. however for several years now the ultimate output of the dsl is just a protobuf (filedescriptorproto), so the dsl could just as easily be implemented in ruby. this pr removes 1,352 lines of code from c and reimplements them as ~400 lines of ruby. this will have the following benefits: reduces our overall c footprint, reducing the chance of sigsegv bugs (such as #8842 which is a recent segv crash bug in the dsl). reduces our overall line count and maintenance burden. makes it possible to share the dsl code between mri and jruby. it is possible that this pr will have some amount of performance regression in the startup time required to load generated foo_pb.rb files, since the dsl is evaluated using ruby instead of c. however, the dsl was already calling back and forth between c and ruby a lot, so hopefully the impact will not be too large. in any case, there are ways of mitigating this if it becomes an issue (see below). this change requires us to add a new method descriptorpool#add_serialized_file, which allows for defining messages using a serialized descriptor proto instead of the dsl. this is necessary to bootstrap google/protobuf/descriptor_pb.rb, which cannot use the dsl as these protos are used to implement the dsl. future directions in the future we may want to change the code generator to use descriptorpool#add_serialized_file for all generated files, instead of the dsl. this would have the following benefits: performance: loading from a serialized descriptor will avoid the cpu cost of evaluating the dsl. for large schemas with many proto files, this could have a noticeable impact on app startup time. correctness/completeness: as we continue to implement missing features in ruby protobuf, particularly custom options, the dsl will become more and more of a hindrance. custom options have some very difficult edge cases that would be nearly impossible to accommodate in the dsl unless we resort to serialized descriptors at some level. using binary descriptors avoids all of this complication. there are various options for how we could keep the generated code readable, even if we move to binary descriptors. for example, we could do something like: if false # code for ides and human readers. class foomessage attr_accessor :bar_field, attr_accessor :baz_field end else # code that is actually executed, implements semantics equivalent to the above. google::protobuf::descriptorpool.generated_pool.add_serialized_file(\"<unreadable binary data>\") foomessage = google::protobuf::descriptorpool.generated_pool.lookup(\"foomessage\").msgclass end since this will require some input and dialogue about what is the best fit for the ruby community, i'm leaving this out of the current pr. the dsl will continue to be available no matter what, since we've exposed it already as a public api. ", "commit_messages": " some preliminary work towards a ruby builder.  pure-ruby dsl is passing all tests!  put the raw descriptor data after __end__ in the ruby source. ", "linked_issue_titles": "", "title": "move dsl implementation from c to pure ruby"}
{"description": " this is a follow up to #18561 it adds more test cases and includes a fix to safari since safari adds another stack frame for the construct call. polyfills might do something similar so this tries to be resilient by skipping over those. results from fixtures at lazy at component ( at div at suspense at babelclasswithfields ( at babelclass ( at frozenclass ( at nativeclass ( at suspenselist at custom name ( at errorboundary ( at example ( firefox: lazy component@ div suspense babelclasswithfields@ babelclass@ frozenclass@ nativeclass@ suspenselist displayname@ errorboundary@ example@ note: firefox doesn't respect displayname in stack traces. safari: lazy component@ div suspense babelclasswithfields@ babelclass@ frozenclass@ nativeclass suspenselist custom name@ errorboundary example@ note: safari doesn't give us a line number for native classes without an explicit constructor. ", "commit_messages": " add more edge cases to fixture  also adjust some expectations. i think the column should ideally be 1 but varies.  the example row is one line off because it throws on the hook but should ideally be the component.  similarly class components with constructors may have the line in the constructor.  account for the construct call taking a stack frame  we do this by first searching for the first different frame, then find  the same frames and then find the first different frame again. ", "linked_issue_titles": "", "title": "fix component stacks for ie and native classes in safari"}
{"description": " mainly opening this pr to get a full ci run before merging, as it's mostly a port of #27386 to the 6.x branch. the changes to versionutils#resolvereleasedversions() and associated tests deserve attention, and ultimately backporting to 6.0 too. i'd wait for ci to pass before looking at this too hard. ", "commit_messages": " prepare for bump to 6.0.1 on the 6.0 branch (#27386)  an attempt to bump to 6.0.1 on the 6.0 branch exposed up a handful of issues that this commit fixes. one of those fixes is a terrible hack that will be fixed more thoroughly in #27397, and another is a back port of d5e56c55553291682932d7e9e8dc7068f59e618b which is related to #27251.  bump version to 6.0.1  remove big horrible hack  version.current.minimumcompatibilityversion() is now version.v_5_6_0 anyway.  fix assertion message  the preceding line modifies versions so versions.get(versions.size() - 1)  no longer contains the highest version.  rewrite the guts of versionutils.resolvereleasedversions()  the policy for which version constants are unreleased changed at 5.6 - we now  plan to keep an unreleased 'marker' version at the end of each minor branch,  whereas prior to 5.6 the unreleased marker version was removed during the  version bumping.  this commit simplifies the logic a bit and also makes it clear which bits can  be removed once 5.x versions are no longer relevant.  orly  improve comments ", "linked_issue_titles": "", "title": "bump version to 6.0.1 on the 6.x branch"}
{"description": " adds the offset field to the indexsymbol struct. this lets code using swift::index functions skip any line/column -> offset reverse calculation if the specific byte offset location is desired. ", "commit_messages": " make swift indexing code capture symbol start/end offset within the current source file.  merge remote-tracking branch 'upstream/master'  make symbol info only store symbol occurrence offset, not start/end offset. the rest can be determined from the source manager by finding the token's sourceloc.  merge remote-tracking branch 'apple/master'  remove unnecessary lexer.h include. ", "linked_issue_titles": "", "title": "store symbol byte offset in indexsymbol"}
{"description": " this removes most uses of fgets() from our codebase, replacing them with read_line(), which is a lot more careful with overly long lines. ", "commit_messages": " clock-util: excorcise fgets()  terminal-util: excorcise fgets()  terminal-util: use fgetc() carefully instead of fread()  binfmt: validate rule file name before using it  binfmt: fgets() excorcism  also, let's not claim we ignored errors when we don't.  cgtop: fgets() excorcism  cryptsetup-generator: fgets() excorcism  catalog: fgets() excorcism  hwdb: fgets() excorcism  keymap-util: fgets() excorcism  modules-load: fgets() excorcism  reply-password: fgets() excorcism  condition: fgets() excorcism  udev-rules: fgets() excorcism ", "linked_issue_titles": "", "title": "let's get rid of fgets()"}
{"description": " netdata-installer.sh: improve message about updater installation packaging/installer/functions.sh: get_crondir fails if crondir is not found packaging/installer/functions.sh: mark get_crondir and check_crondir_permissions functions as private component name netdata-installer.sh some follow-up corrections to netdata-installer.sh based on review comments in #7060 ", "commit_messages": " netdata-installer.sh: improve message about updater installation  packaging/installer/functions.sh: get_crondir() fails if crondir is not found  packaging/installer/functions.sh: mark get_crondir and check_crondir_permissions functions as private ", "linked_issue_titles": "", "title": "netdata-installer.sh follow-up based on #7060 review"}
{"description": " somewhat ironically, bind_to_port isn't currently flagged as deprecated but use_original_dst was, so manually extended its lifetime per discussion on #5355. it wasn't clear to me if the tcp_proxy deprecated_v1 fields were also part of #5355 so tagging piotr as a reviewer. i'll envoy-announce once we've nailed down the fields and gotten approval from all. risk level: high (first time using this process - it will likely cause problems for someone) testing: tests pass. docs changes: n/a release notes: should we relnote these?  they're already in deprecated.md ", "commit_messages": " release: flipping deprecated features to be fatal-by-default  manually reverting fields from #5355 ", "linked_issue_titles": "", "title": "flipping deprecated features to fatal-by-default"}
{"description": " after reading a bunch of changelogs, this upgrades pytest and friends to a good set of versions for increased harmony with the upcoming django 2.2 and python 3.8. not too well-versed in pytest, but most of the few new features over these versions didn't seem really interesting to me. mostly bugfixes and improvements. after pytest 6+ we're able to consolidate configuration into pyproject.toml which is preferable, i went ahead and did that and also cleaned up some old configuration that doesn't apply / isn't useful anymore. --strict-markers is good. i also tried to use the new --import-mode=importlib but that became a todo. i'll follow up with fixing all the warnings and then forbidding warnings with some filters, there's a lot. (there has been a lot even before this.) ", "commit_messages": " upgrade pytest and friends to good versions, consolidate configuration into pyproject.toml  this marker isn't being used  add todo about --import-mode=importlib ", "linked_issue_titles": "", "title": "upgrade pytest and friends, cleanup configuration"}
{"description": " leaving the pad or the invalid_entry aba_ctr uninitialized causes valgrind to complain since part of the atm read is still uninitialized. possibly consider doing this under ndebug? ", "commit_messages": " stop upsetting valgrind with uninitialized shorts  add explicit comments about purpose of writing to pad ", "linked_issue_titles": "", "title": "write to dummy pads and invalid entries in lock-free stack to prevent valgrind complaints"}
{"description": " issue: #10799 update mdx compiler to support .bind() idiom (split into #11198) addon-controls examples for angular, ember, html, svelte, vue, web-components minor cleanup see updated snapshots ", "commit_messages": " mdx: support function.bind({}) syntax  addon-controls: update readme with .bind({}) idiom  addon-controls: angular example  addon-controls: ember example  ember-cli cleanup  addon-controls: html example  official-storybook: use bind idiom for args mdx  addon-controls: svelte example  addon-controls: vue example  addon-controls: vue mdx example  addon-controls: web-components example  argstable stories cleanup ", "linked_issue_titles": "", "title": "add examples to angular, ember, html, svelte, vue, web-components"}
{"description": " cherrypicked from commit (3fdc4ba) backport for pr #56292 ios ", "commit_messages": " to fix ios static route ci failure (#56292)  * ios static failure  * fix ci failure  (cherry picked from commit 3fdc4ba6b4d4ad28e9bdb21d2019975e520e265a)  adding bp changelog ", "linked_issue_titles": "", "title": "backport pr for fixing ios static route tc ci failure"}
{"description": " commit message:add transport failure reason to body additional description: adds transport failure reason to response body . this is specially useful to detect tls related failures when the client does not use envoy. otherwise cert expiration related errors just come as connection failure and it takes some digging to figure out the reason. risk level: low, but changes the existing response body. testing: updated docs changes: n/a release notes: updated ", "commit_messages": " wip  wip  correct test case  add release notes  correct version history ", "linked_issue_titles": "", "title": "add transport failure reason to response body"}
{"description": " modified app.now to correctly return the  timezone-aware current date/time, according to the configured timezone or utc. added unit tests for the changed/added methods. optimize tests by reducing wait time for some test cases due to default polling interval value. fixes #3753. ", "commit_messages": " fix wrong task eta when using timezone setting  optimization: reduce polling interval in test cases  test cases for app.now, app.uses_utc_timezone ", "linked_issue_titles": "", "title": "fix task eta issues when timezone is defined in configuration"}
{"description": " small fixes in the readme conform to the current version of the boilerplate. updated jquery to version 3.1.1 and updated some dependencies to their latest versions. ", "commit_messages": " fixed small grammar error  replaced .jade with .pug  small changes conform to the current version of the app  small changes conform to the current version of the app  updated jquery to version 3.1.1  updated jquery to version 3.1.1  updated some dependencies ", "linked_issue_titles": "", "title": "update readme conform to current version & other small updates"}
{"description": " closes: #1196 closes: #5085 closes: #2759 closes: #11710 closes: #5252 closes: #4735 closes: #5086 this commit allows servers admins to set which ldap groups they want to synchronize with rocket user roles. automatically assign ldap groups to rocket.chat roles admins can choose to automatically remove users from a role if their ldap group is removed. role automatically added role automatically removed example setting the new \"user data group map\" to the following will allow users in ldap under the group \"rocket-admins\" to be assigned the rocket.chat \"admin\" role. { \"rocket-admin\": \"admin\", \"devops\": \"devops\" } here's what the group looks like: automatically add / remove users in channels based on ldap groups for a preview, see: #14278 (comment) tested and working with openldap. ", "commit_messages": " init commit of ldap user role / group synchronization  * 'develop' of  regression: active room was not being marked (#14276)  rename cloud to connectivity services & split apps in apps and marketplace (#14211)  lingohub based on develop (#14178)  [improve] replace livechat inquiry dialog with preview room (#13986)  bump version to 0.74.3  room loading improvements (#13471)  [fix] invalid condition on getting next livechat agent over rest api endpoint (#13360)  [improve] open rooms quicker (#13417)  [fix] \"test desktop notifications\" not triggering a notification (#13457)  [fix] translated and incorrect i18n variables (#13463)  regression: remove console.log on email translations (#13456)  [fix] properly escape custom emoji names for pattern matching (#13408)  [fix] not translated emails (#13452)  added missing package dependency (#13437)  update russian localization (#13244)  [improve] allow configure prometheus port per process via env var (#13436)  [improve] add api option \"permissionsrequired\" (#13430)  [fix] several problems on hipchat importer (#13336)  add the missing uniqueid to the push notifications (#13423)  [fix] notify private settings changes even on public settings changed (#13369)  ... ", "linked_issue_titles": " admins from ldap group  room/channel/group membership based on ldap group membership  ldap put users in different permission roles based on group  ldap - add ability to map ldap groups to roles  ldap - add ability to configure an \"auto join\" for users with a specific group  mapping user in channels based on ldap groups?  automatically add to channel or private room through ldap filters ", "title": "ldap user groups, roles, and channel synchronization"}
{"description": " fixes #16958 alternative to and closes #16963 alternative to and closes #17219 same as #17219 , but raises a warning when a check is skipped. ", "commit_messages": " ignore xfail_checks in check_estimator  avoid ignoring in parametrize...  raise warning ", "linked_issue_titles": " xfail_checks tag only works with parametrize_with_checks ", "title": "mnt ignore xfail_checks tag in check_estimator, with warning"}
{"description": " this is a followup for #6206 as @jarfa is afk for 2 weeks. i has already been reviewed there. i just want to make sure that the changes i made to address my last comment do not break ci. ", "commit_messages": " much faster isotonic regression prediction (involved re-setting interpolation to linear)  change to test_isotonic_regression_ties_min ", "linked_issue_titles": "", "title": "fix isotonic performance issue at prediction time"}
{"description": " db intrinsics are \"keyed\" off of scope, table, and a primary key.  this is how all objects are stored.  it also allows for a secondary key for each type. in chainbase, the secondary keys are ordered by the order of that secondary key, and then by the order of the primary key that is stored with it. db_key_value_format is a class designed to provide the formatting for creating composite keys to store in rocksdb for primary and secondary keys. unit tests verify key construction and deconstruction, ordering and error handling. also, threw in an empty place holder for db_context_rocksdb.cpp. select one ", "commit_messages": " all composite key construction and destruction working.  fixed key256_t and float*_t and cleaned up debug statements.  fixed types after rebasing off integration branch.  fixing more type issues after rebasing to integration branch.  fixed tests for new extra primary key. ", "linked_issue_titles": "", "title": "rocksdb composite key construction for db intrinsic primary and secondary keys"}
{"description": " i hereby agree to the terms of the cla available at:  fixed very rare deadlock at shutdown detailed description / documentation draft: fixes #18891. ", "commit_messages": " revert previous fix  fix rare deadlock on shutdown of backgroundschedulepool ", "linked_issue_titles": " clickhouse-local cannot shutdown correctly. ", "title": "fix rare deadlock at shutdown of backgroundschedulepool"}
{"description": " as mentioned in the bpo, there are some instances where notimplemented is used when notimplementederror was meant to be. this is the example i found after running rg -e notimplemented[^e] doc/, all other usages looked correct. i have updated the doc/library/winreg.rst file, and then noticed that the clinic comments for pc/winreg.c were also incorrect. i updated these and ran python3 tools/clinic/clinic.py pc/winreg.c to generate the new output. this is my first time fixing the docs here so if i have missed a step ", "commit_messages": " fixed wrong use of notimplemented, should be notimplementederror  updated the clinic input in winreg.c and ran clini on it ", "linked_issue_titles": "", "title": "fix usage of notimplemented instead of notimplementederror in docs"}
{"description": " collects latency & count measurements on get and list operations to gce cloud. release note: ", "commit_messages": " add metric capture on gets  undo capture of list clusters  add missing underscore  missed a file ", "linked_issue_titles": "", "title": "collect latency metric on get/list calls"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " added new valid cookie option for client-sessions  modified test case for change in index file  new valid option for cookie in @types/client-sessiosn ", "linked_issue_titles": "", "title": "added valid option for cookie in @types/client-sessions"}
{"description": " #927 - fixes this issue. tested in ie10 and ie11. bug was due to me blindly following an out-of-date mozilla dev guide:  #1131 - fixes this issue. bug was due to autoplay being detected on load, but if the option was changed during the lifetime of the slider then the tab-switch never checked this and would carry on with whatever the initial value was at initialization. now it will check the autoplay option every time the page changes visiblity. ", "commit_messages": " fix ie10/11 visibility bug  fixes #1131 - need to check autoplay during event, in case it was changed during lifetime ", "linked_issue_titles": "", "title": "page visibility fixes for 2 bugs."}
{"description": " #111 with limit by clause you can select only n elements from each chosen group. for example, if you have table t like this (num: 1 1 3 3 3 4 4 5 7 7 7 7), the query select num from t limit 2 by num will give you the following result: (num: 1 1 3 3 4 4 5 7 7) ", "commit_messages": " style of constructor init list  parse limit by [#metr-23881]  ignore qt-creator file  first dirty implementation of limit by clause [#metr-23881]  clone and format limit_by asts [#metr-23881]  getaliasorcolumnname instead of getcolumnname [#metr-23881]  organize code [#metr-23881]  disable some optimization related to limit clause if limit by clause is present [#metr-23881] ", "linked_issue_titles": "", "title": "limit by clause was implemented"}
{"description": " we're skipping build script checks for these libraries temporarily until we make a decision on dart:io support on the web. reland of rolled back pr due to missing video_player. edit: in turns out i needed to land the refactor of goldens to not rely on platform specific code too ... includes some fixes from #38773 fixes #34858 ", "commit_messages": " add comment explaining skip  more specific ", "linked_issue_titles": " [web] dartev compile error http module ", "title": "update the supported library set for flutter for web"}
{"description": " commit message: adds guidance on envoy_bug per #14190 risk level: low docs changes: updates to style.md part of #14190 todos (part of issue): add macro for internal class invariants ", "commit_messages": " draft  fix markdown format  markdown style  fix indent  fix wording ", "linked_issue_titles": "", "title": "add guidance on envoy_bug in style.md"}
{"description": " @rocketchat/core should close #6902 and #7412 i say should because i have not been able to deploy this remotely and have only tested the rc fixes locally. i was getting several \"this.somefunction is undefined\" errors after enabling the irc plugin via the admin panel in chrome 61. i fixed these context errors by binding this to the functions that were giving the undefined message in the constructor. also, there are several regexp's that were declared such that the functions they were made to trigger were not being triggered. i changed the declarations and now i am seeing messages. ", "commit_messages": " bind context so we don't get a call to undefined.  fix bindings.  create regexp's properly. preferring old style over es6 syntax.  try to get a stable docker build working with fix.  revert dockerfile changes.  fix version number. ", "linked_issue_titles": "", "title": "contextual errors for this and regexp declarations in irc module"}
{"description": " what do these changes do? some points in this pr: (1) shorten the length of jobid to 4 bytes. (2) the job_id is generated by gcs for uniqueness. (3) embed job_id to driver id.  the first 4 bytes of a driver id is the job_id bits, and rest 16bits must be filled with 0xff. refer this doc for more details of id refactor. linter i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " wip  fix  add jobid test  fix  add python part  fix  fix tes  remove todos  fix c++ tests  lint ", "linked_issue_titles": "", "title": "shorten the length of  jobid to 4 bytes"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present).  #2479  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dslint/dt.json\" }. already there ", "commit_messages": " add additional type defs for rsvp  satisfy linting ", "linked_issue_titles": "", "title": "ember - add additional type defs for rsvp namespace"}
{"description": " fixes #5016. this adds support for importing the same specifier in multiple ways within the same file. for example, a static and dynamic import, or a url import. previously this was not possible because we used the specifier as the key of an object in the dev packager. now, the specifier is replaced with a hash of the original specifier and the import kind. in addition, some bundler bugs were fixed so that assets/dependencies with different bundlebehavior settings are not merged. ", "commit_messages": " support for multiple types of dependency with the same specifier in the same file  add bundle behavior to bundle id hash and prevent inline/isolated bundles from being merged  fix bugs with wrapped exported symbols in esm output format  add tests for multiple dep types ", "linked_issue_titles": " dynamic import causes static import to resolve to a promise ", "title": "support multiple dependency types on the same specifier in the same file"}
{"description": " parameter pool was not getting passed to the base operator it was using default_pool. added it to the options_to_remove list so that it gets passed as it is. ", "commit_messages": " update forked repo  update qubole_hook filter do not remove pool as an arg for qubole operator ", "linked_issue_titles": "", "title": "update qubole_hook do not remove pool as an arg for qubole operator"}
{"description": " a layout with split left shift, vim arrow keys & iso setup. keymap based on macbooks with iso uk/english international keyboard layouts. i also switched around the parameters in the layout_iso macro so that when editing layers, kc_ent is the last key on the second row, and kc_bsls on the third (as one would expect for the iso layout). ", "commit_messages": " added iso layout  iso dz60 layout: jkbone ", "linked_issue_titles": "", "title": "iso keymap & layout for dz60"}
{"description": " this is a cherry-picks of stack of 2 prs: #52349 and #52350 into release/1.8 branch fixed how type casting is handled in mixed precision onnx export. ", "commit_messages": " [onnx] update fuselogsoftmaxnllloss function to handle autocasting (#51729)  adds a check for patterns for cases with autocasting enabled in which a cast node is inserted before the negativeloglikelihoodloss  node and causing these patterns below not to be recognizable by peephole pass function  [onnx] update layernorm symbolic to handle autocasting (#52199)  when onnx export creates a 0-dim tensor of constant type, this action overrides the type promotion logic as quoted in #9515. in order to prevent this from happening this pr adds the following functionality.  if the data type is a floating point type, it is converted to a 0-dim double tensor, else it is converted to a 0-dim tensor of its original type ", "linked_issue_titles": "", "title": "fix onnx mixed precision export for layernorm & fuselogsoftmaxnllloss"}
{"description": " one of the places where we ask whether a type's metadata should be obtained via its mangled name was missing the newer, more robust checking for minimum deployment target. this pr also re-enables a test that was suppose to be enabled after a fix, but was missed. resolves rdar://83104637 ", "commit_messages": " [irgen][backdeploy] fix infinite recursion in metadata queries  one of the places where we ask whether a type's metadata should  be obtained via its mangled name was missing the newer, more  robust checking for minimum deployment target.  re-enable test that was mistakenly not re-enabled after being fixed ", "linked_issue_titles": "", "title": "fix infinite recursion in determining the mangling kind for a backdeployed feature."}
{"description": " if we set trainer.config[\"horizon\"] to e.g. 2000 (e.g. cartpole), the env should also use that limit (and not stop after 200 steps). i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " fix.  rollback.  wip. ", "linked_issue_titles": "", "title": "if trainer config horizon is provided, should try to increase env steps to that value."}
{"description": " this pull request is in support of wtu. i initially added support for a new flag, pseudoconsole_undocked_prefer_inbox_conhost, which i liked because it was more explicit. you can see that approach in commit cae3289. consider this an open discussion. should we automatically fall back? or should we allow a developer to opt for fallback? automatic fallback pros it's easier on the consumer we can eventually expand it to support $arch/openconsole.exe cons packaging the project wrong will result in a working-but-somewhat-broken experience (old conhost) implicit behavior may be bad manual selection pros consumer gets explicit control cons consumer must explicitly opt in. in the case of wtu, that means pushing a configuration down into terminalconnection all the way from terminalapp to say \"use the inbox one, dummy\" ", "commit_messages": " winconpty: add prefer_inbox_conhost  this flag makes the out-of-box build of winconpty prefer the inbox  console host (conhost.exe).  squash! winconpty: add prefer_inbox_conhost ", "linked_issue_titles": "", "title": "fall back to conhost if openconsole is missing"}
{"description": " the directory structure for icc's installation had changed so it couldn't find he setvars.sh it needed. i now just reference the compiler path for the latest icc directly which shouldn't change. ", "commit_messages": " adding icc to actions  removing icc from travis ", "linked_issue_titles": "", "title": "removing broken icc test from travis and adding working version to actions"}
{"description": " these changes: add support to identify a number of audio stream types via the descriptor tag in mpegts modify (fix?) the way eac3 sync frame format was parsed the following is the set of descriptor tags used by ffmpeg: static const streamtype desc_types[] = { { 0x6a, avmedia_type_audio,    av_codec_id_ac3          }, /* ac-3 descriptor */ { 0x7a, avmedia_type_audio,    av_codec_id_eac3         }, /* e-ac-3 descriptor */ { 0x7b, avmedia_type_audio,    av_codec_id_dts          }, { 0x56, avmedia_type_subtitle, av_codec_id_dvb_teletext }, { 0x59, avmedia_type_subtitle, av_codec_id_dvb_subtitle }, /* subtitling descriptor */ { 0 }, }; after i made the change to handle the descriptor tags, i found that exoplayer still didn't like the eac3 mpegts files output by ffmpeg. upon investigation, we found that exoplayer wasn't skipping the substream id field and therefore the parsing was misaligned. we are under the impression that the field is mandatory so not sure how this worked originally? ", "commit_messages": " add support to identify (e)ac3 streams via ts descriptor tag  skip substream id field when parsing eac3 sync frame format ", "linked_issue_titles": "", "title": "improve identification of (e)ac3 content in mpegts and tweak eac3 parsing"}
{"description": " fixes #4122 there seems to be an issue with the v142 compiler bits which causes the code generated around compactvalue.isundefined to not always return the correct value. using fp:strict within yoga.cpp works around the issue. an alternative would be to fork compactvalue, and add pragma's to enable strict just around that. -- or wait for a compiler fix. we should look at disabling this change on compiler updates to see if the compiler issue has been fixed. microsoft reviewers: open in codeflow ", "commit_messages": " fix issue with yoga layout in x64 release  change files ", "linked_issue_titles": " e2etest failure: padding doesn't work for views on vs 2019, v142 tools, release x64 ", "title": "fix issue with yoga in x64 release builds"}
{"description": " fix #13566 : the code was not clear enough in the connectivity-constrained clustering part of the tutorial. i replace the code example and i add some comments to explain what we are doing. ", "commit_messages": " add context to tutorial example  merge  try to keep line length under 80 characters ", "linked_issue_titles": " tutorial example code lacking context ", "title": "fix tutorial example code lacking context #13566"}
{"description": " implement #1949: profiles.json has been given a setting for background images labeled as shown below, with the following valid values. this allows background images to be anchored to different corners/sides of the console to fit that background image's intended use-case and focus. \"backgroundimagealignment\": \"center\" | \"left\" | \"top\" | \"right\" | \"bottom\" | \"topleft\" | \"topright\" | \"bottomleft\" | \"bottomright\" when left, top, right, or bottom is specified, the other axis is implied to be centered, as that is the default behavior. i went in favor of labeling the default value as center instead of none as \"none\" does not clearly list the alignment behavior. alternative setting the branch dev/trigger/background-image-align-two-settings implements the exact same functionality, but by splitting the profiles.json setting into separate horizontal and vertical settings. i am happy to submit it as a pr if the two-setting approach is preferred. there seems to be no other issues or pull requests relevant to background image alignment. closes #1949 cla signed. if not, go over here and sign the cla requires documentation to be updated (settingsschema.md, usingjsonsettings.md (optional)) i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #1949 the profile class defines methods for parsing and serializing the combined horizontalalignment and verticalalignment enums to and from json. an std::tuple<horizontalalignment, verticalalignment> field _backgroundimagealignment has been added  for storing the profile setting in one place, as it logically makes sense that both alignments to be in use together. terminalsettings and icontrolsettings have been given backgroundimagehorizontalalignment and backgroundimageverticalalignment properties. the combination of std::tuple<horizontalalignment, verticalalignment> is gone once we leave the profile class. combining the two enums is only relevant to how they are stored in profiles.json. terminalsettings defines the default values of both alignment properties as center. the termcontrol class changes the image setup in termcontrol::_initializebackgroundbrush() to assign the _bgimagelayer's (background image control's) alignments to that of the specified alignment settings. the alignments assignments have also been moved from within the image source assignment block, to the bottom of the additional images settings definitions (stretch and opacity). additional fixes the line below for the constant definition has a lowercase i at the beginning of the word \"image\". the i has been capitalized to follow proper uppercamelcase. the two references to this backgroundimagestretchmodekey constant have been updated to reflect the new name. terminal/src/cascadia/terminalapp/profile.cpp line 43 fad7638 static constexpr std::string_view backgroundimagestretchmodekey{ \"backgroundimagestretchmode\" }; (this change was performed in its own commit, so it can be reverted if needed.) test and observe all 9 possible alignment values, invalid input, and not specifying the setting at all. for each image stretch mode. for when a background image is defined or not. confirm alignment names match up. for each alignment value, confirm they are re-serialized correctly when opening windows terminal. confirm default setting results in a centered background image. test and observe if alignment settings are properly applied when first opening the windows terminal or opening a new profile tab. preview example alignments below are examples of the alignments bottom (left) and bottomright (right) in use. figure a (left) shows the use of bottom alignment with uniformtofill stretch mode. the waves will always be at the bottom and stay centered horizontally. figure b (right) shows the use of bottomright alignment with none stretch mode. the image will always remain in the bottom right corner and remain the same size. ", "commit_messages": " implement base background image alignment settings  terminalsettings now has two new properties:  * backgroundimagehorizontalalignment  * backgroundimageverticalalignment  these properties are used in termcontrol::_initializebackgroundbrush to specify the alignment for termcontrol::_bgimagelayer.  this is a base commit that will split into two possible branches:  * use one setting in profiles.json: \"backgroundimagealignment\"  * use two settings in profiles.json: \"backgroundimagehorizontal/verticalalignment\"  implement background image alignment profile setting  implement background image alignment as one profile setting.  * this has the benefit of acting as a single setting when the user would likely want to change both horizontal and vertical alignment.  * horizontalalignment and verticalalignment are still stored as a tuple in profile because they are an optional field. and thus, it would not make sense for one of the alignments to be left unused while the other is not.  * cons are that the tuple signature is quite long, but it is only used in a small number of locations. the serialize method is also a little mishapen with the nested switch statements. empty lines have been added between base-level cases to improve readability.  fix capitalization typo for backgroundimagestretchmodekey  in profiles.cpp, the key for the image stretch mode json property had a lowercase 'i' in \"backgroundimage\", not following proper uppercamelcase.  the \"i\" has been capitalized and the two usages of the constant have been updated as well. ", "linked_issue_titles": " feature request: background image alignment ", "title": "implement #1949 background image align (as one setting)"}
{"description": " it is because the building process can't find the needed header files. and this already introduced building errors on the branches of 5.2.y and 5.3.y for rpi4, and i guess all branches need these two fixes, it is safe to merge these two patches to base branch then it will apply to all branches automatically? ", "commit_messages": " rtl8192cu: let it support to build in the non-src folder  if we build the kernel with \"-o=$non-src-folder\", this driver will  introdcue a building error because of the header's location.  vc_sm: let it support to build in the non-src folder  if we build the kernel with \"-o=$non-src-folder\", this driver will  introdcue a building error because of the header's location. ", "linked_issue_titles": "", "title": "fix two building errors when we build the kernel in the non-src folder"}
{"description": " this adds support for both signed/unsigned 'long long's. (see:  most the work was already there, so this was straightforward. fixes #8896. ", "commit_messages": " add support for 'long long' and 'unsigned long long' types  add long long test  long long test (native side)  update doco for long long type ", "linked_issue_titles": " [webidl] 'long long' datatype doesn't appear to be supported ", "title": "add support for 'long long' datatype"}
{"description": " ports #20735 and #21651 to release-2.7 // ", "commit_messages": " --emitdeclarationsonly flag to enable declarations only output (#20735)  * add emitonlydeclarations flag  * fix name  * verifyoptions checking logic  * passing tests  * dojsemitbaseline  * tests !!!  rename switch --emitdeclarationsonly to --emitdeclarationonly (#21651)  * rename --emitdeclarationsonly to --renamedeclarationonly  * rename test files ", "linked_issue_titles": "", "title": "port --emitdeclarationonly flag support to release-2.7"}
{"description": " original pull-request #30244 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix [i]like function  add test  fix like function ", "linked_issue_titles": "", "title": "cherry pick #30244 to 21.3: fix like function"}
{"description": " making tls testing available to rabbitmq modules. setup_tls setup_rabbitmq the setup_tls integration test target makes use of the  a basic server configuration is included. related to: #47714 ", "commit_messages": " make tls available for rabbitmq  use correct path ", "linked_issue_titles": "", "title": "setup tls integration test for rabbitmq"}
{"description": " update commons-compress to 1.21 due to cve-2021-35517 updated other apache.commons dependencies to latest version separate commits for addressing the commons-compress update and the other apache.commons updates the public api, i.e., is any changed class annotated with @public(evolving): (yes / no) ", "commit_messages": " [flink-24034] upgrade commons-compress to 1.21  [flink-24034] update multiple apache.commons dependencies ", "linked_issue_titles": "", "title": "upgrade commons-compress to 1.21 and other apache.commons updates"}
{"description": " adds the logic for handling joins by a prospective leader. introduces the coordinator class with the basic lifecycle modes (candidate, leader, follower) as well as a joinhelper class that contains most of the plumbing for handling joins. ", "commit_messages": " node joining  start testing  request serialozatono  more testing  factor out into separate class  smaller stuff  own joincallback  simplify logic in handlejoinrequestunderlock  minor stuff ", "linked_issue_titles": "", "title": "add leader-side join handling logic"}
{"description": " closes #3170 just return success if there is no packages which needs to be removed. the final results looks like followings. pipenv uninstall --all un-installing all packages from virtualenv... found 0 installed package(s), purging... environment now purged and fresh! a news fragment in the news/ directory to describe this fix with the extension .bugfix, .feature, .behavior, .doc. .vendor. or .trivial (this will appear in the release changelog). use semantic line breaks and name the file after the issue number or the pr #. ", "commit_messages": " skip purging if there is no packages needs to be removed  add feature news for issue 3170 ", "linked_issue_titles": " pipenv uninstall --all returns error when there is no installed packages in virtuanlenv ", "title": "do not show error for pipenv uninstall --all in a fresh virtuanlenv"}
{"description": " this pr is to update source-map-support. also, this is needed in facebook/jest#7968 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " update source-map-support to include type definition for resetretrievehandlers  update header version  add test ", "linked_issue_titles": "", "title": "update source-map-support to include definition for resetretrievehandlers"}
{"description": " discussed in #19800 (comment) quoting here, i don't think this necessarily fixes it because the updates could still be delayed so resources and updated might have the same values, but it could the old and not the updated values. a better fix would look like this: #19800 (not be closed yet) i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " added retry logic in test_ray_options  applied linting format ", "linked_issue_titles": "", "title": "added retry logic in test_basic::test_ray_options"}
{"description": " have parser inherit from pipe. due to the cdef for the parser, i could only get this to work with a pipe.pxd, but i think that's fine? or am i missing a more easy solution? obliterated the syntax folder - hooray! the old nn_parser is moved to transition_parser in spacy.pipeline the old _parser_model is moved to spacy.models as parser_model everything else is now in spacy.pipeline._parser_internals made some small code fixes in some of the pipe classes removed unnecessary imports enhancement / refactor i have submitted the spacy contributor agreement. ", "commit_messages": " moving syntax folder to _parser_internals  moving nn_parser and transition_system  move nn_parser and transition_system out of internals folder  moving nn_parser code into transition_system file  rename transition_system to transition_parser  moving parser_model and _state to ml  move _state back to internals  the parser now inherits from pipe!  small code fixes  removing unnecessary imports  remove link_vectors_to_models  transition_system to internals folder  little bit more cleanup ", "linked_issue_titles": "", "title": "the parser is now a pipe (2)"}
{"description": " follow-up pr to #54124. changes the name of one of the return values of docker_host_info from host_facts to host_info. also changes the name of docker_node's return value node_facts to node, so that it is more similar to other module's return values and also fits docker_node_info's nodes return value name. docker_host_info docker_node ", "commit_messages": " docker_host_info: host_facts -> host_info  docker_node: node_facts -> node ", "linked_issue_titles": "", "title": "docker_host_info and docker_node: fix return variable names"}
{"description": " keyversionregistry registry for managing the available key version implementations. enables the storage system to easily create a keyversion.builder for a given type. also maintains the protobuf extension registry (contains all the extensions declared by the key version protos). registry and its accompanying registeredkeyversion class are thread-safe. ", "commit_messages": " add key version registry.  - structure is similar to storage driver handling.  - completely thread-safe.  - added appropriate exceptions for the registry.  - includes some alterations to keyverions. ", "linked_issue_titles": "", "title": "add keyversionregistry, and read/write support on key."}
{"description": " as discussed in the forums the first commit makes the logging of incoming json-rpc requests optional. for json-rpc requests over http there is still a debug log message from the webserver (which is not json-rpc specific) but i guess most of the json-rpc log spam comes from json-rpc requests of python addons. and a lot of remotes use json-rpc over tcp. the second commit reduces the log level of a log json-rpc log message from error to warning. the problem is that at the time we don't know if it's actually an error or not. there are cases where it will be an error and others where it can resolved later on. so logging it as a warning should be less confusing. ", "commit_messages": " json-rpc: make logging of incoming requests optional  json-rpc: reduce log level of potential error to warning ", "linked_issue_titles": "", "title": "make logging of incoming requests optional and configurable"}
{"description": " what do these changes do? add a grpc server to the worker that registers with the raylet (but no communication through here yet). also convert rayletclient references to unique_ptr. for more details, refer to #5039 #5029 linter ", "commit_messages": " refactor grpc server  format  change gettask() to pushtask()  merge code, and fix test  merge  change pushtask to assigntask  format  update  fix test  format  merge  merge with latest code ", "linked_issue_titles": "", "title": "add grpc server to worker"}
{"description": " epe-835 added test case that starts up a 4+ producer network, adds all but one producer into the security group, verifies that the producers in the security group are building on each others blocks and that the excluded producer is on its own fork. after that, it adds the remaining producer into the security group and verifies the all eventually become in sync. select one: select any that apply: ", "commit_messages": " added verifying network is in-sync to securitygroup validation and fixed validation for non-participating producers.  added test case #4 test to verify security group forked networks.  added new test for privacy test scenario #4. ", "linked_issue_titles": "", "title": "added  privacy test case #4"}
{"description": " this renames methods on workspaceview that return paneviews. previously it appeared like the methods returned pane objects. now the methods are named so it is clear that they return paneviews. ", "commit_messages": " replace workspaceview:eachpane with workspaceview:eachpaneview  rename workspace::getpanes to workspace::getpaneviews  rename pane focusing methods on workspace  :lipstick:  remove workspace::getfocusedpane  add comment to panecontainer::indexofpane  remove workspaceview::indexofpane ", "linked_issue_titles": "", "title": "rename workspace view pane methods"}
{"description": " this utils.tex_file_writing.get_null() was added in #47 . it was unnecessary as os.devnull does the exact same thing for nt and posix. two places have typos that causes running them failling from syntaxerror in old_projects. one is the keyword arguments with parenthesis. the other is somewhere with an extra parenthesis. i followed how 3b1b uses key=foo rather than key = foo in sort functions of submojects. ", "commit_messages": " update tex_file_writing.py  change \"/dev/null\" to os.getnull in utils/sounds.py sox \"play\" command  fix typo ", "linked_issue_titles": "", "title": "use os.devnull instead of utils.tex_file_writing.get_null(); also small typos that cause syntaxerror"}
{"description": " stop module from running net on empty commands. this fixes a bug where nclu would run net for empty lines produced in jinja templates. this will check to ensure that the command has content before being passed to net, which should improve performance and clean up the msg return value. nclu ansible version ansible 2.7.0.dev0 (devel 577427b1c2) last updated 2018/07/17 15:23:05 (gmt +000) config file = none configured module search path = [u'/home/cumulus/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /home/cumulus/ansible/lib/ansible executable location = /home/cumulus/ansible/bin/ansible python version = 2.7.9 (default, jun 29 2016, 13:08:31) [gcc 4.9.2] task: - name: add 2 interfaces and commit the change. nclu: template: | {% for iface in range(1,3) %} add int swp{{iface}} {% endfor %} commit: true description: \"ansible - add swps1-2\" output before task [examply : add 2 interfaces and commit the change.] ************************************************************************************************************************************************************ ok: [leaf01] => {\"changed\": false, \"msg\": \"\\n\\nusage:\\n    # net <command> [<args>] [help]\\n    #\\n    # net is a command line utility for networking on cumulus linux switches.\\n    #\\n    # commands are listed below and have context specific arguments which can\\n    # be explored by typing \\\"<tab>\\\" or \\\"help\\\" anytime while using net.\\n    #\\n    # use \\\"man net\\\" for a more comprehensive overview.\\n\\n    net abort\\n    net commit [verbose] [confirm [<number-seconds>]] [description <wildcard>]\\n    net commit delete (<number>|<number-range>)\\n    net commit permanent <wildcard>\\n    net del all\\n    net help [verbose]\\n    net pending [json]\\n    net rollback (<number>|last)\\n    net rollback description <wildcard-snapshot>\\n    net show commit (history|<number>|<number-range>|last)\\n    net show rollback (<number>|last)\\n    net show rollback description <wildcard-snapshot>\\n    net show configuration [commands|files|acl|bgp|multicast|ospf|ospf6]\\n    net show configuration interface [<interface>]\\n\\noptions:\\n\\n    # help commands\\n    help     : context sensitive information; see section below\\n    example  : detailed examples of common workflows\\n\\n    # configuration commands\\n    add      : add/modify configuration\\n    del      : remove configuration\\n\\n    # commit buffer commands\\n    abort    : abandon changes in the commit buffer\\n    commit   : apply the commit buffer to the system\\n    pending  : show changes staged in the commit buffer\\n    rollback : revert to a previous configuration state\\n\\n    # status commands\\n    show     : show command output\\n    clear    : clear counters, bgp neighbors, etc\\n\\n    <number-seconds> : number of seconds\\n\\n\\n\\nusage:\\n    # net <command> [<args>] [help]\\n    #\\n    # net is a command line utility for networking on cumulus linux switches.\\n    #\\n    # commands are listed below and have context specific arguments which can\\n    # be explored by typing \\\"<tab>\\\" or \\\"help\\\" anytime while using net.\\n    #\\n    # use \\\"man net\\\" for a more comprehensive overview.\\n\\n    net abort\\n    net commit [verbose] [confirm [<number-seconds>]] [description <wildcard>]\\n    net commit delete (<number>|<number-range>)\\n    net commit permanent <wildcard>\\n    net del all\\n    net help [verbose]\\n    net pending [json]\\n    net rollback (<number>|last)\\n    net rollback description <wildcard-snapshot>\\n    net show commit (history|<number>|<number-range>|last)\\n    net show rollback (<number>|last)\\n    net show rollback description <wildcard-snapshot>\\n    net show configuration [commands|files|acl|bgp|multicast|ospf|ospf6]\\n    net show configuration interface [<interface>]\\n\\noptions:\\n\\n    # help commands\\n    help     : context sensitive information; see section below\\n    example  : detailed examples of common workflows\\n\\n    # configuration commands\\n    add      : add/modify configuration\\n    del      : remove configuration\\n\\n    # commit buffer commands\\n    abort    : abandon changes in the commit buffer\\n    commit   : apply the commit buffer to the system\\n    pending  : show changes staged in the commit buffer\\n    rollback : revert to a previous configuration state\\n\\n    # status commands\\n    show     : show command output\\n    clear    : clear counters, bgp neighbors, etc\\n\\n    <number-seconds> : number of seconds\\n\"} output after task [examply : add 2 interfaces and commit the change.] ************************************************************************************************************************************************************ ok: [leaf01] => {\"changed\": false, \"msg\": \"\\n\"} ", "commit_messages": " update nclu.py  stop module from running net on empty commands.  update nclu.py  updated the copyright date ", "linked_issue_titles": "", "title": "improve performance by not operating on empty lines"}
{"description": " this short document lists useful asp.net core perf diagnostic tools. there's not much 'meat' since the tools are all well-documented elsewhere, but i think it's valuable to have this sort of list so that asp.net core devs can discover the tools (especially perfview and perfcollect, which can be hard to find without links from official docs). fixes #9525 ", "commit_messages": " add asp.net core perf diagnostic tools list  add diagnostic tools doc to toc  a few minor phrasing tweaks  remove a few stray 'en-us' elements from links ", "linked_issue_titles": "", "title": "document asp.net core perf tools"}
{"description": " updates recent changes to my keymaps and userspace in qmk's repo. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " remove macromode functionality  update kbdfans/kbd75/rev1:noroadsleft keymap  - replace _______ instances with xxxxxxx on system layer  - add line breaks between keymap layers ", "linked_issue_titles": "", "title": "update noroadsleft userspace and keymaps (2021-12-13)"}
{"description": " javascript 0.82.0 now tokenizes the $ in  $something as an instance constructor and also fixes tokenization when destructuring in const assignments (const [first, second, ...rest] = array);) python 0.38.0 correctly tokenizes self.something now go 0.31.0 adds the fmt printf snippet for debugging ", "commit_messages": " :arrow_up: language-javascript@0.82.0  :arrow_up: language-python@0.38.0  :arrow_up: language-go@0.31.0 ", "linked_issue_titles": "", "title": "update language-javascript, python, and go"}
{"description": " needed for flashing to use zigbeebridge with tasmota the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on tasmota core esp8266 v.2.7.2.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " create readme.txt  efr32 firmware for zigbeebridge ", "linked_issue_titles": "", "title": "add firmware efr32 files for zigbeebridge"}
{"description": " i was having issues getting an rpm to build. my error was processing files: superset-0.20.1-1.noarch error: file must begin with \"/\": lockup error: file must begin with \"/\": with error: file must begin with \"/\": text.svg error: file must begin with \"/\": lockup error: file must begin with \"/\": with error: file must begin with \"/\": text@2x.png error: file must begin with \"/\": lockup error: file must begin with \"/\": without error: file must begin with \"/\": text@1x.svg error: file must begin with \"/\": lockup error: file must begin with \"/\": without error: file must begin with \"/\": text@2x.png error: file must begin with \"/\": mark.png error: file must begin with \"/\": mark@1x.svg for ref pypa/setuptools#767 file renaming fixes this issue ", "commit_messages": " merging in updates from main repo  updating my fork  merge remote-tracking branch 'upstream/master'  rename files to allow rpm build  i was having issues getting an rpm to build. my error was  processing files: superset-0.20.1-1.noarch  error: file must begin with \"/\": lockup  error: file must begin with \"/\": with  error: file must begin with \"/\": text.svg  error: file must begin with \"/\": lockup  error: file must begin with \"/\": with  error: file must begin with \"/\": text@2x.png  error: file must begin with \"/\": lockup  error: file must begin with \"/\": without  error: file must begin with \"/\": text@1x.svg  error: file must begin with \"/\": lockup  error: file must begin with \"/\": without  error: file must begin with \"/\": text@2x.png  error: file must begin with \"/\": mark.png  error: file must begin with \"/\": mark@1x.svg  for ref  file renaming fixes this issue ", "linked_issue_titles": "", "title": "renaming files to allow rpm build"}
{"description": " make section names unique in loops, as catch doesn't support duplicate sections, see also catchorg/catch2#816 (comment) as a result, when built with gcc, loop iterations were skipped. when built with clang, the test aborted with an assertion in catch.hpp line 6222. this also addresses the issues discussed here: #1032 (comment) and here: catchorg/catch2#1241 as some of the unit tests which never ran before failed now, i added an exclude list for one of the tests (this is due to nlohmann-json ordering dictionaries by key, while the output files it compares against kept the key order of the json files). also, the way the tests were written, they would now take a long time, therefore i moved parsing the source into individual sections (more code, but 99% less parsing operations for the same tests). read the contribution guidelines for detailed information. changes are described in the pull request, or an existing issue is referenced. the test suite compiles and runs without error. code coverage is 100%. test cases can be added by editing the test suite. the source code is amalgamated; that is, after making changes to the sources in the include/nlohmann directory, run make amalgamate to create the single-header file single_include/nlohmann/json.hpp. the whole process is described here. the c++11 support varies between different compilers and versions. please note the list of supported compilers. some compilers like gcc 4.8 (and earlier), clang 3.3 (and earlier), or microsoft visual studio 13.0 and earlier are known not to work due to missing or incomplete c++11 support. please refrain from proposing changes that work around these compiler's limitations with #ifdefs or other means. specifically, i am aware of compilation problems with microsoft visual studio (there even is an issue label for these kind of bugs). i understand that even in 2016, complete c++11 support isn't there yet. but please also understand that i do not want to drop features or uglify the code just to make microsoft's sub-standard compiler happy. the past has shown that there are ways to express the functionality such that the code compiles with the most recent msvc - unfortunately, this is not the main objective of the project. please refrain from proposing changes that would break json conformance. if you propose a conformant extension of json to be supported by the library, please motivate this extension. please do not open pull requests that address multiple issues. ", "commit_messages": " make section names unique in loops, as catch doesn't support duplicate  sections, see also  as a result, when built with gcc, loop iterations were skipped. when  built with clang, the test aborted with an assertion in catch.hpp  line 6222.  this also addresses the issues discussed here:    and here:    please note that this introduces new problems, as some of  the unit tests fail now - the library stores keys in  lexographical order, while the cbor/msgpack/ubjson examples  store them in original order.  exclude bytewise comparison in certain tests.  these tests never worked - they weren't run before  d5aaeb4.  note that these tests would fail because of this library  ordering dictionary keys (which is legal). so changing the  input files (or modifying stored cbor/msgpack/ubjson files)  would make the tests work and they could get removed from  \"exclude_packaged\".  also move parsing of files in these unit tests to within  the inner sections, so that they're only parsed  number_of_files * number_of_sections instead of  number_of_files * number_of_files * number_of_sections  (so, instead of close to 100k parses about 700). ", "linked_issue_titles": "", "title": "fix unit tests that were silently skipped or crashed (depending on the compiler)"}
{"description": " matches the browser default inputs we have and cleans up some code. ", "commit_messages": " make custom select and file inputs 100% wide  matches browser default inputs and swaps some max-width properties for a regular width  space custom select sizing examples ", "linked_issue_titles": "", "title": "full width custom select and file inputs"}
{"description": " bug fixes apis fix the bug of div operation result using scale method do not exactly equal the result of elementwise_div method. remove the _scalar_div_ function. the bug is as follow. and after fixing the bug remove __div__ ,__rdiv__ methods which do not be defined in python3 standard. ", "commit_messages": " fix the bug of div operation result using scale method do not exactly equal the result of elementwise_div method  remove __div__ , __rdiv__ methods which do not define in python3 ", "linked_issue_titles": "", "title": "change '/' method from scale op to elementwise_div op"}
{"description": " replaces the deprecated reacttype with elementtype in react-test-renderer ref -  add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> ", "commit_messages": " fix: add propswithchildren to exoticcomponent  fix[react-test-renderer] - replace reacttype with elementtype ", "linked_issue_titles": "", "title": "fix[react test renderer]  replace deprecated type reacttype"}
{"description": " this pr adds a functional sub-test for calling decodescript with a p2tr / segwit v1 output script (op_1 <32-bytes push>), expecting to return \"witness_v1_taproot\" as type result. in the first two commits, the test rpc_decodescript.py is also improved by adding logging (plus getting rid of the enumerations) and also adding missing checks type result checks for all other output script types. ", "commit_messages": " test: add logging to rpc_decodescript.py  also remove the enumerations (\"1)\", \"2)\"...) from the test  cases as those potentially hinder maintainability; e.g. if a  new case in inserted in-between, all the remaining  enumerations would need to be adapted.  test: check for decodescript rpc 'type' results ", "linked_issue_titles": "", "title": "add decodescript rpc test for p2tr output script"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " types/node-forge/index.d.ts  fix test and add functional ", "linked_issue_titles": "", "title": "@types/node-forge added resolvers for the"}
{"description": " indexing 'option-checking' out of known_args had a type error when option checking is disabled, don't error on duplicate args, just take the last add config.toml stubs for datadir, infodir, and localstatedir (which were already accepted, but broken) this fixes a regression from 1.21 to beta, when the configure script was rewritten in python. ", "commit_messages": " configure.py: fix --disable-option-checking  getting the value of this argument needs another level of indexing,  as known_args are stored in {dict}[list](opt, value) form.  also, when option-checking is disabled, let this bypass the check that  options are only passed once, and just apply the last value.  config.toml: add stubs for recognized-but-unused install paths  ... specifically datadir, infodir, and localstatedir.  these were  already accepted by configure.py, but it didn't have any place to put  the values. ", "linked_issue_titles": "", "title": "fix --disable-option-checking and extra config paths"}
{"description": " fix a crash when the filter chain only update listener update is superseded by the listener removal or full listener update. risk level: low testing: unit test ", "commit_messages": " tcplistener: allow remove filter chain after listener is removed  add listener manager test  address comment: defer delete filter chain  version history ", "linked_issue_titles": "", "title": "fix mixed full listener update and intelligent listener update"}
{"description": " we're currently handling redirects in our api gateway layer. this pr will allow redirects to happen client side. for example, a client may specify a list of redirects in their gatsby-browser.js as follows. exports.modifyroutes = routes => { const redirects = [ { path: '/cat', onenter: (nextstate, replace) => replace('/dog?utm_campaign=cat') } ]; const childrouteslength = routes.childroutes.length; const childroutesbutlast = routes.childroutes.slice(0, childrouteslength - 1); const childrouteslast = routes.childroutes[childrouteslength - 1]; routes.childroutes = childroutesbutlast.concat(redirects).concat([childrouteslast]); return routes; }; ", "commit_messages": " allow client to modify routes  update readme ", "linked_issue_titles": "", "title": "allow client to modify react-router routes"}
{"description": " this fixes some metadata/ast encoding problems that lead to ices.  the way this is currently handled will need revisiting if abstract return types are added, as unboxed closure types from extern crates could show up without being inlined into the local crate. closes #16790 (i think this was fixed earlier by accident and just needed a test case) closes #18378 closes #18543 r? @pcwalton ", "commit_messages": " fix decoding of unboxed closure kinds  closes #18378.  note that cross-crate unboxed closures are  still unimplemented and will fail to work currently.  treat cross-crate unboxed closure def ids consistently  always translate the id into the local crate id space since  presently the only way to encounter an unboxed closure type  from another crate is to inline once of its functions.  this may need to change if abstract return types are added.  closes #18543  add regression test for #16790, #18378 and #18543 ", "linked_issue_titles": " internal compiler error in metadata::tydecode::parse_def_id related to unboxes closures  unboxed closures ice: expected(expected ebml doc with tag esenumvid but found tag 27)  cross-crate unboxed closures are not fully implemented ", "title": "fix some cross-crate unboxed closure bugs"}
{"description": " my recollection is that this was mostly working, but we were seeing just enough failures that we didn't want to leave it enabled while branching for release. let's see whether that's (still) true. see also #19217. / ", "commit_messages": " revert \"leave all our tests as order_dependent! for now\"  this reverts commit 2f52f969885b2834198de0045748436a4651a94e.  conflicts:  actionmailer/test/abstract_unit.rb  actionview/test/abstract_unit.rb  activemodel/test/cases/helper.rb  activerecord/test/cases/helper.rb  activesupport/test/abstract_unit.rb  railties/test/abstract_unit.rb  revert \"for now, we will keep sorting the tests.\"  this reverts commit 7025d7769dc53f0a3ffab8b537727ef3fee367fc. ", "linked_issue_titles": "", "title": "run all our tests in random order"}
{"description": " the paddings on the outer edges of dialog content (not between content) should be smaller for larger text scale size. this pr computes a factor for scaling down the padding and applies it to the space between the edge of the dialog and the content inside. before: after: related issues i added the following tests: 25 padding tests 3 configurations of alertdialog x 5 textscalefactors 2 configurations of simpledialog x 5 textscalefactors before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: ", "commit_messages": " adjust edge paddings on alertdialog title, content, and actions  increase padding de-scale multiplier  adjust logic for padding scaling  update dialogs  add padding rules to simpledialog ", "linked_issue_titles": "", "title": "automatically scale down dialog padding for larger text scale factors"}
{"description": " this allows counting occurrences of unique items (e.g. user id, url, etc.) over rollup intervals in a time range, as well as calculating the total number of unique items over an aggregate time range that spans several rollup intervals. the redis implementation uses hyperloglog to provide cardinality estimates (it probably makes sense to document that there is a approximate standard error of 0.81%) while the in-memory implementation uses sets. this adds support for the following time series queries: users that have been affected by events within a group (issue) users that have been affected by events within a project ", "commit_messages": " add demonstration of distinct counters using hyperloglog in tsdb.  execute queries concurrently (pardon my dust and terrible variable names.)  use target_key from rb==1.3.  style.  allow querying for series data.  cleanup, move interval calculation onto base.  default end to the current time if not provided.  fix expiration logic.  add in memory backend, add it to the test script.  remove extraneous argument from pfadd call. (this is why variadics are bad.)  improve names.  add simple test case for distinct counts.  clean up documentation.  remove example script. ", "linked_issue_titles": "", "title": "add distinct counters to tsdb backends."}
{"description": " a proposed fix for #4802 i added 'replay' option to the playtoggle component. change has been verified in an actual browser (chome, firefox, ie) example created (starter template on jsbin) ", "commit_messages": " sync with origin branch  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  feat: add 'replay' option to the playtoggle component ", "linked_issue_titles": "", "title": "add 'replay' option to the playtoggle component."}
{"description": " i'd like to see the component description from __docgeninfo in the story documentation in the info plugin. i'd like to get the prop type from __docgeninfo for when the type comes back as \"other\". propval had a problem where 'content' was being directly rendered as an object. added to proptable added to propval added to story make a story with a component that has documented (via docgen-style text) description, and the description will show up. like this: /** component description here */ const button = ({children, onclick}) => ( <button onclick={onclick}>{children}</button> ) button.proptypes = { onclick: proptypes.func // make sure this does not come from react, make it come from prop-types module. } storiesof('button', module) .addwithinfo('demo', 'button with children', () => ( <button onclick={action('clicked')}>david</button> )) .addwithinfo('demo', '', () => ( <button onclick={action('clicked')}>david</button> )) you will see a description under the info description, you will also see that the prop type is not 'other' when you use proptypes from something other than react (for support of react >= 15.5.x. ", "commit_messages": " added version number.  working on getting more documentation.  added a post install script.  added code to support js documentation for adding descriptions to a component, fixed issue with content was being rendered as an object and give errors for that, added a fix to when you use proptypes from something other than react that you can get the type from docgen.  removed version number. ", "linked_issue_titles": "", "title": "fix semi broken __docgeninfo integration in addon info"}
{"description": " see discussion in #25007, and particularly #25007 (comment) this changes the parameter value of true to none (without any change in behaviour), so we keep the possibility open to have sort=true to mean \"always sorting\" in the future. i started from the branch of tom in #25007 (as there were already useful doc changes + new tests), and changed the value + updated the tests from there.  closes #24959 ", "commit_messages": " [wip]: api: change default for index.union sort  closes  update test  fixups  multi  doc typo  intersection  whatsnew  update whatsnew  symdiff  whatsnew  doc  index multi  change true to none; disallow true  fix concat tests ", "linked_issue_titles": " index.intersection changed behavior to sort by default in pandas 0.24 ", "title": "change index set ops sort=true -> sort=none"}
{"description": " this pr is first step into better support for polish language. it is just a polish version of lex_attrs.py based on english one and signed contribution agreement. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " signed spacy contributor agreement  added polish version of english lex_attrs ", "linked_issue_titles": "", "title": "lex _attrs for polish language"}
{"description": " this is a continuation of #11614 which takes care of a few other issues as well as making the auto-disabling part of the auto-update feature as opposed to a hard/global policy, and will not interfere with any user actions. i.e when auto-updates are on they will auto disable + show a notification. when off, it should be clearly visible on the info screen before hitting update. ", "commit_messages": " [addons] fix query. broken table is unused and not updated anymore  [addons] dont prevent installation of addons marked broken in addonmgr  this is a soft flag and should be handled in gui layer  [addons] add isautoupdate flag to install job  [addons] remove non-functioning broken status code  [estuary] fix message for broken addons  'broken' does not include incompatible  [addons] auto-disable broken addons after update ", "linked_issue_titles": "", "title": "auto-disable broken addon on update"}
{"description": " the problem is that currently to load a model using from_pretrained requires 2x model size on cpu memory and for those odd cases where a user has large gpu memory, but very little cpu memory it's a problem. this pr is trying to solve the puzzle of loading \"eleutherai/gpt-j-6b\", with revision=\"float16\" and torch_dtype=torch.float16 for the model in full fp16. it shouldn't use more than 12.1gb of cpu ram to work on colab. so this should use 12.1gb of cpu memory including peak memory: m = gptjforcausallm.from_pretrained(\"eleutherai/gpt-j-6b\", revision=\"float16\", torch_dtype=torch.float16, low_cpu_mem_usage=true) this of course won't be enough to be used on the free google colab since it has a total of 12gb of cpu ram for everything, so by the time we come to from_pretrained a few gbs will be already consumed by python/torch/transformers, leaving less than 10gb of cpu ram. here is what this pr does: load state_dict and register which keys we have drop state_dict switch to the meta device all params/buffers that are going to be replaced from the loaded state_dict load state_dict 2nd time replace the params/buffers from the state_dict see the snapshot showing the memory use of just 1x model size and a bit more for temps (this includes peak memory usage). (the automatic cpu/gpu memory usage reporting in the snapshot is courtesy of  todo: if this gets a green light - need to write a test that measure 1x memory size @lysandrejik, @sgugger ", "commit_messages": " one possible solution  low mem from_pretrained ", "linked_issue_titles": "", "title": "1x model size cpu memory usage for from_pretrained"}
{"description": " closes: #17765 bug fix for get_pandas_df() to avoid an exception when reading an empty table. read the pull request guidelines for more information. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. ", "commit_messages": " bug fix to allow empty dataframes in get_pandas_df ", "linked_issue_titles": " get_pandas_df() fails when it tries to read an empty table ", "title": "hivehook fix get_pandas_df() failure when it tries to read an empty table"}
{"description": " fixes the link to security.md in the contributing.md file and makes the filename uppercase for consistency. requires documentation to be updated ", "commit_messages": " fix link to security.md in contributing.md  uppercase contributing.md filename for consistency ", "linked_issue_titles": "", "title": "fix link (and filename) in contributing.md"}
{"description": " please refer to the individual commit messages for additional details. smaller diff with ", "commit_messages": " [pdfsidebarresizer] skip the css.supports checks for mozcentral builds  since css variable support cannot be disabled any more in firefox, the run-time checks are of no using for mozcentral builds.  [pdfsidebarresizer] refactor the clamping in _updatewidth  rather than manually clamping the width here, we can just export an already existing helper function from ui_utils.js instead.  (hopefully it will eventually be possible to replace this helper function with a native math.clamp function, given that there exists a \"stage 1 proposal\" for adding such a thing to the ecmascript specification.)  [pdfsidebarresizer] re-factor the resize event listener to improve readability  i've absolutely no idea why i wrote the code that way originally, since the nested ifs are not really helping readability one bit.  hence this patch which changes things to use early returns instead, to help readability. ", "linked_issue_titles": "", "title": "add a couple of (small) readability improvements in the code"}
{"description": " description: this pr adds functionality for locks expressed through the smartthings platform. locking/unlocking is working great, however i'm not sure whether we should update the state straight away (faster ui feedback) or wait for the confirmation from smartthings (removes false positives). also as mentioned in the referenced issue, there are some other attributes that could possibly be added to the entity. @andrewsayre any chance you could expand on those here? related issue (if applicable): fixes #20889 pull request in home-assistant.io with documentation (if applicable): home-assistant/home-assistant.io#8493 example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new or updated dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. if the code does not interact with devices: ", "commit_messages": " bumped pysmartthings version to 0.6.1  added lock to supported platforms  added smartthings lock component  updated lock to eagerly set state  updated requirements_all.txt & requirements_test_all.txt with pysmartthings==0.6.1  added smartthings lock tests  removed inapplicable comment ", "linked_issue_titles": " smartthings component doesn't show smart lock status ", "title": "add lock capability to smartthings platform"}
{"description": " added arcface face recognition model to example list added arcface, mobilenet, resnet, squeezenet, vgg models to onnx api page please feel free to remove inapplicable items for your pr. code is well-documented: to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change added arcface face recognition model to example list fixed contents in example readme to link to \"other deep learning examples with mxnet\" section added arcface, mobilenet, resnet, squeezenet, vgg to onnx api page (created a new section \"onnx examples\") all the models and related artifacts are linked from onnx model zoo for each model, there are pretrained models in onnx format with notebooks for training, validation and inference, scripts for pre/post processing and dataset prep in mxnet. ", "commit_messages": " added arcface example  updated onnx.md with arcface  updated onnx.md with imagenet models ", "linked_issue_titles": "", "title": "adding models to example list and onnx api page"}
{"description": " when config file i/o was centralized to the main process, the config object's mainsource is disregarded and all configs are serialized to the same file. this results in config file loss when using atom-mocha-test-runner because the atomenvironments built there enable persistence to a temporary directory: global.buildatomenvironment = function (params = {}) { let defaultparams = { applicationdelegate, window, document, enablepersistence: true, configdirpath: tmpdir } return buildatomenvironment(object.assign(defaultparams, params)) } this restores the ability to track multiple config objects and atom environments by passing the source as well as the config payload to the main process through ipc. partial fix for #14909, specifically the bit where atom/github's test suite was resetting configuration ", "commit_messages": " :art: remove extra space  maintain a global map of configfile instances  accept a filepath in the set-user-settings ipc call  pass a configfilepath along with the user settings  pass config file path to applicationdelegate call ", "linked_issue_titles": "", "title": "support multiple config file paths"}
{"description": " @mugen87 there were only minor corrections to the ts introduced with #16969 i realized that codeserializer was poorly documented and that it needed clean-up especially with regard to unused functionality. that's why it became the biggest change here. ", "commit_messages": " codeserializer: clean, update doc and typescript definitions  general: align js docs and ts signature files  codeserializer: clean-up/remove functionality no longer needed. make override clearer via codeserializationinstruction  fixed comments and made minor ts adjustments ", "linked_issue_titles": "", "title": "clean-up, code doc update and ts alignment"}
{"description": " this is a collection of smaller changes, the most invasive being a change to the socket setup process. instead of only tracking connected and disconnected, we now track the initialisation process too. ultimately this allows asynchronous errors from the tcp stack to bubble up to the original connect() call. bonus feature: better logging of tcp state transitions. fixes #419 ", "commit_messages": " kernel: move tcp state logging into tcpsocket  kernel: use a more detailed state machine for socket setup  kernel: detect some outgoing tcp connection failures ", "linked_issue_titles": " connect() doesn't fail properly ", "title": "detect outgoing tcp connection errors"}
{"description": " case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. case 2. improvement to existing type definition. documentation or source code reference which provides context for the suggested changes.  url  it has been reviewed by a definitelytyped member. sorry for my last awful pr ", "commit_messages": " rails-actioncable: add npm support  rails-actioncable: fix ambiguous datatype ", "linked_issue_titles": "", "title": "support import + fix ambicious datatype"}
{"description": " implement function retrieval python apis on existing abis add documentation generation scripts for functions minor fixes on dependencies and configurations in cmake files ", "commit_messages": " add for test function build  add pybind functions for getfunction api  implement fc function testcase  lint code using clang-format  disable warning in covert protobuf::int64 to int  update doc generation scripts and functions doc  trimming some comments  fix doc generation scripts for typecheck  improve cmake scripts for unittest project dependencies and fix linux build issues  lint python code  update api to support functions with multiple versions  update line ending  add changelogs for functions  refactor and lint code ", "linked_issue_titles": "", "title": "implement function retrieval apis; add documentation for functions"}
{"description": " this is a backport of #32657 ", "commit_messages": " adding job process pojos to protocol pkg (#32657)  * adding job process pojos to protocol pkg  * removing unused results_field  * addressing pr comments, removing unnecessary methods  removing min_version field ", "linked_issue_titles": "", "title": "feature/backport ml job process to protocol"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " give the correct type  add a signature  modify a test ", "linked_issue_titles": "", "title": "modify the type of array.compact method in yup"}
{"description": " adds and enhances tests for the dashboard filterbar (nativefilters.) test plan all tests should pass ", "commit_messages": " add filterbar tests  finalize filterbar tests  add tests for filterbar header  add tests for filterbar filterconfigurationlink  add tests for filterbar filtersets editsection  add tests for filterbar filtersets  clean up  add tests for filterbar filtersetunit  add tests for filterbar filtersets filtersheader  add tests for filterbar filtersets footer  fix linting  fix import ", "linked_issue_titles": "", "title": "tests audit for the dashboard filterbar"}
{"description": " _baseencoder._transform() currently calls _encode_check_unknown(), and then calls _encode() which will call _encode_check_unknown() a second time (if the dtype is compatible with numpy) since _encode_check_unknown() calls np.unique() on a given column, its complexity is o(n_samples) which is not negligible on large training sets. this pr avoids this by adding a check_unknown parameter to _encode() which defaults to true. ", "commit_messages": " avoid calling _encode_check_unknown twive  pep8  cosmetics ", "linked_issue_titles": "", "title": "avoid calling _encode_check_unknown() twice in baseencoder.transform"}
{"description": " @matthiasplappert this pull request is a follow up to #1299 here we added -v1 environments: handmanipulate{block, egg, pen}touchsensors-v1 use original sensordata readings (mujoco); handmanipulate{block, egg, pen}touchsensors-v0 use boolean readings; and we also improved gym/envs/robotics/hand/manipulate_touch_sensors.py ", "commit_messages": " envs/__init__.py: register all handmanipulate...touchsensors envs  manipulate_touch_sensors.py > touch_get_obs='sensordata'  handmanipulate...touchsensors-v0 - boolean sensor readings; handmanipulate...touchsensors-v1 - original mujoco sensordata readings; ", "linked_issue_titles": "", "title": "gym/envs/robotics - handmanipulate{block, egg, pen}touchsensors-v1"}
{"description": " fixes #14522 (this demonstrates that mocking is possible and shows how). fix a bug in test.callasyncduplexstreamingcall (reverse order of generic args). show how to create a fake client stub show how to test server-side impl classes that implement the generated server methods. ", "commit_messages": " add tests demonstrating how to mock client stubs  demonstrate testability of server-side impl classes ", "linked_issue_titles": " c# how to mock generated client base? ", "title": "add c# tests that demonstrate how to unit test grpc code with test doubles."}
{"description": " fix #2808 for expo init and expo eject project, name is existing in app.json other than package.json. example output d:\\repo\\awesomeproject>react-native windows --template vnext reading application name from package.json... reading application name from app.json... reading react-native version from node_modules... microsoft reviewers: open in codeflow ", "commit_messages": " read name from app.json  change files ", "linked_issue_titles": " rnw cli doesn't detect the project name for an expo project ", "title": "cli reads name from app.json if it doesn't exist in package.json"}
{"description": " use resizeobserver when available for better and more performant resizing information, otherwise, fall back to a throttled resize event on an iframe that's the size of the player. allows a video.js user to disable this by setting resizemanager: false as an option since the component will not be initialized. this probably needs to revert #4800 (e0ed0b5) because we end up getting two playerresize events with the dimension methods now. todo: revert #4800 fix current tests make ro polyfill possible allow ro to be disabled debounce calls instead of throttle write tests documentation make sure things are disposed properly events objects ", "commit_messages": " resizer  wip  use resize observer or iframe ", "linked_issue_titles": "", "title": "playerresize event in all cases"}
{"description": " i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " chore(sudoku): added type hints [hacktober-fest]  updating directory.md ", "linked_issue_titles": "", "title": "added sudoku type hints [hacktober fest]"}
{"description": " we are still using the hostcache for syntactic features, but no resolution. that means that the host can not ask about files that it did not reference in the list of rootfiles returned by getscriptfilenames(). ideally we would get rid of hostcache, but the only reason we use it is that vs does not handle normalized slashes correctly. once that is done, we can yank it. ", "commit_messages": " remove host cache uses in syntactic features  consolidate the use of normalizeslashes in lookup helpers  remove getcurrentsourcefile and use syntaxtreecache.getcurrentsourcefile instead  remove hostcache.getchangerange ", "linked_issue_titles": "", "title": "simplify updating the host cache for syntactic ls features"}
{"description": " performance optimization others sorted the grad by dtype before coalescing, can decrease the number of coalescing op. besides, by reducing the number of coalesce op, the number of c_allreduce_sum op can also be reduced. all test are based on ernie3.0, pp=dp=mp=2 fp16_allreduce=true optimize_cast=true decrease in number of coalesce op number before this opt number after this opt gain card 0/4 48 6 -700% card 1/5 48 6 -700% card 2/6 120 12 -900% card 3/7 120 12 -900% one dp group 336 36 -833% loss diff performance throughput  before this opt throughput after this opt gain 39146 39232 + 0.2% ", "commit_messages": " sorted the grad by dtype  supports all dtype ", "linked_issue_titles": "", "title": "optim the grad fuse for pipeline mode by sorting the grad by dtype"}
{"description": " i have followed (at least) the pr section of the contributing guide. update autocomplete component documentation for issue closes #22443 ", "commit_messages": " [autocomplete] update doc  autocomplete/autofill  remove extra blank line ", "linked_issue_titles": " unable to disable the browser auto complete feature for the autocomplete component ", "title": "improve the documentation on autocomplete/autofill"}
{"description": " silence all the remaining warnings in video_core generated by gcc 10.2.0. enforce -warray-bounds and -wmissing-field-initializers. ", "commit_messages": " maxwell_to_vk: silence -wextra warnings about using different enum types  maxwell_3d: silence array bounds warnings  video_core: silence -wmissing-field-initializers warnings  video_core/cmake: enforce -warray-bounds and -wmissing-field-initializers ", "linked_issue_titles": "", "title": "silence the remaining gcc warnings and enforce them"}
{"description": " original pull-request #27298 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix bug from #23515.  fix test from fuzzer.  fix spellign.  fix bug from #23515. ", "linked_issue_titles": "", "title": "cherry pick #27298 to 21.7: fix bug from #23515."}
{"description": " fused_elementwise_activetion can fuse some binary and unary computation. two patterns are supported: binary(x, unary(y)) and unary(binary(x, y)). paddle should detect the patterns and do the transformation automatically, but writing a pass is time-assuming. so i pose the api in contrib.layers for first benchmark. example, the computation in paddingrnn: c = pre_cell * layers.sigmoid(f) + layers.sigmoid(i) * layers.tanh(j) m = layers.tanh(c) * layers.sigmoid(o) can be replaced by: # layers.sigmoid(i) * layers.tanh(j) tmp0 = fused_elemwise_activation(x=layers.tanh(j), y=i, functor_list=['elementwise_mul','sigmoid']) # pre_cell * layers.sigmoid(f) tmp1 = fused_elemwise_activation(x=pre_cell, y=f, functor_list=['elementwise_mul','sigmoid']) c = tmp0 + tmp1 # layers.tanh(c) * layers.sigmoid(o) m = fused_elemwise_activation(x=layers.tanh(c), y=o, functor_list=['elementwise_mul','sigmoid']) ", "commit_messages": " enhance fused_elementwise_activation op.  test=develop  move the api fused_elementwise_activation to contrib.  test=develop ", "linked_issue_titles": "", "title": "enhance fused_elementwise_activation op and add python api in contrib.layers"}
{"description": " this simple pr is similar to #6047. it gets rid of leftover calls to global l: in tilelayer.wms: the global call had been introduced by pr #5618. in canvas: introduced by pr #5115, while the pr #4989 that switched to es6 was in process. these should be the last references to global l, apart from l.mixin in checkdeprecatedmixinevents of class, which refers to it on purpose. ", "commit_messages": " fix(tilelayerwms): get rid of l.tilelayer global call  and rely on imported tilelayer instead.  fix(canvas): get rid of l.stamp global call  and rely on imported util.stamp instead. ", "linked_issue_titles": "", "title": "get rid of calls to global l"}
{"description": " it is a small change in travis.yml which migrates the build to container based infrastructure. solves #181 ", "commit_messages": " migrate to container based infrastructure  updated travis.yml to migrate build process from legacy infrastructure to container based infrastructure  migrate to container based infrastructure ", "linked_issue_titles": "", "title": "pr for #181 migrate to container based infrastructure"}
{"description": " use gcsclient instead of redisgcsclient in ray. closes #5058 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " modify redis gcs client usage of raylet and core worker  modify ut usage  rm friend class of redisgcsclient  update comments of redisgcsclient  add override to redisgcsclient methods ", "linked_issue_titles": "", "title": "use new interface class gcsclient in ray"}
{"description": " this pr updates the bottom navigation semantics tests to use the matchessemantics api, which is the newer function for accomplishing the same as the previous tests. i added the following tests: 4 variants of semantics tests in the bottom navigation bar tests. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: ", "commit_messages": " update semantics tests ", "linked_issue_titles": "", "title": "update bottom nav semantics tests to use matches semantics"}
{"description": " the idea is to enqueue mini-tasks (so-called oneshots) for the stuff that should be done on a signal. these oneshots are much lighter than real tasks, because they are not run in an own thread, but they also cannot be scheduled, they simply run until they are done. i had to block signals around locking core->tasks_lock to prevent deadlocks when a signal handler is called while it is still locked. ", "commit_messages": " add task oneshots  use oneshot for cons->event_resize ", "linked_issue_titles": "", "title": "fix segfaults when resize signals occur with running background tasks"}
{"description": " backport of #10193. fix a couple of bugs found by testing in release mode, closes #10185. bug: fix numpy.testing.assert_equal in release mode. to be complete, the nat handling needs to raise assertionerror when comparing nat's with different types. that check was previously passed on and the resulting check, which would succeed in development mode because deprecationwarning was converted to an error, warns in release mode. bug: fix test_1d_format test. the test failed for numpy installed in release mode as the pendingdeprecationwarning issued by object.format(a, '30') was no longer converted to an error. the fix here is to make the test python version dependent and suppress the warning when needed. ", "commit_messages": " bug: fix test_1d_format test.  the test failed for numpy installed in release mode as the  pendingdeprecationwarning issued by object.__format__(a, '30') was no  longer converted to an error. the fix here is to make the test python  version dependent and suppress the warning when needed.  bug: fix numpy.testing.assert_equal in release mode.  to be complete, the nat handling needs to raise assertionerror when  comparing nat's with different types. that check was previously passed  on and the resulting check, which would succeed in development mode  because deprecationwarning was converted to an error, warns in release  mode. ", "linked_issue_titles": "", "title": "fix bugs found by testing in release mode."}
{"description": " this pr ensures that handlers have the correct parent.  this change does for handlers what tasks already had done. this ensures that things like the following apply to handlers: - import_role: name: thing delegate_to: localhost fixes #36518 additionally, on a small note, task_list.extend is in place and returns nothing, don't assign to t. ansible version ", "commit_messages": " ensure role handlers are parented correctly. fixes #36518  add delegate_to test for include_role handlers ", "linked_issue_titles": " import_role with delegate_to does not run handlers on the delegated to host ", "title": "ensure handlers have proper parent"}
{"description": " description: this pr removes the restriction that was in place preventing the creation of a zha device for the zigbee coordinator. this fixes a hard error on the ootb devices page when attempting to load device triggers and actions if someone selects the coordinator and it allows us to interact with the coordinator in group management in the zha configuration panel do not merge without ui pr: home-assistant/frontend#4541 checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " allow zha device creation for coordinator  don't let coordinator get removed  fix truthy issue in logical device type ", "linked_issue_titles": "", "title": "allow zha device creation for the zigbee coordinator"}
{"description": " these changes allow rust to generate position-independent code on riscv64 targets with code model medium. closes: #59802 see also: rust-embedded/riscv-rt#25, rust-embedded/wg#218 ", "commit_messages": " update llvm: apply patches for pc-relative addressing on 64-bit risc-v  use code model 'medium' for 64-bit risc-v targets ", "linked_issue_titles": " risc-v -mcmodel=medium ", "title": "add support for pc-relative addressing on 64-bit risc-v"}
{"description": " this allows you to customize the barrier tween for any modalroute. it currently only defaults to curves.ease. this allows for any subclass of modalroute to implement its own barriercurve. class _dialogroutewithcustombarriercurve<t> extends popuproute<t> { _dialogroutewithcustombarriercurve({ animatable<double> barriercurve, // ... }) : assert(barriercurve!= null), // ... _barriercurve = barriercurve, // ... @override animatable<double> get barriercurve => barriercurve; final animatable<double> _barriercurve; // ... related issues n/a i added the following tests: a test to validate that the default barrier tween remains as curvetween(curve: curves.ease) a test to validate that a custom barrier tween is honored. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide ", "commit_messages": " implement barriertween in modalroute<t>  add modalroute default barriertween test  add tests for custom modalroute.barriertween  group tests ", "linked_issue_titles": "", "title": "allow for customizable modalroute barriertween"}
{"description": " this pr updates deno doc so default exports are handled. currently only variable/function/class exports are supported and they would show up as \"default\" in the doc page. we still need to add support for expressions that are default exports: export default { foo, bar, } unfortunately it requires to change node structure. ", "commit_messages": " test experiments  export default fn ", "linked_issue_titles": "", "title": "deno doc handles default exports"}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"../tslint.json\" }. ", "commit_messages": " add .type(func) to assertion  check if wrapper has type ", "linked_issue_titles": "", "title": "chai-enzyme add .type(func) typing"}
{"description": " fixes #395 this is a natural continuation of pr #446 this allows masking of the cost function for sequence to sequence learning with different lengths. it does so with an optional flag mask_cost at model.compile. ", "commit_messages": " added masking to cost function  when dealing with sequences of different lenghts, this optionally  fixes cost function bias to the largest sequences.  test previous commit ", "linked_issue_titles": "", "title": "optionally mask cost function for sequence to sequence learning"}
{"description": " closes #10041 this pull request seperates standalone::run logic for denort and deno_cli in a way so that deno_cli could intialize it's own ops. title can be improved. ", "commit_messages": " feat(cli/standalone): initialise runtime_compiler ops for cli standalone  quick fix ", "linked_issue_titles": " optionally support thick binaries for compile ", "title": "initialize runtime_compiler ops for deno compile"}
{"description": " the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.3.0, 2.4.2, 2.5.2, and pre-2.6 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " update it-it.h  update pt-br.h ", "linked_issue_titles": "", "title": "shutter and pcf8574 translations for it-it and pt-br"}
{"description": " superset has a few pages that were using  default template provided by appbuilder framework. one problem with this layout is that title, filter, pagination are all stacked row by row, which took a lot of space before actual list content. so we want to make a new list view layout, to make top section cleaner and keep all the existed functionalities. ", "commit_messages": " improve superset list view page layout  - less header spaces and stacks  - move pagination down to bottom  - apply material design style to 'add' action button  - will apply to all superset list view, like slices list, security tab lists etc.  improve superset list view page layout  - less header spaces and stacks  - move pagination down to bottom  - apply material design style to 'add' action button  - will apply to all superset list view, like slices list, security tab lists etc. ", "linked_issue_titles": "", "title": "improve superset list view content layout"}
{"description": " with #8548 we introduced the notion of \"type guards as assertions\". this has caused a steady stream issues as users are surprised by the arguably counter-intuitive effects. with this pr we limit type guards as assertions to only affect incomplete types in control flow analysis of loops. effectively this makes type guards as assertions an implementation detail of the control flow analyzer that isn't observable in the final types computed by the checker, and #8548 is for all practical purposes revoked. for example, we now handle the following from #9246 correctly: type shape = { kind: \"circle\"; radius: number } | { kind: \"rectangle\"; width: number; height: number }; function area(s: shape) { if (s.kind === \"circle\") { return math.pi * s.radius ** 2; } else if (s.kind === \"rectangle\") { return s.width * s.height; } return assertnever(s);  // no error here } function assertnever(x: never): never { return x; } likewise we produce the expected never type in this example from #9869: let stringornumber: string | number = 3 > 5 ? \"a\" : 7; if (typeof stringornumber === \"number\") { if (typeof stringornumber !== \"number\") { stringornumber;  // never } } fixes #9246, #9254, #9260, #9869, #10087. (yeah, it's been causing some confusion!) ", "commit_messages": " limit type guards as assertions to incomplete types in loops  accept new baselines  fix linting error ", "linked_issue_titles": "", "title": "limit \"type guards as assertions\" behavior"}
{"description": " i sorted the index list and the sections below in alphabetical order. i also added a mysql link to the index. ", "commit_messages": " sort sections and list  add mysql link to the index ", "linked_issue_titles": "", "title": "sort and add mysql to index"}
{"description": " original pull-request #13624 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " first attempt  better  add test  update 00157_cache_dictionary.reference  add locks to fix datarace  better  disable test with tsan because it is too slow  update skip_list.json  update test and bump ci  update skip_list.json  final fix  cache-dictionary flap ", "linked_issue_titles": "", "title": "cherry pick #13624 to 20.5: cache-dictionary flap"}
{"description": " hardcoded key escape sequences (such as [[a for arrow-up) serve their purpose in most cases, but not in any terminal configuration. it's a better practice to query the right codes dynamically from $terminfo instead. i expect this to become a real-world problem as soon as recent debian and ubuntu versions become used more widely: those ship with a /etc/zsh/zshrc which enables \"application mode\", in which oh-my-zsh's key bindings partially don't work. i've written down more about that problem on my blog. my commits migrate the key bindings to terminfo wherever possible. please note that in order to use $terminfo, my code hast to activate the \"application mode\" as well and might therefore break custom hardcoded key bindings. i based my work on the documentation efforts by @kylewest from pull request #889. ", "commit_messages": " added documentation to key bindings.  conflicts:  lib/key-bindings.zsh  forgot to save before committing. doh  don't clobber standard esc+. behavior  esc+. works as \"last arg\" on both bash and zsh. seems like a shame to introduce a new standard.  conflicts:  lib/key-bindings.zsh  make sure the terminal is always in application mode when zle is active. ", "linked_issue_titles": "", "title": "use terminfo key codes instead of hardcoded ones for key bindings"}
{"description": " it was reported to me by mwb that on the soldered pcb, both the backspace and left shift keys were not correct on the layout_65_ansi layout. also took the opportunity to do some minor clean ups. my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " both backspace and left shift matrix positions off by one  update the led_update routine  update readme ", "linked_issue_titles": "", "title": "think 6.5 soldered matrix fix"}
{"description": " several changes in react native 0.28 and 0.29 are not reflected in the current definition. this pr fixes that. ", "commit_messages": " rn: widen limit of refreshcontrol  rn: update navigationexperimental to 0.28  rn: define new method from 0.28  rn: promisify requestpermissions per 0.28  rn: remove onnavigate method  see:  rn: add onnavigateback method  see:  rn: deprecate statusbarios  rn: update stylesheet api per 0.29  rn: define keyboardavoidingview added in 0.29  rn: define savetocameraroll added in 0.29  rn: define cancellable from interactionmanager  rn: add new possible values of flexdirection  rn: define linebreakmode  rn: allow zindex prop  rn: allow dimension limits ", "linked_issue_titles": "", "title": "document changes in 0.28 and 0.29 in react native"}
{"description": " control flow analysis can easily hit circularities or exponential behaviour when requesting the contextual type of an expression. when adding an element type to an evolving array type, there is no point in checking the contextual type of the new element type because it is unknown -- it is exactly the type of the evolving array, which is in the middle of being found. fixes #14628 this is code of the form: let x = [] x[0] = { contextual: 'no' } x[1] = { contextual: 'should not check' } x[2] = { contextual: 'contextual type' } // : // : i considered adding a third parameter to gettypeofexpression and calling checkexpressionwithcontextualtype, but i decided having a new function that delegates to gettypeofexpression is less confusing. ", "commit_messages": " evolving array element ignores contextual type  control flow analysis can easily hit circularities or exponential  behaviour when requesting the contextual type of an expression. when  adding an element type to an evolving array type, there is no point in  checking the contextual type of the new element type because it is  unknown -- it is exactly the type of the evolving array, which is  in the middle of being found.  fixes #14628  this is code of the form:  ts  let x = []  x[0] = { contextual: 'no' }  x[1] = { contextual: 'should not check' }  x[2] = { contextual: 'contextual type' }  // :  // :    test: object literal assignments->expanding arrays  previously, the compiler would run out of memory for more than 13 or 14  of these assignments. ", "linked_issue_titles": "", "title": "evolving array element type ignores contextual type"}
{"description": " update generatenm2.ts to create constant spec for turbo modules move react_constant and react_constant_provider to react_get_constants appstatemodule i18nmanagermodule deviceinfomodule microsoft reviewers: open in codeflow ", "commit_messages": " split method validation generation to a single file  refactor  refactor  generate constant spec  update generatenm2.ts  yarn build  update appstatemodule  update i18nmanagermodule  update deviceinfomodule  change files ", "linked_issue_titles": "", "title": "check constants in generated turbo module specs"}
{"description": " new features others first, build the cluster graph from the cluster representation. second, build the process graph from the partitioned program. third, do the mapping between the two graphs. ", "commit_messages": " [auto parallel]  add the unified cluster representation  [auto parallel] add the graph class for physical mapping  [auto parallel] add the simple physical mapper ", "linked_issue_titles": "", "title": "do the physical mapping between the process graph and the cluster graph"}
{"description": " backported #948 to master. ", "commit_messages": " fixed npp error constants usage  fixed constructors for functional objects (added __host__ modifier)  rewrite core/cuda/vec_math.hpp file  old version isn't compiled with cuda 5.5  new version doesn't depend on functional.hpp  fixed broxopticalflow regression test  the output of broxopticalflow differs a bit in cuda 5.5  fixed boxfilter sanity test (different rounding results)  fixed broxopticalflow sanity test (increase epsilon value) ", "linked_issue_titles": "", "title": "fixed gpu modules build with cuda 5.5 rc (master branch)"}
{"description": " gitpython did a new release which breaks our tests:  see:  pinning gitpython for now to make circle ci work did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " fix_torch_device_generate_test  remove @  pin git python ", "linked_issue_titles": "", "title": "pin git python to <3.1.19"}
{"description": " #11520 edit: a change to the defaults of a public method needs to go through the deprecation cycle. this pr has been revised to update the docstring and introduce a futurewarning to power_transform(). looks like the function version of powertransformer wasn't updated when yeo-johnson was added. just matching the defaults and updating the docstring with this pr. congrats on the 0.20 release!! ", "commit_messages": " fix make yeo-johnson default in power_transform()  doc update power_transform() docstring  tst update power_transform() tests with new default ", "linked_issue_titles": "", "title": "fix update power_transform docstring and add futurewarning"}
{"description": " this pull request provides two fixes: prevents cmake from not allowing to create debs due to treating rbpi differently to linux. wiiremote was not build and thus packaging was failing, due to not having the wiiremote target defined. this will also require a backport to v17. pr: #11332 forum topic:  see above built kodi with cpack_generator=deb option. bug fix (non-breaking change which fixes an issue) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) my code follows the code guidelines of this project i have read the contributing document ", "commit_messages": " [cmake] allow rbpi platform to create deb packages  [rpi] adds symlink to linux/extratargets.cmake so it doen't break on building and packaging wiiremote ", "linked_issue_titles": "", "title": "fixes cpack support and wiiremote packaging for rpi"}
{"description": " this did not just work because we build libsdl2_mixer_ogg etc., with a suffix for the codecs we build in. this pr adds an explicit mapping to handle such cases. also improve the test to check this, and add a lot more checks there, like that we don't use sdl1 somehow (which can happen with files like this where the sdl1 and sdl2 apis agree, and so sdl2 does not need to be linked in to get a running executable). fixes #12589 ", "commit_messages": " auto [ci skip]  fixes #12589  test  test  changelog ", "linked_issue_titles": " support -lsdl2_mixer and others ", "title": "allow linking with -lsdl2_mixer to work properly"}
{"description": " add error message when there are conflicting star exports (fixes #7562) use tracked reexport target for sideeffectsplugin improves handled cases regarding dynamic modules display reexport target in module info header (output.pathinfo) refactoring, bugfix, feature yes no optimization.sideeffects depends on optimization.providedexports ", "commit_messages": " track the target binding of harmony reexports  display target binding in module info header  check conflicting star exports (fixes #7562) when statically known  add test case  store multiple targets per exportinfo  resolve target when reading  replace recursion with loop  fix bug in target tracking  use target info to implement side effects plugin  improve test case  update snapshots  add another test case ", "linked_issue_titles": " conflicting esm star re-exports should yield a syntaxerror ", "title": "track reexport target during providedexports analysis"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " added missing params from statuses/update    made all params optional and changed types ", "linked_issue_titles": "", "title": "add properties to params interface in twit package to support the statuses/update endpoint"}
{"description": " description: this pr introduces the initial implementation of an api listener based on the proto configuration merged in #8170. notably, this pr introduces the ability to add only one api listener via bootstrap config only. this decision was made in order to iterate into more complex setups (multiple listeners, lds supplied listeners) in subsequent prs. moreover, the api listener is created in the context of envoy's main thread not worker threads. a first use of this api listener can be seen in envoyproxy/envoy-mobile#616. risk level: low, only used in envoy mobile. the risk here is about building something generally useful and flexible. note however that a couple of things were rejiggered in the hcm. testing: unit and integration tests. additional testing in  docs changes: added inline comments and todos. proto documentation is up-to-date. release notes: similar to doc changes. ", "commit_messages": " wip: get an api listener at all costs  fmt build  building and worksgit add source/! :tada:  initial clean up. builds, tested  fmt  back to singleton. apilistener and apilistenerhandle interfaces  fmt  comments  comments split up  move read callbacks outside of the lambda  comment  fmt  change api listener to implemented ", "linked_issue_titles": "", "title": "first implementation of an api listener"}
{"description": " switches rustup to using the beta channel by default. includes #23824 for the implementation. cc #20453 closes #21149 ", "commit_messages": " rustup: fix comment about darwin's uname -m  add support for channel selection ", "linked_issue_titles": " update rustup.sh for beta ", "title": "default to the beta channel"}
{"description": " this pr: adds support for running an rllib policy server with n listen ports (n workers) accepting one or more client connections. makes sure that in case not all ports have active client connections (or incoming data in general), learning on the server can still continue (not blocked) on all other workers using whatever data comes in from different clients. removes the need to create a randomenv dummy env on the server, only to specify the action/observation space through that env. the spaces can be given now in the config. in a future pr, action and observation spaces will be sent from connected clients and may not be specified at all anymore on the server side. updates the cartpole server/client example script to show how a multi-port setup can be achieved. also enhances the policy server/client test cases to 3 connected clients (from just 1) connecting to different ports. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " wip  wip  wip  wip  # conflicts:  #\trllib/evaluation/sampler.py  # conflicts:  #\trllib/evaluation/sampler.py  # conflicts:  #\trllib/evaluation/rollout_worker.py  fix and lint  fix and lint  fix and lint ", "linked_issue_titles": "", "title": "external env enhancements + more examples."}
{"description": " we currently contextually type un-annotated iife parameters by their corresponding arguments. this pr expands upon this concept by inferring un-annotated iife parameter with missing arguments as optional. that allows us to handle the following common idiom with no errors: let foo = (function (window, undefined) { // body })(window); without this pr the example is an error because the undefined isn't marked optional. note that the pr also simplifies some overly complicated logic for computing the minargcount property in signatures. ", "commit_messages": " allow missing argument for iife parameter with no type annotation  accept new baselines  add tests ", "linked_issue_titles": "", "title": "infer optional types for iife parameters with missing arguments"}
{"description": " the gatsby-node for the wp plugin was meant to be a jumping off point that didn't include any logic. this pr refactors that file so that continues to be the case. it also allows us to reuse this first-supported-api-name logic for any node api in the future if framework adds new node api's. ", "commit_messages": " abstract using multiple lifecycle api names for any node api's  add example ", "linked_issue_titles": "", "title": "refactor logic for supported node api names"}
{"description": " inspired by this. while writing tests i've found some inconsistency between default value of param in c++ code and sklearn wrapper: bagging_freq, default=0, type=int, alias=subsample_freq subsample_freq : int, optional (default=1) also sklearn description says: \"frequence of subsample, <=0 means no enable.\", but on c++ side there is a validation check(bagging_freq >= 0); @guolinke which side should be fixed? even after bringing the consistency in subsample_freq tests fail. for instance, after first predict we have res_engine[0][0] >>> 0.0013241289219269466 res_sklearn[0][0] >>> 0.0013241290058445348 also, is there any way to test pred_parameter works? as i understand, there is no validation for keywords in booster.predict(). ", "commit_messages": " fixed docs  reworker predict method of sklearn wrapper  fixed encapsulation  added test  fixed consistency between docstring and params docs  fixed verbose  replaced predict_proba with predict in test  fixed verbose again ", "linked_issue_titles": "", "title": "reworked predict method in sklearn wrapper and docs improvements"}
{"description": " this pr fix managing of ownstate in explore page before chart was saved includes db migration (follow approval process in sip-59) ", "commit_messages": " fix:fix get permission function  \u0001 conflicts:  \u0001\tsuperset-frontend/src/dashboard/util/getpermissions.ts  fix: fix ownstate for unsaved explore chart ", "linked_issue_titles": "", "title": "fix explore state - backend pagination checkbox in table"}
{"description": " there are a couple of core worker tests that are not quite stable, including testdirectactortaskcrossnodesreconstruction, testdirectactortaskcrossnodesnoreturnperformance .etc, basically the ones that are using waitfordirectcallactorstate() in core_worker_test.cc. the problem is that sometimes the notification for the actor creation is not received by the core worker, thus these tests timeout after 30 seconds.  the underlying issue is subscribe and other operations use different redis contexts, thus it's not guaranteed that which one gets processed earlier. if the requestnotification is processed earlier than subscribe request, then the core worker will not receive the initial notification. this can be fixed by making sure the requestnotification is only called after subscribe is finished. because there can be multiple requestnotification requests (subscribing different ids) submitted before the done callback for subscribe request is invoked, thus we use a list to cache the requestnotification requests when the subscribe request's done callback is not called yet. ", "commit_messages": " fix gcs client subscribe  fix build  format ", "linked_issue_titles": "", "title": "fix flaky core worker tests because of race condition in gcs client subscription"}
{"description": " bias tensor reorder overhead in int8 inference is significant, especially for low latency models (i.e. mobilenet). the reorder primitive is used to quantize fp32 bias tensor into int8. by caching the reordered bias tensor, int8 models' latency got significant improvement. ", "commit_messages": " bias cache implemented.  remove useless comment lines.  add test cases.  remove debug log lines.  add 'const' qualifier to 'scaled_bias'.  do not cache bias_md anymore.  add comments to note: currently we're not inspecting the persistent tensor  contents to see if the cached data is being resued.  add attr \"is_bias_const\" to _mklquantizedconv* ops.  fix a typo: 'is_filter_const' should be 'is_bias_const'.  fix clang format issues of mkl_fused_ops_test.cc  port bias reorder code to mkl-dnn v1.x ", "linked_issue_titles": "", "title": "cache bias tensor for int8 inference"}
{"description": " please see #19146 (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged) fixes #19041 #19146 was missing this, because if we keep quote we still get empty quotes as values for clusterip. as it stands we will still wind up with clusterip: \"\" if no value is provided ... just {{ . }} is better since it will not add clusterip to rendered files if no value is provided, but the user needs to quote any provided values themselves also forgot to do it for metrics service in previous pr dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " no empty string clusterip  no empty quotes value for clusterip ", "linked_issue_titles": " [stable/nginx-ingress] cannot upgrade release with helm 3 ", "title": "nginx ingress no empty quotes clusterip"}
{"description": " i saw that in the java version there was the factorial algorithm, so, i thought that it would be nice to have the same but this time made with c. and i also made a fibonacci algorithm that asks for a number and than it tells which number is in the n position according to the fibonacci sequence. hope you like it :) ", "commit_messages": " add a factorial algorithm  add a fibonacci algorithm ", "linked_issue_titles": "", "title": "add 2 more algorithms (fibonacci and factorial)"}
{"description": " description: fixes and error where devices exposed to emulated hue without a friendly name attribute set would cause emulated hue to fail. related issue (if applicable): fixes # fixes #4787 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> n/a example entry for configuration.yaml (if applicable): n/a checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " get entity name from entity.name  grabbing the attr_friendly_name directly produces an error. instead  grab from entity.name. ", "linked_issue_titles": " emulated_hue error with google home ", "title": "emulated_hue friendly_name key error fix"}
{"description": " fixes #18072 adds support for the suggestions stated in #18072 when an unknown category is encountered and there is a dropped category, then the unknown category will be encoded as the dropped category. (all zeros) the inverse transform will map all zeros to the dropped category if a category was dropped. ", "commit_messages": " wip  enh adds support for handle_unknown=ignore and drop  enh adds inverse_tranform with dropped category ", "linked_issue_titles": " drop must be none for onehotencoder to utilize handle_unknown = 'ignore' ", "title": "enh adds support for drop + handle_unknown=ignore in the onehotencoder"}
{"description": " since version 0.7.0, xmldom is published to npm as @xmldom/xmldom and no longer as xmldom, because the package owners are no longer able to publish xmldom. see xmldom/xmldom#271 for more information. we need to upgrade our xmldom dependencies to mitigate cve-2021-32796. see ghsa-5fg8-2547-mr8q. this issue was partially mitigated by commit bfc26ac, but that commit did not bump the version of xmldom used by @react-native-windows/cli. this pr does do. we would also need to backport this all the way back to 0.63 to mitigate security component governance alerts in internal dependent repos. microsoft reviewers: open in codeflow ", "commit_messages": " bump xmldom to 0.7.0 in @react-native-windows/cli.  change files ", "linked_issue_titles": "", "title": "bump the version of xmldom used by @react-native-windows/cli to 0.7.0."}
{"description": " this is reduced version of #5694. only obvious fixes. ", "commit_messages": " [vfs] [win32] win32file: really support \"test\" read() and write() with zero buffer size  [vfs] [win32] win32file: better handle partially read/written buffer in read()/write()  [vfs] cfile: workaround in read() and write() for vfses that do not support null buffer pointer  [emufnc] dll_read(): set errno if read() failed  [emufnc] dll_write(): set errno if write() failed  [emufnc] fix: \"-1\" is incorrect return value for dll_fwrite() and dll_fread() (return type is size_t)  [emufnc] fix: return zero for dll_fread()/dll_fwrite() if size or count is zero  [emufnc] fix: always read all data in dll_fread()  [emufnc] fix: always read all data in dll_fwrite()  [emufnc] fix: return correct value in dll_fclose()  [emufnc] fixes: correctly emulate on bigendian platforms, use cast to _unsigned_ char in dll_fputc()  [emufnc] use proper macro instead of hardcoded value in dll_ungetc()  [emufnc] fix: use correct return value on error in dll_filbuf, try to restore proper file pointer  [emufnc] fix: use correct return value on error in dll_flsbuf, flush file buffers, properly write data ", "linked_issue_titles": "", "title": "even better emulate posix file functions (reduced)"}
{"description": " just come across this comment ", "commit_messages": " [sema] adding deprecation warning for protocol inheritance class keyword syntax  [test] adjusting test files where class syntax is used for protocol inheritance  [test] adding specific tests for the warning for protocol inheritance class keyword syntax deprecation  [test] adjusting stdlib ocurrences where class syntax is used for protocol inheritance ", "linked_issue_titles": "", "title": "adding deprecation warning for protocol inheritance 'class' syntax"}
{"description": " cherry pick of #102306 #102465 on release-1.21. #102306: return unschedulableandunresolvable instead of error when #102465: return unschedulableandunresolvable when looking up part of #102305 for details on the cherry pick process, see the cherry pick requests page. ", "commit_messages": " return unschedulableandunresolvable instead of error when failing to lookup pvc or storageclass in volumezone plugin  return unschedulableandunresolvable when looking up volume-related resources returns notfound error ", "linked_issue_titles": "", "title": "return unschedulableandunresolvable instead of error when\r\n#102465: return unschedulableandunresolvable when looking up"}
{"description": " recently we have noticed multiple instances where kafkaproducers have failed to constructer due to the following exception: org.apache.kafka.common.kafkaexception: failed to construct kafka producer at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:440) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:291) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:318) java.base/java.lang.thread.run(thread.java:832) caused by: java.util.concurrentmodificationexception at java.base/java.util.hashmap$hashiterator.nextnode(hashmap.java:1584) at java.base/java.util.hashmap$keyiterator.next(hashmap.java:1607) at java.base/java.util.abstractset.removeall(abstractset.java:171) at org.apache.kafka.common.config.abstractconfig.unused(abstractconfig.java:221) at org.apache.kafka.common.config.abstractconfig.logunused(abstractconfig.java:379) at org.apache.kafka.clients.producer.kafkaproducer.<init>(kafkaproducer.java:433) ... 9 more exception.class:org.apache.kafka.common.kafkaexception exception.message:failed to construct kafka producer this is due to the fact that used below is a synchronized set. used is being modified while removeall is being called. this is due to the use of recordingmap in the sender thread (see below). switching to a concurrenthashset avoids this issue as it support concurrent iteration. at org.apache.kafka.clients.producer.producerconfig.ignore(producerconfig.java:569) at org.apache.kafka.common.config.abstractconfig$recordingmap.get(abstractconfig.java:638) at org.apache.kafka.common.network.channelbuilders.createprincipalbuilder(channelbuilders.java:242) at org.apache.kafka.common.network.plaintextchannelbuilder$plaintextauthenticator.<init>(plaintextchannelbuilder.java:96) at org.apache.kafka.common.network.plaintextchannelbuilder$plaintextauthenticator.<init>(plaintextchannelbuilder.java:89) at org.apache.kafka.common.network.plaintextchannelbuilder.lambda$buildchannel$0(plaintextchannelbuilder.java:66) at org.apache.kafka.common.network.kafkachannel.<init>(kafkachannel.java:174) at org.apache.kafka.common.network.kafkachannel.<init>(kafkachannel.java:164) at org.apache.kafka.common.network.plaintextchannelbuilder.buildchannel(plaintextchannelbuilder.java:79) at org.apache.kafka.common.network.plaintextchannelbuilder.buildchannel(plaintextchannelbuilder.java:67) at org.apache.kafka.common.network.selector.buildandattachkafkachannel(selector.java:356) at org.apache.kafka.common.network.selector.registerchannel(selector.java:347) at org.apache.kafka.common.network.selector.connect(selector.java:274) at org.apache.kafka.clients.networkclient.initiateconnect(networkclient.java:1097) at org.apache.kafka.clients.networkclient.access$700(networkclient.java:87) at org.apache.kafka.clients.networkclient$defaultmetadataupdater.maybeupdate(networkclient.java:1276) at org.apache.kafka.clients.networkclient$defaultmetadataupdater.maybeupdate(networkclient.java:1164) at org.apache.kafka.clients.networkclient.poll(networkclient.java:637) at org.apache.kafka.clients.producer.internals.sender.runonce(sender.java:327) at org.apache.kafka.clients.producer.internals.sender.run(sender.java:242) ", "commit_messages": " wip  kafka-12791: fix concurrentmodificationexception in abstractconfig ", "linked_issue_titles": "", "title": "concurrentmodificationexception in abstractconfig use by kafkaproducer"}
{"description": " bpo-30721 added a \"did you mean ...?\" suggestion to rshift typeerror messages that triggers when the lhs is a python c function called \"print\". since this custom error message is expected to be triggered primarily by attempts to use python 2 print redirection syntax in python 3, and is incredibly unlikely to be encountered otherwise, it is also being backported to the next 3.6 maintenance release. ", "commit_messages": " bpo-30721: show correct syntax hint in py3 when using py2 redirection syntax (#2345)  bpo-30721: add missing '?' to new error message (gh-3131) ", "linked_issue_titles": "", "title": "backport custom print rshift message"}
{"description": " this is an initial stab at splitting the autoscaler public/private interface. it moves most of autoscaler (verbatim) into _private, and exposes tags.py, node_provider.py, and a new sdk.py. the public interface should be considered wip at this point pending refinement. since this pr is moving a lot of files, we should try to merge it quickly and iterate. closes #10837 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for ", "commit_messages": " move  update  wip  fix  add sdk  update  fix up imports  audit  fix  lint  wip  fix tests ", "linked_issue_titles": " [autoscaler] expose stable public api, move internals to _private package ", "title": "split autoscaler interface public private"}
{"description": " related issue: #10331 #15850 #17158 #17586 #17958 #20997 adreno drivers do not handle gl_frontfacing properly so we need a workaround. i've made sure that the models in #17804 look correct. ", "commit_messages": " shaderchunk: gl_frontfacing workaround.  shaderchunk: use gl_frontfacing workaround everywhere. ", "linked_issue_titles": "", "title": "workaround for adreno gpus gl_frontfacing bug."}
{"description": " (i'm finally following up on #11090, noticed that we do not do libcryptsetup debug logging correctly) ", "commit_messages": " basic/log: fix systemd_log_* parsing error messages  (likely a copy-paste gone wrong)  cryptsetup: set libcryptsetup global log callback too ", "linked_issue_titles": "", "title": "properly handle libcryptsetup debug logging"}
{"description": " we recently had two migrations merged into master that had the same upstream migration. this pr: adds a merge migration. adds a unit test to catch such cases in the future. #5317, #5267 ", "commit_messages": " add unit test to test for multi-head migrations issue  add merge migration ", "linked_issue_titles": "", "title": "add a merge migration to solve multi head issue"}
{"description": " it has turned out that h2o has stopped sending tls alerts upon handshake failure, when a recent version of openssl is being used (the issue known to happen in 1.1.0g, but not in 1.1.0d). see #1865 (comment) for how it happens. this pr brushes up the fix proposed in #1865 as well as adding a test. ", "commit_messages": " add failing test that fails only with openssl newer than 1.1.0g (likely)  send the tls alert on handshake errors  use dedicated callback  use the exact same error string as we do now  report the *first* fatal error ", "linked_issue_titles": "", "title": "send tls alert on handshake failure when recent versions of openssl is used"}
{"description": " the enhanced sourcekitd requests are editoropen and edtiorreplacetext. in these two requests, the clients can specify a flag \"key. enablesyntaxtree = 1\" to get a serialize libsyntax tree with the response. to help this integration, we added a function in syntaxparsingcontext to explicitly finalize the creation of a sourcefilesyntax to incorporate the fact that sourcekit needs the tree before its destroying the parser instance. to test this integration, we diff the syntax tree serialized from the frontend action and the tree serialized from a sourcekitd response. they should be identical. ", "commit_messages": " libsyntax integration with sourcekit  add test.  make it lazy.  add documentation. ", "linked_issue_titles": "", "title": "integrating libsyntax representation of a source file with several sourcekitd syntax request.s"}
{"description": " userrolemapper.userdata is constructed by each realm and it is used to \"match\" role mapping expressions that eventually supply the role names of the principal. null values as group names or metadata values were not properly supported. most of the time they were filtered out, but under some circumstances they might cause npes (depending of how the oidc and saml's underlying libraries parse purposefully crafted assertions - these libraries don't have internal null checks the same way that the unboundid library does). this pr enforces non-null collection values (lists and maps) earliest in the process and utilizes java 9 unmodifiable collections api, with the goal of eliminating redundant null filtering and repeated wrapping incolllections.unmodifiable* . ", "commit_messages": " wip all but saml  groups don't dig nulls  kerberos and ldap metadata  oidc metadata  done  nits ", "linked_issue_titles": "", "title": "userrolemapper non-null groups and metadata"}
{"description": " as requested, adding in the parameters required to claim a node immediately after installation as part of using kickstart.sh or kickstart-static64.sh or calling netdata-install.sh manually. component name area/docs area/packaging ", "commit_messages": " add section to kickstart doc  add to kickstart64  add section to manual, add examples ", "linked_issue_titles": "", "title": "add documentation for claiming during kickstart installation"}
{"description": " this pr is a subset of #25586. when performing internal patches, we noticed it touches a large number of internal build targets so that they can depend on the new targets introduced in #25586. the downside is that it also involves a large number of reviewers which will make the rollback process slow and difficult. in order to ease the process, in this pr, we introduced new empty targets that will be depended by internal targets, which will be sufficient to make internal changes via lsc. note that this pr includes the minimum code changes needed to successfully build the new targets. ", "commit_messages": " add empty targets  fix format error ", "linked_issue_titles": "", "title": "introduce empty targets to ease the internal merge of #25586"}
{"description": " fixes issue #9193 i could use some extra eyeballs and feedback on this, i'm not entirely familiar with the schema dumper. thanks for your time ", "commit_messages": " add some tests to enumerate how extensions should be stored in the schema output  improve tests to check for existence of extensions method, and skip testing dumped extensions if they are unsupported by the database  add activerecord::abstractadapter#extensions and activerecord::connectionadapters::postgresqladapter#extensions to allow dumping of enabled extensions to schema.rb, add activerecord::schemadumper#extensions to dump extensions to schema.rb ", "linked_issue_titles": "", "title": "adding database extension support to schema.rb"}
{"description": " hi! here's what the three commits are doing: c8ee20a: trivial fix, add a missing break; in the option parsing. i noticed that the option in question, -r is not documented and given the --depth option possibly useless anyway. bcd8e2d: remove strlcat and strlcpy once again. these were removed in 579af6d and added back again in d5625e4. linux does not have these, so we can't use them. my solution is to use manual memcpying, which saves some unnecessary hunting for the null terminator that strlcat would have to do. 29f9ae1: this is the major one. in non-literal mode, the -w option, translates to a set of \\bs around the regexp, which means that the word has to lie at word-character boundaries. it makes sense to keep the same semantics for literal mode, especially given that literal mode is enabled implicitly if the query has no regex special characters. the old behaviour is that the match must be surrounded by whitespace characters. ", "commit_messages": " options.c: fix unintentional switch fallthrough  affects undocumented options -r, -r, which are slightly unnecessary anyway  make it compile on linux (has no strl{cpy,cat})  replacement is also a little faster:  does not search for null terminator twice unnecessarily  fix semantics of -w on literals  ensure the meaning is the same as when using regexes, i.e. look at  whether start and end of the match are both at word-char / non-word-char  boundaries. should also improve performance a little bit. ", "linked_issue_titles": "", "title": "\"-w\" fix; remove strlcat once again; option parsing switch fallthrough fix"}
{"description": " the problem with my previous pr (#36517) was when you were using nested objects, they have to be specified as full objects with all props. this pr fixes that. however, this requires typescript 2.8 which adds support for mapped types. i had to update all other definitions depending on mongoose. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). ", "commit_messages": " add deep partial  change typescript version to 2.8  change connect-mongo typescript version to 2.8  change joigoose typescript version to 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update packages depending on mongoose to ts 2.8  update test to cover deep partial  restore format ", "linked_issue_titles": "", "title": "accept deep partial in model interface"}
{"description": " fix travis deployment condition condition: $multiplatform_jars = 1 || $mac_jars = 1 and bring back java dist commit. the previous condition: $multiplatform_jars = 1 || $mac_jars=1 cause master ci failure. the correct condition should be condition: $multiplatform_jars = 1 || $mac_jars = 1 #9758 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " revert \"revert \"[dist] swap mac/linux wheel build order (#9746)\" and \"fix package and upload ray jar (#9742)\" (#9758)\"  this reverts commit 423dc96cc44b26e3696d80d31b02d194ffafc926.  fix deploy ", "linked_issue_titles": "", "title": "fix travis deploy for java dist"}
{"description": " mcu & flash speed entrys are not needed anymore in platformio ini files the correct values are defined in the boards.json the code change is tested and works on tasmota core esp8266 v.2.7.4.9 the code change is tested and works with core esp32 v.1.0.6 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " remove redundant speed settings (mcu & flash) from platformio  since it is in boards ", "linked_issue_titles": "", "title": "remove redundant entrys from platformio"}
{"description": " adds two new aliases: npm info and npm search the realize the aliases themselves may not be ideal in differentiating them from others. i attempted to find a balance between easy/memorable, while also trying to avoid collisions with other aliases. i'm definitely open to feedback if others feel strongly for better-named aliases. thanks! ", "commit_messages": " npm: add aliases for search and info  npm: update table of aliases ", "linked_issue_titles": "", "title": "add aliases for npm search and npm info"}
{"description": " following the steps in the guide, errors will occur running the workflow due to these syntax problems. example failed run with the guide syntax for environment variables before these changes:  example successful run with the updated environment variable syntax reflected in this pr:  example failed run with the output redirect to $github_env before these changes:  example successful (step) with the updated ::set-ouput syntax reflected in this pr:  syntax of environment variables used in jobs.<job_id>.steps[*].with, from $env_var to ${{ env.env_var }} fix to output command, from redirecting to $github_env to using ::set-output name=variable:: i have reviewed my changes in staging. (look for the deploy-to-heroku link in your pull request, then click view deployment) for content changes, i have reviewed the localization checklist for content changes, i have reviewed the content style guide for github docs. direct link to staging deploy: ", "commit_messages": " use env context syntax for step variables  top-level environment variables cannot be referenced from jobs.<job_id>.steps[*].with using the direct environment variable syntax (e.g. $aws_region)  ::set-output to send image name to steps context  redirecting to $github_env does not populate the ${{ steps.[*].outputs.* }} context ", "linked_issue_titles": "", "title": "updates to aws ecs deploy guide"}
{"description": " from auto-562 and im, another business unit decided to use our service account for docker hub, and they blew through our rate limits. eosio builds are now stuck anywhere that we are hitting docker hub for manifest queries or pulls. this pull request edits the pipeline code to only query our mirror, except in cases where no mirror is specified or where the image does not exist. this should unblock nearly all builds. see also pull request 10044 -- eos:develop pull request 10046 -- eos:release/2.1.x pull request 10047 -- eos:release/2.0.x pull request 10048 -- eos:release/1.8.x select one: ci. select any that apply: none. none. none. ", "commit_messages": " build: don't check manifests at docker hub unless absolutely necessary  simplify variables  bug fixes  generic names  avoid hitting docker hub in docker tag/label step, where possible ", "linked_issue_titles": "", "title": "reduce docker hub manifest queries"}
{"description": " new module pull request network/aos/aos_device ansible version ansible 2.3.0 (aos_device_clean de9d90c9e6) last updated 2017/02/10 15:59:02 (gmt -700) config file = configured module search path = default w/o overrides i'm working for apstra, we are making a product to automate datacenter networks and we are developed a dozen of ansible modules and one dynamic inventory to control our product with ansible. we have tried to follow ansible's best practices as much as possible, all our modules are idempotent and support the mode --check. currently, this module has limited features but the few it has are very useful :). we have implemented the parameter state even if it only supports 1 state right because we know that we will add more very soon, unfortunately it won't be ready for the 2.3 deadline. this is the third batch of modules that i'm submitting for review, the first aos_ip_pool #21044 has been recently approved. ", "commit_messages": " initial version of aos_device  clean up documentation  move try/except closer to device.approve  remove non valid characters ", "linked_issue_titles": "", "title": "aos_device as part of network/aos"}
{"description": " first commit fix log and gui strings. second commit fix log and fix potential bug when some incompatible locales settings (system/user/xbmc). ", "commit_messages": " [win32] network::gethostname: convert result to utf-8  [win32] winsystemwin32 use widestring functions instead of ansi ", "linked_issue_titles": "", "title": "fix ansi used as utf-8"}
{"description": " this pull request updates the expiration date of the wp8/universal app project certificates. from:  renewing a certificate the default certificate that visual studio generates expires one year after the date on which the certificate was created. before the certificate expires, you must use the app manifest designer to either regenerate the certificate or, as the previous procedure describes, provide a different, valid certificate. to renew the certificate in solution explorer, open the shortcut menu for the .appxmanifest file, choose open with, and then choose app manifest designer. in the app manifest designer, choose the packaging tab, and then choose the choose certificate button. in the choose certificate dialog box, expand the configure certificate list, and then choose create test certificate. in the create test certificate dialog box, click the ok button. visual studio regenerates the certificate with a new expiration date. ", "commit_messages": " updated expiration date of project certificates ", "linked_issue_titles": "", "title": "v3 updated expiration date of wp8/universal app project certificates"}
{"description": " and included are some sample userspace files that include my _keymap \"hack\" ", "commit_messages": " cleanup of keymaps  fix merge  remove tap dance from orthodox keymap  cleaned up userspace and keymaps  added sample (template)userspace files to my folder ", "linked_issue_titles": "", "title": "cleaned uppersonal userspace and keymaps"}
{"description": " commit message: this is a follow up (performance nit) after #13423. this builds the replacement map on the first use. additional description: #13423 (comment) risk level: low testing: existing tests docs changes: n/a release notes: n/a ", "commit_messages": " stream_info: build replacement map once  this is a follow up (performance nit) after #13423.  newlines ", "linked_issue_titles": "", "title": "build replacement map on first use"}
{"description": " this pr marks features commented as deprecated with attributes; [[deprecated]] if compiled with c++14 and __attribute__((deprecated)) or __declspec(deprecated) if not. i was able to replace most of the cases where deprecated functionality was used in the library, but one case lingers:  arg_map::init takes const basic_format_args<context>& as its sole argument, which can only be extracted from context_base with the deprecated member function args(). ", "commit_messages": " replace comments regarding deprecation with attributes  remove use cases of deprecated functionality ", "linked_issue_titles": "", "title": "mark deprecated functionality with attributes and remove usage of such features"}
{"description": " i hereby agree to the terms of the cla available at:  category: short description: added possibility to init a clickhouse instance which requires authentication. duplicated: #5321 detailed description: changes make it possible to provide environment variables clickhouse_user & clickhouse_password that will be used for clickhouse-client during initialization. ", "commit_messages": " pr #5321 fix  update documentation for docker image  update documentation for docker image: fix ", "linked_issue_titles": "", "title": "add auth support for init script: fix pr #5321"}
{"description": " this pr improves nuxt ts support by adding a build option useforktschecker that enable type checking thanks to fork-ts-checker-webpack-plugin. type checking makes you able to know if there is ts related errors within your code, which means that without it you may have nuxt webpack compilation succeed, but the errors only reported at runtime and not in an elegant way. the type checker will check your code each time you make changes. in other terms, it's trigerred after each new webpack compilation. usage // nuxt.config.js export default { build: { useforktschecker: true } } useforktschecker can either be a boolean or an object. if it's an object, it will override the plugin options // nuxt.config.js export default { build: { useforktschecker: { silent: true, tslint: false } } } example of an error reported by the type checker project requirements to use this feature the fork-ts-checker-webpack-plugin is used/enabled only if the user project meets these requirements : useforktschecker option is enabled (true) in the nuxt configuration file ts-loader is configured with the transpileonly mode (to not have double type checkers) fork-ts-checker-webpack-plugin (and also tslint) devdependencies are installed if the two first rules are fulfilled but not the latter, a warning will let you know that your project is missing the dependencies required : documentation related to this pr will come later as a whole ts support documentation. ", "commit_messages": " wip  further work  fix lint  useforktschecker only when ts-loader is in transpileonly mode  more understandable code (move console.warn location) ", "linked_issue_titles": "", "title": "provide type checking through fork-ts-checker-webpack-plugin"}
{"description": " #10111 hi @tristazero, @wgy8283335. i've added sql definition for select statement's with clause. please check it. i'll change them based on your feedback. added sql definition for select statement's with clause. added test cases for with clause. i asserted subquery in the withclauseassert. in the sqlserverdmlstatementsqlvisitor, i changed the subquerysegment's start and stop indices by getting from cteclauses()'s subquery(). ", "commit_messages": " add definition for with clause  add start, stop indices for subquery segment ", "linked_issue_titles": "", "title": "add with clause for oracle select statement"}
{"description": " this adds api entries for managing the in-memory list of ignore rules for a repository, along with tests for those apis. this also implements core git's newly introduced default value for the core.excludesfile config setting. ", "commit_messages": " add public api for internal ignores  this creates a public api for adding to the internal ignores  list, which already existing but was not accessible.  this adds the new default value for core.excludesfile also.  wrap up ignore api and add tests  this fills out the ignore api and adds tests. ", "linked_issue_titles": "", "title": "api for managing in-memory ignore rules"}
{"description": " a typing file for google sign-in api: ", "commit_messages": " initial creation of new gapi.auth2 types  add auth2 typings file  let's try this as an interface instead  initial test creation  fix missing return types  add some missing required params to tests ", "linked_issue_titles": "", "title": "new typing for google sign-in api"}
{"description": " references #4830 since that pr was already merged. had the c++ template aliases commit in my master already, so i had to revert that. sorry about that. ", "commit_messages": " added preprocessor define for c++ if template aliases are supported by the compiler  revert \"revert \"performance increase of vector of structures using .net blockcopy (#4830)\"\"  this reverts commit 1f5eae5d6a135ff6811724f6c57f911d1f46bb15.  put<t> method was inside #if unsafe_bytebuffer which caused compilation failure when building in unsafe mode  revert \"added preprocessor define for c++ if template aliases are supported by the compiler\"  this reverts commit a75af7352127c261baf0b6cca5cb823e13e78f11. ", "linked_issue_titles": "", "title": "mono fix for unsafe mode"}
{"description": " this magic method was missing. allow the natural abs(x). please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change add abs magic method. test for the same. ", "commit_messages": " add magic method abs to ndarray  add relevant tests ", "linked_issue_titles": "", "title": "add magic method abs to ndarray and symbol."}
{"description": " doing thigns this way makes incremental parsing (specifically, determining if we can reuse a node) much easier. ", "commit_messages": " rename context flag.  move 'disallowin' into being an ambient parser context flag.  this greatly simplifies how we will do incremental parsing. ", "linked_issue_titles": "", "title": "change 'disallowin' into an ambient parser context flag."}
{"description": " ensures all bottom sheets use non-linear animations for entrance and exits, while still allowing dragging (linearly) bottom sheets. fixes the animation durations to match the spec. before (in slow motion): after (in slow motion):1 related issues closes #19469 future work  #51627 i added the following tests: a test to ensure that persistent bottom sheets animate non-linearly a test to ensure that modal bottom sheets animate non-linearly before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. ", "commit_messages": " merge changes from marcoms:bottom-sheet-curve  add material curves  fix modal bottom sheet duration and easing  fix typo  fix standard bottom sheet easing  remove extraneous exit curve  rename persistentbottomsheetcurve to standardbottomsheetcurve  add tests ", "linked_issue_titles": " material bottom sheet reveal/dismiss animation should use a curved animation ", "title": "material bottom sheet reveal/dismiss animation uses a curved animation"}
{"description": " updated the info.json and .h files to reflect the odd switch matrix regarding the long keys on the right. my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " updated info.json  update v2.h to reflect strange physical layout ", "linked_issue_titles": "", "title": "fixed info.json file for layout_default and layout_ansi_splitspace"}
{"description": " important: pull requests should only be issued against the dev branch. prs against the master branch will always be closed. this pr changes (delete as applicable) nothing, it's a bug fix because the tilemaplayer position is not accounted for in the tilemap collision check, collision fails as it expects the tilemaplayer to have a default position of 0,0 with regards to fixedtocamera being set to false. the benefit of this fix is apparent when creating near infinite (well until you get an arithmetic overflow in regards to position calculations...) tilemap worlds by stitching multiple tilemaplayer's together, and in order to achieve that you would need to set the position of that tilemaplayer to something other than 0,0. ", "commit_messages": " take into account position of tilemap in collision  take into consideration tilemap position into collision ", "linked_issue_titles": "", "title": "fixing tilemap collision when tilemaplayer is set to a position other than 0,0"}
{"description": " description: based on  related issue (if applicable): fixes  pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#4482 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " handle daikin ac devices without fan_mode and swing_mode support  handle daikin ac devices without fan_mode and swing_mode support ", "linked_issue_titles": "", "title": "handle daikin ac adapters without fan mode and swing mode support"}
{"description": " what's in this pull request? this pr implements se-0134. merge simultaneously with apple/swift-corelibs-foundation#486. before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test all supported platforms @swift-ci please smoke test and merge os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform a smoke test on macos does the following: builds the compiler incrementally. builds the standard library only for macos. simulator standard libraries and device standard libraries are not built. lldb is not built. the test and validation-test targets are run only for macos. the optimized version of these tests are not run. a smoke test on linux does the following: builds the compiler incrementally. builds the standard library incrementally. lldb is built incrementally. the swift test and validation-test targets are run. the optimized version of these tests are not run. lldb is tested. validation testing platform comment all supported platforms @swift-ci please test all supported platforms @swift-ci please test and merge os x platform @swift-ci please test os x platform os x platform @swift-ci please benchmark linux platform @swift-ci please test linux platform lint testing language comment python @swift-ci please python lint note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " [se-0134] rename utf8-related properties on string  [se-0134] fix-up for renaming utf8-related properties  [se-0134] another fixup for utf8-related property renaming ", "linked_issue_titles": "", "title": "rename/remove two properties on string"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr continues the planned set that will together add up to #45201 and includes the following changes: adds tests for where, findwhere, shuffle, and sample. updates where and findwhere to take a partial<t> instead of an object to provide better autocomplete support where available and provide an error for inline object declarations with no matching properties. updates the overload of sample in which n is not provided to include undefined as a possible result (for the case where an empty collection is provided). updates the return type for _chain.findwhere to include undefined. removes the redeclaration of the t generic in underscore.sample and _chain.sample which will fix #20440 for those functions. updates the return type of _chain.where, _chain.shuffle, and _chain.sample to use the correct wrapped value type v to partially fix #36308. updates underscorestatic.where and underscorestatic.findwhere to work with both lists and dictionaries to partially fix #20623. ", "commit_messages": " updating type definitions for where, findwhere, shuffle, and sample and adding tests.  fixing a test group comment in map that was missing its collection type differentiator.  adding \"any\" tests for where and findwhere.  fixing various issues. ", "linked_issue_titles": " inaccurate typings for underscore's _.sample method  underscore collections functions should take objects  @types/underscore error ts2322 for `_.chain` after upgrade to v1.9 ", "title": "collection and array tests - where, findwhere, shuffle, and sample"}
{"description": " closes #26068 tests added / passed ensure all linting tests pass, see here for how to run them whatsnew entry ", "commit_messages": " enh : adding support to parse unsigned long long from json (#26068)  tst: refactored tests where necessary and added new testing conditions (#26068) ", "linked_issue_titles": " read_json: valueerror: value is too big ", "title": "enabling parsing ulonglong from json"}
{"description": " related issue = #2590, #2637 one of the remaining issues in #2637 is that grouped loop indices of struct fors are exposed to users as ti.vector however they are (naturally) implemented as individual variables, therefore dynamic indexing cannot work here. my solution is different from the idea in #2637: instead of making members of ti.vector loopable, i prefer to keep the individual variables and assign them to a ti.vector so that the user api is not affected and we don't have to re-design the looping mechanism. furthermore, after we implement complete optimization passes of tensor types in the future, the ti.vector allocation and assignments here can be eliminated, which leads to the same performance as before. ", "commit_messages": " remove disable_local_tensor when building struct for loop indices  fix type assertion error in offsets ", "linked_issue_titles": "", "title": "make dynamic indexing compatible with grouped loop indices of struct fors"}
{"description": " some options need backend to support specific extension, like: default_fp=ti.f64 and ti.extension.data64 dynamic_index=true and ti.extension.dynamic_index currently, the former one is implemented outside @ti.test() and the latter one is implemented inside @ti.test(). we may want to figure out a more elegant way to deal with such cases. we don't want to sneakily change the user's init configurations. how should we respond with dynamic_index=true, when the target backend doesn't support dynamic_index? clean up tests without no ti.init(). figure out how to print to the terminal while running pytest. ", "commit_messages": " wip  clean up fixcrossoffloadreferences  fix tests  avoid storing globalptrstmt more strictly  add test for local tensor  auto format  fix matrix  fix test, only throw exception when can't deduce type ", "linked_issue_titles": "", "title": "unify tests decorators with @ti.test()"}
{"description": " fixes rdar://72999296. cherry-picked from #35488. ", "commit_messages": " [nfc] add crash test case for _atomic(_bool) irgen.  (cherry picked from commit 56f9c89c7e66ea3546f1f7f4204de230739b8bc5)  [irgen] add hack to handle _atomic(_bool) correctly.  (cherry picked from commit a6d0cca20149069f2db793e5ce2c191ebf2aae15) ", "linked_issue_titles": "", "title": "fix crash when trying to compile _atomic(_bool)"}
{"description": " fix the not-working toolbar. now it's working again. some workaround to reduce the chance assert failed.  this pr does not fix this bug. i know what's causing it and fixing it completely requires a lot of time (which i don't have now). i will probably refactor all code about downloading later (which will fix this bug) as it's annoying and influencing user experience, i check the window's existence each time before operating on the window to reduce the chance assert failed. ", "commit_messages": " [rapps] fix the bug that toolbar is not working  [rapps] some renaming  [rapps] reduce the chance assert failed ", "linked_issue_titles": "", "title": "small bugfix and some workaround"}
{"description": " rdar://44109268 ", "commit_messages": " [libsyntax] fix places in which rawsyntax nodes were created without an arena  [libsyntax] make rawsyntax nodes hold a strong reference to their arena  this allows an elegant design in which we can still allocate rawsyntax  nodes using a bump allocator but are able to automatically free that  buffer once the last rawsyntax node within that buffer is freed.  this also resolves a memory leak of rawsyntax nodes that was caused by  parserunit not freeing its underlying astcontext. ", "linked_issue_titles": "", "title": "cherry pick @ahoppen's syntax arena changes to swift-5.0-branch."}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should be present and it shouldn't have any additional or disabling of rules. just content as { \"extends\": \"dtslint/dt.json\" }. if for reason the some rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename]  and not for whole package so that the need for disabling can be reviewed. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " fix: added 'deep' to mergedeepright's type  fix: merge types  fix: missing semicolon  fix: bad test ", "linked_issue_titles": "", "title": "accurate types for mergeall & a fix"}
{"description": " for details see commits. rdar://problem/39978743 ", "commit_messages": " stdlib: remove some @inlineables from string api functions.  beside the general goal to remove inlinable functions, this reduces code size and also improves performance for several benchmarks.  the performance problem was that by inlining top-level string api functions into client code (like string.count) it ended up calling non-inlinable internal string functions eventually.  this is much slower than to make a single call at the top-level api boundary into the library. inside the library all the internal string functions can be specialized and inlined.  rdar://problem/39921548  stdlib: fix performance regression for long string appends.  re-wrote the inner memcpy loops so that they can be vectorized.  also added a few inline(__always).  since we removed some @inlineable attributes this string-append code is not code generated in the client anymore.  the code generation in the stdlib binary is different because all the precondition checks are not folded away.  using explicit loop control statements instead of for-in-range removes the precondition-overhead for those time critical memcpy loops.  stdlib: speed up utf8view -> array conversion by using _copycontents ", "linked_issue_titles": "", "title": "fixes for string performance regressions"}
{"description": " i have added a backspace and delete with mod macro as well as change the bottom row to make the layout more familiar and usable by all ", "commit_messages": " add initial ep40 files  fixed issues  updated keymap  added media control  update keyboards/handwired/ep40/rules.mk  fixed requested changes  fixed more requested changes  added delete key to layor 1  updated defualt keympap to have a backspace mod del key ", "linked_issue_titles": "", "title": "fixed poor layout of ep40 default keymap"}
{"description": " address some of #15880 add from_estimator and from_predictions method and deprecate the plot_roc_curve. todo: add new class methods deprecate plot_roc_curve add check for raising deprecation warnings catch deprecation warning in test add common test for the curve add tests for the display update the examples update the user guide ", "commit_messages": " iiter  iter ", "linked_issue_titles": "", "title": "api add from_estimator and from_predictions to roccurvedisplay"}
{"description": " fixes #19238 relates #16561 cvmat with different dimensions were copied to outputarray _circles. hough_gradient : mat(1, numcircles, cv::traits::type<circletype>::value, &circles[0]).copyto(_circles); vs hough_gradient_alt : std::vector<vec3f> cwow(ncircles); mat(cwow).copyto(_circles); this has been fixed and a test has been added. to the best of my knowledge, the proposed patch is not based on a code under gpl or other license that is incompatible with opencv the pr is proposed to proper branch there is reference to original bug report and related work ", "commit_messages": " fix outputarray _circles dimensions  add houghcircles_alt test ", "linked_issue_titles": " different shape of result of the method hough_gradient_alt in python ", "title": "fix hough circles alt dimensions"}
{"description": " see title ", "commit_messages": " [win32] directx: fix switching display mode in true fullscreen in case when os silently bring app out of full screen  [win32] windowing: resize dx buffers after resolution change to avoid black screen after fall creators update. ", "linked_issue_titles": "", "title": "fixes for display mode switching issues"}
{"description": " as per @samuelgruetter's comments in #55, i added some tests against interval together with multiple subscribers, and then proceeded to fix the behavior by wrapping it in another subscription function. i hope it's ok now. ", "commit_messages": " added test with multiple subscribers  added missing mock  added another test against multiple staggered subscribers  wrapped subscription so that interval works for multiple subscribers and added a test for staggered subscriptions with publish/connect, too ", "linked_issue_titles": "", "title": "make interval work with multiple subscribers"}
{"description": " i just built my jj40 today and decided to port over some of the rgb underglow code i used on the mechmini qmk subdirectory (which is also a ps2avrgb board). the code turned out to move over pretty easily: it's a matter of defining a custom rgblight_set() function in jj40.c, and changing a few things in config.h and rules.mk to enable rgb underglow as i did with the mechmini. all that is different is the number of rgb leds - 5 for the jj40 versus 16 on the mechmini. perhaps this implementation could be used with other ps2avrgb boards? i also cleaned up the redundant/extraneous rgb backlighting code on the mechmini subdirectory (as setting rgb underglow modes/colours is already handled by qmk's built-in rgb support), and reset the keyboard's advertised power draw to 500 ma in usbconfig.h, as i am not sure that the keyboard only draws 100 ma with the underglow set on full. on this - i do now have a usb power draw meter, but i feel like setting the value back to the default is better, with the option for users to modify the value in usbconfig.h as needed instead. ", "commit_messages": " cleanup mechmini keymap. once the custom rgb function is defined, there is no need to manually handle rgb code.  change default to keymap_mit, not keymap_offset  add custom rgb code for jj40  reset mechmini advertised power draw to 500. will have to test actual maximum power draw later.  rgb working on jj40.  fix: saturation increase/decrease flipped ", "linked_issue_titles": "", "title": "rgb underglow support for jj40, clean up redundant code in mechmini keymap"}
{"description": " this sequence of relatively small commits dramatically improves the memory management in epiloguearcanalysis and on certain projects reduces compile time spent in the swift optimizer 36%. ", "commit_messages": " move the include guard of analysis.h /above/ the includes.  otherwise, every time we include analysis.h, we will try to include those other  files even if we have already included analysis.h. this can increase compile  time.  rdar://33841629  (cherry picked from commit 6b54531455c7898b54a8d59c5e3b6a1b472a34c1)  [sil-analysis] add functionanalysisbase::{hasanalysis,maybeget}(silfunction *f).  today, if one wants to invalidate state relative to your own function analysis,  you have to use functionanalysisbase::get() to get the analysis. the problem  here is that if the analysis does not exist yet, then you are actually creating  the analysis. this is an issue when one wants to perform an action on an  analysis only if the analysis has already been built. an example of such a  situation is when one is processing a delete notification. if one does not have  an analysis for a function, one should just do nothing.  i am going to use this to fix a delete notification problem in  epiloguearcanalysis.  rdar://33841629  (cherry picked from commit eb4d94f10b6f66388ce9448fc00d49ce9fdc4e7b)  [epilogue-arc] use maybeget instead of get when handling delete notifications.  by using this the maybeget api on functionanalysisbase instead of get, we stop  epiloguearcanalysis from building itself if it does not yet exist, only to  invalidate itself.  rdar://33841629  (cherry picked from commit ae25f444087c3e5d866f57a0611f71b5f2f2fc45)  [sil-analysis] add a new utility class for functionbaseinfo based analyses: lazyfunctioninfo.  commonly when an analysis uses subanalyses, we eagerly create the sub function  info when constructing the main function info. this is not always necessary and  when the subanalyses do work in their constructor, can be actively harmful if  the parent analysis is never invoked.  this utility class solves this problem by being a very easy way to perform a  delayed call to the sub-analysis to get the sub-functioninfo combined with a  cache so that after the lazyfunctioninfo is used once, we do not reuse the  densemap in the sub-analysis unnecessarily.  an example of where this can happen is in epiloguearcanalysis in combination  with postorderfunctioninfo. postorderfunctioninfo eagerly creates a new post  order. so, if we were to eagerly create the postorderfunctioninfo (the  sub-functioninfo) when we created an epiloguearcfunctioninfo, we would be  creating a post order even if we never actually invoke epiloguearcfunctioninfo.  (cherry picked from commit b70c8b64a10a51bfe9a5acdc8c3461715e133805)  [epilogue-arc-analysis] be more efficient with memory usage.  this patch fixes a number of issues:  the analysis was using epiloguearccontext as a temporary when computing. this is  an performance problem since epiloguearccontext contains all of the memory used  in the analysis. so essentially, we were mallocing tons of memory every time we  missed the analyses cache. this patch changes the pass to instead have 1  epiloguearccontext whose internal state is cleared in between invocations. since  the data structures (see below) used after this patch do not shrink memory after  being cleared, this should cause us to have far less memory churn.  the analysis was managing its block state data structure by allocating the  individual block state structs using a bumpptrallocator/densemap stored in  epiloguearccontext. the individual state structures were allocated from the  bumpptrallocator and the densemap then mapped a specific silbasicblock to its  state data structure. ignoring that we were mallocing this memory every time we  computed rather than reusing global state, this pessimizes performance on small  functions significantly. this is because the bumpptrallocator by default heap  allocates initially a page and densemap initially mallocs a 64 entry hash  table. thus for a 1 block function, we would be allocating a large amount of  memory that is just unneeded.  instead this patch changes the analysis to use a std::vector in combination with  postorderfunctioninfo to manage the per block state. the way this works is that  postorderfunctioninfo already contains a map from a silbasicblock to its post  order number. so, when we are allocating memory for each block, we visit the cfg  in post order. thus we know that each block's state will be stored in the vector  at vector[post order number].  this has a number of nice effects:  1. by eliminating the need for the densemap, in large test cases, we are  signficiantly reducing the memory overhead (by 24 bytes per basic block assuming  8 byte ptrs).  2. we will use far less memory when applying this analysis to small functions.  rdar://33841629  (cherry picked from commit b1debfc401bd80cfe519761155d6219a23dd83ff) ", "linked_issue_titles": "", "title": "fix memory management issues in epiloguearcanalysis"}
{"description": " i'm headed out of town, so i figured i'd go ahead and get some eyes on this and let some people start playing with it. this is the start of cleanly handling intents on android, so we can avoid a huge mess of jni as we start to do more. here, we add a new bridge that lets us call native from java, which is much cleaner for more android-y interfaces like listeners and broadcasters. next step is to add functionality for waiting on messages, callbacks, etc, and to remove our jni code for sending intents in favor of adding it here. ", "commit_messages": " intents: add a java class for listening to intent broadcasts  intents: hook up a jni_onload for finding our java functions  this should be extended to do lots more, so that we can quickly add java code  and access it from native, without the mess that is jni. ", "linked_issue_titles": "", "title": "beginning of android intents handling"}
{"description": " the parser and ner components use transition-based models, that build a state representation by combining the vectors from some tokens in the context. the previous ner feature set was: current word next word previous word first word of the current entity word before first word of the current entity word after first word of the current entity this pr adds a feature set that seems to perform a bit better, while using fewer tokens: current word first word of current entity, if it exists last word of current entity, if it exists this is less redundant, and runs faster. it also prepares us better for the wider token vectors we'll be expecting from transformer models. you can change the feature set by passing nr_token_features to the begin_training method. care should be taken with this, as not all numbers are valid --- they're basically shorthand for particular feature sets. there's also currently no error handling for invalid values, so this is basically internals until we have a better config system in place. nlp.begin_training(component_cfg={\"ner\": {\"nr_feature_tokens\": 3}}) i have submitted the spacy contributor agreement. ", "commit_messages": " support option of three ner features  expose nr_feature parser model setting  give feature tokens better name  test nr_feature=3 for ner  format ", "linked_issue_titles": "", "title": "add option for improved ner feature extraction"}
{"description": " category enhancement (new features, refinement) added support to connect to dremio. tested it on the master. test plan requires db migration. confirm db migration upgrade and downgrade tested. reviewers ", "commit_messages": " added spec for dremio  installation instructions for dremio ", "linked_issue_titles": "", "title": "add support for dremio as a new source"}
{"description": " homing phase. makes homing super repeatable by retracting from endstop hit back to a very specific stepper coil phase. tmc only. delta only. the implementation changes delta homing so when the endstop is hits, the tmc phase is queried and the distance to the next target phase away from endstop is computed and added to endstop trim. notes: trinamic drivers use a stepper phase table with 1024 values which spans 4 full steps with 256 positions each therefore 1024 positions. the full steps (positions 128, 384, 640, 896) have the highest holding torque. the endstop needs to be repeatable to at least half a step. improve homing repeatability. home is now a position with the highest hold torque. #16383 ", "commit_messages": " tmc home to position  stepper home position  fit and finish  phase per axis, warning.  extra space ", "linked_issue_titles": "", "title": "homing phase for tmc drivers"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #42860 (review) include tests for your changes ", "commit_messages": " fix(markdown-it): fix helper parselinklabel argument state type  test(markdown-it): change test due to helper parselinklabel update  chore(markdown-it): correct url for contributors ", "linked_issue_titles": "", "title": "markdown-it helper parselinklabel argument state type"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. changelog updated type definitions for parse 2.10 typescript version 3.3 now using conditional types from ts 2.8 more complex generic inferences from ts 3.3 made parse.object a generic in order to type its attributes in order to handle parse.object's complex construct signature, class object was switched to const object: objectconstructor. this is modeled based on the native const array: arrayconstructor type pattern. the default attributes type is intentionally broad to minimize breaking changes: { [key: string]: any }. users are able to \"opt in\" to stricter typing by passing a type parameter to parse.object all classes that extend parse.object are also generic. added many more tests, and made use of // $expecttype and // $expecterror comments for stricter assertions fixed removed all but two tslint rule exceptions ban-types: false is still necessary because parse has its own object interface that tslint thinks is a banned type no-unnecessary-generics is still necessary because we allow users to type various return types via a type parameter parse/node and parse/react-native module declarations are now in their own files, per tslint preference various other lint fixes: semi-colons, combined overloads, whitespace, comment formatting errorcode was a global type, but is not actually a global in the parse library. it is no longer global. the baseobject interface and class were removed the parse library did not export any such class it was only being used as a convenience to add tojson(): any as a method on other interfaces, but in reality those various tojson methods will not have the same return type. each interface now has its own tojson method, so that in the future it will be easier to provide better typings for them individually. classes that extended parse.object had constructors that were typed incorrectly. parse.user, parse.session, parse.installation, and parse.role now have construct signatures that match the documentation. parse.config does not actually extend parse.object - it is no longer typed as such. some types were removed that are not documented or found in parse's source code parse.version parse.object.cid and parse.object.changed ", "commit_messages": " parse: fix tslint issues  parse: update ts test cases  parse: stricter types for parse.object attributes  better constructor handling for parse.object  use keyof t for more attribute parameters and add tests  parse: improve parse.object method types and add more tests  remove parse.version type as it does not exist in documentation  add references for other declaration files to index.d.ts  parse: fix constructor types for classes that extend parse.object  parse: fix parse.object child classes  return parse functions to old location for more readable diff ", "linked_issue_titles": "", "title": "stricter parse.object attributes type, improve linting, and add tests"}
{"description": " we do two things here: validate that arbitrary properties result in actual parsable css declarations ignore malformed css properties (for example beginning with a number) this prevents generation of classes for things like [0:02] or [autoplay:${autoplay}] which result in invalid css. this does not fix all cases but should help significantly. fixes #6395 ", "commit_messages": " move arbitrary value check  validate that css values are actually parsable ", "linked_issue_titles": " abnormal css ouput when some string in the code is wrapped in square brackets ", "title": "don't output unparsable values"}
{"description": " policy.compute_single_actions is broken for nested (e.g. tuple) actions due to the simplified assumption that the returned action is a simple batch (list). this pr adds an unpatch step and only then returns. issue #8411. closes #8411. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  wip and lint. ", "linked_issue_titles": " [rllib] apparently broken compute_actio function for multiagent environments ", "title": "policy.compute_single_action() broken for nested actions (issue 8411)."}
{"description": " calls to hlfmt_hash () should check if the resulting hash_buf is not null and the length (hash_len) is at least 1. i discovered that sometimes it happens that the format was e.g. detected as shadow, but parsing it failed, therefore the len was 0 and the buf was null. oclhashcat didn't check for such situations and sometimes it resulted in a segfault/crash. thank you very much ", "commit_messages": " added check for hash_len after calls to hlfmt_hash ()  also add check for null pointers ", "linked_issue_titles": "", "title": "added check for hash_len/hash_buf after calls to hlfmt_hash ()"}
{"description": " disallow updating zstd_c_literalcompressionmode during compression, since the optimal parsers statistics would be messed up. tell the optimal parser that literals are 1 byte each when using zstd_lcm_uncompressed, and avoid updating the literal frequencies. add a flag on the cli to control literals compression --[no-]compress-literals. update the regression tests to test level 19 with uncompressed literals. 3d7377b shows the difference after fixing the pricing (-2% on silesia, -5% on github). fix a bug in the compress cctx method that was causing decompression failures. respect --[no-]compress-literals in benchmark mode add cli tests to playtests.sh so they get executed with different configurations. ", "commit_messages": " [regression] test level 19 with uncompressed literals  [libzstd] handle uncompressed literals  fix a bug in the compress cctx method  [zstdcli] add a flag to control literals compression ", "linked_issue_titles": "", "title": "fix optimal parser prices with uncompressed literals"}
{"description": " category choose one bug fix enhancement (new features, refinement) refactor add tests build / development environment documentation wip - this is the first of several prs which addresses sip-24 requires db migration. confirm db migration upgrade and downgrade tested. reviewers ", "commit_messages": " first cut at app factory  setting things back to master  working with new flask_app  # conflicts:  #\tsuperset/__init__.py  still need to refactor celery ", "linked_issue_titles": "", "title": "flask app factory pr #1"}
{"description": " format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " distro check datastorage status before send verify data.  add source server address info for distro verify.  refactor distro verify task.  refactor distro client verify task ", "linked_issue_titles": "", "title": "refactor and enhance for client distro protocol"}
{"description": " for #3691. ", "commit_messages": " add single data source api for shardingdatasourcefactory  fix example  add single data source api for yamlshardingdatasourcefactory  fix example  refactor abstractencryptjdbcdatabaseandtabletest  remove yamlencryptdatasourcefactory  refactor shadowdatasourcefactory  refactor spring boot starter for encrypt ", "linked_issue_titles": "", "title": "redesign spring boot starter api for encrypt"}
{"description": " in order to better maintain the ansible files, i propose to identify these files. please give me a hand for this,if it is ok. thanks. best regard. .github/botmeta.yml ", "commit_messages": " update botmeta.yml  update for cloudengine. ", "linked_issue_titles": "", "title": "update to label cloudengine files."}
{"description": " a function declaration like: func dog cow() {} ... yields a bunch of noisy diagnostics about expecting certain tokens, like \"expected '(' in argument list of function declaration\", or the dreaded \"consecutive statements on a line must be separated by ';'\". instead, look for a repeated identifier in this position and affirm that the repeated identifier wasn't expected, suggesting that maybe this was a single identifier with a break in it. rdar://problem/25761940 ", "commit_messages": " qoi: provide a fix-it for repeated identifiers in function declarations  a function declaration like:  func dog cow() {}  ... yields a bunch of noisy diagnostics about expecting certain tokens, like  \"expected '(' in argument list of function declaration\", or the dreaded  \"consecutive statements on a line must be separated by ';'\". instead,  look for a repeated identifier in this position and affirm that the  repeated identifier wasn't expected, suggesting that maybe this was a  single identifier with a break in it.  rdar://problem/25761940  direct and camel-cased concatenation fixits for repeated identifiers in function declarations  additional qoi to also provide a fix-it to concatenate in camel-case.  rdar://problem/25761940 ", "linked_issue_titles": "", "title": "better diags for repeated identifier in function declarations"}
{"description": " original pull-request #18130 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix remove ttl for column  fix test  fix remove ttl for column ", "linked_issue_titles": "", "title": "cherry pick #18130 to 20.11: fix remove ttl for column"}
{"description": " the commit message contains more information about the individual changes. ", "commit_messages": " optimize textlayerrendertask._layouttext to avoid intermediate string creation  this method creates quite a few intermediate strings on each call and  it's called often, even for smaller documents like the tracemonkey  document. scrolling from top to bottom in that document resulted in  12936 strings being created in this method. with this commit applied,  this is reduced to 3610 strings.  optimize canvasgraphics.setfont to avoid intermediate string creation  this method creates quite a few intermediate strings on each call and  it's called often, even for smaller documents like the tracemonkey  document. scrolling from top to bottom in that document resulted in  14126 strings being created in this method. with this commit applied,  this is reduced to 2018 strings. ", "linked_issue_titles": "", "title": "optimizations to avoid intermediate string creation"}
{"description": " nothing substantial, just clarified how the algorithm works and what is expected (i.e. the bandwidth parameter). ", "commit_messages": " update to mean shit clustering narrative documentation.  update to docstring of meanshift  docstring of module ", "linked_issue_titles": "", "title": "update to mean shift clustering documentation"}
{"description": " this pull has several fixes for issues raised in #154: enhance @selectkey to support multiple key columns (like the existing support with jdbc generated keys) enhance  to support multiple key columns allow select key and generated keys in update statements two tests are marked as ignored because hsql is not returning generated columns after an update statement. ", "commit_messages": " support multiple key properties in @selectkey  add support for selectkey and generated keys in update statements  add xml mapper for selectkey update tests ", "linked_issue_titles": "", "title": "changes for #154 - enhanced support for optimistic locking"}
{"description": " description: added support for humidity and pressure in 1-wire devices. also added support for a couple of new (old) devices. this update changes the names of the sensors from \"<sensor_name>\" to \"<sensor_name> <sensor_type>\" example: kitchen -> kitchen temperature. in the database this looks like: sensor.kitchen -> sensor.kitchen_temperature. this was a necessary change as devices with multiple sensors would be given additional _n suffixes in the database that would be not be persistent per sensor across restarts of ha. if you wish to maintain a single line of record in the database this can be achieved by the following recipe. connect to your database using the instructions from  check the names of sensors: select entity_id, count(*) as count from states group by entity_id order by count desc limit 10; alter the names of sensors using the following examples: update states set entity_id='sensor.<sensor_name>_temperature' where entity_id like 'sensor.<sensor_name>%' and attributes like '%\\u00b0c%'; update states set entity_id='sensor.<sensor_name>_pressure' where entity_id like 'sensor.<sensor_name>%' and attributes like '%mb%'; update states set entity_id='sensor.<sensor_name>_humidity' where entity_id like 'sensor.<sensor_name>%' and attributes like '%%%' escape ''; remember to replace <sensor_name> with the actual name of the sensor as seen in the select query. checklist: local tests with tox run successfully. your pr cannot be merged unless tests pass new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. ", "commit_messages": " added more devices and sensor types.  flake8 fixes ", "linked_issue_titles": "", "title": "added more devices and types to onewire"}
{"description": " fixes a bug related to how \"closed replicated indices\" (introduced in 7.2) interact with the index metadata storage mechanism, which has special handling for closed indices (but incorrectly handles replicated closed indices). on non-master-eligible data nodes, it's possible for the node's manifest file (which tracks the relevant metadata state that the node should persist) to become out of sync with what's actually stored on disk, leading to an inconsistency that is then detected at startup, refusing for the node to start up. the solution used here is to remove the code that treats closed indices specially. this code has not aged well, and its use is dubious as best. closes #47276 ", "commit_messages": " omit writing index metadata for closed indices on data-only node  simplify test ", "linked_issue_titles": " elasticsearch fails to start with error: \"failed to find metadata for index\" on every restart ", "title": "omit writing index metadata for non-replicated closed indices on data-only node"}
{"description": " after the discussion earlier - i put together a bit of what i was thinking the model structure would look like - it eliminates the dataprovider layer and just defines static functions on the models themselves, which i think will make things a bit cleaner as we build out the model layer, and make things a bit easier to picture see what goes where and how things relate. it uses all of the stuff that @jgable put in there already, but puts them onto a base model, which the other inherit from. it also creates a specific namespaced \"ghost\" instance of bookshelf/knex, in case others are using a copy of bookshelf/knex already in their application, which should be accessed from data/models/base.js whenever you need to grab bookshelf/knex. ", "commit_messages": " a bit of organizing/simplifying/fattening the models  merging master ", "linked_issue_titles": "", "title": "shifting around the model structure a bit"}
{"description": " add layout_60_ansi to xd60 rename layout_all to layout_all fix bug in krusli's keymap put 60_ansi in rules.mk so i can generate my default keymap for it. ", "commit_messages": " add new layout and fix formatting  add 60_ansi layout so i can use my user space defined layouts  make qmk_keyboard_h and layout renames  update info.json file ", "linked_issue_titles": "", "title": "add standard layout to xd60"}
{"description": " updating the raygun4js ts definition to 2.4.2. prefer to make your pr against the types-2.0 branch. follow the advice from the readme. avoid common mistakes. run npm run lint -- package-name if a tslint.json is present. provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. ", "commit_messages": " updated raygun4js definition to match version 2.4.2  tests updated  raygun function interface created for the v2 api  added window definition. v2 user details interface added. refactored v2 declaration.  v2 api tests added  documentation added to options. ", "linked_issue_titles": "", "title": "update raygun4js definition to version 2.4.2"}
{"description": " adds a conditional protocol extension that defines mutablecollection.mutablecollection.subscript(bounds: range<_>) -> slice<self> only when subsequence == slice<self>. attempts to mark the unconditional extension method mutablecollection.subscript(bounds: range<_>) -> slice<self> as unavailable mutablecollections where subsequence == slice<self> still get the expected default implementation. adds a default implementation of mutablecollection.subscript(bounds: range<_>) -> subsequence, marked unavailable, in order to prevent invalid conformances from compiling when subsequence is not slice<self>. resolves sr-14850 / rdar://79898408 (and completes the fix to sr-14848). ", "commit_messages": " [test] add a definition that shouldn't compile  [stdlib] mutablecollection fix to _smallstring ", "linked_issue_titles": "", "title": "prevent mutablecollections from inappropriately inheriting a slice<self> subscript"}
{"description": " description: twilio changed the class that needs to be used from twiliorestclient to client. source. this broke after the twilio client was upgraded in #17424 and an api change was missed. related issue (if applicable): fixes #17871 this one is affecting 0.81.x and should be shipped in the next bugfix release. however, i'm not sure how to do that since the component itself was rewritten in #17715 (so the files are not in the same place in dev and master). this pull request is targeted at master in case that helps for the hotfix and #17883 is targeted at dev which should fix it for 0.82.0 checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " 0.81  switch to using client from twilio.rest rather than the deleted twiliorestclient ", "linked_issue_titles": "", "title": "switch to using client from twilio.rest rather than the deleted twilliorestclient"}
{"description": " @piiswrong  hi, pls review the changes. the purpose is to remove the annoying full mkl dependency when set blas=mkl. ", "commit_messages": " rebase to latest one  rebase latest  merge the latest  git pull ", "linked_issue_titles": "", "title": "remove full mkl package dependency for blas=mkl"}
{"description": " please answer these questions before submitting pull request why submit this pull request? bug fix new feature provided improve performance related issues #3583 make create a project of plugin testcase easier. i will provide a script to use it later. and any suggestions and discussions are welcome. ", "commit_messages": " provide archetypes for testcase  provide archetypes for testcase ", "linked_issue_titles": "", "title": "provide archetypes for plugin testcase"}
{"description": " update the backend to add an array of project level threshold and metric to the user misery. apdex to follow. ", "commit_messages": " check in progress  check in progress  check in progress  add fcp support  add multiply and tests ", "linked_issue_titles": "", "title": "add a snuba user misery query that takes project-level thresholds"}
{"description": " these are related typing fixes for #20322, separated to be more easily reviewed and hopefully merged quickly. ", "commit_messages": " fix typing errors in external task sensors  fix types in python operator and sensors  fix typing errors in airflow.operators.datetime  properly type airflow/utils/operator_helpers  fix typing in airflow.utils.weekday  relax jinja rendering function typing  we don't really need to restrict the context to be an airflow context;  any (mutable) mapping would do. ", "linked_issue_titles": "", "title": "typing fixes needed to deprecation warning fixes"}
{"description": " softmax test failed because recently some tests uses 3d tensors as input. before, mkl softmax only supported 2d tensors. now, in this pr, we are supporting 1d, 2d, 3d, 4d and 5d tensors as input to softmax. thus, this pr fixes the ci regression. ", "commit_messages": " adding support of input dimension of 1 to 5 in mkl dnn softmax  fixed clang formatting  cleaing up comments ", "linked_issue_titles": "", "title": "softmax dim fix: supporting 1d to 5d tensors, address the regression of ci"}
{"description": " resolves #18752 catches warnings before the pytest.warns can catch them for voting* filter out non convergence warnings for the rest. ", "commit_messages": " tst fixes warnings for scipy 1.3.0  rev places back record check ", "linked_issue_titles": " failing tests due to scipy.optimize deprecationwarnings ", "title": "mnt catches scipy 1.3.0 for using deprecated tostring method"}
{"description": " closes #31575 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " tst: add test case (#31575)  bug: fix reac_csv with rawiobase broken (#31575) ", "linked_issue_titles": " pandas 1.0.0  read_csv() is broken use `open( buffering=0)` option. ", "title": "read_csv used in file like object rawiobase is not recognize encoding option"}
{"description": " addresses @zhengbli's concern in #4978 (comment). this pr enables us to grab parameters from a \"simple\"/\"canonical\" callable/constructable expression in a variable statement with a single declaration. we only do this for a function expression, arrow function, or class expression with a constructor, or any of the aforementioned in nested parentheses. in the presence of a class expression, if there are multiple constructor declarations, the parameters are acquired from the first one. ", "commit_messages": " modified/added tests.  try to grab parameters for single-declaration variable statements.  we only do this for a (parenthesized) function expression, arrow function,  or class expression with a constructor.  in the presence of a class expression, if there are multiple constructor  declarations, the parameters are acquired from the first one. ", "linked_issue_titles": "", "title": "grab '@param' tags from initializers"}
{"description": " this will allow us to run the conpty tests in ci. closes msft:24265197, closes #3851 i've run the tests. please note: this code is unchanged (apart from wil::scopeexit -> wil::scope_exit) from windows. now is not the time to comment on their perfectness. ", "commit_messages": " conpty: add feature tests from windows  and make them build ", "linked_issue_titles": " pull winconpty api tests out into this project and ci inner-loop ", "title": "migrate the conpty functional tests out of windows"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  include tests for your changes this pr continues the planned set that will together add up to #45201 and includes the following changes: adds tests for sortby, indexby, countby, and invoke. updates sortby, indexby, countby, and invoke to use collection and iteratee to partially fix #20623. updates invoke return types from any and t to any[]. updates the return type of _chain.sortby, _chain.indexby, _chain.countby, and _chain.invoke to use the correct wrapped value type v to partially fix #36308. updates the collection type result for _chain.countby to be number instead of t. updates overloads of groupby to be more consistent with these overloads by making tweaks to summary comments, making iteratee optional, and adding tests for all iteratee types. updates test group comments for max and min to say \"iteratee\" instead of \"iterator\" because i messed that up in my last pr. this is the last pr in the collections family. ", "commit_messages": " updating type definitions for sortby, indexby, and countby and adding tests.  switching \"iterator\" to \"iteratee\" for a few test groups.  making a few adjustments to groupby to better match similar functions. ", "linked_issue_titles": " underscore collections functions should take objects  @types/underscore error ts2322 for `_.chain` after upgrade to v1.9 ", "title": "collection and array tests - sortby, indexby, countby, and invoke"}
{"description": " this started out as just a \"remove s65-plus support from s65-x folder,\" but as i went it kind of snowballed. commit log s65-x: remove s65-plus support (293f9df) the original qmk codebase for the sentraq s65-x actually supported both the s65-x and the s65-plus. in the interim, the s65-plus has been broken off into its own directory. this commit removes support for the s65-plus from the keyboards/s65_x/ directory, as that code has been superseded by the code in the s65-plus directory (keyboards/s65_plus/). deleted s65-plus layout macros from s65_x.h and info.json deleted s65plus keymap directory removed references to the unused column pins removed the two unused columns for the switch matrices renamed switch k300 in layout_ansi to k301 (reflects matrix position) renamed switch k214 in layout_iso to k114 (reflects matrix position) s65-x: keymap refactor (060a7ff) all keymaps now use #include qmk_keyboard_h default and iso keymaps refactored for readability deleted redundant kc_trns and kc_no keycode definitions from smt keymap s65-x: readme update (39dbab0) updated hardware availability link updated docs links s65-plus: add layout_iso data (89226b4) adds layout_iso macro to s65_plus.h and info.json, and an iso layout version of the default keymap. s65-plus: refactor default keymap (43fcfa9) refactor for alignment/readability removed fn_actions code block add empty process_record_user block s65-plus: readme update (911936f) hardware availability link is now a hyperlink updated docs links s65-x: enable 65_ansi and 65_iso community layouts (5f2a3c2) thi commit allows the sentraq s65-x to use the 65_ansi and 65_iso community layouts. layout_ansi renamed to layout_65_ansi layout_iso renamed to layout_65_iso added layouts rule to rules.mk ", "commit_messages": " s65-x: remove s65-plus support  the original qmk codebase for the sentraq s65-x actually supported both the s65-x and the s65-plus. in the interim, the s65-plus has been broken off into its own directory.  this commit removes support for the s65-plus from the keyboards/s65_x/ directory, as that code has been superseded by the code in the s65-plus directory (keyboards/s65_plus/).  - deleted s65-plus layout macros from s65_x.h and info.json  - deleted s65plus keymap directory  - removed references to the unused column pins  - removed the two unused columns for the switch matrices  - renamed switch k300 in layout_ansi to k301 (reflects matrix position)  - renamed switch k214 in layout_iso to k114 (reflects matrix position)  s65-x: keymap refactor  - all keymaps now use #include qmk_keyboard_h  - default and iso keymaps refactored for readability  - deleted redundant kc_trns and kc_no keycode definitions from smt keymap  s65-x: readme update  - updated hardware availability link  - updated docs links  s65-plus: add layout_iso data  adds layout_iso macro to s65_plus.h and info.json, and an iso layout version of the default keymap.  s65-plus: refactor default keymap  - refactor for alignment/readability  - removed fn_actions code block  - add empty process_record_user block  s65-plus: readme update  - hardware availability link is now a hyperlink  - updated docs links  s65-x: enable 65_ansi and 65_iso community layouts  thi commit allows the sentraq s65-x to use the 65_ansi and 65_iso community layouts.  - layout_ansi renamed to layout_65_ansi  - layout_iso renamed to layout_65_iso  - added layouts rule to rules.mk ", "linked_issue_titles": "", "title": "s65-x and s65-plus updates and refactoring"}
{"description": " adapted pinouts and configs from the planck layout for the kbdfans niu mini. i also consulted the auto-generated qmk files from kbfirmware.com (github) from the provided json file by kbdfans. ", "commit_messages": " add niu mini keymap from planck keymap  remove old keymap files ", "linked_issue_titles": "", "title": "add niu mini from kbdfans"}
{"description": " also contains #10418, because in practice we're going to want the same baseline on master and 1.14 to fix the regressions on top of. backports #10430 ", "commit_messages": " maint: remove repeated #ifdefs implementing isinstance(x, basestring) for field names  maint: use valueerror for duplicate field names in lookup  keyerror suggests the field name does not exist, which is inaccurate. ", "linked_issue_titles": "", "title": "use valueerror for duplicate field names in lookup (backport)"}
{"description": " this pr fixes the mouse events (enter, hover exit) so that the event objects contain correct localpositions. related issues fixes #33675 no tests are added. existing tests are added so that they also test local positions. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. ", "commit_messages": " new api  add tests  add tests for mouse region ", "linked_issue_titles": " transform mouse events to the local coordinate system ", "title": "mouse events report correct local positions"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not provide its own types, and you can not add them. create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " created definitions & tests for pick-weight  fix no-single-module  added uniqid definition  m  rge branch 'master' of  merge remote-tracking branch 'source/master'  fix for no documents found - make results optional ", "linked_issue_titles": "", "title": "mongoose-simple-random fix results - make them optional"}
{"description": " see #14913 what is include in the pr: a fix for #14913 download image in found in issue #2447 (comment) resize the image check if all the metadata is there before this fix: after this fix: linked issue: #14913 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " metadata.clone() fails also for situations where we still can recover metadata  metadata.clone() is also an expensive operation (deep copy) and it is not necessary anymore as we build up the metadata object from scratch anyway  if an exception is throw here something is seriously wrong with the metadata structure  we take all metadata we have read so far an write it to the resized image ", "linked_issue_titles": "", "title": "try to recover metadata even when the metadata data structure is invalid (#14913)"}
{"description": " this pr: lets you do python runner.py --help moves some potentially printing code into if __name__ == '__main__' prints help text as soon as possible, so some warnings will come after it lets you run tests from multiple suites on the same command line (e.g. python runner.py other.test_sixtyfour_bit_return_value asm2.test_time) and lists any missing tests - previously it just refused to run anything ensures that if you have 256 test failures it won't come back as 0! ", "commit_messages": " teach test runner about --help  try to execute less if importing the test runner  print help text first for a better chance of seeing warnings ", "linked_issue_titles": "", "title": "allow running tests from different suites"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: <> increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. add constraint for s type parameter. ", "commit_messages": " update redux dependency  update for the current 3.x redux  add required restriction of redux ", "linked_issue_titles": "", "title": "update react-redux-i18n for react-redux 5.0.18 types"}
{"description": " this brings pr #16228 up to date, adds tests and fixes some issues with it. that pr was meant to fix #14567, close #14627 and close #15529 by adding the option to select n features by percentage instead of by absolute number. the changes pr #16228 made to isotronic.py have since been added already and are not included in this pr. here i fix some bugs from pr #16228 and add tests for the new functionality. ping @noatamir ", "commit_messages": " added code from pr #14627  fixed error handling none as n_features_to_select  added test for error message and percentage passing ", "linked_issue_titles": " rfi: setting the number of features to select 'n_features_to_select' to be percentage ", "title": "enable percentage for n_features_to_select in rfe(fix pr #16228)"}
{"description": " new features others added onednn fuse pass for fc + activation. currently gelu, sigmoid and tanh are supported. performance improvement is around 4,5% - benchmarked on bert model using intel(r) d on(r) gold 6348h cpu @ 2.30ghz i1218 22:56:33.140385 102746 helper.h:363] ====== threads: 1, thread id: 0 ====== i1218 22:56:33.140409 102746 helper.h:365] ====== batch size: 1, iterations: 4962, repetitions: 1 ====== i1218 22:56:33.140413 102746 helper.h:367] ====== batch latency: 3.02517ms, number of samples: 4962, sample latency: 3.02517ms, fps: 330.56, data type: float ====== ", "commit_messages": " added base fc+ gelo/tanh activation fuse pass, without tests and formatting  added clang-formatting  minor change  added tests  added formatting ", "linked_issue_titles": "", "title": "added fc + activation fuse pass (currently only gelu, sigmoid and tanh are supported)"}
{"description": " the regex for matching the client list did depend on an ipv4 address, so if a client was connected to the openvpn server via ipv6, it got ignored. so i modified the regex to also match ipv6 addresses; and also ignored clients with the common name undef, which are unauthenticated clients. ( if you get dos-ed, the plugin currently reports hundreds of undef clients, see ", "commit_messages": " openvpn plugin: process also incoming ipv6 connections  openvpn plugin: ignore undef clients ", "linked_issue_titles": "", "title": "fix for ipv6 connections & ignore unauthenticated clients"}
{"description": " this fixes an issue reported on the forums where a removed movie item is not picked up by the update library routine because you can't query a previously removed fileid :) fix for episodes and tvshows has to be done separately as it's a lot more complicated and i don't want to add yet another regression to the upcoming helix betas at this point. bug report @  regression introduced with a32dcc1 and some other refactoring (movie vs movieview) @montellese, @topfs2 for review please. ", "commit_messages": " [videodatabase] path hash is not invalidated when removing movie from library  [videodatabase] path hash is not invalidated when removing musicvideo from library ", "linked_issue_titles": "", "title": "invalidate path hash on remove so the infoscanner can pick it up again"}
{"description": " i fired up windows 8.1 today went through the build instructions. i removed some steps there weren't needed and i also added some requirement verifications to script/bootstrap. closes #2265 / ", "commit_messages": " removed unnecessary instruction.  create separate instruction  i'm not sure if this step is needed, but it existed before. if it is  needed we should include why you have to do this.  ensure that node is 32bit on win32  make sure python2.7 is installed on win32  closes #2193  closes #2167  closes atom/node-runas#5  remove unnecessary instructions  update windows build instructions  require fs in bootstrap ", "linked_issue_titles": " aborted due to warnings - download atom-shell task [error] ", "title": "update windows build instructions and requirements"}
{"description": " there's a lot of work being done on the wp source plugin but a lot of visitors to the site are requesting information on woocommerce specifically. i'm proposing this as a sort of in-between to at least point people in the right direction while that work is being done. this guide presents some options for working with wordpress and woocommerce. i went back and forth about including some more woo-specific instructions (things done in the dashboard). thoughts on whether i should i add that back in? addresses #20222 ", "commit_messages": " add woocommerce guide draft  add wc details ", "linked_issue_titles": "", "title": "reference guide for using woocommerce"}
{"description": " the current bits implementation doesn't cope well when the backing array differs in length. this affects: hashcode/equals: hashcode and equality should only consider set bits. bitwise operations, except andnot(): only performs the operation up to the length of the shortest array. ", "commit_messages": " unit test for bits.  bitwise operations and equals/hashcode work even when word length differs. ", "linked_issue_titles": "", "title": "fixing bits - more considerate about set bits."}
{"description": " ray currently fails to shutdown clusters with over 1000 nodes, because the aws instance termination api only accept a maximum of 1000 instances to terminate in a single request. to fix this, we loop over all the instances we want to terminate, breaking them into chunks of 1000. we previously attempted to implement this in #17642, but that pr was buggy and needed to be reverted. this pr includes a stronger unit test, and fixes typos that were in #17642. i've run scripts/format.sh to lint the changes in this pr. the new unit test makes sure that spot and/or on-demand instances are stopped/terminated with the correct ec2 calls, where each ec2 call stops/terminates a maximum of 1000 nodes. the unit test also makes sure that the aws node provider never attempts to stop a spot instance (because spot instances can only be terminated, not stopped). i have also tested this pr manually by running ray down on clusters with the following configurations (by changing the cluster config yaml): 1 on-demand head node, 2 spot worker nodes, cache_stopped_nodes: true 1 on-demand head node, 2 spot worker nodes, cache_stopped_nodes: false 1 on-demand head node, 2 on-demand worker nodes, cache_stopped_nodes: true 1 on-demand head node, 2 on-demand worker nodes, cache_stopped_nodes: false 1 on-demand head node, 1002 spot worker nodes, cache_stopped_nodes: true i have not yet tested this pr on a cluster with 1000+ nodes except for within the new unit test which mocks all ec2 calls. is there a ray aws account that we could test a 1000+ large cluster on? ", "commit_messages": " revert \"revert \"shutdown clusters when large number of nodes (#17642)\" (#17836)\"  this reverts commit 6957ce66f6eb370d633444b4420c874b2e517505.  update unit test and fix terminate_nodes ", "linked_issue_titles": "", "title": "shutdown clusters on aws with >1000 nodes"}
{"description": " two optimizations: compress foo.bc in each rlib with flate. these are just taking up space and are only used with lto, no need for lto to be speedy. stop install librustc.rlib and friends, this is a huge source of bloat. there's no need for us to install static libraries for these components. cc #12440 ", "commit_messages": " rustc: compress bytecode files in rlibs  these are only ever used with lto, so there's no need for reading them to be  speedy.  mk: don't install host rlibs  you rarely want to statically link against librustc and friends, so there's no  real reason to install the rlib version of these libraries, especially because  the rlibs are massive. ", "linked_issue_titles": "", "title": "reduce the size of a rust install slightly"}
{"description": " original pull-request #32389 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update storagereplicatedmergetree.cpp  follow-up to #32140 ", "linked_issue_titles": "", "title": "cherry pick #32389 to 21.8: follow-up to #32140"}
{"description": " add jumptoitem() to list view. refactor the layout related methods of list view to comply with layout's practice like layout::dolayout(). requestdolayout() and dolayout() are overridden and have to use another dirty flag for list view layout other than layout::_dolayoutdirty because layout::onenter() forces _dolayoutdirty to be true always. but, list view should have a way not to do layout in onenter(). ", "commit_messages": " add 'jumptoitem()' to list view.  refactor list view's layout refreshing logic. ", "linked_issue_titles": "", "title": "add a feature of jumping to a specific item in list tview"}
{"description": " if you look at  also if someone wants to do ioc::resolve('classname', [$dep1]); i have added a patch for this. before it would just auto resolve to a new (instanceof $dep1) instead of assigning $dep1 to the reflector's classname::__construct(classname2 $dep) arguments. wrote unit tests in laravel\\laravel\\cases\\ioc.test.php to look for these types cases if they might arise again ", "commit_messages": " ioc resolves classes with optional params and accepts arguments  adding unit tests for ioc changes ", "linked_issue_titles": "", "title": "ioc container not resolving classes with optional parameters (i.e. models that use eloquent)"}
{"description": " there is an error in document named readme.md,the word 'tables' should be modified to 'table'. ", "commit_messages": " add a new version to it  upgrade the version of it  find an error in line 47,update readme.md  find an error in line 47 of readme.md,the word 'tables' should be changed to 'table' ", "linked_issue_titles": "", "title": "fix an error in line 47,change the word 'tables' to 'table'"}
{"description": " num_restarts must be set before state, or the restarting actor notification might contain a wrong num_restarts. because gcs is updated asynchronously. this will cause a critical problem that i met today: when an actor restarts, since the problem mentioned, restarting notification might contain a lagger num_restarts than expected. for example, when an actor died and restarts for the first time,  all other actors might receive a restarting notification containing num_restarts=1(which is expected to be 0). then, in direct_actor_transport.cc  coreworkerdirectactortasksubmitter::disconnectactor, num_restars in clinetqueue will be set to 1. then alive notification arrives, but in direct_actor_transport.cc  coreworkerdirectactortasksubmitter::connectactor, it will be skipped since 1<=1 if (num_restarts <= queue->second.num_restarts) { // this message is about an old version of the actor and the actor has // already restarted since then. skip the connection. return; } at last, the restarted actor can't be called and won't receive any task, since no rpc_client is available. my fix approach the easiest way i think is to set num_restars before updating the state to restarting. after that restarting notification will always contain num_restarts that are already updated. then in the handler of restarting notification, num_restart should be minus by 1. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " bug fixed for num_restart updating  add log ", "linked_issue_titles": "", "title": "[core]async updating issue fixed for actor's num_restart"}
{"description": " updated versions of the patches that was submitted to the bug tracker. ", "commit_messages": " don't add trailing slash to source with options  sources with |option=value, like http or wedav would get a trailing  slash after the options. for example, davs://example.net/|auth=digest  would become davs://example.net/|auth=digest/ which causes problem later  on.  this solves bug #10871.  respect |option=value with uriutils::getdirectory  keep the |option=value for dav/http paths when getting the directory  part. this is required when playing video from webdav with options like  auth=digest  this solves bug #10862. ", "linked_issue_titles": "", "title": "fixes for webdav with auth=digest option, bug #10862 and #10871"}
{"description": " backport 9ab2b3f and ad03952, allowing libevent 2.0.x to be build on systems with old autoconfs (rhel5, i'm looking at you). ", "commit_messages": " fix missing ac_prog_sed on older autoconfs  for pre-2.59b autoconfs, ac_prog_sed is not available [1]; on such  systems, avoid calling ac_prog_sed, while providing a sensible sed.  this aids backporting to autoconf 2.59.  [1]  backport libevent to vanilla autoconf 2.59 (as used in rhel5)  this is a backport of ad03952. ", "linked_issue_titles": "", "title": "workaround for missing ac_prog_sed, drop to autoconf 2.59"}
{"description": " description: based on #29379 comments it sounds we may want the automation to be reloadable only by the admin users. checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist documentation added/updated in home-assistant.io the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. untested files have been added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " homeassistant/components/automation/__init__.py  register automation.reload as an admin service. ", "linked_issue_titles": "", "title": "register automation.reload service as an admin service."}
{"description": " allows for testing with various versions of python (relatively independently of os version), simplifies and parallelizes testing logic. ", "commit_messages": " base test docker image on python images  fix py3 build  fixes for python-based dockerfile  re-enable py27 build  remove requirements_dev.txt and unittest.cfg (cleaning up build pipeline) ", "linked_issue_titles": "", "title": "test docker images based on python images"}
{"description": " proposed changes upgrade spring cloud consul to the latest version minor fixing include java example and configuration for leadership election with consul pull request checklist please check if your pr fulfills the following requirements: tests build locally code format / lint docs have been reviewed and added other information i followed those guidelines how consul can help in the leadership election using sessions and k/v store ", "commit_messages": " include the following changes:  - upgrade spring cloud consul to latest version  - deploy the spring boot version as web as described in the article  - add leadership-consul dependendencies  add leadership election example and configuration ", "linked_issue_titles": "", "title": "bael-3217 leadership election with consul"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: mrdoob/three.js#15015 (comment) increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update accepted material types to match documentation  fix aframe-io-tests  fix spritecanvasmaterial  fix meshfacematerial  fix spritematerial ", "linked_issue_titles": "", "title": "update object materials to match documentation"}
{"description": " to me it seemed weird that this is a mixin that always returns the line color: #xxx; i modified it to be an actual function and only return a value to be used in any property also updated every use of the 'function' to use the actual function ", "commit_messages": " updating fork of bs to v4-beta1  browsers-devices.md: fix typo. (#23495)  update from official repo  update forked v4-dev  modified the yiq to to an actual function  function only returns a value, not the attribute itself  updated every use of the former mixin to use the new function ", "linked_issue_titles": "", "title": "change yiq mixin to an actual function"}
{"description": " hi, this solve the issue #2491 and i hope future issues of the same type. ", "commit_messages": " trying skip devices instead of return -1  switch to skip instead return -1 for all checks, moved cuda counter update to the end of loop  use skip also with first checks of backend_session_begin() ", "linked_issue_titles": "", "title": "skipping devices instead of stop with error"}
{"description": " taking over #12085. besides fixing the average path length for isolationforest this pr also improves the checks for the predicted number of outliers in the common tests. closes #12085, fixes #11839 only modifications in the tests were required. ", "commit_messages": " fix issue  #11839  fix issue #11839 : sklearn.ensemble.isolationforest._average_path_length returns incorrect values for input < 3.  add non-regression test.  changed existing test to reflect correct values now produced by _average_path_length(), and added checks to ensure non-regression on all \"base case\" values in {0,1,2}.  improve comment & test.  made recommended enhancements to comments, and change assert_almost_equal to assert_equal where constants should be returned.  fix tests in tie cases & match conventions.  change assert_equal to assert ... == to adhere to latest conventions, and change test to properly deal with anomaly score ties in critical regions if 'decision_function' method is supported by the estimator in question, or default to the old behavior if not.  sundry convention tweaks.  add tests of tests.  refactoring and adding more tests to try and get coverage to an acceptable level.  fix test to take lof into account  fix check_outlier_corruption and corresponding tests ", "linked_issue_titles": " sklearn.ensemble.isolationforest._average_path_length returns incorrect values for input < 3. ", "title": "fix iforest average path length"}
{"description": " i used systemd for celery today and found out that the given example did not work so i just fixed that and updated the doc. please note that i also fixed a missing dash (-) in the .service file for the --logfile argument. ", "commit_messages": " fix systemd example file (fixes #2131)  update sample celery files and improve daemonizing with systemd doc ", "linked_issue_titles": "", "title": "update systemd extra files and update doc"}
{"description": " resolves devrel-1530 - private access: create tutorial for security group feature select one: select any that apply: ", "commit_messages": " add first draft of privacy feature tutorial :doc  rename privacy feature tutorial filename :doc  add review edits to privacy feature tutorial :doc ", "linked_issue_titles": "", "title": "add privacy access feature tutorial"}
{"description": " fixes #3830. this adds a setting redis_backend_use_ssl, identical to broker_use_ssl, but used by the backend to determine whether it should use ssl. it also updates the broker_use_ssl documentation which was previously only correct for pyamqp and not redis. ", "commit_messages": " add redis_backend_use_ssl option  correct documentation for broker_use_ssl with redis  the previous documentation was only correct for pyamqp but not redis,  which doesn't allow true and requires a slightly different set of keys  when passing a dictionary.  document redis_backend_use_ssl ", "linked_issue_titles": "", "title": "add ssl option for redis backends"}
{"description": " this pr begins to implement docs recommendations from the plugin authoring workflow evaluation found in #20232 in the effort to improve gatsby workflows from #13708. the changes here make updates to some of the overview pages to link to more recent guides on plugins that have been added as well as adding additional context. i added an example repository for loading local plugins using several different methods as well as a section on verifying that your plugin is loading since those were some things i had questions with when i started loading my own custom local plugins. related to #20232 i also started working on a flowchart/table of plugin vs theme vs starter features in reference to this card on the learning roadmap project: ", "commit_messages": " additional examples to loading/creating, and plugin authoring overview pages  correct minor errors and add tweaks to titles ", "linked_issue_titles": "", "title": "plugin authoring workflow overview pages"}
{"description": " add properties in doc.to_json if they were set, not if they're available. this way, if a processed doc exports \"pos\": none, it means that the tag was explicitly unset. if it exports \"ents\": [], it means that entity annotations are available but that this document doesn't contain any entities. before, this would have been unclear and problematic for training. add doc.is_nered (lol) to indicate if entities have been set. also returns true if not all tokens have entity tags set, e.g. if some tokens have unknown values. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " use default return instead of else  add doc.is_nered to indicate if entities have been set  add properties in doc.to_json if they were set, not if they're available  this way, if a processed doc exports \"pos\": none, it means that the tag was explicitly unset. if it exports \"ents\": [], it means that entity annotations are available but that this document doesn't contain any entities. before, this would have been unclear and problematic for training. ", "linked_issue_titles": "", "title": "improve doc.to_json and add doc.is_nered"}
{"description": " fixed building package on debian jessie lowered initial hashtable size for aggregatefunctiontopk from #778 ", "commit_messages": " build: pass path to debuild  this fixes build on debian  iostream_debug_helpers: fixed build  aggregatefunctiontopk: smaller initial table size  by default start with 2^4 elements ", "linked_issue_titles": "", "title": "fixed build on debian, lower aggregatefunctiontopk initial size"}
{"description": " good morning, i just found this project and it looks awesome. i will probably be joining as a contributor soon, but wanted to start off with something simple that most people don't enjoy taking: grammar fixes! i helped a bit with punctuation and restructured a few sentences without altering meaning, as well as adding uppercase letters in the beginning of a few sentences. i hope you find my changes to your liking. ", "commit_messages": " fix grammar and punctuation a bit  add uppercase where it seemed fit ", "linked_issue_titles": "", "title": "fix grammar and punctuation in readme.md"}
{"description": " cleaned up and adjusted #7601 add a new configuration to inhibit xyz movements if homing hasn't been done. ", "commit_messages": " only marlinconfig.h ahead of feature block  implementing [fr] #7548  added new configuration to inhibit xyz movements when home is not done  updated all examples configurations  forgot to update examples configurations. done now ", "linked_issue_titles": "", "title": "option to disallow motion before homing"}
{"description": " noticed that syntax like vec![0; 5] is never mentioned in vec<t>'s docs, nor used in any of its methods' docs, so i figured i should add a mention of it. also noticed vec!(1, 2) being used in one spot while i was at it, so i fixed that as well for consistency's sake. r? @steveklabnik ", "commit_messages": " mention vec![x; len] syntax in vec docs  make docs for vec::push() use vec! with square brackets ", "linked_issue_titles": "", "title": "mention vec![x; len] syntax in vec<t> docs, fix inconsistent use"}
{"description": " this pr fixes #86288 while commit 520c999 fixed problem with main search field types in \"files to include/exclude\" fields still produced a ton of new history entries. this pr make history entries for these fields created on type delayed in the same way as search field to prevent pollution. alternative implementation can be used if there is need to handle immediate history submit in case when triggeredontype === false, but it looks a bit overkill if only one field can be edited at the time and it will save own history entry on enter. other should be already saved (even by timeout) in general case (i doubt that users will tab to next field and continue typing so \"save\" will be delayed for 2 fields at the same time). ", "commit_messages": " also delay include/exclude pattern fields  force pattern fields history save on enter ", "linked_issue_titles": " search history pollution with search.searchontype enabled ", "title": "debounce on type history entries for \"files to include/exclude\" fields"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. x] run npm run lint package-name (or tsc if no tslint.json is present). the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if a package was never on definitelytyped, you don't need to do anything. (if you wrote a package and provided types, you don't need to register it with us.) add it to notneededpackages.json. ", "commit_messages": " adding class and method descriptions for exchange api  adding class and method descriptions for exchange api - hyperlink fix  adding class and method descriptions for exchange api - note fixing  outlook documentation migration - spacing ", "linked_issue_titles": "", "title": "adding class, method, and parameter descriptions to exchange apis in office.js"}
{"description": " hot fix because in some cases additionalproperties in the available_node_types schema breaks validation. it's unclear why or when, but it seems to be prevalent and not caught by unit tests. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " .  fix  cleanup ", "linked_issue_titles": "", "title": "remove additionalproperties from available_node_types schema"}
{"description": " what this pr does / why we need it: uses git archive to embed version information in the kubernetes source tarball produced in releases. due to recent changes, the version information was missing from the source tarball, causing builds from these source tarballs to potentially fail. this also includes a fix inspired by #56216, since the ld flags in hack/lib/version.sh are not space-safe. which issue(s) this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close the issue(s) when pr gets merged): fixes #56246 release note: /assign @david-mcmahon /priority urgent-soon /sig release ", "commit_messages": " rename tree state from 'git archive' to 'archive'  use git archive to produce kubernetes-src.tar.gz when possible ", "linked_issue_titles": " version information missing from kubernetes-src.tar.gz ", "title": "use git archive to produce kubernetes-src.tar.gz when git tree is clean"}
{"description": " here is the idea: packages should use editor and its methods the main api to manipulate text. this pr removes functionality from editorview that was being used to manipulate text. ", "commit_messages": " remove delegate methods from editorview  fix editorview spec  fix core specs  add commonly used editor methods to editor view  mini-editors use these methods very often, but really we shouldn't need to do  this. ", "linked_issue_titles": "", "title": "remove editor view delegate methods"}
{"description": " cleanup remove unused binddescription struct from youtube-api-wrappers.hpp remove unused members of channeldescription and streamdescription structs as well as related code fixes restore auth.reset() on service switch (fixes #5236) obsolete code makes us unhappy. so do bugs. compiled on windows, verified that #5236 is no longer happening. bug fix (non-breaking change which fixes an issue) code cleanup (non-breaking change which makes code smaller or more readable) my code has been run through clang-format. i have read the contributing document. ", "commit_messages": " ui: remove unused struct  ui: restore auth reset when switching services  fixes #5236  ui: remove obsolete/unused struct members ", "linked_issue_titles": " switching from a streaming service with linked account to service with stream key leaves account linked ", "title": "more youtube cleanup and fixes"}
{"description": " summary allow unrolling rnns with input_length=1. for e.g, this is required to deploy seqseq models on mobile (tflite doesnt support symbolic loop) related issues pr overview ", "commit_messages": " allow len1  add test  pep8 ", "linked_issue_titles": "", "title": "allow unrolled rnns with input_length=1"}
{"description": " two commits: don't allow slow timer callbacks to block script event handling (including quit). timers added from idle observers could fire long after they're due. more details and example at the commit messages. ", "commit_messages": " lua: timers: don't block forever with slow callbacks  previously, process_timers() kept going as long as there were due  timers, which could be for extended periods of time or even forever  if there were slow timer callbacks with either periodic timers or if  timers were added repeatedly.  this prevented dequeuing mpv events, and subsequently, among others,  prevented mpv from quitting until process_timers() completed.  for instance, this caused process_timers() to never return:  function render() <longer than 1/60 s on a slow system> end  mp.add_periodic_timer(1/60, render)  similarly, it never returned if a timer callback always added a new  one-shot which was already due by the time the callback completed.  this commit ensures that process_timers() only executes callbacks which  were due when it started, so that timers which are added (or repeated)  during process_timers() will wait for the next iteration - after mpv  events are dequeued.  this has no performance impact under normal conditions (when callbacks  complete before the next timer is due).  additionally, previously idle-observers were executed unconditionally  after the timers because indeed there was nothing due when (if...)  process_timers() completed. however, now process_timers() can return  even if there are due timers, so skip idle-observers on such case.  lua: idle observers: ensure timers are up-to-date  this fixes two issues, both of which resulted from the timers-wait  period not being re-calculated after idle-observers were executed:  - if timers were added from an idle observer then they could fire long  after they were due (only when/if the next mpv event arrives).  - idle observers don't execute in zero time, and the wait period for  the next timer was implicitly extended by the idle observers  execution time (because it was calculated before the idle observers).  this commit ensures that if idle-observers were executed, then the  timers wait period is re-calculated, which solves both issues. ", "linked_issue_titles": "", "title": "refine timers and idle observers"}
{"description": " this pull request handles part of the problem raised in issue #380. specifically, urls whose scheme is not http or https will throw valueerrors. ", "commit_messages": " added failing test for issue #380.  remove a wayward change.  fail if unsupported schemas are used.  requests only supports http and https. this change enforces that.  correct unfortunate typo. ", "linked_issue_titles": "", "title": "provide useful exceptions for unexpected urls."}
{"description": " this pr adds the rgblight_set_effect_range(start_pos, num_leds) to quantum/rgblight.c. use as in the following example. (i also updated the documentation. docs) #ifdef rgblight_enable // the first three leds are used as indicators for caps_lock, num_lock and scroll_lock. void keyboard_post_init_user(void) { rgblight_set_effect_range(3, rgbled_num-3); led_set_user((1<<usb_led_caps_lock)|(1<<usb_led_num_lock)|(1<<usb_led_scroll_lock)); wait_ms(300); led_set_user(0); } #define hsv_black  0, 0, 0 void led_set_user(uint8_t usb_led) { if (usb_led & (1<<usb_led_caps_lock)) { sethsv_raw(hsv_white, (led_type *)&led[0]); } else { sethsv(hsv_black, (led_type *)&led[0]); } if (usb_led & (1<<usb_led_num_lock)) { sethsv_raw(hsv_green, (led_type *)&led[1]); } else { sethsv(hsv_black, (led_type *)&led[1]); } if (usb_led & (1<<usb_led_scroll_lock)) { sethsv_raw(hsv_yellow, (led_type *)&led[2]); } else { sethsv(hsv_black, (led_type *)&led[2]); } rgblight_set(); } void my_sethsv_range(uint8_t hue, uint8_t sat, uint8_t val, uint8_t start, uint8_t end) { led_type tmp_led; sethsv_raw(hue, sat, val, &tmp_led); for (uint8_t i = start; i < end; i++) { led[i] = tmp_led; } rgblight_set(); } uint32_t layer_state_set_kb(uint32_t state) { switch (biton32(state)) { case _raise: // the top row is used as raise and usb led indicator. rgblight_set_effect_range(matrix_cols, rgbled_num-matrix_cols); my_sethsv_range(hsv_white, 3, matrix_cols); break; case _lower: // the top row is used as lower and usb led indicator. rgblight_set_effect_range(matrix_cols, rgbled_num-matrix_cols); my_sethsv_range(hsv_green, 3, matrix_cols); break; case _adjust: // the top two lines are used as adjust and usb led indicators. rgblight_set_effect_range(matrix_cols*2, rgbled_num-matrix_cols*2); my_sethsv_range(hsv_red, 3, matrix_cols*2); break; default: rgblight_set_effect_range(3, rgbled_num-3); rgblight_sethsv_noeeprom(rgblight_config.hue, rgblight_config.sat, rgblight_config.val); break; } return state; } #endif my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " add rgblight_set_effect_range()  implement effect range  arrange the order of function list in rgblight.h .  update docs/feature_rgblight.md  fix rgblight_rainbow_swirl_range default value  add example code about utility functions  add example code about direct operation functions  when rgblight_split is defined, the following function has no meaning and is invalidated.  * rgblight_setrgb_master(r, g, b)  * rgblight_setrgb_slave(r, g, b)  * rgblight_sethsv_master(h, s, v)  * rgblight_sethsv_slave(h, s, v)  add temporary test code for rgblight_set_effect_range  fix rgblight_effect_knight() bug  test end. revert \"add temporary test code for rgblight_set_effect_range\"  this reverts commit 5680cddd012d68b2db75a532862a7fef250f8973. ", "linked_issue_titles": "", "title": "add effect range to rgblight.c"}
{"description": " adds a few functions to mark and span that i found useful in an upcoming refactor of nll region error reporting. also includes some new documentation based on my discussion with @jseyfried on irc. r? @jseyfried ", "commit_messages": " add documentation for syntaxcontext::remove_mark  implement parent() on syntax_pos::span  ... and reimplement proc_macro::span::parent using it. this function turns out  to be useful in the compiler as well  implement a least upper bound for marks.  this is useful when trying to compute when something is lexically before  something else, but they aren't necessarily in the same syntaxcontext ", "linked_issue_titles": "", "title": "add some utilities to libsyntax"}
{"description": " changes to jison spec to allow underscores in entity names and entities with no relationships.  minor updates to docs, unit tests, and e2e tests resolves #1710 no real design involved; simple changes to improve flexibility ", "commit_messages": " allow underscores in entity names, and entities with no relationships ", "linked_issue_titles": " support underline for table names in er diagrams ", "title": "bug/1710 underscore in entity names"}
{"description": " this pr addresses all the basic setup required to implement capturing child tasks. it was discussed in the simple design doc with @ericl. it implements pg.ready() & pg.bundle_spec calls gcs server to obtain bundle when they are called for the first time. this helps us to avoid having bundles as an argument of class placementgroup. setup placement group id to the worker context. for actors, it is set at the process level. for tasks, it is set at the thread level. get_current_placement_group api to obtain class placemenetgroup where a current task / actor belongs to. #9808 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " in progress.  in progers.  done. ", "linked_issue_titles": "", "title": "capture child task part 1"}
{"description": " signature help for tagged templates this pr enables signature help support in the language service for tagged template strings. the idea is that a tagged template is a bit of an implicit function invocation. whenever a user requests signature help (or it is triggered by the consuming environment), we should figure out what function a tag refers to, which overload should be chosen, and which parameter is currently being fed. substitution-argument correspondence when a template expression is tagged, each substitution expression corresponds to an argument in invoking that tag. specifically, the nth substitution expression in a tagged template expression is the (n+1)th argument in an invocation. templatestringsarray argument whenever the cursor lies within a template literal (whether a no-substitution literal, or a fragment of a template expression), the parameter in question is the first parameter of the tag in question. this is because each template literal in a tagged template corresponds to an array element in the cooked/raw array object specified in es6. this means that as the cursor moves through a template expression, parameters will not be highlighted from left-to-right consistently. ", "commit_messages": " initial signature help work for tagged templates.  stylistic changes/comment fixups.  got sig help working in the template head.  got sig help working in tagged no-sub templates.  refactored code, adjusted for residing out of bounds of the template.  fixed isunclosedtemplateliteral to account for new possible inputs.  conflicts:  src/services/signaturehelp.ts  fixed template head offsetting.  tests for signature help on tagged templates with no overloads.  added tests for overloads.  fixed broken test. ", "linked_issue_titles": "", "title": "tagged template signature help support in language service"}
{"description": " my next plugin ;) node.js plugin readme page section in node.d/readme.md default configuration in conf.d/node.d/stiebeleltron.conf.md updated infographic. had to move the lowest section down a bit, to provide space for this and future plugins i didn't update the \"add charts\" wiki yet. should i split the \"ups and power\" section into \"ups\" and \"household appliances\"? or just a new section? which links would get broken? i'm thinking of moving the solar power plugins and this one to \"household\", which would make more sense to me. i'm aware that the plugin is collecting values based on a rather large json configuration (definition of charts, dimensions etc.). i decided to do it in this way so that other people are able to collect different values in their systems. i cannot provide a plugin that is working for every setup, since i cannot test them (there are air/water systems, geothermal probes, etc). but i can make it adaptive. also the metrics are collected using regex. not optimal but there is no direct api (afaik) and performance-wise they are just fine (some 0.9% spikes on a intel xeon). the slowest component is the device response itself (usually around 1s, sometimes it takes up to 4s). ", "commit_messages": " first implementation  first working implementation.  improvements to dashboard  create stiebeleltron.conf.md  update isg web link  fixed dimension id bug.  renamed charts of output in the default config.  update netdata-overview.xml with stiebel eltron logo  added the stiebel eltron wiki ", "linked_issue_titles": "", "title": "add plugin for stiebel eltron heat pump system"}
{"description": " if user never made a new virtual desktop, there will be no information about virtual desktop id in the registry, and zeroed-guid will be used. migrate persisted information for zeroed-guid in primary desktop when virtual desktop switch occurs. don't use ivirtualdesktopmanager::getwindowdesktopid on getforegroundwindow during initialization. if powertoys start right away when system starts, getforegroundwindow might not contain valid hwnd, and we could end up with zeroed-guid. pr checklist applies to: #7790 #7011 cla signed. if not, go over here and sign the cla validation steps performed clear the registry (both software\\microsoft\\windows\\currentversion\\explorer\\sessioninfo\\\\virtualdesktops and software\\microsoft\\windows\\currentversion\\explorer\\virtualdesktops) and persisted fancyzones settings (c:\\users<user-name>\\appdata\\local\\microsoft\\powertoys\\fancyzones), reboot the machine. start powertoys and apply either template or custom layout on primary desktop. verify that layout information is persisted, and zeroed guid is used to define primary desktop. create new virtual desktop. verify that layout information for primary desktop is preserved, but guid is updated to the real one. ", "commit_messages": " update primary desktop data after virtual desktop switch  don't remove zeroed-guid inside removedeleteddesktops method ", "linked_issue_titles": "", "title": "update primary desktop data on virtual desktop switch"}
{"description": " a point is a fairly basic abstraction that is better put in common (along with rectangle, and vec), which can then be reused elsewhere without bringing in any unrelated code. ", "commit_messages": " common: extract point into a common struct  this is generic enough that it can be moved into the common class for  reuse.  touchscreen: make use of common point struct ", "linked_issue_titles": "", "title": "extract point struct into common"}
{"description": " this is something i always need when making some pixel art / graphics, so i've added this feature. preview: pixel_grid_demo.mp4 special mention to @tobyase for fixing the bug that allows this to work nicely :^) ", "commit_messages": " pixelpaint: show a pixel grid when zoomed in enough  the editor now draws a grid showing the pixels if you are zoomed  in enough. currently the threshold is a scale of 15 (so if one  pixel side on the image takes up > 15 pixels in the editor)  pixelpaint: add menu action to toggle pixel grid visibility  you can now toggle on/off the visibility of the pixel grid from  the view menu, if you don't want it shown for some reason. ", "linked_issue_titles": "", "title": "show a pixel grid when zoomed in :^)"}
{"description": " for #22821 the first approach we tried was #25325. this only logs the messages from allocation commands once the cluster state update has been acknowledged. @ywelsch (who i got this in a little too late for) recommended to hold off on exposing it in the rest layer for now. ", "commit_messages": " wip #22821  write the messages as a new element to the reroute response.  tests not passing  wip #22821  build messages from explanations and log them on cluster state  ack. it passes  wip #22821 only log if dry run, fill in it which passes  wip #22821 clean up imports and formatting ", "linked_issue_titles": "", "title": "log messages from allocation commands"}
{"description": " some sample sites still had 'copyright 2012' in the footer, updated to 2013. ", "commit_messages": " update docs/examples/fluid.html  updated copyright to 2013  update docs/examples/carousel.html  updated copyright to 2013  update docs/examples/hero.html  updated copyright to 2013  update docs/examples/marketing-alternate.html  updated copyright to 2013  update docs/examples/marketing-narrow.html  updated copyright to 2013 ", "linked_issue_titles": "", "title": "updated copyright to 2013 in examples"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add accesstype to jest.spyon  adjust version ", "linked_issue_titles": "", "title": "add accesstype to jest.spyon as supported in jest 22.1.0+ for types/jest"}
{"description": " original pull-request #13386 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " done  fix build  update ownsplitchannel.cpp  fix style  deadlock in textlog ", "linked_issue_titles": "", "title": "cherry pick #13386 to 20.4: deadlock in textlog"}
{"description": " new features apis add complex apis: paddle.real paddle.imag paddle.conj cherry-pick prs: #29603 #29672 #29527 ", "commit_messages": " add complex dtype op (add) test example (#29603)  * add op test case for complex  * polish code details  * add xpu set constant support  * fix argument rror  * remove useless pyc file  [complex] add real & imag op and api for complex tensor (#29672)  * add complex real op & api & unittest  * add imag op & api & unittest  * refactor op impl  * revert simplify writing due to complile failed  * polish details  * polish grad op code  add conj op for complex types (#29527)  * add conj op for complex types  * add conj for complex types  * add more test case  * add conj_op test  * modify conj api and impl  * add complex type for fill_constant_op xpu  * add setconstant for complex type  * remove complex conj test file  * user define grad for test_conj_op  * add test case for static mode of conj api  * modify conj doc  * change input args name to x  * remove useless codes  * conj support real types  * add conj test case for real number ", "linked_issue_titles": "", "title": "add complex api conj, real and imag"}
{"description": " this pr silences some compiler warnings, and also fixes an error in cvideoinfoscanner where an int parameter was used as a string. ", "commit_messages": " rendermanager: fix log line  guidialogaddoninfo: fix compiler warning  warning was:  comparison of integers of different signs: 'int' and 'size_type' (aka 'unsigned long')  videoinfoscanner: fix logging error  guiwindowslideshow: fix signed vs. unsigned compiler warnings  stringutils: fix signed vs. unsigned compiler warning  colormanager: fix signed vs. unsigned compiler warning  capplication: fix initialization order  this fixes the following compiler warning:  field 'm_processedexternalcalls' will be initialized after field 'm_ignoreskinsettingchanges' ", "linked_issue_titles": "", "title": "fix 1 error and 5 compiler warnings"}
{"description": " fix issue #5953 by giving its associated opening tag. initially, the pr tried to address preventing adding the global symbols that is not in jsx into the opening tag. however, doing so cause some inconsistent so the change is rolled back. ", "commit_messages": " update tests  don't include completion in opening tag, include name of opening in closing tag  update baseline from returning with unknownsymbol ", "linked_issue_titles": "", "title": "fix crash inside jsx closing tag"}
{"description": " performance optimization ops this pr optimize current implementations for sgd and sum operators for bf16 data type (mainly) when selectedrows (sparse) tensors were used by reusing onednn handler. the performance results on word2vec model are as follows on cpx 6348 machine with single thread: commit engine words/sec bf16 c56d697 onednn 18142.32 bf16 this pr onednn 20814.31 fp32 c56d697 cpu 27680.99 this gives ~15% speedup. from profiling: commit sgd total[ms] sgd % sum total[ms] sum % fp32 c56d697 117.77 2.5 395.31 8 bf16 c56d697 954.94 8.6 5151.35 47 bf16 wo cache 339.28 4.6 2159.22 29 ", "commit_messages": " create stateful onednnaxpyhandler object.  this makes it possible to call it multiple times without recreating the  onednn primitives every time.  prepare sgdopkernel to reuse its implementation from onednn kernel.  onednn sgd kernel.  update call to use new onednnaxpyhandler object api.  setup seed in proper place.  enable onednn kernel only for single case.  * for dense param and sparse grad.  small refactor.  enable onednn by op attr or by cmd line flag.  use int64_t type for number of elements.  support dense param and grad from onednn kernel.  enable sgd onednn kernel when use mp bf16 optimizer.  force non-copyable/movable onednnaxpyhandler.  reuse onednnaxpyhandler for spare tensors in sum op. ", "linked_issue_titles": "", "title": "reuse onednn handler for sgd and sum for selectedrows input tensors."}
{"description": " issue: follow up to #13775 i added support for vue 3 in addon-storyshots. additionally, i added some more stuff to the vue-3-cli example that makes it easier to try out the storyshots stuff. as you can see, i was able to successfully generate the snapshots with storyshots, but those can't run during a normal test run because of all the troubles i've been encountering with having vue 2 and vue 3 in the dependency tree of this monorepo. is this testable with jest or chromatic screenshots? generated but not run on normal test runs does this need a new example in the kitchen sink apps? added does this need an update to the documentation? updated the readme for storyshots ", "commit_messages": " feat: utilize typescript in vue 3 example files  chore: cleanup some vue 3 example stories  feat: add vue3 support to storyshots  feat: add storyshots to vue 3 example but disable in suite  docs: document vue3 storyshots setup ", "linked_issue_titles": "", "title": "add support for vue 3"}
{"description": " the slug package support an option to allow having whitespace at the end of a string. add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes:  add it to notneededpackages.json. ", "commit_messages": " adds trim property for the slug package  the slug package support an option to allow having whitespace at the end of a string.  update slug-tests.ts ", "linked_issue_titles": "", "title": "slug@v5.1.0 - adds trim property for the slug package"}
{"description": " what types of changes does your pr introduce? put an x in all boxes that apply ", "commit_messages": " add royal tsx to remote login software  add raycast to productivity  add vectornator to design tools  add vectornator to design tools  add responsively to developer utilities  add responsively to developer utilities ", "linked_issue_titles": "", "title": "add responsively to developer tools"}
{"description": " as null safety feature for flutter driver was merged (#67570), we'd need to reland the extension feature patch (#67456). it should be compliant now, no lint nor build errors are reported. related issues #67570 #67456 packages/flutter_driver/test/src/real_tests/extension_test.dart before you create this pr, confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i read the tree hygiene wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. no, no existing tests failed, so this is not a breaking change. ", "commit_messages": " flutter driver - create widget finders from serialized finders extensions  add license header  tests  add new line  stubs & tests  widget tests  fix tests typo  expose finder factory to finder creator  rename test variable  format  remove trailing whitespaces  null safety ", "linked_issue_titles": "", "title": "reland \"flutter driver - create widget finders from serialized finders extensions\" with null safety"}
{"description": " miscellaneous cleanups for same-type requirements: use isderivedrequirement() consistently, which fixes an issue that showed up in printing, clean up printing via requirement signatures a little, associating self == self.a requirements with a when we can ", "commit_messages": " [gsb] use isderivedrequirement() for same-type connected components  [ast printer] associate \"self == self.foo requirements with \"foo\".  [ast printer] swap the order of \"self == self.a\" requirements associated with a  it looks better this way. ", "linked_issue_titles": "", "title": "clean up handling of same-type requirements"}
{"description": " the main patch is by klim with some subsequent updates and fixes ", "commit_messages": " add ipp support in resize, warpaffine, warpperspective functions  fixed bug in ipp-accelerated morphology; added several ipp imgwarp functions (by klim) ", "linked_issue_titles": "", "title": "accelerated resize, warpaffine, warpperspective using ipp"}
{"description": " fixes #43493. ", "commit_messages": " fix getrecursionidentity, undo changes from #43435 (but keep tests)  remove test that takes excessively long to run  accept new baselines  fix formatting ", "linked_issue_titles": " \"excessive stack depth comparing types 'flatarray<arr, ?>' and 'flatarray<arr, ?>'\" false positive ", "title": "fix getrecursionidentity function to always return some identity"}
{"description": " discovered using clang's memorysanitizer. an msan build will fail by simply executing: ./python -c 'u\"\\n\"' (cherry picked from commit 746b2d3) ", "commit_messages": " fix an out of bounds memory access.  news entry ", "linked_issue_titles": "", "title": "fix oob memory access in unicode escape parser (gh-10506)"}
{"description": " update some behaviors of ndarrayiter change the functionality of class ndarrayiter last_batch_handle = roll_over. change the timing of shuffling. previously, it shuffles only during the initialization, which didn't meet training needs. the above change is tackled by #12285. this pr add the following thing, please refer to concat, edge case for end variable, unit test for different kinds of input of labels and ndarrayiter_csr fix index out of range error (#12526 #12539 #12538) by handling the missing labels case. please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change shuffle when calling the reset. when last_batch_handle is roll_over, the last batch should be rolled over to next epoch add the unit tests for different situations (shuffle equals to true/false, data source is mx.ndarray/ np.ndarray, 3 last_batch handle parameters and pass the normal labels/ none/ empty list) @sandeep-krishnamurthy @zhreshold ", "commit_messages": " 1. move the shuffle to the reset 2. modify the roll_over behavior accordingly  refactor the concat part  refactor the code  implement unit test for last_batch_handle  refactor the getdata part  add docstring and refine the code according to linter  1. add test case for ndarrayiter_h5py 2. refactor the implementation  update contributions doc  fix wording  update doc for roll_over  1. add test for second iteration of roll_over 2. add shuffle test case  fix some wording and refine the variables naming  move utility function to new file  move utility function to io_utils.py  change shuffle function name to avoid redefining name  make io as a module  rename the utility functions  disable wildcard-import ", "linked_issue_titles": "", "title": "change the way ndarrayiter handle the last batch"}
{"description": " with this pr we narrow the string and number types as appropriate when they are compared with values of literal types. function move(direction: \"up\" | \"down\") { // ... } function do1(command: string) { if (command === \"up\" || command === \"down\") { move(command);  // narrowed to type \"up\" | \"down\" } } function do2(command: string) { switch (command) { case \"up\": case \"down\": move(command);  // narrowed to type \"up\" | \"down\" break; } } function f1(x: number, y: 1 | 2) { if (x === 0 || x === y) { x;  // narrowed to type 0 | 1 | 2 } } function f2(x: number | \"foo\" | \"bar\", y: 1 | 2 | string) { if (x === y) { x;  // narrowed to type \"foo\" | \"bar\" | 1 | 2 y;  // narrowed to type \"foo\" | \"bar\" | 1 | 2 } } interestingly this found a bug in our scanner, pointing out that type 2 is not comparable to type 8. fixes #7447. fixes #10417. fixes #11306. ", "commit_messages": " narrow string and number types in equality checks and switch cases  fix bug in scanner  properly narrow union types containing string and number  accept new baselines  add tests ", "linked_issue_titles": "", "title": "narrow string and number types in literal equality checks"}
{"description": " two cleanups to the representation of archetypetype: eliminate the isrecursive bit that nobody is using; yay for single bits forcing 31 bits of padding. overlap 'associated type' and 'name' storage; the latter is derivable from the former. ", "commit_messages": " [ast] drop the 'isrecursive' bit from archetypetype. nfc  [ast] compress archetypetype's storage slightly.  the \"associated type\" and \"name\" fields are mutually independent,  because one can recover the name from the associated type.  [serialization] simplify serialized representation of archetype types.  we don't need to store the associated type declaration and name  separately in the module file, either. ", "linked_issue_titles": "", "title": "improve the representation of archetypetype"}
{"description": " i hereby agree to the terms of the cla available at: ", "commit_messages": " clickhouse-2: support negative tests  update client.cpp  clickhouse-2 client testmode fixes: reconnect on clienterror, clear expected errors, return error to os ", "linked_issue_titles": "", "title": "fix client's --testmode (allow multiple negative tests with clienterror)"}
{"description": " this pr updates keyedjsonatomicfielddata to always return ordinals in the range [0, (maxord - minord)], which is necessary for certain aggregations and sorting options to be supported. as discussed in #41220, i opted not to support keyedindexfielddata#getordinalmap, as it would add substantial complexity. the one place this affects is the 'low cardinality' optimization for terms aggregations, which now needs to be disabled for keyed json fields. it was fairly difficult to incorporate this change, and i have a couple follow-up refactors in mind to help simplify the global ordinals code. (i will likely wait until this feature branch is merged though before opening prs on master). ", "commit_messages": " add unit tests that exercise ordinal rebasing.  rebase global ordinals to lie in the range [0, (maxord-minord)].  add tests around cardinality aggregations.  disable the low cardinality optimization to make sure getordinalmap is not accessed. ", "linked_issue_titles": "", "title": "rebase keyed json ordinals to start from zero."}
{"description": " reopening #1200 i cannot provide continuous integration for xboxone, but i was able to run the following tests with this change: //#include \"test/gtest-filepath_test.cc\" #include \"test/gtest-linked_ptr_test.cc\" #include \"test/gtest-message_test.cc\" //#include \"test/gtest-options_test.cc\" //#include \"test/gtest-port_test.cc\" #include \"test/gtest_pred_impl_unittest.cc\" #include \"test/gtest_prod_test.cc\" #include \"test/gtest-test-part_test.cc\" #include \"test/gtest-typed-test_test.cc\" #include \"test/gtest-typed-test2_test.cc\" //#include \"test/gtest_unittest.cc\" #include \"test/production.cc\" the others required getenv, chdir or capturestdout would this output be enough to get approval for the pull request? connect to pipe \\sevpipe\\9021f601f657ec5f ", "commit_messages": " added support for winapi_partition_tv_title which is defined on xboxone  added support for winapi_partition_tv_title which is defined on xboxone  added support for winapi_partition_tv_title which is defined on xboxone ", "linked_issue_titles": "", "title": "added support for winapi_partition_tv_title to support xboxone applications"}
{"description": " this is re-submission of #20687 but removed test import related changes. closes #20684 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " [job submission] use specific redis_address and redis_password instead of \"auto\" (#20687)  fix test imports ", "linked_issue_titles": " [bug][jobs] job submission cli didn't work on first ray install ", "title": "fix job server's ray init(to use redis address rather than auto"}
{"description": " this change is ", "commit_messages": " disable redirection for wow64 processes. issue #899  fixing for winxp compatibility  format code  format code  still trying to fix issues with 32bit systems  # conflicts:  #\tsrc/launcher/x64_dbg_launcher.cpp  remove extra new line ", "linked_issue_titles": "", "title": "disable fs redirection for 64bit applications on wow64"}
{"description": " correctly check that an item does not exist in the aclk thread list and ignore it (instead of accessing invalid memory and crash) ignore error when attempting to wake up event loop (do not fatal) component name aclk the code is not active yet ", "commit_messages": " make sure an element was found for removal  remove fatal if async send fails  add newline ", "linked_issue_titles": "", "title": "fix list corruption in aclk sync code and remove fatal"}
{"description": " use stable ship protocol for transaction_trace move eosio-tester type conversion to state_history library select one: select any that apply: ", "commit_messages": " move eosio => ship type conversion to type_convert.hpp  use ship protocol trnsaction_trace for amqp_trace_plugin ", "linked_issue_titles": "", "title": "amqp_trace_plugin ship protocol for transaction_trace"}
{"description": " this pr fixes asan detected global-buffer-overflow in issue #5281 . the fixes apply variable.defined() checks before reading any member variable of the variable. tested with asan_symbolizer_path=/usr/bin/llvm-symbolizer asan_options=symbolize=1 python test/test_autograd.py please review @ezyang @apaszke edit : reverted change in any_variable_requires_grad in function.h ", "commit_messages": " fix asan buffer overflow in autograd saved_variable.cpp  fix asan global buffer overflow in any_variable_requires_grad ", "linked_issue_titles": "", "title": "fix asan detected global buffer overflows in autograd"}
{"description": " i've been working on synthetickeyboardevent test and have gotten a significant amount of tests to pass but wanted to see if the community had feedback on my work so far and advice on how to complete the few remaining tests where i am stuck. problem: i am unable to fire events and pass tests that require a 'keypress' event. i've looked thru other examples, specifically mdn docs and pr #11365 to fire the keypress event, specifically on line 41. via mdn and other pr's, i've found no significant difference on why a 'keypress' event and and the 'keydown'/'keyup' which fire as expected. @gaearon any feedback or tips would be on my approach/code appreciated ", "commit_messages": " keyboardevent interface-keypress  pass first 6 tests  merge  merge ", "linked_issue_titles": "", "title": "refactor synthetickeyboardevent tests to only use the public api"}
{"description": " this implements the direct call <-> plasma interop described in  after this change, we have near feature parity for direct call tasks / actors on a single node. there are two remaining issues for full parity: failure handling. right now objects promoted to plasma have no task lease, so we need to add back fault handling so that workers don't block forever waiting for failed objects. spillback scheduling. direct call tasks aren't spilled yet. ", "commit_messages": " wip  fix test  add mem test ", "linked_issue_titles": "", "title": "handle exchange of direct call objects between tasks and actors"}
{"description": " feat: implementation of a* search algorithm. topic: ai/ml. added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines this code might be too long, so any suggestions about any changes are welcome. ", "commit_messages": " fix: lgtm warnings in...  updating directory.md  update current tree  merge remote-tracking branch 'upstream/master'  feat: a* search algorithm, type: ai/ml  type changes  code reformatting.  code reformatting-2  code refactoring-3.  code refactoring-3.  code refactoring-4.  code refactoring-4.  code refactoring-5.  updating directory.md ", "linked_issue_titles": "", "title": "a star search, type: ai/ml"}
{"description": " detailed description / documentation draft: small blog post snippet that links to the mindsdb blog for further reading. ", "commit_messages": " initial mindsdb blog post content and image references.  update mindsdb blog post content, title and slug. ", "linked_issue_titles": "", "title": "blog post how to enable predictive capabilities in clickhouse"}
{"description": " currently, travis runs 12 build jobs: (linux | osx) * (gcc | clang) * (googletest | googlemock | googlemock-c++11) but the googlemock build includes googletest already, including all unit tests and samples of googletest, so a separate build of googletest doesn't provide additional knowledge. by removing the googletest build, we can reduce the build number from 12 to 8 builds and thus get a much quicker response from travis, without reducing the test coverage. ", "commit_messages": " switch on verbose make  run combined build only  there is no need for separate 'googlemock' and 'googletest' builds,  as the 'googlemock' build includes 'googletest' and it's unit tests. ", "linked_issue_titles": "", "title": "reduce travis buildjobs by 4/12"}
{"description": " fixes #17728 modifies section 1.12 multiclass and multilabel algorithms as follows: change section title to \"multiclass and multioutput algorithms\" to match sklearn module names (sklearn.multiclass and sklearn.multioutput) change overall section structure so that headers == problem type, and subheaders == target format and meta-estimators redistribute content from introduction (problem types, target formats) into corresponding sections rewrite the rest of the introduction to be concise, and to mention sklearn.multioutput add chart image to introduction that shows hierarchy of topics/classes fix :mod:/:class:/:func: links to sklearn.multioutput/sklearn.utils.multiclass that weren't rendering because of the presence of the ..currentmodule sklearn.multiclass directive apart from the introduction, right now the existing content is left largely unmodified -- i've simply moved it around into new header sections to improve clarity. that said, i feel some sections are still unclear, and could possibly use rewriting: the multiclass-multioutput classification section is tricky. it's the combination of multiclass and multioutput, so it doesn't read like a distinct problem type. that makes it tough to fit into the topic hierarchy. the existing content never mentions which meta-estimators support this. is it the same as meta-estimators which support the multilabel-indicator target type? this could be clarified. onevsrestclassifier, a multiclass estimator, can also do multilabel classification. this is unintuitive and potentially confusing! the class docstring was changed in #17646, but further changes could be made to the user guide and api reference to clarify the dual nature of this estimator. classifierchain and regressorchain sections are somewhat brief, and don't have usage examples. regarding the chart figure the chart image i added is possibly difficult to maintain. if changes are made to sklearn.multiclass or sklearn.multioutput, the image would need to be updated too. i wanted to generate the visualization programmatically, but i couldn't figure out how using sphinx/matplotlb/etc. i created it using google drawings, so here is a shareable link for anyone coming from the future wondering what the source of the chart image is. you should be able to make a copy and edit it if need be. ", "commit_messages": " remove multilabel target format section  this information is already presented in the prelude of this user guide  page.  restructure headers to match problem domains  previously, headers were organized by strategy type. however, i feel it  is easier to parse when organized by problem type. strategies are  relegated to subheaders within each problem header. as well, a  subheader for target format is added.  no content is edited in this commit -- only headers.  redistribute content from intro to new sections  again, no edits made to the content itself -- simply redistributing  content from the introduction to the body sections of the page.  retitle section \"multiclass and multioutput\"  the previous title was \"multiclass and multilabel\", but multilabel  doesn't account for multioutput regression. this new title is more  inclusive of all multilearning problem types.  rewrite introduction to include multioutput module  also included is a chart which outlines the responsibilities and  classes for each module.  clarify multioutput/multilabel classification term  fix class/function links  the ..currentmodule directive was set to sklearn.multiclass, so sphinx  assumed all links were from that module. but, this guide contains links  to sklearn.multioutput and sklearn.utils.multiclass. to make them  render properly, i've removed the ..currentmodule directive, and updated  links accordingly.  update subheader titles to class names  subheaders were previously titled either using the name of the strategy  or the name of the problem type. when headers (not subheaders) were  changed to problem types, this resulted in some subheaders having the  same name as headers (e.g. \"multioutput regression\"). this change fixes  the conflicts.  tweak multiclass-multioutput content  * re-add entry to summary table  * make sure all terms use \"multiclass-multioutput\" and not  \"multioutput-multiclass\" ", "linked_issue_titles": " restructure \"section 1.12. multiclass and multilabel algorithms\" to make distinctions between concepts clearer ", "title": "doc restructure multiclass and multilabel in user guide"}
{"description": " #16763 is adding an internal listener. the internal listener is not driven by event dispatcher. however, it shares the common functionalities of structuring the ownership of connections with the tcp listener. this pr extracts the common functions out of activetcplistener so those can be reused by internal listener. the common includes activeconnection definition the helper method of remove an active connection and remove an filter chain risk level: low ", "commit_messages": " initial internal listener  for new pr  merge main  delete test/integration/internal_tcp_proxy_integration_test.cc  coverage  remove clientconnectionimpl ctor for internal socket  revert dispatcher  merged main  revert internal listener ", "linked_issue_titles": "", "title": "move active connection collection out of active tcp listener"}
{"description": " see #18751 for more info on the bug. this changes the ref counting protocol to make sure that workers report any nested objectrefs that are still in scope. the main issue is that we need to make sure to eventually clean up all objectrefs that have gone out of python scope, but we also need to make sure to account for all nested objectrefs that might still be in scope. this pr uses a per-object flag to indicate whether it has any nested objectrefs that might still be in scope. the flag gets updated recursively whenever a nested objectref is used. when an object ref goes out of scope and the borrower responds to the waitforrefremoved rpc, the reply includes all nested refs and we reset the flag. then, we just have to make sure not to delete an objectref if its flag is set. this should not result in any additional messages, but individual messages may be larger because they can include object refs that have already gone out of scope and don't need to be reported. i chose not to optimize this for now. closes #18751. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " fix assertion crash  test, lint  todo  tests  protocol  test  fix  lint  header  recursive  note  forward test ", "linked_issue_titles": " [bug] ref count safety bug when inlining objectrefs or deserializing objectrefs multiple times ", "title": "fix bug in ref counting protocol for nested objects"}
{"description": " this builds on #33518 . wildcard index expressions are tricky because when security is enabled, widcards (inclusions and exclusions) have to be expanded in the scope of the authenticated user. relates: #33805 edit: the security plugin authorizes actions on indices. this implies that a request with the indices expression containing wildcards has to be first evaluated, in the authorization layer, before the request is handled. for authorization purposes, wildcards in expressions will only be expanded to indices visible by the authenticated user. however, this \"constrained\" evaluation has to be compatible with the expression evaluation that a cluster without the security plugin installed would do. therefore every change in the evaluation logic in any of the to sites has to be mirrored in the other. #33518 added support forwildcard exclusion (-...*) at the core logic site. this pr mirrors that at the indicesandaliasesresolver site, which is the site that does the affore mentioned \"constrained\" expression evaluation. ", "commit_messages": " wip main code  main code  getalias 404 for requested indices  darn indicestodisplay bs  get alias wildcard rest-api tests  almost all tests pass ", "linked_issue_titles": "", "title": "get alias api wildcard exclusion with security"}
{"description": " this pull request adds additional documentation as requested by #7578. the documentation contains how to properly configure the dospagecount from the mod_evasive apache module for a virtual host. component name docs ", "commit_messages": " docs(running-behind-apache): add vhost example for dospagecount  docs(running-behind-apache): adjust indentation level for code block; change dospagecount value from 50 to 30 ", "linked_issue_titles": "", "title": "add configuration details for vhost about dospagecount to apache proxy guide"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). added property types to the existing draweritems (was missing). flow source ", "commit_messages": " improved draweritems  ran 'npm run lint package-name' ", "linked_issue_titles": "", "title": "added property type to draweritems"}
{"description": " fix: some refactor about datazoom and axis scale extent calculation: the \"scale extent calculation\" is depended by both coord sys and \"datazoom\". so it need to be performed in different stage of workflow and should avoid to call it repleatly or implement it repeatly. but previously, the \"scale extent calculation\" is implemented both in axishelper.ts and datazoom/axisproxy.ts, where different code implements similar logic. \"scale extent calculation\" is based on input of: (i) option specified min/max/scale (including callback) and (ii) dataextent and (iii) some filter related components like datazoom. currently we need add more filters depends on that axis scale calculation. e.g., (i) one axis min max effect the other axis extent (ii) custom filter. so we refactor that \"scale extent calculation\" as a reusable module (see scalerawextentinfo.ts). based on (1), make the callback of axis.min/axis.max consistent whatever it is called in \"data processing stage\" or \"coord sys updating stage\" based on (1), fix some \"inconsistent\" flaw in datazoom when handling stacked series. fix the type of axis.min/max to scaledatavalue. and enable the callback of axis.min/max to return scaledatavalue. remove some code that never used. make the \"data filter\", which will \"block stream\", not as the default data processor in the register api. feature: enable category axis min/max to shrink the other axis extent in cartesian. after this modification, if some data if out of the range of a category axis, the data item will not be filtered, but the extent of the other axis will be calculated based on the filtered data. if datazoom is used in either of the xaxis or yaxis in that cartesian, the shrink will not be performed. ", "commit_messages": " fix: some refactor about datazoom and axis scale extent calculation:  (1) the \"scale extent calculation\" is depended by both coord sys and \"datazoom\".  so it need to be performed in different stage of workflow and should avoid to call it repleatly or implement it repeatly.  but previously, the \"scale extent calculation\" is implemented both in axishelper.ts and datazoom/axisproxy.ts,  where different code implements similar logic.  \"scale extent calculation\" is based on input of:  (i) option specified min/max/scale (including callback) and  (ii) dataextent and  (iii) some filter related components like datazoom.  currently we need add more filters depends on that axis scale calculation.  e.g.,  (i) one axis min max effect the other axis extent  (ii) custom filter.  so we refactor that \"scale extent calculation\" as a reusable module (see scalerawextentinfo.ts).  (2) based on (1), make the callback of axis.min/axis.max consistent whatever it is called in  \"data processing stage\" or \"coord sys updating stage\"  (3) based on (1), fix some \"inconsistent\" flaw in datazoom when handling stacked series.  (4) fix the type of axis.min/max to scaledatavalue. and enable the callback of axis.min/max to return scaledatavalue.  (5) remove some code that never used.  (6) make the \"data filter\", which will \"block stream\", not as the default data processor in the register api.  feature: enable category axis min/max to shrink the other axis extent in cartesian.  after this modification, if some data if out of the range of a category axis,  the data item will not be filtered, but the extent of the other axis will be calculated  based on the filtered data.  if datazoom is used in either of the xaxis or yaxis in that cartesian, the shrink will not be performed. ", "linked_issue_titles": "", "title": "extent filtered by other axis"}
{"description": " this patch allows over 44words fqdn for backend server name. in aws elasticache provides long server name (eg. cache-cluster-hoge.bixxxx.0001.apne1.cache.amazonaws.com) but,   nc_inet_addrstrlen limits 45words. so, domain is not recognized only up to 44 characters. ", "commit_messages": " fix fail long fqdn name resolve  remove strdup  remove unuse define ", "linked_issue_titles": "", "title": "fix long server  fqdn can not recognized"}
{"description": " this accessibility prop is needed by some partners for the help of reading comments/replies. i will backport this to .65/.64/.63 uia_itemtypepropertyid - identifies the itemtype property, which is a text string describing the type of the automation element. itemtype is used to obtain information about items in a list, tree view, or data grid. for example, an item in a file directory view might be a \"document file\" or a \"folder\". when itemtype is supported, the string must match the application ui language or the operating system default ui language. microsoft reviewers: open in codeflow ", "commit_messages": " adding accessibilityitemtype property to viewwin32  revert unneccesary change  adding to testpage  removing old change ", "linked_issue_titles": "", "title": "adding accessibility prop accessibilityitemtype on viewwin32"}
{"description": " hi, when you try to use serverless framework with localstack is impossible to deploy because the cloudformation generated by serverless doesn't come with accesscontrol property so the deployment breaks, i debug into the issue and we only need to make a quick fix and set a default value for this acl to continue with the deployment. this also fixes the issue #475  that i reported before. note: i also add a gitignore entry because i use pycharm as ide and there always create an .idea directory. ", "commit_messages": " ignore .idea folder of pycharm ide  add s3 acl publicread as default value fixes #475 ", "linked_issue_titles": "", "title": "set s3 acl default value in case comes empty"}
{"description": " this pr is part of the process separation project. move nodeimpl from interfaces/node.cpp to node/interfaces.cpp move chainimpl from interfaces/chain.cpp to node/interfaces.cpp move walletimpl from interfaces/wallet.cpp to wallet/interfaces.cpp no changes to any classes (can review with git diff --color-moved=dimmed_zebra) motivation for this change is to move node and wallet code to respective directories where it might fit in better than src/interfaces/, but also to remove all unnecessary code from src/interfaces/ to unblock #19160 review, which has been hung up partially because of code organization. building on top of this pr, #19160 should now be able to organize interface implementations more understandably in src/node/ src/wallet/ src/ipc/ and src/init/ directories instead of having so much functionality all in src/interfaces/ ", "commit_messages": " move nodeimpl from interfaces/node.cpp to node/interfaces.cpp  move chainimpl from interfaces/chain.cpp to node/interfaces.cpp  no changes to chainimpl or any related classes (review with git diff --color-moved=dimmed_zebra)  move walletimpl from interfaces/wallet.cpp to wallet/interfaces.cpp ", "linked_issue_titles": "", "title": "move node and wallet code out of src/interfaces"}
{"description": " when running in modern server mode, our response varies depending on user-agent. a reverse-proxy may wrongly cache the modern/legacy response and use it for others. this pr tries to prevent that. ", "commit_messages": " fix(vue-renderer): add vary header for server mode  test: add test for vary user-agent ", "linked_issue_titles": "", "title": "add vary header for user-agent in modern server mode"}
{"description": " fix a few small issues that could cause crashes with property wrappers: provide source locations for synthesized initializer calls (fixes rdar://problem/52969503 and rdar://problem/53183030) check for a null type before digging into an expression to find the type-checked \"initial value\" (fixes rdar://problem/53120878) ", "commit_messages": " [se-0258] fix source locations for implicitly-generated initializer calls.  fixes rdar://problem/52969503, a crash due to missing source location  information in implicitly-generated calls.  [se-0258] check for a null type.  within invalid code, we might encounter expressions without type  information yet. check for null here.  fixes crash from rdar://problem/53120878.  add now-fixed test case from rdar://problem/53183030 ", "linked_issue_titles": "", "title": "fix a few more crashes involving property wrappers in invalid code"}
{"description": " add v8 jsi executor support (disabled via use_v8 by default), with the requisite include directories, libraries, etc. if the given bundle name is already an absolute path, don't attempt to append the executable's path to it (useful for debugging bundle loading) microsoft reviewers: open in codeflow ", "commit_messages": " native modules in jsi mode  merge master  attempt to fix v8 build  merge remote-tracking branch 'upstream/master'  revert v8 and hermes defaults ", "linked_issue_titles": "", "title": "add optional v8 jsi executor support (disabled by default)"}
{"description": " add documentation in doc-src explaining how to add a new content viewer view class to contentview.py. ", "commit_messages": " begin work on documenting adding a new view  continue work on documentation of adding views  more documentation  more documentation  more documentation cleanup and formatting  further cleanup of documentation  finalizing documentation ", "linked_issue_titles": "", "title": "documentation for adding a new content viewer / view class"}
{"description": " continuation of #9642 add config option system_tables_lazy_load that, if set to false, loads system tables with logs at the server startup. alexander burmak, svyatoslav tkhon il pak, #9642 ", "commit_messages": " added a patch from alexander burmak  added a test from svyatoslav tkhon il pak @deifythegod #9642 ", "linked_issue_titles": "", "title": "system tables eager creation, continuation"}
{"description": " this pr is to add typings for part of the dynamic values functionality in react-jss. a few things i'm not happy with: i can't work out how to define typings for the other part of the spec (classname: props => {color: 'red', etc...}) i had to disable strict function checking in tsconfig.json to get tsc to pass with the changes made to the test file. would be glad if anyone has pointers or wants to look at these parts. add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " allow dynamic css values based on component props  add attribution, fix linter errors  rename to dynamiccssrule  update tests - had to disable strict function checking, if anyone knows how to make it work with this, please do! ", "linked_issue_titles": "", "title": "allow dynamic css values based on component props in react-jss"}
{"description": " add validator for javanese script (based on khmer). validation rules may need an update after review by language experts. ", "commit_messages": " initial commit to add aksara jawa - javanese script  fix typo re javanese ", "linked_issue_titles": "", "title": "add support for javanese script - aksara jawa"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. documentation for #6226 ", "commit_messages": " typo fix.  update log_family.md (#43)  update tinylog.md (#44)  docapi-7991: ru translation. ", "linked_issue_titles": "", "title": "en review,  ru translation for the update of log engines docs"}
{"description": " fixes argos running on empty screenshots. following screenshots are still empty:     would keep them so that we're notified once they start working. no idea why they won't render. ", "commit_messages": " fix react-select using no space in regression test  fixup customization route change  fix certain regression demos taking no space  ignore container demos ", "linked_issue_titles": "", "title": "fix empty visual rergression screenshots"}
{"description": " the pdf unit tests use a mock of the istream interface which fails if it can't copy the contents of the stream in a single pass. what is include in the pr: fixes for the mock to run correctly even when it receives a smaller buffer side. also run pdf thumbnail tests as part of the automated tests. took the chance to also add pdf modules to the bug report template. tests run successfully. linked issue: #13247 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries ", "commit_messages": " [ci] reduce pdf preview and thumbnail flakiness  [ci] run pdf thumbnail tests ", "linked_issue_titles": "", "title": "fix pdf thumbnail unit tests flakiness"}
{"description": " this pr removes interpolation of values into event errors. to make errors more clear when not expanded, the name attribute is special cased in rendering and prepended to the error message, if available (and set). this is a preparation for auto-generating event errors from _meta (#10779). ", "commit_messages": " ref(eventerror): make the eventerror class more useful  ref(eventerror): stop interpolating error messages  ref(ui): render event error paths explicitly ", "linked_issue_titles": "", "title": "stop interpolating event error messages"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: < if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " missing number array test  fix whitespace  fix comment alignment ", "linked_issue_titles": "", "title": "add missing methods for signale 1.4"}
{"description": " veml7700: command support values are normalized update de language: update de language  \"illuminance\" for a \"more\" german word related issue (if applicable): fixes # the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.2 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " update de language for illuminance for a \"more\" german word  add 2 commands for veml7700 sensor (gain, integration time); value normalizing activated ", "linked_issue_titles": "", "title": "update de language for \"illuminance\", update veml7700 sensor"}
{"description": " see jenkins-49044. jenkins-49044: descriptorvisibilityfilter extensions are now applied to securityrealm and authorizationstrategy. changelog entry appropriate for the audience affected by the change (users or developer, depending on the change). examples * use the internal:  prefix if the change has no user-visible impact (api, test frameworks, etc.) @reviewbybees ", "commit_messages": " [jenkins-49044] honor descriptorvisibilityfilter for securityrealm and authorizationstrategy  [jenkins-49044] the test ", "linked_issue_titles": "", "title": "apply visibility filters to securityrealm and authorizationstrategy"}
{"description": " if the user is using a version of git < 2.7.0, disable git integration (to prevent gitpython from prompting for credentials), and warn the user to upgrade their git: the text needs a product pass: do we want it above or below the streamlit welcome text? should we be more specific about what git integration means? (possibly link to docs?) should we be less prominent with this warning? maybe it's just a single line? git integration is disabled. streamlit requires git 2.7.0 or later, but you have 2.6.4. to use streamlit's git integration, please update git. fixes #2323 ", "commit_messages": " disable gitrepo if git is old, and warn the user  mypy annotation  test_print_old_git_warning ", "linked_issue_titles": " using git below version 2.7 requires remote (e.g. github) credentials on every run (for private repos) ", "title": "disable git integration for ancient gits"}
{"description": " tested with visual studio 2015 community, without mkl, and python 3.5.0b4, 32 and 64 bit. travis ci failures seem unrelated. ", "commit_messages": " bld: enable c99 complex for msvc14  bld: enable c99 isnan and isinf for msvc14  bld: disable broken msvc14 trigonometric functions ", "linked_issue_titles": "", "title": "enable visual studio 2015 c99 features"}
{"description": " the tests assume that hashmap is iterated in a certain order, which can cause the tests to fail under different java versions or platforms. the fix simply changes hashmap to linkedhashmap, as linkedhashmap does guarantee an order of iteration. ", "commit_messages": " fixed com.alibaba.json.bvt.bug.bug_for_smoothrat5#test_map to not rely on nondeterministic apis  fixed com.alibaba.json.bvt.bug.bug_for_smoothrat9#test_set to not rely on nondeterministic apis ", "linked_issue_titles": "", "title": "fixed 2 more tests that relied on non-deterministic apis"}
{"description": " objects which are not naively dumpable to json break ansible-connection rpc. this pickles any non-string to avoid this issue. ansible-connection ", "commit_messages": " fail more helpfully when data is not str  pickle arbitrary objects to return from connection ", "linked_issue_titles": "", "title": "pickle non-str objects to survive connection return"}
{"description": " added the 20 key (4x5) macropad/keyboard called emi20 to the list of keyboards. added the default keymap. this keymap includes a simpel numpad like layer on layer 0 and extra keys on layer 1 with the comments to help new users to edit the firmware themselves. updated the store on which this keyboard will be sold at my code follows the code style of this project: c, python i have read the pr checklist document and have made the appropriate changes. i have read the contributing document. ", "commit_messages": " added emi20 as a keyboard with the default firmware as it was previously not in the list of keyboards  i updated the store on which this keybaord will be sold in the readme file ", "linked_issue_titles": "", "title": "added emi20 as a keyboard with the default keymap"}
{"description": " this pr adds user timing marks at key points in the reconciler's execution. the marks are used by this new concurrent mode profiler tool that @kartik918 and i are building under @bvaughn and @jevakallio's guidance. high level breakdown of this pr: add a enableschedulingprofiling feature flag. add functions that call user timing apis to a new schedulingprofiling.js file. the file follows debugtracing's structure. add user timing marks to places where debugtracing logs. add user timing marks to most other places where @bvaughn's original draft debugtracing branch marks. tests added more context (and discussions with @bvaughn) available at our internal pr mlh-fellowship#11 and issue mlh-fellowship#5. similar to debugtracing, we've only added scheduling profiling calls to the old reconciler fork. test plan yarn test-prod yarn flow dom this test app that i created has a custom build of react with enableschedulingprofiling and enabledebugtracing set to true. when profiled with firefox profiler, the marks are visible in the output. ", "commit_messages": " add enableschedulingprofiler feature flag  add mark utility functions  combines those defined in both debugtracing.js and  [this branch](  rename enableschedulingprofiler -> enableschedulingprofiling  add all marks except commits and effects  reduce performance api requirements  add tests for schedulingprofiling  comment out tests covering kartik's code  add tests to cover markrenderabandoned and fix passive effect marks  comment out tests covering kartik's code  add remaining user timing marks  re add tests  add missing markcommitstopped calls, relocated some mark* calls for consistency, add blank lines  replace binary lane bitmask with decimal for compactness  reduce test strictness to fix test-prod  remove todo for markrenderscheduled  add markcommitstarted call to new logcommitstarted location  remove markrenderabandoned ", "linked_issue_titles": "", "title": "add user timing marks for scheduling profiler tool"}
{"description": " fixes #57172 when an ansible vault password file is specified in config and another is passed in as a command line argument, they need to be combined. the value from config is a tuple (by design) and needs to be converted to a list so it can be modified. the integration tests did not test this scenario, so i added a test for this case. lib/ansible/cli/vault.py ", "commit_messages": " convert vault_password_files to a list  add changelog and tests ", "linked_issue_titles": " ansible-vault: 'tuple' object has no attribute 'append' when multiple password files are configured ", "title": "convert vault_password_files to list to prevent traceback"}
{"description": " i just extended the types of the arguments for the #registerpartial function, because per the implementation that function is polymorphic. if the first argument is a string then the second must be a template fn, but in case the first argument is an object then the second argument is discarded making it optional. the implementation in question ", "commit_messages": " updating types for #registerpartial  #registerpartial is a polymorphic function now it accepts a single object making the second param optional.  excerpt from the implementation:  js  registerpartial: function(name, partial) {  if (tostring.call(name) === objecttype) {  extend(this.partials, name);  } else {  if (typeof partial === 'undefined') {  throw new exception(attempting to register a partial called \"${name}\" as undefined);  }  this.partials[name] = partial;  }  },    updated handelbars#registerpartials  removed extra spaces ", "linked_issue_titles": "", "title": "updated type definitions for handlebars#registerpartials"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: #23723 increase the version number in the header if appropriate. (not appropriate) if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. (already exists) fixes #23723, along with other related improvements. generally increased support for properly typed results when using lodash with numericdictionary collections (object with numeric key type). in methods that use iterators (foreach, map, etc.), the key param of the iterator is now string to match the run-time type of keys of objects. omit now returns exactly the same kind of dictionary/numericdictionary that was provided as a param. many methods updated to remove overloads to handle numericdictionary explicitly, and now instead rely on more generic handling of t extends object where possible. many other methods that previously accepted dictionary param are now updated to also accept numericdictionary. added unit tests for mapvalues, which uncovered many flaws with signature overloads. added a few missing signatures, re-ordered as necessary, etc. removed explicit type parameters from many calls to methods in unit tests. several other small improvements/additions to unit tests. ", "commit_messages": " change numericdictionaryiterator's \"key\" to type \"string\"  finish updating unit tests  improve support of numericdictionary.  * update signature overloads of many methods.  * improve many unit tests.  fix some mapvalues overloads  revert changes to v3 files  improve _.omit to fully support dictionary and numericdictionary  remove unused dictionaryiterator typedefs  improve signatures of mapvalues and add tons of unit tests ", "linked_issue_titles": "", "title": "improve support for numericdictionary collections"}
{"description": " de-capitalize variables in etcd make the image pull policy as \"ifnotpresent\" use image.repository to replace image which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # ", "commit_messages": " de-capitalize all the variables of etcd  remove unused variables  refactor the image definition ", "linked_issue_titles": "", "title": "refactor etcd to meet the chart tech requirement"}
{"description": " an implementation of single widget reloads which delegates to the compiler provided widget cache. this is the last step for implementing single widget reloads. since the compiler is able to detect all subtypes, the tool no longer needs to perform an expression evaluation in order to perform a fast reassemble. this updates the tool code to forward the compiler specified widget class, and updates the tests to perform real integration tests. fixes #61407 ", "commit_messages": " widget cache mark 2  update for latest draft of widget cache ", "linked_issue_titles": " implement faster single-widget hot reloads ", "title": "connect widget cache from frontend_server"}
{"description": " this sets up the public files route similar to how we set up the static files route and makes sure we handle the same special file names for the public folder that we did for the static folder closes: #10004 closes: #9706 closes: #9705 ", "commit_messages": " update serving of files from public folder to handle special chars ", "linked_issue_titles": " 9.1.5 path-to-regexp error with static routes with special symbols * ( +  404 if public/ filename contains a space ", "title": "fix public/ file name encoding"}
{"description": " the removes images from the clojure package to help resolve license issues from #15542 please feel free to remove inapplicable items for your pr. all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " remove test images  add script and .gitignore  add test helper to download images  remove unlicensed pic ", "linked_issue_titles": "", "title": "clojure package remove source images"}
{"description": " today, stmt matchers stop too early when parsing expression statements that begin with non-braced macro invocations. for example, fn main() { macro_rules! m { ($s:stmt;) => { $s } } id!(vec![].push(0);); //^ before this pr, the stmt matcher only consumes \"vec![]\", so this is an error. //| after this pr, the stmt matcher consumes \"vec![].push(0)\", so this compiles. } this change is backwards compatible due to the follow set for stmt. r? @eddyb ", "commit_messages": " macros: fix bug in statement matchers  add regression test ", "linked_issue_titles": "", "title": "fix bug in stmt matchers"}
{"description": " case 1. add a new type definition. checked compilation succeeds with --target es6 and --noimplicitany options. has correct naming convention has a test file with the suffix of  -tests.ts or -tests.tsx. ", "commit_messages": " added react-big-calendar module declaration  added test file  added tests cases  updated definitions  fixing moment import  reindent to 4 spaces  reindented to 4 spaces  fix author url ", "linked_issue_titles": "", "title": "add a new definition for react-big-calendar"}
{"description": " i'd like to be able to build android host tools and libraries on android. ", "commit_messages": " [cmake] make sourcekit respect link_libraries and library_search_directories  add_sourcekit_default_compiler_flags was invoking  _add_variant_link_flags and getting link flags but not actually using  the link_libraries or library_search_directories. in android builds,  this means that the correct libc++ is not being linked against.  [cmake] make sure icu libdir is correctly added to library_search_directories  the cmake variables ${sdk} and ${arch} are only set if  _add_variant_link_flags is invoked from add_swift_target_library calling  _add_swift_library_single. if you get to _add_swift_library_single from  add_swift_host_library, those variables will not be set and subsequent  linking will not find icu libraries. this was an issue when building  swift host libraries on android. ", "linked_issue_titles": "", "title": "add support for building swift host libraries and tools for android host"}
{"description": " make your pr against the master branch. follow the advice from the readme. avoid common mistakes. run tsc without errors. run npm run lint package-name if a tslint.json is present. the package does not provide its own types, and you can not add them. create it with npm run new-package package-name, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, and strictnullchecks set to true. ", "commit_messages": " add typing files for react-portal  add header to restrict tsc version to 2.1 ", "linked_issue_titles": "", "title": "new definition for react-portal 3.0 npm module"}
{"description": " this prepares data to be abi stable. primarily we are now letting the compiler do the work of any public inline accessors. our internal structure is defined to have certain paths marked as usable from inline and specific internal methods to be inlined, the reset of the public interface will defer to the wisdom of the compiler itself to understand which methods can and cannot be inlined. in most cases this results in a performance gain due to the conversion to private/internal types. however there is one known regression when appending a sequence that is not an array or data or unsafebufferpointer etc. one particular case that is a known regression is repeating. we plan on addressing this in a followup change that will add better inlines for this type of case (perhaps even boiling down to memset). resolves rdar://problem/33678210 ", "commit_messages": " [foundation] migrate data to a abi stable variant  this has one known performance regression; appending with a sequence (not an array, but something like a repeated<uint8>) is slower. we aknowlege this regression and plan to offer an update later that has a specialized variation of this api that optimizes to a memset/memset_pattern. this set of changes is limited to specifically targeting abi stability and inline characteristics of data and leaves that optimization as a future addition.  remove additional inlines  remove last public inlines ", "linked_issue_titles": "", "title": "swift 4.2 branch update data inlines"}
{"description": " updated the linear regression example documentation. the original documentation had duplicated work \"the\" and following sentence seemed choppy therefore modified to a more appealing tone. ", "commit_messages": " deleted duplicated word {the} and and made sentences more clear.  deleted duplicated word {the} and and made sentences more clear.  deleted duplicated word {the} and and made sentences more clear.  deleted duplicated word {the} and and made sentences more clear. ", "linked_issue_titles": "", "title": "doc cleaned descriptive paragraph for linear regression example"}
{"description": " these changes: verify only specific roles are able to edit settings limits editing of members flag by the owner role only clean up settings test @allouis let me know what you think about these. i had to create this new concept of unsafeattrsobject in controllers to be able to leave the permissions layer less coupled from controller implementation. it also only checks for single labs key right now, but think that's fine as it's only use case we care about. some more descriptions about the thinking in commit messages ;) another thing to consider here is somehow disabling toggling members for no owner in the ui. at the moment it just drops the error in top banner and disallows toggling. ", "commit_messages": " moved existing suite inside 'as owner' group  added test cases to check edit permission on settings endpoints  symetric changes to v2 test pt. 1  symetric changes to v2 test pt. 2  added test to demonstrate only owner being able to toggle members flag  permission check when editing settings lab.members  - passed additional function to permissions to allow custom selection of unsafe attributes due to settings object structure.  - fully implementing this check on controller level would be wrong architecturally and not that straight forward because we lack role data in \"frame\"  cleaned up test after moving default_content_visibility to it's own property ", "linked_issue_titles": "", "title": "added permission restrictions to editing members flag"}
{"description": " problem when you want to run a script located in the root dir in a complicated dir structure, when there is no fixed pattern for the distance of the sub-dir level  from the root dir. root-dir/ packages/ cool-package/ @some-scope/ some-package/ other-package/ scripts/ lerna.json package.json /root-dir/packages/cool-package$ node ../../scripts/some-script.js /root-dir/packages/@some-scope/some-package$ node ../../../scripts/some-script.js /root-dir$ lerna exec node ../{???}/scripts/some-script.js solution if there is a environment variable that contains the root path dir, it is possible to run scripts that are located in the root dir easily. /root-dir$ cross-env lerna exec node $lerna_root_path/scripts/some-script.js ", "commit_messages": " feat: add $lerna_root_path environmental variable for lerna exec  to make it easy to run a script that located in the root dir, in a complicated dir structurean, when  there is no fixed pattern for the distance of the sub-dir level from the root dir.  docs: add docs for $lerna_root_path environment variable ", "linked_issue_titles": "", "title": "root path dir environment variable"}
{"description": " fixes #3874, closes #3886. previously @wintercomes  tried to solve the issue but hasn't responded to one final query by @kmike. i completed the simple query. ", "commit_messages": " change download_maxsize logger level from error to warning  reverted maxsize warning log message ", "linked_issue_titles": " download_maxsize logger level shouldn't be error ", "title": "download_maxsize logger level changed from error to warning"}
{"description": " the padding after the magic signature value should be 12 bytes rather than 28 bytes. the other 16 should be placed after the title id pattern for nrrs. also amend the nroheader structure to reflect information on switchbrew. ", "commit_messages": " service/ldr: corrent padding within the nrr header layout  the padding after the magic signature value should be 12 bytes rather  than 28 bytes. the other 16 should be placed after the title id pattern.  service/ldr: amend layout of the nro header  the first word is just a padding byte, it's not an actual entry  instruction. also renames the rest of the entries according to  switchbrew. ", "linked_issue_titles": "", "title": "amend layouts of nro and nrr headers"}
{"description": " use kparsefullprecision to turn on this option in compile-time. the implementation of new option should have no performance impact if the flag is not used. implementation details the full-precision path tries to use fast-path if possible. if the criteria of fast-path cannot be met, it falls back to use strtod() to convert string. note that the parser still verify the json syntax of number as in normal-precision path. to fulfill the above requirement, the parser needs to backup the correctly parsed characters from stream (as some streams cannot read back). a helper template class genericreader::numberstream is designed for this. if full-precision is set, then backup is required, and a specialized numberstream will backup the characters during numberstream::take() into the genericreader::stack_. that stack_ was previously used only for storing the decoded characters in parsestring(). unit test added random numbers to test more cases for integer types and double. this experimental results show that full precision generate exact representation (no error), while normal precision parsing has maximum error of 3 ulp. denormal numbers () are not tested as it varies among platforms. implementations of strtod() in standard libraries may also simply flush denormal to zero. fix #120 ", "commit_messages": " add test case  fallback strtod() when not able to do fast-path  this shall generate best possible precision (if strtod() is correctly  implemented). need more unit tests and performance tests. may add an  option for accepting precision error. otherwise lut in pow10() can be  reduced.  add random tests for parsenumber  check \"fast path cases in disguise\" in strtod  refactor parsenumber for two modes (incomplete)  merge master and implement kparsefullprecision  optimize parsenumber()  fix parsenumber_integer test  compute error statistics of normal precision  update document for kparsefullprecisionflag ", "linked_issue_titles": " float point reading is lossy. ", "title": "parse json number to double in full-precision."}
{"description": " allows usage of more windows apis such as winhttp for networking components. microsoft reviewers: open in codeflow ", "commit_messages": " bump min. windows desktop supported version to 8.  use winver property to set _win32_winnt.  drop _win32_winnt in favor of winver.  place controlflowguard in the appropriate property sheet.  change files ", "linked_issue_titles": "", "title": "upgrade minimum supported version to windows 8."}
{"description": " docs(vi-mode): revamp readme and document settings fix(vi-mode): hide cursor-change logic behind vi_mode_set_cursor setting fixes #9570 ", "commit_messages": " docs(vi-mode): revamp readme and document settings  fix(vi-mode): hide cursor-change logic behind vi_mode_set_cursor setting  fixes #9570 ", "linked_issue_titles": " vi-mode changed the cursor shape; how do i disable it? ", "title": "hide cursor-change logic behind opt-in setting"}
{"description": " the proposal is to offer an uncomplicated example of distributed load execution. with just a few steps we have locust provisioned and distributed in the number of nodes provided, running in the aws cloud under ec2. 1. aws authentication export aws_access_key_id=aiaxxxxxxxxxxxxxxxxx export aws_secret_access_key=t9hyxxxxxxxxxxxxxxxxxxxxxxxxxxxx 2. configure your provisioning don't forget to provide the correct subnet name in the variable file define location and file of your locust plan script define the number of nodes to create variables.tf variable \"node_size\" { description = \"size of total nodes\" default = 2 } variable \"loadtest_dir_source\" { default = \"plan/\" } variable \"locust_plan_filename\" { default = \"basic.py\" } variable \"subnet_name\" { default = \"subnet-prd-a\" description = \"subnet name\" } 3. execute terraform cd examples/distribuited_execution_terraform/aws terraform init terraform apply --auto-approve 4. access ui click on the link below to access the ui: result exemple: apply complete! resources: 14 added, 0 changed, 0 destroyed. outputs: dashboard_url = \" leader_private_ip = \"10.17.5.119\" leader_public_ip = \"3.237.255.123\" nodes_private_ip = [ \"10.17.5.167\", \"10.17.5.39\", ] nodes_public_ip = [ \"3.235.45.218\", \"100.24.124.0\", ] 5. cleanup terraform destroy --auto-approve 6. more information terraform aws-get-started >> install-terraform-on-linux terraform module aws loadtest distribuited ", "commit_messages": " example of distribuited execution on aws ec2 using terraform  fix new line ", "linked_issue_titles": "", "title": "new provisioning example for distributed execution using iac - terraform/aws/ec2"}
{"description": " strip trailling comments from /etc/default/passwd like: minweeks=1 #minweeks=2 maxweeks=12  # maxweeks=8 which otherwise cause failures with \"failed to read /etc/default/passwd: too many values to unpack\" user module ansible version ansible 2.4.2.0 config file = /development/ansible/ansible.cfg configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python2.7/site-packages/ansible executable location = /usr/bin/ansible python version = 2.7.5 (default, may 31 2018, 09:41:32) [gcc 4.8.5 20150623 (red hat 4.8.5-28)] but present in the current 2.6+ releases too. example input file #ident  \"@(#)passwd.dfl 1.8     14/01/24 smi\" # copyright (c) 1989, 2014, oracle and/or its affiliates. all rights reserved. maxweeks=12 #maxweeks=8 minweeks=0  # minweeks=4 passlength=8 minalpha=1 # minalpha = 2 #whitespace=yes old code fails with valueerror: too many values to unpack import sys def get_password_defaults(): # read password aging defaults minweeks = '' maxweeks = '' warnweeks = '' for line in open(\"/tmp/default_passwd\", 'r'): line = line.strip() if (line.startswith('#') or line == ''): continue key, value = line.split('=') if key == \"minweeks\": minweeks = value.rstrip('\\n') elif key == \"maxweeks\": maxweeks = value.rstrip('\\n') elif key == \"warnweeks\": warnweeks = value.rstrip('\\n') return (minweeks, maxweeks, warnweeks) minweeks, maxweeks, warnweeks = get_password_defaults() fixed code strips trailing comments import sys import re def get_password_defaults(): # read password aging defaults minweeks = '' maxweeks = '' warnweeks = '' for line in open(\"/tmp/default_passwd\", 'r'): line = line.strip() if (line.startswith('#') or line == ''): continue m = re.match(r'^([^#]*)#(.*)$', line) if m:  # the line contains a hash / comment line = m.group(1) key, value = line.split('=') if key == \"minweeks\": minweeks = value.rstrip('\\n') elif key == \"maxweeks\": maxweeks = value.rstrip('\\n') elif key == \"warnweeks\": warnweeks = value.rstrip('\\n') return (minweeks, maxweeks, warnweeks) minweeks, maxweeks, warnweeks = get_password_defaults() ", "commit_messages": " strip additional comments from /etc/default/passwd  strip trailling comments from /etc/default/passwd like  minweeks=1 #minweeks=2  maxweeks=12  # maxweeks=8  which otherwise cause failures with \"failed to read /etc/default/passwd: too many values to unpack\"  fix carriage return typo in commit  yet another typo in commit ", "linked_issue_titles": "", "title": "strip trailing comments from /etc/default/passwd"}
{"description": " a lot of vulnerabilities are found. i updated the following packages for fixing it. jest babel-jest react-svg-loader lodash now: ", "commit_messages": " fix vulnerabilities  update jest configuration  add license header  fix lint warning of webpack configs  add svgo options to webpack configs ", "linked_issue_titles": "", "title": "update packages which has vulnerabilities"}
{"description": " please check if what you want to add to awesome-go list meets quality standards before sending pull request. thanks! github.com repo:  pkg.go.dev:  goreportcard.com:  coverage service link (codecov, coveralls, gocover etc.):  very good coverage note: that new categories can be added only when there are 3 packages or more. make sure that you've checked the boxes below before you submit pr: i have added my package in alphabetical order. i have an appropriate description with correct grammar. i know that this package was not listed before. i have added pkg.go.dev link to the repo and to my pull request. i have added coverage service link to the repo and to my pull request. i have added goreportcard link to the repo and to my pull request. i have read contribution guidelines, maintainers note and quality standard. ", "commit_messages": " add package btnguyen2k/olaf  merge with avelino/awesome-go:master  add database client and driver for azure cosmos db ", "linked_issue_titles": "", "title": "add rest client and database/sql driver for azure cosmos db"}
{"description": " this pr adds the following features: netdata saves the alarms log to /var/lib/netdata/health/health_log.db. this file is a machine readable text file. this file is auto-rotated by netdata (by default every 10000 entries the file is renamed to .old and a new one is created. these files (the primary and its .old) are loaded back when netdata restarts, so that the alarm log at the dashboard shows the alarm history properly. this also allows the alarm log and the alarms themeselves to have incremental ids. fixes #1036 other changes: added fping plugin. check #1122 - this requires a special version of fping, which currently can be downloaded from  netdata installer now runs with priority 19 (the lowest) and uses all the available processors to compile netdata. ansible playbook removed in favor of:  minor other improvements ", "commit_messages": " health log is saved and loaded back  add fping.plugin; fixes #1122  fixed minor printf formating issues regards signed numbers  added fping.conf and resize secondary fping charts  updated configs.signatures ", "linked_issue_titles": " alarm log should be saved and loaded back on netdata restart ", "title": "alarm log is saved and loaded back; added fping.plugin"}
{"description": " there are subtle differences between loki and sift query operators that we are trying to account for. this fixes some of those: sift allows querying arrays with $eq and $ne, which translates to $contains and $containsnone in loki the special case for $nin added false, which should be undefined. this also needed removing cloning the query args with json.parse/stringify, because undefined=>null, but it does not seem to serve a purpose anymore anyway. the fix for { $ne: true } now handles nesting levels > 2, e.g.  { \"foo.bar.baz\": { $ne: true } } the conversion to dotted query fields was producing { \"\": {} } for an empty object. ", "commit_messages": " fix(gatsby): fix loki special-casing for $ne: true  fix loki query operators ", "linked_issue_titles": "", "title": "fix loki query operators special casing"}
{"description": " to make the explore code more maintainable, i will refactor some controls, so first i need to move some files to the sub-component. this change will not change any codebase logic this change will not change the filename test plan it / cypress run ok requires db migration. confirm db migration upgrade and downgrade tested. ", "commit_messages": " wip  wip  wip  wip  move spec  wip  wip  remove unused file  wip  wip ", "linked_issue_titles": "", "title": "move metriccontrol and filtercontrol to sub-component"}
{"description": " backporting #47096 into v2.6. junos ansible version ansible 2.6.5.post0 (backport/2.6/47096 85b161065e) last updated 2018/10/17 10:12:01 (gmt -500) config file = none configured module search path = [u'/users/fxfitz/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /users/fxfitz/dev/ansible/lib/ansible executable location = /users/fxfitz/.pyenv/versions/ansible/bin/ansible python version = 2.7.15 (default, may 29 2018, 20:16:38) [gcc 4.2.1 compatible apple llvm 9.1.0 (clang-902.0.39.1)] n/a ", "commit_messages": " fix junos terminal regex (#47096)  fix junos stdout regex  change at hing  (cherry picked from commit fc341e01face3544c649b54015605f94597e069c)  changelog: adds fragment for junos fix terminal ", "linked_issue_titles": "", "title": "junos terminal regex prompt fix to v2.6"}
{"description": " these changes should take care of the final 7 post-migration errors triggered by ansible-test sanity --test docs-build. docs.ansible.com ", "commit_messages": " address toc-tree-glob-pattern-no-match errors  address include-file-not-found error  address 2.10 porting guide errors, add warning to page ", "linked_issue_titles": "", "title": "fix last 7 docs errors on post-migration test runs"}
{"description": " xref #32865 1 tests added / 1 passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry scope of pr this pr does a couple things to fix the performance of skew, and this also fixes the behavior of all the functions that have require_min_periods for small values of min_periods: clarify docs. name all sample methods uniformly, add a note to the caveat that users should in general be careful about using sample methods with windows fix bug in _apply that made us never go into the baseindexer control flow branch fix bug in _apply: pass window_indexer.window_size into calc_min_periods instead of min_periods or 1. we want the custom indexer window size there, so it's not clear to me why we were passing min_periods or 1 . details the algorithm itself is robust, but it defaults to sample skewness, which is why there was a difference between its output and numpy. to prevent misunderstandings, i clarified the docs a bit. we were also passing a wrong value to calc_min_periods, and we weren't going into the proper if branch, because we were checking the type of window instead of self.window. background on the wider issue we currently don't support several rolling window functions when building a rolling window object using a custom class descended from pandas.api.indexers.baseindexer. the implementations were written with backward-looking windows in mind, and this led to these functions breaking. currently, using these functions returns a notimplemented error thanks to #33057, but ideally we want to update the implementations, so that they will work without a performance hit. this is what i aim to do over a series of prs. perf notes no changes to algorithms. ", "commit_messages": " whitelist rolling skewness  doc: clarify that all sample metrics need careful treatment  clarify that any method that has sample before its name needs to  be used carefully with windows as this is almost never what the  user wants.  bug: fix self.window type check  also fix the value passed to calculate_min_periods  for custom baseindexer implementations.  tst: add test  doc: add whatsnew entry  cln: run black pandas ", "linked_issue_titles": "", "title": "support skew function for custom baseindexer rolling windows"}
{"description": " this implements a better (more python-style) list.sort. it's not really about that, though; it's about me figuring out a sane way forward for keyword-argument functions (and function metadata). but it's useful as is, and shouldn't break any existing code, so here you have it; i'm going to park it in my mind for a bit while sorting out the rest of the dict branch. ", "commit_messages": " this implements a better (more python-conformant) list.sort.  it's not really about that, though; it's about me figuring out a sane  way forward for keyword-argument functions (and function  metadata). but it's useful as is, and shouldn't break any existing  code, so here you have it; i'm going to park it in my mind for a bit  while sorting out the rest of the dict branch.  conflicts:  py/obj.h  py/objbool.c  py/objboundmeth.c  py/objcell.c  py/objclass.c  py/objclosure.c  py/objcomplex.c  py/objdict.c  py/objexcept.c  py/objfun.c  py/objgenerator.c  py/objinstance.c  py/objmodule.c  py/objrange.c  py/objset.c  py/objslice.c  a bit of stylistic cleanup (chose the wrong side during conflict resolution). ", "linked_issue_titles": "", "title": "a more python-style list.sort. and keyword arguments."}
{"description": " resolves #56377, very much along the same lines as #52073 this pr changes the shrink action to also be allowed in the hot phase after a rollover. as with #52073, a shrink in the hot phase must be accompanied by a rollover, and policy validation has been updated to check for this. reviewing commit-by-commit is best, there's a few relatively self-contained cleanup commits. ", "commit_messages": " getordefault with null is just get  map.of makes this immutable  and lets us drop the static initializer  refactor a bit  to allow the possibility that there could be more actions in the hot  phase that require rollover, rather than only just forcemerge.  allow shrink in the hot phase  as long as there's an accompanying rollover.  tidy up some whitespace ", "linked_issue_titles": " add shrink action to the hot phase ", "title": "allow shrink in the hot phase for ilm policies"}
{"description": " should fix #1439 (comment) - with automatic selection based on browser detection. ", "commit_messages": " tilelayer - globalcompositionoperation set once  this might fix a safari issue; it also avoids repeatedly setting the  [same] composition operation and saving/loading context states.  tilemaplayer: re-added secondary copy-canvas  - this change uses a secondary canvas and rectangle clearing instead of a  'copy' composition on the same canvas. this should hopefully address  the flickering issue in safari and safari mobile  tilemaplayer rendering double-copy  - memory optimization of delta-scroll shifting.  - the copy canvas is shared between all tilemaplayers  - the copy is done in segments to reduce the memory usage of the copy  canvas. currently this is a 1/4 ratio.  - device has the feature (by browser) check to see if bitblt works  - tilemaplayer will automatically enable the double-copy as needed  - device.whenready can be used to override the device value ", "linked_issue_titles": "", "title": "fix / double-copy for safari tilemap bug when rendering with delta scrolling"}
{"description": " excludeclass used to get called twice, which internally used to check if class is a innerclass, or an anonymous or local class. attaching the cpu profiler snapshot. with this change, we only check once and return if the class has to be excluded. ", "commit_messages": " optimized the create() method, excludeclass used to get called two times, changed it to one  fixed the create() method, and added support to disableanonymousandlocalclassserialization ", "linked_issue_titles": "", "title": "optimised the create() call for excluder typeadapterfactory"}
{"description": " update #7615 since it was a couple of months out of date. ", "commit_messages": " support this.prop = expr; assignments as declarations for es6 js classes  handle jsdoc tags on 'this' properties  update tests ", "linked_issue_titles": "", "title": "support this.prop = expr; assignments as declarations for es6 js classes &mdash; take 2"}
{"description": " another step toward #11638 this pr is a continuation of #12732. there were blas calls in the following cython files: weight_vector.pyx, cd_fast.pyx and    _k_means.pyx. there were also blas calls in the c file cholesky_delete.h. i decided to move (using fused types) the only function there to cython in arrayfuncs.pyx where there was a python wrapper for it. i added rot an rotg to the cython blas functions which i forgot in #12732 because i didn't check c files... i also removed linking to blas libs in some setups for modules which didn't call blas functions. the only remaining calls to bundled cblas in sklearn appear in tron.cpp, used in liblinear. they can't be replaced easily by calls to scipy cython blas because the calls to blas are not from cython files but from c files. ", "commit_messages": " replace cblas calls in utils/weight_vector  add rot & rotg to cython_blas  cholesky_delete -> cython to use cython_blas  add rot & rotg to cython_blas  rot & rotg cython_blas tests  cholesky delete fix  cblas to scipy cython_blas in linear_model/cd_fast  cblas to scipy cython_blas in cluster/_k_means  cleanup manifold setup ", "linked_issue_titles": "", "title": "continue moving from cblas to scipy cython blas"}
{"description": " addressed issue that can arise when user has libtool installed multiple locations or runs into conflict with homebrew installing /usr/local/bin/glibtool. $ find /usr /library -type f -name libtool -print 2>/dev/null /usr/bin/libtool /usr/local/bin/libtool /usr/local/src/libtool-2.4.6/libtool /library/developer/commandlinetools/usr/bin/libtool ", "commit_messages": " darwin: new procedure for indentifying installed homebrew dependencies  darwin: change the libtool check to glibtool  darwin: added doxygen to homebrew dependency installation  merging master into eosio_build_darwin_bullettproof  last merge before pr for branch eosio_build_darwin_bulletproof ", "linked_issue_titles": "", "title": "eosio build darwin libtool conflict addressed"}
{"description": " na_ontap_qtree: added new operation to modify qtree options. added new parameters: -- export-policy -- unix-permissions -- oplocks -- security-style na_ontap_gather_facts: new subsets: -- igroup_info -- qos_policy_info -- qos_adaptive_policy_info na_ontap_qtree na_ontap_gather_facts ", "commit_messages": " qtree new parameters and modify action  fixing pylint offenses  fixing shippable fails  added igroup_info gather_subset  added qos_policy_info / qos_adaptive_policy_info gather_subsets  pylint fixes ", "linked_issue_titles": "", "title": "qtree new params and modify operation / new subsets"}
{"description": " this pr enables checking exclusivity violations for no escape closures. for testing purposes it includes all the commits from #10360 plus one additional commit (73d7476) that is the only new content for this pr w/r/t 10360. ", "commit_messages": " [exclusivity] make helper functions to static. nfc.  make helper functions static and avoid defining one except when assertions  are enabled.  [exclusivity] relax enforcement for separate struct stored properties  relax the static enforcement of exclusive access so that we no longer diagnose  on accesses to separate stored structs of the same property:  takesinout(&s.f1, &s.f2) // no-warning  and perform the analogous relaxation for tuple elements.  to do this, track for each begin_access the projection path from that  access and record the read and write-like modifications on a per-subpath  basis.  we still warn if the there are conflicting accesses on subpaths where one is  the prefix of another.  this commit leaves the diagnostic text in a not-so-good shape since we refer  to the descriptivedeclkind of the access even describing a subpath.  i'll fix that up in a later commit that changes only diagnostic text.    rdar://problem/31909639  [exclusivity] update static diagnostic text for \"simultaneous\" accesses  remove the descriptive decl kind (since with subpaths it is not correct and  cannot represent a tuple element) and change \"simultaneous\" to \"overlapping\"  in order to lower the register slightly and avoid connoting threading.  for example, for the following:  takestwoinouts(&x.f, &x.f)  the diagnostic will change from  \"simultaneous accesses to var 'x.f', but modification requires exclusive access;  consider copying to a local variable\"  to  \"overlapping accesses to 'x.f', but modification requires exclusive access;  consider copying to a local variable\"  [exclusivity] remove erroneous no-error comments from tests. nfc.  copy-pasta strikes again!  [sil utils] move indextrienode into its own header in utils. nfc.  move indextrienode from deadobjectelimination into its own header. i plan to  use this data structure when diagnosing static violations of exclusive access.  [exclusivity] add analysis pass summarizing accesses to inout_aliasable args  add an interprocedural sil analysis pass that summarizes the accesses that  closures make on their @inout_aliasable captures. this will be used to  statically enforce exclusivity for calls to functions that take noescape  closures.  the analysis summarizes the accesses on each argument independently and  uses the bottomupipanalysis utility class to iterate to a fixed point when  there are cycles in the call graph.  for now, the analysis is not stored-property-sensitive -- that will come in a  later commit.  [exclusivity] switch static checking to use indextrie instead of projectionpath  indextrie is a more light-weight representation and it works well in this case.  this requires recovering the represented sequence from an indextrienode, so  also add a getparent() method.  [exclusivity] statically enforce exclusive access in noescape closures (#10310)  use the accesssummaryanalysis to statically enforce exclusive access for  noescape closures passed as arguments to functions.  we will now diagnose when a function is passed a noescape closure that begins  an access on capture when that same capture already has a conflicting access  in progress at the time the function is applied.  the interprocedural analysis is not yet stored-property sensitive (unlike the  intraprocedural analysis), so this will report violations on accesses to  separate stored properties of the same struct.  rdar://problem/32020710 ", "linked_issue_titles": "", "title": "diagnose exclusivity violations for noescape closures"}
{"description": " type: fix description: when this.props.data.values is undefined, many functions are broken because they expect a defined thread. this pr fixes the problem by returning null in case of undefined thread ps: i also made a small change in threadselector style ", "commit_messages": " fix(ui): fixed undefined thread  ref(ui): updated style ", "linked_issue_titles": "", "title": "return null when thread is undefined"}
{"description": " in pull_requests.md commit message: currently the fault filter will create a stats storage for each http request with \"x-envoy-downstream-service-cluster\" field set, which introduce unbounded memory usage. by adding a flag to control whether downstream server name should be traced in stats, envoy can be protected from downstream servers that send requests header setting different downstream cluster names. risk level: low testing: add unit test and integration test. docs changes: will change doc for fault filter ", "commit_messages": " add member variable  fix test  add comment ", "linked_issue_titles": "", "title": "add option to disable fault filter stats that trace downstream server name"}
{"description": " my solution about issue #5179 and i implemented part of todo about avoid forks in 'izz*' / 'izzq' / 'izzj'. ", "commit_messages": " removed some forks  a bit of refactoring  done test and fix bug ", "linked_issue_titles": "", "title": "#5179 and todo about avoid forks"}
{"description": " no whats new this is a 1.4.0 feature fix. ", "commit_messages": " longtable label allowed even when caption is none  longtable label allowed even when caption is none  longtable label allowed even when caption is none ", "linked_issue_titles": "", "title": "no label render in styler.to_latex if caption and \"longtable\""}
{"description": " original pull-request #19443 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix wrong parts in parts_to_do  update replicatedmergetreequeue.cpp  update replicatedmergetreequeue.cpp  addition to #15537 ", "linked_issue_titles": "", "title": "cherry pick #19443 to 20.8: addition to #15537"}
{"description": " in forms/checks-radios: give examples of the pure toggle checks and radios, without the button group class. show that these work fine without .btn-group, but still cross-reference it move the explanation from \"checkbox toggle buttons\" directly to \"toggle buttons\", as the mention of using button classes applies equally to the subsequent \"radio toggle buttons\" and \"outlined styles\" subsections. in components/button-groups: expand button group page description as it's not just single line, but vertical as well add more colour ... .btn-secondary is just dull and uninspiring new section to showcase \"checkbox and radio button groups\" add a mixed styles example add an example of vertical radio button group follow-up from #30650 (comment) which suggested porting some of the docs changes trialled in #28463 previews: checks & radios toggle buttons / button group ", "commit_messages": " keep checks/radio toggle buttons on topic  - give examples of the pure toggle checks and radios, without the button group class. show that these work fine without .btn-group, but still cross-reference it  - move the explanation from \"checkbox toggle buttons\" directly to \"toggle buttons\", as the mention of using button classes applies equally to the subsequent \"radio toggle buttons\" and \"outlined styles\" subsections.  expand button group description  as it's not just single line, but vertical as well ", "linked_issue_titles": "", "title": "separate button group out of checks/radios, expand button groups page"}
{"description": " this pr changes the configure.ac to require zmq version 4.x or newer, which is provided on debian and derivatives as package libzmq3-dev.  it also updates the release notes, build-unix.md, and zmq.md docs to reflect this change and add missing documentation. (whitespace changes are purely trimming of extraneous previous whitespace by my editor.) ", "commit_messages": " zmq: require version 4.x or newer of libzmq  zmq: update and cleanup build-unix, release-notes, and zmq docs ", "linked_issue_titles": "", "title": "require zmq version 4.x and update/cleanup zmq docs"}
{"description": " change this change adds a more fully functional search to the sqliteindex.  it implements both exact and substring matching across id, name, moniker, tags, and commands.  only one \"search\" string can be used at a time, either the generic query argument or one of the filters.  more extensive match options and filtering will be enabled in a future checkin. search is implemented by creating a temporary table to hold the results.  we iteratively insert results from specific searches on a given field and match type.  each successive search should be broader, as we will order the results given back to the caller in the order that they were performed.  thus for a substring query search that is not field specific, we perform exact match searches across all fields, then substring search across all fields.  in this way, if app a has a tag \"foo\" and app b has id \"foobar\", we will sort a higher in a search for \"foo\", but b higher in a search for \"fo\" (as id is searched before tags). as the search priority is driven solely by the order in which we perform searches, we can change the prioritization in the future simply be changing the order of the calls. testing tests are added to ensure that all search combinations (field x match type) can execute properly, and to ensure that searches are consistent with intentions. ", "commit_messages": " groundwork laid, algorithm sketched out  search functionality complete, working on getting results  query working, needs more testing ", "linked_issue_titles": "", "title": "implement search across all fields"}
{"description": " builtins.__import__ was missing a check to flag that if no dot was found in the __name__ of a module that isn't explicitly a submodule of a package then a relative import is incorrect. ", "commit_messages": " regression tests for bpo-37409  bpo-37409: fix builtin/importlib discrepancy for \"from . import *\" where no package exists  relative imports use resolve_name to get the absolute target name,  which first seeks the current module's absolute package name from the globals:  if __package__ (and __spec__.parent) are missing then  as a hail mary it uses __name__, truncating the last segment if  the module is any submodule rather than a package __init__.py  (which it guesses from whether __path__ is defined).  the hail mary should fail if there is no parent package (top level modules),  if __name__ is uninformatively '__main__' (-m entry points), or both (scripts).  that is, if both __name__ has no subcomponents and the module does not seem  to be a package __init__ module.  (bug silently used module as if package, aliasing unexpected objects.  note importlib contained an unaffected alternative __import__ implementation.) ", "linked_issue_titles": "", "title": "fix relative import with no parent"}
{"description": " this pr changes how #[inline] functions are translated. before, there was one \"master instance\" of the function with external linkage and a number of on-demand instances with available_externally linkage in each codegen unit that referenced the function. this had two downsides: public functions marked with #[inline] would be present in machine code of libraries unnecessarily (see #36280 for an example) llvm would crash on i686-pc-windows-msvc due to what i suspect to be a bug in llvm's win32 exception handling code, because it doesn't like available_externally there (#36309). this pr changes the behavior, so that there is no master instance and only on-demand instances with internal linkage. the downside of this is potential code-bloat if llvm does not completely inline away the internal instances because then there'd be n instances of the function instead of 1. however, this can only become a problem when using more than one codegen unit per crate. ", "commit_messages": " trans: only translate #[inline] functions if they are used somewhere.  adapt run-make/sep-comp-inlining test case to new behaviour  trans: allow base::internalize_symbols() to internalize #[no_mangle] symbols  adapt codegen-unit test cases to new behaviour ", "linked_issue_titles": "", "title": "only instantiate #[inline] functions in codegen units referencing them"}
{"description": " while the transform is running, it will be good to persist the running statistics to an index. this should not happen on each change, but at some determined periodicity. overview: the docs are going to be stored in the .data-frame-internal-1 index along with the configurations and the checkpoint documents stats will be associated to a transform via the transform.id, and the document id will be deterministic in containing the transform id pagination is now supported in the _stats call, and the associated transport, rest, action classes have been updated to reflect that. dataframefeatureset#usage has been refactored to account for the stats living in documents. closes #39994 ", "commit_messages": " [ml] add mappings, serialization, and hooks to persist stats  adding tests for transforms without tasks having stats persisted  intermittent commit  adjusting usage stats to account for stored stats docs ", "linked_issue_titles": " [ml] handle large number of dataframe transforms in internal logic ", "title": "periodically persist data-frame running statistics to internal index"}
{"description": " this restores the behavior of the old frontend - which would skip these post-pipeline actions wholesale. #33672 tried turning it on, but it turns out we were modeling objc header inputs as swift files, and so the first post-pipeline action to build the main module would suck in the bridging header and try to parse it as swift code. to tackle that last one, explicitly model objcheader as an input kind. this is just plumbing i'll need for later. rdar://68587228 ", "commit_messages": " [nfc] mark sourcemanager::getidforbufferidentifier const  model objcheader inputs  these inputs were previously modeled as swift files, which would lead to bizarre situations where parts of the pipeline expecting swift inputs actually wound up parsing objective-c.  add doesactionperformendofpipelineactions  for now, force the clang-based actions to skip the end of the pipeline. this restores the previous behavior of the frontend, but may not be desirable in the long run. for example, one may want to dump clang stats after running an -emit-pch job, but that is impossible without forcing the end of the pipeline to be more tolerant of objcheader/modulemap-only inputs.  rdar://68587228 ", "linked_issue_titles": "", "title": "-disable end of pipeline actions for objc actions"}
{"description": " ... and added skflow to default import of contrib. builds on top of #1829 ", "commit_messages": " added datasets package, added boston and iris datasets. (prep for removing hard dep on sklearn)  correct datasets loading to match sklearn output  add first version of sklearn-related functionality when sklearn is not found.  changing skflow modules to use _sklearn for loading sklearn tools  bump size of histogram test to medium  moved datasets into filegroup and added skflow by default import in contrib  correct more imports in ops/ to use full paths  adding csv files to manifest for pip  fixing skflow imports to use global import for tensorflow ops  add skflow import by default to contrib, to make tf.contrib.skflow work ", "linked_issue_titles": "", "title": "fix imports to use specific tf modules"}
{"description": " this slightly changes the behavior of scrollpane#scrollto centering, and removes scrollpane#scrolltocenter. scrollpane#scrolltocenter was equivalent to scrollpane#scrollto(x, y, width, height, false, true); ", "commit_messages": " add centering to scrollpane.scrollto; fix #2561  scrolltocenter(x, y, width, height) is now equivalent to scrollto(x, y, width, height, false, true);  update changes, reflect scrollpane#scrollto change ", "linked_issue_titles": "", "title": "add another scrollpane#scrollto; fix #2561"}
{"description": " fixes #25987 as mentioned in-person with @mhegazy, since our goal with the index signature was to just squelch a class of errors in js, this accomplishes the same thing without the unfortunate side effect of mangling our inferences. this has the fortunate side-effect that the meaningless index signatures are no longer present in quickinfo and the like. these accesses are also now marked in noimplicitany mode now - which i'd argue is a correct thing to do. that is the breaking change referenced in the pr labels, however in practice it's unlikely to break much (and when it does it's probably desirable!) as js codebases using noimplicitany are relatively rare. ", "commit_messages": " remove index signatures from js literals, use an object flag to indicate errors should be ignored instead  add focused test on the keyof problem  fix fourslash test ", "linked_issue_titles": "", "title": "flag js literals and ignore assignments/accesses to invalid props, instead of adding an index"}
{"description": " passing by values means extra copies + extra atomic addref and release. pass by ref instead. this was a quick find/replace, inspect, and see if we compile deal. i didn't bother trying to catch everything in every view manager, and just fixed the main interface. much of this will likely get nuked when abiviewmanager becomes the sole source of goodness. microsoft reviewers: open in codeflow ", "commit_messages": " pass xamlview's through reactuwp view managers by const ref  passing by values means extra copies + extra atomic addref and release. pass by ref instead.  this was a quick find/replace, inspect, and see if we compile deal. i didn't bother trying to catch everything in every view manager, and just fixed the main interface. much of this will likely get nuked when abiviewmanager becomes the sole source of goodness.  change files  yarn format ", "linked_issue_titles": "", "title": "pass xamlviews through reactuwp view managers by const ref"}
{"description": " closes #20878 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " update warnings on attribute access  update warnings on attribute access ", "linked_issue_titles": " update docs on reserved attributes ", "title": "fixes update docs on reserved attributes #20878"}
{"description": " freeze those objects: internal objects vm app element comment listener app.prototype document.prototype element.prototype comment.prototype listener.prototype build-in objects object array object.prototype array.prototype string.prototype number.prototype boolean.prototype error.prototype date.prototype regexp.prototype once the object is frozen, there has no chance to unfreeze it. in addition, because we use strict mode in the js bundle, modify those frozen objects will throw a typeerror. ", "commit_messages": " + [jsfm] add test case for strict mode  * [jsfm] freeze the prototype of build-in objects  * [jsfm] istanbul ignore ployfills  + [jsfm] add test case for freezeprototype ", "linked_issue_titles": "", "title": "freeze the prototype of intrenal and build-in objects"}
{"description": " this cherry-picks from main changes for the winsdk module to the 5.4 release branch.  this only impacts the windows path and should be safe for the platform as it only changes how headers are mapped into the clang importer. ", "commit_messages": " add winsdk.winsafer  (cherry picked from commit 281ae3c2a68e2fbda7d6dd560bbd9dfaa08679f1)  platform: add directx mappings  add the module definitions for:  - direct3d v12  - xaudio 2.9  - xinput 1.4  additionally, add the following, unusable modules:  - dxcore  dxcore requires c++ support (c++11 or newer to be precise) and is not  yet available until c++ interop can be made to work fully.  (cherry picked from commit c5bc227ac7d88538bc4980e92620597495216ec1)  winsdk: add xaml hosting submodule  this exposes idesktopwindowxamlsourcenative interface, which is used for embedding winui xaml controls into win32 apps  (cherry picked from commit 6970054b63168999b1236fd1e34021dee19745f7)  platform: add a cplusplus requirement to xaudio  in some cases when building the xaudio module, we would end up going  down c++ paths:    c:\\program files (x86)\\windows kits\\10\\/include/10.0.17763.0/um/xaudio2.h:61:26: error: 'uuid' attribute is not supported in c  interface __declspec(uuid(\"2b02e3cf-2e0b-4ec3-be45-1b2a3fe7210d\")) ixaudio2;  ^  <module-includes>:29:10: note: in file included from <module-includes>:29:  ^    although this works with newer sdks, it does not work with older sdks.  filter out the module for the time being with a requirement on c++.  this should be possible to use with -enable-cxx-interop.  (cherry picked from commit 715d81cf269ba77b9e580924621c1df97487f0e6)  winsdk: use xinput instead of xinputuap  the uap variant is included into the winsdk module which then fails to  run.  adjust the linkage.  (cherry picked from commit 5bfbaadb4377ab19ffa9d5821e95bd475406d5d7)  platform: add activex module  add the activex module to the windows sdk.  this is needed for the  ipropbag2 interface.  (cherry picked from commit fc8cd455d0084953e3d7244c8e20eea34385939e)  platform: add direct3d11 module  this adds the direct3d v11 module for windows.  this is required to gain  access to the dxgi interfaces, which homes the dxgiswapchain interface.  (cherry picked from commit 86a8b1b4dc0e40a2d97d19a01b5abd95ff6ff7ff)  platform: extend the d3d v10 module  add the extensions for the direct3d v10 api to enable access to the  newer dxgiswapchain interfaces.  additionally, correct the linking to  ensure that we pick up the v10 version of the import library.  (cherry picked from commit e508b1ab1481555dc863cd42026d9c697ade4c1e)  platform: add dxgi1_6 to the direct3d module  there is no usermode header which has the dxgi1.6 interfaces included  unfortunately.  this adds the interfaces to the module which is required  for idxgiadapter4 interface.  (cherry picked from commit 4084f7a5a667ae11bb04a30ab8e7bcfdb97c45b9)  platform: add hlsl compiler to the winsdk modulemap  the directx subsystem may require access to the hlsl compiler for  building the shaders before uploading to the gpu.  this is adds to the  modulemap the d3dcompiler module to get access to the compiler.  (cherry picked from commit 997cb0f6719c3f487795f1f7487c6364e1dd44e1)  platform: add dxgidebug.h to _dxgi module  the debug header is used for enumeration of certain dxgi interfaces  related to debugging of the pipeline.  add this to gain access to the  interfaces and some of the global guids associated with it.  (cherry picked from commit 66a9ae44b43450c2db9bdb89d25480166cf20fce) ", "linked_issue_titles": "", "title": "update winsdk module for latest changes"}
{"description": " needs to applied to the docker environment after #236 is submitted, before the ruby docker images are rebuilt, so that the tests are run with the correct flags ", "commit_messages": " updates the ruby dockerfile to copy the cacerts directory from the docker host  updates/adds test commands  - the client test gets new, necessary flags  - adds a prod test command that explicitly sets the ssl_cert_file to pick up  certs that the c core can load successfully.  adds a func for installing the googles's roots.pem  roots.pem is not added to source control, but is instead saved on gcs.  the func copies roots.pem to docker host, to a location that can referenced by  dockerfiles using the add directive ", "linked_issue_titles": "", "title": "grpc tools update ruby to run prod tests"}
{"description": " this addresses #494. this diff includes multiple fixes and workarounds to make the current master build and pass tests on windows 7 & 10 without cuda. we will be putting up official windows ci as soon as possible and it will make it easier to maintain windows compatibility. all credit goes to @peterjc123 who have been spending a lot of effort maintaining the windows build for a long time. ", "commit_messages": " don't override cmake_generator in windows  hide the unknown headers for win32  disable funsion_compiler for windows  add at_api to tensorgeometry.h  fix test cases for windows ", "linked_issue_titles": "", "title": "fix issues with windows 7 & 10 cpu build"}
{"description": " closes #8508 i made more changes than absolutely necessary for documenting this. it's a bit more complete and it reads a more similar to pd.read_csv() ", "commit_messages": " fix typo  update to_csv docstring ", "linked_issue_titles": " allow writing to s3 paths ", "title": "document s3 and gcs path functionality of dataframe.to_csv()"}
{"description": " this major change to slate removed change and folded all of its functionality into the editor controller. i have updated the slate definitions to reflect this, included doc comments for the new commands, and added additional tests. i've also applied the respective changes to the slate-react package. this is quite a large change so any feedback is appreciated add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: pr merge increase the version number in the header if appropriate. ", "commit_messages": " implement new 'command' logic for editor  merge remote-tracking branch 'upstream/master'  add tests for commands  fix slate-react tests  revert unintended change  version number ", "linked_issue_titles": "", "title": "update typings to reflect new command structure"}
{"description": " added support for amd require / es6 import to the text-encoding typed definition. it falls under case 2: improvement to existing type definition. here you can find some context for the change. ", "commit_messages": " merge remote-tracking branch 'refs/remotes/definitelytyped/master'  support amd require / es6 import ", "linked_issue_titles": "", "title": "support amd require / es6 import for text-encoding"}
{"description": " iterate through custom packages locations instead of assuming packages/* my project has custom packages locations and all needs canary publish. see also #875 tests have been updated ", "commit_messages": " fix: custom packages location used with publish --canary (#875)  include build in git ", "linked_issue_titles": "", "title": "use all packages locations when resetting canary changes"}
{"description": " following discussion in #11398, changing obj to the object names may avoid confusion. ", "commit_messages": " [mrg] fix misleading doc in contibuting guidelines  the estimator object is that which implements fit, not the one returned by fit.  changed obj into predictor, estimator... ", "linked_issue_titles": "", "title": "clearer doc in contibuting guidelines"}
{"description": " cab is a wrapper around ghc-pkg and cabal. this pr adds autocompletion for cab if the command is present. ", "commit_messages": " added cab autocompletion to the cabal plugin.  cab is a wrapper for ghc-pkg and cabal that provides some nice features  like listing outdated packages.  see  program. ", "linked_issue_titles": "", "title": "add cab autocompletion to the cabal plugin"}
{"description": " as discussed on  from ", "commit_messages": " v4l2: fix incorrect pool sizing  v4l2: add option to disable enum_framesizes.  gstreamer's handling of a driver that advertises  v4l2_frmsize_type_stepwise to define the supported  resolutions is broken. see bug    optional parameter of gst_v4l2src_is_broken added.  if non-zero, the driver claims not to support that  ioctl, and gstreamer should be happy again (it  guesses a set of defaults for itself). ", "linked_issue_titles": "", "title": "fix regression, and gstreamer workaround"}
{"description": " fixes #968 ", "commit_messages": " server: upgrade browserify preprocessor to 1.0.1  server: rename preprocessor config to file object  server: normalize path when removing preprocessor file  server: only add one listener for file:updated in socket  previously, a listener would be added for every spec file opened, linearly increasing how many watched:file:changed events would be fired when a single file changed ", "linked_issue_titles": "", "title": "fix firing 'watched:file:changed' twice on change"}
{"description": " we would like to know when a route update is loaded to envoy. this pr adds a stat to indicate the same. commit message: add config reload time stat. risk level: low testing: added docs changes: updated release notes: updated ", "commit_messages": " add test for priority  add config reload time stat  format ", "linked_issue_titles": "", "title": "add config reload time stat for rds"}
{"description": " what do these changes do? this pr thread is identical to  as the source branch was mis-deleted, i have to reopen a pr. ", "commit_messages": " add noisy network  distributional q-learning in dev  add distributional q-learning  validated rainbow module  add some comments  supply some comments  remove redundant argument to pass ci test  async replay optimizer does not need annealing beta ", "linked_issue_titles": "", "title": "add noisy network and distributional q-learning to implement rainbow"}
{"description": " closes #7738 now, when you have multiple cursors or selections and press esc, the single cursor or selection that will remain is the original cursor/selection ", "commit_messages": " reduce multiple cursors/selections to the first, original, cursor/selection  :tulip: change the spec for consolidateselections ", "linked_issue_titles": " feature request: pressing `esc` on multiple cursors returns you to original cursor location. ", "title": "pressing esc on multiple cursors returns to original cursor or selection"}
{"description": " set environment variables: ndk_root and cocos_console_root. because there is not api in python to set system environment variables, so i add it in ~/.bash_profile on linux and mac os x, and modify register table on windows.  any other elegant way? after setting environment variables, any way to make it take effect immediately? i want to use the environment value to use cocos-console after install.py return, like this ./install cocos project new ... i wanted to use os.system() to do it, but found it would create a new process. ", "commit_messages": " add install.py  check validation of ndk root ", "linked_issue_titles": "", "title": "create install.py to set environment variables needed by cocos2d-x"}
{"description": " description: revert unnecessary changes to platforms during previous device registry pr. dr uses device_info now instead of device. checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " revert tank_utility  fix soundtouch  fix plex  fix emby  fix radiotherm  fix juicenet  fix qwikswitch  fix xiaomi miio  fix nest  fix tellduslive  fix knx ", "linked_issue_titles": "", "title": "revert changes to platforms using self.device"}
{"description": " since i was having trouble with the minifier (part of our codebase minifies correctly only with uglify-es, part only with babeli), i updated the minifier-js package to report which backend was used for minification to ease debugging. ", "commit_messages": " remove outdated fallback.  report used minifier.  this allows packages such as standard-minifier-js to generate statistics per minifier, which is useful to analyze how often the fallback is needed. ", "linked_issue_titles": "", "title": "minifier js report used minifier"}
{"description": " removes our dependency on css.escape and ensures we always rely on postcss-selector-parser's built-in escape handling for any situations where we need to escape anything to avoid subtle inconsistencies. ", "commit_messages": " update postcss-selector-parser  use postcss-selector-parser class escape handling  switch from css.escape to cssesc  this is what postcss-selector-parser uses internally, best to rely on the same escaping logic everywhere.  remove dependency on cssesc  makes it easier to guarantee that our escape behavior stays in line with postcss-selector-parser if their internal implementation ever changes. ", "linked_issue_titles": "", "title": "leverage built-in escape handling in postcss-selector-parser"}
{"description": " description fixes #18338 - fixed an issue with trailingslash: true adding a slash to the end of an external link. after <h1 class=\"home_title__3djr7\">welcome to <a href=\" <h1 class=\"home_title__3djr7\">welcome to <a href=\" <h1 class=\"home_title__3djr7\">welcome to <a href=\" <h1 class=\"home_title__3djr7\">welcome to <a href=\" ", "commit_messages": " fix: no slashes for external links  test: added test code ", "linked_issue_titles": " trailing slashes appends slashes to external links ", "title": "issue #18338 - don't add a trailing slash to external links"}
{"description": " closes #14759 this is my first pr here. not sure about the missing entries in api reference. need some guidance on that. the same doubt about the best place to put the xref in computation.rst and timeseries.rst thanks. ", "commit_messages": " documentation of groupby resample expanding  removing foo ", "linked_issue_titles": " doc: document groupby.resample/rolling ", "title": "add section on groupby().rolling/expanding/resample"}
{"description": " changes the vertical alignment of inputs and buttons to be middle rather than baseline, which allows for stable alignment across all browsers. (e.g.  the search and inline form fields and buttons match exactly.) also fixes display of checkboxes in ie9+ by removing round corners, and fixes checkbox labels across all browsers, which were off from the left-aligned field label by 1px. ", "commit_messages": " fixes off-by-1px between checkbox and form label (all browsers)  clears border-radius on checkboxes because they look bad on ie  makes inputs and buttons align middle so they line up in all browsers  rebuild *.css ", "linked_issue_titles": "", "title": "form alignment in ie and others"}
{"description": " original pull-request #13386 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " done  fix build  update ownsplitchannel.cpp  fix style  deadlock in textlog ", "linked_issue_titles": "", "title": "cherry pick #13386 to 20.6: deadlock in textlog"}
{"description": " closes #26122 1 test added passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry added ", "commit_messages": " add is_coerce arg to array_to_datetime_object  add one test  add whatsnew note ", "linked_issue_titles": " unexpected 'to_datetime' behaviour for datetime strings with different offset in 'arg', when errors='coerce' ", "title": "add is_coerce argument to func array_to_datetime_object (gh26122)"}
{"description": " adds useslider hook and updates the sliderunstyled component's logic to be compatible with the other unstyled components. i don't expect there to be breaking changes in the @mui/material's slider component. one change that i needed to make is to handle the component prop in the slider component, as it differs to how it is implemented in the sliderunstyled (the component prop just changes the tag, the components.root replaces the whole root element, for example the styles won't be applied). in a follow up pr i plan to address the todos that came up while converting the code to the hook which is written in typescript. ", "commit_messages": " [sliderunstyled] update components & componentsprops  [useslider] add hook (wip)  proptypes & docs:api ", "linked_issue_titles": "", "title": "add useslider hook and polish"}
{"description": " our application has tens of chunks. we don't need a prefetch for all files. in addition, my laptop started to heat up strongly in developer mode since this observer exists. and most important: chrome doesn't like excessive preload. look how the console looks on zeit.co (pic rel). ", "commit_messages": " restoring not working mouse event  restoring possibility of conditionally switching off the prefetch ", "linked_issue_titles": "", "title": "restoring possibility of conditionally switching off the <link/> prefetch"}
{"description": " @dt-bot follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). < < increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " fix type definition of spreadsheetapp.getactive  fix type definition of spreadsheetapp.getactivespreadsheet ", "linked_issue_titles": "", "title": "modify type definitions of functions which can return null"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " an assumption was made that the string indexable collections new with xrm 9 applied to all collections.  they don't.  i've have added seperate collection index to be able to allow for the string indexability of the new collections.  added back accidently removed overlaod  f ", "linked_issue_titles": "", "title": "added new collection interface defined via the client web api"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " adding new options for nodemailer-mailgun-transport 1.4  adjusting tests to use host option ", "linked_issue_titles": "", "title": "@types/nodemailer-mailgun-transport added options for 1.4"}
{"description": " closes #17361 ", "commit_messages": " respect mut in &mut str in astconv  closes #17361  add regression test for issue #17361 ", "linked_issue_titles": " can't return `&mut str` (\"values differ in mutability\") from a method when implementing a trait for `str` ", "title": "don't throw away mutability of &mut str in astconv"}
{"description": " fixes #9830. ", "commit_messages": " librustc: don't ice on packed structs in statics.  update test for packed structs to also test being placed in statics. ", "linked_issue_titles": " static instance of #[packed] struct makes rustc fail ", "title": "don't ice on packed structs in a static."}
{"description": " removes the blocking flag from serve.init(), replacing it with a time-based timeout defined in ray.serve.constants. n/a i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  only ray serve tests were run. ", "commit_messages": " removed blocking flag from serve.init().  added timeout parameter to block_until_http_ready().  moved sleep to end of loop.  removed retries and exponential sleep from block_until_http_ready. moved default timeout to ray.serve.constants ", "linked_issue_titles": "", "title": "remove blocking flag from serve.init()"}
{"description": " as per title, this pr attempts to improve react's textnode update/patch performance by accessing the firstchild.nodevalue. this can have a big impact on performance where textnode updates are frequently changing. this pr also removes the polyfill for element.textcontent as this is no longer required for ie9+. no new tests were added to this pr as the test coverage already covers this use-case, let me know if you think this is wrong and i can add tests for use cases that may not have been covered given the changes. ", "commit_messages": " added logic to apply an update using node.firstchild.nodevalue, which is a more performant text update operation. also removed the ie8 polyfill for textcontent (ie8 is no longer supported?).  removed un-needed typof check on lastcontent and ensured updatetextcontent gets called with same argument count ", "linked_issue_titles": "", "title": "settextcontent should attempt to set textnode nodevalue where possible"}
{"description": " had the same json deserialization problem as in issue 1559; now that it's fixed, i had a look at the code and noticed that test code was left in. also, small typo fix. ", "commit_messages": " removed leftover test code.  fixed typo: managedtexurelist -> managedtexturelist ", "linked_issue_titles": "", "title": "issue 1559 and typo fix"}
{"description": " closes #4009 added a processcreation folder in operating system folder. it contains implementation in c. ", "commit_messages": " add process creation algo  update readme.md  update readme.md ", "linked_issue_titles": " add new algorithm in c for child process creation in linux operating system ", "title": "add child process creation code in linux operating system"}
{"description": " this pr fixes #6574. sometimes users have the expectation that calling map on a homogeneous tuple will create a tuple type of the same size, but with the element types appropriately mapped on. for instance: interface person { name: string; } declare let couple: [person, person]; // should have type '[string, string]', but currently has type 'string[]'. let names = couple.map(p => p.name); now that we have this-types, we can actually enable overloads that can only apply if the target object (the thing being dotted on) has a specific type. i'd like to hear feedback from the team (especially @sandersn & @ahejlsberg) about whether this is a good idea. this fulfills a lot of users' expectations, but they could instead just augment array<t> with these overloads if they're interested. also tagging @philpee2 who asked me about this yesterday. ", "commit_messages": " added test.  accepted baselines.  added overloads for 'map' on tuple types.  accepted baselines. ", "linked_issue_titles": " tuple types and map ", "title": "add overloads for 'map' on tuple types"}
{"description": " second try, replaces #6373, 9600 baud tested by @jason2866 (thanks a lot) improvements to tasmotaserial leverage attachinterruptarg() from stage and pre-2.6, removes the need for multiple interrupt functions, saves 224 bytes of iram pre-compute m_bit_start_time time for first byte, instead of computing it in the interrupt handler removed optimistic_yield(1) from the interrupt handler, optimistic_yield is not in iram, i'm not sure it's safe to call it from the interrupt handler. anyways, low baud (9600) should use the nw option. changed while (esp.getcyclecount()-start < wait) to while (esp.getcyclecount() < wait + start), the addition gets out of the loop (minor change) removed first digitalwrite(m_tx_pin, high);, if the output is not already in high mode then it's too late to change it (am i missing something?) when sending, re-enable interrupts at the beginning of stop bits, instead of after stop bits. total time won't change but it allows other interrupts to be served earlier i did lots of tests with zigbee and discovered that sometimes bytes were misread. what happens is that when receiving a row of bytes, interrupts are disabled for each byte, re-enabled after stop bit and disables again for next byte. this short window would allow other interrupts to fire and delay enough the serial interrupt that the first bit would be missed. i changed so that the interrupt handler wait for 3.5 stop bits if the next message is already there. if so it continues to read it without lifting interrupts, if not it re-enables interrupts. overall i saw a huge improvement in reliability when receiving at 115200. overall iram saving: 280 bytes theo, i didn't change the tasmotaserial verion number. i hope i did not change the behavior at lower baud rate, this might need some more testing. the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core 2.3.0, 2.4.2 and 2.5.2 the code change pass travis tests. your pr cannot be merged unless tests pass i accept the cla. ", "commit_messages": " change improve reliability of tasmotaserial at 115200 bauds and reduce iram usage for stage/pre-2.6  tasmotaserial 2.3.5 ", "linked_issue_titles": "", "title": "reduce iram usage by 280 bytes and improve reliability at 115200 bauds (v2)"}
{"description": " relates to #3954. in addition to changing exceptions types returned to be more explicit, this pull incorporates the following changes: adds a new assertraisesregexp to util/testing.py to port the assertraisesregexp helper from 2.7+ unittest cleans up stats/common. fix up initial assertions in tseries.offset._cached_range that were all off + fix the test cases which were all just raising typeerrors because they were calling with the wrong arguments. changes the example timezone from asia/beijing to asia/hong+kong b/c asia/beijing is not supported by pytz. any tz-aware : tz-naive comparison fails with typeerror, as will mismatched, localize, etc. calls. changes sparsearray indexing error messages to match tuple message for completeness. improves the window check in ols. after you all say it's okay to merge, i'll update the docs to reflect changes. ", "commit_messages": " enh/tst: add assertraisesregexp to util/testing  port of assertraisesregexp from python 2.7 unittest  cln: change merge to raise valueerror on overlapping indices  tst: change exceptions to appropriate cases for tests involving merge.  cln: change internal error from exception to pandaserror  cln: stats/common: replace bare exceptions  replace with more descriptive exceptions  tst: add test case for unrecognized cluster  cln: cleaner window check in ols + add error message  cln: cleanup stats/common and change exception type  made it explicit that cluster_type checks if it's a window type first.  changed get_cluster_type to be clearer as well.  replaced the exception raise with a valueerror raise.  tst: add test case for bad window_type  cln: pandas/sparse: replace bare exceptions  replace with more descriptive exceptions  cln: sparsepanel: replace bare exceptions  cln: sparseframe: change bare exceptions  cln: sparseseries: change bare exceptions  cln: sparsearray: change bare exceptions  harmonize capitalization of sparsearray indexerrors  added note about possible unreachable code fragment  tst: add test cases for sparsearray  tst: add sparseframe test cases for the improved exceptions  cln: tools/tile: replace bare exceptions  tst: add test for new valueerror in tile tests  cln: pandas/tseries: replace bare exceptions  replaces bare exceptions with more descriptive ones.  cln: tseries/frequencies: replace bare exceptions  cln: tseries/index: replace bare exceptions (mostly tz-aware + tz-naive  typeerror stuff)  cln: tseries/offsets: replace bare exceptions  cln: tseries/tools: replace bare exceptions  cln: remove exclamation points from error messages.  tst: add more descriptive tests for tseries.  tst: change tests in tseries/test_offsets to be more descriptive  tst: update tests for exceptions from frequencies.py  tst: make more exception tests in tseries/test_timezones explicit  tst: change test of ole2datetime to use explicit exception check  tst: fix up tests in tseries/test/test_daterange  in particular, fix up a bunch of test cases that were failing because  of typeerrors/clearly not changing when _cached_range changed type  signature.  cln: use timezone natively supported by pytz  apparently asia/beijing is actually used in china, but it's  not natively supported in timezone software. see for example:    that said, example timezone in docs should at least work, so  that's the reason for the change  cln: make aware vs. naive always a typeerror ", "linked_issue_titles": "", "title": "change bare exceptions pt 1"}
{"description": " replaces the solution merged with #1327 a better solution. handles the problem and guides the user (dev). see updated discussion in #1231 ", "commit_messages": " fix(generator):  #1231 'generate container' produces unnecessary return  fix(generator): improved solution to 'generate container' produces unnecessary return #1327  merge dev into useless-return ", "linked_issue_titles": "", "title": "'generate container' produces unnecessary return - better solution"}
{"description": " fixed the bug from #5407 and #2603. the function matchesfilter returned true if the file's relative path or its basename matched the given regular expression. i adjusted this to only test the basename for a match if the base option is not set (or set to .). i added the test pack should include files only ignored in other directories. two tests were failing on my local build, but they were also failing before making the changes. all other tests were green. ", "commit_messages": " test: test .gitignore files restricting to their own subdirectories (#2603)  currently, .gitignore statements extend to the parent directory. as such, even files in different  directories, not targetted by that specific .gitignore file are ignored when packaging.  fix: don't filter files by basename  files are filtered by basename, even when being in a subdirectory  closes #2603, #5407 ", "linked_issue_titles": "", "title": "restrict .gitignore to their own subdirectories"}
{"description": " closes #67. yes i know i should keep cleanup separate from new features. ", "commit_messages": " these parens are extraneous.  start of --pager support.  change all printf()s to fprintf()s and all putchar()s to fputc()s.  no, these should not be macros.  pclose() out_fd if we're using a pager. ", "linked_issue_titles": " pager support (for paging through colored results) ", "title": "random cleanup, add --pager option."}
{"description": "", "commit_messages": " note performance aspects of using multiple accumulators  add accuracy notes  show where each footnote applies  better wording for the incremental loop costs  improve wording for the accuracy paragraph  add test cases  show subtest parameters in hex.  improve comment  remove doubt by computing reference values directly  add documentation ", "linked_issue_titles": "", "title": "add docs and tests for hypot()"}
{"description": " drag gesture recognizer now accepts all pointers when any pointer is accepted. this is useful when the accepted pointer is accepted by default, i.e. when all other arena memebers has quit (been disposed). fixes #82784. i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " basic test  fix ", "linked_issue_titles": " drag gesture crashes when one of the 2 pointers wins by default and is then released ", "title": "drag gesture recognizer accepts all pointers when any pointer is accepted"}
{"description": " based on: #53588 & #53519 but upgraded to popper v2 as requested note: i upped the minimal node version add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " upgrade react-datepicker to v4 and popper v2  fix: use arrey  fix: set minimal typescript version ", "linked_issue_titles": "", "title": "upgrade react datepicker v4 & popper v2"}
{"description": " this should get our unit tests going again. also it fixes bad clean of our source tree (which left xbmc/addons/addons.a and object files stale) because the exclude pattern also applied for xbmc/addons and not only the addons subdir (thx @wsnipex for the correct syntax). i have compile tested this with and without unit tests already on jenkins and have now kicked a build for verifying the clean issue. once it looks good i will merge this with out further jenkins torture. this partly reverts: 3764f03 ", "commit_messages": " [buildsys/make] - remove main.a from the list of directory_archives for preventing duplicate linkage when compiling unit tests  [jenkins] - ensure that only the path workspace/addons is excluded from the clean - before it excluded workspace/xbmc/addons aswell which left the stale addons.a file around ", "linked_issue_titles": "", "title": "fixed duplicate main function during linkage of unit tests"}
{"description": " description what does your pr belong to? website snippets general / things regarding the repository (like ci integration) tests types of changes bug fix (non-breaking change which fixes an issue) enhancement (non-breaking improvement of a snippet) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to change) checklist: my code follows the code style of this project. my change requires a change to the documentation. i have updated the documentation accordingly. i have checked that the changes are working properly i have checked that there isn't any pr doing the same i have read the contributing document. ", "commit_messages": " test for randomnumberinrange  update test for random hexcolorcode  test for randomintarray  fix conflicts  fix typo in average test ", "linked_issue_titles": "", "title": "fix typo in average test and add test for randomhexcolorcode"}
{"description": " a backport of #11248 broke the 2.8 build due to usage of the embeddedkafkacluster#stop method, which used to be private. it seems we made this public when we upgraded to junit5 on the 3.0 branch and had to remove the externalresource that was previously responsible for calling start() and stop() for this class using the no-longer-available @classrule annotation. rather than adapt this test to the 2.8 style by migrating it to use @classrule as well, i opted to just make the stop() method public as well (since its analogue start() has always been public anyways). this should hopefully prevent any future backports that include integration tests from having to manually go in and adapt the test, or accidentally break the build as happened here. ", "commit_messages": " use embeddedkafkacluster as classrule in 2.8  just make it public instead for future compatibility ", "linked_issue_titles": "", "title": "fix backport of #11248 by future-proofing the embeddedkafkacluster"}
{"description": " the status is recorded into a separate bigquery table, due to the limit of streaming uploading of run that block the record from being updated. the new status table is only inserted/updated via standard sql query. ", "commit_messages": " update benchmark logger to update the run status.  this is important for streaming upload to bigquery so that the  dashboard can ignore the 'running' benchmark at the moment since  its not finished yet.  move the run status into a separate table.  also update the run status in the benchmark uploader and  bigquerybenchmarklogger.  insert instead of update for the benchmark status for file logger. ", "linked_issue_titles": "", "title": "record the status for a benchmark run."}
{"description": " i'm currently working toward getting a src/ci/docker container working to do isolated/automated builds and testing of x86_64-unknown-cloudabi. this is working pretty well, but still requires some fixes to libtest and compiletest. here is the first set of fixes that i had to apply. ", "commit_messages": " add cloudabi to the list of supported targets in compiletest.  without this change, compiletest will fail to run when targetting  cloudabi.  move the testpaths structure from libtest to compiletest.  this structure doesn't seem to be used by libtest itself. it is used by  compiletest, but never passed on to anything externally. this makes it  easier to get the testing framework to work for cloudabi crossbuilds, as  cloudabi currently lacks pathbuf, which is used by testpaths. ", "linked_issue_titles": "", "title": "tiny fixes to make compiletest work for cloudabi cross builds"}
{"description": " original pull-request #27317 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " update dockerfile  update pvs checksum ", "linked_issue_titles": "", "title": "cherry pick #27317 to 21.7: update pvs checksum"}
{"description": " this is a follow up for #29526 which removes all left-overs from gatsby-image as the output looked very unfinished, i gave the layout and output a few css updates. the code related to gatsby-image removal is in the first commit ", "commit_messages": " refactor: use gatsby-plugin-image only  fix: improve header layout and use layout on image example page ", "linked_issue_titles": "", "title": "using-contentful to use gatsby-plugin-image exclusively"}
{"description": " see individual commits. the goal is to narrow down those utilities because they are copied into both bundles. while we're at it, also making some things dev-only. there is a bit more duplication than i'd like, but it's partly due to stack. for things like symbols, i don't think modules are super useful. note: this 441a04e breaks ie8 hard. ", "commit_messages": " make reactcontrolledvalueproptypes dev-only  remove candefineproperty  this breaks ie8. we don't support it.  remove getnextdebugid  it was added temporarily to avoid stack shared state issues across renderers.  not a problem anymore.  make keyescapeutils.unescape() dev-only  remove unused deprecated() module  it's unlikely we'll deprecate anything else on react.* object soon.  inline getiteratorfn at the call sites  inline reactelementsymbol  inline keyescapeutils into children and move the file into stack  it's only used in one place in isomorphic.  it's used more broadly in stack so we move it there to die.  update artifacts ", "linked_issue_titles": "", "title": "inline some internals, reduce shared/ utilities between isomorphic and renderers"}
{"description": " @brendandburns @roberthbailey ", "commit_messages": " update the kubelet to ignore syncing pods until the container runtime is up.  truncate ssh usernames to 32 chars.  pass through an explicit proxy_ssh_user.  use user@user instead of user@hostname in case hostname is too long. ", "linked_issue_titles": "", "title": "allow passing through an explicit proxy_ssh_user."}
{"description": " performance yes if relevant, link to documentation update: n/a summary sort parents, children, siblings in stats improve way of getting combinations of chunks no other information ", "commit_messages": " sort parents, children, siblings in stats  update test case to be more complex ", "linked_issue_titles": "", "title": "improve performance of chunk splitting combinations"}
{"description": " in the guides of active storage overview, there is an example for direct_uploads.js, which contains xss attack vulnerability. the web application fails to sanitise the name of the uploaded file for special html characters and allows injection of html/javascript payload into the dom model of the web page. for example, when an file with the following name is uploaded, the simple javascript code embedded in the filename is executed: \"><img src=a onerror=alert(1)>.png solution: sanitised file name for file uploads before it is incorporated in html dom model. i have chosen to add sanitised file name as a text content after inserting of direct-upload html, so that text remains same for user. if i just replace ${file.name} for ${encodeuri(file.name)}, user will see encoded characters in direct-upload html, in example case: \"%22%3e%3cimg%20src=a%20onerror=alert(1)%3e.png\". ", "commit_messages": " updated active storage overview guide by sanitizing direct upload file name  updated active storage overview guide by sanitizing direct upload file name ", "linked_issue_titles": "", "title": "fixed active storage overview guide containing xss vulnerability"}
{"description": " this takes #4933 but only runs the invasive tests during the nightly runs. ", "commit_messages": " ci: move coverity in its own pipeline  since coverity is down for a unspecified timeframe, isolate it from the  \"hosted\" nightlies.  ci: enable some of the invasive testcases  tests: fix test expectation mismatch  ci: precisely identify the invasive tests  ci: clear settings variables in powershell  ci: only run invasive tests during nightly runs  ci: run all invasive tests on windows ", "linked_issue_titles": "", "title": "only run invasive tests in nightly"}
{"description": " dear @peng-yongsheng @ascrutae @candyleer @liuhaoyang @adriancole @basvanbeek @jcchavezs, i am working on this pull request, which is about receiving and analysis zipkin trace. i paste the reamde doc of this module at here, to give everyone a brief: zipkin receiver zipkin receiver provides the feature to receive span data from zipkin instrumented applications. skywalking backend provides analysis, aggregation and visualization. so the user will not need to learn how skywalking auto instrumentation agents(java, .net, node.js) work, or they don't want to change for some reasons, such as zipkin integration has been completed. zipkin receiver is only an optional features in skywalking, even now it is an incubating feature. limits as an incubating feature, it is a prototype. so it has following limits: don't try to use skywalking native agents and zipkin's libs in the same distributed system. considering headers of zipkin and skywalking aren't shared/interoperable, their two will not propagate context for each other. trace will not continue. don't support cluster mode. analysis based on trace will be finished in the certain and given duration. the default assumption is 2 min most. skywalking used more complex header and context to avoid this in analysis stage. right now(28th, may.), i just finished my codes with following features: open and listen /api/v2/spans service receive and deserialize spans from existed openzipkin/sleuth-webmvc-example. use caffeine cache implementor to organize all spans into a trace. use cache expired mechanism, assume trace can be analysis x(setting) mins after last span of the certain traceid reported. i want to ask any one who has time, interest and is familiar with zipkin format, especially @adriancole @basvanbeek @jcchavezs , to check whether i miss anything for a zipkin v2 json format. the next i am going to do is: after trace finished, analysis the whole trace(spans), transfer them to tracesegment based on its tree structure and localendpoint/servicename as application code. for milestone, in beta2, i will definitely consider this as an incubating feature only.  wait for me or someone else to change the local cache implementor to redis(cluster) based in 5.1.x series, maybe. ", "commit_messages": " add zipkin receiver module  open http service at zipkin tranditional port, and context path. and put some doc for it.  update description.  add the link to zipkin.io  make zipkin sdk connected.  finish zipkin trace cache and finish mechanism(based on timeout) ", "linked_issue_titles": "", "title": "zipkin receiver in skywalking collector"}
{"description": " this pr removes the need for a custom named column in case of a distinct count function. fixes #39511. ", "commit_messages": " removed custom naming for distinct count ", "linked_issue_titles": " sql: count(distinct) column name has an extra distinct in it ", "title": "fix count distinct column name"}
{"description": " this pull requests enables caps lock to be remapped to either escape or control which is very useful for for instance using vim where you hit escape a lot. if you remap caps lock to escape for instance and then want to remap it back to caps lock you will need to restart the application for it to register properly, but i find that to be ok for this cut, it can be improved upon later. another improvement down the line would be to move the settings to the actual settings panel inside the app. this fixes #38 . ", "commit_messages": " remap caps lock to be escape  right now this always remaps caps lock to be escape, but with support to  change this later.  add settings.bundle  this bundle keeps the setting of what to remap caps lock to. this should  be changed to use the in-app settings system instead. the transition  there should be pretty straight forward.  let caps lock be overwritten from settings  now you can go to settings and ish and chose what you want the caps lock  to be verwritten to! ", "linked_issue_titles": " allow to map cap-lock to escape ", "title": "allow caps lock to be remapped to escape and control"}
{"description": " the test_scheduler_reschedule method fails when creating processes in spawn mode, which is the default mode for python 3.8 on macos. test_scheduler_reschedule depends on mock.patch() decorators around the .do_schedule() method in the parent process to mock dagbag objects in the child process. since spawn mode limits the amount of parent state accessible within the child process, dagbag is not properly mocked in the new process, causing the test to fail. this pr forces the test to use fork instead of spawn when creating a child process, allowing the mocks to work as intended. make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow \"how to write a good git commit message\" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. ", "commit_messages": " use 'fork' in test bc 'spawn' breaks mocks. ", "linked_issue_titles": "", "title": "use fork when test relies on mock.patch in parent process."}
{"description": " what this pr does / why we need it: before we had the hyperkube base image, it was difficult to build the hyperkube with bazel. now that we have the base image with all the necessary dependencies, this has become trivial. this will enable federation jobs etc on prow. release note: /assign @bentheelder @mikedanese @spxtr ", "commit_messages": " bazel: bump rules_go  build hyperkube image with bazel ", "linked_issue_titles": "", "title": "build hyperkube image using bazel"}
{"description": " changes in this pull request: fixes to scoped_exit. check for redundant signatures due to multiple signatures from same key. fix bug in record_locks_for_data_access (did not account for intersection between read_locks of transaction_trace and write_locks of existing shard_trace). put limits on number of keys/accounts in authorities (but a high limit like 2^16) to make overflow of accumulated weights impossible. disallow empty parent for permissions other than owner. actually enforce the existence of permissions contained in an updated authority (changed find to get). reserve account names starting with \"eosio.\" (previously was a much stricter check of whether the name contains \"eosio.\"). reserve permission names starting with \"eosio.\" create dummy permission_object as first object in permission_index during chain initialization so that a parent id of 0 can never refer to a legitimate object. use fc::microseconds for delay rather than time_point. fixed bug with how a permission visitor works with the authority_checker. it would visit permissions that did not end up contributing towards satisfying the authority. my quick fix (a more elegant fix is eventually desired) causes the permission visitor to visit unneeded permissions but now with extra surrounding information (push_undo, pop_undo, squash_undo) to help it discard the side effects of visits to permissions that ended up not being used. this bug had implications on the minimum delay calculated by check_authorization (they could have been higher than necessary). changes to validating signatures/authorities/tapos/expiration/uniqueness (affects #1753 and #1755): see details below. there are two stages to validating a transaction. the first stage involves checks that can be made with minimal state information: just the information either included in the packed_transaction itself or the state available as of the end of the previous block (specifically head block timestamp and tapos block ids). the first stage of checks are mostly done in a function called validate_transaction_with_minimal_state. it checks that there is at least one action in the transaction, that is has not expired yet, that its tapos referenced block is valid, and that the network usage due to the packed_transaction alone is not too much to cause the transaction to be invalid based on its (soon to be) upper bound on net usage committed in the transaction header. there is also another check/processing that can be done in this first stage (except for generated transactions): recovering the public keys from the signatures and ensuring there are not multiple signatures signed by the same key. the second stage involves the remaining checks that require the state information at the point at which the transaction is scheduled to execute (or be delayed). they include the checks on uniqueness of the transaction, that the expiration in the transaction header is not too far in the future relative to the appropriate reference time (head block time + any delay imposed) based on the limits in the chain parameters, and that the accounts referenced in the authorizations of the transaction exist. they also include checking the authorizations using: if an input transaction, the set of recovered public keys from the signatures; or if a generated transaction, only the owner permission of the contract code that generated the transaction. for delayed input transactions or generated transactions (whether delayed or not), checks occur at two different times. first, the delayed input or generated transaction is checked using the stage 1 and stage 2 checks at the time of dispatch. then, at the time of scheduling/execution additional checks are performed: check that the transaction is not executing prematurely, check that the transaction has not expired yet again, and check uniqueness again. ", "commit_messages": " fix scoped_exit #1755  check expiration time of deferred tx to avoid keeping the tx id in transaction_index for too long #1753  unit test on deferred transaction expiring too late #1753  remove redundant validate_block_header when generating a block #1755  added signature/authorization check for input transactions. #1755  also, disallowed redundant signatures in a tx that are signed by the  same key.  modified block_tests/irrelevant_sig_soft_check to check for multiple  signatures by same key and to account for the fact that blocks with  transactions that have irrelevant signatures are objectively invalid.  also added block_tests/irrelevant_sig_hard_check unit test to verify  that such objectively invalid blocks are rejected.  send_action_large in api_tests/transaction_tests is behaving very oddly.  the size of the too large inline action it is sending is calculated as  8107 when it should be 8227.  (there is no miscalculation of the inline action size if the dummy data  is increased to 9*1024.)  this causes read_action_normal to actually execute when instead the  \"inline action too big\" error should have been thrown.  even more bizarrely, the boost_check_exception of the \"inline action too  big\" error for that test succeeds if there are print statements in  read_action_normal.  but whenever the print statements in read_action_normal are removed, it  instead gives another error message \"abort() called\" causing the  boost_check_exception to fail.  fixed bug in record_locks_for_data_access.  limits on authority size to prevent accumulated weight overflow  also, added a comment regarding a potential issue with  shared_authority::get_billable_size() which is relevant whenever new  public keys are to be added via hardfork after launch of a live network.  bug fixes for permissions and reserved names  permissions in updated authority should exist.  non-privileged account creators should be restricted from using account  names that _start_ with \"eosio.\".  reserve \"eosio.any\" as permission name.  disallow empty parent for any permission other than owner.  reserve id = 0 in permission_index so that a parent id of 0 always means  \"no parent\" rather than referring to a legitimate permission_object  (e.g. the owner permission of the system account).  permission visitor should not consider visits that did not contribute to satisfying the authority  also, now using fc::microseconds for delay.  progress on #1755 and on cleaning up delayed transactions  reserve all permission names that start with 'eosio.' ", "linked_issue_titles": "", "title": "check signatures, transaction validation checks, and many other bug fixes"}
{"description": " currententry is taken from string array this.history. it represents an url string but not an object. the field currententry.url should not be accessible by any means. i believe this was a coding error made by mistake. this pr fixes this bug. this pr also removes return statement from the callback in order to keep consistency. ", "commit_messages": " fix a minor bug in navigation-controller where a string is used as an object  simplify logic ", "linked_issue_titles": "", "title": "fix a bug in navigation-controller where string is used as object"}
{"description": " same as #2121 but for both react and vue apps (the change doesn't seem to make sense for rn app) ", "commit_messages": " avoid logging an object on compilation errors  in certain configurations storybook might log the whole webpack  build object when warnings or errors are thrown. this was caused  by a logger.error call inside the index.js catch. this fixes by logging  the error only when it's an instance of an error.  copypaste the change to vue app ", "linked_issue_titles": "", "title": "avoid logging an object on compilation errors [2]"}
{"description": " resolves devrel-1575: fix broken references to eos repo docs (backport of pr #10570 #10571 to 2.1) select one: select any that apply: ", "commit_messages": " remove broken cleos wrap cmd ref link :doc  fix broken links in cleos wallet keys cmd :doc  fix broken link in cleos wallet create cmd :doc  fix broken link in cleos create account cmd :doc  fix broken link in cleos get transaction cmd :doc  update eosio overview index file from 2.0 :doc  fix broken link in how to connect to specific net :doc  fix broken links in cleos system buyram cmd :doc  fix broken links in nodeos deep mind logger :doc  fix self link in keosd wallet plugin index :doc ", "linked_issue_titles": "", "title": "fix some broken anchors and links - 2.1"}
{"description": " this change points users in the direction of 1.x docs in the repo. ", "commit_messages": " link to 1.x documentation in notes  update readme to link to previous versions  note - this removed now not required mention of liquid tags in docs. ", "linked_issue_titles": "", "title": "link to previous version docs"}
{"description": " description: the states opening and closing was inverted for homekit covers which is fixed with this change. related issue (if applicable): fixes #25945 checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " update cover.py  update test_cover.py ", "linked_issue_titles": " closing/opening seems to be swapped ", "title": "inverting states for opening/closing homekit covers"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). the load method can also be modified to take a second argument, an object with an integrations dictionary, which used to load only the integrations that are marked as enabled with the boolean value true. works in version 4.1.0 or higher. more info about this can be found in segment analytics documentations. ", "commit_messages": " configure segment with write key & integration management  capitalize a word in comments ", "linked_issue_titles": "", "title": "segment-analytics | configure segment with write key & integration management"}
{"description": " added missing some enum values to predefined types (according to tabulator documentation/examples) ", "commit_messages": " update index.d.ts  added missing some enum values to predefined types (according to tabulator documentation/examples)  update index.d.ts  replaced function with specific function type  update index.d.ts  updated onrendered type for formatter type definition  updated formatter definition. updated tabulator-tables-tests according formatter definition  update tabulator-tables-tests.ts  fixed tabulator.emptycallback reference in tabulator-tables-tests ", "linked_issue_titles": "", "title": "updated some type declaration for tabulator-tables"}
{"description": " this will reintroduce the changes from #64678, which was reverted because it was out of date with test files that had been migrated to nnbd. did any tests fail when you ran them? please read handling breaking changes. no, no existing tests failed, so this is not a breaking change. ", "commit_messages": " wrap popupmenu with safearea to respect status bar  edit second popupmenu test  add newline between tests  add newline between added tests  remove trailing spaces  specify type in test code  update tests  remove trailing space  add nnbd to tests ", "linked_issue_titles": "", "title": "re-land 'wrap popupmenu with safearea to respect status bar'"}
{"description": " closes: #7370 ", "commit_messages": " upgrade gradle-wrapper (and gradle) to the latest version.  this is a snapshot after 'gradlew wrapper --gradle-version 6.5.1'  * make it work.  * use the latest clojure and clojurescript gradle pluguin. they are renamed.  * fix gradle deprecated warnings.  * upgrade libs to sync with the java invoke bridge. ", "linked_issue_titles": " the dependency gradle-wrapper.jar has a number of security flaws as identified by a veracode static scan ", "title": "upgrade gradle-wrapper and gradle to fix #7370"}
{"description": " i'm proposing 3 different automations to manage our issues: close issues opened without using one of our pre-defined issue templates close stale issues labeled as stat: need more info after 2 weeks close stale issues without any comments after 67 days the stale issue handling are done via a github action called stale and the other one via close issue app. the main idea behind this is to get rid of very old and not relevant issues so we can focus on the important ones. once we enabled this, this is the issues that would be immediately affected: 1459 issues marked as stale to be closed after 7 days if nobody adds a comment - link to preview 23 issues marked with \"no response\" to be closed after 4 days if nobody adds a comment - link to preview how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog this is how they are intended to work: stale issues (without interaction) bot will search for issues without new comments in the last 60 days that doesn't have any of the following labels: epic feature: planned sla sponsored stat: waiting pr merge triaged subj: security for issues matching the criteria the bot will add the label stat: stale and will add a comment to explain that the issue is now marked as stale. if the issue receives a new comment or any other update after being marked as stale, it will automatically be removed from stale and have it's label removed. issues with the label stat: stale that didn't receive new comments or updates after 7 days will be automatically closed. new comments after the issue is closed will not open the issue again (not supported by the bot). what we could do in this (and is supported by the bot) is to add a new comment saying what the issue owner can do, it could be something like \"please test with most recent release and open a new issue if still happening\". no response issues bot will search for issues with label stat: need more info without new comments or updates in the last 10 days for issues matching the criteria the bot will add the label stat: no response and will add a comment to explain that the issue is now marked as stale. if the issue receives a new comment or any other update after being marked as stale, it will automatically be removed from stale and have it's label removed. issues with the label stat: no response that didn't receive new comments or updates after 4 days will be automatically closed. since someone have interacted with the issue before the bot actually close the issue, if the owner replies after it is closed, it's responsibility to the user that add the label stat: need more info to evaluate the reply and open issue again. ", "commit_messages": " remove custom issue template  add stale app config  add no response app config  add isse close app config  add comment  use github actions for stale issues ", "linked_issue_titles": "", "title": "add apps to control github issues"}
{"description": " there are a few things i missed in gh-27980.  this is a follow-up that will make subsequent prs cleaner.  it includes fixes to tests and tools that reference the frozen modules. (fyi, these changes come from gh-28107.  @gvanrossum already reviewed them there.) ", "commit_messages": " fix freeze_module() in freeze_modules.py.  add frozensource and frozenmodule to freeze_modules.py.  leave all non-required frozen modules uncommitted.  leave *all* frozen modules uncommitted.  generate the list of frozen modules used by test_ctypes.  ignore frozen submodules in generate_stdlib_module_names.py.  add a comment to the frozen modules manifest file.  show how the frozen manifest changed.  go back to keeping frozen modules in the repo.  also stop tracking the frozen manifest.  mark the frozen manifest as a generated file.  drop a superfluous prefix on makefile rule dependencies.  do not generate test code.  drop unused code from freeze_modules.py.  do not clear the frozen .h files with \"make distclean\", now that they are back in the repo.  always flush the printed \"title\" when freezing modules.  add the frozen manifest back into the repo.  on windows, only freeze the essential modules for now. ", "linked_issue_titles": "", "title": "do some cleanup related to frozen modules."}
{"description": " pass devicestatus to iob.calctotal and cob.cobtotal let iob be undefined sometimes (no treatments and no devicestatus in sandbox == haven't heard from device in a while == undefined iob, displayed as \"---u\". assuming/showing \"0u\" in this case would be misleading.) ...but always return a number on /pebble for backwards compatibility with the clients in the wild ", "commit_messages": " pass devicestatus to iob.calctotal  show iob from devicestatus when available  make day-to-day report able to plot negative or discontinuous iob  don't assume iob is 0 in the absence of treatments  handle iob format from mm connect  show 0 iob on /pebble even when undefined, for backwards compatibility ", "linked_issue_titles": "", "title": "show iob from devicestatus when available (openaps or mm connect)"}
{"description": " fixes #12314. however, whether the solution is optimal is tbd. furthermore, i put the sentry_dsn environment variable into the envobject in next.config.js. however, it is not 100% clear to me whether this is correct. ", "commit_messages": " update sentry packages  disable sentry in development and add auth for sourcemap upload ", "linked_issue_titles": " with-sentry-simple requires auth to upload sourcemaps via webpack plugin ", "title": "#12314 add auth to with-sentry-simple example"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). multi:  tokey:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " fix: add multi and tokey methods  fix: return pipeline without promise  test: add test ", "linked_issue_titles": "", "title": "add missing low level methods"}
{"description": " class which calculates pi using nilakanthas infinite series #2323 i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " added class pinilakantha.java  which calculates pi using nilakanthas infinite series  added link to explanation  partially fixes #2323 ", "linked_issue_titles": "", "title": "added class that calculated pi"}
{"description": " for #5301 fix #6003 fix select_distinct_with_multi_column_without_order_by fix select_distinct_without_order_by fix select_with_case_expression enable db rule type ", "commit_messages": " fix select_distinct_with_multi_column_without_order_by  fix select_with_case_expression & enable db rule type ", "linked_issue_titles": " distinct sql assert failed in integration test after open db rule type ", "title": "fix integrate test error in db rule type mode"}
{"description": " towards #16155 remove boston dataset in sklearn/ensemble/tests/test_gradient_boosting.py. use a subset of california housing dataset for test_boston and use diabetes dataset for all remaining tests. used california dataset for test_boston due to the high mse error if diabetes dataset used (for parameters in test, mse ranged from ~600-1700). correspondingly there was also a bigger difference between predictions (assert_array_almost_equal(last_y_pred, y_pred)) and predictions were only equal with decimals=-2. happy to change to diabetes/another dataset if california not suitable. ", "commit_messages": " check diabetes  use diabetes and cali  pytest network ", "linked_issue_titles": "", "title": "tst replace boston in test_gradient_boosting.py"}
{"description": " making it possible to build libchromiumcontent locally instead of downloading prebuilt binaries from internet. close #3310. refs #259. ", "commit_messages": " add --build_libchromiumcontent option  docs: cleanup unnecessary parts in build-instructions-linux.md  docs: the --build_libchromiumcontent switch ", "linked_issue_titles": "", "title": "add --build_libchromiumcontent command line switch"}
{"description": " this change introduces a bottomsheettheme that allows you to theme color, elevation, and shape of bottomsheet. this can be done at the theme level and at call time of showbottomsheet and showmodalbottomsheet. see the following image for an example (with some questionable design choices): related issues closes #26854 closes #30444 i added the following tests: tests for the theme and modifying the color/elevation/shape of the bottomsheet itself tests for ensuring the showbottomsheet and showmodalbottomsheet pass through color/elevation/shape to the bottomsheet before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " introduce bottomsheettheme and shape support for bottom sheet  add bottom sheet theme to themedata. use theme in bottom sheet build ", "linked_issue_titles": " adding shape for bottom sheet  implement shape support for bottomsheet ", "title": "add bottomsheettheme to enable theming color, elevation, shape of bottomsheet"}
{"description": " this fixes requiring next/document directly failing since it uses webpack loader syntax at the top level fixes: #9401 ", "commit_messages": " don't use loader import at top level in next/document ", "linked_issue_titles": " 9.1.3 fails using jest when a test involves something imported from next/document ", "title": "remove top level usage of loader imports in next/document"}
{"description": " recreated pr #19844 by @senseisimple so it can be edited. keep an eye out for this check-box when creating prs: compile error when case_light_no_brightness is set but case_light_default_brightness is disabled/commented creating minor confusion since one definition implies that the other is not needed or is in conflict. further, the serial echo behavior for turning the case light on with case_light_no_brightness defined is echo:case light: <brightness> which doesn't make semantic sense for the  setting since the brightness value (pnnn) is ignored. since the functionality for the output of echo:case light: off (language const) was already there for a non-pwm pin, a simple solution is to hardcode a default case_light_default_brightness  to 0 (zero) when the case_light_no_brightness is enabled so as to not disturb current functionality and a modified evaluation for the serial echo string is  (!pwm_pin(case_light_pin) || enabled(case_light_no_brightness)) this improves the intuitive understanding between configuring either case_light_no_brightness and/or  case_light_default_brightness as well as a nicer serial output message for on/off states when the case light is not pwm but on a pwm pin. none, definitions already present in configuration_adv.h none ", "commit_messages": " case light no_brightness on pwm pin serial echo  compile error when case_light_no_brightness is set but case_light_default_brightness is disabled/commented.  before this patch the serial echo behavior for turning the case light on was echo:case light: <brightness> which doesn't make semantic sense for the no_brightness setting since the brightness value (pnnn) is ignored.  since the functionality for echo echo:case light: off (language const) was already there for non-pwm pin, a simple solution is to hardcode a default case_light_default_brightness to 0 (zero) when the no_brightness is enabled (so as to not disturb current functionality) and a new evaluation for the serial echo string is  (!pwm_pin(case_light_pin) || enabled(case_light_no_brightness))  case_light_brightness m115 cap ", "linked_issue_titles": "", "title": "case_light_no_brightness on pwm pin improvement"}
{"description": " title is self-explanatory. closes #15895. ", "commit_messages": " doc: document pandas.core.dtypes.common  closes gh-15895.  tst: add tests for pandas.core.dtypes.common  the testing of this module was especially lacking  with the exception of is_dtype_equal and pandas_dtype. ", "linked_issue_titles": "", "title": "document and test functions in dtypes/common.py"}
{"description": " when a tokenizer is being loaded with pretrainedtokenizer._from_pretrained, it should set added_tokens and all_special_tokens to unique_added_tokens_encoder. if we don't do it, it will corrupt the tokenization. example: import transformers tokenizer = transformers.berttokenizer.from_pretrained(\"bert-base-uncased\") tokenizer.tokenize(\"[cls] token should not be splitted.\") # correct output # ['[cls]', 'token', 'should', 'not', 'be', 'split', '##ted', '.'] # incorrect output # ['[', '[unk]', ']', 'token', 'should', 'not', 'be', 'split', '##ted', '.'] ", "commit_messages": " fixed lack of added and special tokens  add special tokens to unique_added_tokens_encoder ", "linked_issue_titles": "", "title": "correct tokenization for special and added tokens"}
{"description": " change this change creates an isource implementation for sqliteindex that provides the interface glue around new functionality to perform a search and query specific data from an index.  the source can also hold a crossprocessreaderwriterlock to prevent any other processes from writing to the index file while it is being used. the search functionality implemented within sqliteindex is minimal; only exact match on id is supported through the query parameter currently (also, everything can be retrieved by giving no query parameter).  however, this still enables all other functionality to be exercised.  additionally, any existing semantics that require version sorting are not implemented, and the results returned are in a somewhat arbitrary order (expect reverse insertion order). additionally, the preindexedpackagesourcefactory has also been enlightened (in both forms) to create a source in response to the opensource function.  this enables the client to complete an e2e scenario of: adding a source searching for an id installing based on an id (and optionally version and channel) other minor changes of note: utility::download will now create any missing directories required to be able to write to the dest file. testing tests are added for the new functionality exposed from sqliteindex, as well as their use through the sqliteindexsource. ", "commit_messages": " most of barebones support in  baseline code complete  tests for sqliteindex changes  merge from upstream/master  hook up source factory to sources and add tests for source  fix downloading manifest from remote ", "linked_issue_titles": "", "title": "create sqliteindexsource with bare minimum search functionality"}
{"description": " this syncs miri with what the nomicon and the reference say, and resolves rust-lang/miri#447. also this would not have worked without #62982 due to new cycles. ;) r? @oli-obk ", "commit_messages": " check that ptr is valid already when doing deref, not only when doing the access  discourage use of ref_to_mplace  the alignment checks on access can no longer fail now ", "linked_issue_titles": " check that offset is not too big, check projection offset to be inbounds ", "title": "check that a ptr is aligned and inbounds already when evaluating *"}
{"description": " add a new addon database feature which can be used by addons to persist data with the storybook. the default configuration stores data in a json file inside the storybook config directory (.storybook). ", "commit_messages": " update storybook-addons api  from v1.5 it include get/set database methods  implement database server  add default database client  fix lint errors ", "linked_issue_titles": "", "title": "add database support for addons"}
{"description": " hello @kazuho !! i implemented some h2o::request methods. for example, executed curl 127.0.0.1:8080/index.html?a=1: r = h2o::request.new r.hostname    #=> \"127.0.0.1:8080\" r.authority   #=> \"127.0.0.1:8080\" r.uri         #=> \"/index.html?a=1\" r.path        #=> \"/index.html?a=1\" r.method      #=> \"get\" r.qeury       #=> \"?a=1\" # if not found query, r.query return nil ", "commit_messages": " add h2o::request#{uri,path}  cleanup exmaple  add h2o::request#{hostname,authority}  add h2o::request#method  add h2o::request#query  add test of h2o::request#{uri,query,method,hostname} ", "linked_issue_titles": "", "title": "add some h2o::request methods"}
{"description": " cherry pick of #100183 on release-1.21. #100183: add e2e test for nodeunstage error cases for details on the cherry pick process, see the cherry pick requests page. ", "commit_messages": " add e2e test for nodeunstage error cases  fix unmountdevice error cases  when unmountdevice fails, kubelet treat the volume mount as uncertain,  because it does not know at which stage unmountdevice failed. it may be  already partially unmonted / destroyed.  as result, mountdevice will be performer when a new pod is started on the  node after unmountdevice faiure.  add getpossiblymountedvolumesforpod to let kubelet know all volumes were unmounted  podvolumesexist() should consider also uncertain volumes (where kubelet  does not know if a volume was fully unmounted) when checking for pod's  volumes. added getpossiblymountedvolumesforpod for that.  adding uncertain mounts to getmountedvolumesforpod would potentially break  other callers (e.g. verifyvolumesmountedfunc).  add podremovedfromvolume  to know when a volume has been fully unmounted (incl. uncertain mounts).  refactor dswp unit tests  change existing desiredstateofworldpopulator.findandaddnewpods tests to use  a common initialization function.  add unit test for dswp with uncertain volume  desiredstateofworldpopulator.findandremovedeletedpods() should remove  volumes from dsw when a pod is deleted on the api server and the volume is  uncertain in asw. ", "linked_issue_titles": "", "title": "mark volume as uncertain after unmount* fails"}
{"description": " first of all, thanks for your contribution! :-) please makes sure these boxes are checked before submitting your pr, thank you! make sure you follow antd's code convention. run npm run lint and fix those errors before submitting in order to keep consistent code style. rebase before creating a pr to keep commit history clear. add some descriptions and refer relative issues for you pr. ", "commit_messages": " swedish locale  create sv_se.tsx  create sv_se.tsx  create sv_se.tsx ", "linked_issue_titles": "", "title": "add support for swedish locale"}
{"description": " this refactors the remote module to use weakref instead of our bespoke weakref-like solution on the renderer side. similar browser-side refactor to follow. depends on #24034. npm test passes tests are changed or added pr title follows semantic commit guidelines this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: none ", "commit_messages": " refactor: tsify remote  refactor: use weakref instead of v8util.createidweakmap in remote ", "linked_issue_titles": "", "title": "use weakref on renderer side of remote"}
{"description": " this pr implements a onrefresh action to let the native filters reload when the dashboard reloads. fixes #15808 126416469-24a7a2ad-3f6b-4da9-9dfd-68d724a1e1eb.mp4 untitled.dashb.3.mp4 open a dashboard with native filters on add a filter remove any of the options from the dataset refresh the dashboard observe that the option is not appearing in the filter has associated issue: #15808 includes db migration (follow approval process in sip-59) ", "commit_messages": " implement onrefresh action  update tests  clean up ", "linked_issue_titles": " [native filter] options for value filter should refresh when dashboard refresh but currently only when page refresh ", "title": "refresh native filters when dashboard refreshes"}
{"description": " fixes the slave encoder state syncing to reduce dropped pulses. includes fix for iris rev3/rev4 phantom pulses. fixes #7055 my code follows the code style of this project. i have read the contributing document. ", "commit_messages": " updated slave encoder sync to reduce dropped pulses  fixing encoder direction  encoder behavior fixes, tested  update keyboards/rgbkb/sol/keymaps/xulkal/rules.mk  to make fauxpark happy  update custom_encoder.c  update rules.mk  iris r4 fix ", "linked_issue_titles": " rotary encoder unresponsive on slave half of split keyboard ", "title": "updated slave encoder sync to reduce dropped pulses - v2"}
{"description": " more typing cleanups original failures: pandas/core/groupby/ops.py:13: error: module 'pandas._libs' has no attribute 'groupby' pandas/core/groupby/ops.py:13: error: module 'pandas._libs' has no attribute 'reduction' pandas/core/groupby/groupby.py:22: error: module 'pandas._libs' has no attribute 'groupby' pandas/core/groupby/groupby.py:329: error: need type annotation for '_apply_whitelist' pandas/core/groupby/generic.py:220: error: incompatible types in assignment (expression has type \"callable[[arg(any, 'arg'), vararg(any), kwarg(any)], any]\", base class \"selectionmixin\" defined the type as \"callable[[arg(any, 'func'), vararg(any), kwarg(any)], any]\") ", "commit_messages": " removed groupby modules from mypy blacklist  fixed typing issues in pandas.core.groupby ", "linked_issue_titles": "", "title": "fix up typing in groupby"}
{"description": " adds [lint skip] marker to azure pipeline ci to run all the tests even if linting fails. ", "commit_messages": " mnt adds lint skipping to azure ci  bld [lint skip]  bug fix [lint skip] ", "linked_issue_titles": "", "title": "mnt adds skip lint to azure pipeline ci"}
{"description": " moved the different cli managers into their own modules, to allow reuse of sub command names. added two new commands to data source cli: edit and delete (guess what they do...). removed some obsolete commands. ", "commit_messages": " remove import from settings command (obsolete).  split cli commands to several files for easier editing and naming.  added edit & delete commands to data source cli ", "linked_issue_titles": "", "title": "new data source management commands in manage.py"}
{"description": " this pr fixes two related bugs that happened after running retokenizer.split: the lemma information was not updated and was still referring to the old token.text attributes. this is fixed/reset by calling token.lemma = 0 on the split tokens. the vector attributes were left unchanged, causing an out-of-bounds error as described in issue #3540. this is fixed by extending the doc.tensor and setting the vectors of the split tokens to an array of zeros (not sure what else to do). bug fix i have submitted the spacy contributor agreement. ", "commit_messages": " fixing vector and lemma attributes after retokenizer.split  fixing unit test with mockup tensor  xp instead of numpy ", "linked_issue_titles": "", "title": "update lemma and vector information after splitting a token"}
{"description": " fixes rdar://problem/78960468. ", "commit_messages": " sema: resolveidenttypecomponent() can use a for loop instead of recursion  sema: allow omitting generic parameters when accessing member type with a fully-constrained 'where' clause  fixes rdar://problem/78960468. ", "linked_issue_titles": "", "title": "allow omitting generic parameters when accessing member type with a fully-constrained 'where' clause [5.5-05/14/2021]"}
{"description": " changes id and class names of svg image elements in challenge, to ensure their uniqueness for the image, and to stop interference from logo svg. slightly cleans-up formatting. tested on local fork. i have read freecodecamp's contribution guidelines. my pull request has a descriptive title (not a vague title like update index.md) my pull request targets the main branch of freecodecamp. all the files i changed are in the same world language, for example: only english changes, or only chinese changes, etc. closes #41247 ", "commit_messages": " fix: correct displaying of malformed svg  fix: formatting clean-up ", "linked_issue_titles": " rosetta code: cut a rectangle - svg image impacted by svg in navbar ", "title": "prevent malforming of svg image"}
{"description": " this pr addresses issue #15613. this adds a git setting which determines whether or not to prompt the user if there are changes in the working tree and none of them are staged. ", "commit_messages": " add git enablesmartcommit setting  if false, this setting will prompt the user if they want to commit all files if none are staged  check git enablesmartcommit if no staged files  prevent redundant enablesmartcommit prompt  this prevents a prompt for enablesmartcommit if there are no changes at all ", "linked_issue_titles": "", "title": "issue 15613 all files committed"}
{"description": " the english version is a pdf file, and make chinese version a md file which is easier to maintain later. ", "commit_messages": " committed a file into the wrong directory on june 9  this is a stupid mistake, i found that there missed one chinese version file that i committed yesterday, finally i realized that it was in the wrong directory. the fact that it isn't in the right place can cause a real problem, because all pictures can not be shown. so please merge this modification.  merge from source  create coordination_cn.md  4 new pictures for coordination_cn.md  create coordination_cn.md ", "linked_issue_titles": "", "title": "commit coordination_cn chinese version along with 4 newly added pictures"}
{"description": " split the monolithic grab-bag into targeted modules. promotes separation of concerns, easier maintenance, and more targeted mocking. package instance methods hasdependencyinstalled and hasmatchingdependency were moved to separate files, as they are only used in lerna bootstrap. createpackagegraph was removed in favor of direct instantiation of packagegraph. adddependencies is now a packagegraph instance method, which encapsulates the logic better. initcommand no longer checks for the ancient version file, and its tests were significantly simplified. ", "commit_messages": " feat: split packageutilities into src/utils/*  validatepackagenames should be a bootstrapcommand method, and throw an error  adddependencies should be a packagegraph instance method  batch-packages does not need a separate test file  collect-packages does not need a separate test file  filter-packages does not need a separate test file  matchpackagename.js -> match-package-name.js  symlinkpackages + createbinarylink = src/utils/symlink  dependencyissatisfied moved entirely within package instance method  run-parallel-batches doesn't need a separate test file  remove createpackagegraph util  move dependency-related utils out of package, only consumed in bootstrap ", "linked_issue_titles": "", "title": "split packageutilities into smaller files"}
{"description": " i carefully read the contribution guidelines and agree to them. this is a preview of the changes that match the requested change in issue #3183 ", "commit_messages": " removing the search bar icon when in search mode. issue: #3138  removing the search bar icon when in search mode. issue: #3183 ", "linked_issue_titles": " ui remove search icon when in search mode ", "title": "remove search icon in search mode. issue: #3183"}
{"description": " allow lcd_bed_leveling to be used with the automatic abl options so that fade, probe z offset, etc. are more easily found. counterpart to #10587 ", "commit_messages": " fewer includes of vector_3.h  rename float32 => float52, etc.  lcd_bed_leveling enables a sub-menu for abl ", "linked_issue_titles": "", "title": "sub-menu for abl with lcd_bed_leveling"}
{"description": " this is a copy of #5950, but for the 0.10 branch. unfortually a fallback to \"c\" locale via std::locale::global does not cover all scenarios with messed up environment locale settings and on ubuntu 14.01 (with lang=en_us.utf-8, language=en_us, lc_* empty) setting lang=invalid triggers a crash right at the start of bitcoind and bitcoin-qt. this also affects test_bitcoin and test_bitcoin-qt, which were not guarded at all. the pr expands the scope of the locale fallback and prevents crashes due to invalid locale settings of bitcoind, bitcoin-qt, test_bitcoin and test_bitcoin-qt. i used the rpc test test_locale.py to confirm the 0.10 branch is affected by bad locale environment settings in this build, and that this pr does what it should in another build. the test was not added to this pr, because it executes the boost tests a few times, which seems too expensive and wasteful. ", "commit_messages": " initialization: set fallback locale as environment variable  the scope of std::locale::global appears to be smaller than setenv(\"lc_all\", ...) and insufficient to fix messed up locale settings for the whole application.  initialization: setup environment before starting tests  the environment is prepared by the main thread to guard against invalid locale settings and to prevent deinitialization issues of boost path, which can result in app crashes.  initialization: setup environment before starting qt tests  the environment is prepared by the main thread to guard against invalid locale settings. ", "linked_issue_titles": "", "title": "fix locale fallback and guard tests against invalid locale settings"}
{"description": " overview conform range, closedrange, partialrangeupto, partialrangethrough and partialrangefrom to codable. bug report sr-8649 forum thread range conform to codable proposal amendment pr swift evolution pr #915 ", "commit_messages": " added codable conformance for range, closedrange, partialrangeupto, partialrangethrough and partialrangefrom  codable cleanup ", "linked_issue_titles": "", "title": "range types conform to codable"}
{"description": " on windows we can't reference the runtime's builtin.nativeobject value witness table directly from class metadata. instead fill it in at runtime for singleton metadata initialization. do this on all platforms, even though its not needed on linux or darwin, for simplicity. a subsequent windows-specific change will force the use of singleton metadata initialization for all classes, even when the class is otherwise fixed. ", "commit_messages": " runtime: some const correctness  runtime: the ivar destroyer can be null  this reverts commit b3a50ea9fdd6fb8cb0cbcba059dcb5b8029db7c4.  runtime: the class metadata relocation function can be null  irgen always just emits a simple implementation that immediately  calls swift_relocateclassmetadata(); so allow the function to be  null in this case to save on code size.  runtime: fill in the value witness table of a class when doing singleton metadata initialization  on windows the image format does not support cross-image absolute  data symbol references. one case where we emit these is in class  metadata, because the value witness table always points at the  value witness table for builtin.nativeobject, defined in the  runtime.  instead, fill in the value witness table at runtime when doing  singleton metadata initialization.  another change that will come later is to force use of singleton  metadata initialization on windows, even if the class is otherwise  completely fixed. ", "linked_issue_titles": "", "title": "class metadata fix for windows [5.0, abi]"}
{"description": " i tried to translate the original file into arabic, but there are some blocks that cannot be translated into arabic because the meaning is very different, for the tables, i could not translate them completely ", "commit_messages": " add the ds link  finish translating math  add arabic version of the readme file  add arabic version of the readme file  add the arabic readme file link to main readme file  add the arabic readme file link to main readme file  add the arabic readme file link to main readme file ", "linked_issue_titles": "", "title": "add an arabic version of the readme file"}
{"description": " if not proxying 100-continue, swallow 100-continues. also handle the case of multiple continues headers \"cleanly\" by resetting the stream, rather than crashing.  support for responses with multiple headers, such as 103 (early hint) can be added when there's a need. risk level: medium (on top of a high risk feature) testing: lots and lots of extended integration tests. docs changes: envoyproxy/data-plane-api#492 release notes: 100-continue support already docced. fixes #2563 ", "commit_messages": " handling the case of double 100 continue  fixes from #2560 ", "linked_issue_titles": "", "title": "guard against multiple 100 responses"}
{"description": " fixes #1818 . add sql.simple to sharding config. if this properties is true,in shard module,log will display in sample style. ", "commit_messages": " add sql.simple.length config  just async  add sql.simple to sharing config ", "linked_issue_titles": "", "title": "#1818 add sql.simple to sharding config"}
{"description": " (duplicate of #29970. the commit from that pr was accidentally reverted in master, so here's another pr to bring it back.) gray 200 is not an accessible icon color. we should use the subtext color alias instead. before: after: ", "commit_messages": " fix(ui): use gray300 for requestinterface's icon  gray 200 is not an accessible icon color. we should use the subtext color alias instead. ", "linked_issue_titles": "", "title": "use subtext alias for requestinterface's icon"}
{"description": " while looking for some example code to initialize an op's output shape from a shape provided in an attribute, i found a six-line snippet that is repeated in seven different places. it looks like some copying and pasting has happened in the past. this pull request pulls that shared code into a single function in common_shape_fns.cc. ", "commit_messages": " factoring out explicitshape() shape function. ", "linked_issue_titles": "", "title": "pull out repeated shape-related code into shared function"}
{"description": " since error boundaries are \"atomic\" in fiber, and errors in \"did\" lifecycles and \"willunmount\" only surface after committing, we can end up in a situation where two independent boundaries should receive two independent errors from several components with broken lifecycle hooks. this pr adds support for this and removes some unnecessary recursion. it also \"fixes\" (i'm not sure it's a fix though) a problem: rethrowing errors makes some roots forever skip updates. you can search for \"fixme\": // we need to make sure any future root can get scheduled despite these errors. // currently after throwing, nothing gets scheduled because these fields are set. // fixme: this is likely a wrong fix! it's still better than ignoring updates though. nextscheduledroot = null; lastscheduledroot = null; if i don't those fields, this test fails: var container = document.createelement('div'); expect(() => { reactdom.render(<brokenrender />, container); }).tothrow('hello'); container = document.createelement('div'); expect(() => { reactdom.render(<brokencomponentwillmount />, container); }).tothrow('hello'); container = document.createelement('div'); expect(() => { reactdom.render(<brokencomponentdidmount />, container); }).tothrow('hello'); it fails because second and third requests to render are completely ignored since scheduler thinks they're already scheduled. i don't understand the scheduler well enough to propose a better fix. ", "commit_messages": " add more tests for error boundaries  add a failing test for multiple independent boundaries  now that commits are treated as atomic, it is possible that componentdidmount, componentdidupdate, or componentwillunmount threw in multiple places during the commit. we need to make sure we notify all affected boundaries of the first errors in them.  add tests verifying we don't swallow exceptions  handle multiple errors in boundaries ", "linked_issue_titles": "", "title": "error boundaries should handle errors independently"}
{"description": " addresses #20308 this pr ensures histgradientboostingclassifier is compatible with numpydoc. remove histgradientboostingclassifier from docstring_ignore_list. verify that all tests are passing. #dataumbrella sprint ", "commit_messages": " remove histgradientboostingclassifier from docstring_ignore_list.  fix numpydocs from histgradientboostingclassifier. ", "linked_issue_titles": "", "title": "doc ensures that histgradientboostingclassifier passes numpydoc validation"}
{"description": " fix #85462. this will not affect abi since the other variant of the enum is bigger. it may break some code, but that would be very strange: usually people don't continue after the first done (or none for a normal iterator). @rustbot label t-libs a-str a-patterns ", "commit_messages": " fix #85462 by adding a marker flag  this will not affect abi since the other variant of the enum is bigger.  it may break some code, but that would be very strange: usually people  don't continue after the first done (or none for a normal iterator).  add test for the fix ", "linked_issue_titles": " strsearcher does not behave correctly with empty strings as needle/haystack ", "title": "make strsearcher behave correctly on empty needle"}
{"description": " (cherry picked from commit 0f268e7) fixes #44075 ios_user.py ansible version stable-2.5 ", "commit_messages": " fix ios_user issues (#44904)  * fix ios_user issues  * modify regex and fix unittests  (cherry picked from commit 0f268e70a1694f4f40e7251fb9488602d2c0a616)  added changelog ", "linked_issue_titles": "", "title": "fix ios_user issue cp in 2.5"}
{"description": " editor output folder: modules\\keyboardmanager\\keyboardmanagereditor keyboardmanagereditorlibrary and keyboardmanagerenginelibrary output folder: modules\\keyboardmanager what is include in the pr: rebuild projects and verify that files are in place. linked issue: #10127 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " editor output folder  lib output ", "linked_issue_titles": "", "title": "changed editor and libraries output folders"}
{"description": " this pr fixes the path of the secret key value in the deployment. in the values.yaml file and readme the path of the secret key is auth.secret.key. however, in the deployment the path is secret.key. the pr also updates the redisaddress field in the readme to indicate that rediss:// should be used for ssl connections. none dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " update secret key path in deployment  clarify use of ssl connections in redis address  update chart version ", "linked_issue_titles": "", "title": "fix secret key path in deployment"}
{"description": " the first commit allows us to run markdown in serial mode again (the remark plugin was not awaiting the cache plugins so it was not properly running in serial). this may also fix a race condition where the same source is parsed twice at the same time, since the cache.set call of the first may not have been completed when the second starts. but that's a very unlike scenario as these caches are more likely to be hit for subsequent builds, not the same session. the remaining commits refactor the code. i can be okay to drop most of them if people feel it's too much. ", "commit_messages": " chore(gatsby-transformer-remark): refactor async logic to allow serial mode  refactor the rest while we are here  move addslugtourl out of the inner-inner function  arrow -> nfe ", "linked_issue_titles": "", "title": "wait for cache promises before returning"}
{"description": " fixes #8337 #8431 this pr cleans up some of the health-related documentation, and adds references to the [health] section of netdata.conf, as requested by chris, and makes consistent how we reference the ip/fqdn of a user's node. i do want to push this node syntax across the docs, but that's for another project. component name health/ ", "commit_messages": " fix chris' bug and cleanup  fixes for thiago ", "linked_issue_titles": " health configuration interconnections ", "title": "improve health docs by adding daemon config to health section and standardizing ip references"}
{"description": " add parameters to module vmware_guest for conversion of disk to thin or thick when vm is cloned or deployed with template @akasurde vmware_guest.py ansible version 2.8-devel ", "commit_messages": " update vmware_guest.py  add parameters to module vmware_guest for conversion of disk to thin or thick when vm is cloned or deployed with template  update vmware_guest.py ", "linked_issue_titles": "", "title": "update vmware_guest.py  add option to modify disk type while cloning template"}
{"description": " additional changes: 36cefa6 i read the contributor guide and followed the process outlined there for submitting prs. i read the tree hygiene wiki page, which explains my responsibilities. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i updated/added relevant documentation (doc comments with ///). i added new tests to check the change i am making or feature i am adding, or hixie said the pr is test-exempt. if you need help, consider asking for advice on the #hackers-new channel on discord. ", "commit_messages": " reland \"make filteringtextinputformatter's filtering selection/composing region agnostic\"  relax assert constraints in fluteringtextinputformatter ", "linked_issue_titles": "", "title": "reland \"make filteringtextinputformatter's filtering selection/composing region agnostic\" #89327"}
{"description": " most important is the aml fix for the mode strings, that they changed in latest sdk (top-left corner thumb effect) @holzhaus can provide more info on the libamcodec.so patch. for review: @mrmc @stefansaraev @stane1983 ", "commit_messages": " pd#113872:first kodi 15.2 version for amlogic  1.fixed can not play h265 and 4k with amcodec  2.fixed video zoom error  3.merge some patch from old versionx  change-id: i79e333d5ce30ea461f849416df446032d8936d85  chg: [aml] remove cpufreq hacks  chg: [aml] drop device-specific hacks  fix: [aml] smarter capabilities detection  [amlcodec] remove unreachable code in set_header_info()  [amlcodec] remove unused methods/members from dlllibamcodec/am_private_t  the methods \"h263vld\" and \"decodeble_h263()\" from dlllibamcodec are not  used anymore. the \"h263_decodable\" member from the am_private_t struct  is also obsolete now. although the struct member \"flv_flag\" gets  assigned, is never read, so we remove it, too.  [amlcodec] remove dependency on amffmpeg and use libavutil instead  [amlcodec] use libamcodec.so if libamplayer.so is missing  some linux distibutions like openelec and archlinuxarm ship  libamcodec.so instead of libamplayer.so, which is included in the latest  buildroot package (2015-01-20-4a5990f135) from amlogic:    (buildroot/package/multimedia/aml_libs/src/amcodec/makefile, line 26)  thus, users of these distros will eventually run into this issue:  error: unable to load libamplayer.so, reason: libamplayer.so: cannot  open shared object file: no such file or directory  this commit fixes that by checking if libamplayer.so can be loaded, and  if not, we'll try to use libamcodec.so instead. ", "linked_issue_titles": "", "title": "various aml fixes and cleanups"}
{"description": " this pr is the refactoring mentioned here: #29135 tbc the clients (amazonec2 and storage) were already built lazily (and cached and reused) for the afore mentioned plugins. this is the refactoring of that logic. the 'client settings' and the 'client instance' always had to go together which made the code bug prone, i.e. when the settings changed you had to make sure the client was destroyed so that it was lazily rebuilt using the new settings. for the discovery-ec2 and repository-gcs plugins, it replaces the duality '(map) client settings' - '(map) client instance' with a lazy client supplier. the supplier encapsulates the settings required to build the client. the lazy supplier caches the returned value once computed. this factors out the memoize supplier behavior (e.g. elasticsearch/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/internalawss3service.java line 75 918827c public amazons3reference client(string clientname) { ) in a lazy instance. this change was not required for the repository-azure plugin as it does not caches client instances (hence only the settings are stored) because client instances are not thread-safe. this change cannot be applied to the repository-s3 plugin, until the feature branch reload-secure-store-action is merged, because this plugin explicitly requires the settings to be stored so that they can be overriden from the cluster state ( elasticsearch/plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/s3repository.java line 223 918827c void overridecredentialsfromclusterstate(awss3service awsservice) { ), see also: 17d0155 originally, the goal for this refactoring was much more ambitious: to have an abstract component that creates and caches clients for all plugins that have clients using secure settings. but this is currently not possible, as the plugin requirements are quite diverse, eg: discovery-ec2 and repository-s3 have closeable, thread-safe clients, but the repository-azure clients are not thread-safe. repository-gcs clients are thread-safe but not closeable. the repository plugins use a dictionary of clients, but the discovery-ec2 plugin only uses one client. relates #29135 ", "commit_messages": " added lazy  gcs removed double map (config + clients)  ec2 plugin lazy client ditching cached settings ", "linked_issue_titles": "", "title": "ec2 and gcs plugins build client lazily"}
{"description": " this adds the following new functionality: envvar $systemd_in_initrd can be used to test generator behaviour in the real system allow{suspend,hibernation,suspendthenhibernate,hybridsleep}=yes|no can be used to pick what does are advertised 'noresume' on the kernel command line can be used to disable resuming (only to be used in rare circumstances, for example when the filesystem was modified using a different root partition and the resume image is stale). the longer-term goal is to autodetect the resume partition. but that is a more complicated problem and cannot be solved in all cases. so even if we have auto-detection, we still need to disable hibernation in cases where we cannot auto-detect the resume partition. also, people want to disable hibernation if it does not work on their hardware. i'll submit the autodection part later. ", "commit_messages": " bootspec: fix include lines  list all files we use definitions from.  bootspec: rename \"filename\" field to \"id\"  this follows the renaming done a few commits earlier too systemd-boot  itself.  also, let's show the id, since it's useful. ", "linked_issue_titles": "", "title": "switches to disable hibernation and/or resuming"}
{"description": " add a note about custom cuda paths in windows guide, like in linux one. encourage users to pass boost paths via cmake options instead of environment variables to deal with cmp0074. i tested on windows 10 with visual studio 2017 the following cases: cmake 3.14.1 and boost 1.69.0 (after adding cmp0074); cmake 3.11.0 and boost 1.65.1 (before adding cmp0074). they worked fine. closed #2081. refer to #2081 (comment), #1632, ", "commit_messages": " updated installation guide  updated python installation guide  added note about opencl path to windows section  added space before path in message  minor correction for option description in python installation guide ", "linked_issue_titles": " error: please install cmake first ", "title": "updated the part about boost in installation guide"}
{"description": " description: the set_config_paramter failed for devices having an int in the configuration option list. while debugging this, i also came accross another bug, that button value types were not set, and generated a traceback. this is also fixed in this pr. related issue (if applicable): fixes #12419 pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.github.io#<home-assistant.github.io pr number goes here> example entry for configuration.yaml (if applicable): checklist: local tests pass with tox. your pr cannot be merged unless tests pass documentation added/updated in home-assistant.github.io new dependencies have been added to the requirements variable (example). new dependencies are only imported inside functions that use them (example). new dependencies have been added to requirements_all.txt by running script/gen_requirements_all.py. new files were added to .coveragerc. if the code does not interact with devices: ", "commit_messages": " cast list and bool options to str  add button options to str  add type_button to value types  adjust comparison  remove logging  remove empty line  update tests ", "linked_issue_titles": " zwave node configuration options broken? ", "title": "zwave set_config_parameter failed when config list contained int"}
{"description": " this fixes a bug that only became apparent when wasm2js started to emit more interesting js code, which confused the pass. historically the pass was just used on asm.js globals, which are trivial, and it was reused for wasm2js, but as wasm2js output changed we ran into the issue. specifically, the old code made some assumptions about fastcomp output like that the first item shouldn't be minified, and that we can ignore some things and not others; those hacks are now all removed. the new design is cleaner and more general, but still not 100% fully general, see the corner case it doesn't handle in the comment. it may be good to handle that to prevent future bugs, but it would add significant complexity here. adding just an assert might be better, but that would still need the complexity to reason about scopes. unintentionally, this cleaner design can also do better at minifying, improving wasm2js hello world's total size by over 10% (!) this removes the old fastcomp-style handling in minifyglobals, with the testcase for that. the new pass just focuses on wasm2js's output format. once this lands we can re-enable minification in binaryen.js ci, which is disabled atm. ", "commit_messages": " fix? [ci skip]  update tests  work [ci skip]  update tests  comment ", "linked_issue_titles": "", "title": "rewrite minifyglobals js optimizer pass"}
{"description": " i have followed (at least) the pr section of the contributing guide. as per #14427 (comment) closes #14427 ", "commit_messages": " fix 1 new autofill error occurance.  completed fix ", "linked_issue_titles": " [textfield] handle chrome autofill ", "title": "fix remaining issues with chrome autofill"}
{"description": " some small improvements to texteditor. set cut and copy actions to disabled on init and enable them first when a selection is made. this is mostly an indicator to the user that it's not possible to use these actions with nothing selected. previously they would simply not do anything when clicked. reset editor width when disabling preview mode. when disabling preview mode after adjusting the splitter the editor would still be fixed width and therefore not fill out the window. this is one of the solutions that @trflynn89 proposed in #7462. i believe it's an ok fix in this particular case, but with splitters containing more elements his other solution might be better suited. fixes #7462 don't discard changes if user closes save dialog. this breaks out the save-if-modified-logic into it's own function, getting rid of some code duplication and makes sure that the  logic in 9720261 also applies when the user aborts a save dialog on new/open and not just on exit. dropping this one since it was fixed in 928364e. ", "commit_messages": " libgui/texteditor: set cut and copy actions to disabled on init  we can presume that there is nothing to cut or copy on init since  nothing is selected yet.  texteditor: reset editor width when disabling preview mode  when disabling preview mode, reset the fixed width of m_editor so that  it fills out the window again even after resizing the splitter. ", "linked_issue_titles": " texteditor: \"no preview\" mode does not hide preview panel ", "title": "small fixes when asking to save & disabling preview mode"}
{"description": " when the viewport is moved to the \"virtual bottom\" of the buffer (via the movetobottom method), it is important that the horizontal viewport offset be left as it is, otherwise that can result in some undesirable side effects. since the vt coordinate system is relative to the top of the viewport, many vt operations call the movetobottom method to make sure the viewport is correctly positioned before proceeding. there is no need for the horizontal position to be adjusted, though, since the x coordinates are not constrained by the viewport, but are instead relative to the underlying buffer. setting the viewport x coordinate to 0 in movetobottom (as we were previously doing) could result in the cursor being pushed off screen. and if the operation itself was moving the cursor, that would then trigger another viewport move to bring the cursor back into view. these conflicting movements meant the viewport was always forced as far left as possible, and could also result in cursor \"droppings\" as the cursor lost track of where it had been. i've now fixed this by updating the getvirtualviewport method to match the horizontal offset of the active viewport, instead of having the x coordinate hardcoded to 0. i've manually confirmed that this fixes the cursor \"droppings\" test case reported in issue #8213. i've also added a screen buffer test that makes sure the movetobottom method is working as expected, and not changing the horizontal viewport offset when it moves down. closes #8213 ", "commit_messages": " retain the horizontal viewport offset in the virtual viewport.  add test to confirm x offset isn't updated by movetobottom. ", "linked_issue_titles": " more cursor droppings ", "title": "retain horizontal viewport offset when moving to bottom"}
{"description": " ability to customize webview2 version needed in order to add access to the winui webview2 control. added  option to experimental features. microsoft reviewers: open in codeflow ", "commit_messages": " add webview2version to experimental props  change files ", "linked_issue_titles": "", "title": "add webview2 version customization to experimental features"}
{"description": " this prevents failing to write to these clusters from failing the entire write operation. ", "commit_messages": " feels bad  it's not as bad as it looks  test suppression wrapper  explain suppressionwrapper  explain return type of get_cluster ", "linked_issue_titles": "", "title": "enable marking clusters as non-durable for writes"}
{"description": " inspired by the direction @bjnath took in the rewrite of the glossary page in gh-16996, i moved many of the numpy/doc/*.py informative documents into their *.rst counterparts. i used git grep doc.xxx to find places the page was referenced, copy-pasted the content of the page as-is into its counterpart git rm numpy/doc.xxx.py removed it from test_public_apii. in the second commit, which was suprisingly small, i cleaned up a few build problems with the resulting docs. i did not remove numpy/doc/consts.py nor numpy/doc/ufuncs.py since the former is code with docstrings for constants, and the latter should be merged with the content in doc/source/reference/ufuncs.rst. once this goes in, it will be easier to review the content of gh-16996. ", "commit_messages": " doc: redistribute docstring-only content from numpy/doc  doc: post-transition clean-up ", "linked_issue_titles": "", "title": "move informational files from numpy.doc..py to their .rst counterparts"}
{"description": " this pr adds example code for fsner (few-shot named entity recognition) using huggingface's transformers library. only prediction/inference code is provided, training code will be provided very soon. did you read the contributor guideline, was this discussed/approved via a github issue or the forum? please add a link #13155 documentation guidelines, and here are tips on formatting docstrings. @nielsrogge @lysandrejik ", "commit_messages": " add example use of few-shot named entity recognition model in research_projects folder.  apply suggestions from code review  update fsner example readme.md.  - change wrong import fsnertokenizerwrapper to fsnertokenizerutils in the example code  - add a link to the model identifier  update examples/research_projects/fsner/src/fsner/model.py  fix spelling mistake in the default parameter of pretrained model name.  add example use of few-shot named entity recognition model in research_projects folder.  apply suggestions from code review  update fsner example readme.md.  - change wrong import fsnertokenizerwrapper to fsnertokenizerutils in the example code  - add a link to the model identifier  update examples/research_projects/fsner/src/fsner/model.py  fix spelling mistake in the default parameter of pretrained model name.  run checking/fixing examples/flax/language-modeling/run_clm_flax.py examples/flax/question-answering/run_qa.py examples/flax/question-answering/utils_qa.py examples/flax/token-classification/run_flax_ner.py examples/legacy/multiple_choice/utils_multiple_choice.py examples/legacy/seq2seq/seq2seq_trainer.py examples/legacy/token-classification/utils_ner.py examples/pytorch/image-classification/run_image_classification.py examples/pytorch/language-modeling/run_clm.py examples/pytorch/language-modeling/run_clm_no_trainer.py examples/pytorch/language-modeling/run_mlm.py examples/pytorch/language-modeling/run_mlm_no_trainer.py examples/pytorch/language-modeling/run_plm.py examples/pytorch/multiple-choice/run_swag.py examples/pytorch/multiple-choice/run_swag_no_trainer.py examples/pytorch/question-answering/run_qa.py examples/pytorch/question-answering/run_qa_beam_search.py examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py examples/pytorch/question-answering/run_qa_no_trainer.py examples/pytorch/summarization/run_summarization.py examples/pytorch/summarization/run_summarization_no_trainer.py examples/pytorch/test_examples.py examples/pytorch/text-classification/run_glue.py examples/pytorch/text-classification/run_glue_no_trainer.py examples/pytorch/text-classification/run_xnli.py examples/pytorch/token-classification/run_ner.py examples/pytorch/token-classification/run_ner_no_trainer.py examples/pytorch/translation/run_translation.py examples/pytorch/translation/run_translation_no_trainer.py examples/research_projects/adversarial/utils_hans.py examples/research_projects/distillation/grouped_batch_sampler.py examples/research_projects/fsner/setup.py examples/research_projects/fsner/src/fsner/__init__.py examples/research_projects/fsner/src/fsner/model.py examples/research_projects/fsner/src/fsner/tokenizer_utils.py examples/research_projects/jax-projects/big_bird/evaluate.py examples/research_projects/jax-projects/hybrid_clip/run_hybrid_clip.py examples/tensorflow/language-modeling/run_clm.py examples/tensorflow/multiple-choice/run_swag.py examples/tensorflow/question-answering/run_qa.py examples/tensorflow/summarization/run_summarization.py examples/tensorflow/text-classification/run_glue.py examples/tensorflow/translation/run_translation.py src/transformers/__init__.py src/transformers/commands/add_new_model.py src/transformers/configuration_utils.py src/transformers/convert_slow_tokenizer.py src/transformers/data/__init__.py src/transformers/data/data_collator.py src/transformers/data/datasets/glue.py src/transformers/data/datasets/language_modeling.py src/transformers/data/datasets/squad.py src/transformers/deepspeed.py src/transformers/dependency_versions_table.py src/transformers/feature_extraction_sequence_utils.py src/transformers/file_utils.py src/transformers/generation_flax_utils.py src/transformers/generation_logits_process.py src/transformers/generation_tf_utils.py src/transformers/generation_utils.py src/transformers/integrations.py src/transformers/modelcard.py src/transformers/modeling_flax_utils.py src/transformers/modeling_outputs.py src/transformers/modeling_tf_utils.py src/transformers/modeling_utils.py src/transformers/models/__init__.py src/transformers/models/albert/__init__.py src/transformers/models/albert/modeling_albert.py src/transformers/models/albert/modeling_flax_albert.py src/transformers/models/albert/tokenization_albert_fast.py src/transformers/models/auto/__init__.py src/transformers/models/auto/auto_factory.py src/transformers/models/auto/configuration_auto.py src/transformers/models/auto/dynamic.py src/transformers/models/auto/feature_extraction_auto.py src/transformers/models/auto/modeling_auto.py src/transformers/models/auto/modeling_flax_auto.py src/transformers/models/auto/modeling_tf_auto.py src/transformers/models/auto/tokenization_auto.py src/transformers/models/bart/configuration_bart.py src/transformers/models/bart/modeling_bart.py src/transformers/models/bart/modeling_flax_bart.py src/transformers/models/bart/modeling_tf_bart.py src/transformers/models/barthez/tokenization_barthez_fast.py src/transformers/models/beit/__init__.py src/transformers/models/beit/configuration_beit.py src/transformers/models/beit/modeling_beit.py src/transformers/models/beit/modeling_flax_beit.py src/transformers/models/bert/configuration_bert.py src/transformers/models/bert/modeling_bert.py src/transformers/models/bert/modeling_flax_bert.py src/transformers/models/bert_generation/configuration_bert_generation.py src/transformers/models/bert_generation/modeling_bert_generation.py src/transformers/models/big_bird/configuration_big_bird.py src/transformers/models/big_bird/modeling_big_bird.py src/transformers/models/big_bird/modeling_flax_big_bird.py src/transformers/models/big_bird/tokenization_big_bird_fast.py src/transformers/models/bigbird_pegasus/configuration_bigbird_pegasus.py src/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py src/transformers/models/blenderbot/configuration_blenderbot.py src/transformers/models/blenderbot/modeling_blenderbot.py src/transformers/models/blenderbot/modeling_tf_blenderbot.py src/transformers/models/blenderbot_small/configuration_blenderbot_small.py src/transformers/models/blenderbot_small/modeling_blenderbot_small.py src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py src/transformers/models/byt5/tokenization_byt5.py src/transformers/models/camembert/tokenization_camembert_fast.py src/transformers/models/canine/configuration_canine.py src/transformers/models/canine/modeling_canine.py src/transformers/models/clip/configuration_clip.py src/transformers/models/clip/convert_clip_original_pytorch_to_hf.py src/transformers/models/clip/modeling_clip.py src/transformers/models/clip/modeling_flax_clip.py src/transformers/models/clip/tokenization_clip.py src/transformers/models/convbert/modeling_convbert.py src/transformers/models/ctrl/configuration_ctrl.py src/transformers/models/deberta/modeling_tf_deberta.py src/transformers/models/deberta_v2/__init__.py src/transformers/models/deberta_v2/modeling_deberta_v2.py src/transformers/models/deberta_v2/modeling_tf_deberta_v2.py src/transformers/models/deit/configuration_deit.py src/transformers/models/deit/modeling_deit.py src/transformers/models/detr/configuration_detr.py src/transformers/models/detr/modeling_detr.py src/transformers/models/distilbert/__init__.py src/transformers/models/distilbert/configuration_distilbert.py src/transformers/models/distilbert/modeling_distilbert.py src/transformers/models/distilbert/modeling_flax_distilbert.py src/transformers/models/dpr/configuration_dpr.py src/transformers/models/dpr/modeling_dpr.py src/transformers/models/electra/modeling_electra.py src/transformers/models/electra/modeling_flax_electra.py src/transformers/models/encoder_decoder/__init__.py src/transformers/models/encoder_decoder/modeling_encoder_decoder.py src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py src/transformers/models/flaubert/configuration_flaubert.py src/transformers/models/flaubert/modeling_flaubert.py src/transformers/models/fnet/__init__.py src/transformers/models/fnet/configuration_fnet.py src/transformers/models/fnet/convert_fnet_original_flax_checkpoint_to_pytorch.py src/transformers/models/fnet/modeling_fnet.py src/transformers/models/fnet/tokenization_fnet.py src/transformers/models/fnet/tokenization_fnet_fast.py src/transformers/models/fsmt/configuration_fsmt.py src/transformers/models/fsmt/modeling_fsmt.py src/transformers/models/funnel/configuration_funnel.py src/transformers/models/gpt2/__init__.py src/transformers/models/gpt2/configuration_gpt2.py src/transformers/models/gpt2/modeling_flax_gpt2.py src/transformers/models/gpt2/modeling_gpt2.py src/transformers/models/gpt2/modeling_tf_gpt2.py src/transformers/models/gpt_neo/configuration_gpt_neo.py src/transformers/models/gpt_neo/modeling_gpt_neo.py src/transformers/models/gptj/__init__.py src/transformers/models/gptj/configuration_gptj.py src/transformers/models/gptj/modeling_gptj.py src/transformers/models/herbert/tokenization_herbert_fast.py src/transformers/models/hubert/__init__.py src/transformers/models/hubert/configuration_hubert.py src/transformers/models/hubert/convert_hubert_original_s3prl_checkpoint_to_pytorch.py src/transformers/models/hubert/modeling_hubert.py src/transformers/models/hubert/modeling_tf_hubert.py src/transformers/models/ibert/modeling_ibert.py src/transformers/models/layoutlm/__init__.py src/transformers/models/layoutlm/configuration_layoutlm.py src/transformers/models/layoutlm/modeling_layoutlm.py src/transformers/models/layoutlmv2/__init__.py src/transformers/models/layoutlmv2/configuration_layoutlmv2.py src/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py src/transformers/models/layoutlmv2/modeling_layoutlmv2.py src/transformers/models/layoutlmv2/processing_layoutlmv2.py src/transformers/models/layoutlmv2/tokenization_layoutlmv2.py src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py src/transformers/models/led/configuration_led.py src/transformers/models/led/modeling_led.py src/transformers/models/longformer/modeling_longformer.py src/transformers/models/luke/configuration_luke.py src/transformers/models/luke/modeling_luke.py src/transformers/models/luke/tokenization_luke.py src/transformers/models/lxmert/configuration_lxmert.py src/transformers/models/m2m_100/configuration_m2m_100.py src/transformers/models/m2m_100/modeling_m2m_100.py src/transformers/models/m2m_100/tokenization_m2m_100.py src/transformers/models/marian/configuration_marian.py src/transformers/models/marian/modeling_flax_marian.py src/transformers/models/marian/modeling_marian.py src/transformers/models/marian/modeling_tf_marian.py src/transformers/models/mbart/configuration_mbart.py src/transformers/models/mbart/modeling_flax_mbart.py src/transformers/models/mbart/modeling_mbart.py src/transformers/models/mbart/tokenization_mbart.py src/transformers/models/mbart/tokenization_mbart_fast.py src/transformers/models/mbart50/tokenization_mbart50.py src/transformers/models/mbart50/tokenization_mbart50_fast.py src/transformers/models/megatron_bert/configuration_megatron_bert.py src/transformers/models/megatron_bert/convert_megatron_bert_checkpoint.py src/transformers/models/megatron_bert/modeling_megatron_bert.py src/transformers/models/megatron_gpt2/convert_megatron_gpt2_checkpoint.py src/transformers/models/openai/configuration_openai.py src/transformers/models/pegasus/__init__.py src/transformers/models/pegasus/configuration_pegasus.py src/transformers/models/pegasus/modeling_flax_pegasus.py src/transformers/models/pegasus/modeling_pegasus.py src/transformers/models/pegasus/modeling_tf_pegasus.py src/transformers/models/pegasus/tokenization_pegasus_fast.py src/transformers/models/prophetnet/configuration_prophetnet.py src/transformers/models/prophetnet/modeling_prophetnet.py src/transformers/models/rag/modeling_rag.py src/transformers/models/rag/modeling_tf_rag.py src/transformers/models/reformer/configuration_reformer.py src/transformers/models/reformer/tokenization_reformer_fast.py src/transformers/models/rembert/configuration_rembert.py src/transformers/models/rembert/modeling_rembert.py src/transformers/models/rembert/tokenization_rembert_fast.py src/transformers/models/roberta/modeling_flax_roberta.py src/transformers/models/roberta/modeling_roberta.py src/transformers/models/roberta/modeling_tf_roberta.py src/transformers/models/roformer/configuration_roformer.py src/transformers/models/roformer/modeling_roformer.py src/transformers/models/speech_encoder_decoder/__init__.py src/transformers/models/speech_encoder_decoder/configuration_speech_encoder_decoder.py src/transformers/models/speech_encoder_decoder/convert_speech_to_text_wav2vec2_seq2seq_original_to_pytorch.py src/transformers/models/speech_encoder_decoder/modeling_speech_encoder_decoder.py src/transformers/models/speech_to_text/configuration_speech_to_text.py src/transformers/models/speech_to_text/feature_extraction_speech_to_text.py src/transformers/models/speech_to_text/modeling_speech_to_text.py src/transformers/models/speech_to_text_2/__init__.py src/transformers/models/speech_to_text_2/configuration_speech_to_text_2.py src/transformers/models/speech_to_text_2/modeling_speech_to_text_2.py src/transformers/models/speech_to_text_2/processing_speech_to_text_2.py src/transformers/models/speech_to_text_2/tokenization_speech_to_text_2.py src/transformers/models/splinter/configuration_splinter.py src/transformers/models/splinter/modeling_splinter.py src/transformers/models/t5/configuration_t5.py src/transformers/models/t5/modeling_flax_t5.py src/transformers/models/t5/modeling_t5.py src/transformers/models/t5/modeling_tf_t5.py src/transformers/models/t5/tokenization_t5_fast.py src/transformers/models/tapas/__init__.py src/transformers/models/tapas/configuration_tapas.py src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py src/transformers/models/tapas/modeling_tapas.py src/transformers/models/tapas/tokenization_tapas.py src/transformers/models/transfo_xl/configuration_transfo_xl.py src/transformers/models/visual_bert/modeling_visual_bert.py src/transformers/models/vit/configuration_vit.py src/transformers/models/vit/convert_dino_to_pytorch.py src/transformers/models/vit/modeling_flax_vit.py src/transformers/models/vit/modeling_vit.py src/transformers/models/wav2vec2/__init__.py src/transformers/models/wav2vec2/configuration_wav2vec2.py src/transformers/models/wav2vec2/convert_wav2vec2_original_s3prl_checkpoint_to_pytorch.py src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py src/transformers/models/wav2vec2/modeling_flax_wav2vec2.py src/transformers/models/wav2vec2/modeling_wav2vec2.py src/transformers/models/wav2vec2/tokenization_wav2vec2.py src/transformers/models/xlm/configuration_xlm.py src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py src/transformers/models/xlnet/configuration_xlnet.py src/transformers/models/xlnet/tokenization_xlnet_fast.py src/transformers/onnx/convert.py src/transformers/onnx/features.py src/transformers/optimization.py src/transformers/pipelines/__init__.py src/transformers/pipelines/audio_classification.py src/transformers/pipelines/automatic_speech_recognition.py src/transformers/pipelines/base.py src/transformers/pipelines/conversational.py src/transformers/pipelines/feature_extraction.py src/transformers/pipelines/fill_mask.py src/transformers/pipelines/image_classification.py src/transformers/pipelines/object_detection.py src/transformers/pipelines/question_answering.py src/transformers/pipelines/table_question_answering.py src/transformers/pipelines/text2text_generation.py src/transformers/pipelines/text_classification.py src/transformers/pipelines/text_generation.py src/transformers/pipelines/token_classification.py src/transformers/pipelines/zero_shot_classification.py src/transformers/testing_utils.py src/transformers/tokenization_utils.py src/transformers/tokenization_utils_base.py src/transformers/tokenization_utils_fast.py src/transformers/trainer.py src/transformers/trainer_callback.py src/transformers/trainer_pt_utils.py src/transformers/trainer_seq2seq.py src/transformers/trainer_utils.py src/transformers/training_args.py src/transformers/training_args_seq2seq.py src/transformers/utils/dummy_detectron2_objects.py src/transformers/utils/dummy_flax_objects.py src/transformers/utils/dummy_pt_objects.py src/transformers/utils/dummy_tf_objects.py src/transformers/utils/dummy_tokenizers_objects.py src/transformers/utils/dummy_vision_objects.py tests/deepspeed/test_deepspeed.py tests/sagemaker/conftest.py tests/sagemaker/test_multi_node_data_parallel.py tests/test_configuration_auto.py tests/test_configuration_common.py tests/test_data_collator.py tests/test_feature_extraction_auto.py tests/test_feature_extraction_layoutlmv2.py tests/test_feature_extraction_speech_to_text.py tests/test_feature_extraction_wav2vec2.py tests/test_file_utils.py tests/test_modeling_auto.py tests/test_modeling_bart.py tests/test_modeling_beit.py tests/test_modeling_bert.py tests/test_modeling_clip.py tests/test_modeling_common.py tests/test_modeling_convbert.py tests/test_modeling_deit.py tests/test_modeling_distilbert.py tests/test_modeling_encoder_decoder.py tests/test_modeling_flaubert.py tests/test_modeling_flax_albert.py tests/test_modeling_flax_bart.py tests/test_modeling_flax_beit.py tests/test_modeling_flax_distilbert.py tests/test_modeling_flax_encoder_decoder.py tests/test_modeling_flax_gpt2.py tests/test_modeling_flax_gpt_neo.py tests/test_modeling_flax_mt5.py tests/test_modeling_flax_pegasus.py tests/test_modeling_fnet.py tests/test_modeling_gpt2.py tests/test_modeling_gpt_neo.py tests/test_modeling_gptj.py tests/test_modeling_hubert.py tests/test_modeling_layoutlmv2.py tests/test_modeling_pegasus.py tests/test_modeling_rag.py tests/test_modeling_reformer.py tests/test_modeling_speech_encoder_decoder.py tests/test_modeling_speech_to_text.py tests/test_modeling_speech_to_text_2.py tests/test_modeling_tf_auto.py tests/test_modeling_tf_deberta_v2.py tests/test_modeling_tf_hubert.py tests/test_modeling_tf_pytorch.py tests/test_modeling_tf_wav2vec2.py tests/test_modeling_wav2vec2.py tests/test_onnx_v2.py tests/test_pipelines_audio_classification.py tests/test_pipelines_automatic_speech_recognition.py tests/test_pipelines_common.py tests/test_pipelines_conversational.py tests/test_pipelines_feature_extraction.py tests/test_pipelines_fill_mask.py tests/test_pipelines_image_classification.py tests/test_pipelines_object_detection.py tests/test_pipelines_question_answering.py tests/test_pipelines_summarization.py tests/test_pipelines_table_question_answering.py tests/test_pipelines_text2text_generation.py tests/test_pipelines_text_classification.py tests/test_pipelines_text_generation.py tests/test_pipelines_token_classification.py tests/test_pipelines_translation.py tests/test_pipelines_zero_shot.py tests/test_processor_layoutlmv2.py tests/test_processor_wav2vec2.py tests/test_sequence_feature_extraction_common.py tests/test_tokenization_auto.py tests/test_tokenization_byt5.py tests/test_tokenization_canine.py tests/test_tokenization_common.py tests/test_tokenization_fnet.py tests/test_tokenization_layoutlmv2.py tests/test_tokenization_luke.py tests/test_tokenization_mbart.py tests/test_tokenization_mbart50.py tests/test_tokenization_speech_to_text_2.py tests/test_tokenization_t5.py tests/test_tokenization_tapas.py tests/test_tokenization_xlm_roberta.py tests/test_trainer.py tests/test_trainer_distributed.py tests/test_trainer_tpu.py tests/test_utils_check_copies.py utils/check_copies.py utils/check_repo.py utils/notification_service.py utils/release.py utils/tests_fetcher.py  python utils/custom_init_isort.py  python utils/style_doc.py src/transformers docs/source --max_len 119  running deps_table_update  updating src/transformers/dependency_versions_table.py  python utils/check_copies.py  python utils/check_table.py  python utils/check_dummies.py  python utils/check_repo.py  checking all models are public.  checking all models are properly tested.  checking all objects are properly documented.  checking all models are in at least one auto class.  python utils/check_inits.py  python utils/tests_fetcher.py --sanity_check and fix suggested changes.  run black examples tests src utils  isort examples tests src utils  skipped 1 files  make autogenerate_code  make[1]: entering directory '/mnt/c/users/admin/desktop/home/projects/transformers'  running deps_table_update  updating src/transformers/dependency_versions_table.py  make[1]: leaving directory '/mnt/c/users/admin/desktop/home/projects/transformers'  make extra_style_checks  make[1]: entering directory '/mnt/c/users/admin/desktop/home/projects/transformers'  python utils/custom_init_isort.py  python utils/style_doc.py src/transformers docs/source --max_len 119  make[1]: leaving directory '/mnt/c/users/admin/desktop/home/projects/transformers' for reformatting code.  add installation dependencies for examples/research_projects/fsner. ", "linked_issue_titles": "", "title": "add fsner example in research_projects"}
{"description": " description: add 'priority' attribute to set the priority of the hyperion remote instance. pull request in home-assistant.github.io with documentation (if applicable): home-assistant/home-assistant.io#3751 example entry for configuration.yaml (if applicable): light: - platform: hyperion host: 127.0.0.1 priority: 128 checklist: documentation added/updated in home-assistant.github.io local tests with tox run successfully. your pr cannot be merged unless tests pass ", "commit_messages": " remove async_update (#9997)  light.hyperion: add priority attribute  allows to set the priority of the hyperion remote instance. ", "linked_issue_titles": "", "title": "add priority attribute for hyperion"}
{"description": " change types to have latest api in  p.s: current readme wasn't updated after keys() method removal, pr already exist to fix that: jonschlinkert/parse-git-config#11 and there is only expandkeys() method left: ", "commit_messages": " sync latest parse-git-config api changes  parse-git-config - fix tabulation ", "linked_issue_titles": "", "title": "sync with latest api changes"}
{"description": " related issue: 55f98ce#r51139097 import oimo via namespace to make the oimophysics.js helper work also in the examples/js world since the library is exposed as window.oimo in non-module script. ", "commit_messages": " import oimo using namespace  esline: add oimo in globals ", "linked_issue_titles": "", "title": "import oimo using its namespace"}
{"description": " this means you can set test_args on the command line, in a .properties config for a jenkins job, etc, to toggle gated features. for example: test_args='--feature-gates=dynamickubeletconfig=true' / this change is ", "commit_messages": " feature-gates flag plumbing for node e2e tests  this gives the node e2e test binary a --feature-gates flag that populates a  featuregates field on the test context. the value of this field is forwarded  to the kubelet's --feature-gates flag and is also used to populate the global  defaultfeaturegate object so that statically-linked components see the same  feature gate settings as provided via the flag.  this means that you can set feature gates via the test_args environment  variable when running node e2e tests. for example:  test_args='--feature-gates=dynamickubeletconfig=true'  enable dynamic kubelet configuration for node e2e jenkins serial tests  this commit enables the dynamic kubelet configuration feature for the  node e2e jenkins serial tests, which is where the test for dynamic kubelet  configuration currently runs. ", "linked_issue_titles": "", "title": "plumb --feature-gates from test_args to components in node e2e tests"}
{"description": " the user-agent format is \"tornado\\{tornado_version}\". if self.request.user_agent isn't set and self.request.headers has no user-agent in it's keys the default user-agent is added. fixes: #2702 ", "commit_messages": " getting changes from tornado december 9, 2019  added default user-agent to the simple http client if not provided.  the user-agent format is \"tornado\\{tornado_version}\".  if self.request.user_agent isn't set and self.request.headers has  no user-agent in it's keys the default user-agent is added.  fixes: #2702  checked request headers using it's get method.  fixes: #2702 ", "linked_issue_titles": " provide default user-agent in simpleasynchttpclient ", "title": "provided default user-agent to simpleasynchttpclient if not provided."}
{"description": " issue: #16763 #14612 #15246 #15855 not solve but provide a solution / or related for #15261 #15351 add styles and stylepreprocessoroptions options storybook angular builder allow the angular 12.2.x and >=13  project to set styles config without using browsertarget in order to rely on another builder's config. very useful in the case of a library where you don't have an application but you want to configure styles in storybook like an app ", "commit_messages": " fix(angular): missing remove oneof in builder schema  this onof is no more necessary  feat(angular): add styles and stylepreprocessoroptions to add dedicated styles config  allow the angular project to set styles config without using browsertarget in order to rely on another builder's config.  very useful in the case of a library where you don't have an application but you want to configure styles in storybook like an app ", "linked_issue_titles": "", "title": "add styles and stylepreprocessoroptions to angular builder"}
{"description": " i hereby agree to the terms of the cla available at:  fix infinite non joined block stream in partial_merge_join close #26325 ", "commit_messages": " cleanup joiningtransform::readexecute  fix infine non joined block stream in merge join ", "linked_issue_titles": " infinite loop in \"partial merge join\". ", "title": "fix infinite non joined block stream in merge join"}
{"description": " this pull request moves the logic from os::make_absolute() into the path module and fixes path joining for windows.  it does this by adding an unsafe_join() function that implements the operating system's path joining semantics. additionally it also adds an is_restricted() method to the trait which will return true if the path points to a windows device file. ", "commit_messages": " refactored make_absolute into functionality on the path  improved windows path handling support  added is_restricted() to path ", "linked_issue_titles": "", "title": "os::make_absolute() and windowspath refactoring and fixes"}
{"description": " create step 1 database ui connection flow to allow users to pick the type of engine before entering credentials add on to #14881  includes db migration (follow approval process in sip-59) ", "commit_messages": " poc picker for db selection  working select  setup is loading for available dbs and step1 view  fix on close  update on fetch ", "linked_issue_titles": "", "title": "allow users to pick engine"}
{"description": " the problem was that the library was assuming that fs::exists() would return false for directories, which is true for spiffs, but not for littlefs. i changed the implementation to be compatible with both. i don't like using fs.open(), but i couldn't find any better way to check if something is a directory or a file. if there is such a thing, please point me in the right direction and i will be happy to use that instead. ", "commit_messages": " remove trailing whitespace  improve \"is file\" check for littlefs support  the previous implementation was based on a quirk of spiffs (that exists  returns false for directories) so it wouldn't work with littlefs. this  implementation works with both. ", "linked_issue_titles": "", "title": "add littlefs support to esp8266webserver.servestatic()"}
{"description": " jenkins-27607 subsumes #1595: adds a test. @reviewbybees ", "commit_messages": " fix mime tipe with jsonp  using  refused to execute script from 'jenkins_url' because its mime type ('application/json') is not executable, and strict mime type checking is enabled.  fix: bump stapler version  bump stapler to lastest.  enh: bump stapler to stable version  bump to stapler 1.236 stable  [jenkins-27607] reproduced in test.  merged #1595 and enabled test. ", "linked_issue_titles": "", "title": "fix mime type with jsonp"}
{"description": " description: use the sni value as the upstream cluster name. this is similar to the cluster_header feature in hcm. leverages the perconnectionstate to dynamically control the cluster used by tcp_proxy filter. we plan to use this in istio, where pilot would manage two kubernetes setups, such that the envoys will have the same set of clusters, but the non-local clusters will have the ip of a gateway envoy (edge/front envoy). mtls traffic arriving at the gateway envoy will be routed to the internal (envoy)clusters based on the sni value depends on #4454 risk level: low testing: unit tests docs changes: yes release notes: yes ", "commit_messages": " cluster name from sni  tests and more  fixes  tests and fixes  streamline ", "linked_issue_titles": "", "title": "network filter to set upstream cluster from sni"}
{"description": " first pr for the implementation of on prem server. this pr adds the ability in oss to automatically manage local/onprem clusters. the user on the server runs python coordinator_server.py --ips  --ports then the user can modify the current example-full.yaml for local clusters and replace head_ip and worker_ips with coordinator_address as follows: before: # local specific configuration. provider: type: local head_ip: your_head_node_hostname worker_ips: [worker_node_1_hostname, worker_node_2_hostname, ... ] after: # local specific configuration. provider: type: local coordinator_address: \"<the coordinator address>\" in addition to auto-management, closes #9662. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " on prem server first commit  minor fix ", "linked_issue_titles": " can't reduce num_workers for local node provider ", "title": "on prem server first pr"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. ", "commit_messages": " docapi-5203: direct i/o settings for mergetree descriptions.  docapi-5203: edits after prereview of pull. ", "linked_issue_titles": "", "title": "direct i/o settings for mergetree descriptions. en review and ru translation."}
{"description": " checklist: my code follows the code style of this project. i have read the contributing document. ( it compiles correctly for the promicros, which is what i had to test with: * the firmware size is fine - 28664/28672 (8 bytes free) ", "commit_messages": " adding my keymap primarily to iris  adding my crkbd keymap and update my iris keymap readme with an extra pic ", "linked_issue_titles": "", "title": "adding my keymap for the helidox and update my iris keymap readme"}
{"description": " changes: make uvscalemap updates backwards-compatible fix error in morph targets if normal attributes are undefined (the frog rome model broke here) flatten a three.group if it only contains a single mesh try to eliminate more cases where names might be duplicated, breaking animation. examples: parent node and child mesh share the same name in source gltf mesh is reused by multiple nodes (see: cesiummilktruck) this fixes all of the rome examples, although they still require three.doubleside. demo:  the demo will print a tree of mesh names coming out of the loader. examples: animatedmorphsphere cesiummilktruck fixes #12368. problems with rome models were related to (1) missing normals in one model, and (2) nodes and meshes sharing names in many models. improves #11944, although there's still more we can do to flatten the output. polly (#12364) still does not work completely; the head disappears at odd intervals. looks like an animation problem, or some ambiguity in the gltf spec. ", "commit_messages": " gltfloader: deduplicate node/mesh names and flatten single-mesh nodes.  gltfloader: keep uvscalemap updates backwards-compatible.  gltfloader: disambiguate names for multiple instances of the same mesh. ", "linked_issue_titles": " gltfloader: morph targets not animating correctly in rome models ", "title": "more robust de-duping of mesh/node names, morph target fixes, etc."}
{"description": " dqn ape-x and ddpg ape-x agents do not take the value set by users for the parameter prioritized_replay  into account. in addition to the unexpected per behavior, this prevents these agents from being used with replay_mode=lockstep. closes #17540 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " feat(rllib/apex): do not update priorities when 'prioritized_replay == false'  feat(rllib/apex): prevent worker side prioritization without per  feat(rllib/ddpg): add config check for 'prioritized_replay' parameter  feat(rllib/ddpg): add config checks for 'prioritized_replay' parameter ", "linked_issue_titles": " [rllib] apex doesn't take the value of `prioritized_replay` into account. ", "title": "ape-x doesn't take the value of prioritized_replay into account"}
{"description": " for #8057. ", "commit_messages": " add tablecontainedrule  remove useless implements  refactor generic type of shardingspheremetadataloader  refactor generic type of shardingspheremetadataloader  refactor schemametadataloader  rename datanodecontainedrule's variable  remove useless shardingspheremetadataloader.load  refactor schemametadataloader  merge shardingspheremetadatadecorator into shardingspheremetadataloader ", "linked_issue_titles": "", "title": "add tablecontainedrule to simplify shardingspheremetadataloader"}
{"description": " this pr is trying to fix compilation problems in gpu code with msvc 2015, in issue #439. @tt83 can you test if it removes all warnings? for the long string literal problem i am still trying to figure out a clean resolution. ", "commit_messages": " fix warnings when compiled with -pedantic  add -dboost_all_no_lib for windows build ", "linked_issue_titles": "", "title": "fix compilation problems with msvc"}
{"description": " this is the proper fix / improvement for #7573 by supporting minimum/step/maximum not only in spinners but also in lists. to not duplicate a lot of code i added an additional base class csettingcontrolformattedrange used by csettingcontrolspinner and csettingcontrollist and i refactored the integer/string options handling so that the same code can be used by cguicontrolspinexsetting and cguicontrollistsetting. this doesn't touch the settings library at all because it already supports this use case. just the gui integration was missing this part. ", "commit_messages": " settings: use range based for loop in cguicontrolbasesetting and derived classes  settings: add support for minimum/step/maximum in csettingcontrollist  settings: refactor handling of integer/string spinners/lists and add support for minimum/step/maximum in cguicontrollistsetting ", "linked_issue_titles": "", "title": "support minimum/step/maximum in lists (not only spinners)"}
{"description": " removed trival warnings from the files ", "commit_messages": " removed warning from the file.  fixed the warning in the file.  removed warning from the file.  fixed warning from the file.  removed warning from the file.  fixed warning in the file.  fixed warning in the file.  removed the warning in the file. ", "linked_issue_titles": "", "title": "fixed warnings in the files"}
{"description": " prior modifications to the chart (in order to enforce mongo oplog for version 1.x+ )  creates a  mongodb replicaset consisting of 3x mongo instances.   this has unnecessarily tripled the resource requirement to deploy the default basic chart. this pr corrects the situation and starts a single mongodb instance with oplog enabled. significantly reducing the minimal deploy resource requirements. please review and test   @geekgonecrazy dco signed title of the pr starts with chart name (e.g. [stable/chart]) ", "commit_messages": " start mongo primary with oplog only by default; no need for secondary or arbiter  bump chart version ", "linked_issue_titles": "", "title": "correct mongodb to single node oplog enabled by default"}
{"description": " bug fixes in @next/eslint-plugin-next. adds rules to recommended config. ", "commit_messages": " addinng no html-link lint rule  fixing lint tests  adding the utils file  fixing lock file  prettier fix  bug fixes  exact regexpmatch ", "linked_issue_titles": "", "title": "bug fixes for lint routing"}
{"description": " original pull-request #19443 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " fix wrong parts in parts_to_do  update replicatedmergetreequeue.cpp  update replicatedmergetreequeue.cpp  addition to #15537 ", "linked_issue_titles": "", "title": "cherry pick #19443 to 20.12: addition to #15537"}
{"description": " document manage_inactivity function allow extruder_runout_prevent to work with all extruders use faster memcpy for copying coordinates fix some spelling in the configurations ", "commit_messages": " spacing and spelling  fix manage_inactivity  - document manage_inactivity function  - allow extruder_runout_prevent to work with all extruders  - use faster memcpy for copying coordinates ", "linked_issue_titles": "", "title": "optimize coordinate copying, fix extruder_runout_prevent"}
{"description": " fixes a part of #9325 fixes docstring parameters test for cross_decomposition and discriminant_analysis the issue is not closed, other packages still need to be checked. don't hesitate to tell me if i can improve anything in this pr! ", "commit_messages": " fixing cross_decomposition docstring parameters  fixing discriminant analysis docstring parameters ", "linked_issue_titles": "", "title": "docstring parameters improvements for cross_decomposition and discriminant_analysis"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). createkeyring:  createcryptokey:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. i'm not ", "commit_messages": " add createkeyring declarations  add createcryptokey declarations that don't quite work with all options  apparently it worked with rotationperiod  add nanos field to make it happy  function order  run lint  update package version from 1.3 to 1.5.1 in header ", "linked_issue_titles": "", "title": "add missing types for creating keyrings and cryptokeys"}
{"description": " addresses #4009 added : patch for moto sns create platform endpoint refactored api logic to use snsbackend class to keep track of state instead of global variables. refactored sns integration test to use snsbackend class instead of global variables ", "commit_messages": " merge original repo to update forked repo  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fix create platform endpoint idempotency ", "linked_issue_titles": "", "title": "sns create platform endpoint idempotency"}
{"description": " makes more ci jobs compatible with github actions. #631 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " fix typo in job triggers  check if travis before not enabling -ux  try gimme_go_version=stable  explicitly read file as utf-8 for check_import_order.py to address windows cp-1252 encoding issue  add llvm/clang to path on windows for linter  use gcc in build.sh for psutil ", "linked_issue_titles": "", "title": "factor out more travis code and update github actions"}
{"description": " fix #4873 ", "commit_messages": " fix a bug that index url is not correctly saved in pipfile  add news entry ", "linked_issue_titles": " `pipenv install --index <my-pypi-registry> <my-package>` generates a pipfile that `pipenv lock` can't handle ", "title": "fix a bug of source saving in pipfile"}
{"description": " part of #34338 ", "commit_messages": " add documentation for many of the atomic_* intrinsics  part of #34338  add documentation for the volatile_read and volatile_write intrinsics  part of #34338  add documentation for some of the add/sub/mul intrinsics  part of #34338 ", "linked_issue_titles": "", "title": "add documentation to some of the unstable intrinsics"}
{"description": " original pull-request #16205 this pull-request is a first step of an automated backporting. it contains changes like after calling a local command git cherry-pick. if you intend to continue backporting this changes, then resolve all conflicts if any. otherwise, if you do not want to backport them, then just close this pull-request. the check results does not matter at this step - you can safely ignore them. also this pull-request will be merged automatically as it reaches the mergeable state, but you always can merge it manually. ", "commit_messages": " add a test for dictget in sharding_key after dictionary reload  do not cache dictionary for dictget*/dicthas*  there are places where expressionactionsptr is cached  (storagedistributed caching it for sharding_key_expr and  optimize_skip_unused_shards), and if the dictionary will be cached  within \"query\" then cached expressionactionsptr will always have first  version of the query and the dictionary will not be updated after  reload.  for example this will fix dictget in sharding_key (and similar places,  i.e. when the function context is stored permanently)  fixes: 01527_dist_sharding_key_dictget_reload  do not cache dictionary for dictget*/dicthas* ", "linked_issue_titles": "", "title": "do not cache dictionary for dictget/dicthas"}
{"description": " improve git helper scripts and provide a readme.md fix spelling, formatting, and reduce size of some config comments ", "commit_messages": " minor fix in k8200 readme  tweak command index increment  tweak git helper scripts  edit configuration comments ", "linked_issue_titles": "", "title": "update git helper scripts, config comments"}
{"description": " this fix tries to fix the issue raised in #13506 where int64 data types for bounds in tf.image.pad_to_bounding_box crashes. the reason of the crash is caused by the fact that int64 was directly converted into int32 without passing through kernel registeration. this fix fixes the issue by adding typename tpadding to the template and adds appropriate kernels. this fix fixes #13506. ", "commit_messages": " add int64 bounds support for tf.image.pad_to_bounding_box  this fix tries to fix the issue raised in 13506 where int64 data types  for bounds in tf.image.pad_to_bounding_box crashes.  the reason of the crash is caused by the fact that int64 was directly  converted into int32 without passing through kernel registeration.  this fix fixes the issue by adding typename tpadding to the template.  this fix fixes 13506.  add test cases for int64 bounds of tf.image.pad_to_bounding_box  this fix adds test cases for int64 bounds of tf.image.pad_to_bounding_box  add gpu support for int64 bound of tf.image.pad_to_bounding_box  address gpu build for int64 bounds support of tf.image.pad_to_bounding_box ", "linked_issue_titles": " tf.image.pad_to_bounding_box crashes when passed bounds with dtype int64 ", "title": "fix crash when tf.pad is used with int64 paddings."}
{"description": " resolves #5069 ", "commit_messages": " add sections describing default and custom file names in file pipelines  add sections describing default and custom file names in file pipelines ", "linked_issue_titles": " document how to change file system storage default file name ", "title": "add docs sections describing default and custom file names"}
{"description": " change adds the packagefamilyname and productcode values to parsing by the manifest.  these can be at the root level, where they will be inherited.  they can also be provided per installer, but they must match the installertype or it will be an error. also makes major changes to the way the manifestversion is handled.  for now, the version is largely ignored (except it must be major version 0 if provided).  a concept of extensions is added, which are defined as the hyphen separated values after the primary version.  these can also be versioned, although the code does not exist to check it.  the syntax is: manifestversion := version (- extension) extension := version (- extension) where the version portion of extension is treated as name.version.  for instance, 1.0.0-extension and 1.0.0-extension.2. additionally: fixes an issue with the version sorting where additional version characters would sort higher than those without (ex. 1.0 will now be greater than 1.0-alpha) validation tests are added for packagefamilyname and productcode, as well as the manifest version parsing. microsoft reviewers: open in codeflow ", "commit_messages": " manifest parser updates to not be minor version strict and create extension semantics  add tests and fixes based on them ", "linked_issue_titles": "", "title": "add system reference values to manifest parsing"}
{"description": " what did you implement: adding documentation for environment variables how did you implement it: simple documentation change how can we verify it: check the doc/providers/spotinst/ : guide/variables.md guide/quick-start.md todos: write tests write documentation fix linting errors make sure code coverage hasn't dropped provide verification config / commands / resources enable \"allow edits from maintainers\" for this pr update the messages below is this ready for review?: yes is it a breaking change?: no ", "commit_messages": " spotinst- adding variables documentation in the user guide  spotinst - updating the quickstart guide  spotinst - fixing spelling error ", "linked_issue_titles": "", "title": "spotinst - adding documentation for new environment variables feature and update the quick start"}
{"description": " after the merging of #9848 , we can now interact with the jsonapi endpoints of a drupal site behind basic authentication. this works, however gatsby cannot retrieve remote files, because the calls executed in createremotefilenode do not currently take into consideration the basic auth credentials. this pull request adds those credentials so that files are correctly fetched from the remote drupal site behind basic auth. ", "commit_messages": " gatsby-source-drupal: use basic auth credentials also when fetching remote files.  gatsby-source-drupal: better support the case where no basic auth is specified. ", "linked_issue_titles": "", "title": "use basic auth credentials to fetch remote files as well."}
{"description": " resolve #6163 conflicts adding suggested changes. most of the resources was already listed, so in those cases complete info according to review suggestions. resolves #6163, closes #6163, locks #6163 read our contributing guidelines search for duplicates. #6163 ", "commit_messages": " add book mysql  fixing  added course laravel  update free-courses-id.md  fixing directly youtube  added belajar vue.js  fixing book mysql & course laravel  solve lint errors + add book author as seen in the footer of webpage  add  \"account required\" notation  resolves:  -  -  recover removed authoring after add access notes  recovered from commit  apply review suggestions  - yt playlist  - complete instructors  - alphabetize  solve outdated conflicts ", "linked_issue_titles": "", "title": "bump pr/endrose/6163 - added belajar vue js"}
{"description": " move some dev tools files around since i'm gonna have to add more. call out material stuff explicitly with material. call out generated stuff explicitly with generated. related issues #13452 before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. my pr includes tests for all changed/updated/fixed behaviors (see test coverage). i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i read and followed the flutter style guide, including features we expect every widget to implement. i signed the cla. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). no, this is not a breaking change. ", "commit_messages": " cupertino global localization  do 2 arbs  start messing with gen_localizations  re-combed the arb file and categorized the global source in the interface  cupertino localization step 3: in-place move some material tool around to make room for cupertino ", "linked_issue_titles": "", "title": "in-place move some material tools around to make room for cupertino"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ", "commit_messages": " added quill isenabled method  added quill isenabled method  updated header with my name ", "linked_issue_titles": "", "title": "quill - added isenabled type method"}
{"description": " remove the devtools extensions file when the loaded extensions array is empty instead of writing an empty array to the file. this prevents the file from getting created when no extensions are used in the app. fixes #4296 ", "commit_messages": " correct typo in comment  add failing spec for dev tools extensions file  delete extensions file when there are no loaded extensions ", "linked_issue_titles": "", "title": "don't write empty dev tools extensions file"}
{"description": " this is independent from #8779 and doesn't require an update of electron. the good thing is all native modules are now update-to-date, and we no longer need to worry the build would break when we update a module or package to a later version. the only change is to update the modules to use nan 2, the build is green, but we might probably encounter bugs due to the update. fixes #8508 / ", "commit_messages": " :arrow_up: runas@3.1  :arrow_up: atom-keymap@6.0.0  :arrow_up: pathwatcher@6.2  :arrow_up: nslog@3  :arrow_up: oniguruma@5  :arrow_up: git-utils@4  :arrow_up: scrollbar-style@3.2  :arrow_up: text-buffer@7.1.0  :arrow_up: scandal@2.2  :arrow_up: apm@1.1.1  :arrow_up: link@0.31.0  :arrow_up: markdown-preview@0.153.0  :arrow_up: symbols-view@0.108.0  :arrow_up: tree-view@0.189.0  :arrow_up: spell-check@0.60.0 ", "linked_issue_titles": "", "title": "update all native modules and their dependents to nan 2"}
{"description": " currently, these attributes are not visited, so they are not gated feature checked in the post expansion visitor. this only affects crates using #![feature(stmt_expr_attributes)]. r? @nrc ", "commit_messages": " visit statement and expression attributes  check that custom attributes are disallowed on statements and expressions ", "linked_issue_titles": "", "title": "visit statement and expression attributes in the ast visitor"}
{"description": " updated glob-stream to version 3.1.0. this version allows users to set the base path for all files. use case: user wants to copy \"lib/\" and \"bin/\" to /my/path/lib and /my/path/bin. ", "commit_messages": " update glob-stream to 3.1.0. this versions supports the ability to set  the file base path to the cwd or custom.  bump version ", "linked_issue_titles": "", "title": "update glob-stream version to 3.1.0"}
{"description": " add and document cli options for batch size, max doc length, min doc length for spacy pretrain. also improve cli output. closes #3216 i have submitted the spacy contributor agreement. ", "commit_messages": " improve pretrain progress log  add batch_size, max_length and min_length cli arguments for pretrain  document new pretrain arguments ", "linked_issue_titles": "", "title": "expose batch size and length caps on cli for pretrain"}
{"description": " scale the retro terminal effects (#3468) scan lines with the screen's dpi. remove artifacts from sampling wrap around. before & after, with my display scale set to 350%: before & after showing artifact removal, with my display scale set to 100%, and image enlarged to 400%: closes #4362 cla signed. if not, go over here and sign the cla requires documentation to be updated adds a constant buffer, which could be used for other settings for the retro terminal pixel shader. i haven't touched c++ in over a decade before this change, and this is the first time i've played with directx, so please assume my code isn't exactly best practice. changed display scale with experimental.retroterminaleffect enabled, enjoyed scan lines on high resolution monitors. enabled experimental.retroterminaleffect, turned the setting off, changed display scale. retro tabs still scale scan lines. ", "commit_messages": " scale retro scan lines initial  just put the pixel shader settings into its own member struct  undo unintended formatting changes ", "linked_issue_titles": " retro terminal effect prodces artifacts on the right screen edge ", "title": "scale retro terminal scan lines"}
{"description": " after careful discussion we decided we are not happy with the breaking change and will be making this configurable at the daemon level for users that do not want it to be sigkilled. ", "commit_messages": " revert \"fix failing test to use kill instead of stop\"  this reverts commit 4434dcee89f7d0d0239f6b492b24e940cdbafb21.  docker-dco-1.1-signed-off-by: michael crosby <michael@crosbymichael.com> (github: crosbymichael)  revert \"disable automatic killing of containers when docker stop fails\"  this reverts commit 8b5cf51d600dc4f3611cf063c52cf3448e7b01e5.  docker-dco-1.1-signed-off-by: michael crosby <michael@crosbymichael.com> (github: crosbymichael) ", "linked_issue_titles": "", "title": "revert back to the default stop functionality of sigkill after timeout"}
{"description": " others others optimize inplace logic and fix bugs when run kernel that has args of vector ", "commit_messages": " add inplace op adaptation  optimize inplace logic and fix bugs when run kernel that has args of vector<densetensor> ", "linked_issue_titles": "", "title": "[pten]make inplace_op and vector<densetensor> input compatible with old architecture"}
{"description": " (this is part of the cleanup in activesupport::dependencies due to the deletion of classic.) the methods constantize and safe_constantize of activesupport::dependencies are private. they have nothing to do with autoloading, just forward to the inflector. they were there for historical reasons, but today we no longer need them. the public interface is in string. so model_name.constantize instead of activesupport::dependencies.constantize(model_name) the majority of the framework already did this, there were only a few occurrences. ", "commit_messages": " delete as::dependencies.constantize  delete as::dependencies.safe_constantize ", "linked_issue_titles": "", "title": "delete as::dependencies.(safe_)constantize"}
{"description": " this is a continuation of the work started in #17870. mksnapshot must be run with the same arguments that generated the original mksnapshot, otherwise crashes happen. we currently ensure that these are the same by hand. this makes them the same by definition. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: no-notes ", "commit_messages": " build: robustify verify-mksnapshot w.r.t. command-line parameters  debugging  debug args ", "linked_issue_titles": "", "title": "make sure mksnapshot is invoked with proper args."}
{"description": " fixed everywhere the chrome api documentation said something could be null but the types didn't allow it under strict null checking. added some additional tests for chrome.storage to check all the different ways the function can be called, enabled strict null checking for the tests, and fixed some issues with the existing tests i found after doing that. the example code at ", "commit_messages": " fix strict null checking in chrome  fixed everywhere the chrome api documentation said something could be null but  the types didn't allow it under strict null checking.  fix chrome tests with strict null checking enabled  enabled strict null checking for chrome tests and fixed some issues with the  existing tests.  the example code at    would use an uninitialized 'span' variable if bookmarknode.title was empty.  since i have no idea what it was supposed to do in that case, i just moved the  declaration of span up a block. ", "linked_issue_titles": "", "title": "improve chrome definitions with strict null checking enabled"}
{"description": " it's no longer grey and doesn't have a gradient. what the final wording of the description should be, i'm not sure. but i'm sure the community has ideas. ", "commit_messages": " removed reference to button color and gradient  changed the wording to reflect the default button's new look since it's no longer grey and doesn't have a gradient. i'd say this new wording isn't ideal and needs something a bit more, well, descriptive.  removed extraneous space ", "linked_issue_titles": "", "title": "changed description of default button"}
{"description": " preparatory change to enable reg-free winrt (only works with .exe's, not .dll's; meant to replace current link-time override of rogetactivationfactory) sharing of test code between microsoft.reactnative.integrationtests (already a gtest project) and react.native.desktop.abitests microsoft reviewers: open in codeflow ", "commit_messages": " change abitest project to googletest executable  change files ", "linked_issue_titles": "", "title": "change abitest project to gtest executable"}
{"description": " do not emit source maps when generating dts file json files from project reference should be able to do dts emit default if for any reason signature calculation fails should be source file version and exported modules from the file (just like what we do for d.ts file) ", "commit_messages": " test update  use source file version as default signature for the file whenever there is no dts emit for the file  json source files from project reference should be able to calculate the signature  dont emit declaration map when emitting dts files for force emit for signature ", "linked_issue_titles": "", "title": "improvements to dts emit for tsbuildinfo"}
{"description": " regression, introduced in 3.5.0 send all keyboard events to single value change inputs fix #5476 we now send all the proper events to input elements with type date, time, and datetime-local #5476 when typing into certain inputs (like date), we now send all keyboard events as we did prior to 3.5.0. some frameworks were reacting to this bug by seemingly deleting the value after it's been typed ", "commit_messages": " fix not firing key events on singlevaluechange inputs  use http for livereload  add link to issue ", "linked_issue_titles": " date/time input broken (no input events) since 3.5.0 ", "title": "3.5.0 - send keyboard events for single value change inputs"}
{"description": " added actual link to the list items. added a link next to the view source button to open the example. ", "commit_messages": " added defined default value to crossorigin  added filter search to documentation page  added mobile version with media queries  conflicts:  docs/index.html  fix for retina displays  reverted  conflicts:  examples/webgl_geometry_terrain_raycast.html  added button to get direct link to the example  fixed merge  newline  fix for panel repetition ", "linked_issue_titles": "", "title": "access to example link from examples page"}
{"description": " currently all uncaught exceptions of the requests library that is used in winrm will lead to an \"unexpected failure during module execution\". instead of letting all exceptions bubble up we catch the connection related errors (inkl. timeouts) and re-raise them as ansibleconnectionerror so ansible will mark the host as unreachable and exit with the correct return code. this is especially important for zuul ( backport of #51744. winrm fatal: [win-node]: failed! => {\"msg\": \"unexpected failure during module execution.\", \"stdout\": \"\"} an exception occurred during task execution. to see the full traceback, use -vvv. the error was: requests.exceptions.readtimeout: httpsconnectionpool(host='xxx.xxx.xxx.xxx', port=5986): read timed out. (read timeout=120) traceback (most recent call last): file \"/opt/zuul/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 384, in _make_request six.raise_from(e, none) file \"<string>\", line 2, in raise_from file \"/opt/zuul/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 380, in _make_request httplib_response = conn.getresponse() file \"/usr/lib/python3.6/http/client.py\", line 1331, in getresponse response.begin() file \"/usr/lib/python3.6/http/client.py\", line 297, in begin version, status, reason = self._read_status() file \"/usr/lib/python3.6/http/client.py\", line 258, in _read_status line = str(self.fp.readline(_maxline + 1), \"iso-8859-1\") file \"/usr/lib/python3.6/socket.py\", line 586, in readinto return self._sock.recv_into(b) file \"/usr/lib/python3.6/ssl.py\", line 1012, in recv_into return self.read(nbytes, buffer) file \"/usr/lib/python3.6/ssl.py\", line 874, in read return self._sslobj.read(len, buffer) file \"/usr/lib/python3....ib/python3.6/site-packages/winrm/protocol.py\", line 417, in _raw_get_command_output res = self.send_message(xmltodict.unparse(req)) file \"/opt/zuul/lib/python3.6/site-packages/winrm/protocol.py\", line 234, in send_message resp = self.transport.send_message(message) file \"/opt/zuul/lib/python3.6/site-packages/winrm/transport.py\", line 256, in send_message response = self._send_message_request(prepared_request, message) file \"/opt/zuul/lib/python3.6/site-packages/winrm/transport.py\", line 261, in _send_message_request response = self.session.send(prepared_request, timeout=self.read_timeout_sec) file \"/opt/zuul/lib/python3.6/site-packages/requests/sessions.py\", line 646, in send r = adapter.send(request, **kwargs) file \"/opt/zuul/lib/python3.6/site-packages/requests/adapters.py\", line 529, in send raise readtimeout(e, request=request) requests.exceptions.readtimeout: httpsconnectionpool(host=\"xxx.xxx.xxx.xxx\", port=5986): read timed out. (read timeout=120) ", "commit_messages": " raise ansibleconnectionerror on winrm con errors  currently all uncaught exceptions of the requests library that is used  in winrm will lead to an \"unexpected failure during module execution\".  instead of letting all exceptions bubble up we catch the connection  related errors (inkl. timeouts) and re-raise them as  ansibleconnectionerror so ansible will mark the host as unreachable and  exit with the correct return code.  this is especially important for zuul (  distinguish between failures and connection/host related errors.  update lib/ansible/plugins/connection/winrm.py  add changelog fragment ", "linked_issue_titles": "", "title": "raise ansibleconnectionerror on winrm connnection errors"}
{"description": " closes #2420 closes #2433 (just main variables, have not checked parallelization) this exposed an issue #2439 that we can solve separately: this pr just extracts env variables for these two providers ", "commit_messages": " extract build variables for bitbucket pipeline  test bitbucket commit info ", "linked_issue_titles": " collect ci information from bitbucket pipeline  collect env variables for vsts / teamfoundation microsoft ci ", "title": "extract bitbucket pipeline and teamfoundation environment variables"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: playground link include tests for your changes: history-tests.ts if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. updates overload signatures for history.pull and history.replace either a single parameter of either string or object. note: ran prettier on the latest version of history package definitions only prior to making changes to those declarations in a separate commit. ", "commit_messages": " run 'prettier' on latest history package  fix history package's overload signatures to support indeterminate location type ", "linked_issue_titles": "", "title": "accept single ambiguous location parameter for history's push and replace methods"}
{"description": " check prs with ci method without building firmware files the pull request is done against the latest dev branch only one feature/fix was added per pr. the code change is tested and works on core esp8266 v.2.7.1 the code change is tested and works on core esp32 v.1.12.0 i accept the cla. note: the code change must pass ci tests. your pr cannot be merged unless tests pass ", "commit_messages": " build only when push  update and rename ci_github.yml.off to ci_github.yml  update and rename ci_github_esp32.yml.off to ci_github_esp32.yml ", "linked_issue_titles": "", "title": "build firmware only with action push"}
{"description": " follow-up pr for #40429 add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " fix(parse/object): attributes in constructor should be optional  refactor(parse/geopoint): update constructor params  feat(parse/query): add generic attr check for functions  lint(parse): fix lint issues  feat(parse/query): key types for matcheskeyinquery()  refactor(parse/query): add base attrs to query checks  feat(parse/query): check type for value params in modifiers  refactor(parse/query): remove unnecessary extract<> from modifiers  feat(parse/query): support pointer for object attrs in equalto() ", "linked_issue_titles": "", "title": "add generic type check for modifiers functions"}
{"description": " closed my first pr so i could clean up my fork and submit a good pull. this has been working for a couple months now.  everything functions as intended.  engage and disengage without issue and never loose steering. heres a couple drives in case its needed hwy drive  city drive ", "commit_messages": " 0.5.6  merge devel  added acadia  adding acadia  adding acadia  update radar_interface.py  adding acadia  added acadia  refactored  fixed tuning  adding acadia ", "linked_issue_titles": "", "title": "adding support for 2018 gmc acadia denali"}
{"description": " the issue is that when imgur upload fails and generates error, the text was not selectable to be copied by user. see the commit messages for more granular info. p.s: i'm not sure about the coding quality as i'm not a c++ dev nor a qt dev. so feel free to fix it (and i'll learn) ", "commit_messages": " makes text of the imgur upload selectable  fix the mouse to i shape for selectable texts ", "linked_issue_titles": "", "title": "minor fix and modification on selectable tests in dialogs"}
{"description": " a pr for the only remaining ipv6 rule using state rather than conntrack, improves consistency of the rules. ", "commit_messages": " update rules.v6.j2  updated to use -m conntrack for consistency as per the other ipv6 rules.  update rules.v6.j2 ", "linked_issue_titles": "", "title": "use conntrack rather than state"}
{"description": " this pr will add a new utm info module which allows the management of network interface address entries of the sophos utm. this module integrates with the existing utm_utils . new module pull request module/web_infrastructure/sophos_utm/utm_network_interface_address.py module/web_infrastructure/sophos_utm/utm_network_interface_address_info.py ", "commit_messages": " - initial commit  - fix sanity checks  - fixed documentation trailing whitespaces  - changed author github contact as he has no account i'll (@steamx) take responsibility ", "linked_issue_titles": "", "title": "added ansible utm info module for network interface address entities."}
{"description": " allow nozzle clean to be called with limited axis. specifically enables the use of wiper pads on purge buckets for multi tool machines where a z movement for the wipe would mean a definitive crash. ", "commit_messages": " initial commit  remove default since only called from one place  minor corrections ", "linked_issue_titles": "", "title": "allow nozzle clean with limited axis"}
{"description": " check out the rcharts lecture now. everything is in slidify so no switching between browser windows when recording. ", "commit_messages": " added an rcharts lecture start, still working on it  added a lot to the rcharts lecture, all plots are embedded in slidify  added a googlevis lecture shell  added library files so we don't have to keep fetching them ", "linked_issue_titles": "", "title": "the rcharts lecture is nearly complete, it's pretty slick. also added a googlevis shell"}
{"description": " as per issue #184 this adds some short descriptions (following the established style) to some of the patterns of the class. (i may do some more later) ", "commit_messages": " adds description to abstract factory  adds description to builder  adds description to object pool ", "linked_issue_titles": "", "title": "add short descriptions to abstract factory, builder and objectpool"}
{"description": " closes #16223 earlier the title of the rooms wasn't clickable. an event was added to open the room info/user info page when clicked, instead. earlier: title not clickable now: ", "commit_messages": " [feature] closes #16223. clicking room header opens room info/user info.  removed redundancies and corrected lint errors ", "linked_issue_titles": " make the room name clickable and open room info ", "title": "make the header for rooms clickable"}
{"description": " without these properties, these sections of the page in the rust book do not have momentum scrolling in ios which makes reading the book on ios a fairly arduous experience. these commits adds the -webkit-overflow-scrolling: touch; property to both the toc and the page content itself. ", "commit_messages": " add \"-webkit-overflow-scrolling: touch\" to book css for the page wrapper.  this change permits native momentum scrolling in safari on ios in the book.  add same \"-webkit-overflow-scrolling: touch\" to the table of contents in the book. ", "linked_issue_titles": "", "title": "add \"-webkit-overflow-scrolling: touch;\" to book css"}
{"description": " based on #85937 with #85937 (comment) addressed fix bug where kube-apiserver would fail to start when not providing service cidr the strings.split documentation states: // if s does not contain sep and sep is not empty, split returns a // slice of length 1 whose only element is s. import ( \"fmt\" \"strings\" func main() { serviceclusteripranges := \"\" serviceclusteriprangelist := strings.split(serviceclusteripranges, \",\") fmt.printf(\"len: %d, value: %+v\", len(serviceclusteriprangelist), serviceclusteriprangelist) } // output // len: 1, value: [] playground link this would fail the if check here and apiserver wouldn't start. this pr fixes this bug. does this pr introduce a user-facing change?: release note: ", "commit_messages": " fix bug in apiserver service cluster cidr split  refactor parsing logic for service ip and ranges, add tests ", "linked_issue_titles": "", "title": "fix bug in apiserver service cidr split"}
{"description": " fixes rdar://problem/61407215 and rdar://problem/50905075. cherry-pick #31196 onto 5.3 branch. ", "commit_messages": " [nfc] add test case for old arm64e fallback behavior.  [moduleinterface] remove fallback behavior for arm64e -> arm64.  addresses rdar://problem/61407215.  [moduleloader] emit a better diagnostic for swiftinterfaces with wrong arch.  before this change, we would emit the warning only for swiftmodules; however,  it may be the case that only a swiftinterface (of a different arch) is present  but no swiftmodule is present.  fixes rdar://problem/50905075. ", "linked_issue_titles": "", "title": "remove fallback for arm64e -> arm64."}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: ghsa-7wwv-vh3v-89cq if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. note: besides, adjustments have been made in line with the changed api: markdown-it/markdown-it#626 ", "commit_messages": " bump dependency highlight.js of types/markdown-it from 9.7.0 to 10.4.1  add support for changed api of markdown-it ( ", "linked_issue_titles": "", "title": "remove dependency highlight.js (and only keep @types/highlight.js) to resolve vulnerability ghsa-7wwv-vh3v-89cq"}
{"description": " this pr is based on #6160 ", "commit_messages": " cceventdispatcher crash fix  fix possible crashes which could be caused by the eventdispatcher having listeners associated with nodes are destroyed. catch the case where a node registers a listener while we are dispatching events and gets destroyed while that event is still being dispatched. check the list of nodes to be added into the event dispatcher fully when we are cleaning listeners for a target node.  this issue was found using the extra debug verification in this pull request:    add an event dispatcher test  add an event dispatcher test to help reproduce crashes fixed by the previous commit and to verify that the fix still works.  unregistered listener when it's removed from _toaddedlisteners. ", "linked_issue_titles": "", "title": "fixed a potential crash in eventdispatcher, based on pr #6160"}
{"description": " introduces new progressiverendering utility and uses it to display /asynchpeople incrementally. /people now a 404, but /people/api still works. ", "commit_messages": " progressiverendering  .classname, not .class.  asynchpeople  do initial refresh asynch; seems to work better with some kinds of html.  ts_refresh  using ts_refresh to resort properly.  e.setattribute('a', v) is apparently different from e.a=v.  ts_refresh was much harder than i thought.  [fixed jenkins-15206] displaying <code>/people</code> can consume huge resources.  forgotten link.  no need to really wait the first time.  @since ", "linked_issue_titles": "", "title": "displaying /people can consume huge resources."}
{"description": " important: this integration must be merged, not squashed! ", "commit_messages": " sync from piper @368734211  protobuf_sync_piper  merge tag 'refs/tags/sync-piper' into sync-stage  # conflicts:  #\tsrc/google/protobuf/compiler/cpp/cpp_helpers.cc  #\tsrc/google/protobuf/port_def.inc  ported c++ parse function generator to new enum names.  updated changes.txt. ", "linked_issue_titles": "", "title": "integrate from piper for c++, java, and python"}
{"description": " this pr adds the detailed view for plugins in the new integration directory. here are some nifty screenshots: information tab: project config tab: you'll notice that the information tab contains information about the features that was added in this pr #16797. we pull them off the feature_descriptions of the plugin classes. for the configurations tab, i decided to call it project configurations so it's a bit more clear that these are project specific. the items you see in the rows have project badges so they look like projects elsewhere in sentry. you'll notice we have the following buttons in the rows: enable: enables a plugin that has already been configured configure: takes you to the configuration page of that plugin for that project uninstall: resets the configuration and disables the plugin for that project/plugin at the top we have the add to project button. clicking it generates the project select modal: doesn't look that great now but we will probably improve it once we have a proper design. ", "commit_messages": " sets up initial detailed view for plugins  chore(ts): convert actioncreator navigation  make comingfromprojectid optional  progress  change import  merge from master  progress  more changes  merge from master  update ", "linked_issue_titles": "", "title": "feat(integration-directory): plugin detailed view"}
{"description": " this pr adds an optional parameter callback to the configuration of the highlight plugin. if a callback function is provided, the function is called with hljs as argument before the plugin starts to highlight the code. sample configuration reveal.initialize({ // ... highlight: { callback: registerampl }, // ... }); a new language can then be added, by including the respective function as shown below: function registerampl(hljs) { hljs.registerlanguage(\"ampl\",function(hljs){ return   { contains: [ hljs.hash_comment_mode, hljs.c_block_comment_mode, { classname: \"number\", begin: string.raw\\b(\\d*\\.?\\d+)\\b, relevance:0 }, { classname: \"strong\", begin: string.raw^ampl[\\?:], relevance:0 } ], keywords: { keyword: 'maximize minimize subject to set within union inter diff symdiff cross sum in by mod var param default setof dimen symbolic if then else', type: 'binary integer', string: 'reset model solve data option solver solver_msg solution_precision display include print printf quit', built_in: 'abs max min sqrt round trunc ceil floor', number: 'infinity', symbol: '_nvars _varname _var' } }; }); } fixes #2761 ", "commit_messages": " allow users to register additional languages via callback  remove accidentally added tab ", "linked_issue_titles": "", "title": "add option for highlight plugin to register additional languages via callback"}
{"description": " closes #2733 i have read contributing.md. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " add bfs to binary tree - fixes #2733  add note on the equivalence of dfs and inorder - fixes #2733 ", "linked_issue_titles": " binary tree bfs/dfs missing ", "title": "add bfs to binary tree and add note about inorder traversal == dfs"}
{"description": " my third attempt at a fix for iso layouts in the configurator, last issue was caused by an unexpected key i left in the keymap. ", "commit_messages": " added basic mxss support  fixed split rshft for iso layouts  updated readme.md for mxss  added initial support for individual control of front rgb leds  changed rgbled color selection to work using hue and saturation rather than rgb  added code for led state change on layer change  avoid needing an entire 8 bits to store the brightness value  added custom keycodes, along with their handlers  added eeprom storage for front led config  fixed up ability to use qmk configurator and updated readme.md  applied suggested changes from pull request:  updated name in license descriptions  updated layouts to snake case  corrected mistakes in info.json  updated layer_colors to a weak attributed array in mxss.c  defined a new safe range for custom keycodes in keymap.c  fixed up issues with front led  fixed leds not always updating in indicator mode  added support for the other rgblight modes in rgb mode  attempted fix for iso layouts for qmk configurator  synced to main fork  updated mxss iso layouts to remove an unnecessary key ", "linked_issue_titles": "", "title": "fixed mxss iso layouts in qmk configuator (hopefully)"}
{"description": " issue #3803 added test_issue3803.pywithin regression/ to test true for spanish num-like tokens. added lex_attrs.pywithin lang/es/ to overwrite default getter for like_num and include spanish words for numbers. modified __init__.py within lang/es/ to import lex_attrs and update lex_attr_getters within spanishdefaults. added munozbravo.md to .github/contributors/ as specified for contributor agreement. enhancement lang/es i have submitted the spacy contributor agreement. ", "commit_messages": " (#3803) spanish like_num returning false for number-like token  (#3803) spanish like_num now returning true for number-like token ", "linked_issue_titles": "", "title": "overwrites default getter for like_num in spanish by adding _num_words and like_num to lex_attrs.py"}
{"description": " see the individual commit messages for more detail. fixes #5389 ", "commit_messages": " use consistent whitespace before comments  changelog: note new error class git_error_http  updates #5389  transports: use git_eauth for authentication failures  when the failure is clearly an auth failure  (as opposed to possibly an auth failure),  use the error code git_eauth instead of git_error.  while we're here, fix a typo and improve an error message.  fixes #5389. ", "linked_issue_titles": " use error code git_eauth for http auth failures ", "title": "use error code git_eauth for authentication failures"}
{"description": " this opens up access to the tf_operationinputlistlength c api from java, for operations that return specified input lists. ", "commit_messages": " java api to get the size of specified input list of operations  merge remote-tracking branch 'upstream/master' ", "linked_issue_titles": "", "title": "java api to get the size of specified input list of operations."}
{"description": " add or edit tests to reflect the change. (run with npm test your_package_name.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: <> include tests for your changes if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " fix parameteraddresses error in custom-functions-runtime/index.d.ts  correct two req set numbers, update error code comments to match ui experience in types/custom-functions-runtime/index.d.ts  fix whitespaces per npm lint ", "linked_issue_titles": "", "title": "fix syntax error, match comments to excel ui"}
{"description": " description: symboltables are conceptually and structurally really powerful ways to reduce memory overhead for repeated patterns. however the space savings was limited by some taxes: references in structures to aid in raii -- we can use assert statement to get most of the value. lots of very small integers held in arrays of uint32_t -- we can a utf-8-like encoding scheme 16 bytes overhead for vectors, to store size and capacity -- we can store fixed size in 2 uint8s. with these changes the raw space taken by all the stats in a 1k cluster system are reduced by 4x. this is one step toward resolving #4196. we will also be able to concatenate statnames without accessing the global symbol table, enabling lock-free scoped name lookup. risk level: low for now as they are not used yet, but probably wants to be fuzz-tested. testing: //test/common/stats/... docs changes: n/a release notes: n/a ", "commit_messages": " typically tests in envoy for files named foo_impl.cc are called foo_impl_test.cc.  this just corrects that for two tests.  also make tag_extractor and tag_producer consistent.  use uint8_t encoding for symbol arrays, and rely on asserts rather than raii to avoid leaks.  the raii concept is nice but it's expensive; need to keep 8-byte  symboltable reference with each stat-name.  further naming clarification.  format  test sorting and hashing.  add a test for memory usage. ", "linked_issue_titles": "", "title": "use a more compact rep for symboltable and add tests for memory usage"}
{"description": " added working v3-beta version in package.json. also, example here has syntax error. this is my first pull request here, i'm not sure if i'm doing the right way :l ", "commit_messages": " add next.config.js file for static routes  reverted start npm script to default  eslint fix ", "linked_issue_titles": "", "title": "add next.config.js for v3 next export example with-dynamic-import"}
{"description": " i got it wrong on pr #13568.   m43's toggle and watch utilizes were not working because the parsed_pin_index function was not handling the default conditions properly. the pr #13568 changes have already been backed out. parsed_pin_index scans the command line for code and returns an index into the pin map.  if the code is found and the pin is valid then the index for the pin is returned.  it returns the default if the code is not found or the pin is not valid. parsed_pin_index changes: adding -1 results in getting the default when the code is not present. const uint16_t val = (uint16_t)parser.intval(code, -1), port = val / 100, pin = val % 100; changing to -1 results in getting the default value if an invalid pin is specified. return ind > -1 ? ind : dval; additional changes were needed to make the m43 toggle utility work reliably with a lpc176x: toggling the three usb pins causes hangs & disconnects.  the m43_never_touch macro was added to cover this. random hangs and disconnects were occurring when the wdt was enabled.  wdt resets were added to minimize. this. ", "commit_messages": " games, for fun (and stress-testing) (#13464)  backout previous pr, correct parsed_pin_index function  remove menu_main.cpp from pr ", "linked_issue_titles": "", "title": "m43 & lpc176x - the real fix (pr #13568 was wrong)"}
{"description": " resolves #12517 adds a decorator called _retry_if_error_with_cache_removed to implement the retry logic, when the read from cache fails. this pr includes a minor refactoring to use contextlib.closing to make sure streams are closed, when an exception gets raised. ", "commit_messages": " enh: correctly handles closing  enh: invalidates cache support  rev: remove invalidates_cache  enh: users decorator to handle retries  rfc: one line message  bug: only unlink if cache file exists ", "linked_issue_titles": " fetch_openml migration between 0.20.0 and 0.20.1 ", "title": "openml, adds retrying if reading from cache fails"}
{"description": " this pull request fixes two more build breakages on freebsd introduced recently: add freebsd to the list of platforms with pthread support in runtime/mutex.h link core library with libexecinfo which is required for backtrace_symbols link unit tests runtime with libexecinfo for the same reason before merging this pull request to apple/swift repository: test pull request on swift continuous integration. triggering swift ci the swift-ci is triggered by writing a comment on this pr addressed to the github user @swift-ci. different tests will run depending on the specific comment that you use. the currently available comments are: smoke testing platform comment all supported platforms @swift-ci please smoke test os x platform @swift-ci please smoke test os x platform linux platform @swift-ci please smoke test linux platform validation testing platform comment all supported platforms @swift-ci please test os x platform @swift-ci please test os x platform linux platform @swift-ci please test linux platform note: only members of the apple organization can trigger swift-ci. ", "commit_messages": " add freebsd to the list of platforms with phreads  link with libexecinfo on freebsd  backtrace_symbols is defined in libexecinfo on freebsd ", "linked_issue_titles": "", "title": "link with libexecinfo, fix runtime/mutex.h"}
{"description": " follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update from origin  update from origin  catch up  add subscription items  fix #22783  add subscriptionitem property and fix bugs  add tests ", "linked_issue_titles": "", "title": "update stripe package to include subscription items"}
{"description": " what do these changes do? before this pr, if we want to specify some resources, we must do as following codes: @rayremote(resources={resourceitem(\"cpu\", 10)}) public static void f1() { // do sth } @rayremote(resources={resourceitem(\"cpu\", 10)}) class demo { // sth } unfortunately, it's no way for us to create another actor or task with different resources required. after this pr, the thing will be: actorcreationoptions option = new actorcreationoptions(); option.resources.put(\"cpu\", 4.0); rayactor<echo> echo1 = ray.createactor(echo::new, option); option.resources.put(\"res-a\", 4.0); rayactor<echo> echo2 = ray.createactor(echo::new, option); //if we don't specify resource,  the resources will be {\"cpu\":0.0} by default. ray.call(echo::echo, echo2, 100); n/a ", "commit_messages": " support dynamic resources in raycall.  add test.  remove useless methods.  fix minor err.  add doc. ", "linked_issue_titles": "", "title": "support dynamic resources required when submitting task."}
{"description": " also some cleanup to conform to documentation style. ", "commit_messages": " doc: cleanup.  remove ~~~ for code block specification. use /// over /** */ for doc  blocks.  doc: methods for result::result.  doc: methods for option::option ", "linked_issue_titles": "", "title": "method examples for result and option"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: braintree/braintree-web#544 ", "commit_messages": " add tokenize as valid payment intent  format with prettier ", "linked_issue_titles": "", "title": "add tokenize as valid payment intent value"}
{"description": " found the request for adding title case to main article headings per the gatsby style guide. this adds title case to the tutorial sidebar menu. ", "commit_messages": " remove title case from the heading to match the sidebar menu  changed all top-level headings to title case  all top-level headings (the main steps) were converted to title case. the sub-headings were left in sentence case. also changed instance of css in all lowercase to uppercase. ", "linked_issue_titles": "", "title": "adding title case to tutorial sidebar menu"}
{"description": " another approach of webglrenderer webgl 2.0 initial support with glsl \"1 to 3\" conversion advantages compared to glsl 3 to 1 approach less changes because i don't change src/renderer/shaders keep webgl 1.0 stable for us, webgl 2.0 support is still unstable and experimental. so i don't think it's a good idea to affect three.js + webgl 1.0 stability by changing shader code. imo the change isn't too huge, and new codes aren't so mess. this webglrenderer webgl2.0 initial support pr is acceptable. but we may end up wanting to separate webgl2renderer from webglrenderer once we aggressively attempt to add webgl 2.0 features and optimize for them. related: glsl 3 to 1 approach #13701 ", "commit_messages": " webglrenderer webgl2.0 basic support  minor clean up  add internalformat conversion function to webgltextures  update setupframebuffertexture()  skip glsl conversion if material is rawshadermaterial  ignore ext_frag_depth for webgl 2.0  ignore ext_shader_texture_lod for webgl 2.0  update instancing for webgl 2.0  clean up webglutils  clean up webglprogram  add .isglsl3 to shadermaterial  clean up webgltextures  update ext_blend_minmax handling for webgl 2.0  update webglutils for webgl 2.0 unsigned_int_24_8  update internalformat for webgl2.0  add webgl_draw_buffers as built-in extensionn for webgl2.0 to webglextensions  clean up webglprogram ", "linked_issue_titles": "", "title": "webglrenderer webgl2.0 initial support with glsl 1 to 3 runtime conversion"}
{"description": " attempting a reland of #87289. part of #86396. updated the skip tests in the 'cupertino' package. turned some tests back on and marked others with exclude instead of skip as they will never work on the web. ", "commit_messages": " updated the skipped tests for cupertino package.  reverted a change that was still needed.  update from review.  removed some left over 'exclude' parameters. ", "linked_issue_titles": "", "title": "updated the skipped tests for cupertino package. (reland)"}
{"description": " closes #12908 add a new setting to show/hide agent information on livechat widget. related to rocketchat/rocket.chat.livechat#279 ", "commit_messages": " add new setting to show/hide agent infornation on livechat widget. ", "linked_issue_titles": " live chat: hide live agent name and profile picture ", "title": "livechat setting to show/hide agent information on the widget"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. fixes typed-ember/ember-cli-typescript#295 ", "commit_messages": " [@ember/utils] move types from ember. @ember/utils is now the source of truth  [ember] @ember/object as source of types, ember as re-export  [ember] restore original mixin test ", "linked_issue_titles": "", "title": "move types to @types/ember__object, @types/ember is now the re-export"}
{"description": " this pr adds two additional tests for the ownership verifier. 8d519bd: this test makes sure that the ownership verifier asserts if we use a borrowed value after the relevant end_borrow has invalidated it. f44f7ea: this test makes sure that the verifier asserts if we destroy an owned value while there are borrows that have not been ended via end_borrow. rdar://29791263 edit: fixed typo in commit hash. ", "commit_messages": " [semantic-sil] improve output for filecheck tests for ownership verifier by printing out the function name first.  this just standardizes the output.  rdar://29791263  [ownership-verifier] add a test for a use of a borrowed value after an end_borrow.  this test makes sure that we properly error when we use a borrowed value after  the borrow has been invalided by an \"end_borrow\".  rdar://29791263  [ownership-verifier] add a test for a destroy of an owned value before it is no longer borrowed.  this makes sure that we treat the end_borrow as a proper use of the original  value. in such a situation since it is a use, the verifier should trigger that  we have a use after free.  rdar://29791263 ", "linked_issue_titles": "", "title": "add two ownership verifier tests"}
{"description": " fix the hash checking mechanism upgrade pip before using wheel related pr #18276 ", "commit_messages": " revert \"revert \"roll foward \"strip python wheel binary\"\"\"  this reverts commit 98fc9022005126897b809c5337944afadf27c619.  upgrade pip before using wheel  fix the hash checking mechanism ", "linked_issue_titles": "", "title": "roll forward \"strip python wheel binary\" again"}
{"description": " moved ols regression implementation from numerical methods to machine learning folder. fixed variable names to avoid mis-representation by doxygen added file name matches file name guidelines added documentation so that the program is self-explanatory and educational - doxygen guidelines pr title follows semantic commit guidelines ", "commit_messages": " move ols regressor to machine learning folder  updating directory.md  use better test function names to avoid conflict  use better test data variable names to avoid conflict ", "linked_issue_titles": "", "title": "ols regressor should be considered an ml algorithm and not a numerical method"}
{"description": " this fixes an issue with extends where the instantiation of a class-like \"constructor\" function used as a base class fails when the construct signature returns a type parameter default. this also fixes an issue where we were not reporting a grammar error for an empty type argument list in a heritage clause. fixes #16211 ", "commit_messages": " fix grammar check for empty type argument list and compiler crash  fix constructor instantiation with defaults ", "linked_issue_titles": " cannot extend from type which constructs intersection of type parameter with a default ", "title": "fix 'extends' with type parameter default returned from superclass construct signature"}
{"description": " i have used the style of the <dialog> element in chrome as a baseline: ", "commit_messages": " [modal] make the modal style more naked  fix typo changelog  remove noise from the console in dev mode  fix eslint error  make codesandbox edit work again ", "linked_issue_titles": "", "title": "make the modal demo style more \"agnostic\""}
{"description": " this is more hotfix than proper fix but this allows new clusters to be initialised even without ssl enabled. more details about issue in #18884 dco signed title of the pr starts with chart name (e.g. [stable/mychartname]) ", "commit_messages": " change from string null to nil  bump version  set ssl off ", "linked_issue_titles": "", "title": "fix initialisation of cluster when ssl is disabled"}
{"description": " this builds on top of #16237 to better address #14528. this pr focused on adding more explicit warnings while not changing the code of the examples. updating the examples to rewrite them to use permutation_importance can be done in another pr to be able to quickly merge this one. ", "commit_messages": " warn about misleading cardinality bias for feature_importances_ in tree docstrings  more explicit warning in the ensemble documentation  small improvement to permutation_importance.rst  add warning in the api doc for the feature_importances_ attribute ", "linked_issue_titles": "", "title": "doc more explicit warnings about the misleading use of impurity-based feature_importances"}
{"description": " this is related to #22116. a number of modules (reindex, etc) use the rest client. the rest client opens connections using the apache http client. to avoid throwing securityexception when using the securitymanager these operations must be privileged. this is tricky because connections are opened within the httpclient code on its reactor thread. the way i confronted this was to wrap the creation of the client (and creation of reactor thread) in a doprivileged block. the new thread inherits the existing security context. ", "commit_messages": " add privilege to the starting of http client ", "linked_issue_titles": "", "title": "wrap rest httpclient with doprivileged blocks"}
{"description": " see #161 and #162. ", "commit_messages": " d3.min & d3.max: pass index and array to accessor.  fixes #162.  d3.min & d3.max: ignore nan at [0].  note: this now returns infinity and -infinity for zero-element arrays, whereas  previously an error would have occurred.  fixes #161. ", "linked_issue_titles": "", "title": "fixes for d3.min and d3.max."}
{"description": " if a celery worker is segmented from a cluster and is told to die, it will try very aggressively to connect to the transport that may or not exist at this point. this can add a bit of time to shutdown procedures and usually ends up just getting sigkill'd by the init/supervisor regardless. this change makes it so that the worker-offline is still sent, but if it is lost, just accept it and die peacefully by setting retry=false on the worker-offline message. in cases where a cluster is still fully operational from the segmented worker, it will track the worker as lost by heartbeats instead of the offline message. ", "commit_messages": " if worker-offline event fails to send, give up and die peacefully  add test for retry= and msgs in heartbeat ", "linked_issue_titles": "", "title": "give up sending a worker-offline message if transport is not connected"}
{"description": " this relands #65966, which was reverted by #66027. the reason for the reversion was a broken scuba test (see b/168761772).  i made an auxiliary fix in the original pr not directly related to the issue, and it seems that bug was relied upon by a dependent app.  i think the real solution there is a more complicated fix, which i'm tracking in the new issue #66050.  i've also added a new test here that should catch the problem before running post submit tests in the future. in the meantime, let's reland this so that the original layout bug #65572 will be fixed. related issues #65572 b/168761772 #66050 ", "commit_messages": " revert \"revert \"textfield constrained layout bug (#65966)\" (#66027)\"  this reverts commit 48ba488d33a457a1faab84f7cef55d7fbecb8771.  remove fixbelow bugfix and open an issue for it ", "linked_issue_titles": "", "title": "reland \"textfield constrained layout bug (#65966)\""}
{"description": " new features apis add support for double grad computation in reduce sum op. ", "commit_messages": " set default value to strategy in distributed_optimizer test=develop  set default value to strategy in distributed_optimizer test=develop  add unittest  add unittest test=develop  merge  update  merge  merge  merge  merge  support reduce_sum double grad test=develop ", "linked_issue_titles": "", "title": "add double grad in reduce sum"}
{"description": " minor fixes to provisioning script: moved invoke-vcvarsall to osquery_utils.ps1 so all provisioning scripts can use it force set tls 1.2 in osquery_utils.ps1 explicitly check perl install to make sure incompatible version is not used clean up external executions for things like .bat scripts and 7z, nmake, etc ", "commit_messages": " fixes to openssl provisioning script  clean up external executions ", "linked_issue_titles": "", "title": "update win64 openssl provisioning script"}
{"description": " these changes are needed so that we can queue non-actor tasks as they are received at the executing workers. the changes will also facilitate work stealing (see pr #10607 ). the changes do not affect the way in which actor tasks are handled. the changes in this pr are required to simplify pr #10607 ", "commit_messages": " separated adding tasks to queue and executing them (worker side)  linting ", "linked_issue_titles": "", "title": "queueing non-actor tasks at the workers"}
{"description": " remove overloadchoicekind::basetype and re-introduce a couple of assertions. ", "commit_messages": " [cs] nfc: remove overloadchoicekind::basetype  this doesn't appear to be used any more.  [cs] re-introduce some assertions  these fixmes appear to now be outdated.  this commit also adds an additional assertion in  bindtypevariable. ", "linked_issue_titles": "", "title": "a couple of minor cleanups"}
{"description": " hi oleksii, i've created a folder for ml in algorithms and added knn to it. added tests in tests folder, and they are running with full code coverage. i have created a readme explaining the algorithm. also i've added knn to the main readme with link. please do have a look and tell if anything else needs to be done. thanks, avi ", "commit_messages": " updated knn and readme  update readme.md ", "linked_issue_titles": "", "title": "adding k nearest neighbor to ml folder in algorithms with readme and tests"}
{"description": " implement callbacks to collect worker stats in node manager. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " callback status canceld when collecting worker stats  add get core worker stats handler in core worker ", "linked_issue_titles": "", "title": "collecting worker stats in node manager and implement webui display in the backend"}
{"description": " all system examples now use the sx prop in the examples instead of the deprecated box props. the basics page is not converted as it will be updated in a dedicated pr together with the other necessary updates in the content. ", "commit_messages": " converted border demos  displays examples converted  flexbox examples converted  converted palette examples  positions examples converted  visuallyhidden & shadows examples converted  sizing examples converted  spacing examples converted  typography examples updated  prettier ", "linked_issue_titles": "", "title": "update system pages to use sx prop instead of deprecated box props"}
{"description": " commit message: remove envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2 multiplexing http connections (http/2, http/3) will always be sent a goaway when the overload action for disabling connection keepalive triggers. risk level: low testing: ran affected tests docs changes: n/a release notes: documented removed override platform specific features: n/a fixes #16010 ", "commit_messages": " remove deprecated override  remove deprecated override  envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2.  multiplexing http connections (http/2, http/3) will always be sent a  goaway when the overload action for disabling connection keepalive  triggers.  document removed runtime override ", "linked_issue_titles": " envoy.reloadable_features.overload_manager_disable_keepalive_drain_http2 deprecation ", "title": "remove override for http/2 goaway"}
{"description": " the commits below speed up retrieval of metadata during files mode in the video library by using a single query (or 2) based on the path being retrieved, rather than a separate query per item. speed up is reasonably significant with many items in a folder, and is generally faster even when only 1 item exists in the folder. please review for sanity - will commit in a day or two if no issues pop up. ", "commit_messages": " use a single query for retrieving playcounts to speed up file listings  make sure paths with content set are imported from xml prior to importing media, ensuring we can set the basepath correctly  change addpath so it checks for a previously existing path and make it public  add an extra column to the video database with the parent path id to allow faster lookup of items by folder  update comment with note regarding items in a folder with content set that aren't yet in the db  speed up retrieval of library info when browsing by file ", "linked_issue_titles": "", "title": "use a single query for playcounts/metadata in files views"}
{"description": " desktop plugins with a pure dart implementation should generate a plugin class in the generated registrant. this change adds a dartpluginclass value that is not currently used, but in the future will be used to register a dart implementation of the plugin. related issues part of #52267. added a test to plugins_test.dart to make sure native files are not created. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i read the [tree hygiene] wiki page, which explains my responsibilities. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. did any tests fail when you ran them? please read [handling breaking changes]. no, no existing tests failed, so this is not a breaking change. yes, this is a breaking change. if not, delete the remainder of this section. i wrote a design doc:  i got input from the developer relations team, specifically from: replace with the names of who gave advice i wrote a migration guide: replace with a link to your migration guide ", "commit_messages": " working implementation with a couple of clean up  fix and add testes  fix test  update comment ", "linked_issue_titles": "", "title": "don't generate native registrant classes if no pluginclass is defined"}
{"description": " new features apis add iterabledataset support for multiprocess dataloader add paddle.io.iterabledataset base class add paddle.io.get_worker_info to get worker process information for data splitting in iterabledataset ", "commit_messages": " add iterabledataset support in multiprocess dataloader. test=develop  fix single process exit. test=develop ", "linked_issue_titles": "", "title": "add iterable dataset support for multiprocess dataloader"}
{"description": " re: mozilla#458 ", "commit_messages": " pull upstream to alison's fork july 4  pull upstream to fork 7.22.18  pull from upstream 7.29.18  ports propagating query execution errors from celery tasks properly  re: ", "linked_issue_titles": "", "title": "propagate query execution errors from celery tasks properly"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. if for reason the any rule need to be disabled, disable it for that line using // tslint:disable-next-line [rulename] and not for whole package so that the need for disabling can be reviewed. ", "commit_messages": " added missing $filter overload  added missing $filter overload that allows multiple strings to translate and returns an object  merge remote-tracking branch 'upstream/master'  make visitor.id optional  update tests ", "linked_issue_titles": "", "title": "pendo.io - make visitor.id optional in initialize()"}
{"description": " historically only two extra activities happened in the final reduction: empty buckets were filled, and pipeline aggs were reduced (since it was the final reduction, this was safe).  usage of the final reduction is growing however.  auto-date-histo might need to perform many reductions on final-reduce to merge down buckets, ccs may need to side-step the final reduction if sending to a different cluster, etc having pipelines generate their output in the final reduce was convenient, but is becoming increasingly difficult to manage as the rest of the agg framework advances. this commit decouples pipeline aggs from the final reduction: introduces a new \"top level\" reduce, which should be called at the beginning of the reduce cycle (e.g. from the searchphasecontroller) adds a materializepipeline() method to internalaggs and internalmultibucket.  this is essentially the final reduce for pipelines makes reductions on pipelines a no-op by separating pipeline reduction into their own set of methods, aggregations are free to use the final reduction for whatever purpose without worrying about generating pipeline results which are non-reducible closes #44914, predecessor pr was #45359 ", "commit_messages": " decouple pipeline reductions from final reduction  historically only two things happened in the final reduction:  empty buckets were filled, and pipeline aggs were reduced (since it  was the final reduction, this was safe).  usage of the final reduction  is growing however.  auto-date-histo might need to perform  many reductions on final-reduce to merge down buckets, ccs  may need to side-step the final reduction if sending to a  different cluster, etc  having pipelines generate their output in the final reduce was  convenient, but is becoming increasingly difficult to manage  as the rest of the agg framework advances.  this commit decouples pipeline aggs from the final reduction:  1. introduces a new \"top level\" reduce, which should be called  at the beginning of the reduce cycle (e.g. from the searchphasecontroller)  2. adds a materializepipeline() method to internalaggs and  internalmultibucket.  this is essentially the final reduce  for pipelines  3. makes reductions on pipelines a no-op  by separating pipeline reduction into their own set of methods,  aggregations are free to use the final reduction for whatever  purpose without worrying about generating pipeline results  which are non-reducible  remove unnecessary doreduce()  add assertions, javadoc ", "linked_issue_titles": " auto_date_histogram fails where date_histogram does not ", "title": "decouple pipeline reductions from final agg reduction"}
{"description": " the first commit in this pr closes #11287 by adding a \"subscribe to releases on libraries.io\" link to the \"what's new\" page: i also noticed that there is no link to the changelog/what's new page from the ", "commit_messages": " doc add \"subscribe to releases on libraries.io\" tip to whats_new page  doc add \"what's new\" and libraries.io links to readme ", "linked_issue_titles": " include \"subscribe to releases on libraries.io\" in docs ", "title": "doc add libraries.io and changelog links"}
{"description": " the new ops based recovery, introduce as part of  #10708, is based on the assumption that all operations below the global checkpoint known to the replica do not need to be synced with the primary. this is based on the guarantee that all ops below it are available on primary and they are equal. under normal operations this guarantee holds. sadly, it can be violated when a primary is restored from an old snapshot. at the point the restore primary can miss operations below the replica's global checkpoint, or even worse may have total different operations at the same spot. this pr introduces the notion of a history uuid to be able to capture the difference with the restored primary (in a follow up pr). the history uuid is generated by a primary when it is first created and is synced to the replicas which are recovered via a file based recovery. the pr adds a requirement to ops based recovery to make sure that the history uuid of the source and the target are equal. under normal operations, all shard copies will stay with that history uuid for the rest of the index lifetime and thus this is a noop. however, it gives us a place to guarantee we fall back to file base syncing in special events like a restore from snapshot (to be done as a follow up) and when someone calls the truncate translog command which can go wrong when combined with primary recovery (this is done in this pr). we considered in the past to use the translog uuid for this function (i.e., sync it across copies) and thus avoid adding an extra identifier. this idea was rejected as it removes the ability to verify that a specific translog really belongs to a specific lucene index. we also feel that having a history uuid will serve us well in the future. last the pr also tightens up the connection between the checkpoint file, it's translog and it's lucene index by adding both the translog uuid and the history uuid to it and verifying on read. ps i still want to go through the test and make sure the coverage is good enough. i also want to validate the bwc logic that will only run properly on ci once this is backported. that said, i think we can start reviewing. ", "commit_messages": " added a history uuid to engine/translog infra  fix truncatetranslogcommand dir locking  fix flush docs  make history uuid a requirement for ops based recovery  tighten up reading global checkpoint reading  fix peerrecoverysourceservice or peerrecoverytargetservicetests  testdifferenthistoryuuiddisablesopsrecovery ", "linked_issue_titles": "", "title": "introduce a history uuid as a requirement for ops based recovery"}
{"description": " following up on #1120 ", "commit_messages": " remove py2 compatibility code from fasthttp  remove six py2 compatibility usage  remove some py2 compatibility code  remove six dependency  update readme to reflect that we dont support 2.7 any more. ", "linked_issue_titles": "", "title": "remove six and other 2.7 compatibility code"}
{"description": " with this pr, given a variable x of type unknown, the pattern x && typeof x === 'object' narrows x to object. previously we'd narrow to object | null because a truthiness check applied to unknown is still unknown (and unknown includes null). note that this is a targeted fix for a relatively common pattern. in an ideal world we'd be able to accurately represent types that are known to be truthy, but we currently don't have that ability. fixes #36870. ", "commit_messages": " for x && typeof x === 'object', narrow x to just type object  add tests ", "linked_issue_titles": " truthy check loses effect based on position in \"&&\" chain ", "title": "narrowing from truthy unknown to object"}
{"description": " currently, the new scheduler only spills back from tasks that are \"pending\" scheduling. once the task has been scheduled to the local node, they are not spilled back again. this can cause load balancing tests to fail when a task is assigned to a node that doesn't have enough resources to run, but there are enough resources on a different node. this happens in test_actor_advanced::test_actor_lifetime_load_balancing in the following order: actor creation tasks a and b are queued by and scheduled to node 1. only one actor can live on the node at a time. node 1 starts a worker. node 1 assigns task a, b cannot run. this pr fixes the above scenario by rerunning the spillback policy on tasks that have been assigned to the local node. it spills back at most one queued task per resource shape per call to dispatchscheduledtaskstoworkers. note that this call is currently triggered once per remote node heartbeat received (in addition to local state transitions), so it is probably inefficient but it will guarantee that a task that is stuck in the local queue will eventually get spilled back. i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " spillback from dispatch queue and refactor  unit test  doc ", "linked_issue_titles": "", "title": "spillback from the queue of tasks assigned to the local node"}
{"description": " this fixes sr-11540 by just disfavoring overloads to closures with anonymous var that are function types with more than one argument that matches arguments of no-arg function types. the first approach was to not accept cases like func foo(<t, r>(action: (t) -> r) -> void {}) match foo(action: { return }, in a way that: func foo<t, r>(action: (t) -> r) -> void {} foo(action: { return }) // expected-error {{contextual type for closure argument list expects 1 argument, which cannot be implicitly ignored}} // expected-error@-1 {{generic parameter 't' could not be inferred}} expected-error@-1{{generic parameter 'r' could not be inferred}} // is expected to be foo(action: { _ in return }) but since it broke few tests(that was actually accepting this syntax) and i was not sure if this would be a source-compatible change... so opting to just disfavor the overload disambiguate seemed like a better option :)  resolves sr-11540. ", "commit_messages": " [cssimplify] difavor function type overload when trying to match no arg function type with a closure with a anonimous implicit var closure  [tests] adding sr-11540 tests into test/expr/closure/inference.swift ", "linked_issue_titles": "", "title": "fix ambiguos overload apply to argument for contextual closure"}
{"description": " i refactored the error message built during routes creation. previously tests were failing with node 4, but now it is ok for both stable and 4. ", "commit_messages": " fix error message construction in index.js  the error message in routes creation was not validated by eslint.  now it is accepted as valid and every test runs well.  fix error message for both latest and 4 node versions ", "linked_issue_titles": "", "title": "fixed eslint errors in tests"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). when installing @types/fork-ts-checker-webpack-plugin in a project, its package.json is missing tslint as a dependency: \"dependencies\": { \"@types/webpack\": \"*\", \"@types/node\": \"*\" }, i'm not sure why tslint is not included in here, but from reading the documentation, i can manually add dependencies by creating a package.json file here, so i did that. let me know if there's a better way to go about this! ", "commit_messages": " add tslint dependency to fork-ts-checker-webpack-plugin package.json  add private:true prop to package.json ", "linked_issue_titles": "", "title": "[fork-ts-checker-webpack-plugin]: add missing tslint dependency"}
{"description": " relevant code from v3.5.17 of d3 ticksubdivide:  pie.sort allows null comparator:  add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. provide a url to documentation or source code which provides context for the suggested changes: urls above ", "commit_messages": " d3: add ticksubdivide type to axis  d3: allow null comparator for pie.sort  d3: add test for ticksubdivide ", "linked_issue_titles": "", "title": "add ticksubdivide type to axis and allow null comparator for pie.sort"}
{"description": " closes ##21471 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry this error related to pr #21249 and #21227. this is never supported use case and to use file-handle in to_csv with compression, the file-object itself should be a compression archive such as: with gzip.open('test.txt.gz', 'wt') as f: pd.dataframe([0,1],index=['a','b'], columns=['c']).to_csv(f, sep='\\t') regressed to 0.22 to_csv with support for zipfile. zipfile doesn't support writing csv strings to a zip archive using a file-handle. so buffer is used to catch the writing and dump into zip archive in one go. the other scenarios remain unchanged. ", "commit_messages": " implement closed attribute for py2  revert pr 21249  revert pr 21249  use _get_handle to produce a handle  use _get_handle to produce file handle  regression to 0.22 and add zipfile support ", "linked_issue_titles": "", "title": "file-handle object handled incorrectly in to_csv"}
{"description": " please feel free to remove inapplicable items for your pr. the pr title starts with [mxnet-$jira_id], where $jira_id refers to the relevant jira issue created (except prs with tiny changes) all changes have test coverage: unit tests are added for small changes to verify correctness (e.g. adding a new operator) nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore) build tests will be added for build configuration changes (e.g. adding a new build option with nccl) code is well-documented: for user-facing api changes, api doc string has been updated. for new c++ functions in header files, their functionalities and arguments are documented. for new examples, readme.md is added to explain the what the example does, the source of the dataset, expected performance on test set and reference to the original paper if applicable check the api doc at  to the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change ", "commit_messages": " add sparse block  add sparse embedding  add doc ", "linked_issue_titles": "", "title": "gluon sparse block and sparse embedding"}
{"description": " this pr fixes the case where two applications use the same default storage key but they provide different custom color schemes. for example, app 1: support light, dark, and orange app 2: support light, dark, and yellow if you select orange in app 1 and then open app 2, it will break because they share the same storage key. this pr fixes this edge case by fallback to the default color scheme if the value in storage is not a supported color scheme. i have followed (at least) the pr section of the contributing guide. ", "commit_messages": " fix no colorscheme case  add edge case test ", "linked_issue_titles": "", "title": "fix colorscheme conflict between application"}
{"description": " when executing an escape sequence that might cause the viewport to scroll, a check is made to see whether the cursor position is in the bounds of the scroll margins, otherwise the scroll operation shouldn't happen. in a couple of cases (in the ri, dl, and il escape sequence), these boundary tests were incorrect, so the scroll operation would sometimes not occur when it should have. this pr fixes those boundary tests. tested manually, and with the joe editor which was previously failing, and with some additional screen buffer unit tests. closes #1366 cla signed. if not, go over here and sign the cla requires documentation to be updated i've discussed this with core contributors already. if not checked, i'm ready to accept this work might be rejected in favor of a different grand plan. issue number where discussion took place: #1366 the one problem was the use of viewport::isinbounds method to check whether the cursor was inside the margins. that method only works on the first column of the screen, because the horizontal margins are always set to 0. so that needed to be replaced with a test that only checked the y offset against the vertical margins. the other problem was not first checking whether the margins had actually been set. when the margins aren't set, the top and bottom boundaries are both 0, so that needs to be handled as a special case, otherwise it'll only match positions on the first line of the screen. having made these fixes in the dosrvprivatereverselinefeed and dosrvprivatemodifylinesimpl methods, i thought it might also be a good idea to refactor the boundary tests into a shared method in the screen_information class, to try and make the code more readable. i could also then make use of that method to simplify the dosrvmovecursorvertically implementation a little. i had initially planned to refactor the adjustcursorposition method as well, but i decided against that in the end, because the code is a lot more complicated in that case, and i didn't want to risk potential performance issues given the frequency of its use. in any event, i've committed the refactoring as a separate step, so i can always revert that if you don't think it's a good idea. i've added a few screen buffer units tests that make sure the ri, dl, and il escape sequences basically work, and also specifically check the conditions that were previously failing. i've also run a few of my own manual tests which check various margin boundary conditions. and i've made sure that the problem with joe editor that was reported in issue #1366 is now working. ", "commit_messages": " fix margin boundary tests in the ri, dl, and il sequences.  refactor the margin boundary tests into a reusable screen_information method.  add screen buffer unit tests for the ri, dl, and il sequences. ", "linked_issue_titles": " screen margins and scrolling regions are acting strange for the joe editor ", "title": "fix margin boundary tests in the ri, dl, and il escape sequences."}
{"description": " ne2000 was broken because the os thought the link was always down. fixed that and improved a few things, see the commits. sorry for the archeology, but this seemed like nice stuff for me to get more acquainted with the project :) ", "commit_messages": " kernel/ne2000: correct receive ring buffer wrap-around  next_packet_page points to a page, but was being compared to a byte  offset rather than a page offset when adjusting the boundary register  when the ring buffer wraps around.  fixes #8327.  kernel/ne2000: assume link status is up  right now, ne2000 nics don't work because the link is down by default  and this will never change. of all the ne2000 documentation i looked  at i could not find a link status indicator, so just assume the link  is up.  kernel/ne2000: harvest entropy from ne2000 interrupts  meta/run.sh: allow for overriding of qemu ethernet device type  you can set the serenity_ethernet_device_type environment variable to  pick another device type (i.e. ne2k_pci). defaults to e1000 as before. ", "linked_issue_titles": "", "title": "ne2000 working again and improved"}
{"description": " fix #7161 org.apache.dubbo.config.sslconfig#getserverkeycertchainpathstream  each call will create a new stream,should be closed after use. public inputstream getserverkeycertchainpathstream() throws ioexception { if (serverkeycertchainpath != null) { serverkeycertchainpathstream = ioutils.geturl(serverkeycertchainpath).openstream(); } return serverkeycertchainpathstream; } make sure there is a github_issue field for the change (usually before you start working on it). trivial changes like typos do not require a github issue. your pull request should address just this issue, without pulling in other changes - one pr resolves one issue. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add sample in dubbo samples project. add some description to dubbo-website project if you are requesting to add a feature. if this contribution is large, please follow the software donation guide. ", "commit_messages": " fix netty ssl file leak  remove useless code ", "linked_issue_titles": "", "title": "[master]fix netty ssl file leak"}
{"description": " the title says it all. rdar://28851920 ", "commit_messages": " [semantic-arc] wire up parsing/printing/irgen/serialization/deserialization for copy_value, destroy_value.  rdar://28851920  [semantic-arc] implement ownershipmodeleliminator support for copy_value, destroy_value.  rdar://28851920  [gardening] refactor out setting insertion point and debug scope from each visitor to beforevisit in the ownershipmodeleliminator. ", "linked_issue_titles": "", "title": "ownership model eliminator support for copyvalueinst and destroyvalueinst"}
{"description": " i have followed (at least) the pr section of the contributing guide. the following demos of the transfer list component were migrated: basic transfer list enhanced transfer list related to #16947 ", "commit_messages": " docs: migrate basic transfer lsit demo to emotion  docs: migrate enhanced transfer list demo to emotion ", "linked_issue_titles": "", "title": "migrate transfer list demos to emotion"}
{"description": " fixes use of the wrong exception name in openssl_certificate_info, and makes openssl_csr always use crypto_utils.load_certificate_request(). both changes get no changelog since they affect code new for 2.8. openssl_certificate_info openssl_csr ", "commit_messages": " fix wrong exception name.  use crypto_utils.load_certificate_request() to load csrs with both backends. ", "linked_issue_titles": "", "title": "fix wrong exception, and little refactoring"}
{"description": " as the datastream information is stored in the clusterstate.metadata we exposed the metadata to the asyncwaitstep#evaluatecondition method in order for the steps to be able to identify when a managed index is part of a datastream. if a managed index is part of a datastream the rollover target is the datastream name and the highest generation index is the write index (ie. the rolled index). (cherry picked from commit 6b410df) backport of #57295 ", "commit_messages": " ilm: add support for rolling over data streams  (#57295)  as the datastream information is stored in the clusterstate.metadata we exposed  the metadata to the asyncwaitstep#evaluatecondition method in order for  the steps to be able to identify when a managed index is part of a datastream.  if a managed index is part of a datastream the rollover target is the datastream  name and the highest generation index is the write index (ie. the rolled index).  (cherry picked from commit 6b410dfb78f3676fce1b7401f1628c1ca6fbd45a)  replace java.uitl.list.of usage ", "linked_issue_titles": "", "title": "add support for rolling over data streams (#57295)"}
{"description": " this pr introduces several enhancements to the native filters form and some new functionalities: it shows [untitled] on the left pane when no name is entered. this is consistent with other parts of the platform it shows an error indication on the left pane when an error is generated on the fly or on save. this drags the attention of the user to the right filters where an action is required it restructures a little bit the form using the antdesign form.item wherever possible. however, the constraints of this implementation are huge and i advocate for a full refactor asap video.game.sales.4.mp4 open a dashboard with native filters enabled fill in the form and observe the behavior when an error is generated includes db migration (follow approval process in sip-59) ", "commit_messages": " implement errored filters  clean up ", "linked_issue_titles": "", "title": "highlight errored filters on the left pane of the native filters form plus several enhancements"}
{"description": " this pr fixes the issue where collapsing the side bar in demo mode shifted the demo header instead of leaving it in place. now, when collapsing and expanding the sidebar, the header stays in place and does not move. fixes jira grw-111 ", "commit_messages": " header changes  remove artificial delay ", "linked_issue_titles": "", "title": "fix demo header margin when collapsing and expanding"}
{"description": " issue: #6604 #6605 the react-native storybook ui is lagging web. @domyen and others want to help but are not familiar with react-native. to make things easier, we'd like to use emotion just like on web to make it easier to contribute style changes. migrate the react-native codebase over from stylesheet to emotion. in a few places, the type of some components is manually annotated. that's temporary until emotion-js/emotion#1176 lands. one nice side effect of this change is that the ui becomes themeable almost for free. out of scope these changes do not include any visual changes. visual improvements will be implemented in a follow up pr. ", "commit_messages": " add emotion dependency  update ondeviceui/addons to use emotion  update ondeviceui/navigation to use emotion  update remaining ondeviceui to use emotion  update storylistview to use emotion  update storyview to use emotion  rm remaining style files ", "linked_issue_titles": "", "title": "use emotion to style react-native ui"}
{"description": " it turns out that in rare cases, ensureresources can fail. it's not currently known what can cause it. but the outcome of when it fails is that we hit an error accessing properties on an undefined object.  so this fix at least throws an error in render and doesn't try to render the app causing misleading errors. addresses #19959 ", "commit_messages": " fix(gatsby): ensure that ensureresources ensures resources  test ", "linked_issue_titles": "", "title": "improve error message when ensureresources fails to ensure a resource"}
{"description": " i hereby agree to the terms of the cla available at:  non-significant (changelog entry is not required) processors pipeline for reading from other storages. ", "commit_messages": " processors support for storagedictionary.  processors support for storagedistributed reading.  processors support for storagefile reading. ", "linked_issue_titles": "", "title": "more processors for storage::read"}
{"description": " this fixes a regression compared to fastcomp/emterpretify. enables browser.test_sdl_audio_beep_sleep on upstream. fixes #9823 ", "commit_messages": " add sleep callbacks in asyncify, and use them for sdl audio. fixes #9823  fix ", "linked_issue_titles": " asyncify behaving differently then emterpreter ", "title": "add sleep callbacks to asyncify, allowing sdl audio to automatically update"}
{"description": " you will be asked some questions, please read them carefully and answer honestly put an x into all the boxes [ ] relevant to your pull request (like that [x]) use preview tab to see how your pull request will actually look like before submitting a pull request make sure you have: at least skimmed through adding new extractor tutorial and youtube-dl coding conventions sections searched the bugtracker for similar pull requests checked the code with flake8 in order to be accepted and merged into youtube-dl each piece of code must be in public domain or released under unlicense. check one of the following options: i am the original author of this code and i am willing to release it under unlicense i am not the original author of this code but it is in public domain or released under unlicense (provide reliable evidence) what is the purpose of your pull request? added a new extractor for the unity platform [ this site provides a number of free video tutorials for unity, a popular content creator for 3d games and apps. cheers and thank you! parmjit v. ", "commit_messages": " [unity] add new extractor  [unity] corrected test description field ", "linked_issue_titles": "", "title": "add new extractor (fixes issue #14528)"}
{"description": " align redis chart documentation/readme to actual defaults. as shown here, the real default for master.service.type is clusterip, not loadbalancer. ", "commit_messages": " fix docs to reflect actual default in values.yaml  bump chart patch ", "linked_issue_titles": "", "title": "fix readme for master service type"}
{"description": " we are not going to support 32-bit platforms. but this pr adds 32-bit tests (gcc and clang). fixes #976 ", "commit_messages": " permit 32-bit gcc compilation  minor fixes to avoid 32-bit warnings.  minor fixes to avoid 32-bit warnings.  permit 32-bit gcc compilation  patching things up and adding tests. ", "linked_issue_titles": " check for 32-bit mingw to permit r distribution on windows ", "title": "fix for issue 976 (something like 32-bit support)"}
{"description": " the showdialog function takes a context parameter. that parameter is used to get the current theme.of(context) when showdialog is called. the showdialog dart docs say that after showdialog is called, its widget can safely be removed from the tree, since context is only used when the method is called. this was not actually true, since the theme.of(context) call was happening inside the pagebuilder, even though the context being used was from the original function call. this meant that it was possible for theme.of(context) to be called with an already deactivated build context, throwing an error. related issues fixes #28505 i added the following tests: // regression test for  testwidgets('showdialog only gets theme from context on the first call', (widgettester tester) async { widget buildframe(key builderkey) { return materialapp( home: material( child: center( child: builder( key: builderkey, builder: (buildcontext outercontext) { return raisedbutton( onpressed: () { showdialog<void>( context: outercontext, builder: (buildcontext innercontext) { return const alertdialog(title: text('title')); }, ); }, child: const text('show dialog'), ); }, ), ), ), ); } // first time build. await tester.pumpwidget(buildframe(uniquekey())); // open the dialog. await tester.tap(find.bytype(raisedbutton)); await tester.pumpandsettle(); // second time build. await tester.pumpwidget(buildframe(uniquekey())); // app crashes when we try to open the dialog, because it tries to get the // theme from the old context. await tester.tap(find.bytype(raisedbutton)); }); before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the contributor guide and followed the process outlined there for submitting prs. i signed the cla. i read and followed the flutter style guide, including features we expect every widget to implement. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read handling breaking changes). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " fix bug, add regression test.  remove unnecessary space ", "linked_issue_titles": " showdialog is using the wrong context ", "title": "fix showdialog crasher caused by old contexts"}
{"description": " added riot and svelte to the list of supported frameworks and added the a11y addon to all of the framework examples. modified the waiting text to use the word accessibility rather than a11y is this testable with jest or chromatic screenshots? yes does this need a new example in the kitchen sink apps? no does this need an update to the documentation? no ", "commit_messages": " modified the waiting text to use the word accessibility rather than a11y  added a11y addon to the angular example  added a11y addon to the cra example  added a11y addon to the cra ts example  added a11y addon to the html example  added the a11y addon to the marko example  added the a11y addon to the mithril example  added the a11y addon to the polymer example  added the a11y addon to the preact example  added the a11y addon to the riot example  added the a11y addon to the svelte example  added the a11y addon to the vue example  updated the addon support documentation ", "linked_issue_titles": "", "title": "add a11y examples and documentation"}
{"description": " provide type of key and value of key in std::out_of_range exception adds an additional requirement that key is streamable ", "commit_messages": " add tuple_io include needed by chainbase key streaming  update chainbase to unkown-key branch ", "linked_issue_titles": "", "title": "additional info for unknown key exceptions"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " fix mousetrapstatic returned type  fix mousetrapinstance returned type ", "linked_issue_titles": "", "title": "fix different from the actual return types"}
{"description": " closes #23216 freq inference is pure overhead for the series/dataframe op because freq gets discarded. ", "commit_messages": " api: infer freq in fewer arithmetic ops  dont need separate path ", "linked_issue_titles": " api: which datetimeindex/timedeltaindex ops should infer frequency? ", "title": "dont infer freq in dta/tda arithmetic ops"}
{"description": " was checking the wrong parameter, causing the code to ignore provided stream-specific ssl certificate. better error handling in sslcontext and crypto. follow up on #29871. ", "commit_messages": " fix streampeerssl connect_to_stream w/ custom cert  follow up on #29871.  was checking the wrong parameter, causing the code to ignore provided  stream-specific ssl certificate.  better error handling in sslcontext, crypto ", "linked_issue_titles": "", "title": "fix streampeerssl connect_to_stream w/ custom cert."}
{"description": " this fixes three bugs with the formatting code (used by printf et al) .. well, arguably one of them is a new feature (one called for by the spec). if you zero-pad a negative integer (as with %010d), the zeros would appear before the negative sign (00000-1977) instead of after (-000001977). this was only a bug with integers, not with floats. if you force the display of the sign on a negative integer (as with %+d), the sign would be printed twice (--1977 instead of just -1977). again, this only seemed to be a problem on integers. the \"space\" formatting flag (which is basically the same as + but prints a space instead of a positive sign) was not implemented. i've added tests for all 3 new cases. i did note however that test_printf seems to have two reference output files, one for regular and one for precise 64-bit math. however there does not seem to be a way to run the test with precise 64-bit math. it looks like there was intended to be, but i don't see a way to trigger it. as for running the existing tests, i get 7 errors (out of 2718 tests) running all core tests on the incoming branch. this is before my changes, not after. the tests with errors are default.test_bigswitch, asm1.test_cases, asm2.test_cases, asm2.test_fuzz, asm2g.test_cases, asm2g.test_fuzz, asm2x86.test_cases. with my changes, the errors are exactly the same. i did not cause any of the errors, nor am i sure what is causing them. let me know if you have any questions.. thanks! ", "commit_messages": " fix bug with zero-padded negative integers  the zero padding was before the sign. it should be after.  fix bug with forced display of sign on negative integers  the negative sign was displayed twice.  implement missing 'space' formatting flag  this flag causes space (padding) to be reserved for the sign even if the  number is positive. it is basically the same as the 'plus' flag except that  a space is displayed instead of a plus sign. the 'plus' flag takes precedence. ", "linked_issue_titles": "", "title": "fix 3 issues with formatting (printf)"}
{"description": " following prior work done in #25836, this pr delays emitting balloon events from the tray module to avoid entering v8 during a wndproc callback. implementation details since trayicon objects are deleted when the tray gets garbage collected, we don't want the callback to be processed if the icon is gone. this pr uses weakptr references to achieve this end. this also means that the affected events won't be emitted if the wndproc callback is entered, but the trayicon is destroyed. this behaviour seems in line with electron's existing tray api design, as a reference to the tray needs to be maintained for its api to be used at all.  npm test passes pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed a rare crash on windows that could occur when emitting certain tray events. ", "commit_messages": " wip?  attempt to use weakptr  apply posttask change to other balloon events ", "linked_issue_titles": "", "title": "delay emitting notifyicon events on windows"}
{"description": " backport of #25018 resolves #24942 for 10-x-y npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. this is not a breaking change. breaking changes may not be merged to master until 11-x-y is branched. notes: none ", "commit_messages": " tests: fix early-in-memory-session-create crash test on woa  ci: cleanup user app data directories on woa  (cherry picked from commit 43106d28d8425fd3056d329957beba1503d16f22)  renable crash tests on woa ", "linked_issue_titles": "", "title": "fix woa failing tests (10-x-y)"}
{"description": " as per discussion in the pr azure/msrest-for-python/#145, there some issues with server responses (specially from microsoft) that have bom in it. you can see errors in the tests from my branch here reproducing the same behavior when trying to parse both text and json. this has been fixed by forcing encoding to utf-8-sig when http header has signalized utf-8 or leave to chardet when no encoding has been identified. that way the parsing works as expected and no errors are thrown. ", "commit_messages": " add utf8 with bom to test  add failing tests for bom  fix response with utf8 bom ", "linked_issue_titles": "", "title": "fix for response with utf-8 bom"}
{"description": " i took another look at my original markdown to json conversion scripts and realized how painfully complicated i made my life while quickly writing them. this new converter does everything the old scripts did in half the lines (two for the price of one!). plus, it looks like the original conversion wiped out any punctuation (see the json file changes), so that bug has been squashed in the new version as well. plus, this saves @jbrooksuk from having to work on pr #421 ", "commit_messages": " update build script  display format file during build  add markdown to json converter in python3  remove outdated conversion scripts  update category split logic  update build script to use new converter  add new starter json  remove duplicate json build steps ", "linked_issue_titles": "", "title": "update md2json, validate_format, and validate_links"}
{"description": " run npm run lint meteor provide a url to documentation or source code which provides context for the suggested changes:  also it should be reflected in official doc ", "commit_messages": " fix accounts.onlogout declaration  fix email's form field according to code ", "linked_issue_titles": "", "title": "fix 'from' email's field for accounts.emailtemplates.xxx.from"}
{"description": " this relands #35297 the followings have been done to fix the broken tests: add didsendfirstframerasterizedevent extension and its tests wait for didsendfirstframerasterizedevent instead of didsendfirstframeevent during start up tests mark missed (probably newly added) start up tests as flaky ", "commit_messages": " revert \"revert \"fix the first frame logic in tracing and driver (#35297)\" (#37027)\"  this reverts commit 3068fc4f7c78599ab4a09b096f0672e8510fc7e6.  fix start up tests  1. add didsendfirstframerasterizedevent extension and its tests  2. wait for didsendfirstframerasterizedevent instead of  didsendfirstframeevent during start up tests  3. mark missed (probably newly added) start up tests as flaky ", "linked_issue_titles": "", "title": "reland \"fix the first frame logic in tracing and driver (#35297)\""}
{"description": " hey. this is just a draft to add gcs feed export. i followed the same behavior as the filespipeline, so i'm just using the gcs_project_id setting and it requires the developer to provide the credentials through environment variables (refer to  about the credentials above, i think we could also add a new setting with a path to the credentials file and initialize it using  the list of todos, besides your thoughts are: add documentation add gcs schema add bucket policy options please note that i worked with unit tests here, but i'm open to idea of integration tests. do you have any thoughts? thanks for your time to review this pr (edit) closes #685 ", "commit_messages": " adding gcsfeedstorage  refactoring tests ", "linked_issue_titles": " google cloud storage support (storage backends) ", "title": "fix for #685 add google cloud storage feed export"}
{"description": " to ship gatsby-source-wordpress we previously removed docker from our tests and used a live wp url. this was done because in switching from github actions to circleci, we couldn't properly expose dockers wp url to gatsby. it turns out the reason was that we were using the custom node executor that all the other gatsby integration tests are using. custom executors run in a docker container and don't allow for networking with nested docker containers (due to a security hole that would open in circleci). switching to the machine executor runs the wp tests in a linux vm which allows for proper networking between gatsby and our docker containers. that fix was simple but our test setup turned out to need a bunch of other tweaks to get things running again properly, hence the long list of commits here. ", "commit_messages": " use linux vm for wp int tests  temp comment out other tests ", "linked_issue_titles": "", "title": "feat(gatsby-source-wordpress): use docker for tests"}
{"description": " kip files are used by some sysmodules, both homebrew and official. this is intended to be a \"first step\" towards lle emulation of services, but all this pr adds is the ability to execute kips as if the main application is a kip. this supports both compressed (with blz) and uncompressed kips. this also adds ini file parsing, which is a custom yet simple container nintendo uses to package up to 0x50 kips together. this is used internally with package 2 (to contain some of the most essential sysmodules, like fsp-srv, sm, ldr, and pm) i wrote a quick sample homebrew and used elf2kip to make a kip out of it (as an initial poc): my kip if any of you want to try it: hello world kip file i was also able to launch: a homebrew kip for a custom sysmodule -- there was activity but ofc no graphics (it was xor.play so it wasn't possible to look for a service registration) the offical kip for the settings services, v262144 -- this actually tried to register the set service and threw fatal because we already have it. if you remove yuzu's hle of set, this will register it and then wait for requests as intended, a very good sign! ", "commit_messages": " file_sys: add classes to parse kip1 and ini1 files  partition_data_manager: remove kip processing and use filesys  previously, this tu contained the necessary headers to parse kip/ini but now it should just use the filesys class.  program_metadata: add function to load meta from raw parameters  needed for kip loading as kips do not have an npdm but do have the essential parts of the data within.  loader: add apploader_kip for kip files  loader: add kip and ini file parser-specific errors  loader: add recognition for kip file type  game_list: accept *.kip as a file extension of executables ", "linked_issue_titles": "", "title": "add support for parsing and loading kip (kernel internal process) files"}
{"description": " this pr is a follow up fix to #44730. the pr implements a more thorough check to ensure references are non-mutable when they are narrowed by aliased conditional expressions. for example: function test(obj: { readonly x: string | number }) { const isstring = typeof obj.x === 'string'; obj = { x: 42 }; if (isstring) { let s: string = obj.x;  // not narrowed because obj is assigned in function body } } previously we'd just check that x is readonly. now we also check that obj isn't assigned in the function body. ", "commit_messages": " check entire access path is constant when narrowing by inlining  add tests  accept new baselines ", "linked_issue_titles": "", "title": "fix constant reference check in cfa"}
{"description": " fixes #32984 ", "commit_messages": " add test case  fix infer from usage property assignment  property assignment and shorthand property assignment were incorrectly  treated differently; both have objectliteralexpression as a parent, but  the code previously assumed that property assignments had  objectliteralexpression as parent.parent.  also make fourslash directives case insensitive and less whitespace  sensitive. ", "linked_issue_titles": " crash: infer from usage on create-react-app ", "title": "fix infer from usage prop assignment"}
{"description": " when updating sprite with different region of the same texture, region of existing particles is not updated. this change will call setregion on all active particles to update textureregion. this should fix #4496 ", "commit_messages": " added particle emitter sprite change test  update particle region  fixes #4496 ", "linked_issue_titles": " unable to change particles sprite after spawn ", "title": "fix particle emitter sprite update"}
{"description": " add following awesome python packages: python-stop-words: get list of common stop words in various languages in python. python-currencies: display money format and its filthy currencies, for all money lovers out there. django-markwhat: a collection of template filters that implement common markup languages. short_url: python implementation for generating tiny url- and bit.ly-like urls. sanitize: bringing sanity to world of messed-up data. ", "commit_messages": " \u0001add \u0001python-stop-words  get list of common stop words in various languages in python.  add \u0001python-currencies  display money format and its filthy currencies, for all money lovers out there.  add django-markwhat  a collection of template filters that implement common markup languages.  add short_url  python implementation for generating tiny url- and bit.ly-like urls.  add sanitize  bringing sanity to world of messed-up data. ", "linked_issue_titles": "", "title": "add stop-words, currencies, django-markwha, short_url, sanitize"}
{"description": " sorry @bvaughn and @gaearon. we can add it back. some of the concepts are changing. e.g. getting the current priority level isn't as obviously going to be in the same place. priority field on update isn't useful anymore since the lanes convey more info. this code is also in all the places moving around. it'll be easier to just add this back than to try to keep them each time they move. ", "commit_messages": " remove priority field from tracing  remove debugtracing mode from new reconciler (temporarily)  run debugtracing tests in the *other* variant so it's no on for new reconciler ", "linked_issue_titles": "", "title": "temporarily remove debugtracing from the new reconciler"}
{"description": " with this pr, we now support overload resolution when the tag of a tagged template has multiple signatures. type argument inference when performing overload resolution on a signature. ", "commit_messages": " initial work on overload resolution with tagged templates.  currently type argument inference breaks hard when the first parameter of a tag has a generic type.  conflicts:  tests/baselines/reference/taggedtemplatestringswithincompatibletypedtags.errors.txt  proper type arg inference with apppropriate overload res tests.  corrected comment. ", "linked_issue_titles": "", "title": "type checking for tagged template expressions"}
{"description": " backport of #7380 ", "commit_messages": " [gui] introduce a dialog modality type to differ between modalities  in some cases it happens that the busy dialog is already open before the window activation kicks in.  this will results in a refuse of the activation and some pain for different addon devs because they need to hack around that issue.  this is an attempt to overcome the root cause. it adds a new dialog modality type as a replacement for the current modal flag and  specifed a new type system_modal which is left-out at the check in cguiwindowmanager::activatewindow_internal  [gui] adjusts log level for the window activation refused message  [cosmetics] removes left-over enum window_type in cguiwindow ", "linked_issue_titles": "", "title": "fix activation of window if top most modal is dialog busy"}
{"description": " the viewsets and routers use both base_name and basename. it would be nice if this were consistent. i've deprecated base_name in favor of basename, and get_default_base_name in favor of get_default_basename. fortunately, the deprecation is fairly straightforward. router.register needs to handle both arguments appropriately (fallback to the old value if present, raise deprecation warnings, complain if both arguments are provided) django has a deprecation utility metaclass that already handles method renames. ", "commit_messages": " rename base_name => basename for consistency  update tests to use basename ", "linked_issue_titles": "", "title": "rename base_name => basename for consistency's sake"}
{"description": " updated generate_opcode_h.py. i made the little changes in the header of generate_opcode_h.py. which might be helpful for other to understand the flow of generation of opcode.h ", "commit_messages": " updated  updated latest  updated  updated header in generate_opcode_h.py  run make regen-all successfully ", "linked_issue_titles": "", "title": "update opcode.h header to mention the source data file"}
{"description": " imported render targets are a special case in the frame graph, in particular, the texture resource that refers to them is not a real texture with a hwtexture handle, it can be converted back to the render target, but it can never be used as an actual texture -- in particular it can't be used to create a hwrendertarget. there was other problem related to clearing render targets, individual fixes are explained in their respective cl. this should fix #4085 ", "commit_messages": " add post-processing option to gltf-viewer  fix opaque blit with imported render targets  when the source of a blit refers to an imported render target,  we can't create a hwrendertarget from it because the resource  is not a real texture and doesn't have a hwtexture.  however, it can be converted back to the hwrendertarget it  represents, using the framegraph's declarerenderpass api.  it's a slightly strange usage of this api, but not technically  wrong.  this is the main fix for bug #4085  fix imported target discard and clear flags  an imported target shouldn't specify the discardstart flags, those  are calculated from the graph. however, it needs to specify \"keep\" flags,  to take into account constaints that the graph cannot see (due to the fact  that it's imported into the graph). i.e. the imported target may have  content that needs to be preserved.  an imported target can specify a clear color and clear flags that will  override the flags from the logical descriptor -- this is a way to  delay the swapchain clear to when we're actually rendering into it  (which usually happens in the very last pass).  fix automatic clearing of rendertargets  we were automatically clearing the color pass render target when  the view was translucent -- the idea was that when it gets blended at  the end it wouldn't override the content of the render target.  unfortunately, this doesn't work when the rendertarget is imported,  because in that case, it's not actually blended, we're just rendering  into it directly. the clear would then erase the previous content.  this is fixed by moving the clearing decision in the execute closure and  piggy-backing on the computed discard flag. discard means clear.  the discard flag will be set for newly created buffers and not for an  imported target that needs to keep its content.  disable skybox/clear optimization  we were disabling the color pass render target clear when a skybox  was present. this optimization doesn't work when the viewport is not  full. currently there is no way to know that, so we disable this  optimization for now. performance loss is not expected to be significant  if present at all. ", "linked_issue_titles": " rendertarget crashes with transparent material ", "title": "fix several framegraph issues related to imported render targets"}
{"description": " this fix is for issue: #5713 for a reason still unknown, once py2-psycopg2 package fails to reinstall due to an upstream apk bug (which we are actively fixing), permanently putting apk into a broken state. initially, i had fixed this through a pr: 2925b27 but this had two problems: the less scalable problem was that the fix was targetted to py2-psycopg2 more so, it was discovered that apk fix itself only ever works intermittently (#5713) this change updates the reinstall block with the latest recommended blob from polyverse in general (running the install script, and then checking exit code before proceeding to update/reinstall as a separate if ... fi block.) in addition, we have blacklisted py2-psycopg2 in our repository, thus preventing it from reinstalling, and created a mechanism to ensure we can add more blacklisted packages as we find them in the medium run. in the long run, we're going to fix apk itself to remedy the situation in general for all alpine users (the issue also happens with non-polyverse involvement, we just ended up surfacing it due to the in-place reinstall case.) component name docker packaging ", "commit_messages": " fix py2-psycopg2 right after upgrade  this mitigates the issue  merge remote-tracking branch 'netdata/master'  improve reinstall script so it doesn't get into broken state ", "linked_issue_titles": "", "title": "fix the polyverse reinstall that caused apk broken state"}
{"description": " the current pisink has a few issues that these commits address. it fixes some high cpu and underrun issues. it fixes passthrough of dts/ac3. it fixes the speaker mapping of multichannel. it has been tested for a few weeks in milhouse and miappa test builds with positive results. i think it is suitable for gotham. ", "commit_messages": " [pisink] ensure audio buffers use reasonable sized chunks  previously the sink tried to consume exactly the number of samples required to maintain the desired audio latency.  that has a problem that we reapeatedly get called, and just consume a few samples each call.  as the cost of sending the data to the gpu is quite high, this results in a lot of cpu being used.  this changes the buffering to sleep for a quarter of buffer size, which ensures the samples submitted are always at lease a quarter of the total  also, now the latency is never more than audio_playbuffer, so report that directly in getcachetotal.  [pisink] add support for float and 32-bit formats  significant cpu is consumed in converting audio to the sink's format, so add support for common formats to the sink.  requires update firmware to handle this  [pisink] fix multichannel and passthough  the current pi sink has random speaker allocation and plays noise when passthrough is enabled.  this adds messages to gpu to describe speaker layout for multichannel, and signal when passthrough is used  fixing both these issues  [pisink] increase pi sink's buffering  we do get underruns and breakups at 50ms latency. increase to 100ms. ", "linked_issue_titles": "", "title": "fixes for underrun, passthrough and multichannel"}
{"description": " this project has the code to mock spring webclient mock integration test using \"okhttp - mockwebserver\" ", "commit_messages": " adding complete code implementation of hexagonal architectute example  refactored the code  added the webclient mocking  removed the unwanted repo ", "linked_issue_titles": "", "title": "spring webclient mocking code repo"}
{"description": " fix for #3171. ", "commit_messages": " core: split out selinux label retrieval logic into a function of its own  this should bring no behavioural change.  core: don't implicit open missing socket fds on daemon reload  previously, when the daemon was reloaded and the configuration of a socket unit  file was changed so that a different set of socket ports was defined for the  socket we'd simply reopen the socket fds not yet open. this is problematic  however, as this means the socket_chown state is not run for them, and thus  their uid/gid is not corrected.  with this change, don't open the missing file descriptors, but log about this  issue, and ask the user to restart the socket explicit, to make sure all  missing fds are opened.  fixes: #3171  core: rework how we flush incoming traffic when a socket unit goes down  previously, we'd simply close and reopen the socket file descriptors. this is  problematic however, as we won't transition through the socket_chown state  then, and thus the file ownership won't be correct for the sockets.  rework the flushing logic, and actually read any queued data from the sockets  for flushing, and accept any queued messages and disconnect them. ", "linked_issue_titles": "", "title": "don't reopen socket fds when reloading the daemon"}
{"description": " this replaces the searchcontext passed to the ctor of aggregations with aggregationcontext. it ends up adding a fairly large number of methods to aggregationcontext but in exchange it shows a path to removing a few methods from searchcontext. that seems nice! it also gives us an accurate inventory of \"all of the stuff\" that aggregations use to build and run. ", "commit_messages": " wip  drop searchcontext from agg ctors  cleanup  don't stick to searchcontext  markup  wip  extras  figure out ", "linked_issue_titles": "", "title": "remove searchcontext from constructing aggregations"}
{"description": " _pyunicode_transformdecimalandspacetoascii() missed trailing nul char. it cause buffer overflow in _py_string_to_number_with_underscores(). this bug is introduced in bpo-31979, 9b6c60c. ", "commit_messages": " fix int(s) and similar function may break memory  _pyunicode_transformdecimalandspacetoascii() missed trailing nul char.  it cause buffer overflow in _py_string_to_number_with_underscores().  this bug is introduced in bpo-31979, 9b6c60cb.  add news ", "linked_issue_titles": "", "title": "fix buffer overflow in int(s) and similar functions"}
{"description": " this pr: tweaks some copy in parts 1, 2, and 4 of the tutorial. embeds the livestream video for part 1. /docs/tutorial/part-1/ /docs/tutorial/part-2/ /docs/tutorial/part-4/ ", "commit_messages": " docs(tutorial): copy edits for part 1; embed livestream  docs(tutorial): copy edits for part 4  docs(tutorial): copy edits for part 2 ", "linked_issue_titles": "", "title": "copy edits for parts 1, 2, 4"}
{"description": " test forward with requires_grad=false (this wasn't currently broken but was reported recently). test forward with requires_grad=true (this was actually fixed recently in aten when making size/stride native functions) fix and test backwards.  this required changing the gradient formula and also changing gradcheck to support empty inputs. gradgradcheck fails due to some size issues that don't look related to the formula for this specific function.  it may not be able to handle multiple outputs where some are empty tensors. ", "commit_messages": " add test for empty variable cat (forward only).  test for empty cat (no grad/gradgrad checks)  support gradcheck on empty inputs, check it for cat with an empty variable. ", "linked_issue_titles": "", "title": "improvements around torch.cat on empty variables"}
{"description": " this pull requests adds a setthumbnailclip(region) api to browserwindow instances on windows that can be used to control which region of the window is used to generate the thumbnail image displayed in the taskbar when the window is hoverered over. for the sample electron app if you called it as: require('electron').remote.getcurrentwindow().setthumbnailclip({x:0, y:0, width:500, height:100}) it would change the taskbar thumbnail from: default set via setthumbnailclip this can be useful for media-related apps that want the thumbnail to be the specific content such as an image, video element, etc. closes #2623 ", "commit_messages": " win: add setthumbnailclip window api  document setthumbnailclip ", "linked_issue_titles": "", "title": "add setthumbnailclip api on windows"}
{"description": " source code for the mini article bael-2534 @thombergs ", "commit_messages": " source code for hexagonal architecture article.  source code for hexagonal architecture article.  merge remote-tracking branch 'upstream/master'  source code for bael-2534 : determine if all elements are the same in a java list  source code for bael-2534 : determine if all elements are the same in a java list  removing code done for demo on hexagonal design pattern. ", "linked_issue_titles": "", "title": "bael-2534 - determine if all elements are the same in a java list"}
{"description": " work in progress. made new folder static/asset under articles. i use this to store example images in docs. ", "commit_messages": " [doc] complete outline of docs in gui system  add links to apis  complete simple apis with links  added examples to gui drawing apis ", "linked_issue_titles": "", "title": "add documentation for gui system and install trouble shooting."}
{"description": " see electron/asar#25 for more. fixes #1205. ", "commit_messages": " no need to override child_process.fork  we already support asar in node mode.  spec: test asar archive with unpacked files  recognize asar archive with unpacked files ", "linked_issue_titles": " asar native module unpacking triggers virus scanners ", "title": "add support for asar archives with unpacked files"}
{"description": " our public python apis are often situated next to internal, private apis, with an indication to the user (in code) that those apis are private. this results in users depending on our internal apis, making our python codebase more difficult to evolve. this pr moves some modules containing internal apis to ray._private in an attempt to mitigate this issue. each commit is isolated to the movement of a single module (and all associated changes required); the module that was moved is given in the commit message. the one exception is for monitor, log_monitor, and ray_process_reaper, which were all moved in the same commit in order to make a single update to ray/_private/services.py, which needed a python executable path adjustment. between each commit, i ran ray/tests/test_basic.py to ensure that there weren't any immediately obvious breaks. we'll see if anything else broke in the ci. not that i only changed python code that was contained in python/ray, or symlinked within (such as the dashboard, rllib, streaming etc.). i haven't looked at any other python code that may be hanging around in ray. todos validate that all of these modules strictly contain private apis, and that we want to move them to ray._private. ensure all tests are still passing and that there are no regressions in general. towards #13995 i've run scripts/format.sh to lint the changes in this pr. ", "commit_messages": " async_compat  utils  cluster_utils  compat  function_manager  import_thread  memory_monitor  monitor, log_monitor, ray_process_reaper  metrics_agent  parameter ", "linked_issue_titles": "", "title": "first pass at privatizing non-public python apis."}
{"description": " for #6869. ", "commit_messages": " use mocked data source on spring boot test  remove useless fixture of sharding spring boot test  move shardingspringbootconditiontest package  remove useless javadoc  rename shadowspringbootconditiontest  rename masterslavespringbootstartertest  rename encryptspringbootstartertest ", "linked_issue_titles": "", "title": "replace mock data source to spring boot integrate tests"}
{"description": " closes #26397 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " bug: ensure that top and freq are reported as none for empty dataframes  bug: ensure that the index values obtained when calling describe on an empty categorical / object column is the same as that of an non empty column ", "linked_issue_titles": " dataframe.describe excludes top and freq for empty dataframe ", "title": "fix the output of df.describe on an empty categorical / object column"}
{"description": " @gretzky, i think what was happening was some of the commits in master were also in dev but not all of them. so git/github were freaking out. i created a new branch from the same point as master and rebased those commits on top of dev. everything should be good now and we'll be able to merge dev into master when we're ready for a release. ", "commit_messages": " update issue templates  replace gitter with spectrum (#2483)  replace gitter with spectrum  update issue template and issue-close-app ", "linked_issue_titles": "", "title": "master changes back into dev"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: pinojs/pino#588 ", "commit_messages": " add bindings definition to baselogger  linting fix ", "linked_issue_titles": "", "title": "add definition for logger bindings"}
{"description": " this pr adds support for defining the textcolor of buttons when the button is in the hovered, focused, or pressed states. this is useful for preserving the contrast ratio of the text on a button. often, when buttons are interacted with, the contrast ratio can drop. this makes the text on buttons more difficult to read, and less accessible. for example, we can make the blue text in this button darker on hover, and even darker on pressed. implementation the implementation comes in three parts. creating an enum for materialstate, this includes, hovered, pressed, focused, dragged, disabled, and, error. creating a materialstatecolor class. materialstatecolor has a resolve method that gets the color given a set of states. or just use materialstatecolor.resolvewith(...) and pass a callback that will be used to get a color given a set of states. updating the rawmaterialbutton to keep track of a set<materialstate>, the using it to get the color for the current state from materialstatecolor (or just the color itself if the text color is not a materialstatecolor). i added the following tests: contrast ratio tests for flatbutton, outlinebutton, and raisedbutton in the hovered and focused states. tests that the text/icon of flatbutton, outlinebutton, and raisedbutton can be updated depending on the hovered, focused, and pressed states (using materialstatecolor). tests for buttons in a blue color scheme.  normally in the blue color scheme, the button text is inaccessible in interactive states, but with materialstatecolor, they can be fixed. tests that verify that passing a materialstatcolor to a buttontheme still allows you to specify the hovered, pressed, and focused text color of a given button. tests that verify that passing a materialstatecolor to textcolor will cause disabledtextcolor to be ignored. instead, textcolor in the disabled state will be used. before you create this pr confirm that it meets all requirements listed below by checking the relevant checkboxes ([x]). this will ensure a smooth and quick review process. i read the [contributor guide] and followed the process outlined there for submitting prs. i updated/added relevant documentation (doc comments with ///). the analyzer (flutter analyze --flutter-repo) does not report any problems on my pr. i am willing to follow-up on review comments in a timely manner. does your pr require flutter developers to manually update their apps to accommodate your change? yes, this is a breaking change (please read [handling breaking changes]). replace this with a link to the e-mail where you asked for input on this proposed change. no, this is not a breaking change. ", "commit_messages": " support for stateful text colors in buttons  add color and a11y tests for buttons  fix npe  add documentation ", "linked_issue_titles": "", "title": "add support for hovered, pressed, and focused text color on buttons."}
{"description": " added bson binary definition and a couple of indexing overloads of mongodb. ensureindex and createindex options field is optional so added an overload for that. ", "commit_messages": " added binary class to mongodb.  added createindex and ensureindex overloads to mongodb.collection. ", "linked_issue_titles": "", "title": "mongodb binary object and index overloads."}
{"description": " this is related to #27260. this commit moves the niotransport from :test:framework to a new nio-transport plugin. additionally, supporting tcp decoding classes are moved to this plugin. generic byte reading and writing contexts are moved to the nio library. additionally, this commit adds a basic mockniotransport to :test:framework that is a tcptransport implementation for testing that is driven by nio. ", "commit_messages": " wip  wip  wip  wip ", "linked_issue_titles": "", "title": "create nio-transport plugin for niotransport"}
{"description": " fix missing versionadded/versionchanged for version 0.23, and also fix doc formatting. ", "commit_messages": " fix minor typo in hyperlink  add versionchanged to make_circles and make_moons  fix minor docstring format  fix docstring containing randomstateinstance  add versionadded to basehistgradientboosting and baseloss  add versionadded to histgradientboostingregressor/classifier  add versionadded to votingclassifier/regressor verbose  fix class name in docstring note  add versionchanged to histgradientboostingregressor loss  add versionchanged to iterativeimputer min_value/max_value  add versionadded to glm  add versionadded to elasticnet.fit sample_weight  fix docstring convention formatting  add versionadded to lars/lassolars jitter and random_state  fix pr id in whatsnew  add versionadded to ridgecv/ridgeclassifiercv best_score_  fix docstring hyperlinks  add versionchanged to onehotencoder drop  add versionchanged to onehotencoder drop_idx_ ", "linked_issue_titles": "", "title": "doc fix versionadded for 0.23"}
{"description": " in jungle testnet, libs were not advancing in a mixed of rel. 2.0.x and rel. 2.1.x nodes. this was due to 2.0.x validation failure of blocks produced by 2.1.x, and in turn caused by incorrect conversion between packed_transaction_v0 and packed_transaction_v1. the solution is to make sure a conversion does not stripped any data. new test cases are added. select one: select any that apply: ", "commit_messages": " fix packed_transaction version conversion problem  remove commented out code  call local_pack_context_free_data in packed_transaction_v0 ", "linked_issue_titles": "", "title": "fix packed transaction version conversion -- release 2.1.x"}
{"description": " refactor current tests should pass if relevant, link to documentation update: n/a summary upgrade harmonyexportimportedspecifierdependency and harmonyexportimportedspecifierdependencytemplate to es6 no ", "commit_messages": " raw refactor of harmonyexportimportedspecifierdependency to es6  raw refactor of harmonyexportimportedspecifierdependencytemplate to es6  extract content generation into own method and early return on each stage in harmonyexportimportedspecifierdependencytemplate  extract and simplify getreexportstatement in harmonyexportimportedspecifierdependencytemplate  move comments on top of ifs to make them easier readable  add helper method to determine the hash value in harmonyexportimportedspecifierdependency  early return on getexports if importedmodule is not available  return as early as possible in getreference in harmonyexportimportedspecifierdependency ", "linked_issue_titles": "", "title": "refactor harmony export import specifier dependency to es6"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes: none. it is a purely internal change not based on any changes to the lib. increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " add generic to tomatchobject ", "linked_issue_titles": "", "title": "added generic for \"tomatchobject\" function"}
{"description": " some people on #tox-dev complained that there are too many statuses: user status, connection status and friend status. this pr removes friend status from client-side api and replaces it with two new functions: /* checks friend's connecting status. * *  return 1 if friend is connected to us (online). *  return 0 if friend is not connected to us (offline). *  return -1 on failure. */ int tox_get_friend_connectionstatus(tox *tox, int friendnumber); /* checks if there exists a friend with given friendnumber. * *  return 1 if friend exists. *  return 0 if friend doesn't exist. */ int tox_friend_exists(tox *tox, int friendnumber); ", "commit_messages": " removed friendstatus from client api  modified test ", "linked_issue_titles": "", "title": "removed friendstatus from client-side api, replacing it with alternative functions"}
{"description": " a massive set of updates to office.js, accumulating changes from the past ~6 months for excel, word, and onenote addition of the excelapi 1.7 api set, which adds some 400+ apis codegen updates to word and onenote apis (e.g., new codegen-ed interfaces for .set and .tojson methods) refactoring of enums into strongly-typed strings, for superior intellisense & compile-time safety.  also introducing method overloads that make use of these enums removing of ipromise and promise classes in favor of using the native promise type. adding typings for a few additional apis on the officeextension namespace (more information exposed in debuginfo, pendingstatements, etc.) add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. ", "commit_messages": " update to excelapi 1.7 and with latest word d.ts codegen  remove other ipromise dependencies, making everything be just regular promises  annotate with ts 2.4 requirement in the header ", "linked_issue_titles": "", "title": "excelapi 1.7, additions to word and onenote codegen"}
{"description": " secrets management file of elasticsearch username and password the value of secretsmanagementfile should point to the secrets management file absolute path. the file includes username and password of elasticsearch server in the properties format. user=xxx password=yyy the major difference between using user/password configs in the application.yaml and this file is, this file is being watched by the oap server. once it is changed manually or through 3rd party tool, such as vault, the storage provider will use the new username and password to establish the connection and close the old one. if the information exist in the file, the user/password will be overrided. ", "commit_messages": " temp commit  support secretsmanagementfile file. ", "linked_issue_titles": " support es username/password change dynamically ", "title": "support secrets management file in the elasticsearch 6/7 storage"}
{"description": " i'm \"cherry picking\" these features because i missed them when migrating to 2.1 from 2.2-legacy (i noticed this because of this post on facebook group). i had to do these changes manually because the structure of 2.1 (and master) is different from 2.2 (eg: 2.1 and master has no /tools folder). i made the commits separately for easier testing and revision ^^ ", "commit_messages": " re-add script button from b77200728e7f2b2dd446a9717c83a20c9aac0ce4  re-add create/load script button and context menu  - create from f51b202566e9b2a9deb3eb4836f6e00fb30e8500  - load from 41329f9750379b3c2e506d1e9ed7f6195c812920  re-add script icons from 544194053a54870320d860f1cf333f45723758b9  re-add clear script button and context menu from ce5200b30e6d262905912c6571d51ba6f5979bd7  re-add attach button and context menu from 1880238c3e54f57a14361d2c347387edebc6391b ", "linked_issue_titles": "", "title": "add attach and clear script buttons (2.1)"}
{"description": " running the publish command on a new initialized lerna repo, e.g. with no commits at all, will lead to an error message as reported in issue #773. this change will add a test if there are any commits and will exit the publish command with a more elaborated error message in order to push the user in the right direction what happened and why publish won't proceed. the issue is described in #773. the error message leads the user in a wrong direction what the issue with the failing publish really is: there are no commits, therefore there's nothing to publish. i refactored the init-fixture in order to prepare the test environment without any commits. afterwards i wrote the tests for the added functionality, which is located in commands/publish/lib/is-anything-commited.js and updated the tests for this and for get-current-branch.js as well. the change affects @lerna-test/init-fixture as well as commands/publish/get-current-branch.js. tested on macos 10.13.4 w/ git version 2.15.1 (apple git-101). i have read the contributing document. ", "commit_messages": " refactor(init-fixture): init without commits  fix(command-publish): crash on publish w/o commits  lerna will throw an error, when publishing the current project and  there are no commits at all. this change will check if there are  any commits before proceeding with the publish command.  - refactor the fixtures as preparation for tests with/without commit  - add check if any commits are present  - add tests for this behaviour  closes #773. ", "linked_issue_titles": "", "title": "exit early when publishing w/o commits"}
{"description": " (also make btree's filevtable const, included just to test on travis) ", "commit_messages": " extmod/modbtree: make filevtable const to put it in rom.  py/nativeglue: remove unused mp_obj_new_cell from mp_fun_table.  it has been unused since 9988618e0e0f5c319e31b135d993e22efb593093 ", "linked_issue_titles": "", "title": "remove mp_obj_new_cell from native fun table"}
{"description": " plasma::seal was not synchronous in the previous version of arrow. this meant that a worker trying to create an object would send an async seal to the plasma store, then send an ipc to the local raylet to pin the object. the local raylet would send a get to the plasma store, which could be received before the client's seal. then, it would appear as if the object is not in the plasma store. this will likely have an impact on ray.put() performance for small objects. on my laptop: before this pr single client put calls per second 10610.79 +- 161.55 single client put gigabytes per second 7.39 +- 0.18 multi client put calls per second 16235.04 +- 191.21 multi client put gigabytes per second 10.53 +- 0.53 after this pr: single client put calls per second 8897.05 +- 41.73 single client put gigabytes per second 7.28 +- 0.33 multi client put calls per second 13717.71 +- 345.07 multi client put gigabytes per second 9.51 +- 0.33 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at ", "commit_messages": " upgrade arrow to master  fix build ", "linked_issue_titles": "", "title": "upgrade plasma to latest version, use synchronous seal"}
{"description": " closes #20835 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " added test case  round trippable read/write with errors  added index to test case  mirrored encoding impl  updated whatsnew  lint fixup ", "linked_issue_titles": " \"to_hdf()\" with \"format='table'\" ignores encoder \"errors\" argument. ", "title": "allow errors keyword for hdf io encoding err handling"}
{"description": " the audio mixer tracks changes to the volume using the settings: tdesktop/telegram/sourcefiles/media/audio/media_audio.cpp lines 588 to 596 in 5000902 core::app().settings().songvolumechanges( ) | rpl::start_with_next([=] { qmetaobject::invokemethod(_fader, \"onsongvolumechanged\"); }, _lifetime); core::app().settings().videovolumechanges( ) | rpl::start_with_next([=] { qmetaobject::invokemethod(_fader, \"onvideovolumechanged\"); }, _lifetime); however it uses the internal value _volumesong to set the volume, so if the setting is updated before the mixer value, the previous value is used. when the slider value changes, the value in settings gets updated before the mixer value, causing the previous value to be used in the mixer, which causes #16276 additionally, setting the volume with media controls only updates the setting, causing the playback volume to not change, which causes #16905 ", "commit_messages": " set mixer volume before changing setting  set mixer volume on media control change ", "linked_issue_titles": "", "title": "fix song volume controls, closes #16276 #16905"}
{"description": " this pr requires  #21990 to be merged in first. addresses #20724 and #21927 #dataumbrella summary of changes to basegradientboosting: add tests to ensure gradientboostingclassifier and gradientboostingregressor raise proper errors when invalid arguments are passed in. use the helper function check_scalar from sklearn.utils to validate the scalar parameters. test and validation progress: in both estimators learning_rate n_estimators min_samples_split min_samples_leaf min_weight_fraction_leaf max_depth min_impurity_decrease subsample max_features ccp_alpha verbose max_leaf_nodes warm_start validation_fraction n_iter_no_change tol in gradientboostingregressor alpha references check_scalar docs pr #20723 for the unchecked tasks, validation is coming from basedecisiontree, however, tests have been added for them here. ", "commit_messages": " n_estimators: update unit tests  n_estimators: add validation with check_scalar ", "linked_issue_titles": "", "title": "maint use check_scalar in basegradientboosting"}
{"description": " static saml conf some idps provide metadata urls, okta refers to this scheme as \"dynamic\" configuration. however, some idps do not provide this metadata url, and the alternative is to \"statically\" specify an sso url, entity id, and x509 certificate on the client-side. with this pr, this is configurable through the ui and environment variables. saml response encryption it may be desirable to encrypt the saml response from the idp to the sp. with this pr, this is configurable through environment variables. n/a recording: ", "commit_messages": " change front-end and data model for saml2 auth - static configuration  add changes to use inline metadata.  add changes to use inline metadata.  add switch for static and dynamic saml configurations  fixed config of backend static/dynamic to match ui  add ability to encrypt/decrypt saml assertions with pem and crt files. upgraded to pysaml2 6.1.0 to mitigate signature mismatch during decryption  remove print debug statement ", "linked_issue_titles": "", "title": "static saml configuration and assertion encryption"}
{"description": " fixes: #5971 by re adding the code generation command back in. ran tests/generate_code.sh and . src/clang-format-git.sh which included all the other files and minor formatting issues. ", "commit_messages": " fixed refractoring issue in reflection/generate_code.sh. also, mv deletes the original file, so i don't need to clean it up manually in that case.  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fixed dart tests by removing code-gen for included files.  added code gen for evolution tests back in.  merge remote-tracking branch 'origin/master'  merge remote-tracking branch 'upstream/master'  general generate code and clang format ", "linked_issue_titles": " add code gen step for evolution test schema ", "title": "re-added evolution schema code generation command"}
{"description": " requirements filling out the template is required. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. all new code requires tests to ensure against regressions description of the change my previous attempt to prevent specs from modifying the recent project history (#16255) worked for the most part but had some edge cases that i'm attempting to fix in this pr.  specifically, #16255 only spied on atom.history.savestate.  if a different historymanager was instantiated, it would be able to save history state and globally modify the recent project history.  i found this to occur in at least two specs: a workspace spec that was creating a new atomenvironment (and hence associated historymanager) and historymanager specs that used its own historymanager instance.  to prevent any historymanagers from modifying project history, spec-helper now spies on the historymanager prototype rather than a specific instance.  that means all instances of historymanager will now have savestate spied on.  however, since some historymanager specs explicitly test savestate, for those tests i temporarily unspy savestate and instead spy on the underlying state store.  my previous \"fix\" for historymanager was to spy on atom.applicationdelegate.didchangehistorymanager, which is responsible for broadcasting project history changes to other atom windows.  this was a faulty implementation because while the project history would appear to be conserved, the state store would still be updated with the incorrect project history data.  therefore as soon as you opened another window the recent projects menu would again be incorrect. test plan run some specs in the dedicated spec window and then close it.  ensure that other non-spec windows have their project history maintained, even after opening a new window. run all workspace specs.  ensure that other non-spec windows have their project history maintained, even after opening a new window. run all historymanager specs.  ensure that other non-spec windows have their project history maintained, even after opening a new window. alternate designs none. why should this be in core? the legacy spec helper is in core. benefits no specs should be able to modify project history unless you explicitly unspy savestate. possible drawbacks none. applicable issues #16255 ", "commit_messages": " spy on historymanager prototype  to prevent other instances of historymanager from messing up the project  history  update historymanager spec to mock the state store  don't require historymanager in spec-helper  :art:  :memo: ", "linked_issue_titles": "", "title": "more history manager fixes in specs"}
{"description": " this is a workaround for #54. i'm also sending a separate commit to update autogen.sh to advocate using --with-rootprefix=/ which i believe is slightly better since it's more usual and explicit way to specify the root. i'll try to work with autoconf-archive to extend the macro upstream. i didn't do a full test, just ran autogen.sh and then ./configure --with-rootprefix= and checked the value of the generated rootprefix variable in makefile but i'm fairly confident this should work fine in all cases. more testing is definitely appreciated. @mbiebl @martinpitt @zonque cheers! filipe ", "commit_messages": " build-sys: recommend --with-rootprefix=/ for split-usr  since we started using ax_normalize_path, that is a valid supported  setup and is more explicit than --with-rootprefix= (empty) which is  actually currently broken.  let's advocate for it in the ./configure suggestion from autogen.sh.  build-sys: work around --with-rootprefix= (empty) not producing /  since we introduced ax_normalize_path, using --with-rootprefix=/ does  produce an empty string, but using --with-rootprefix= (empty) now  produces \".\" instead which is wrong.  work around it until we can find a better solution for ax_normalize_path  upstream at autoconf-archive.  bug: ", "linked_issue_titles": "", "title": "fix --with-rootprefix= (empty) with a workaround for now."}
{"description": " this allows requests from non-admin users that have at least \"view_only\" permissions on the ds. also adds the view_only information and limit the result information when the user is non-admin. reverts #4927 as with this the specific route can be used. reasoning: it removes the need for the \"list_data_sources\" permission when accessing the view query page. -- -- ", "commit_messages": " update ds api to accept get from non-admins  revert \"fork button disabled on view query page for non-admin users (#4927)\"  this reverts commit d55042748532517a2b37d23423402c00620aa5ac. ", "linked_issue_titles": "", "title": "allow get from non-admins on data source resource"}
{"description": " this is a continuation of #2460 by @paulfalgout. the former boolean shallow parameter of both the internal and the external flatten is replaced by a depth parameter which can be either boolean or numeric. boolean values still have the same meaning. numeric 1 has the same meaning as true while 0 or less results in a shallow copy without any flattening. the default is still infinite depth. @jashkenas the original pr was approved by @akre54 and @michaelficarra in 2016. if this is sufficiently reassuring for you, you can stop reading here. @paulfalgout i moved your checks against nonnumeric and nonpositive depth values back from the public to the internal flatten. at the time, you were concerned that this would be inconsistent with strict === true, but there is actually no conflict. when depth === 1, every nested element of every array is copied whether the nested element is an array or not, even when strict === true. extrapolating this to depth === 0, \"every array\" is just the top-level array, so every element of it should be copied, regardless of whether it is an array and regardless of the value of strict. merging this should automatically also merge #2460. ", "commit_messages": " allow a specified depth for flatten  per a new tc39 proposal  this was fairly trivial to implement without breaking the current functionality.  thoughts?  account for 0 and negative depths for _.flatten  move a comment back to where it came from  update the comment to _.flatten  add sanity checks  this is mostly to ensure that the internal flatten is still  well-behaved, since it being called internally with boolean arguments,  and there is no check in place to enforce that false is interpreted as  infinite depth.  move the depth guard to the internal flatten  manual testing revealed that flattening with depth=false behaved as a  shallow flatten instead of a deep one. ", "linked_issue_titles": "", "title": "enable flattening to a specified depth (continued)"}
{"description": " currently, the test_logging_config.test_reload_module test fails when processes are created in spawn mode, because the change in how memory is shared between processes means the test logging configs don't get loaded properly in the child. this saves the logging config to an environment variable, which is accessible from the child process. make sure to mark the boxes below before creating pr: [x] description above provides context of the change unit tests coverage for changes (not needed for documentation changes) target github issue in description if exists commits follow \"how to write a good git commit message\" relevant documentation is updated including usage instructions. i will engage committers as explained in contribution workflow example. in case of fundamental code change, airflow improvement proposal (aip) is needed. in case of a new dependency, check compliance with the asf 3rd party license policy. in case of backwards incompatible changes please leave a note in updating.md. read the pull request guidelines for more information. ", "commit_messages": " ensure test_logging_config.test_reload_module works w spawn.  reset configs after reload_logging test is complete. ", "linked_issue_titles": "", "title": "ensure test_logging_config.test_reload_module works in spawn mode."}
{"description": " description: this pr bumps the version of the zha quirks lib. checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " bump zha quirks version  update requirements ", "linked_issue_titles": "", "title": "bump zha quirks to 0.0.31"}
{"description": " this is an example patch for  issue #9177 ", "commit_messages": " add 'normalized' bool and accessor to bufferattribute array in interleavedbufferattribute  add webgl_buffergeometry_points_interleaved example  featuring interleavedbuffer with different numercial type (float32 and  uint8) ", "linked_issue_titles": "", "title": "fix problems with non floating type in interleavedbufferattribute."}
{"description": " my plugin had been updated, so i  want to update it description ", "commit_messages": " add a new context menu component  update vue-mouse-menu to 2.0.0 version, add some new function and supported multi-terminal running. ", "linked_issue_titles": "", "title": "my plugin description have been updated, support for mobile.  please accept my pull request, thanks"}
{"description": " merged a commit that broke test_metrics. this fixes the test for the changes and recommits. i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " revert \"revert \"[dashboard] group by actor class (#10147)\" (#10180)\"  this reverts commit e4d2ca620a20211ccd1ae01c240fe3e21ab8dee3.  fix metrics test to agree with the new logical view api ", "linked_issue_titles": "", "title": "fix and recommit reverted group by actor class pr"}
{"description": " add get_addr() to retrieve the pointer of an snode. this only works on llvm backends for now. ", "commit_messages": " sparse examples and get_addr  .  temp commit. get_addr not working  remove redundant logging  remove more redundant logging ", "linked_issue_titles": "", "title": "add get_addr() to retrieve the buffer addr of an snode"}
{"description": " similar to pull request #5736, this sorts some of the properties in order to be in the same order as the parameters. i went through all the files so hopefully i didn't miss any. additionally, fixed some typos and added a description to two parameters. ", "commit_messages": " fixed typos and reordered properties to reflect parameter order ", "linked_issue_titles": "", "title": "sorted remaining docs properties and added parameter descriptions"}
{"description": " i started with the commit already in #4435: joshwillik@c77bed6 i rebased it on to master to make sure it still applied cleanly, which it does. i checked for test coverage of the related checkssl middleware and found no unit tests, presumably because of the dependencies on config, req and res. i added a commit which is purely a refactor which moves most of checkssl into a unit-testable routine and added several unit tests for it. since the routine was not tested, i moved it from the middleware/index.js to middleware/middleware.js as the docs say that the later is the location for unit-testable middleware. the two commits are not squashed because they are clearer as two: the former shows the logic change, the latter is a refactor. there some functional testing in test/functional/routes/admin_test.js which confirms the refactor doesn't break anything. ", "commit_messages": " make https compatible with a ghost module  closes #4434  - change an incorrect redirect  refactor: make checkssl unit-testable and add unit tests for it.  - code was moved to core/server/middleware/middleware.js, which is the  home for unit-testable middleware.  - functional code coverage for this code also exists at:  test/functional/routes/admin_test.js ", "linked_issue_titles": "", "title": "fixes #4435, also refactors checkssl to be unit-tested."}
{"description": " this change adds the after_key of a composite aggregation directly in the response. it is redundant when all buckets are not filtered/removed by a pipeline aggregation since in this case the after_key is always the last bucket in the response. though when using a pipeline aggregation to filter composite buckets, the after_key can be lost if the last bucket is filtered. this commit fixes this situation by always returning the after_key in a dedicated section. ", "commit_messages": " returns the after_key in composite aggregation response  this change adds the after_key of a composite aggregation directly in the response.  it is redundant when all buckets are not filtered/removed by a pipeline aggregation since in this case the after_key is always the last bucket  in the response. though when using a pipeline aggregation to filter composite buckets, the after_key can be lost if the last bucket is filtered.  this commit fixes this situation by always returning the after_key in a dedicated section.  fix rest test ", "linked_issue_titles": "", "title": "always return the after_key in composite aggregation response"}
{"description": " some modules have more than one component, which is not recommended for maintenance. by extracting those components, we can avoid duplication (e.g. modals and filters). additionally some components were rewritten in typescript and fuselage typings were updated. how to test or reproduce types of changes bugfix (non-breaking change which fixes an issue) improvement (non-breaking change which improves a current function) new feature (non-breaking change which adds functionality) breaking change (fix or feature that would cause existing functionality to not work as expected) hotfix (a major bugfix that has to be merged asap) documentation update (if none of the other choices apply) checklist i have read the contributing doc changelog ", "commit_messages": " replace toastr in components  convert contexts to typescript  split account components  split apps components ", "linked_issue_titles": "", "title": "refactor some react pages and components"}
{"description": " preconditions should retry internally on stale watch data instead of surfacing an error. fixes #82130 does this pr introduce a user-facing change?: fix a bug in apiserver that could cause a valid update request to be rejected with a precondition check failure. /sig api-machinery / ", "commit_messages": " test  in guaranteedupdate, retry on precondition check failure if we are working with cached data ", "linked_issue_titles": " \"precondition failed: uid in precondition\" flakes ", "title": "in guaranteedupdate, retry on a precondition check failure if we are working with cached data"}
{"description": " the custom layout zone number is limited with 40 zones as like as a template. what is include in the pr: linked issue: #9352 communication: i've discussed this with core contributors in the issue. tests: added/updated and all pass installer: added/updated and all pass localization: all end user facing strings can be localized docs: added/ updated binaries: any new files are added to wxs / yml yml for signing for new binaries wxs for installer for new binaries a cla must be signed. if not, go over here and sign the cla. ", "commit_messages": " disable add zone button  unify zone adding ", "linked_issue_titles": "", "title": "limit zones number for custom layouts."}
{"description": " bug fixes ops removed unreasonable code, and fixed an input uninitialized problem. ", "commit_messages": " support elementwise_add triple grad kernel  change code-format to follow ci std  removed unreasonable code, and fixed an input uninitialized issue  support elementwise_add triple grad kernel  change code-format to follow ci std  removed unreasonable code, and fixed an input uninitialized issue  merge commit 'fetch_head' into elementwise_add_triple_grad ", "linked_issue_titles": "", "title": "elementwise_add triple grad, fixed an input uninitialized problem"}
{"description": " this pr gets rid of the singleton implementation of the valuessourceregistry i had been using for prototyping, and replaces it with something that behaves like we generally expect a registry to behave.  searchmodule creates an instance of valuessourceregistry, which then gets pulled down through the various index management classes, until it gets made available to the aggregations framework via queryshardcontext. this also lets us get rid of the atomic initialization guards on the aggregation builders, since tests creating multiple searchmodule instances now get isolated valuessourceregistry instances. special thanks to @nik9000 for pointing me in the right direction on this! ", "commit_messages": " get the vsregistry from queryshardcontext  pass vsregistry into queryshardcontext  wire all the way back to search module  valuessourceregistry member for searchmodule  clean up other uses of vsregistry.getinstance  get rid of singleton & weird atomic init guards ", "linked_issue_titles": "", "title": "plumb valuessourceregistry through to querysearchcontext"}
{"description": " i spent a lot of time to get my jtag debugger to work with arduino and marlin in order to have a real dev environment for my planned multi extruder changes. to be able to use jtag it was required to port the project to avrstudio to compile / upload / debug it there (i tried eclipse without success since avrice and my jtag ice mkii don't really like each other). this pull request includes some correction (typos), bug fixes and stabilizations (have a look at the individual commit comments) i back ported which i think are useful to apply to marlin. maik ", "commit_messages": " fixed typo in comment  delete obsolete and wrong code  \"i\" runs from 0 to 4 but \"add_homeing\" array size is 3 only. on the  other hand the calculated value gets overwritten by either one of the  if choice.  explicit includes to make it compile with avrstudio/eclipse  moved lcd initialization out of constructor  since the class \"mainmenu\" was used within a static variable the  initialization of the object (constructor call) was done before arduino  library startup. it always caused a crash when using avrstudio with  jtag debugger (caused from calling the lcd initialization / the lot of  i/o work / the stack used during this calls). by moving the lcd_init  out of the constructor and using an explicit call inside of arduino  setup() implementation immediately fixed all problems and the jtag  debugger runs fine. ", "linked_issue_titles": "", "title": "marlin v1 - bug fixes / corrections"}
{"description": " #24738, but for 2021 and not 2018. the parts from the original pr description that still hold: interestingly, there is some fallout here in some odd places: first of all, some small changes needed to occur to replicate old behavior. right now, a computed name of type any produces a number index signature. with this change, we make a string index signature instead (it's more broad and closer to correct). lastly, some emit changes - specifically, where previously we'd elide symbol.iterator when it appeared as a property name (and assume that the expression had no sideffects), now we retain and emit it (and potentially cache it), as we generally do not assume property access expressions are safe to elide or copy. fixes #24622 an important implementation note: as we discussed in person, inside the checker, if we see members of the global symbolconstructor of type symbol, we also assume you meant to say unique symbol. in this way, we retain compatibility with older libs or definition files (even as they update), which is how this can build (at all), given node is shimming symbol.iterator as a symbol. fixes #24622 fixes #27525 fixes #31253 fixes #21603 fixes #37182 fixes half of #36468 (indirect calls to symbol() still do not produce fresh unique symbols like direct calls do - but that should be a separate change, imo) ", "commit_messages": " eliminate well-known symbols in the checker: 2021 edition  actually update the lib text to say unique symbol, too (this is unneeded with compat code in place, but this makes goto-def make more sense)  add test showing mismatched symbol constructor type interop  add more test cases for some other related issues this fixes ", "linked_issue_titles": " use unique symbol for well-known symbols  keyof does not include well known symbols  make symbol.* (e.g. symbol.iterator) unique symbols  readonly<float32array> not assignable to float32array  readonly<t> miss all internal symbol keys ", "title": "eliminate well known symbols as a concept in the checker and rely on unique symbols"}
{"description": " attrs in retokenizer.merge and retokenizer.split can now also include lexical attributes and binary flags (like lower, is_stop or like_num). those will be set on the lexeme, so they'll be valid for all entries in the vocabulary, not just that particular token in context. enhancement i have submitted the spacy contributor agreement. ", "commit_messages": " fix formatting and whitespace  add support for lexical attributes (closes #2390)  document lexical attribute setting during retokenization ", "linked_issue_titles": "", "title": "support lexical attributes in retokenizer attrs (closes #2390)"}
{"description": " this adds a new action, clearbuffer. it accepts 3 values for the clear type: \"clear\": \"screen\": clear the terminal viewport content. leaves the scrollback untouched. moves the cursor row to the top of the viewport (unmodified). \"clear\": \"scrollback\": clear the scrollback. leaves the viewport untouched. \"clear\": \"all\": (default) clear the scrollback and the visible viewport. moves the cursor row to the top of the viewport (unmodified). \"clear buffer\" has also been added to defaults.json. from microsoft/vscode#75141 originally closes #1193 closes #1882 i work here requires documentation to be updated this is a bit tricky, because we need to plumb it all the way through conpty to clear the buffer. if we don't, then conpty will immediately just redraw the screen. so this sends a signal to the attached conpty, and then waits for conpty to draw the updated, cleared, screen back to us. works for each of the three clear types as expected tests pass. works even with ping -t 8.8.8.8 as you'd hope. ", "commit_messages": " blindly, i think this is the conpty half of the ask  this plumbs #1882 and #1193 all the way through.  unfortunately, i need to reset the cursor position, and i actually just need  to do this differently entirely.  iterm actually maintains the last line of the buffer entirely. that's kind of  important! otherwise the prompt just disappears too.  they're actually even smarter than that:  *  *  and know where the prompt starts and ends, and keep all of multi-line prompts.  that's a very 2023 feature, but we should keep at least one line.  the revert i was talking about  this is almost right, but we're clearing the attributes of the top line, which is _not_ right.  whatever, it works man  add a roundtrip test  much cleanup. add resource strings  comments comments comments  write a test for controlcore ", "linked_issue_titles": " support manually clearing the conpty buffer  add a terminal-side shortcut for clearing the screen and/or scrollback ", "title": "implement and action for manually clearing the terminal (and conpty) buffer"}
{"description": " followup to #7108 - this further improves code size with that option (by not disabling wasm-only mode). we do still disable it when in a shared module, as further work needs to be done there, but for standalone code this works fine. ", "commit_messages": " don't export the entire table unless we are in a shared module  in wasm mode, emulated function pointers don't force us to export the whole table (but asm.js would need more work to benefit from that)  add test  test  move test  ifdef out asm.js code for emulated function pointers in wasm mode  don't emit table checking code without assertions  try to leave wasm-only with emulated function pointers  update test  update test  wip [ci skip]  merge  update binaryen, and fix a test which assumed vars are called  in the text format (we changed to just )  fix  fix test [ci skip]  allow wasm-only with emulated function pointers, except in shared modules  restore fix ", "linked_issue_titles": "", "title": "allow wasm-only mode with emulated_function_pointers"}
{"description": " i added the new recipes for pages and layouts to get this docs train moving! this pr also includes some of the restructuring i proposed in previous issues (and in the recipe spreadsheet). new recipes in this pr: gatsby project structure creating pages automatically creating pages from markdown posts with createpage (bonus recipe!) creating pages without graphql creating a layout component i also added a numbering system (1.1, 1.2, 2.1, etc.) since these are longer than i'd hoped to still be actionable on-page - that's a goal of these content pieces. i think the table of contents in #15251 will help a lot, too, and we could potentially add an expand/collapse component in the future to make the page easier to digest and scan. closes #14807 closes #14808 closes #14809 closes #14810 ", "commit_messages": " fix: restructure recipes  add new recipes for pages and layouts ", "linked_issue_titles": " [docs][recipes] pages/layouts: project structure  [docs][recipes] pages/layouts: create pages without graphql  [docs][recipes] pages/layouts: create pages automatically  [docs][recipes] pages/layouts: create a layout component ", "title": "rearrange and add new recipes on pages and layouts"}
{"description": " updating the rel documentation section and syncing it with the latest code from  i'm not in favor of directly showing the actual code from the project repo, as sometimes i simplified the code a little to avoid clutter and focus on the main parts. i also really like the current way of showing the implementation in the main body of the docs and the corresponding config section on the right. docs update i have submitted the spacy contributor agreement. ", "commit_messages": " add link to rel project  update rel model code  small fixes and formatting  edits and updates to implementing rel component docs  final fixes  more small corrections  typo ", "linked_issue_titles": "", "title": "update rel example in docs"}
{"description": " this is @mattklein123  idea of to fix #5311 store end_stream for each filter,  if a filter has been \"end_stream\", not to call its decodedata() or encodedata() again. need to do this for response_encoder too. risk level:  low testing:  added unit-test ", "commit_messages": " test continuedecoding  use end_stream for each filter ", "linked_issue_titles": " bug: continuedecoding calls the wrong filter for decodedata() calls ", "title": "store end_stream for each filter, and use it to not call decodedata again()"}
{"description": " currently it only throws the error if you make the request using request.head(uri) this pr updates to also throw the error when making the request by manually setting the method request({ uri: uri, method: 'head' }) ", "commit_messages": " failing test for setting head with a body  throw error if method is head and sending a body ", "linked_issue_titles": "", "title": "throw error when making head request with a body"}
{"description": " related to #11000. minor refactor before my actual pr for #10516. i moved some related syntax tests out of nameandtyperesolution/ and gave them more descriptive names. there are actually two tests that were duplicated version of others, with a typo in their names. ", "commit_messages": " move several tests related to function types from nameandtyperesolution/ to more specific directories  remove duplicate syntax tests for functions taking internal struct types ", "linked_issue_titles": "", "title": "minor cleanup in syntax tests for function types"}
{"description": " this pr adds a tooltip to the guidetool which shows the current offset of the guide that is changing. also, when holding shift, we can snap to a multiple of a value, which is controlled by the property widget. ", "commit_messages": " libgui: add show_tooltip_immediately()  this allows an application to display a tooltip without waiting for a  timer to fire first.  pixelpaint: add tooltip to guidetool to show current offset  the offset of the currently edited guide is shown in a tooltip when  using the guidetool. ", "linked_issue_titles": "", "title": "show offset and add snapping"}
{"description": " this strives to fix several issues with cordova integration plugins handling: fixes several cases causing cordova plugins reinstall on every build: proper handling of scoped npm cordova plugins (adding one would cause reinstall on every build) proper detection of plugin removal (previously a cordova plugin containing a dependency would make the algorithm think a package was removed from cordova-plugins) proper handling of plugins which have plugin.xml id different than the npm package name additionally: rechecks the build integrity verifying if packages were really installed and perform a retry if needed. allows to override a meteor package cordova dependency with scoped package i.e. @scope/cordova-dummy-plugin will now override a cordova-dummy-plugin dependency. (now in this case the same plugin will be installed twice, cordova will leave the last one installed) fixes <dependency id=\"es6-promise-plugin\" url=\" the main benefit is that the full plugins uninstall and reinstall will only happen on plugin being updated, removed or added. now for most projects it happens every build even though cordova-plugins file did not change. additionally because cordova_lib is not handling properly the promises from plugin remove a situation is happening when plugins are missing - this adds a re-check of plugins state and retries to add missing plugins. fixes: #9548 #9973 ", "commit_messages": " validating cordova plugins installation (#9548)  improvements to cordova plugin set change detection algorithm  fixes several cases causing cordova plugins reinstall on every build:  - proper handling of scoped npm cordova plugins  - proper detection of plugin removal (previously a cordova plugin containing a dependency would make the algorithm think a package was removed from cordova-plugins)  - proper handling of plugins which have plugin.xml id different than the npm package name  additionally rechecks the build integrity verifying if packages were really installed and perform a retry if needed.  allows to override a meteor package cordova dependency with scoped package i.e. @scope/cordova-dummy-plugin will now override a cordova-dummy-plugin dependency. ", "linked_issue_titles": "", "title": "cordova plugin handling algorithm consistency improvements"}
{"description": " compiled by vs2010. update powervr libs to 2.09.29. ", "commit_messages": " compilation bug fix. starting android port.  glintptr compilation fix  compilation fix for iphone/android regarding opengl and gl usage  android gles2.0 black screen but compile and run  gles2.0 on android device, some work should be done to detect the correct gles version and launch with the correct parameter.  compilation issue fix  some bug fixes about ios compilation  remove debug and android-10 target downgraded to 8  remove debug from cocos2x android.mk  opengles11context can run on win32, and update pvr lib to 2.0.9.  opengles20context compiled ok, and add pvr gles2 libs to 2.09.29.0649.  issue #757 helloworld and tests compiled by vs2010 based on ogles2 run correctly on win32. ", "linked_issue_titles": "", "title": "gles2.0 helloworld and tests perform correctly on win32."}
{"description": " description: changes a few coding cases to make import cleaner. risk level: low testing: //test/... docs changes: n/a release notes: n/a ", "commit_messages": " make imports easier with some minor cleanups.  format  rename a variable to make it easier to find with 'sed' in google's import. ", "linked_issue_titles": "", "title": "minor changes to make import to google easier"}
{"description": " replace uses of _.kebabcase() with kebabhash(). #4637 this is our first gatsby pr so all feedback welcome. i ran yarn test and updated the snapshots to have the same number of test failures as the v2 branch. ", "commit_messages": " add dep kebab-hash to packages/gatsby. #4637  replace _.kebabcase() with kebabhash(). #4637  add dep kebab-hash to packages/gatsby. #4637  replace _.kebabcase() with kebabhash(). #4637  in the gatsby-plugin-netlify package.  bump kebab-hash to 0.1.2. #4637  update snapshots for new path id format. #4637 ", "linked_issue_titles": "", "title": "use kebabhash() instead of _.kebabcase()"}
{"description": " i hereby agree to the terms of the cla available at:  for changelog. remove if this is non-significant change. short description (up to few sentences): when determining shards of a \"distributed\" table to be covered by a read query (for optimize_skip_unused_shards = 1) clickhouse now checks conditions from both prewhere and where clauses of select statement ", "commit_messages": " process prewhere clause in optimize_skip_unused_shards  added +x for test ", "linked_issue_titles": "", "title": "process prewhere clause in \"skip unused shards\" optimization"}
{"description": " c# apps use the \"x86\" platform identified whereas c++ use win32. fix the cli to account for this. fixes #6213 microsoft reviewers: open in codeflow ", "commit_messages": " c# apps have x86 platform=x86 but c++ apps have win32  change files ", "linked_issue_titles": " \"yarn windows --release\" fails to deploy in e2etest ", "title": "fix deploy of c# apps in release x86"}
{"description": " update node.js to v4.8.1. notable changes:  update npm package to v4.4.4. notable changes:  i'll highlight this part: less verbose error messages with this change the output is cut down substantially, centering the error message. this means that users should expect a lot of the extra (generally repetitive and unhelpful) details to go away with this update.  for example, the following verbiage is no longer always present: npm err! make sure you have the latest version of node.js and npm installed. npm err! if you do, this is most likely a problem with the error-prone package, npm err! not with npm itself. npm err! tell the author that this fails on your system: npm err!     echo \"error: success\" && exit 255 npm err! you can get information on how to open an issue for this project with: npm err!     npm bugs error-prone npm err! or if that isn't available, you can get their info via: npm err!     npm owner ls error-prone update node-gyp and node-pre-gyp packages. node-gyp - adds support for visual studio 2017.  node-pre-gyp - nothing notable. ", "commit_messages": " update node.js to v4.8.1.  notable changes:    disable display of update msg about npm itself, since it's bundled.  as of npm 4.4.0 this is necessary as it will now self-check once per day  for updates.  meteor pre-bundles the version of npm though so this  message will be confusing to users of the meteor tool.    update npm package to v4.4.4.  notable changes:    update node-gyp and node-pre-gyp packages.  * node-gyp - adds support for visual studio 2017.  -  * node-pre-gyp - nothing notable.  - ", "linked_issue_titles": "", "title": "update node.js, npm, node-gyp, node-pre-gyp."}
{"description": " closes #35889 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry in v1.1.2.rst ", "commit_messages": " bug: add unit test, should fail (#35889)  expand tests: group with no np.nan, fix expected output (#35889)  * tests should still fail.  * test dropna=true|false with no np.nan in groupings.  * fix expected outputs, declare expected multiindex in resulting  dataframe after df.group().apply()  double quotes instead of single quote (#35889)  adjust comparison: handle np.nan compare (#35889)  * nans at same positions in level and key compares as equal.  refactor test: handle multiindex dropping nan (#35889)  * this makes test pass.  * follow existing style where we create multiindex,  then set_levels to reinsert nan for case when  dropna=false, and groups has nan grouping.  bug: update rst (#35889)  bug: run code formatters (#35889)  * black pandas  * git diff upstream/master -u -- \"*.py\" | flake8 --diff ", "linked_issue_titles": " bug: groupby dropna=false with nan value in groupby causes valueerror when apply() ", "title": "fix dataframe.groupby().apply() for nan groups with dropna=false"}
{"description": " we want to build networkmanager with -wvla to forbid variable-length arrays. the reason is that glib's g_static_assert() is implemented using an array of negative size, and it can easily happen by mistake that the argument is not a const-argument. for example, when using a static-assert inside a macro, it's much less obvious that the argument is expected to be a constant expression. a non-const expression leads to silently accept the condition by interpreting the result at run-time (actually, at runtime there isn't anything to execute either, because the statement is just a variable declaration). for macros we often declare a temporary variable using typeof() to evaluate the argument only once and avoid size-effects. with variable-length arrays, typeof() and sizeof() are evaluated at runtime, unexpectedly evaluating the expression. as networkmanager has a fork of some systemd sources, we patch them to not use strlen() in such cases to avoid the -wvla warning. but we don't like deviating our fork from upstream and try to minimize such modifications. an alternative would be to build the particular sources with -wno-vla, but that would require to detect support for -wvla in the first place (which it's even more ugly then patching the fork). obviously, systemd makes many uses of this like char path[strlen(\"/proc/self/fdinfo/\") + decimal_str_max(int)]; the pull request doesn't fix most uses, only the two that annoy us. i don't actually believe that systemd likes this approach, but i would be happy if  the pull request would be accepted. an alternative would be to forgo the strlen() macro and use sizeof() directly. i don't mind either way. thanks for consideration. ", "commit_messages": " basic/macros: add strlen() to get length of string literal as constant expression  while the compiler likely optimizes strlen(x) for string literals,  it is not a constant expression.  hence,  char buffer[strlen(\"option_000\") + 1];  declares a variable-length array. strlen() can be used instead  when a constant espression is needed.  it's not entirely identical to strlen(), as strlen(\"a\\0\") counts 2.  also, it only works with string literals and the macro enforces  that the argument is a literal.  tree-wide: use strlen() to allocate buffer of constant size  using strlen() to declare a buffer results in a variable-length array,  even if the compiler likely optimizes it to be a compile time constant.  when building with -wvla, certain versions of gcc complain about such  buffers. compiling with -wvla has the advantage of preventing variably  length array, which defeat static asserts that are implemented by  declaring an array of negative length. ", "linked_issue_titles": "", "title": "don't use strlen() to declare variable-length arrays"}
{"description": " note: this doesn't really do anything, but will allow testing the subroutines pr. also it is unclear whether berlin will have any changes which require breaking evmc api changes. ", "commit_messages": " update evmc to 7.2.0  evmhost: simplify code using new evmc features  evmhost: enable support for berlin ", "linked_issue_titles": "", "title": "update evmc to 7.2.0 and enable berlin support"}
{"description": " some existing tests are modifying the caffe mode halfway through the execution, this is documented to be invalid:  if, for performance reasons, host memory is allocated through cudamallochost, changing the mode halfway can cause a pointer returned by cudamallochost to be freed by free(2), resulting in undefined behavior. the reciprocal is also possible. another possible issue is that if some tests incorrectly assume that the default mode is cpu, the test could actually run on the gpu if the previous test clobbered the global mode. see the full analysis of this issue in #2398 the solution is, imho, to forbid calls to caffe::set_mode() in individual test cases, this function should only be called by the test framework in order to limit the risks of a misuse. to achieve this, the following patch set reuses the existing multidevicetest class and similarly add new classes gpudevicetest and cpudevicetest. in the case where we need to share code between cpu and gpu tests, the shared test code can directly derive from class multidevicetest but derived classes needs to be defined for cpu and gpu. ", "commit_messages": " refactor types floatcpu and doublecpu into a new type cpudevice<t>  similarly, floatgpu and doublegpu are replaced by a new type gpudevice<t>.  split class mathfunctionstest into cpumathfunctionstest and gpumathfunctionstest ", "linked_issue_titles": "", "title": "fix invalid mode changes during tests"}
{"description": " fixes #16326 allow falsy union types like false | t or null | t in spread in order to allow conditionally spreading: function f(shouldspread: boolean, origin: a, spreadee: b) { return { ...origin, ...shouldspread && spreadee }; } it's worth noting that this works currently without strictnullchecks because the type of shouldspread && spreadee is b. however, with strictnullchecks it becomes false | b. this pr special-cases changes the isvalidspreadtype check to allow falsy unions, which are unions that have (1) have one or more falsy types (2) whose non-falsy parts return true for isvalidspreadtype. this is actually stricter than before; these spreads are no longer allowed: var n = { ...null }; var u = { ...undefined }; var un = { ...null, ...undefined }; earlier in the pr's history, i had to to create a bespoke partial<t> which was pretty clunky, but this code is not actually needed to fix the example from #16326, which i believe is by far the most common pattern. ", "commit_messages": " allow booleans in spread types  special-case types produced by bool && expr with the type false | t.  this spreads partial<t> instead of false | t.  update spread tests for booleans in spread types ", "linked_issue_titles": " [suggestion] support conditionally setting keys with the spread operator ", "title": "allow falsy | t spreads for falsy primitives"}
{"description": " i created maze search problem using bfs. for example if the input grid is: 101111 101010 101011 111011 the minimum steps from location (0,0) to (3,5) is 14, so the output is 14. another example: 100 011 011 you cannot go from (0,0) to (2,2), so the output is -1. if creating a new file : added links to it in the readme files ? included tests with it ? added description (overview of algorithm, time and space compleixty, and possible edge case) in docstrings ? ", "commit_messages": " create maze_search.py  create test_bfs.py  create __init__.py  update readme.md  update readme.md  update readme_cn.md  update readme_ge.md  update readme_jp.md  update readme_kr.md ", "linked_issue_titles": "", "title": "created bfs maze_search.py and test case"}
{"description": " closes #33313 tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry  n/a pandas.io.parquet.get_engine() uses handling of importerrors for flow control to decide which parquet reader engine is used. in doing so, it quashed lower-level error messages that would have been helpful to the user attempting to diagnose the error, replacing it with a misleading error message. i refactored the error handling, allowing for these lower-level error messages to be collected and explicitly \"bubbled up\". thus fixing the incorrect error message. no tests added -- this behaviour is not worthy of testing. presumably not worthy of a whatsnew entry either. ", "commit_messages": " collect import error messages and display them  black ", "linked_issue_titles": " bug: bad error message on read_parquet() when wrong version of pyarrow is installed ", "title": "fix read parquet import error message"}
{"description": " this pr introduces the following fixes: duplicate tags are largely eliminated on /blog/tags (e.g. react vs. react, jamstack vs. jamstack, etc.) only tags tied to blog posts are shown (e.g. fixes  removes redundant gatsby tags (note: this was manual and not programmatic) i feel like the tolowercase() and kebabcase mix is a little janky. in the past, i've solved this by adding a custom slug resolver, but it's a bit harder to do with tags. that said, other approaches more than welcome :) ", "commit_messages": " chore: remove gatsby tag from blog posts  fix: iron out some issues on the tag pages ", "linked_issue_titles": "", "title": "fix tag pages on blog/docs"}
{"description": " update scripts under tools/ to use $map.increment and documentation examples. the 1st commit replaces the increments by 1 the 2nd commit replace increments of steps bigger than 1, as introduced in #1897 the 3rd one updates the documentation cc/ @bobrik ", "commit_messages": " replace boilerplate for increment with a call to increment  from new tooling. found cases to replace using ripgrep[1]:    $ rg '\\(\\*\\w+\\)\\s*\\+\\+' -l | grep tools | grep -v old    [1]:  replace boilerplate for bigger than 1 increments with the new  increment call  from new tooling. found cases to replace using ripgrep[1]:    $ rg '\\(\\*\\w+\\)\\s*\\+=' -l | grep tools | grep -v old    [1]: ", "linked_issue_titles": "", "title": "update scripts to use increment"}
{"description": " with index.js imports a.glsl imports sub/a.glsl imports sub/b.glsl, the last import (using require(./b)) should be relative to sub, not asset.filepath (which is in the parent folder. closes #7253 ", "commit_messages": " add test  fix ", "linked_issue_titles": " glsl transformer fails to find nested vendor dependencies (works in v1, fails in v2) ", "title": "resolve glsl relative to the importer, not the asset"}
{"description": " we're proud to have launched vue formulate 2.0 as an open-source form authoring solution for vue.js. this pr adds vue formulate to 3 lists which all apply to the capabilities of the tool. additions have been made to the bottom of the lists on: generator form form -> validation ", "commit_messages": " adds vue formulate to relevant sections of the readme.md file  specifies front-end validation in regards to form validation ", "linked_issue_titles": "", "title": "adds vue formulate to relevant lists"}
{"description": " don't checkout llvm-project don't require cmake and ninja fixes #78564 ", "commit_messages": " don't checkout llvm-project when the llvm backend isn't built  don't require cmake and ninja when the llvm backend is not used ", "linked_issue_titles": " bootstrap: don't mandate cmake and ninja when the llvm backend is disabled ", "title": "misc rustbuild improvements when the llvm backend isn't used"}
{"description": " on the way towards #602 note: i could not find as last_change for linux interfaces. note2: these might want to include flags (on both osx/linux). ", "commit_messages": " added interfaces to linux  merged linux/osx interfaces implementation ", "linked_issue_titles": "", "title": "implement interface_addresses, interface_details for linux"}
{"description": " this pr fixes the error in #42489 this error is caused by not sending activation parameter with conv + bn + leakyrelu pattern in remapper.cc 4d022d6 is the squeeze commit for all  commits in #42489 6aabcb1 updates the unit test to capture the error found in google internal test. 62db9a7 fixes the error. ", "commit_messages": " enable conv + (bias/bn) + leakyrelu fusion  update remapper tests for copy leakyrelu alpha  fix missing activation in conv bn leakyrelu copyattr ", "linked_issue_titles": "", "title": "enable conv + (bias+bn) + leakyrelu fusion with eigen implementation in cpu (resubmit)"}
{"description": " description: adds reset reason to logs for debug purpose and to the body as well. risk level: low testing: existing tests docs changes: n/a release notes: n/a ", "commit_messages": " log reset reason and add it to body ", "linked_issue_titles": "", "title": "add reset reason to logs and body"}
{"description": " both the sentencepiece and tokenizers libraries can limit the users: sentencepiece is not available on conda on every plateform and one of the reason transformers is not on conda tokenizers cannot be used inside some labs which need to build all from source and don't have a rust tooling. this pr aim at making both optional leveraging the addition of sentencepiece algorithms in tokenizer. note: at least one of sentencepiece and tokenizers will be required to use the sentencepiece tokenizers. tokenizers is also required to use the fast tokenizers. main changes in the library organization: fast tokenizers are now separated in tokenization_xxx_fast.py files a convert_slow_tokenizer.py file host conversion methods for a slow to a fast tokenizer but a direct path from a tokenizers serialization file is favored when such a file is available. the test suite for slow and fast tokenizers are now gathered in a single test suite. main new requirements for the tokenizers to pass the new test suite: at least one default vocabulary checkpoint (and max length) should be provided, it is used for the deep tests the fast tokenizer should have an explicit tokenizer_file keyword argument with a default to none (we check that to be sure all the fast tokenizer can accept the new serialization format. to-add: when the documentation for tokenizers is ready: add a lot of link on how to build and add a fast tokenizer add a detailed explanation on how to add a fast tokenizer in the library this pr also: add a __repr__ for the tokenizers (finally...) add a name_or_path attribute to the models and tokenizers giving the shortcut name or the path of the pretrained checkpoint used for instantiation update the fast tokenizer to use (when possible) the new serialization format of the tokenizers library, falling back on the old diverse set of saving format if not available. clean up the tests for the fast tokenizers to bring them in the common tokenizer tests fixes #7402 #5100 (and maybe others) documentation guidelines, and here are tips on formatting docstrings. ", "commit_messages": " splitting fast and slow tokenizers [wip]  [wip] splitting sentencepiece and tokenizers dependencies ", "linked_issue_titles": " tokenizers as an optional dependency ", "title": "make both sentencepiece and tokenizers optional dependencies"}
{"description": " fixes #111 the modulo operator on this calculator gives the result that is different to the most used calculators. the current modrate function is the equivalent of rem(...)/remainder(...), not mod(...)/modulo(...) available in some popular math apps. rename modrate in remrate to be more accurate. add modrate, calculating modulo similarly to matlab, bing, google calculator, maxima, wolfram alpha and microsoft excel add rationalmath::mod using modrate as an alternative to rational::operator% using remrate add a helper sign to retrieve the sign of a rational. modify calcengine to use modrate in normal and scientific mode and remrate in programmer mode. manually and unit tests added ", "commit_messages": " - rename modrate in remrate  - add modrate (arithmetic modular)  - modify calcengine to use modrate in normal and scientific mode and remrate in programmer mode  add unit tests to test rem(x, 0) and mod(x, 0) ", "linked_issue_titles": " modulo operator should work like other calculators out there ", "title": "modify how modulo is calculated in normal and scientific mode."}
{"description": " description: use renamed pypi dependency to 'pyps4-2ndscreen' from 'pyps4-homeassistant' fixes issue where cannot turn on ps4 consistently. try to fix flaky tests leaving files behind checklist: local tests pass with tox. your pr cannot be merged unless tests pass i have followed the development checklist the manifest file has all fields filled out correctly. update and include derived files by running python3 -m script.hassfest. new or updated dependencies have been added to requirements_all.txt by running python3 -m script.gen_requirements_all. ", "commit_messages": " change to renamed dependency pyps4-2ndscreen 0.9.0  rename / bump to ps4 dependency to 1.0.0 ", "linked_issue_titles": "", "title": "ps4 bump to renamed dependency"}
{"description": " xcpretty has been pretty bad at showing reasonable test failure messages recently, so i am reverting to egrep filter strategy and made some changes to better debug jenkins/kokoro test failures. ", "commit_messages": " revert to more useful debug info  show passed tests as well ", "linked_issue_titles": "", "title": "get more useful debug info out of jenkins"}
{"description": " backport of: don't suggest placing use statements into expanded code #44215 stabilize tcpstream_connect_timeout #44563 stabilized iterator_for_each #44567 travis: move sccache to the us-west-1 region #44574 stabilized ord_max_min #44593 stabilized compiler_fences #44595 ci: upload/download from a new s3 bucket #44617 stabilized needs_drop #44639 stabilized vec_splice and modified splice tracking issue #44640 backport libs stabilizations to 1.21 beta #44824 ", "commit_messages": " stabilize tcpstream_connect_timeout (closes #43079)  travis: move sccache to the us-west-1 region  most of the other rust-lang buckets are in us-west-1 and i think the original  bucket was just accidentally created in the us-east-1 region. let's consolidate  by moving it to the same location as the rest of our buckets.  stabilized ord_max_min (fixes #25663)  stabilized iterator_for_each (closes #42986)  updated clippy and rls as it uses the iterator_for_each  stabilized compiler_fences (fixes #41091)  added example to compiler_fence docs taken from unstable-book  added more text from unstable-book to compiler_fence docs  ci: upload/download from a new s3 bucket  moving buckets from us-east-1 to us-west-1 because us-west-1 is where  rust-central-station itself runs and in general is where we have all our other  buckets.  stabilized needs_drop (fixes #41890)  stabilized vec_splice (fixes #32310)  updated tracking issue for string::splice and its unstable-book entry ", "linked_issue_titles": "", "title": "backport accepted prs to 1.21"}
{"description": " deleting directory make gatsby crash. when working with markdownfiles and deleting a directory the developer server will crash. the same check that is for files should also be on directories, otherwise it might try to delete a directory that does not exist. ", "commit_messages": " update gatsby-node.js  deleting directory make gatsby crash. when working with markdownfiles and deleting a directory the developer server will crash. the same check that is for files should also be on directories, otherwise it might try to delete a directory that does not exist.  update gatsby-node.js ", "linked_issue_titles": "", "title": "developer server crash when deleting markdown directories"}
{"description": " release notes for maven-surefire-plugin 2.19: new parser of test patterns, let's call it test filter api, related to parameters: test, ex/includes, ex/includesfile; a feature to interrupting the test-set after exceedded certain number of errors/failures new doxia version anchoring test class names shutdown operations command based communication between in-plugin and forked process improvements in junit and testng runners etc. see  release notes for maven-checkstyle-plugin 2.17: bug improvement task release notes - apache maven clean plugin  version 3.0.0  improvements: release notes - apache maven shade plugin  version 2.4.2  bugs: improvements: same as #14193 but on 2.x branch ", "commit_messages": " update surefire to 2.19 and checkstyle to  # release notes for maven-surefire-plugin 2.19:  * new parser of test patterns, let's call it test filter api, related to  parameters: test, ex/includes, ex/includesfile;  * a feature to interrupting the test-set after exceedded certain number of  errors/failures  * new doxia version  * anchoring test class names  * shutdown operations  * command based communication between in-plugin and forked process  * improvements in junit and testng runners  * etc.  see  # release notes for maven-checkstyle-plugin 2.17:  ## bug  * [mcheckstyle-302] - using inline configuration does not work with maven 2.2.1  * [mcheckstyle-304] - using inline configuration, checkstyle-checker.xml is generated using dtd v1.2  * [mcheckstyle-310] - parrallel build failing with various errors  * [mcheckstyle-311] - \"mvn clean site -preporting\" fails with could not find resource 'config/maven_checks.xml'  ## improvement  * [mcheckstyle-291] - change format of violation message  * [mcheckstyle-293] - update to use non deprecated method checker.setclassloader()  ## task  * [mcheckstyle-307] - upgrade to checkstyle 6.11  * [mcheckstyle-313] - upgrade to checkstyle 6.11.2  update clean plugin to 3.0.0  # release notes - apache maven clean plugin  version 3.0.0    ## improvements:  * [mclean-56] - make plugin only 3.x compatible - get rid of maven 2.  * [mclean-62] - upgrade to maven-plugins parent version 27  * [mclean-63] - make naming of properties consistent  * [mclean-65] - bump version to 3.0.0  * [mclean-66] - upgrade maven-shared-utils to 0.9  * [mclean-67] - change package name to org.apache.maven.plugins  * [mclean-69] - upgrade maven-shared-utils to 3.0.0  update maven shade plugin to 2.4.2  although not really used:  release notes - apache maven shade plugin  version 2.4.2    bugs:  * [mshade-172] - \"java.lang.arithmeticexception: / by zero\" in minijarfilter  * [mshade-190] - shade does not relocate the contents of meta-inf/services files  * [mshade-209] - [regression] \"java.lang.arithmeticexception: / by zero\" in minijarfilter (reporter jon mclean).  improvements:  * [mshade-205] - better use of clazzpathunit for improved jar minimization (contribution of benoit perrot).  * [mshade-207] - replace wrong link to codehaus with correct location  * [mshade-210] - upgrade maven-plugins parent to version 28.  * [mshade-211] - keep java 1.5 ", "linked_issue_titles": "", "title": "update surefire to 2.19, checkstyle to 2.17, clean to 3.0.0, shade to 2.4.2"}
{"description": " fixes #13102 did you read the contributor guideline, pull request section? was this discussed/approved via a github issue or the forum? inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) #13102 @patrickvonplaten @patil-suraj ", "commit_messages": " fix inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) (#13102)  fix missing elements in outputs tuple ", "linked_issue_titles": " inconsistency of the last element in hidden_states between pytorch/flax gpt2(neo) ", "title": "fix flax gpt2 hidden states"}
{"description": " the pattern let &(ref a, ref b) = &selfcauses a compiler ice. avoid use of it in libcore/to_bytes.rs. ", "commit_messages": " libcore/to_bytes.rs: add iterbytes impls for pairs and triples  libcore/to_bytes.rs: fix iterbytes instances for pairs, triples to not cause ice when used ", "linked_issue_titles": "", "title": "fix tuple instances for iterbytes to avoid ice, fixes #4092"}
{"description": " fixes #40488 and #40489. ", "commit_messages": " modify test case to reproduce error  fix typeonlyexport codefix to work with 3 or more type exports in the same declaration  the check to ensure that a fixed export declaration wasn't fixed again  was reversed. this only surfaced when 3 or more type exports existed in  the same declaration.  add failing test cases for comments being duplicated  fix converttotypeonlyexport codefix from duplicating leading comments ", "linked_issue_titles": " converttotypeonlyexport codefix breaks when applying all codefixes to an export with 3 re-exported types ", "title": "fix two issues with converttotypeonlyexport codefix"}
{"description": " --preload-file / --embed-file add some pre-js code to load the file. a user pre-js can break that if it does module = {} for example, as the files have assigned to module.prerun to set up a task. this is rare because preloading files is really just common on the web, and there we normally don't do module = { .. } in the js. instead the module is defined on the html earlier. however, i debugged something now that ended up being this, and it can be confusing. to avoid others being confused, add some assertions that check that module.prerun has the right values even after the user pre-js. ", "commit_messages": " rev  more [ci skip]  more  fix  flake8 ", "linked_issue_titles": "", "title": "add an assertion for bad --pre-js / files interaction"}
{"description": " this adds host grouping based on \"service\" and \"stack\" to the docker.py inventory script. docker.py inventory ansible version ansible 2.7.0 config file = none configured module search path = [u'/home/eric/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules'] ansible python module location = /usr/local/lib/python2.7/dist-packages/ansible executable location = /usr/local/bin/ansible python version = 2.7.15rc1 (default, apr 15 2018, 21:51:34) [gcc 7.3.0] this makes no change to existing functionality but extends the grouping of containers based on image to group on stack and service as well. this is done by conditionally keying the a host's groups off of the labels com.docker.stack.namespace and com.docker.swarm.service.name. the derived groups are in the format service_<service_name> and stack_<stack_name> you can find the docker-compose file i used to create these groups here. excerpt from \"pretty\" docker.py output: $ contrib/inventory/docker.py | jq .service_ansible_mock_host [ \"ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef\", \"ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann\", \"ansible_mock_host.3.sn74oapkk5ay3la148js5z93n\", \"ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b\", \"ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg\", \"ansible_mock_host.3.ly13cxwzvibmuf6volsr8t1z8\", \"ansible_mock_host.2.bkiiay0a48a3koxkgbvvte9me\" ] $ contrib/inventory/docker.py | jq .stack_ansible_mock [ \"ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef\", \"ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann\", \"ansible_mock_host.3.sn74oapkk5ay3la148js5z93n\", \"ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b\", \"ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg\", \"ansible_mock_host.3.ly13cxwzvibmuf6volsr8t1z8\", \"ansible_mock_host.2.bkiiay0a48a3koxkgbvvte9me\" ] # warnings omitted from output for legibility $ ansible -i contrib/inventory/docker.py 'stack_ansible_mock:&running' \\ -m ping -e ansible_connection=docker -e ansible_python_interpreter=/usr/local/bin/python ansible_mock_host.1.hxnrh84blwmscu2pmgl4p5ann | success => { \"changed\": false, \"ping\": \"pong\" } ansible_mock_host.5.i5t8il409jgua2olw1wfw5ucg | success => { \"changed\": false, \"ping\": \"pong\" } ansible_mock_host.3.sn74oapkk5ay3la148js5z93n | success => { \"changed\": false, \"ping\": \"pong\" } ansible_mock_host.4.zi8jyrocpts7hw8x0sba9k47b | success => { \"changed\": false, \"ping\": \"pong\" } ansible_mock_host.2.qo2m6mrmtfy8f8zl64yogsyef | success => { \"changed\": false, \"ping\": \"pong\" } ", "commit_messages": " adding service and stack grouping to docker inventory  updating documentation ", "linked_issue_titles": "", "title": "docker inventory service/stack groups for docker swarm"}
{"description": " not sure if this is already fixed upstream but in case it's not @merceyz tests failed for me as well with core.autocrlf=false on win10 and passed after this fix. @mnajdova could you check this out and see if it works? if not please include the output of git config --get core.autocrlf ", "commit_messages": " [test] fix ttp tests failing on windows  fix macro tests as well ", "linked_issue_titles": "", "title": "fix failing tests on windows"}
{"description": " summary master: installation of mkl and mkl-services: 10.10s installation of pil/pillow: 11s installation of pydot graphvis: 21s total: 43s proposed: grouped installation of  mkl ,mkl-services pil/pillow pydot graphvis: 24.8s. we can save ~18s on all travis jobs. related issues pr overview this pr requires new unit tests [y/n] (make sure tests are included) this pr requires to update the documentation [y/n] (make sure the docs are up-to-date) this pr is backwards compatible [y/n] this pr changes the current api [y/n] (all api changes need to be approved by fchollet) ", "commit_messages": " grouped conda installation together.  added travis retry. ", "linked_issue_titles": "", "title": "grouped conda installations together to speed up the travis build."}
{"description": " this pr adds min, max and clamp as css functions to data types. this allows us to also write more \"modern\" arbitrary values, e.g.: <div class=\"text-[min(10vh,100px)]\"></div> which results in: .text-\\[min\\(10vh\\2c 100px\\)\\] { font-size: min(10vh, 100px); } before this pr, this code wouldn't even be generated, if you wanted this to be generated then you had to force the length: data type for example: <div class=\"text-[length:min(10vh,100px)]\"></div> ", "commit_messages": " update changelog  add tests to verify that w-[0] works  ensure that min, max and clamp also work with arbitrary values ", "linked_issue_titles": "", "title": "add css functions to data types"}
{"description": " this will add support for google voice sms. this is dependent on ", "commit_messages": " pygooglevoice-sms support  pygooglevoice-sms support  updated googlevoicesms version  added target support for googlevoice  fixed style errors  added test exclude in .coveragerc ", "linked_issue_titles": "", "title": "google voice sms notification support"}
{"description": " this changes add documentation for accessing datetimes in painless scripts from the three most common inputs of params, _source, and doc. ", "commit_messages": " add inputs for datetimes  quick word change  checkpoint  add painless datetime input documentation ", "linked_issue_titles": "", "title": "add painless docs for datetime inputs"}
{"description": " have you signed the contributor license agreement? resolves #409 when resource.pri is not present a winrt::hresult_error is thrown by the loader. we then catch the exception and try to log using a localized string which makes the exception be thrown again. this changes adds a try catch in winrt::hresult_error catch. the new catch will default to the english message for unexpectederrorexecutingcommand. also add logging when the loader fails. microsoft reviewers: open in codeflow ", "commit_messages": " add try catch and logging for failed to load resources file  handle exception better ", "linked_issue_titles": " after building from source code, winget \"install\" command crashes when trying load string from resources. ", "title": "fix crash when resource.pri is not present"}
{"description": " allow user to disconnect a connection on server side and passing websocket close status code (1000 or 4000-4999 and close reason. modify the handler of close frame in swwebsocket_dispatch_frame, avoid sending double close frames when the server actively close the connection. add a simple test tests/swoole_websocket_server/websocket_disconnect.phpt for testing disconnect method. ", "commit_messages": " add websocket_server disconnect, change websocket dispatch close frame logic  websocket_server->disconnect($fd, $code, $reason)  close frame:  1. start and send by client, response with close frame with echo  2. start by server and send by client, no reply  add test for websocket_server->disconnect()  fix tab intend with 4 spaces  fix tab intend with 4 spaces ", "linked_issue_titles": "", "title": "add websocket server disconnect method with status code and reason"}
{"description": " backport of #16666 ", "commit_messages": " [ios] add iphones 11 to the list of known devices  [ios] don't rely on main screen having only one screen mode - it's not true for iphones 11  partially reverts a85e511 ", "linked_issue_titles": "", "title": "add support for iphones 11"}
{"description": " the cleanup after federation service e2e tests is not effective as this function cleanupserviceshardsandproviderresources is getting called with empty string for namespace (\"nsname\") because the nsname variable is getting redefined. another issue is we are prematurely exiting the poll in waitforserviceorfail and the error check is incorrect. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # fixing the 2 issues mentioned above. release note: ", "commit_messages": " fix lb and service leak in federated clusters in e2e tests  fix prematurely exiting testcase while waiting for clustered service ", "linked_issue_titles": "", "title": "fix resource leak in federation e2e tests and another issue"}
{"description": " changing accidental contentrootpath link to webroot link on generic host doc. this fix should have been in #14108 (diff)     discovered just as it was merged however so fixing here. fixes issue #10559 ", "commit_messages": " just updated sxs link per issue 10559  updates for side by side and web root references  updated per tdykstra recommendations, link changes  changes xref to relative link for web root  link fix, switching contentroot to webroot ", "linked_issue_titles": "", "title": "link fix related to 14108"}
{"description": " decode the parent expansion for traits and enums in rustc_resolve, this was already being used for resolution in typeck avoid suggesting importing names with def-site hygiene, since it's often not useful add more tests r? @petrochenkov ", "commit_messages": " handle cross-crate module expnids consistently  - always use the expnid serialized to tables  - use the id for traits and enums from other crates in resolution.  don't suggest importing items with hygienic names  this will potentially hide a few correct suggestions, but importing  these items from another module is not generally possible. ", "linked_issue_titles": "", "title": "improve and test cross-crate hygiene"}
{"description": " newlines in the command, args, env.value, or annotations fields are not uncommon. wrap and indent these fields so that describe is more readable. before: host port:     <none> command: /bin/bash #!/bin/bash set -euo pipefail # set by the node image unset kubeconfig trap 'kill $(jobs -p); exit 0' term # track the current state of the config after: host port:     <none> command: /bin/bash #!/bin/bash set -euo pipefail # set by the node image unset kubeconfig trap 'kill $(jobs -p); exit 0' term # track the current state of the config annotations when wrapping: annotations:  kubectl.kubernetes.io/desired-replicas: 1 openshift.io/deployer-pod.completed-at: 2018-07-31 22:47:15 +0000 utc openshift.io/deployer-pod.created-at: 2018-07-31 22:37:11 +0000 utc openshift.io/deployer-pod.name: test-3-deploy openshift.io/deployment-config.latest-version: 3 openshift.io/deployment-config.name: test openshift.io/deployment.phase: failed openshift.io/deployment.replicas: 0 openshift.io/deployment.status-reason: manual change openshift.io/encoded-deployment-config: {\"kind\":\"deploymentconfig\",\"apiversion\":\"apps.openshift.io/v1\",\"metadata\":{\"name\":\"test\",\"namespace\":\"clayton-dev\",\"selflink\":\"/apis/apps.op... handle newlines for command, args, env, and annotations in kubectl describe wrapping ", "commit_messages": " break command and args in description by newline  inline scripts may use newlines in these fields, and properly indenting makes the output more readable:    command:  /bin/bash  -c  #!/bin/bash  echo \"inline script should be indented\"    environment vars with newlines should be indented  break env var values with newlines so they form a consistent left alignment.  add tests for newline in command, arg, and env  break annotations with newlines and shorten length  make annotations with newlines display a more consistent left edge, and indent the value  when the annotation is too long to give the value more space. shorten the width of the  trimmed annotation to a value more consistent with our -o wide value.  instead of putting the key and value flush with a = separator, make annotations closer  to fields than to labels by using :  as a separator. ", "linked_issue_titles": "", "title": "make kubectl describe more tolerant of newlines"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. / ", "commit_messages": " [yandex-maps] fix module format  add missing each() method for layers  make context optional in each()  add tests for layers.each() ", "linked_issue_titles": "", "title": "fix module format, fix each()"}
{"description": " background when we have worked on #16991 we wanted to test the new functionalities in concrete and accurate unittest. all chartdata flows and its components are too couple to superset so it is impossible to create unittests. the flows are not testable and so many components do not meet the very important principle srp and the code became so dirty so i've started to refactor it (#17344 ) but many changes were added and it was hard to review so i decided to split those changes into small prs so will be easier to follow this is the eleventh pr in a sequence of prs to meet these the next pr is #17497 pr description querycontext class contains static methods used as dataframe utils. to meet srp, those methods moved to a utils package. to keep the utils meeting srp, it implies arranging the utils to be as package and separating each of the related methods into ad hoc modules. test plans there is no logic added so new tests are not required previous prs #17399 #17400 #17405 #17407 #17425 #17461 #17465 #17466 #17479 #17495 ", "commit_messages": " chore(common.utils): modified utils from module based to package based  refactor(common.utils): move querycachemanager to ad-hoc module  refactor(querycontext): move df method utils to utils module ", "linked_issue_titles": "", "title": "move df methods utils to utils package"}
{"description": " using the gi command provided by the gitignore plugin was causing a % to be shown in the terminal at the end of output. i opened an issue on the gitignore.io repository and they suggested adding -w '\\n' to the curl command in order to make curl add the new line character at the end. the linked issue explains what my problem was in more detail. this pr applies the suggested fix. further, arguments expansion has been double-quoted for security reasons. see ", "commit_messages": " add trailing new line at the end of output  double-quote variable expansion  it's good practice to double-quote variable expansions, for security  reason.  see ", "linked_issue_titles": "", "title": "minor improvements to the gitignore plugin"}
{"description": " as is described in #5667, the flannbasedmatcher doesn't work in python (linux and osx confirmed, python 2.7 and 3.5) at the moment. the following code generates an error as of the 3.1 tag: import numpy as np import cv2 img1 = cv2.imread('opencv/samples/data/box.png',0)          # queryimage img2 = cv2.imread('opencv/samples/data/box_in_scene.png',0) # trainimage sift = cv2.xfeatures2d.sift_create() # initiate sift detector kp1, des1 = sift.detectandcompute(img1,none) # find the keypoints and descriptors with sift kp2, des2 = sift.detectandcompute(img2,none) flann_index_kdtree = 0 index_params = dict(algorithm = flann_index_kdtree, trees = 5) search_params = dict(checks=50)   # or pass empty dictionary matcher = cv2.flannbasedmatcher(index_params, search_params) matches = matcher.knnmatch(des1, des2, k=2) # error is thrown opencv error: assertion failed (the data should normally be null!) in allocate, file opencv/modules/python/src2/cv2.cpp, line 163 traceback (most recent call last): file \"test.py\", line 21, in <module> matches = flann.knnmatch(des1, des2,  k=2) cv2.error: opencv/modules/python/src2/cv2.cpp:163: error: (-215) the data should normally be null! in function allocate this seems to be caused by the flannbasedmatcher::add overload, as this does not occur when using the bfmatcher. given the logic from descriptormatcher:add, it looks as though the inputarray was not being properly marshalled. this fixes that and i can confirm that the error no longer occurs on this branch. ", "commit_messages": " update indentation to match rest of file  very cosmetic, but was analyzing code and just wanted to make it  consistent.  fix parsing of training vecs for flannbasedmatcher  flannbasedmatcher::add is overloaded, but the style of parsing the  inputarrayofarrays does not match the style from  descriptormatcher::add. the issue is that inputarrayofarrays  must be properly marshalled so that the data can be read  correctly. in this case, the method expects the training  descriptors to be either a vector of matrices or a single matrix  (as is shown in descriptormatcher::add). these code  replicates that for the case of the flannbasedmatcher::add.  in fact, a similar commit to this was added by 26d9a7c but was  ultimately not accepted in #4111. this is likely due to the  fact that the input arrays were not parsed properly and the  case of a single matrix was being improperly handled. i believe  this commit to be correct given the logic from  descriptormatcher::add. ", "linked_issue_titles": "", "title": "flannbasedmatcher python fix (fixes #5667)"}
{"description": " $ hexo help list above command causes outofmemory. cause at hexo v3.0.1, printlist(title, list) ( hexo/lib/plugins/console/help.js line 59 e8e45ed function printlist(title, list){ ) has a problem. if list have only one element, variable length becomes zero (because of the list is not sorted). then while (padding--){ ... } causes infinite loop. solution i separate setting length from sorting. ", "commit_messages": " add test  fix infinite loop  set initial value of length to avoid inifinite loop. ", "linked_issue_titles": "", "title": "hexo help list command causes outofmemory"}
{"description": " add or edit tests to reflect the change. (run with npm test.) follow the advice from the readme. avoid common mistakes. run npm run lint package-name (or tsc if no tslint.json is present). provide a url to documentation or source code which provides context for the suggested changes:  increase the version number in the header if appropriate. if you are making substantial changes, consider adding a tslint.json containing { \"extends\": \"dtslint/dt.json\" }. former declaration was broken on koa-websocket 5.0. latest version of koa framework and its components doesn't rely on this. middlewares shares the request context using their first parameter context. ", "commit_messages": " fix koa-websocket to match with its implementation  the major change is about middleware. koa-websocket doesn't inject  this argument to its middlewares. instead, additional properties are  appended on the koa context.    extract context.websocket  it's necessary to use well with other middlewares,  like koa-router or else.  add context.app to be able to access ctx.app.ws  add a test about context.app ", "linked_issue_titles": "", "title": "fix to match with its implementation"}
{"description": " add or edit tests to reflect the change. follow the advice from the readme. avoid common mistakes. run npm test <package to test>. the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. represents shape of module/library correctly tslint.json should contain { \"extends\": \"dtslint/dt.json\" }, and no additional rules. tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. provide a url to documentation or source code which provides context for the suggested changes: < add it to notneededpackages.json. additional info about the change: ioredis package adds a standard version and a buffer version for each redis method there is, but not everyone is exposed through this typing. it's done at the line 83 of this code and is applied at the line 199 of this one. as i'm aware that not all methods provided will fit well with the buffer version typing, hmgetbuffer is an exception: it'll work as expected. @luin @dominikpalo fyk ", "commit_messages": " feat: adding hmsetbuffer and hmgetbuffer to ioredis.redis contract  fix: removing hmgetbuffer, as it not fit well typing yet ", "linked_issue_titles": "", "title": "adding hmgetbuffer to ioredis.redis contract"}
{"description": " add the itemstyle to legend symbol. the default borderwidth of legend symbol is 0, so the bordercolor only can be seen when the legend.itemstyle.borderwidth isn't 0. legend.itemstyle.borderwidth !== 0 the borderwidth of legend symbol only depends on  legend.itemstyle.borderwidth the bodercolor of legend symbol depends on legend.itemstyle.bordercolor and series[i].itemstyle.bordercolor, and the legend.itemstyle.bordercolor has higher priority. the bordercolor of emptycircle legend symbol is the same as color of series the legend bordercolor is incompatible with barbordercolor the former pr ", "commit_messages": " fix bug #7340  fix bug #7340 ", "linked_issue_titles": "", "title": "feature #7340. add the itemstyle to legend"}
{"description": " add new parameters to ovirt_vms module to support high performance vm:  ovirt_vms ansible version 2.4.2 ", "commit_messages": " ovirt_vms: add cpu_mode  ovirt_vms: add placement_policy  ovirt_vms: add cpu_pinning  ovirt_vms: add soundcard_enabled  ovirt_vms: add smartcard_enabled  ovirt_vms: add io_threads_enabled  ovirt_vms: add ballooning_enabled  ovirt_vms: add rng_device  ovirt_vms: add custom_properties  ovirt_vms: add memory_max ", "linked_issue_titles": "", "title": "support high performance vm in ovirt"}
{"description": " fix #1698 #1609 format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " subject to the actual startup context path  if not set the context path with the webserverinitializedevent then real '/' is context path  runningconfig support get from spring.properties configuration file  1. optimize log printing  2. improve the robustness and readability of your code  support datum is null case  repair httpgetlarge#httpgetlarge will call entity.getcontenttype().getelements() the contenttype is npe  normalize http response entity with responseentity by spring ", "linked_issue_titles": " nullpointer exception if sync content is empty ", "title": "repair the npe and optimize related code"}
{"description": " tests added / passed passes black pandas passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry i ran into this while implementing the hvplot backend. in hvplot you can do: df.hvplot.hist(y='y', by='category') but with the pandas version pd.options.plotting.backend= 'holoviews' df.plot.hist(y='y', by='category') will fail because data = data[y]  is called before the plotting is passed off to the backend. basically it seems like backend writers should be free to get the passed pandas objects with as little interference as possible. ", "commit_messages": " when using another backend, don't do the munging ahead of time  fixing data ", "linked_issue_titles": "", "title": "when using another plotting backend, minimize pre-processing"}
{"description": " before pr all modules were enabled by default. it is a lot of work to enable the ones i need and disable the rest. default: default_run = yes from python.d.conf # if \"default_run\" = \"yes\" the default for all modules is enabled (yes). # setting any of these to \"no\" will disable it. # if \"default_run\" = \"no\" the default for all modules is disabled (no). # setting any of these to \"yes\" will enable it. ", "commit_messages": " python.d.plugin: \"default_run\" option for python.d.conf added  python.d.plugin: python.d.conf update ", "linked_issue_titles": "", "title": "option to change default behavior (enabled/disabled) for python modules"}
{"description": " all packaging environment under docker, now it support: - os=fedora dist=25 - os=fedora dist=26 - os=ubuntu dist=trusty       //14.04 lts, only for build & test & appimage - os=ubuntu dist=xenial       //16.04 lts - os=ubuntu dist=zesty        //17.04 - os=ubuntu dist=artful        //17.10 - os=debian dist=jessie        //8 - os=debian dist=stretch      //9 and appveyor ci for windows. p.s. deb, rpm, appimage package for linux has been realized by the script .travis_linux.sh . i wish you can upload .deb, .rpm, .appimage and windows portable zip archive to github release. ", "commit_messages": " improvement of deb package  update  update  rpm and deb package & add appveyor  deploy to github release ", "linked_issue_titles": "", "title": "deb and rpm packaging & add appveyor"}
{"description": " format the pull request title like [issue #123] fix unknownexception when host config not exist. each commit in the pull request should have a meaningful subject line and body. write necessary unit-test to verify your logic correction, more mock a little better when cross module dependency exist. if the new feature or significant change is committed, please remember to add integration-test in test module. run mvn -b clean package apache-rat:check findbugs:findbugs -dmaven.test.skip=true to make sure basic checks pass. run mvn clean install -dskipits to make sure unit-test pass. run mvn clean test-compile failsafe:integration-test  to make sure integration-test pass. ", "commit_messages": " grpc port modified;change notify bugfix.  default member port fix  modify grpc port to offset  modify grpc port to offset ", "linked_issue_titles": "", "title": "tag publish bugfix; ignore server port for connection reset request."}
{"description": " i hereby agree to the terms of the cla available at:  check #3695 (comment) and further comments waiting for server start (via http pings) clickhouse-client added to clickhouse-server image, that is just a symlink but makes it possible to connect to the server running in the container in a natural way with simple sudo docker container exec -it container_name clickhouse-client. related to #580 wget added (actually waiting for accepting connections can be implemented w/o it, but wget is quite tiny and handy) greps changed to clickhouse extract-from-config format_schema_path added gosu moved higher (that makes rebuilds of image connected to lines below it cheaper) ", "commit_messages": " documenting numbers table function, verticalraw format, http sessions, http compression.  fixing bad copy-paste, shorten sample  fixing obsolete name of clickhouse-compressor  fix word end  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  merge remote-tracking branch 'upstream/master'  fixes from comments of #3695 ", "linked_issue_titles": "", "title": "docker fixes (related to #3695)"}
{"description": " opening up a new pr based on #10513 which uses @sgugger's new image_utils.py instead of torchvision for the image transformations, and is up-to-date with master. things to do: fix one integration test (currently vitfeatureextractor converts the numpy arrays into doubletensors, but the model expects floattensors) fix styling (make style is not working as expected on my machine, see remaining comments in previous pr) perhaps change pooler logic? design (and updated conversion script) currently at branch \"add_pooler_to_vit\" ", "commit_messages": " squash all commits into one  rebase with master  update vitfeatureextractor to use image_utils instead of torchvision  remove torchvision and add pillow  small docs improvement ", "linked_issue_titles": "", "title": "add vision transformer and vitfeatureextractor"}
{"description": " closes #23970 tests added / passed passes git diff upstream/master -u -- \"*.py\" | flake8 --diff whatsnew entry ", "commit_messages": " gh23970 added test-case that causes bug 23970  gh 23970 fixed source of the bug  bug would have impacted any groupby function that relied on observed  if it were true  gh23970 added relevant docstring to whatsnew ", "linked_issue_titles": " groupby observed=true not working for aggregating a column ", "title": "fix groupby observed=true when aggregating a column"}
{"description": " adding discussions links for faq - general as per 1785 updates to existing questions section i re-arranged the orders of few titles like dont use redux to appear together omitted this discussion  @markerikson please review ", "commit_messages": " adding few more discussions links to faq-general - when should i use redux  removing duplicate link ", "linked_issue_titles": "", "title": "faq general - discussion links for when should i use redux"}
{"description": " this rule replaces incorrect yum commands, such as yum isntall into yum install and yum remove into yum uninstall. ", "commit_messages": " - add skeleton code for yum_invalid_operation.py  - add test for rule/yum_invalid_operation  add: mocker for subprocess.popen.  fix: invalid yum_operations.  fix: added missing fixtures.  add: yum_invalid_operation implementation.  add: enabled_by_default variable for rules/yum_invalid_operation.  update readme. ", "linked_issue_titles": "", "title": "support for yum invalid commands."}
{"description": " if a promise is rejected, we should halt the entire application, which we can do by just calling abort(), which is more concise. this changed the return code from 1 to 7 in that case, which required updating a test. ", "commit_messages": " simplify node unhandledrejection-handling code  update test ", "linked_issue_titles": "", "title": "simplify the node rejection handling code"}
{"description": " when using ss through another socks5 proxy, the prev version still resolves ss server's domain name locally. this could lead to wrong results. this patch allow proxy module to resolve domain name itself. -socks5 proxy: just pass the domain name to socks5 proxy server cuz the protocol support domain name. -direct connect: still resolves locally and synchronously. ", "commit_messages": " let proxy module handle name resolving itself.  fix wrong output in proxyconnecttimer_elapsed.  let socks5 proxy handle server host's domain name.  don't resolve it locally because socks5 support domain name connection. ", "linked_issue_titles": "", "title": "resolving domain name through socks5 proxy"}
{"description": " since 3b6314c the pretty printer seems to only print trait bounds for ast::ty_path(...)s that have a generics arguments list. that seems wrong, so let's always print them. closes #9253, un-xfails test for #7673. ", "commit_messages": " pp: typo in comment  pp: also print bounds in paths with no generic params  since 3b6314c3 the pretty printer seems to only print trait bounds for  ast::ty_path(...)s that have a generics arguments list. that seems  wrong, so let's always print them.  closes #9253, un-xfails test for #7673. ", "linked_issue_titles": " pretty printer doesn't preserve built-in trait bounds on trait objects ", "title": "pretty-print bounds in paths with no generic params"}
{"description": " add more default layers!! optimize default layer keycode handling remove rgb twinkling, since not enough firmware space :'( disable split keyboard on viterbi, and make necessary changes (it's a macro pad, so ...) better handle multiple keyboard versions add destiny 2 specific keycodes to ergodox, since must use le monarque add planck rev6 specific code sadly, this misses a lot of my more recent code changes, since i'm using a very customized branch that includes stuff like the expanded startup functionality, custom tapping terms, arm audio fixes, etc. checklist: my code follows the code style of this project. i have read the contributing document. ( ", "commit_messages": " proper rules include  minor tweaks  minor tweaks  add desitny 2 swapped layout support  add keycode to keylogger  convert my viterbi keymaps  fix orthodox keyboard  add more default layers  make default layer keycodes more optimized  update gitlab ci yaml file  rev6 cleanup  fix kc_make macro  update gitlab ci yaml file  more gitlab ci changes  one final gitlab ci change  optimize kc_make  reformatting of config  feature creeeeeeep  planck rev6 updates ", "linked_issue_titles": "", "title": "update to drashna keymaps and userspace"}
{"description": " not sure if this would be useful or not, but i added a text editor that you can use through the file system. you can click a file in the file explorer and it will open a popup that displays the filename (and extension), and the content of the file that's currently there. i've provided screenshots as well. open in the tron-disrupted theme open in the red theme right now, the only kinds of files that can be opened are html, css, javascript, xml, yaml, java, c#, c++ and h, markdown, batch and shell, gdscript (godot engine), json (excludes the themes, keyboards, settings.json, and shortcuts.json), plain text, and log files, though that list can be expanded as needed. in the future, i might try to make the different file types able to be differentiated by their icons, though that's a project for another day. i might also have the text inside the textarea a little bigger, and maybe always white, because the red theme is really hard to read from the default monospace font. lmk if i need to make any changes ", "commit_messages": " fix #861  implement text editor feature - surge ", "linked_issue_titles": "", "title": "implement a text editor feature"}
{"description": " close #46201 and see more discussion in #46203 ", "commit_messages": " merge the lastest commits from author  do sync before closeintoreader to make sure we move most of the data to disk outside of the lock  modify comments in translog.rollgeneration  merge latest code from author  merge lastest code from author  trimunreferencedreaders: move sync translog operation outside writelock  trimunreferencedreaders: move try-catch inside if condition  merge latest code from author  merge from author  trimunreferencedreaders: sync before write lock ", "linked_issue_titles": " optimize translog writing by move sync outside writelock in trimunreferencedreaders ", "title": "sync before trimunreferencedreaders to improve index preformance"}
{"description": " during the development of atom-typescript they have added quite a bit of methods to atom's definitions, but the changes haven't been yet committed to this repo. i've added all their changes to atom.d.ts to this pull request and fixed the indentation a bit. ", "commit_messages": " add atom.d.ts from atom-typescript project  merge with the main branch  add typings for igrammar interface  fix indentation ", "linked_issue_titles": "", "title": "add definitions to atom.d.ts from atom-typescript"}
{"description": " contains two commits. please rebase and merge. revert 02bd71d. please read comment here. add a small code snippet to bring back the functionality of the importer. ", "commit_messages": " revert \" fixed importer duplicate detection for posts\"  refs #8717  - we decided to not changing the current importer behaviour  - no slug duplication detection means, importing posts can result in duplicates  fixed import test: post duplication detection within a file to import  no issue  - with  - this commit simply adds a small code snippet to reflect the importer behaviour  1) duplicate slugs *within* a file are getting ignored  2) existing posts in the database and posts to import with the same slug, result in duplicates  further improvements regarding duplication detection will happen via #8717. ", "linked_issue_titles": "", "title": "duplicate slugs revert && bring back importer behaviour for detection"}
{"description": " this adds the ignorecase option for createredirect in gatsby v2 (from #29714) but in a backwards compatible (without the breaking change of setting it to true by default) ", "commit_messages": " add ignorecase option for createredirect and support it in client side navigation  add typings for ignorecase  update packages/gatsby/src/redux/actions/public.js  prepare lowercased redirects at build time  add tests  remove only  switch to o(1) maps  update navigate as well  update packages/gatsby/index.d.ts  update packages/gatsby/cache-dir/navigation.js ", "linked_issue_titles": "", "title": "ignore case option in create redirect"}
{"description": " this pr fixes #7169 ", "commit_messages": " :lipstick: let -> const  maintain undo stack across text model disposal / creation  add more tests  add textchange  remove itextchange  split into lines manually  reduce usage of ivalidatededitoperation.lines  remove ivalidatededitoperation.lines  maintain version id across model disposing  compress consecutive edits in undo stack  reduce memory usage ", "linked_issue_titles": " keep undo stack between file close and reopen ", "title": "keep undo-redo stack elements after a model is disposed"}
{"description": " description: very small change, but it irritated me that mpd would write \"none\" when playing songs without meta-data. changes: mpd now shows file_name instead of \"none\" as the \"media_title\" i only changed five lines in the mpd component, and, as far as i could see, no test-cases exist in regards to the mpd component, so i didn't actually run any test cases to make sure it works, but you are very welcome to test it locally in case i made some massive mistake, however it should work. ", "commit_messages": " added support for filename  used the getter instead - minor mistake ", "linked_issue_titles": "", "title": "mpd now uses the filename if song doesn't have metadata"}
{"description": " fix for #4357. the issue is that when a dependency (dep a) defined in resolutions (includes dep a, dep b) depends on another resolution (dep b), then it expects to match its own nested dep b to the top level resolution dep b. so the first part of this fix is \"don't run resolutions map check when it's in flat mode\", which is what threw the invariant warning. second part of the fix is that we still want that nested dependency (dep b) of a resolution (dep a) to be resolved correctly. --flat mode solves this by collapsing all versions after the resolver is done. for resolutions, i'm adding a delay queue for requests with resolutions but no manifests found yet so that they will be resolved later. added tests in resolutions ", "commit_messages": " add tests  add delay queue  ignore resolutions when installed in flat mode ", "linked_issue_titles": "", "title": "fix #4357 - allow resolver to delay resolutions for nested dependencies"}
{"description": " remove some useless configure for bindings-generator of lua in the ini files of  tools/tolua, because these classes and functions no longer exist. ", "commit_messages": " update comment for lua  remove useless configure for bindings-generator of lua ", "linked_issue_titles": "", "title": "update comments of lua and remove some useless configure for bindings-generator of lua"}
{"description": " fix three different issues that affect the runtime's demangling to metadata: the verification enabled by swift_enable_mangled_name_verification could cause the metadata machinery to deadlock, because demangling to metadata was requesting complete metadata when it only needs abstract metadata. our mangling of generic parameter references, which are used in generic requirements (that runtime conditional conformances and runtime demangling depend on), could end up colliding, causing corrupted metadata. the resolution of generic parameter references used an older function signature for associated type access functions, which meant that we were calling it incorrectly... and getting bogus results. fixes sr-7553 / rdar://problem/39769906 ", "commit_messages": " [irgen] move the protocol conformance descriptor builder.  place it right there next to the witnesstablebuilder, because the  two should be the same thing. nfc  [runtime] only request abstract metadata when demangling to metadata.  when swift_enable_mangled_name_verification is set, we would end up  deadlocking when we encounter a metadata cycle. the demangling code only  requires abstract metadata, because at most it needs type identity and  filling in the type arguments of generics. update clients of  _gettypebymangledname to assert the kind of metadata they require.  [mangling] mangle protocol names in assoc-type-paths.  the mangling of associated type paths was only adding the names of  associated types, and not their enclosing protocols. this led to mangling  collisions that could lead to corrupted metadata. in the standard  library, for example, the generic requirements for the  unicode _parsingiterator in the standard library ended up encoding an  access to sequence.element rather than iteratorprotocol.element due  to the mangling conflict.  part of sr-7553 / rdar://problem/39769906.  [runtime] replace outdated signature for associated type access functions.  the resolution of generic parameter references, which is used for  checking generic requirements at runtime, was written in terms of an  outdated signature for associated type access functions that did not  account for the metadatarequest parameter or metadataresponse result.  use the existing associatedtypeaccessfunction typedef instead.  fixes sr-7553 / rdar://problem/39769906 ", "linked_issue_titles": "", "title": "fixes for demangling to metadata"}
{"description": " used to report td-1523, now able to display taos memory leak issues with python script. the check-in also included a so called valgrind error suppression file, generated using the valgrind tool itself, as the python run time does not always clean up all the memory it uses. without such suppression file, the taos related memory leaks will be hard to see among the numerous python memory leaks. ", "commit_messages": " enhanced crash_gen tool to test against multiple databases concurrently, getting ready to test against clusters  added tracking of longest time-consuming query in crash_gen tool  half way through enabling read/write check  added limited data verification to crash_gen tool, with -v option  minor crash_gen tweaks  adjusted crash_gen tool directory structure, added valgrind suppression file to expose client side memory leaks ", "linked_issue_titles": "", "title": "added valgrind memory check to crash_gen tool"}
{"description": " i took the provided (from other repo) download script which should now work on all platforms. tested all steps, removed some errors and inconsistencies, updated to rtm. i am not exactly sure about that iis - asp.net core registration step, if that may also improved over time. the dotnetcore download script left my nano in inconsistent state, if there is not enough disk space. i added a tiny check. for ref see also #2089 ", "commit_messages": " first changes to nano aspnetcore tutorial  further updates  update  docs and download script updated ", "linked_issue_titles": "", "title": "updated nano server tutorial to rtm and dotnet-download script."}
{"description": " the package does not already provide its own types, or cannot have its .d.ts files generated via --declaration create it with dts-gen --dt, not by basing it on an existing project. tslint.json should be present, and tsconfig.json should have noimplicitany, noimplicitthis, strictnullchecks, and strictfunctiontypes set to true. ", "commit_messages": " types for react-tag-autocomplete pkg  add ts version to declarion file  fix test errors ", "linked_issue_titles": "", "title": "add types for react-tag-autocomplete pkg"}
{"description": " this change integrates deno_ast and lazily caches/reuses swc ast in the language server. i've yet to come up with a benchmark i think is worthwhile to have... given that swc is already so fast this change is only noticable with very large files. i would say this isn't so much a performance improvement, but rather just a refactoring. closes #11345 closes #11854 ", "commit_messages": " documentdata - change bytes to source and make source and line_index non-optional  committing what i've done for backup purposes.  more work. for some reason the lsp tests fail when running together now though...  improve lazy_init, but now i just found out about once_cell crate. that would be better.  format.  use oncecell for lazy initialization as we already have it as a dependency and it may be added to the standard library in the future.  creating sourcefiletext.  extract out documentsource for reuse in sources.  format.  move lineindex into documentsource.  version bump, but looks like changes are required because of deno_doc changes  format ", "linked_issue_titles": " lsp: cache swc asts  support class static blocks (stage-3) ", "title": "use deno_ast and cache swc asts"}
{"description": " import_role: mention version from which behavior changed fix typos in documentation s/default/defaults/ s/the the/the/ s/functinality/functionality/ import_role doc and 2.7 porting guide ansible version 2.7 ", "commit_messages": " [doc] fix some typos  [doc] import_role: mention version from which behavior changed ", "linked_issue_titles": "", "title": "mention version from which behavior changed and fix some typos"}
{"description": " this pr fixes # #112755 ", "commit_messages": " debug: do not render checkmark in view menu for the debug console  ignore focus when toggling debug console visibility  render \"debug console\" action after a separator ", "linked_issue_titles": "", "title": "debug console view menu action polish"}
{"description": " description: this pr makes the following enhancements to the prometheus component: all metrics gain an additional domain label. a new state_change metric is incremented for each state change. checklist: local tests pass with tox. your pr cannot be merged unless tests pass ", "commit_messages": " add domain to labels  count state changes ", "linked_issue_titles": "", "title": "add domain to labels and count state changes to prometheus"}
{"description": " network/aos/aos_* ansible version ansible 2.3.0 (fix-aos-login cc16903b5c) last updated 2017/02/20 13:08:42 (gmt -700) config file = configured module search path = default w/o overrides change the name of the session variable in all aos_* modules to align with that is returned by aos_login module ", "commit_messages": " fix examples to make session variable homogeneous across all modules  fix parameter name in example, template not design_template ", "linked_issue_titles": "", "title": "network/aos - fix doc for session information"}
{"description": " others docs add cpp_extension  en doc, zh doc: #31187 ", "commit_messages": " split cxx/nvcc compile flags  enhance input argument check  rename extra_cflags into extrac_cxx_flags  add name checking in setup  fix test_dispatch failed  fix word typo and rm usless import statement  refine import statement  fix unittest failed  fix cuda flags error  add cpp_extension en doc ", "linked_issue_titles": "", "title": "[customop]add cpp_extension  en doc"}
{"description": " these two objectives are closely related. i included (1) a note in the docs to be explicit that xentropy is necessary when labels are not binary and (2) an example that makes the relationship clear for users coming at this with \"logistic regression\" in mind. non-binary labels are a trivial extension of binary ones under log-loss; any lack of generalization is in the code (i.e. enforcing int instead of float) rather than mathematical, and so it would be understandable if a user mistakenly tried applying binary with non-binary labels. if fact i was doing this in r and have yet to identify why it gave reasonable results and did not crash (while binary with non-binary labels does crash in python). ", "commit_messages": " note the relationship between binary and xentropy in the docs and provide an example that compares them ", "linked_issue_titles": "", "title": "clarify relationship between xentropy and binary"}
{"description": " as part of rust-lang/miri#1814, i realized that we currently allow deallocating immutable allocations. this pr fixes that, and also adds some new apis that are required to still support the existing miri backtrace support. r? @oli-obk ", "commit_messages": " reject deallocation of read-only allocations  avoid redundant immutability check ", "linked_issue_titles": "", "title": "fix deallocation of immutable allocations"}
{"description": " contribution to fix part of #15440 ensuring logisticregression methods pass numpy doc validation ", "commit_messages": " densify docstring fixed  fixed predict_log_proba doc  sparsify docstring update  set_params partial fix  logit score docstring fix  logistic predict_proba docstring fix  logistic get_params docstring fixed  logistic predict docstring fixes  logistic set_params docstring fix ", "linked_issue_titles": "", "title": "doc numpy doc validations to logisticregression"}
{"description": " fixes #30850. this pr improves the error messages shown when the return/instance type of the function/class used as a jsx component is not assignable to jsx.element or jsx.elementclass. i thought the problem is not specific to void; referring to constructor function is always misleading. so this pr fully replaces the current message with new ones. the new error messages refer to return type, instance type or element type depending on what call signatures the component has. also this pr changes the span of the error from whole jsx element to only its tag name so the actual cause is clearer. example source code: namespace jsx { export interface element { type: 'element'; } export interface elementclass { type: 'element-class'; } } const functioncomponent = () => ({ type: 'string', }); class classcomponent { foo = \"bar\" } const mixedcomponent = math.random() ? functioncomponent : classcomponent; const elem1 = <functioncomponent />; const elem2 = <classcomponent />; const elem3 = <mixedcomponent />; current behavior (ts3.5.3): test.tsx:20:15 - error ts2605: jsx element type '{ type: string; }' is not a constructor function for jsx elements. type '{ type: string; }' is missing the following properties from type 'element': props, key 20 const elem1 = <functioncomponent />; ~~~~~~~~~~~~~~~~~~~~~ test.tsx:21:15 - error ts2605: jsx element type 'classcomponent' is not a constructor function for jsx elements. type 'classcomponent' is missing the following properties from type 'elementclass': type, render, context, setstate, and 4 more. 21 const elem2 = <classcomponent />; ~~~~~~~~~~~~~~~~~~ test.tsx:22:15 - error ts2605: jsx element type 'classcomponent | { type: string; }' is not a constructor function for jsx elements. type 'classcomponent' is not assignable to type 'element | elementclass'. type 'classcomponent' is not assignable to type 'elementclass'. 22 const elem3 = <mixedcomponent />; ~~~~~~~~~~~~~~~~~~ found 3 errors. new behavior: index.tsx:20:16 - error ts2774: 'functioncomponent' cannot be used as a jsx component. its return type '{ type: string; }' is not a valid jsx element. types of property 'type' are incompatible. type 'string' is not assignable to type '\"element\"'. 20 const elem1 = <functioncomponent />; ~~~~~~~~~~~~~~~~~ index.tsx:21:16 - error ts2774: 'classcomponent' cannot be used as a jsx component. its instance type 'classcomponent' is not a valid jsx element. property 'type' is missing in type 'classcomponent' but required in type 'elementclass'. 21 const elem2 = <classcomponent />; ~~~~~~~~~~~~~~ index.tsx:6:5 6     type: 'element-class'; ~~~~ 'type' is declared here. index.tsx:22:16 - error ts2774: 'mixedcomponent' cannot be used as a jsx component. its element type 'classcomponent | { type: string; }' is not a valid jsx element. type 'classcomponent' is not assignable to type 'element | elementclass | null'. type 'classcomponent' is not assignable to type 'elementclass'. 22 const elem3 = <mixedcomponent />; ~~~~~~~~~~~~~~ found 3 errors. alternative option i chose to separate the new error messages to two parts: one is 'componentname' cannot be used as a jsx component.and the other isits return type '{0}' is not a valid jsx element.or similar. another option is to merge them into one so the new message is'componentname' cannot be used as a jsx component because its return type '{0}' is not a valid jsx element. i chose the first option for two reasons. one is that in this way we get the same top-level error message for all the three cases. the other reason is that the merged message, especially the part before '{0}', is too long. the cause of the error (the return type {0} in this case) should be reachable as easily as possible. this is achieved by chaining two messages as done in this pr. ", "commit_messages": " new diagnostic message for wrong jsx function component  component and mixed type  fix existing tests  add new test for jsx component return type error ", "linked_issue_titles": " better error message for void-returning functions used as jsx elements ", "title": "improve error message for invalid return type of jsx component"}
{"description": " backport of #17538. npm test passes tests are changed or added pr title follows semantic commit guidelines pr release notes describe the change in a way relevant to app developers, and are capitalized, punctuated, and past tense. notes: fixed offscreen rendering not working with viz compositor. ", "commit_messages": " fix: make osr work with viz compositor  fix: update osr patch  fix: update patch again  fix: update viz_osr.patch for macos  fix: gn check warnings  chore: no need to change softwareoutputdevicewinproxy  chore: add check in case we missed something  fix: consider scale factor when compare size  fix: make gpu osr work  fix: autofill popups with osr  chore: use unix line ending for osr_video_consumer  chore: code is already in defined(os_macosx)  fix: share same osr implementation on macos  this should also fix the crash when there is navigation on macos.  test: osr window should not crash after navigation  fix: make osr work on mac properly  fix: software osr on windows  fix: software osr on linux  fix: split local surface id allocation into two  fix: update patch for 5-0-x  fix: patch and update videoconsumer to report proper damage_rect ", "linked_issue_titles": "", "title": "port osr code to new viz compositor codepath (backport: 5-0-x)"}
{"description": " cache results from queries that use scripts if they use only deterministic api calls.  nondeterministic api calls are marked in the whitelist with the @nondeterministic annotation.  examples are math.random() and new date(). refs: #49466 ", "commit_messages": " notes  wiring from whitelist annotations to painlessmethod and painlessconstructor  generate isresultdeterministic  formatting, parseint is deterministic  wip  update whitelist based on core-infra discussion, map/set iterators are ok  revert linkedhashmap  maxaggregatortests.testdontcachescripts -> testcachescripts ", "linked_issue_titles": "", "title": "cache script results if deterministic"}
{"description": " this is the default set of keys used for jupyter notebooks, so it makes sense to support it too. note: this is only applied to the query source page i tried to make 314eae5 from the queryeditor component, without success. the main idea is not to have an annoying behavior of a new line added when you press shift+enter and the query cannot execute. -- -- ", "commit_messages": " add shift+enter for query execution  keep shortcut keys when execute button is disabled ", "linked_issue_titles": "", "title": "add shift+enter shortcut for query execution"}
{"description": " pull request to discuss what to do with the tests for internal eas (and one of the comments i still had in #21160) basically, i would keep the tests/extension/.. only for subclassing the base extension array test suite, and any array-specific functionality is tested in tests/arrays/.. (eg closed attribute for intervalarray, specific arithmetic behaviour for integerarray, ...) this means that when adding a test related to eas, we need to think about: is this testing something that is applicable to all eas? (-> add a base test to tests/extension/base so this is tested for all internal and external eas) or is this testing something specific to a particular ea? (-> add a test in tests/array/eatype/..) of course often there can be some ambiguity here. main reason that i would split them is that over time, we probably add a lot of ea-type-specific tests, and then keeping the general ones mixed with the specific ones will make it only confusing / hard to see what is going on. drawback is of course that it is tested in two places. in practice what i propose in this pr, is also what we already do for categorical at the moment: categorical has its own tests in tests/arrays/categorical (and probably also some in indexes and frame, ..), but we also run the base extension tests for categorical in tests/extension/ ", "commit_messages": " split integer array tests in tests/arrays/integer and tests/extension/integer  split interval tests ", "linked_issue_titles": "", "title": "restructure internal extension arrays tests (split between /arrays and /extension)"}
{"description": " this pr targets the next branch and not master you've included links to relevant issues, if any with #issue_num ", "commit_messages": " update readme 1 (manpages)  update 2 (create config.md)  readme update final 1  rename to config  readme update final 2  small update ", "linked_issue_titles": "", "title": "update to documentation by  raz0rr-two"}
{"description": " related to #19939 build on the top of #19939 add the couple of equation for gaussianprocessregression and a link to the book. add small optimizations: do not check for finite inputs when solving systems; use original paper algorithm and only solve triangular system instead of two triangular system ", "commit_messages": " use cho_solve when return_std=true  resolving doc issue  responding to comments, primarily style changes, minor revisions to test.  doc add reference gpr and equation as comments ", "linked_issue_titles": "", "title": "ehn/doc add reference and small optimizations for gpr"}
{"description": " backports the following 1.4 fixes to 1.3 since atom is still on that version and hitting these bugs: #7209 #7980 / ", "commit_messages": " add failing spec for missing remote properties  only set members when members exist  allow spec to be run multiple times in same runner  don't load remote properties until they are accessed  guard against missing members in setobjectmembers ", "linked_issue_titles": "", "title": "backport 1.4 remote module bug fixes to 1.3"}
{"description": " this is the 2nd try for #14631 to verify this: git clean -fdx to clean all local files. run tensorflow/contrib/lite/download_dependencies.sh verify that you see \"download_dependencies.sh completed successfully\", so the script is completed. verify these files are downloaded to correct location. tensorflow/contrib/lite/examples/ios/camera/data/labels.txt tensorflow/contrib/lite/examples/ios/camera/data/mobilenet_quant_v1_224.tflite tensorflow/contrib/lite/examples/ios/simple/data/labels.txt tensorflow/contrib/lite/examples/ios/simple/data/mobilenet_v1_1.0_224.tflite run tensorflow/contrib/lite/build_ios_universal_lib.sh to verify the library can be built. ", "commit_messages": " fix: can't build tflite after running download_dependencies.sh.  root cause: the script downloads files for building tflite for ios  example. it writes to downloads/ directory and conflicts with the  visibility rule \"**/*\" in build  retain lite/examples/ios/camera/data directory in git.  fix some bugs in download_dependencies.sh  * handle both the cases that the zip file has nested directories  or not.  * always use curl since wget sometimes has certificate problem  in some mac machines. ", "linked_issue_titles": "", "title": "fixing download_dependencies.sh bugs for generating tflite ios exmaples"}
{"description": " this pr is a follow up of #43691 and prevents a restart of the dispatcher if it has been configured without fault-tolerance. failing to do so will lead to a perpetual stream of warn messages on a dispatcher restart and unnecessarily extend the testing time without an immediate exit. @aaudiber until the enhancements are implemented to handle such scenarios (as per our discussion), this will help us in handling the upcoming test cases. ", "commit_messages": " prevent restart of dispatcher w/o fault-tolerance  remove unused import ", "linked_issue_titles": "", "title": "prevent restart of the dispatcher server w/o fault-tolerance, in the test bed"}
{"description": " this pr fix #4181, re-benchmark maskrcnn, and provide valid link of ckpt and log for cityscapes. ", "commit_messages": " fix #4181, invalid link in readme for maskrcnn cityscapes  undo  fix #4181, invalid link in readme for maskrcnn cityscapes  updating performance ", "linked_issue_titles": " invalid link in readme of cityscape ", "title": "fix invalid ckpt and log in maskrcnn cityscapes"}
{"description": " requirements for adding, changing, or removing a feature fill out the template below. any pull request that does not include enough information to be reviewed in a timely manner may be closed at the maintainers' discretion. the pull request must contribute a change that has been endorsed by the maintainer team. see details in the template below. the pull request must update the test suite to exercise the updated functionality. for guidance, please see  after you create the pull request, all status checks must be pass before a maintainer reviews your contribution. for more details, please see  issue or rfc endorsed by atom's maintainers #20071 also notarization is going to be a hard requirements this year. description of the change enabling codesign in hardened runtime and adding notarization as part of atom's build process. alternate designs we could migrate our code signing from cli to electron packager (oxs-sign) and implement the notarization using cli, if you will call that an alternate design, since it's all doing the exact same thing. possible drawbacks verification process the notarization didn't throw in the build process (in other words it succeeded). all ci tests are green. i downloaded the artifact (atom-mac.zip) and checked the codesign and notarization using cli. i didn't get the \"can't be open because apple can't check it for malicious software\" (check the screenshots for before and after) and i was able to launch the app normally without having to go to the download location and right-click to open the app. i did a smoke test by running the application to make sure basic io functions work (open a file, save a file, re-open a file). before: after: release notes ", "commit_messages": " upgrade macos image to majove to support notarization  enable hardend runtime for code-signing on mac  pass notarization credentials to the build script  add notarization to the build process  remove entitlement allow-jit and downgrade ci to macos 10.13  attempt fix by adding more entitlements  correct entitlements path  try to make the app work with minimum entitlements ", "linked_issue_titles": "", "title": "add notarization to macos app"}
{"description": " what this pr does / why we need it: in order to get istio to work with cockraochdb the port cannot be named grpc or it routes all traffic back to the pod that originated the traffic. to fix this, i broke the external and internal ports out into their own settings and then i can set the external port to be called grpc (thus leveraging istio's grpc featureset) and the internal port can be called something besides grpc (causing istio to use the protocol type field rather than infer from the name field.) i did some other tweaks along the way such as adding service annotations so i can use google internal load balancer for the service. which issue this pr fixes (optional, in fixes #<issue number>(, fixes #<issue_number>, ...) format, will close that issue when pr gets merged): fixes # ", "commit_messages": " [stable/cockroachdb] added support for node selector  merge with charts/stable  [stable/cockroachdb] added support for node selector  [stable/cockroachdb] added support for node selector  new chart stable/mysqldump (#4069)  * new chart stable/mysqldump  helps the user backup mysql databases to a persistent volume  * use chart.name from tpl, add app label  * add app/chart fixes to mysqldump-cron.yaml  * fix backofflimit in wrong place.  * exit gracefully if db host not specified  merge with charts/stable  chart version bump  added external and internal grpc port as options. also added options to customize service annotations. need these for istio config.  updated readme to include values i added. reformatted the table so it reads pretty in plaintext ", "linked_issue_titles": "", "title": "breakout ports to support istio"}
{"description": " the use_lstm flag is currently broken for tf and was never supported for pytorch. this pr fixes this issue by providing a modelv1-free lstm wrapper around any default model (tf or torch). add two short learning tests for ppo w/ use_lstm=true. closes issue #8615 closes issue #8615 i've run scripts/format.sh to lint the changes in this pr. i've included any doc changes needed for  i've made sure the tests are passing. note that there might be a few flaky tests, see the recent failure rates at  this pr is not tested (please justify below) ", "commit_messages": " wip.  wip.  wip.  wip and lint. ", "linked_issue_titles": "", "title": "fix use_lstm flag for modelv2 (w/o modelv1 wrapping) and add it for pytorch."}
{"description": " fixes #6998 i added a deprecationwarning to the class dpgmm and the class vbgmm, as well as public functions in dpgmm.py i added tests for these warnings in test_dpgmm.py @tguillemot ", "commit_messages": " added deprecation warnings to dpgmm and vbgmm classes and other functions  modified/added functions test_digamma, test_gammaln, test_log_normalize to check for deprecationwarning  added functions to test for deprecated warnings for wishart_log_det, wishart_logz  updated test_log_normalize function  fixed spelling in deprecationwarning for class dpgmm and  added deprecationwarning tests test_dpgmm_deprecation, test_vbgmm_deprecation  added blank lines near inserted deprecatedwarnings to conform to pep8  added blank lines and deleted trailing whitespace for pep8  removed 'import warnings' since not used ", "linked_issue_titles": " warning about dpgmm and vbgmm on instantiation ", "title": "adds deprecationwarning to dpgmm and vbgmm"}
{"description": " this pr fix the last consistency issue between scorer and metrics function (#2096). i finally chose to rename auc_score to roc_auc_score, auc_scorer to roc_auc_scorer to have the most explicit name. i haven't created an alias since i think that is a bad option. ", "commit_messages": " enh more explicit name for auc + consistency for scorer, fix #2096  doc put the narrative documentation of roc_curve and roc_auc_score in one place  fix search and replace misstake ", "linked_issue_titles": "", "title": "fix consistency issue between scorer string and metrics function"}
{"description": " for changelog. remove if this is non-significant change. short description (up to few sentences): forbid to specify a database when creating a temporary table. in previous versions, the database was silently ignored. ", "commit_messages": " forbid to specify a database when creating a temporary table [#clickhouse-4294]  added a test ", "linked_issue_titles": "", "title": "forbid temporary tables in database"}
{"description": " this is the last pr in the cable testing series (at least for now ): added channel_test generator added connection_test to app generator (unless --skip-action-cable) added \"action cable testing\" guides to \"testing\" guides added \"action cable testing\" as a highlight to 6.0 release notes (finally) added changelog entry. / ", "commit_messages": " add channel test generator  add connection_test to app generator ", "linked_issue_titles": "", "title": "add action cable testing guides and generators"}
{"description": " rebased version of #4090 waiting for travis to be green, and merging ", "commit_messages": " enh precomputed is now a valid metric for 'brute'  enh precomputed is now a valid metric for 'auto' neighbors  also, handle radius_neighbors case identically to kneighbors for precomputed  enh support precomputed neighbors where query != index  tst precomputed matrix validation in correct place  fix add _pairwise and test to neighborsbase  doc fix up parameter descriptions  fix broken rebase  tst add test for precomputed metric and x=none at predict  fix test with invalid input; simplify dbscan precomputed  tst: use a local random state ", "linked_issue_titles": "", "title": "support metric='precomputed' in nearest neighbors [rebased version of #4090]"}
{"description": " edward is a library for probabilistic programming with a few thousand active users. gpflow is a library for gaussian processes which also has an active user base. ", "commit_messages": " add edward to community page  add gpflow to community page ", "linked_issue_titles": "", "title": "add edward and gpflow to community page"}
{"description": " bump go.d.plugin version to v0.24.0 component name packaging install this branch, ensure there is no errors and go.d.plugin version is 0.24.0 ", "commit_messages": " packaging: bump go.d version to v0.24.0  packaging: update go.d checksums ", "linked_issue_titles": "", "title": "update go.d.plugin version to v0.24.0"}
{"description": " after refactoring the queries to make them parsable on the coordinating note and adding serialization and equals/hashcode capability to them. so far shapebuilders nested inside queries were still transported as a byte array that needs to be parsed later on the shard receiving the query. to be able to also serialize geo shapes this way, we also need to make all the implementations of shapebuilder implement writable. this pr adds this to pointbuilder, circlebuilder and envelopebuilder and also adds tests for serialization, equality and hashcode. relates to #14416 ", "commit_messages": " geo: make shapebuilders implement writable  we recently refactored the queries to make them parsable on the  coordinating note and adding serialization and equals/hashcode  capability to them. so far shapebuilders nested inside queries  were still transported as a byte array that needs to be parsed  later on the shard receiving the query. to be able to also  serialize geo shapes this way, we also need to make all the  implementations of shapebuilder implement writable.  this pr adds this to pointbuilder and also adds tests for  serialization, equality and hashcode.  making circlebuilder writable and adding equals/hashcode ", "linked_issue_titles": "", "title": "make pointbuilder, circlebuilder & envelopebuilder implement writable"}
{"description": " the following commits contain some cosmetic changes and a few optimisations for sql queries (specifically where conditions) generated for / used by smartplaylists. basically the idea is to use (not) exists instead of in because (not exists) can exit/break after the first match/mismatch in the subquery whereas in will always run the full sub-query. as verified by @popcornmix in ", "commit_messages": " smartplaylists: use simple where conditions instead of expensive in statements  smartplaylists: cosmetics in sql queries  smartplaylists: use select distinct in sql sub-queries  smartplaylists: replace sql in with sql exists in where conditions ", "linked_issue_titles": "", "title": "optimisations for sql queries generated for smartplaylists"}
{"description": " this pr changes the existing base64_cipher.py with an easy to understand script that explains how the base64 algorithm works under the hood. the solution is not necessarily faster, but i believe it will help people understand how the algorithm works and why it is possible to use base64 in steganography to conceal the existence of a piece of data. further more, i believe the base64_cipher.py name can be misleading as base64 is considered an encoding, and not a cipher. improve an existing solution. i have read contributing.md. all function parameters and return values are annotated with python type hints. all functions have doctests that pass the automated testing. if this pull request resolves one or more open issues then the commit message contains fixes: #{$issue_no}. ", "commit_messages": " rename base64_cipher.py to base64_encoding.py  edit base64_encoding.py ", "linked_issue_titles": "", "title": "replace base64_cipher.py with an easy to understand version"}
